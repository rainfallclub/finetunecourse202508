{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 7500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0004,
      "grad_norm": 13.512296676635742,
      "learning_rate": 1e-06,
      "logits/chosen": -2.699465751647949,
      "logits/rejected": -2.3847317695617676,
      "logps/chosen": -82.99998474121094,
      "logps/rejected": -54.078102111816406,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 1
    },
    {
      "epoch": 0.0008,
      "grad_norm": 11.800760269165039,
      "learning_rate": 9.998666666666665e-07,
      "logits/chosen": -2.609684944152832,
      "logits/rejected": -2.3874735832214355,
      "logps/chosen": -94.02216339111328,
      "logps/rejected": -54.92398452758789,
      "loss": 0.6986,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.02344703860580921,
      "rewards/margins": -0.010770607739686966,
      "rewards/rejected": -0.012676429934799671,
      "step": 2
    },
    {
      "epoch": 0.0012,
      "grad_norm": 15.781888008117676,
      "learning_rate": 9.997333333333333e-07,
      "logits/chosen": -2.5938620567321777,
      "logits/rejected": -2.1409411430358887,
      "logps/chosen": -105.30233764648438,
      "logps/rejected": -76.81292724609375,
      "loss": 0.6979,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.009686279110610485,
      "rewards/margins": -0.009347152896225452,
      "rewards/rejected": -0.00033912668004631996,
      "step": 3
    },
    {
      "epoch": 0.0016,
      "grad_norm": 15.159504890441895,
      "learning_rate": 9.996e-07,
      "logits/chosen": -2.7568912506103516,
      "logits/rejected": -2.5085556507110596,
      "logps/chosen": -88.6353988647461,
      "logps/rejected": -39.58189010620117,
      "loss": 0.687,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0022171020973473787,
      "rewards/margins": 0.01245336513966322,
      "rewards/rejected": -0.010236263275146484,
      "step": 4
    },
    {
      "epoch": 0.002,
      "grad_norm": 15.874883651733398,
      "learning_rate": 9.994666666666665e-07,
      "logits/chosen": -2.630089282989502,
      "logits/rejected": -2.332699775695801,
      "logps/chosen": -80.50376892089844,
      "logps/rejected": -88.54825592041016,
      "loss": 0.6845,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0030647278763353825,
      "rewards/margins": 0.017407799139618874,
      "rewards/rejected": -0.014343071728944778,
      "step": 5
    },
    {
      "epoch": 0.0024,
      "grad_norm": 14.87882137298584,
      "learning_rate": 9.993333333333333e-07,
      "logits/chosen": -2.573819875717163,
      "logits/rejected": -2.070141553878784,
      "logps/chosen": -83.9910888671875,
      "logps/rejected": -58.68234634399414,
      "loss": 0.6844,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.02292614057660103,
      "rewards/margins": 0.017689131200313568,
      "rewards/rejected": 0.005237007513642311,
      "step": 6
    },
    {
      "epoch": 0.0028,
      "grad_norm": 16.410667419433594,
      "learning_rate": 9.992e-07,
      "logits/chosen": -2.4251599311828613,
      "logits/rejected": -2.0627429485321045,
      "logps/chosen": -96.90115356445312,
      "logps/rejected": -78.18516540527344,
      "loss": 0.6984,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.010162354446947575,
      "rewards/margins": -0.01032943930476904,
      "rewards/rejected": 0.00016708392649888992,
      "step": 7
    },
    {
      "epoch": 0.0032,
      "grad_norm": 15.073379516601562,
      "learning_rate": 9.990666666666667e-07,
      "logits/chosen": -2.573678970336914,
      "logits/rejected": -2.5972378253936768,
      "logps/chosen": -90.11979675292969,
      "logps/rejected": -72.87448120117188,
      "loss": 0.6884,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.00668754568323493,
      "rewards/margins": 0.009442711248993874,
      "rewards/rejected": -0.0027551651000976562,
      "step": 8
    },
    {
      "epoch": 0.0036,
      "grad_norm": 14.440460205078125,
      "learning_rate": 9.989333333333333e-07,
      "logits/chosen": -2.5097997188568115,
      "logits/rejected": -2.1855015754699707,
      "logps/chosen": -85.04312896728516,
      "logps/rejected": -65.44865417480469,
      "loss": 0.683,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.011353683657944202,
      "rewards/margins": 0.020317651331424713,
      "rewards/rejected": -0.008963966742157936,
      "step": 9
    },
    {
      "epoch": 0.004,
      "grad_norm": 14.61590576171875,
      "learning_rate": 9.988e-07,
      "logits/chosen": -2.474048614501953,
      "logits/rejected": -2.284398078918457,
      "logps/chosen": -79.46929931640625,
      "logps/rejected": -50.45545196533203,
      "loss": 0.6907,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.013484764844179153,
      "rewards/margins": 0.004971505142748356,
      "rewards/rejected": 0.008513259701430798,
      "step": 10
    },
    {
      "epoch": 0.0044,
      "grad_norm": 18.79172134399414,
      "learning_rate": 9.986666666666667e-07,
      "logits/chosen": -2.4582128524780273,
      "logits/rejected": -2.475778102874756,
      "logps/chosen": -153.35076904296875,
      "logps/rejected": -111.25537109375,
      "loss": 0.6924,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.02016639895737171,
      "rewards/margins": 0.0017875675112009048,
      "rewards/rejected": 0.018378831446170807,
      "step": 11
    },
    {
      "epoch": 0.0048,
      "grad_norm": 19.26764678955078,
      "learning_rate": 9.985333333333332e-07,
      "logits/chosen": -2.281985282897949,
      "logits/rejected": -2.5365443229675293,
      "logps/chosen": -100.39356231689453,
      "logps/rejected": -110.58184051513672,
      "loss": 0.689,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0029582977294921875,
      "rewards/margins": 0.008327102288603783,
      "rewards/rejected": -0.01128540001809597,
      "step": 12
    },
    {
      "epoch": 0.0052,
      "grad_norm": 15.381803512573242,
      "learning_rate": 9.983999999999998e-07,
      "logits/chosen": -2.501955509185791,
      "logits/rejected": -2.5618739128112793,
      "logps/chosen": -84.88104248046875,
      "logps/rejected": -53.3974609375,
      "loss": 0.7075,
      "rewards/accuracies": 0.0,
      "rewards/chosen": -0.028794098645448685,
      "rewards/margins": -0.028472140431404114,
      "rewards/rejected": -0.0003219603095203638,
      "step": 13
    },
    {
      "epoch": 0.0056,
      "grad_norm": 16.027141571044922,
      "learning_rate": 9.982666666666666e-07,
      "logits/chosen": -2.557560920715332,
      "logits/rejected": -2.351749897003174,
      "logps/chosen": -105.24269104003906,
      "logps/rejected": -43.175270080566406,
      "loss": 0.6918,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0005825045518577099,
      "rewards/margins": 0.002749443519860506,
      "rewards/rejected": -0.002166938968002796,
      "step": 14
    },
    {
      "epoch": 0.006,
      "grad_norm": 14.150995254516602,
      "learning_rate": 9.981333333333332e-07,
      "logits/chosen": -2.5996270179748535,
      "logits/rejected": -2.085439682006836,
      "logps/chosen": -77.74247741699219,
      "logps/rejected": -59.589111328125,
      "loss": 0.7036,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.00223121652379632,
      "rewards/margins": -0.020827006548643112,
      "rewards/rejected": 0.023058224469423294,
      "step": 15
    },
    {
      "epoch": 0.0064,
      "grad_norm": 11.978816032409668,
      "learning_rate": 9.98e-07,
      "logits/chosen": -2.500481367111206,
      "logits/rejected": -2.0699245929718018,
      "logps/chosen": -84.57806396484375,
      "logps/rejected": -45.674522399902344,
      "loss": 0.6802,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02967376820743084,
      "rewards/margins": 0.02627391926944256,
      "rewards/rejected": 0.0033998489379882812,
      "step": 16
    },
    {
      "epoch": 0.0068,
      "grad_norm": 16.050321578979492,
      "learning_rate": 9.978666666666666e-07,
      "logits/chosen": -2.5159616470336914,
      "logits/rejected": -2.3357343673706055,
      "logps/chosen": -79.78278350830078,
      "logps/rejected": -69.8223876953125,
      "loss": 0.6741,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01166381873190403,
      "rewards/margins": 0.03853874281048775,
      "rewards/rejected": -0.026874924078583717,
      "step": 17
    },
    {
      "epoch": 0.0072,
      "grad_norm": 15.418329238891602,
      "learning_rate": 9.977333333333334e-07,
      "logits/chosen": -2.3759241104125977,
      "logits/rejected": -2.060605049133301,
      "logps/chosen": -110.97213745117188,
      "logps/rejected": -74.70889282226562,
      "loss": 0.7028,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0021480561699718237,
      "rewards/margins": -0.019138718023896217,
      "rewards/rejected": 0.021286774426698685,
      "step": 18
    },
    {
      "epoch": 0.0076,
      "grad_norm": 10.939030647277832,
      "learning_rate": 9.976e-07,
      "logits/chosen": -2.6569736003875732,
      "logits/rejected": -2.3801651000976562,
      "logps/chosen": -86.09681701660156,
      "logps/rejected": -48.259281158447266,
      "loss": 0.6906,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01016159076243639,
      "rewards/margins": 0.005191803444176912,
      "rewards/rejected": 0.004969787318259478,
      "step": 19
    },
    {
      "epoch": 0.008,
      "grad_norm": 13.668734550476074,
      "learning_rate": 9.974666666666666e-07,
      "logits/chosen": -2.514233350753784,
      "logits/rejected": -2.33058500289917,
      "logps/chosen": -74.27719116210938,
      "logps/rejected": -82.25919342041016,
      "loss": 0.703,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.01895770989358425,
      "rewards/margins": -0.019480323418974876,
      "rewards/rejected": 0.000522613525390625,
      "step": 20
    },
    {
      "epoch": 0.0084,
      "grad_norm": 13.443421363830566,
      "learning_rate": 9.973333333333332e-07,
      "logits/chosen": -2.5717074871063232,
      "logits/rejected": -2.5668039321899414,
      "logps/chosen": -62.510833740234375,
      "logps/rejected": -33.386478424072266,
      "loss": 0.6915,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.007451438810676336,
      "rewards/margins": 0.0033876425586640835,
      "rewards/rejected": -0.010839080438017845,
      "step": 21
    },
    {
      "epoch": 0.0088,
      "grad_norm": 14.936837196350098,
      "learning_rate": 9.972e-07,
      "logits/chosen": -2.441720485687256,
      "logits/rejected": -2.013104200363159,
      "logps/chosen": -103.34754943847656,
      "logps/rejected": -73.03929138183594,
      "loss": 0.7035,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0002662660554051399,
      "rewards/margins": -0.02056579478085041,
      "rewards/rejected": 0.020299529656767845,
      "step": 22
    },
    {
      "epoch": 0.0092,
      "grad_norm": 19.955310821533203,
      "learning_rate": 9.970666666666665e-07,
      "logits/chosen": -2.597564697265625,
      "logits/rejected": -2.3450510501861572,
      "logps/chosen": -175.91897583007812,
      "logps/rejected": -69.21991729736328,
      "loss": 0.6854,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.03135223686695099,
      "rewards/margins": 0.015633203089237213,
      "rewards/rejected": 0.015719031915068626,
      "step": 23
    },
    {
      "epoch": 0.0096,
      "grad_norm": 15.306673049926758,
      "learning_rate": 9.969333333333333e-07,
      "logits/chosen": -2.2763872146606445,
      "logits/rejected": -2.515639305114746,
      "logps/chosen": -84.45590209960938,
      "logps/rejected": -49.808170318603516,
      "loss": 0.6909,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.013363647274672985,
      "rewards/margins": 0.004770755767822266,
      "rewards/rejected": -0.018134403973817825,
      "step": 24
    },
    {
      "epoch": 0.01,
      "grad_norm": 14.171131134033203,
      "learning_rate": 9.968e-07,
      "logits/chosen": -2.4113850593566895,
      "logits/rejected": -1.797917366027832,
      "logps/chosen": -117.77029418945312,
      "logps/rejected": -71.93365478515625,
      "loss": 0.6794,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.04406891018152237,
      "rewards/margins": 0.028002548962831497,
      "rewards/rejected": 0.016066361218690872,
      "step": 25
    },
    {
      "epoch": 0.0104,
      "grad_norm": 19.268552780151367,
      "learning_rate": 9.966666666666667e-07,
      "logits/chosen": -2.3053956031799316,
      "logits/rejected": -1.9682464599609375,
      "logps/chosen": -164.64105224609375,
      "logps/rejected": -89.95523834228516,
      "loss": 0.6763,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026482392102479935,
      "rewards/margins": 0.033904265612363815,
      "rewards/rejected": -0.0074218749068677425,
      "step": 26
    },
    {
      "epoch": 0.0108,
      "grad_norm": 11.366241455078125,
      "learning_rate": 9.965333333333333e-07,
      "logits/chosen": -2.3886799812316895,
      "logits/rejected": -2.623533248901367,
      "logps/chosen": -87.4281997680664,
      "logps/rejected": -45.751773834228516,
      "loss": 0.6689,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.022022055462002754,
      "rewards/margins": 0.049080654978752136,
      "rewards/rejected": -0.02705860137939453,
      "step": 27
    },
    {
      "epoch": 0.0112,
      "grad_norm": 12.276991844177246,
      "learning_rate": 9.964e-07,
      "logits/chosen": -2.6753339767456055,
      "logits/rejected": -2.5755152702331543,
      "logps/chosen": -66.32839965820312,
      "logps/rejected": -51.785186767578125,
      "loss": 0.6974,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.00709114084020257,
      "rewards/margins": -0.008386040106415749,
      "rewards/rejected": 0.015477180480957031,
      "step": 28
    },
    {
      "epoch": 0.0116,
      "grad_norm": 12.189730644226074,
      "learning_rate": 9.962666666666667e-07,
      "logits/chosen": -2.750777244567871,
      "logits/rejected": -2.3039817810058594,
      "logps/chosen": -91.70169067382812,
      "logps/rejected": -43.99217224121094,
      "loss": 0.6958,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.003875351045280695,
      "rewards/margins": -0.005193901248276234,
      "rewards/rejected": 0.009069251827895641,
      "step": 29
    },
    {
      "epoch": 0.012,
      "grad_norm": 12.742350578308105,
      "learning_rate": 9.961333333333333e-07,
      "logits/chosen": -2.6927735805511475,
      "logits/rejected": -1.9487287998199463,
      "logps/chosen": -81.10741424560547,
      "logps/rejected": -50.937904357910156,
      "loss": 0.6738,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.018291665241122246,
      "rewards/margins": 0.03934631496667862,
      "rewards/rejected": -0.021054649725556374,
      "step": 30
    },
    {
      "epoch": 0.0124,
      "grad_norm": 17.87017250061035,
      "learning_rate": 9.959999999999999e-07,
      "logits/chosen": -2.2394914627075195,
      "logits/rejected": -1.8848414421081543,
      "logps/chosen": -175.58383178710938,
      "logps/rejected": -67.90876770019531,
      "loss": 0.682,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0006134033901616931,
      "rewards/margins": 0.022529983893036842,
      "rewards/rejected": -0.023143386468291283,
      "step": 31
    },
    {
      "epoch": 0.0128,
      "grad_norm": 13.451481819152832,
      "learning_rate": 9.958666666666667e-07,
      "logits/chosen": -2.60264253616333,
      "logits/rejected": -2.6713461875915527,
      "logps/chosen": -167.69235229492188,
      "logps/rejected": -36.244049072265625,
      "loss": 0.6712,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.027495574206113815,
      "rewards/margins": 0.04444437101483345,
      "rewards/rejected": -0.016948796808719635,
      "step": 32
    },
    {
      "epoch": 0.0132,
      "grad_norm": 11.41445255279541,
      "learning_rate": 9.957333333333332e-07,
      "logits/chosen": -2.4743499755859375,
      "logits/rejected": -3.0760891437530518,
      "logps/chosen": -72.44193267822266,
      "logps/rejected": -35.22481918334961,
      "loss": 0.6798,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01470870990306139,
      "rewards/margins": 0.026889897882938385,
      "rewards/rejected": -0.01218118704855442,
      "step": 33
    },
    {
      "epoch": 0.0136,
      "grad_norm": 14.52765941619873,
      "learning_rate": 9.956e-07,
      "logits/chosen": -2.7682414054870605,
      "logits/rejected": -2.3684468269348145,
      "logps/chosen": -111.35729217529297,
      "logps/rejected": -64.16927337646484,
      "loss": 0.6896,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01309051550924778,
      "rewards/margins": 0.007119942456483841,
      "rewards/rejected": 0.005970573518425226,
      "step": 34
    },
    {
      "epoch": 0.014,
      "grad_norm": 17.6096134185791,
      "learning_rate": 9.954666666666666e-07,
      "logits/chosen": -2.402313709259033,
      "logits/rejected": -1.9912583827972412,
      "logps/chosen": -138.64849853515625,
      "logps/rejected": -69.49003601074219,
      "loss": 0.7066,
      "rewards/accuracies": 0.0,
      "rewards/chosen": -0.009525299072265625,
      "rewards/margins": -0.02671661414206028,
      "rewards/rejected": 0.017191315069794655,
      "step": 35
    },
    {
      "epoch": 0.0144,
      "grad_norm": 20.915285110473633,
      "learning_rate": 9.953333333333332e-07,
      "logits/chosen": -2.607860565185547,
      "logits/rejected": -2.0417745113372803,
      "logps/chosen": -78.84552001953125,
      "logps/rejected": -145.231689453125,
      "loss": 0.6626,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026204491034150124,
      "rewards/margins": 0.062032509595155716,
      "rewards/rejected": -0.03582802042365074,
      "step": 36
    },
    {
      "epoch": 0.0148,
      "grad_norm": 10.696374893188477,
      "learning_rate": 9.952e-07,
      "logits/chosen": -2.656345844268799,
      "logits/rejected": -2.426760196685791,
      "logps/chosen": -68.73768615722656,
      "logps/rejected": -51.49125289916992,
      "loss": 0.6703,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03181963041424751,
      "rewards/margins": 0.04625149071216583,
      "rewards/rejected": -0.014431859366595745,
      "step": 37
    },
    {
      "epoch": 0.0152,
      "grad_norm": 12.351095199584961,
      "learning_rate": 9.950666666666666e-07,
      "logits/chosen": -2.601393699645996,
      "logits/rejected": -2.1656651496887207,
      "logps/chosen": -68.3328857421875,
      "logps/rejected": -50.550872802734375,
      "loss": 0.6829,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.012289809063076973,
      "rewards/margins": 0.020631026476621628,
      "rewards/rejected": -0.008341217413544655,
      "step": 38
    },
    {
      "epoch": 0.0156,
      "grad_norm": 14.899835586547852,
      "learning_rate": 9.949333333333332e-07,
      "logits/chosen": -2.4341554641723633,
      "logits/rejected": -2.3832039833068848,
      "logps/chosen": -121.84197998046875,
      "logps/rejected": -63.43353271484375,
      "loss": 0.6822,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02607898600399494,
      "rewards/margins": 0.021941661834716797,
      "rewards/rejected": 0.0041373251006007195,
      "step": 39
    },
    {
      "epoch": 0.016,
      "grad_norm": 18.286880493164062,
      "learning_rate": 9.948e-07,
      "logits/chosen": -2.2689571380615234,
      "logits/rejected": -2.1177425384521484,
      "logps/chosen": -120.97726440429688,
      "logps/rejected": -119.96501159667969,
      "loss": 0.6591,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.038445666432380676,
      "rewards/margins": 0.06965942680835724,
      "rewards/rejected": -0.031213760375976562,
      "step": 40
    },
    {
      "epoch": 0.0164,
      "grad_norm": 20.343961715698242,
      "learning_rate": 9.946666666666666e-07,
      "logits/chosen": -2.3058812618255615,
      "logits/rejected": -2.2559094429016113,
      "logps/chosen": -176.1468505859375,
      "logps/rejected": -109.3658447265625,
      "loss": 0.7054,
      "rewards/accuracies": 0.0,
      "rewards/chosen": -0.011562347412109375,
      "rewards/margins": -0.024274062365293503,
      "rewards/rejected": 0.012711715884506702,
      "step": 41
    },
    {
      "epoch": 0.0168,
      "grad_norm": 19.265945434570312,
      "learning_rate": 9.945333333333334e-07,
      "logits/chosen": -2.10456919670105,
      "logits/rejected": -2.0885188579559326,
      "logps/chosen": -226.7252655029297,
      "logps/rejected": -57.8664436340332,
      "loss": 0.6863,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.01588287390768528,
      "rewards/margins": 0.014054490253329277,
      "rewards/rejected": 0.0018283845856785774,
      "step": 42
    },
    {
      "epoch": 0.0172,
      "grad_norm": 15.925848007202148,
      "learning_rate": 9.944e-07,
      "logits/chosen": -2.379669189453125,
      "logits/rejected": -2.3110527992248535,
      "logps/chosen": -97.53451538085938,
      "logps/rejected": -67.13097381591797,
      "loss": 0.6792,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.022522736340761185,
      "rewards/margins": 0.028103256598114967,
      "rewards/rejected": -0.005580520257353783,
      "step": 43
    },
    {
      "epoch": 0.0176,
      "grad_norm": 12.444212913513184,
      "learning_rate": 9.942666666666665e-07,
      "logits/chosen": -2.6052088737487793,
      "logits/rejected": -2.2764878273010254,
      "logps/chosen": -88.61040496826172,
      "logps/rejected": -50.039825439453125,
      "loss": 0.6872,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.009527969174087048,
      "rewards/margins": 0.011935806833207607,
      "rewards/rejected": -0.0024078369606286287,
      "step": 44
    },
    {
      "epoch": 0.018,
      "grad_norm": 16.835895538330078,
      "learning_rate": 9.941333333333333e-07,
      "logits/chosen": -2.5566635131835938,
      "logits/rejected": -2.353781223297119,
      "logps/chosen": -99.1561279296875,
      "logps/rejected": -54.36686706542969,
      "loss": 0.6653,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026900101453065872,
      "rewards/margins": 0.05652580410242081,
      "rewards/rejected": -0.029625700786709785,
      "step": 45
    },
    {
      "epoch": 0.0184,
      "grad_norm": 12.362852096557617,
      "learning_rate": 9.94e-07,
      "logits/chosen": -2.629991054534912,
      "logits/rejected": -2.443228244781494,
      "logps/chosen": -79.53598022460938,
      "logps/rejected": -67.14981079101562,
      "loss": 0.6866,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.033950045704841614,
      "rewards/margins": 0.0133119598031044,
      "rewards/rejected": 0.020638084039092064,
      "step": 46
    },
    {
      "epoch": 0.0188,
      "grad_norm": 16.827966690063477,
      "learning_rate": 9.938666666666667e-07,
      "logits/chosen": -2.486583709716797,
      "logits/rejected": -2.125027656555176,
      "logps/chosen": -104.43228912353516,
      "logps/rejected": -182.9217071533203,
      "loss": 0.6898,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.011145401746034622,
      "rewards/margins": 0.0066162110306322575,
      "rewards/rejected": 0.004529190249741077,
      "step": 47
    },
    {
      "epoch": 0.0192,
      "grad_norm": 14.227279663085938,
      "learning_rate": 9.937333333333333e-07,
      "logits/chosen": -2.518037796020508,
      "logits/rejected": -2.3826684951782227,
      "logps/chosen": -113.6904067993164,
      "logps/rejected": -34.25845718383789,
      "loss": 0.6772,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.021072007715702057,
      "rewards/margins": 0.03217659145593643,
      "rewards/rejected": -0.011104583740234375,
      "step": 48
    },
    {
      "epoch": 0.0196,
      "grad_norm": 12.103313446044922,
      "learning_rate": 9.936e-07,
      "logits/chosen": -2.6242263317108154,
      "logits/rejected": -2.988600730895996,
      "logps/chosen": -88.62031555175781,
      "logps/rejected": -58.29010772705078,
      "loss": 0.6864,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.00823135394603014,
      "rewards/margins": 0.013660239987075329,
      "rewards/rejected": -0.005428886041045189,
      "step": 49
    },
    {
      "epoch": 0.02,
      "grad_norm": 15.732169151306152,
      "learning_rate": 9.934666666666667e-07,
      "logits/chosen": -2.5722672939300537,
      "logits/rejected": -2.276771068572998,
      "logps/chosen": -43.637081146240234,
      "logps/rejected": -58.75352478027344,
      "loss": 0.6804,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.01857910305261612,
      "rewards/margins": 0.02590942569077015,
      "rewards/rejected": -0.00733032263815403,
      "step": 50
    },
    {
      "epoch": 0.0204,
      "grad_norm": 26.60228729248047,
      "learning_rate": 9.933333333333333e-07,
      "logits/chosen": -2.095705032348633,
      "logits/rejected": -2.12764048576355,
      "logps/chosen": -229.4913330078125,
      "logps/rejected": -166.95782470703125,
      "loss": 0.6716,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.018387984484434128,
      "rewards/margins": 0.04353523254394531,
      "rewards/rejected": -0.025147248059511185,
      "step": 51
    },
    {
      "epoch": 0.0208,
      "grad_norm": 17.253746032714844,
      "learning_rate": 9.931999999999999e-07,
      "logits/chosen": -2.4018807411193848,
      "logits/rejected": -2.2065885066986084,
      "logps/chosen": -201.08590698242188,
      "logps/rejected": -46.73985290527344,
      "loss": 0.6619,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.052707672119140625,
      "rewards/margins": 0.0637744888663292,
      "rewards/rejected": -0.011066818609833717,
      "step": 52
    },
    {
      "epoch": 0.0212,
      "grad_norm": 16.046735763549805,
      "learning_rate": 9.930666666666667e-07,
      "logits/chosen": -2.292649269104004,
      "logits/rejected": -2.270784854888916,
      "logps/chosen": -84.51968383789062,
      "logps/rejected": -74.3475341796875,
      "loss": 0.6895,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.005035972688347101,
      "rewards/margins": 0.007237053010612726,
      "rewards/rejected": -0.012273025698959827,
      "step": 53
    },
    {
      "epoch": 0.0216,
      "grad_norm": 11.936999320983887,
      "learning_rate": 9.929333333333333e-07,
      "logits/chosen": -2.462177276611328,
      "logits/rejected": -2.3253426551818848,
      "logps/chosen": -90.78257751464844,
      "logps/rejected": -34.40665817260742,
      "loss": 0.6728,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04165840148925781,
      "rewards/margins": 0.04141588509082794,
      "rewards/rejected": 0.0002425194252282381,
      "step": 54
    },
    {
      "epoch": 0.022,
      "grad_norm": 14.90976619720459,
      "learning_rate": 9.928e-07,
      "logits/chosen": -2.8120932579040527,
      "logits/rejected": -2.3987555503845215,
      "logps/chosen": -93.51927185058594,
      "logps/rejected": -87.83679962158203,
      "loss": 0.6914,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.015320968814194202,
      "rewards/margins": 0.00360717810690403,
      "rewards/rejected": 0.011713790707290173,
      "step": 55
    },
    {
      "epoch": 0.0224,
      "grad_norm": 17.24989128112793,
      "learning_rate": 9.926666666666666e-07,
      "logits/chosen": -2.499271869659424,
      "logits/rejected": -2.340231418609619,
      "logps/chosen": -172.67999267578125,
      "logps/rejected": -54.464481353759766,
      "loss": 0.6751,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02993011474609375,
      "rewards/margins": 0.03647155687212944,
      "rewards/rejected": -0.006541442591696978,
      "step": 56
    },
    {
      "epoch": 0.0228,
      "grad_norm": 13.458093643188477,
      "learning_rate": 9.925333333333334e-07,
      "logits/chosen": -2.5802290439605713,
      "logits/rejected": -2.2431936264038086,
      "logps/chosen": -94.86028289794922,
      "logps/rejected": -71.93104553222656,
      "loss": 0.6877,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01495285052806139,
      "rewards/margins": 0.011006355285644531,
      "rewards/rejected": 0.003946495242416859,
      "step": 57
    },
    {
      "epoch": 0.0232,
      "grad_norm": 13.449041366577148,
      "learning_rate": 9.923999999999998e-07,
      "logits/chosen": -2.7058534622192383,
      "logits/rejected": -2.3879103660583496,
      "logps/chosen": -70.39569854736328,
      "logps/rejected": -45.199806213378906,
      "loss": 0.6661,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.018984222784638405,
      "rewards/margins": 0.054936982691287994,
      "rewards/rejected": -0.03595275804400444,
      "step": 58
    },
    {
      "epoch": 0.0236,
      "grad_norm": 10.055298805236816,
      "learning_rate": 9.922666666666666e-07,
      "logits/chosen": -2.8486075401306152,
      "logits/rejected": -2.3616437911987305,
      "logps/chosen": -71.697509765625,
      "logps/rejected": -45.288116455078125,
      "loss": 0.6786,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020900726318359375,
      "rewards/margins": 0.02929058112204075,
      "rewards/rejected": -0.008389854803681374,
      "step": 59
    },
    {
      "epoch": 0.024,
      "grad_norm": 13.124246597290039,
      "learning_rate": 9.921333333333332e-07,
      "logits/chosen": -2.6316449642181396,
      "logits/rejected": -2.147831916809082,
      "logps/chosen": -73.2223129272461,
      "logps/rejected": -66.27352905273438,
      "loss": 0.6788,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.04286670684814453,
      "rewards/margins": 0.029211807996034622,
      "rewards/rejected": 0.013654899783432484,
      "step": 60
    },
    {
      "epoch": 0.0244,
      "grad_norm": 13.702712059020996,
      "learning_rate": 9.92e-07,
      "logits/chosen": -2.564556121826172,
      "logits/rejected": -2.1452088356018066,
      "logps/chosen": -90.26545715332031,
      "logps/rejected": -74.82636260986328,
      "loss": 0.6796,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.028232574462890625,
      "rewards/margins": 0.027333451434969902,
      "rewards/rejected": 0.0008991240756586194,
      "step": 61
    },
    {
      "epoch": 0.0248,
      "grad_norm": 13.311633110046387,
      "learning_rate": 9.918666666666666e-07,
      "logits/chosen": -2.7074222564697266,
      "logits/rejected": -2.593219757080078,
      "logps/chosen": -108.9154052734375,
      "logps/rejected": -47.98976135253906,
      "loss": 0.6836,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.007992744445800781,
      "rewards/margins": 0.019226456061005592,
      "rewards/rejected": -0.011233711615204811,
      "step": 62
    },
    {
      "epoch": 0.0252,
      "grad_norm": 13.839876174926758,
      "learning_rate": 9.917333333333334e-07,
      "logits/chosen": -2.442014217376709,
      "logits/rejected": -2.348437786102295,
      "logps/chosen": -119.05526733398438,
      "logps/rejected": -58.61376953125,
      "loss": 0.6665,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05255012586712837,
      "rewards/margins": 0.05441684648394585,
      "rewards/rejected": -0.0018667220138013363,
      "step": 63
    },
    {
      "epoch": 0.0256,
      "grad_norm": 16.145259857177734,
      "learning_rate": 9.916e-07,
      "logits/chosen": -2.2904670238494873,
      "logits/rejected": -2.127653121948242,
      "logps/chosen": -169.77334594726562,
      "logps/rejected": -62.39577102661133,
      "loss": 0.6714,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.048482514917850494,
      "rewards/margins": 0.04414673149585724,
      "rewards/rejected": 0.0043357848189771175,
      "step": 64
    },
    {
      "epoch": 0.026,
      "grad_norm": 15.411185264587402,
      "learning_rate": 9.914666666666668e-07,
      "logits/chosen": -2.5380983352661133,
      "logits/rejected": -2.5589022636413574,
      "logps/chosen": -117.77030944824219,
      "logps/rejected": -61.31010818481445,
      "loss": 0.6746,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019069289788603783,
      "rewards/margins": 0.03751830756664276,
      "rewards/rejected": -0.018449019640684128,
      "step": 65
    },
    {
      "epoch": 0.0264,
      "grad_norm": 17.011415481567383,
      "learning_rate": 9.913333333333333e-07,
      "logits/chosen": -2.7496089935302734,
      "logits/rejected": -2.6306562423706055,
      "logps/chosen": -95.19454193115234,
      "logps/rejected": -99.60920715332031,
      "loss": 0.6859,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01324310339987278,
      "rewards/margins": 0.014463234692811966,
      "rewards/rejected": -0.0012201310601085424,
      "step": 66
    },
    {
      "epoch": 0.0268,
      "grad_norm": 18.157175064086914,
      "learning_rate": 9.912e-07,
      "logits/chosen": -2.4788269996643066,
      "logits/rejected": -2.194610595703125,
      "logps/chosen": -124.06230163574219,
      "logps/rejected": -120.83554077148438,
      "loss": 0.6755,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03191642835736275,
      "rewards/margins": 0.03573112562298775,
      "rewards/rejected": -0.003814697265625,
      "step": 67
    },
    {
      "epoch": 0.0272,
      "grad_norm": 13.854452133178711,
      "learning_rate": 9.910666666666665e-07,
      "logits/chosen": -2.703536033630371,
      "logits/rejected": -2.3545048236846924,
      "logps/chosen": -81.44841003417969,
      "logps/rejected": -60.54271697998047,
      "loss": 0.6738,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02294464036822319,
      "rewards/margins": 0.03924693912267685,
      "rewards/rejected": -0.01630230061709881,
      "step": 68
    },
    {
      "epoch": 0.0276,
      "grad_norm": 15.372726440429688,
      "learning_rate": 9.909333333333333e-07,
      "logits/chosen": -2.6919784545898438,
      "logits/rejected": -2.154071807861328,
      "logps/chosen": -91.09754943847656,
      "logps/rejected": -48.99240493774414,
      "loss": 0.6656,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026116561144590378,
      "rewards/margins": 0.05590953677892685,
      "rewards/rejected": -0.02979297749698162,
      "step": 69
    },
    {
      "epoch": 0.028,
      "grad_norm": 18.598440170288086,
      "learning_rate": 9.908e-07,
      "logits/chosen": -2.4918689727783203,
      "logits/rejected": -2.289350986480713,
      "logps/chosen": -192.07382202148438,
      "logps/rejected": -94.94775390625,
      "loss": 0.6654,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07462730258703232,
      "rewards/margins": 0.056461334228515625,
      "rewards/rejected": 0.018165970221161842,
      "step": 70
    },
    {
      "epoch": 0.0284,
      "grad_norm": 12.059795379638672,
      "learning_rate": 9.906666666666667e-07,
      "logits/chosen": -2.496755599975586,
      "logits/rejected": -2.3956716060638428,
      "logps/chosen": -87.79493713378906,
      "logps/rejected": -48.86542510986328,
      "loss": 0.6686,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.027042008936405182,
      "rewards/margins": 0.04969635233283043,
      "rewards/rejected": -0.022654343396425247,
      "step": 71
    },
    {
      "epoch": 0.0288,
      "grad_norm": 13.786430358886719,
      "learning_rate": 9.905333333333333e-07,
      "logits/chosen": -2.667698383331299,
      "logits/rejected": -3.0838546752929688,
      "logps/chosen": -98.4437255859375,
      "logps/rejected": -49.09233856201172,
      "loss": 0.6581,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.055107880383729935,
      "rewards/margins": 0.07133521884679794,
      "rewards/rejected": -0.016227342188358307,
      "step": 72
    },
    {
      "epoch": 0.0292,
      "grad_norm": 17.0825252532959,
      "learning_rate": 9.903999999999999e-07,
      "logits/chosen": -2.455509901046753,
      "logits/rejected": -2.337120294570923,
      "logps/chosen": -114.85538482666016,
      "logps/rejected": -94.40107727050781,
      "loss": 0.6597,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.048836518079042435,
      "rewards/margins": 0.06864280998706818,
      "rewards/rejected": -0.019806290045380592,
      "step": 73
    },
    {
      "epoch": 0.0296,
      "grad_norm": 13.381896018981934,
      "learning_rate": 9.902666666666667e-07,
      "logits/chosen": -2.7234864234924316,
      "logits/rejected": -2.494211196899414,
      "logps/chosen": -140.990966796875,
      "logps/rejected": -68.22091674804688,
      "loss": 0.6691,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.039679910987615585,
      "rewards/margins": 0.04859981685876846,
      "rewards/rejected": -0.008919905871152878,
      "step": 74
    },
    {
      "epoch": 0.03,
      "grad_norm": 17.78492546081543,
      "learning_rate": 9.901333333333333e-07,
      "logits/chosen": -2.6262316703796387,
      "logits/rejected": -2.537130355834961,
      "logps/chosen": -89.0415267944336,
      "logps/rejected": -46.291259765625,
      "loss": 0.6674,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.006882095709443092,
      "rewards/margins": 0.05229254066944122,
      "rewards/rejected": -0.04541044309735298,
      "step": 75
    },
    {
      "epoch": 0.0304,
      "grad_norm": 14.133370399475098,
      "learning_rate": 9.9e-07,
      "logits/chosen": -2.717761278152466,
      "logits/rejected": -2.5286049842834473,
      "logps/chosen": -106.68714904785156,
      "logps/rejected": -53.77918243408203,
      "loss": 0.664,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04736023023724556,
      "rewards/margins": 0.05907135084271431,
      "rewards/rejected": -0.01171112060546875,
      "step": 76
    },
    {
      "epoch": 0.0308,
      "grad_norm": 12.237464904785156,
      "learning_rate": 9.898666666666666e-07,
      "logits/chosen": -2.6619606018066406,
      "logits/rejected": -3.0190470218658447,
      "logps/chosen": -55.41109848022461,
      "logps/rejected": -55.00809097290039,
      "loss": 0.676,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.009251976385712624,
      "rewards/margins": 0.034774210304021835,
      "rewards/rejected": -0.025522232055664062,
      "step": 77
    },
    {
      "epoch": 0.0312,
      "grad_norm": 13.263189315795898,
      "learning_rate": 9.897333333333332e-07,
      "logits/chosen": -2.442291498184204,
      "logits/rejected": -2.313649892807007,
      "logps/chosen": -99.27287292480469,
      "logps/rejected": -63.071624755859375,
      "loss": 0.6644,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.048767853528261185,
      "rewards/margins": 0.05844078212976456,
      "rewards/rejected": -0.009672928601503372,
      "step": 78
    },
    {
      "epoch": 0.0316,
      "grad_norm": 13.274079322814941,
      "learning_rate": 9.896e-07,
      "logits/chosen": -2.7443978786468506,
      "logits/rejected": -2.7487587928771973,
      "logps/chosen": -78.2238540649414,
      "logps/rejected": -53.6631965637207,
      "loss": 0.6588,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.053751371800899506,
      "rewards/margins": 0.07030382752418518,
      "rewards/rejected": -0.016552448272705078,
      "step": 79
    },
    {
      "epoch": 0.032,
      "grad_norm": 13.446778297424316,
      "learning_rate": 9.894666666666666e-07,
      "logits/chosen": -2.564119815826416,
      "logits/rejected": -2.544692039489746,
      "logps/chosen": -101.3280029296875,
      "logps/rejected": -47.65416717529297,
      "loss": 0.6877,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.016594696789979935,
      "rewards/margins": 0.010939503088593483,
      "rewards/rejected": 0.005655193235725164,
      "step": 80
    },
    {
      "epoch": 0.0324,
      "grad_norm": 9.982138633728027,
      "learning_rate": 9.893333333333332e-07,
      "logits/chosen": -2.643305778503418,
      "logits/rejected": -2.232400894165039,
      "logps/chosen": -53.300933837890625,
      "logps/rejected": -46.48255920410156,
      "loss": 0.6924,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.00320777902379632,
      "rewards/margins": 0.001559639349579811,
      "rewards/rejected": 0.0016481396742165089,
      "step": 81
    },
    {
      "epoch": 0.0328,
      "grad_norm": 14.612065315246582,
      "learning_rate": 9.892e-07,
      "logits/chosen": -2.7158446311950684,
      "logits/rejected": -2.4164884090423584,
      "logps/chosen": -68.76417541503906,
      "logps/rejected": -54.44032287597656,
      "loss": 0.6598,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.029139423742890358,
      "rewards/margins": 0.06802034378051758,
      "rewards/rejected": -0.03888092190027237,
      "step": 82
    },
    {
      "epoch": 0.0332,
      "grad_norm": 10.603015899658203,
      "learning_rate": 9.890666666666666e-07,
      "logits/chosen": -2.8636293411254883,
      "logits/rejected": -2.80703067779541,
      "logps/chosen": -50.05656433105469,
      "logps/rejected": -42.56791687011719,
      "loss": 0.6615,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04291858524084091,
      "rewards/margins": 0.0647699385881424,
      "rewards/rejected": -0.021851349622011185,
      "step": 83
    },
    {
      "epoch": 0.0336,
      "grad_norm": 11.133346557617188,
      "learning_rate": 9.889333333333334e-07,
      "logits/chosen": -2.624326467514038,
      "logits/rejected": -2.0948121547698975,
      "logps/chosen": -59.76945877075195,
      "logps/rejected": -51.22698211669922,
      "loss": 0.6661,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01655559614300728,
      "rewards/margins": 0.055228427052497864,
      "rewards/rejected": -0.038672830909490585,
      "step": 84
    },
    {
      "epoch": 0.034,
      "grad_norm": 11.83665657043457,
      "learning_rate": 9.888e-07,
      "logits/chosen": -2.7608559131622314,
      "logits/rejected": -2.5418596267700195,
      "logps/chosen": -78.26544189453125,
      "logps/rejected": -52.227413177490234,
      "loss": 0.6727,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.029183387756347656,
      "rewards/margins": 0.04127636179327965,
      "rewards/rejected": -0.012092972174286842,
      "step": 85
    },
    {
      "epoch": 0.0344,
      "grad_norm": 10.245931625366211,
      "learning_rate": 9.886666666666665e-07,
      "logits/chosen": -2.7059130668640137,
      "logits/rejected": -2.4621920585632324,
      "logps/chosen": -74.52787017822266,
      "logps/rejected": -46.70286560058594,
      "loss": 0.677,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04314785078167915,
      "rewards/margins": 0.032706454396247864,
      "rewards/rejected": 0.010441399179399014,
      "step": 86
    },
    {
      "epoch": 0.0348,
      "grad_norm": 13.097764015197754,
      "learning_rate": 9.885333333333333e-07,
      "logits/chosen": -2.5814852714538574,
      "logits/rejected": -2.0646822452545166,
      "logps/chosen": -93.29955291748047,
      "logps/rejected": -70.37939453125,
      "loss": 0.6635,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05102997273206711,
      "rewards/margins": 0.06035767123103142,
      "rewards/rejected": -0.00932769849896431,
      "step": 87
    },
    {
      "epoch": 0.0352,
      "grad_norm": 14.86804485321045,
      "learning_rate": 9.884e-07,
      "logits/chosen": -2.7476186752319336,
      "logits/rejected": -2.6740574836730957,
      "logps/chosen": -114.8035888671875,
      "logps/rejected": -42.23850631713867,
      "loss": 0.6623,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.040073394775390625,
      "rewards/margins": 0.06300163269042969,
      "rewards/rejected": -0.022928237915039062,
      "step": 88
    },
    {
      "epoch": 0.0356,
      "grad_norm": 14.039629936218262,
      "learning_rate": 9.882666666666665e-07,
      "logits/chosen": -2.5291223526000977,
      "logits/rejected": -2.2298779487609863,
      "logps/chosen": -93.63629150390625,
      "logps/rejected": -43.524261474609375,
      "loss": 0.6671,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.030557632446289062,
      "rewards/margins": 0.05281639099121094,
      "rewards/rejected": -0.022258758544921875,
      "step": 89
    },
    {
      "epoch": 0.036,
      "grad_norm": 9.977744102478027,
      "learning_rate": 9.881333333333333e-07,
      "logits/chosen": -2.7665982246398926,
      "logits/rejected": -2.509946823120117,
      "logps/chosen": -61.11590576171875,
      "logps/rejected": -50.359230041503906,
      "loss": 0.6903,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0018201828934252262,
      "rewards/margins": 0.005820083431899548,
      "rewards/rejected": -0.003999901004135609,
      "step": 90
    },
    {
      "epoch": 0.0364,
      "grad_norm": 13.188657760620117,
      "learning_rate": 9.88e-07,
      "logits/chosen": -2.397639751434326,
      "logits/rejected": -2.0545079708099365,
      "logps/chosen": -98.88114929199219,
      "logps/rejected": -85.0347900390625,
      "loss": 0.6694,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04599189758300781,
      "rewards/margins": 0.0480014830827713,
      "rewards/rejected": -0.002009582705795765,
      "step": 91
    },
    {
      "epoch": 0.0368,
      "grad_norm": 21.91863250732422,
      "learning_rate": 9.878666666666667e-07,
      "logits/chosen": -2.568302631378174,
      "logits/rejected": -2.4410510063171387,
      "logps/chosen": -240.68386840820312,
      "logps/rejected": -55.38026428222656,
      "loss": 0.6423,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07412414252758026,
      "rewards/margins": 0.1045541763305664,
      "rewards/rejected": -0.030430030077695847,
      "step": 92
    },
    {
      "epoch": 0.0372,
      "grad_norm": 11.358046531677246,
      "learning_rate": 9.877333333333333e-07,
      "logits/chosen": -2.62086820602417,
      "logits/rejected": -2.4644808769226074,
      "logps/chosen": -59.58660888671875,
      "logps/rejected": -55.48918151855469,
      "loss": 0.6718,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.027381516993045807,
      "rewards/margins": 0.04310321807861328,
      "rewards/rejected": -0.015721702948212624,
      "step": 93
    },
    {
      "epoch": 0.0376,
      "grad_norm": 11.617855072021484,
      "learning_rate": 9.876e-07,
      "logits/chosen": -2.428567886352539,
      "logits/rejected": -2.324681282043457,
      "logps/chosen": -80.64247131347656,
      "logps/rejected": -47.71152114868164,
      "loss": 0.6766,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04334449768066406,
      "rewards/margins": 0.033303454518318176,
      "rewards/rejected": 0.01004104595631361,
      "step": 94
    },
    {
      "epoch": 0.038,
      "grad_norm": 10.020343780517578,
      "learning_rate": 9.874666666666667e-07,
      "logits/chosen": -2.6952626705169678,
      "logits/rejected": -2.6267573833465576,
      "logps/chosen": -54.65968322753906,
      "logps/rejected": -34.31790542602539,
      "loss": 0.6549,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.052095986902713776,
      "rewards/margins": 0.07813616096973419,
      "rewards/rejected": -0.026040174067020416,
      "step": 95
    },
    {
      "epoch": 0.0384,
      "grad_norm": 15.179516792297363,
      "learning_rate": 9.873333333333333e-07,
      "logits/chosen": -2.2198503017425537,
      "logits/rejected": -1.8829281330108643,
      "logps/chosen": -127.65184020996094,
      "logps/rejected": -81.86521911621094,
      "loss": 0.6454,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0845867171883583,
      "rewards/margins": 0.09787388145923615,
      "rewards/rejected": -0.013287163339555264,
      "step": 96
    },
    {
      "epoch": 0.0388,
      "grad_norm": 15.83975601196289,
      "learning_rate": 9.871999999999998e-07,
      "logits/chosen": -2.8075037002563477,
      "logits/rejected": -2.473984479904175,
      "logps/chosen": -103.66439056396484,
      "logps/rejected": -45.933570861816406,
      "loss": 0.6359,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06424102932214737,
      "rewards/margins": 0.11804886162281036,
      "rewards/rejected": -0.053807832300662994,
      "step": 97
    },
    {
      "epoch": 0.0392,
      "grad_norm": 15.903670310974121,
      "learning_rate": 9.870666666666666e-07,
      "logits/chosen": -2.6155166625976562,
      "logits/rejected": -2.2520856857299805,
      "logps/chosen": -109.43702697753906,
      "logps/rejected": -65.6524429321289,
      "loss": 0.629,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06921043246984482,
      "rewards/margins": 0.1326616257429123,
      "rewards/rejected": -0.06345120072364807,
      "step": 98
    },
    {
      "epoch": 0.0396,
      "grad_norm": 17.621440887451172,
      "learning_rate": 9.869333333333332e-07,
      "logits/chosen": -2.5486209392547607,
      "logits/rejected": -2.263875722885132,
      "logps/chosen": -91.68687438964844,
      "logps/rejected": -79.24162292480469,
      "loss": 0.6476,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07293548434972763,
      "rewards/margins": 0.09323825687170029,
      "rewards/rejected": -0.020302772521972656,
      "step": 99
    },
    {
      "epoch": 0.04,
      "grad_norm": 15.494315147399902,
      "learning_rate": 9.868e-07,
      "logits/chosen": -2.367539882659912,
      "logits/rejected": -2.148068904876709,
      "logps/chosen": -89.60328674316406,
      "logps/rejected": -104.20743560791016,
      "loss": 0.6635,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07278557121753693,
      "rewards/margins": 0.06026153266429901,
      "rewards/rejected": 0.012524032965302467,
      "step": 100
    },
    {
      "epoch": 0.0404,
      "grad_norm": 14.173794746398926,
      "learning_rate": 9.866666666666666e-07,
      "logits/chosen": -2.353376865386963,
      "logits/rejected": -2.206512928009033,
      "logps/chosen": -98.37272644042969,
      "logps/rejected": -51.838783264160156,
      "loss": 0.6398,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09947815537452698,
      "rewards/margins": 0.10964564979076385,
      "rewards/rejected": -0.010167503729462624,
      "step": 101
    },
    {
      "epoch": 0.0408,
      "grad_norm": 12.766595840454102,
      "learning_rate": 9.865333333333334e-07,
      "logits/chosen": -2.3131463527679443,
      "logits/rejected": -2.2532167434692383,
      "logps/chosen": -70.44921875,
      "logps/rejected": -49.855384826660156,
      "loss": 0.6628,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05134925991296768,
      "rewards/margins": 0.06220264732837677,
      "rewards/rejected": -0.010853385552763939,
      "step": 102
    },
    {
      "epoch": 0.0412,
      "grad_norm": 17.606731414794922,
      "learning_rate": 9.864e-07,
      "logits/chosen": -2.49942684173584,
      "logits/rejected": -1.6951868534088135,
      "logps/chosen": -135.3409881591797,
      "logps/rejected": -96.83672332763672,
      "loss": 0.6751,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026133347302675247,
      "rewards/margins": 0.03673362731933594,
      "rewards/rejected": -0.010600280947983265,
      "step": 103
    },
    {
      "epoch": 0.0416,
      "grad_norm": 17.221052169799805,
      "learning_rate": 9.862666666666666e-07,
      "logits/chosen": -2.149052858352661,
      "logits/rejected": -2.3621482849121094,
      "logps/chosen": -164.6374053955078,
      "logps/rejected": -41.60797882080078,
      "loss": 0.6398,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.104949951171875,
      "rewards/margins": 0.11002416163682938,
      "rewards/rejected": -0.005074214655905962,
      "step": 104
    },
    {
      "epoch": 0.042,
      "grad_norm": 14.42043399810791,
      "learning_rate": 9.861333333333332e-07,
      "logits/chosen": -2.786414861679077,
      "logits/rejected": -2.4971466064453125,
      "logps/chosen": -65.34880065917969,
      "logps/rejected": -45.960384368896484,
      "loss": 0.653,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05068321153521538,
      "rewards/margins": 0.08209991455078125,
      "rewards/rejected": -0.03141670301556587,
      "step": 105
    },
    {
      "epoch": 0.0424,
      "grad_norm": 11.710993766784668,
      "learning_rate": 9.86e-07,
      "logits/chosen": -2.6763243675231934,
      "logits/rejected": -2.719191074371338,
      "logps/chosen": -106.65567779541016,
      "logps/rejected": -23.993087768554688,
      "loss": 0.672,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.040413666516542435,
      "rewards/margins": 0.042876627296209335,
      "rewards/rejected": -0.002462959149852395,
      "step": 106
    },
    {
      "epoch": 0.0428,
      "grad_norm": 19.654922485351562,
      "learning_rate": 9.858666666666665e-07,
      "logits/chosen": -2.1038625240325928,
      "logits/rejected": -1.8920645713806152,
      "logps/chosen": -156.963623046875,
      "logps/rejected": -108.44174194335938,
      "loss": 0.6381,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10430603474378586,
      "rewards/margins": 0.11325035244226456,
      "rewards/rejected": -0.008944319561123848,
      "step": 107
    },
    {
      "epoch": 0.0432,
      "grad_norm": 15.515430450439453,
      "learning_rate": 9.857333333333333e-07,
      "logits/chosen": -2.73183012008667,
      "logits/rejected": -2.618557929992676,
      "logps/chosen": -53.38029861450195,
      "logps/rejected": -62.145484924316406,
      "loss": 0.6254,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.040489960461854935,
      "rewards/margins": 0.14495545625686646,
      "rewards/rejected": -0.10446548461914062,
      "step": 108
    },
    {
      "epoch": 0.0436,
      "grad_norm": 12.753960609436035,
      "learning_rate": 9.856e-07,
      "logits/chosen": -2.7009942531585693,
      "logits/rejected": -2.6352410316467285,
      "logps/chosen": -98.31204986572266,
      "logps/rejected": -66.18223571777344,
      "loss": 0.6619,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03813285753130913,
      "rewards/margins": 0.06356201320886612,
      "rewards/rejected": -0.025429153814911842,
      "step": 109
    },
    {
      "epoch": 0.044,
      "grad_norm": 17.53839874267578,
      "learning_rate": 9.854666666666667e-07,
      "logits/chosen": -2.4905266761779785,
      "logits/rejected": -2.14811372756958,
      "logps/chosen": -129.27639770507812,
      "logps/rejected": -72.30937194824219,
      "loss": 0.6536,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05814514309167862,
      "rewards/margins": 0.08247547596693039,
      "rewards/rejected": -0.02433032914996147,
      "step": 110
    },
    {
      "epoch": 0.0444,
      "grad_norm": 15.272439956665039,
      "learning_rate": 9.853333333333333e-07,
      "logits/chosen": -2.4573404788970947,
      "logits/rejected": -2.2240264415740967,
      "logps/chosen": -101.48109436035156,
      "logps/rejected": -50.78173065185547,
      "loss": 0.6483,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06268005818128586,
      "rewards/margins": 0.0917806625366211,
      "rewards/rejected": -0.029100609943270683,
      "step": 111
    },
    {
      "epoch": 0.0448,
      "grad_norm": 12.539530754089355,
      "learning_rate": 9.852e-07,
      "logits/chosen": -2.3986291885375977,
      "logits/rejected": -2.4601612091064453,
      "logps/chosen": -88.30593872070312,
      "logps/rejected": -29.84058952331543,
      "loss": 0.6674,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03644371032714844,
      "rewards/margins": 0.052216436713933945,
      "rewards/rejected": -0.015772724524140358,
      "step": 112
    },
    {
      "epoch": 0.0452,
      "grad_norm": 21.501115798950195,
      "learning_rate": 9.850666666666667e-07,
      "logits/chosen": -2.2088873386383057,
      "logits/rejected": -2.1818971633911133,
      "logps/chosen": -187.82803344726562,
      "logps/rejected": -115.54207611083984,
      "loss": 0.6502,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.039276886731386185,
      "rewards/margins": 0.08954544365406036,
      "rewards/rejected": -0.05026855319738388,
      "step": 113
    },
    {
      "epoch": 0.0456,
      "grad_norm": 15.077722549438477,
      "learning_rate": 9.849333333333333e-07,
      "logits/chosen": -2.657918930053711,
      "logits/rejected": -2.262918710708618,
      "logps/chosen": -111.15251922607422,
      "logps/rejected": -56.687870025634766,
      "loss": 0.6413,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08632317185401917,
      "rewards/margins": 0.1066741943359375,
      "rewards/rejected": -0.020351028069853783,
      "step": 114
    },
    {
      "epoch": 0.046,
      "grad_norm": 19.322227478027344,
      "learning_rate": 9.847999999999999e-07,
      "logits/chosen": -2.2761635780334473,
      "logits/rejected": -2.0277206897735596,
      "logps/chosen": -159.23773193359375,
      "logps/rejected": -127.10931396484375,
      "loss": 0.6044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14540863037109375,
      "rewards/margins": 0.18625202775001526,
      "rewards/rejected": -0.04084338992834091,
      "step": 115
    },
    {
      "epoch": 0.0464,
      "grad_norm": 15.679142951965332,
      "learning_rate": 9.846666666666667e-07,
      "logits/chosen": -2.621067523956299,
      "logits/rejected": -2.006695508956909,
      "logps/chosen": -102.19481658935547,
      "logps/rejected": -63.176849365234375,
      "loss": 0.6253,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07461357116699219,
      "rewards/margins": 0.14079990983009338,
      "rewards/rejected": -0.0661863386631012,
      "step": 116
    },
    {
      "epoch": 0.0468,
      "grad_norm": 15.067336082458496,
      "learning_rate": 9.845333333333333e-07,
      "logits/chosen": -2.492436170578003,
      "logits/rejected": -2.156163215637207,
      "logps/chosen": -113.13489532470703,
      "logps/rejected": -67.87509155273438,
      "loss": 0.6329,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1063573881983757,
      "rewards/margins": 0.12569676339626312,
      "rewards/rejected": -0.019339371472597122,
      "step": 117
    },
    {
      "epoch": 0.0472,
      "grad_norm": 10.228123664855957,
      "learning_rate": 9.844e-07,
      "logits/chosen": -2.80379581451416,
      "logits/rejected": -2.3772854804992676,
      "logps/chosen": -79.30857849121094,
      "logps/rejected": -49.2274169921875,
      "loss": 0.6687,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.016634751111268997,
      "rewards/margins": 0.04958648979663849,
      "rewards/rejected": -0.03295173868536949,
      "step": 118
    },
    {
      "epoch": 0.0476,
      "grad_norm": 12.849050521850586,
      "learning_rate": 9.842666666666666e-07,
      "logits/chosen": -2.881279468536377,
      "logits/rejected": -2.90769100189209,
      "logps/chosen": -79.68154907226562,
      "logps/rejected": -43.01917266845703,
      "loss": 0.6435,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0998203307390213,
      "rewards/margins": 0.10191573947668076,
      "rewards/rejected": -0.0020954131614416838,
      "step": 119
    },
    {
      "epoch": 0.048,
      "grad_norm": 14.13040828704834,
      "learning_rate": 9.841333333333332e-07,
      "logits/chosen": -2.5698561668395996,
      "logits/rejected": -2.5123376846313477,
      "logps/chosen": -110.36695861816406,
      "logps/rejected": -59.88834762573242,
      "loss": 0.6538,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03227539360523224,
      "rewards/margins": 0.08177833259105682,
      "rewards/rejected": -0.04950294643640518,
      "step": 120
    },
    {
      "epoch": 0.0484,
      "grad_norm": 13.639582633972168,
      "learning_rate": 9.84e-07,
      "logits/chosen": -2.660252809524536,
      "logits/rejected": -1.9674174785614014,
      "logps/chosen": -52.05958938598633,
      "logps/rejected": -65.95793151855469,
      "loss": 0.6799,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.02510957606136799,
      "rewards/margins": 0.02707834169268608,
      "rewards/rejected": -0.001968765165656805,
      "step": 121
    },
    {
      "epoch": 0.0488,
      "grad_norm": 17.181657791137695,
      "learning_rate": 9.838666666666666e-07,
      "logits/chosen": -2.1279282569885254,
      "logits/rejected": -2.0224449634552,
      "logps/chosen": -215.03424072265625,
      "logps/rejected": -55.2001838684082,
      "loss": 0.6095,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15160445868968964,
      "rewards/margins": 0.1758180558681488,
      "rewards/rejected": -0.024213599041104317,
      "step": 122
    },
    {
      "epoch": 0.0492,
      "grad_norm": 20.73459243774414,
      "learning_rate": 9.837333333333334e-07,
      "logits/chosen": -2.319655418395996,
      "logits/rejected": -2.2731680870056152,
      "logps/chosen": -133.42886352539062,
      "logps/rejected": -127.17373657226562,
      "loss": 0.5951,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13092041015625,
      "rewards/margins": 0.20686110854148865,
      "rewards/rejected": -0.07594070583581924,
      "step": 123
    },
    {
      "epoch": 0.0496,
      "grad_norm": 12.473859786987305,
      "learning_rate": 9.836e-07,
      "logits/chosen": -2.5978305339813232,
      "logits/rejected": -2.6384451389312744,
      "logps/chosen": -59.3004035949707,
      "logps/rejected": -54.59162902832031,
      "loss": 0.6828,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03549232333898544,
      "rewards/margins": 0.020888900384306908,
      "rewards/rejected": 0.01460342388600111,
      "step": 124
    },
    {
      "epoch": 0.05,
      "grad_norm": 13.420065879821777,
      "learning_rate": 9.834666666666666e-07,
      "logits/chosen": -2.4634580612182617,
      "logits/rejected": -2.0666494369506836,
      "logps/chosen": -93.75486755371094,
      "logps/rejected": -52.32176971435547,
      "loss": 0.6416,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04543037340044975,
      "rewards/margins": 0.10583706200122833,
      "rewards/rejected": -0.06040668487548828,
      "step": 125
    },
    {
      "epoch": 0.0504,
      "grad_norm": 10.774871826171875,
      "learning_rate": 9.833333333333332e-07,
      "logits/chosen": -2.5242667198181152,
      "logits/rejected": -2.306793689727783,
      "logps/chosen": -75.37612915039062,
      "logps/rejected": -47.06969451904297,
      "loss": 0.6521,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08342132717370987,
      "rewards/margins": 0.08408603817224503,
      "rewards/rejected": -0.0006647109985351562,
      "step": 126
    },
    {
      "epoch": 0.0508,
      "grad_norm": 12.536107063293457,
      "learning_rate": 9.832e-07,
      "logits/chosen": -2.3334596157073975,
      "logits/rejected": -2.3767433166503906,
      "logps/chosen": -110.92833709716797,
      "logps/rejected": -48.60060501098633,
      "loss": 0.6592,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03541736677289009,
      "rewards/margins": 0.06912918388843536,
      "rewards/rejected": -0.03371181711554527,
      "step": 127
    },
    {
      "epoch": 0.0512,
      "grad_norm": 12.467316627502441,
      "learning_rate": 9.830666666666665e-07,
      "logits/chosen": -2.982734203338623,
      "logits/rejected": -2.5879855155944824,
      "logps/chosen": -59.78775405883789,
      "logps/rejected": -46.30915069580078,
      "loss": 0.6365,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.057686999440193176,
      "rewards/margins": 0.11681833863258362,
      "rewards/rejected": -0.05913133546710014,
      "step": 128
    },
    {
      "epoch": 0.0516,
      "grad_norm": 19.870864868164062,
      "learning_rate": 9.829333333333333e-07,
      "logits/chosen": -2.3741042613983154,
      "logits/rejected": -2.1897730827331543,
      "logps/chosen": -254.10906982421875,
      "logps/rejected": -110.15434265136719,
      "loss": 0.5915,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13858795166015625,
      "rewards/margins": 0.21474343538284302,
      "rewards/rejected": -0.07615546882152557,
      "step": 129
    },
    {
      "epoch": 0.052,
      "grad_norm": 16.12512969970703,
      "learning_rate": 9.828e-07,
      "logits/chosen": -2.4495902061462402,
      "logits/rejected": -2.2165956497192383,
      "logps/chosen": -93.01590728759766,
      "logps/rejected": -69.57440948486328,
      "loss": 0.619,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14226913452148438,
      "rewards/margins": 0.15529805421829224,
      "rewards/rejected": -0.013028908520936966,
      "step": 130
    },
    {
      "epoch": 0.0524,
      "grad_norm": 12.749618530273438,
      "learning_rate": 9.826666666666667e-07,
      "logits/chosen": -2.71126127243042,
      "logits/rejected": -2.4430463314056396,
      "logps/chosen": -77.2818374633789,
      "logps/rejected": -48.14076232910156,
      "loss": 0.6496,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.049563217908144,
      "rewards/margins": 0.08906612545251846,
      "rewards/rejected": -0.039502907544374466,
      "step": 131
    },
    {
      "epoch": 0.0528,
      "grad_norm": 13.80865478515625,
      "learning_rate": 9.825333333333333e-07,
      "logits/chosen": -2.471135377883911,
      "logits/rejected": -2.3507118225097656,
      "logps/chosen": -126.16656494140625,
      "logps/rejected": -35.4891357421875,
      "loss": 0.6284,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09151344001293182,
      "rewards/margins": 0.1341135948896408,
      "rewards/rejected": -0.042600154876708984,
      "step": 132
    },
    {
      "epoch": 0.0532,
      "grad_norm": 12.49707317352295,
      "learning_rate": 9.824e-07,
      "logits/chosen": -2.5316901206970215,
      "logits/rejected": -2.6947145462036133,
      "logps/chosen": -102.55702209472656,
      "logps/rejected": -36.39509582519531,
      "loss": 0.6585,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07394237816333771,
      "rewards/margins": 0.07088489830493927,
      "rewards/rejected": 0.003057480091229081,
      "step": 133
    },
    {
      "epoch": 0.0536,
      "grad_norm": 17.454513549804688,
      "learning_rate": 9.822666666666665e-07,
      "logits/chosen": -2.224247932434082,
      "logits/rejected": -2.262056350708008,
      "logps/chosen": -189.37750244140625,
      "logps/rejected": -96.58187103271484,
      "loss": 0.6272,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08768997341394424,
      "rewards/margins": 0.13669928908348083,
      "rewards/rejected": -0.04900932312011719,
      "step": 134
    },
    {
      "epoch": 0.054,
      "grad_norm": 17.285654067993164,
      "learning_rate": 9.821333333333333e-07,
      "logits/chosen": -2.095879077911377,
      "logits/rejected": -2.3146328926086426,
      "logps/chosen": -121.73636627197266,
      "logps/rejected": -61.48462677001953,
      "loss": 0.6214,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11104736477136612,
      "rewards/margins": 0.14904117584228516,
      "rewards/rejected": -0.03799381107091904,
      "step": 135
    },
    {
      "epoch": 0.0544,
      "grad_norm": 13.055630683898926,
      "learning_rate": 9.819999999999999e-07,
      "logits/chosen": -2.609738349914551,
      "logits/rejected": -2.2937827110290527,
      "logps/chosen": -66.54853820800781,
      "logps/rejected": -75.77311706542969,
      "loss": 0.654,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06003990396857262,
      "rewards/margins": 0.07999706268310547,
      "rewards/rejected": -0.01995716243982315,
      "step": 136
    },
    {
      "epoch": 0.0548,
      "grad_norm": 13.661934852600098,
      "learning_rate": 9.818666666666667e-07,
      "logits/chosen": -2.928156852722168,
      "logits/rejected": -2.4309940338134766,
      "logps/chosen": -58.10895919799805,
      "logps/rejected": -38.93890380859375,
      "loss": 0.6251,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06401672214269638,
      "rewards/margins": 0.14165401458740234,
      "rewards/rejected": -0.07763729244470596,
      "step": 137
    },
    {
      "epoch": 0.0552,
      "grad_norm": 12.699196815490723,
      "learning_rate": 9.817333333333333e-07,
      "logits/chosen": -2.586045265197754,
      "logits/rejected": -2.4757494926452637,
      "logps/chosen": -85.7677230834961,
      "logps/rejected": -31.88982391357422,
      "loss": 0.6671,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06308994442224503,
      "rewards/margins": 0.052802279591560364,
      "rewards/rejected": 0.010287666693329811,
      "step": 138
    },
    {
      "epoch": 0.0556,
      "grad_norm": 17.60076904296875,
      "learning_rate": 9.816e-07,
      "logits/chosen": -2.6114611625671387,
      "logits/rejected": -2.7764313220977783,
      "logps/chosen": -131.7801055908203,
      "logps/rejected": -78.59396362304688,
      "loss": 0.609,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09960269927978516,
      "rewards/margins": 0.1782234162092209,
      "rewards/rejected": -0.07862071692943573,
      "step": 139
    },
    {
      "epoch": 0.056,
      "grad_norm": 10.553407669067383,
      "learning_rate": 9.814666666666666e-07,
      "logits/chosen": -2.5865135192871094,
      "logits/rejected": -2.594745635986328,
      "logps/chosen": -37.61603927612305,
      "logps/rejected": -45.13688278198242,
      "loss": 0.669,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026866627857089043,
      "rewards/margins": 0.04890470206737518,
      "rewards/rejected": -0.02203807793557644,
      "step": 140
    },
    {
      "epoch": 0.0564,
      "grad_norm": 14.495136260986328,
      "learning_rate": 9.813333333333332e-07,
      "logits/chosen": -2.406733989715576,
      "logits/rejected": -2.096024751663208,
      "logps/chosen": -144.19601440429688,
      "logps/rejected": -64.3586654663086,
      "loss": 0.5953,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14374962449073792,
      "rewards/margins": 0.2067190259695053,
      "rewards/rejected": -0.0629694014787674,
      "step": 141
    },
    {
      "epoch": 0.0568,
      "grad_norm": 16.257719039916992,
      "learning_rate": 9.811999999999998e-07,
      "logits/chosen": -2.4081521034240723,
      "logits/rejected": -2.0964040756225586,
      "logps/chosen": -159.15298461914062,
      "logps/rejected": -69.09764099121094,
      "loss": 0.6125,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11420135200023651,
      "rewards/margins": 0.1685047149658203,
      "rewards/rejected": -0.0543033592402935,
      "step": 142
    },
    {
      "epoch": 0.0572,
      "grad_norm": 16.882484436035156,
      "learning_rate": 9.810666666666666e-07,
      "logits/chosen": -2.4436044692993164,
      "logits/rejected": -2.151324510574341,
      "logps/chosen": -156.321044921875,
      "logps/rejected": -76.92486572265625,
      "loss": 0.6029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15906067192554474,
      "rewards/margins": 0.1895286589860916,
      "rewards/rejected": -0.030467987060546875,
      "step": 143
    },
    {
      "epoch": 0.0576,
      "grad_norm": 14.411722183227539,
      "learning_rate": 9.809333333333332e-07,
      "logits/chosen": -2.1775505542755127,
      "logits/rejected": -2.195483446121216,
      "logps/chosen": -129.58004760742188,
      "logps/rejected": -93.11490631103516,
      "loss": 0.6295,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12112465500831604,
      "rewards/margins": 0.13164635002613068,
      "rewards/rejected": -0.01052169781178236,
      "step": 144
    },
    {
      "epoch": 0.058,
      "grad_norm": 14.414278030395508,
      "learning_rate": 9.808e-07,
      "logits/chosen": -2.6034116744995117,
      "logits/rejected": -2.336117744445801,
      "logps/chosen": -118.37809753417969,
      "logps/rejected": -106.50898742675781,
      "loss": 0.6315,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09071274101734161,
      "rewards/margins": 0.12749844789505005,
      "rewards/rejected": -0.03678569942712784,
      "step": 145
    },
    {
      "epoch": 0.0584,
      "grad_norm": 13.913385391235352,
      "learning_rate": 9.806666666666666e-07,
      "logits/chosen": -2.577723979949951,
      "logits/rejected": -2.270568370819092,
      "logps/chosen": -89.01192474365234,
      "logps/rejected": -69.87481689453125,
      "loss": 0.5975,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14238452911376953,
      "rewards/margins": 0.20242711901664734,
      "rewards/rejected": -0.060042575001716614,
      "step": 146
    },
    {
      "epoch": 0.0588,
      "grad_norm": 13.007224082946777,
      "learning_rate": 9.805333333333334e-07,
      "logits/chosen": -2.4427385330200195,
      "logits/rejected": -2.161454677581787,
      "logps/chosen": -98.32166290283203,
      "logps/rejected": -55.22492980957031,
      "loss": 0.6084,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12103233486413956,
      "rewards/margins": 0.17739620804786682,
      "rewards/rejected": -0.056363869458436966,
      "step": 147
    },
    {
      "epoch": 0.0592,
      "grad_norm": 16.65958595275879,
      "learning_rate": 9.804e-07,
      "logits/chosen": -2.3185083866119385,
      "logits/rejected": -2.4869704246520996,
      "logps/chosen": -120.33802032470703,
      "logps/rejected": -68.99076843261719,
      "loss": 0.6208,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10898704826831818,
      "rewards/margins": 0.15045452117919922,
      "rewards/rejected": -0.04146747663617134,
      "step": 148
    },
    {
      "epoch": 0.0596,
      "grad_norm": 12.651381492614746,
      "learning_rate": 9.802666666666666e-07,
      "logits/chosen": -2.7814712524414062,
      "logits/rejected": -2.4141829013824463,
      "logps/chosen": -120.2364501953125,
      "logps/rejected": -47.21514129638672,
      "loss": 0.6532,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05476226657629013,
      "rewards/margins": 0.08148936927318573,
      "rewards/rejected": -0.026727106422185898,
      "step": 149
    },
    {
      "epoch": 0.06,
      "grad_norm": 17.321949005126953,
      "learning_rate": 9.801333333333333e-07,
      "logits/chosen": -2.3802688121795654,
      "logits/rejected": -2.454864978790283,
      "logps/chosen": -101.86961364746094,
      "logps/rejected": -112.9331283569336,
      "loss": 0.6302,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07240181416273117,
      "rewards/margins": 0.13226661086082458,
      "rewards/rejected": -0.05986480787396431,
      "step": 150
    },
    {
      "epoch": 0.0604,
      "grad_norm": 19.12685775756836,
      "learning_rate": 9.8e-07,
      "logits/chosen": -2.348263740539551,
      "logits/rejected": -2.388594627380371,
      "logps/chosen": -132.79278564453125,
      "logps/rejected": -99.22760009765625,
      "loss": 0.5805,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14401550590991974,
      "rewards/margins": 0.23984527587890625,
      "rewards/rejected": -0.09582977741956711,
      "step": 151
    },
    {
      "epoch": 0.0608,
      "grad_norm": 12.70956802368164,
      "learning_rate": 9.798666666666665e-07,
      "logits/chosen": -2.7859814167022705,
      "logits/rejected": -2.221273183822632,
      "logps/chosen": -78.42546081542969,
      "logps/rejected": -57.94566345214844,
      "loss": 0.6249,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09875984489917755,
      "rewards/margins": 0.14153900742530823,
      "rewards/rejected": -0.04277915880084038,
      "step": 152
    },
    {
      "epoch": 0.0612,
      "grad_norm": 12.849546432495117,
      "learning_rate": 9.797333333333333e-07,
      "logits/chosen": -2.9635496139526367,
      "logits/rejected": -2.471177101135254,
      "logps/chosen": -62.277076721191406,
      "logps/rejected": -40.088905334472656,
      "loss": 0.6275,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09076347947120667,
      "rewards/margins": 0.1369139701128006,
      "rewards/rejected": -0.04615049436688423,
      "step": 153
    },
    {
      "epoch": 0.0616,
      "grad_norm": 11.532133102416992,
      "learning_rate": 9.796e-07,
      "logits/chosen": -2.5901646614074707,
      "logits/rejected": -2.3803117275238037,
      "logps/chosen": -88.91942596435547,
      "logps/rejected": -44.90519714355469,
      "loss": 0.6189,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09946899116039276,
      "rewards/margins": 0.1547456681728363,
      "rewards/rejected": -0.05527668073773384,
      "step": 154
    },
    {
      "epoch": 0.062,
      "grad_norm": 15.06943416595459,
      "learning_rate": 9.794666666666667e-07,
      "logits/chosen": -2.715388059616089,
      "logits/rejected": -2.2561147212982178,
      "logps/chosen": -107.70947265625,
      "logps/rejected": -62.5075798034668,
      "loss": 0.5902,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11653290688991547,
      "rewards/margins": 0.21796303987503052,
      "rewards/rejected": -0.10143013298511505,
      "step": 155
    },
    {
      "epoch": 0.0624,
      "grad_norm": 13.904183387756348,
      "learning_rate": 9.793333333333333e-07,
      "logits/chosen": -2.7502975463867188,
      "logits/rejected": -2.6798205375671387,
      "logps/chosen": -80.57382202148438,
      "logps/rejected": -58.740264892578125,
      "loss": 0.61,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13877029716968536,
      "rewards/margins": 0.17621898651123047,
      "rewards/rejected": -0.0374486930668354,
      "step": 156
    },
    {
      "epoch": 0.0628,
      "grad_norm": 14.058469772338867,
      "learning_rate": 9.791999999999999e-07,
      "logits/chosen": -2.3740785121917725,
      "logits/rejected": -2.202065944671631,
      "logps/chosen": -102.05219268798828,
      "logps/rejected": -72.61740112304688,
      "loss": 0.606,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10093098133802414,
      "rewards/margins": 0.18277759850025177,
      "rewards/rejected": -0.08184662461280823,
      "step": 157
    },
    {
      "epoch": 0.0632,
      "grad_norm": 16.562028884887695,
      "learning_rate": 9.790666666666667e-07,
      "logits/chosen": -2.205183982849121,
      "logits/rejected": -2.564093589782715,
      "logps/chosen": -89.48286437988281,
      "logps/rejected": -93.21549224853516,
      "loss": 0.6042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1647419035434723,
      "rewards/margins": 0.18655738234519958,
      "rewards/rejected": -0.02181548997759819,
      "step": 158
    },
    {
      "epoch": 0.0636,
      "grad_norm": 12.002010345458984,
      "learning_rate": 9.789333333333333e-07,
      "logits/chosen": -2.6650407314300537,
      "logits/rejected": -2.312936305999756,
      "logps/chosen": -63.562156677246094,
      "logps/rejected": -41.216636657714844,
      "loss": 0.641,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03362846374511719,
      "rewards/margins": 0.10715122520923615,
      "rewards/rejected": -0.07352276146411896,
      "step": 159
    },
    {
      "epoch": 0.064,
      "grad_norm": 16.268495559692383,
      "learning_rate": 9.788e-07,
      "logits/chosen": -2.640575408935547,
      "logits/rejected": -3.0102109909057617,
      "logps/chosen": -166.2091827392578,
      "logps/rejected": -51.930397033691406,
      "loss": 0.5857,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.195048525929451,
      "rewards/margins": 0.22793827950954437,
      "rewards/rejected": -0.032889749854803085,
      "step": 160
    },
    {
      "epoch": 0.0644,
      "grad_norm": 14.18042278289795,
      "learning_rate": 9.786666666666666e-07,
      "logits/chosen": -2.606067180633545,
      "logits/rejected": -2.432009220123291,
      "logps/chosen": -68.10592651367188,
      "logps/rejected": -59.240943908691406,
      "loss": 0.6334,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.089080810546875,
      "rewards/margins": 0.12334365397691727,
      "rewards/rejected": -0.034262847155332565,
      "step": 161
    },
    {
      "epoch": 0.0648,
      "grad_norm": 12.689811706542969,
      "learning_rate": 9.785333333333332e-07,
      "logits/chosen": -2.3104796409606934,
      "logits/rejected": -2.293181896209717,
      "logps/chosen": -68.61328125,
      "logps/rejected": -41.27921676635742,
      "loss": 0.6071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14006289839744568,
      "rewards/margins": 0.1801280975341797,
      "rewards/rejected": -0.04006519168615341,
      "step": 162
    },
    {
      "epoch": 0.0652,
      "grad_norm": 14.246278762817383,
      "learning_rate": 9.784e-07,
      "logits/chosen": -2.515120029449463,
      "logits/rejected": -2.8205552101135254,
      "logps/chosen": -119.37251281738281,
      "logps/rejected": -62.96295928955078,
      "loss": 0.5871,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14041291177272797,
      "rewards/margins": 0.22485429048538208,
      "rewards/rejected": -0.08444137871265411,
      "step": 163
    },
    {
      "epoch": 0.0656,
      "grad_norm": 16.03215980529785,
      "learning_rate": 9.782666666666666e-07,
      "logits/chosen": -2.840700149536133,
      "logits/rejected": -2.3381590843200684,
      "logps/chosen": -68.00086975097656,
      "logps/rejected": -58.081241607666016,
      "loss": 0.6002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06596946716308594,
      "rewards/margins": 0.19560813903808594,
      "rewards/rejected": -0.129638671875,
      "step": 164
    },
    {
      "epoch": 0.066,
      "grad_norm": 12.401250839233398,
      "learning_rate": 9.781333333333332e-07,
      "logits/chosen": -2.5486786365509033,
      "logits/rejected": -2.466860771179199,
      "logps/chosen": -118.59378814697266,
      "logps/rejected": -52.10026550292969,
      "loss": 0.616,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11596374958753586,
      "rewards/margins": 0.1614236831665039,
      "rewards/rejected": -0.045459941029548645,
      "step": 165
    },
    {
      "epoch": 0.0664,
      "grad_norm": 15.22043228149414,
      "learning_rate": 9.78e-07,
      "logits/chosen": -2.6750378608703613,
      "logits/rejected": -2.3356800079345703,
      "logps/chosen": -117.47923278808594,
      "logps/rejected": -57.26303482055664,
      "loss": 0.5971,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12694816291332245,
      "rewards/margins": 0.20248907804489136,
      "rewards/rejected": -0.0755409225821495,
      "step": 166
    },
    {
      "epoch": 0.0668,
      "grad_norm": 11.974371910095215,
      "learning_rate": 9.778666666666666e-07,
      "logits/chosen": -2.6787023544311523,
      "logits/rejected": -2.697864532470703,
      "logps/chosen": -58.437957763671875,
      "logps/rejected": -32.77934265136719,
      "loss": 0.6226,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11717434227466583,
      "rewards/margins": 0.14640408754348755,
      "rewards/rejected": -0.02922973781824112,
      "step": 167
    },
    {
      "epoch": 0.0672,
      "grad_norm": 9.56755256652832,
      "learning_rate": 9.777333333333334e-07,
      "logits/chosen": -2.839261531829834,
      "logits/rejected": -2.3225746154785156,
      "logps/chosen": -40.09414291381836,
      "logps/rejected": -59.29850769042969,
      "loss": 0.6464,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06457310169935226,
      "rewards/margins": 0.09571953117847443,
      "rewards/rejected": -0.031146429479122162,
      "step": 168
    },
    {
      "epoch": 0.0676,
      "grad_norm": 12.801657676696777,
      "learning_rate": 9.776e-07,
      "logits/chosen": -2.4110422134399414,
      "logits/rejected": -2.521109104156494,
      "logps/chosen": -103.95060729980469,
      "logps/rejected": -53.69306564331055,
      "loss": 0.632,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08881835639476776,
      "rewards/margins": 0.1263725310564041,
      "rewards/rejected": -0.037554170936346054,
      "step": 169
    },
    {
      "epoch": 0.068,
      "grad_norm": 10.40366268157959,
      "learning_rate": 9.774666666666668e-07,
      "logits/chosen": -2.647660732269287,
      "logits/rejected": -2.5383834838867188,
      "logps/chosen": -59.57886505126953,
      "logps/rejected": -64.16822814941406,
      "loss": 0.6202,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.043979838490486145,
      "rewards/margins": 0.1533329039812088,
      "rewards/rejected": -0.10935306549072266,
      "step": 170
    },
    {
      "epoch": 0.0684,
      "grad_norm": 13.481136322021484,
      "learning_rate": 9.773333333333333e-07,
      "logits/chosen": -2.5411412715911865,
      "logits/rejected": -2.0702202320098877,
      "logps/chosen": -65.86190795898438,
      "logps/rejected": -67.6516342163086,
      "loss": 0.6354,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09223709255456924,
      "rewards/margins": 0.11995430290699005,
      "rewards/rejected": -0.027717210352420807,
      "step": 171
    },
    {
      "epoch": 0.0688,
      "grad_norm": 15.33928108215332,
      "learning_rate": 9.772e-07,
      "logits/chosen": -2.684009075164795,
      "logits/rejected": -2.281155586242676,
      "logps/chosen": -102.49629974365234,
      "logps/rejected": -87.34649658203125,
      "loss": 0.5921,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13637390732765198,
      "rewards/margins": 0.21369019150733948,
      "rewards/rejected": -0.0773162841796875,
      "step": 172
    },
    {
      "epoch": 0.0692,
      "grad_norm": 14.157709121704102,
      "learning_rate": 9.770666666666665e-07,
      "logits/chosen": -2.52530574798584,
      "logits/rejected": -2.270124673843384,
      "logps/chosen": -138.04122924804688,
      "logps/rejected": -40.21875762939453,
      "loss": 0.5937,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21083489060401917,
      "rewards/margins": 0.2104644775390625,
      "rewards/rejected": 0.00037040701135993004,
      "step": 173
    },
    {
      "epoch": 0.0696,
      "grad_norm": 14.468500137329102,
      "learning_rate": 9.769333333333333e-07,
      "logits/chosen": -2.5372095108032227,
      "logits/rejected": -2.342556953430176,
      "logps/chosen": -173.35855102539062,
      "logps/rejected": -62.83746337890625,
      "loss": 0.5486,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2153644561767578,
      "rewards/margins": 0.31370604038238525,
      "rewards/rejected": -0.09834156185388565,
      "step": 174
    },
    {
      "epoch": 0.07,
      "grad_norm": 13.610636711120605,
      "learning_rate": 9.768e-07,
      "logits/chosen": -2.519141674041748,
      "logits/rejected": -2.047071933746338,
      "logps/chosen": -89.35191345214844,
      "logps/rejected": -63.887821197509766,
      "loss": 0.5791,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18361511826515198,
      "rewards/margins": 0.2429184913635254,
      "rewards/rejected": -0.05930338054895401,
      "step": 175
    },
    {
      "epoch": 0.0704,
      "grad_norm": 14.860725402832031,
      "learning_rate": 9.766666666666667e-07,
      "logits/chosen": -2.502148151397705,
      "logits/rejected": -2.3834500312805176,
      "logps/chosen": -84.34638977050781,
      "logps/rejected": -106.9073486328125,
      "loss": 0.6321,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06221161037683487,
      "rewards/margins": 0.12652377784252167,
      "rewards/rejected": -0.0643121749162674,
      "step": 176
    },
    {
      "epoch": 0.0708,
      "grad_norm": 16.173368453979492,
      "learning_rate": 9.765333333333333e-07,
      "logits/chosen": -2.763873815536499,
      "logits/rejected": -2.134052276611328,
      "logps/chosen": -121.75788879394531,
      "logps/rejected": -85.43965148925781,
      "loss": 0.5903,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1387508511543274,
      "rewards/margins": 0.21766282618045807,
      "rewards/rejected": -0.07891197502613068,
      "step": 177
    },
    {
      "epoch": 0.0712,
      "grad_norm": 10.394576072692871,
      "learning_rate": 9.764e-07,
      "logits/chosen": -2.4596710205078125,
      "logits/rejected": -2.393911838531494,
      "logps/chosen": -66.3003921508789,
      "logps/rejected": -40.0162467956543,
      "loss": 0.6238,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09022464603185654,
      "rewards/margins": 0.14398527145385742,
      "rewards/rejected": -0.053760625422000885,
      "step": 178
    },
    {
      "epoch": 0.0716,
      "grad_norm": 11.223247528076172,
      "learning_rate": 9.762666666666667e-07,
      "logits/chosen": -2.613981008529663,
      "logits/rejected": -2.3208842277526855,
      "logps/chosen": -70.19561767578125,
      "logps/rejected": -66.3702392578125,
      "loss": 0.6182,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12082862854003906,
      "rewards/margins": 0.1572292447090149,
      "rewards/rejected": -0.036400604993104935,
      "step": 179
    },
    {
      "epoch": 0.072,
      "grad_norm": 10.757207870483398,
      "learning_rate": 9.761333333333333e-07,
      "logits/chosen": -2.6236348152160645,
      "logits/rejected": -2.8064377307891846,
      "logps/chosen": -92.37345886230469,
      "logps/rejected": -51.347408294677734,
      "loss": 0.6302,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10040054470300674,
      "rewards/margins": 0.13425111770629883,
      "rewards/rejected": -0.03385057672858238,
      "step": 180
    },
    {
      "epoch": 0.0724,
      "grad_norm": 15.238554000854492,
      "learning_rate": 9.759999999999998e-07,
      "logits/chosen": -2.544790506362915,
      "logits/rejected": -2.3591628074645996,
      "logps/chosen": -148.02725219726562,
      "logps/rejected": -135.37950134277344,
      "loss": 0.57,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22240638732910156,
      "rewards/margins": 0.2645856738090515,
      "rewards/rejected": -0.04217929765582085,
      "step": 181
    },
    {
      "epoch": 0.0728,
      "grad_norm": 12.55057144165039,
      "learning_rate": 9.758666666666666e-07,
      "logits/chosen": -2.6411876678466797,
      "logits/rejected": -2.538816213607788,
      "logps/chosen": -85.20639038085938,
      "logps/rejected": -50.90767288208008,
      "loss": 0.6036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14683380722999573,
      "rewards/margins": 0.18860892951488495,
      "rewards/rejected": -0.04177512973546982,
      "step": 182
    },
    {
      "epoch": 0.0732,
      "grad_norm": 13.009540557861328,
      "learning_rate": 9.757333333333332e-07,
      "logits/chosen": -2.658900737762451,
      "logits/rejected": -2.010918617248535,
      "logps/chosen": -89.82271575927734,
      "logps/rejected": -56.64371109008789,
      "loss": 0.5994,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11250686645507812,
      "rewards/margins": 0.1973033845424652,
      "rewards/rejected": -0.08479652553796768,
      "step": 183
    },
    {
      "epoch": 0.0736,
      "grad_norm": 13.91130542755127,
      "learning_rate": 9.756e-07,
      "logits/chosen": -2.490847587585449,
      "logits/rejected": -2.224323272705078,
      "logps/chosen": -195.69993591308594,
      "logps/rejected": -59.51710510253906,
      "loss": 0.5765,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20431958138942719,
      "rewards/margins": 0.25517961382865906,
      "rewards/rejected": -0.050860024988651276,
      "step": 184
    },
    {
      "epoch": 0.074,
      "grad_norm": 14.13329792022705,
      "learning_rate": 9.754666666666666e-07,
      "logits/chosen": -2.2589945793151855,
      "logits/rejected": -1.9582715034484863,
      "logps/chosen": -133.11253356933594,
      "logps/rejected": -47.13139343261719,
      "loss": 0.5761,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19053229689598083,
      "rewards/margins": 0.24956151843070984,
      "rewards/rejected": -0.05902919918298721,
      "step": 185
    },
    {
      "epoch": 0.0744,
      "grad_norm": 14.445374488830566,
      "learning_rate": 9.753333333333334e-07,
      "logits/chosen": -2.6159613132476807,
      "logits/rejected": -2.353656053543091,
      "logps/chosen": -117.75196838378906,
      "logps/rejected": -58.41766357421875,
      "loss": 0.5783,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11914634704589844,
      "rewards/margins": 0.24900835752487183,
      "rewards/rejected": -0.12986202538013458,
      "step": 186
    },
    {
      "epoch": 0.0748,
      "grad_norm": 12.221263885498047,
      "learning_rate": 9.752e-07,
      "logits/chosen": -2.53963303565979,
      "logits/rejected": -2.023056983947754,
      "logps/chosen": -109.53294372558594,
      "logps/rejected": -53.84758377075195,
      "loss": 0.5937,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14505119621753693,
      "rewards/margins": 0.2131446897983551,
      "rewards/rejected": -0.06809349358081818,
      "step": 187
    },
    {
      "epoch": 0.0752,
      "grad_norm": 12.104873657226562,
      "learning_rate": 9.750666666666666e-07,
      "logits/chosen": -2.6169815063476562,
      "logits/rejected": -2.4630699157714844,
      "logps/chosen": -74.4407730102539,
      "logps/rejected": -35.57379913330078,
      "loss": 0.6348,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07618217170238495,
      "rewards/margins": 0.12099237740039825,
      "rewards/rejected": -0.04481019824743271,
      "step": 188
    },
    {
      "epoch": 0.0756,
      "grad_norm": 13.491036415100098,
      "learning_rate": 9.749333333333332e-07,
      "logits/chosen": -2.4594054222106934,
      "logits/rejected": -2.398836135864258,
      "logps/chosen": -121.76921081542969,
      "logps/rejected": -70.77013397216797,
      "loss": 0.5653,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18827667832374573,
      "rewards/margins": 0.2750892639160156,
      "rewards/rejected": -0.0868125930428505,
      "step": 189
    },
    {
      "epoch": 0.076,
      "grad_norm": 13.392132759094238,
      "learning_rate": 9.748e-07,
      "logits/chosen": -2.5389256477355957,
      "logits/rejected": -2.6744706630706787,
      "logps/chosen": -87.00148010253906,
      "logps/rejected": -64.60879516601562,
      "loss": 0.6549,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04396476596593857,
      "rewards/margins": 0.07846193015575409,
      "rewards/rejected": -0.03449716791510582,
      "step": 190
    },
    {
      "epoch": 0.0764,
      "grad_norm": 12.882509231567383,
      "learning_rate": 9.746666666666666e-07,
      "logits/chosen": -2.815789222717285,
      "logits/rejected": -2.3597426414489746,
      "logps/chosen": -114.21184539794922,
      "logps/rejected": -64.83372497558594,
      "loss": 0.6225,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08543644100427628,
      "rewards/margins": 0.14673995971679688,
      "rewards/rejected": -0.0613035187125206,
      "step": 191
    },
    {
      "epoch": 0.0768,
      "grad_norm": 13.024002075195312,
      "learning_rate": 9.745333333333334e-07,
      "logits/chosen": -2.5807695388793945,
      "logits/rejected": -2.543455123901367,
      "logps/chosen": -80.27820587158203,
      "logps/rejected": -48.241886138916016,
      "loss": 0.6381,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03187866136431694,
      "rewards/margins": 0.1133296936750412,
      "rewards/rejected": -0.08145103603601456,
      "step": 192
    },
    {
      "epoch": 0.0772,
      "grad_norm": 12.493098258972168,
      "learning_rate": 9.744e-07,
      "logits/chosen": -2.426931858062744,
      "logits/rejected": -2.1097571849823,
      "logps/chosen": -145.6441650390625,
      "logps/rejected": -64.24252319335938,
      "loss": 0.5668,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20467263460159302,
      "rewards/margins": 0.2727148234844208,
      "rewards/rejected": -0.06804218888282776,
      "step": 193
    },
    {
      "epoch": 0.0776,
      "grad_norm": 13.721565246582031,
      "learning_rate": 9.742666666666665e-07,
      "logits/chosen": -2.3463566303253174,
      "logits/rejected": -2.3674187660217285,
      "logps/chosen": -61.527137756347656,
      "logps/rejected": -80.31248474121094,
      "loss": 0.6519,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0980835035443306,
      "rewards/margins": 0.08649330586194992,
      "rewards/rejected": 0.011590193957090378,
      "step": 194
    },
    {
      "epoch": 0.078,
      "grad_norm": 12.367606163024902,
      "learning_rate": 9.741333333333333e-07,
      "logits/chosen": -2.7025461196899414,
      "logits/rejected": -2.3908634185791016,
      "logps/chosen": -116.02816009521484,
      "logps/rejected": -39.13177490234375,
      "loss": 0.6118,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07552490383386612,
      "rewards/margins": 0.16990184783935547,
      "rewards/rejected": -0.09437694400548935,
      "step": 195
    },
    {
      "epoch": 0.0784,
      "grad_norm": 14.273737907409668,
      "learning_rate": 9.74e-07,
      "logits/chosen": -2.634795904159546,
      "logits/rejected": -2.116486072540283,
      "logps/chosen": -86.11515808105469,
      "logps/rejected": -73.79899597167969,
      "loss": 0.6104,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0998508483171463,
      "rewards/margins": 0.17323037981987,
      "rewards/rejected": -0.0733795166015625,
      "step": 196
    },
    {
      "epoch": 0.0788,
      "grad_norm": 12.511002540588379,
      "learning_rate": 9.738666666666667e-07,
      "logits/chosen": -2.6575684547424316,
      "logits/rejected": -2.17000675201416,
      "logps/chosen": -99.81582641601562,
      "logps/rejected": -58.17241668701172,
      "loss": 0.5566,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17083969712257385,
      "rewards/margins": 0.2950897216796875,
      "rewards/rejected": -0.12425003200769424,
      "step": 197
    },
    {
      "epoch": 0.0792,
      "grad_norm": 14.100727081298828,
      "learning_rate": 9.737333333333333e-07,
      "logits/chosen": -2.437241315841675,
      "logits/rejected": -2.1547999382019043,
      "logps/chosen": -125.94692993164062,
      "logps/rejected": -52.95383834838867,
      "loss": 0.5429,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24865645170211792,
      "rewards/margins": 0.32876282930374146,
      "rewards/rejected": -0.08010635524988174,
      "step": 198
    },
    {
      "epoch": 0.0796,
      "grad_norm": 13.15439510345459,
      "learning_rate": 9.735999999999999e-07,
      "logits/chosen": -2.4852232933044434,
      "logits/rejected": -2.0735151767730713,
      "logps/chosen": -101.50788879394531,
      "logps/rejected": -74.0443344116211,
      "loss": 0.6142,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09748420864343643,
      "rewards/margins": 0.16560478508472443,
      "rewards/rejected": -0.068120576441288,
      "step": 199
    },
    {
      "epoch": 0.08,
      "grad_norm": 16.574424743652344,
      "learning_rate": 9.734666666666667e-07,
      "logits/chosen": -2.73518705368042,
      "logits/rejected": -2.1120548248291016,
      "logps/chosen": -122.01954650878906,
      "logps/rejected": -73.86256408691406,
      "loss": 0.5874,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13187141716480255,
      "rewards/margins": 0.22514191269874573,
      "rewards/rejected": -0.09327049553394318,
      "step": 200
    },
    {
      "epoch": 0.0804,
      "grad_norm": 14.085041999816895,
      "learning_rate": 9.733333333333333e-07,
      "logits/chosen": -2.310880661010742,
      "logits/rejected": -2.1054210662841797,
      "logps/chosen": -121.9035415649414,
      "logps/rejected": -63.83659362792969,
      "loss": 0.5521,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2522915005683899,
      "rewards/margins": 0.3070787489414215,
      "rewards/rejected": -0.05478725582361221,
      "step": 201
    },
    {
      "epoch": 0.0808,
      "grad_norm": 13.253968238830566,
      "learning_rate": 9.731999999999998e-07,
      "logits/chosen": -2.520526885986328,
      "logits/rejected": -2.109015703201294,
      "logps/chosen": -126.63980102539062,
      "logps/rejected": -38.848846435546875,
      "loss": 0.5312,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.26054686307907104,
      "rewards/margins": 0.35680657625198364,
      "rewards/rejected": -0.0962596908211708,
      "step": 202
    },
    {
      "epoch": 0.0812,
      "grad_norm": 15.35814094543457,
      "learning_rate": 9.730666666666666e-07,
      "logits/chosen": -2.7966442108154297,
      "logits/rejected": -2.5204412937164307,
      "logps/chosen": -55.95186996459961,
      "logps/rejected": -39.965003967285156,
      "loss": 0.6127,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02956981584429741,
      "rewards/margins": 0.1692153960466385,
      "rewards/rejected": -0.13964557647705078,
      "step": 203
    },
    {
      "epoch": 0.0816,
      "grad_norm": 12.223445892333984,
      "learning_rate": 9.729333333333332e-07,
      "logits/chosen": -2.502016067504883,
      "logits/rejected": -2.121386766433716,
      "logps/chosen": -75.79730224609375,
      "logps/rejected": -41.70969772338867,
      "loss": 0.6321,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05466194078326225,
      "rewards/margins": 0.12700214982032776,
      "rewards/rejected": -0.07234020531177521,
      "step": 204
    },
    {
      "epoch": 0.082,
      "grad_norm": 13.900459289550781,
      "learning_rate": 9.728e-07,
      "logits/chosen": -2.46927547454834,
      "logits/rejected": -2.423003911972046,
      "logps/chosen": -106.84066772460938,
      "logps/rejected": -52.385841369628906,
      "loss": 0.6099,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1289745271205902,
      "rewards/margins": 0.1747695952653885,
      "rewards/rejected": -0.04579506069421768,
      "step": 205
    },
    {
      "epoch": 0.0824,
      "grad_norm": 11.75875186920166,
      "learning_rate": 9.726666666666666e-07,
      "logits/chosen": -2.4690134525299072,
      "logits/rejected": -2.2987735271453857,
      "logps/chosen": -102.68810272216797,
      "logps/rejected": -47.49870300292969,
      "loss": 0.6242,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12059440463781357,
      "rewards/margins": 0.14445562660694122,
      "rewards/rejected": -0.023861218243837357,
      "step": 206
    },
    {
      "epoch": 0.0828,
      "grad_norm": 14.43976879119873,
      "learning_rate": 9.725333333333334e-07,
      "logits/chosen": -2.339705467224121,
      "logits/rejected": -2.1746726036071777,
      "logps/chosen": -89.90642547607422,
      "logps/rejected": -62.09516143798828,
      "loss": 0.6023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12951889634132385,
      "rewards/margins": 0.19091454148292542,
      "rewards/rejected": -0.06139564514160156,
      "step": 207
    },
    {
      "epoch": 0.0832,
      "grad_norm": 12.158750534057617,
      "learning_rate": 9.724e-07,
      "logits/chosen": -2.586766004562378,
      "logits/rejected": -2.1931939125061035,
      "logps/chosen": -89.7695083618164,
      "logps/rejected": -57.20719909667969,
      "loss": 0.6121,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.149455264210701,
      "rewards/margins": 0.1700584441423416,
      "rewards/rejected": -0.020603179931640625,
      "step": 208
    },
    {
      "epoch": 0.0836,
      "grad_norm": 13.46362018585205,
      "learning_rate": 9.722666666666666e-07,
      "logits/chosen": -2.62265682220459,
      "logits/rejected": -2.1533946990966797,
      "logps/chosen": -105.95735168457031,
      "logps/rejected": -58.09284210205078,
      "loss": 0.5461,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16802310943603516,
      "rewards/margins": 0.3196481764316559,
      "rewards/rejected": -0.15162506699562073,
      "step": 209
    },
    {
      "epoch": 0.084,
      "grad_norm": 13.40267562866211,
      "learning_rate": 9.721333333333332e-07,
      "logits/chosen": -2.4628825187683105,
      "logits/rejected": -2.2002739906311035,
      "logps/chosen": -102.86214447021484,
      "logps/rejected": -79.26235961914062,
      "loss": 0.5953,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1520179808139801,
      "rewards/margins": 0.20666885375976562,
      "rewards/rejected": -0.05465088039636612,
      "step": 210
    },
    {
      "epoch": 0.0844,
      "grad_norm": 14.674041748046875,
      "learning_rate": 9.72e-07,
      "logits/chosen": -2.5921671390533447,
      "logits/rejected": -2.6063332557678223,
      "logps/chosen": -141.09835815429688,
      "logps/rejected": -55.48844909667969,
      "loss": 0.5686,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1265125274658203,
      "rewards/margins": 0.2671205699443817,
      "rewards/rejected": -0.1406080275774002,
      "step": 211
    },
    {
      "epoch": 0.0848,
      "grad_norm": 14.030073165893555,
      "learning_rate": 9.718666666666666e-07,
      "logits/chosen": -2.6080422401428223,
      "logits/rejected": -2.442185163497925,
      "logps/chosen": -107.21106719970703,
      "logps/rejected": -54.063201904296875,
      "loss": 0.5998,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1216224655508995,
      "rewards/margins": 0.19626197218894958,
      "rewards/rejected": -0.07463951408863068,
      "step": 212
    },
    {
      "epoch": 0.0852,
      "grad_norm": 12.377387046813965,
      "learning_rate": 9.717333333333334e-07,
      "logits/chosen": -2.553173065185547,
      "logits/rejected": -2.0857231616973877,
      "logps/chosen": -79.9833984375,
      "logps/rejected": -58.61269760131836,
      "loss": 0.5648,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19005203247070312,
      "rewards/margins": 0.27882349491119385,
      "rewards/rejected": -0.08877144008874893,
      "step": 213
    },
    {
      "epoch": 0.0856,
      "grad_norm": 10.029678344726562,
      "learning_rate": 9.716e-07,
      "logits/chosen": -2.6526880264282227,
      "logits/rejected": -2.240144968032837,
      "logps/chosen": -67.7286605834961,
      "logps/rejected": -42.97083282470703,
      "loss": 0.6189,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09683170169591904,
      "rewards/margins": 0.15470066666603088,
      "rewards/rejected": -0.05786895751953125,
      "step": 214
    },
    {
      "epoch": 0.086,
      "grad_norm": 16.310699462890625,
      "learning_rate": 9.714666666666667e-07,
      "logits/chosen": -2.4245495796203613,
      "logits/rejected": -2.266432285308838,
      "logps/chosen": -155.18699645996094,
      "logps/rejected": -48.4926872253418,
      "loss": 0.6098,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12389717251062393,
      "rewards/margins": 0.17803631722927094,
      "rewards/rejected": -0.054139137268066406,
      "step": 215
    },
    {
      "epoch": 0.0864,
      "grad_norm": 17.83713150024414,
      "learning_rate": 9.713333333333333e-07,
      "logits/chosen": -2.5526857376098633,
      "logits/rejected": -2.1456360816955566,
      "logps/chosen": -94.75148010253906,
      "logps/rejected": -112.73416900634766,
      "loss": 0.5508,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18683452904224396,
      "rewards/margins": 0.30908793210983276,
      "rewards/rejected": -0.12225341796875,
      "step": 216
    },
    {
      "epoch": 0.0868,
      "grad_norm": 15.972107887268066,
      "learning_rate": 9.712e-07,
      "logits/chosen": -2.2765235900878906,
      "logits/rejected": -1.9614554643630981,
      "logps/chosen": -116.5810546875,
      "logps/rejected": -117.35147857666016,
      "loss": 0.5452,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.26737290620803833,
      "rewards/margins": 0.3225513696670532,
      "rewards/rejected": -0.055178452283144,
      "step": 217
    },
    {
      "epoch": 0.0872,
      "grad_norm": 15.744436264038086,
      "learning_rate": 9.710666666666665e-07,
      "logits/chosen": -2.667387008666992,
      "logits/rejected": -2.194443941116333,
      "logps/chosen": -113.19833374023438,
      "logps/rejected": -53.8026008605957,
      "loss": 0.5368,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27815818786621094,
      "rewards/margins": 0.3427799344062805,
      "rewards/rejected": -0.06462173163890839,
      "step": 218
    },
    {
      "epoch": 0.0876,
      "grad_norm": 9.97567081451416,
      "learning_rate": 9.709333333333333e-07,
      "logits/chosen": -2.651978015899658,
      "logits/rejected": -2.3461384773254395,
      "logps/chosen": -96.32782745361328,
      "logps/rejected": -72.5383071899414,
      "loss": 0.617,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14570847153663635,
      "rewards/margins": 0.15960007905960083,
      "rewards/rejected": -0.01389160193502903,
      "step": 219
    },
    {
      "epoch": 0.088,
      "grad_norm": 14.62214183807373,
      "learning_rate": 9.707999999999999e-07,
      "logits/chosen": -2.7356319427490234,
      "logits/rejected": -1.9240953922271729,
      "logps/chosen": -107.44426727294922,
      "logps/rejected": -81.70783233642578,
      "loss": 0.5489,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1468641310930252,
      "rewards/margins": 0.31289997696876526,
      "rewards/rejected": -0.16603584587574005,
      "step": 220
    },
    {
      "epoch": 0.0884,
      "grad_norm": 11.554261207580566,
      "learning_rate": 9.706666666666667e-07,
      "logits/chosen": -2.4378106594085693,
      "logits/rejected": -2.183840274810791,
      "logps/chosen": -58.2733268737793,
      "logps/rejected": -67.87977600097656,
      "loss": 0.5836,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11960754543542862,
      "rewards/margins": 0.2329055815935135,
      "rewards/rejected": -0.11329803615808487,
      "step": 221
    },
    {
      "epoch": 0.0888,
      "grad_norm": 13.798287391662598,
      "learning_rate": 9.705333333333333e-07,
      "logits/chosen": -2.5107309818267822,
      "logits/rejected": -2.266831874847412,
      "logps/chosen": -139.7756805419922,
      "logps/rejected": -66.74773406982422,
      "loss": 0.569,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23758602142333984,
      "rewards/margins": 0.273404598236084,
      "rewards/rejected": -0.03581857681274414,
      "step": 222
    },
    {
      "epoch": 0.0892,
      "grad_norm": 12.079108238220215,
      "learning_rate": 9.704e-07,
      "logits/chosen": -2.5562214851379395,
      "logits/rejected": -2.2027313709259033,
      "logps/chosen": -70.17146301269531,
      "logps/rejected": -56.87889862060547,
      "loss": 0.593,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12565994262695312,
      "rewards/margins": 0.21141719818115234,
      "rewards/rejected": -0.08575725555419922,
      "step": 223
    },
    {
      "epoch": 0.0896,
      "grad_norm": 15.261964797973633,
      "learning_rate": 9.702666666666666e-07,
      "logits/chosen": -2.3747081756591797,
      "logits/rejected": -2.2134218215942383,
      "logps/chosen": -145.92124938964844,
      "logps/rejected": -56.443939208984375,
      "loss": 0.561,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2430259734392166,
      "rewards/margins": 0.2936277389526367,
      "rewards/rejected": -0.0506017692387104,
      "step": 224
    },
    {
      "epoch": 0.09,
      "grad_norm": 15.437687873840332,
      "learning_rate": 9.701333333333332e-07,
      "logits/chosen": -2.9022216796875,
      "logits/rejected": -2.5747342109680176,
      "logps/chosen": -122.28606414794922,
      "logps/rejected": -51.930564880371094,
      "loss": 0.5577,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21182556450366974,
      "rewards/margins": 0.29226571321487427,
      "rewards/rejected": -0.08044014126062393,
      "step": 225
    },
    {
      "epoch": 0.0904,
      "grad_norm": 10.360330581665039,
      "learning_rate": 9.7e-07,
      "logits/chosen": -2.7891573905944824,
      "logits/rejected": -2.4499053955078125,
      "logps/chosen": -58.02589797973633,
      "logps/rejected": -49.827327728271484,
      "loss": 0.5635,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22001762688159943,
      "rewards/margins": 0.2814491391181946,
      "rewards/rejected": -0.06143150478601456,
      "step": 226
    },
    {
      "epoch": 0.0908,
      "grad_norm": 9.86115837097168,
      "learning_rate": 9.698666666666666e-07,
      "logits/chosen": -2.6100125312805176,
      "logits/rejected": -2.6158242225646973,
      "logps/chosen": -68.2683334350586,
      "logps/rejected": -36.09784698486328,
      "loss": 0.6019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16095027327537537,
      "rewards/margins": 0.19347457587718964,
      "rewards/rejected": -0.03252429887652397,
      "step": 227
    },
    {
      "epoch": 0.0912,
      "grad_norm": 15.843421936035156,
      "learning_rate": 9.697333333333332e-07,
      "logits/chosen": -2.3240714073181152,
      "logits/rejected": -2.0315067768096924,
      "logps/chosen": -131.14602661132812,
      "logps/rejected": -93.50782775878906,
      "loss": 0.5172,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.29099464416503906,
      "rewards/margins": 0.38970261812210083,
      "rewards/rejected": -0.09870795905590057,
      "step": 228
    },
    {
      "epoch": 0.0916,
      "grad_norm": 16.425153732299805,
      "learning_rate": 9.696e-07,
      "logits/chosen": -2.400860548019409,
      "logits/rejected": -2.0988292694091797,
      "logps/chosen": -122.16734313964844,
      "logps/rejected": -76.30987548828125,
      "loss": 0.551,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19385185837745667,
      "rewards/margins": 0.30798912048339844,
      "rewards/rejected": -0.11413726955652237,
      "step": 229
    },
    {
      "epoch": 0.092,
      "grad_norm": 14.908544540405273,
      "learning_rate": 9.694666666666666e-07,
      "logits/chosen": -2.8865253925323486,
      "logits/rejected": -2.228080987930298,
      "logps/chosen": -92.8294677734375,
      "logps/rejected": -61.723167419433594,
      "loss": 0.5756,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10207214951515198,
      "rewards/margins": 0.2509273886680603,
      "rewards/rejected": -0.14885520935058594,
      "step": 230
    },
    {
      "epoch": 0.0924,
      "grad_norm": 12.916053771972656,
      "learning_rate": 9.693333333333334e-07,
      "logits/chosen": -2.859241247177124,
      "logits/rejected": -2.6664223670959473,
      "logps/chosen": -82.57144165039062,
      "logps/rejected": -38.05243682861328,
      "loss": 0.6265,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08627624064683914,
      "rewards/margins": 0.14050082862377167,
      "rewards/rejected": -0.054224587976932526,
      "step": 231
    },
    {
      "epoch": 0.0928,
      "grad_norm": 13.688039779663086,
      "learning_rate": 9.692e-07,
      "logits/chosen": -2.48392391204834,
      "logits/rejected": -2.191270351409912,
      "logps/chosen": -170.55123901367188,
      "logps/rejected": -55.89426803588867,
      "loss": 0.5816,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12835770845413208,
      "rewards/margins": 0.23827706277370453,
      "rewards/rejected": -0.10991936177015305,
      "step": 232
    },
    {
      "epoch": 0.0932,
      "grad_norm": 13.909658432006836,
      "learning_rate": 9.690666666666666e-07,
      "logits/chosen": -2.65440034866333,
      "logits/rejected": -2.262838363647461,
      "logps/chosen": -122.96910095214844,
      "logps/rejected": -67.47294616699219,
      "loss": 0.5281,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2093936949968338,
      "rewards/margins": 0.37022075057029724,
      "rewards/rejected": -0.16082707047462463,
      "step": 233
    },
    {
      "epoch": 0.0936,
      "grad_norm": 12.93312931060791,
      "learning_rate": 9.689333333333334e-07,
      "logits/chosen": -2.547330379486084,
      "logits/rejected": -2.3813669681549072,
      "logps/chosen": -108.52625274658203,
      "logps/rejected": -79.21321105957031,
      "loss": 0.5325,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21155357360839844,
      "rewards/margins": 0.3526592254638672,
      "rewards/rejected": -0.14110565185546875,
      "step": 234
    },
    {
      "epoch": 0.094,
      "grad_norm": 12.608149528503418,
      "learning_rate": 9.688e-07,
      "logits/chosen": -2.9641146659851074,
      "logits/rejected": -2.2039449214935303,
      "logps/chosen": -48.37688446044922,
      "logps/rejected": -57.32930374145508,
      "loss": 0.5626,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12079200893640518,
      "rewards/margins": 0.28163567185401917,
      "rewards/rejected": -0.1608436554670334,
      "step": 235
    },
    {
      "epoch": 0.0944,
      "grad_norm": 13.939122200012207,
      "learning_rate": 9.686666666666667e-07,
      "logits/chosen": -2.265079975128174,
      "logits/rejected": -2.1687662601470947,
      "logps/chosen": -142.1063690185547,
      "logps/rejected": -52.11003112792969,
      "loss": 0.5503,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1966731995344162,
      "rewards/margins": 0.31588342785835266,
      "rewards/rejected": -0.11921024322509766,
      "step": 236
    },
    {
      "epoch": 0.0948,
      "grad_norm": 10.4120454788208,
      "learning_rate": 9.685333333333333e-07,
      "logits/chosen": -2.799139976501465,
      "logits/rejected": -2.4456796646118164,
      "logps/chosen": -82.47776794433594,
      "logps/rejected": -46.45611572265625,
      "loss": 0.5504,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21945419907569885,
      "rewards/margins": 0.30990469455718994,
      "rewards/rejected": -0.0904504805803299,
      "step": 237
    },
    {
      "epoch": 0.0952,
      "grad_norm": 12.869604110717773,
      "learning_rate": 9.684e-07,
      "logits/chosen": -2.699747085571289,
      "logits/rejected": -2.158806324005127,
      "logps/chosen": -154.96807861328125,
      "logps/rejected": -53.3379020690918,
      "loss": 0.5445,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16052933037281036,
      "rewards/margins": 0.326046347618103,
      "rewards/rejected": -0.16551704704761505,
      "step": 238
    },
    {
      "epoch": 0.0956,
      "grad_norm": 11.156209945678711,
      "learning_rate": 9.682666666666667e-07,
      "logits/chosen": -2.5740654468536377,
      "logits/rejected": -2.534010410308838,
      "logps/chosen": -113.69047546386719,
      "logps/rejected": -39.520294189453125,
      "loss": 0.5787,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20405197143554688,
      "rewards/margins": 0.24408093094825745,
      "rewards/rejected": -0.04002895578742027,
      "step": 239
    },
    {
      "epoch": 0.096,
      "grad_norm": 10.830411911010742,
      "learning_rate": 9.681333333333333e-07,
      "logits/chosen": -2.681501865386963,
      "logits/rejected": -2.3931915760040283,
      "logps/chosen": -57.056785583496094,
      "logps/rejected": -71.1357421875,
      "loss": 0.6021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14244328439235687,
      "rewards/margins": 0.19637872278690338,
      "rewards/rejected": -0.05393543466925621,
      "step": 240
    },
    {
      "epoch": 0.0964,
      "grad_norm": 14.933113098144531,
      "learning_rate": 9.679999999999999e-07,
      "logits/chosen": -2.378328561782837,
      "logits/rejected": -2.1354238986968994,
      "logps/chosen": -117.75642395019531,
      "logps/rejected": -59.979732513427734,
      "loss": 0.5146,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32200852036476135,
      "rewards/margins": 0.3963966369628906,
      "rewards/rejected": -0.07438812404870987,
      "step": 241
    },
    {
      "epoch": 0.0968,
      "grad_norm": 11.585288047790527,
      "learning_rate": 9.678666666666667e-07,
      "logits/chosen": -2.6012721061706543,
      "logits/rejected": -2.4696052074432373,
      "logps/chosen": -88.02135467529297,
      "logps/rejected": -53.245731353759766,
      "loss": 0.5377,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21404343843460083,
      "rewards/margins": 0.34404146671295166,
      "rewards/rejected": -0.12999801337718964,
      "step": 242
    },
    {
      "epoch": 0.0972,
      "grad_norm": 11.19133472442627,
      "learning_rate": 9.677333333333333e-07,
      "logits/chosen": -2.8466906547546387,
      "logits/rejected": -2.562554359436035,
      "logps/chosen": -101.45362854003906,
      "logps/rejected": -53.99629592895508,
      "loss": 0.5656,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16729851067066193,
      "rewards/margins": 0.2744918763637543,
      "rewards/rejected": -0.10719337314367294,
      "step": 243
    },
    {
      "epoch": 0.0976,
      "grad_norm": 10.916500091552734,
      "learning_rate": 9.676e-07,
      "logits/chosen": -2.682588577270508,
      "logits/rejected": -2.5322775840759277,
      "logps/chosen": -55.45278549194336,
      "logps/rejected": -46.25843048095703,
      "loss": 0.5776,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1315101683139801,
      "rewards/margins": 0.25006169080734253,
      "rewards/rejected": -0.11855154484510422,
      "step": 244
    },
    {
      "epoch": 0.098,
      "grad_norm": 13.464993476867676,
      "learning_rate": 9.674666666666666e-07,
      "logits/chosen": -2.470658302307129,
      "logits/rejected": -1.9035453796386719,
      "logps/chosen": -135.5701904296875,
      "logps/rejected": -77.5209732055664,
      "loss": 0.533,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2267555296421051,
      "rewards/margins": 0.3543861508369446,
      "rewards/rejected": -0.12763062119483948,
      "step": 245
    },
    {
      "epoch": 0.0984,
      "grad_norm": 16.757408142089844,
      "learning_rate": 9.673333333333332e-07,
      "logits/chosen": -2.1699752807617188,
      "logits/rejected": -1.9810905456542969,
      "logps/chosen": -212.91053771972656,
      "logps/rejected": -96.94473266601562,
      "loss": 0.5527,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22557449340820312,
      "rewards/margins": 0.3099815249443054,
      "rewards/rejected": -0.08440704643726349,
      "step": 246
    },
    {
      "epoch": 0.0988,
      "grad_norm": 10.305451393127441,
      "learning_rate": 9.671999999999998e-07,
      "logits/chosen": -2.92205810546875,
      "logits/rejected": -2.5920681953430176,
      "logps/chosen": -65.25975036621094,
      "logps/rejected": -44.52280044555664,
      "loss": 0.6338,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08603516221046448,
      "rewards/margins": 0.1226116195321083,
      "rewards/rejected": -0.03657646104693413,
      "step": 247
    },
    {
      "epoch": 0.0992,
      "grad_norm": 11.873031616210938,
      "learning_rate": 9.670666666666666e-07,
      "logits/chosen": -2.6884591579437256,
      "logits/rejected": -2.5462114810943604,
      "logps/chosen": -82.27705383300781,
      "logps/rejected": -51.558746337890625,
      "loss": 0.6041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11294479668140411,
      "rewards/margins": 0.18721751868724823,
      "rewards/rejected": -0.07427272945642471,
      "step": 248
    },
    {
      "epoch": 0.0996,
      "grad_norm": 12.636064529418945,
      "learning_rate": 9.669333333333332e-07,
      "logits/chosen": -2.8846096992492676,
      "logits/rejected": -2.6405303478240967,
      "logps/chosen": -76.11021423339844,
      "logps/rejected": -55.318702697753906,
      "loss": 0.5371,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2146022915840149,
      "rewards/margins": 0.34162139892578125,
      "rewards/rejected": -0.12701912224292755,
      "step": 249
    },
    {
      "epoch": 0.1,
      "grad_norm": 14.477986335754395,
      "learning_rate": 9.668e-07,
      "logits/chosen": -2.996796131134033,
      "logits/rejected": -2.5445210933685303,
      "logps/chosen": -81.55099487304688,
      "logps/rejected": -67.04156494140625,
      "loss": 0.5442,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1414463073015213,
      "rewards/margins": 0.3286117613315582,
      "rewards/rejected": -0.18716545403003693,
      "step": 250
    },
    {
      "epoch": 0.1004,
      "grad_norm": 12.285835266113281,
      "learning_rate": 9.666666666666666e-07,
      "logits/chosen": -2.5787463188171387,
      "logits/rejected": -2.3602828979492188,
      "logps/chosen": -85.18162536621094,
      "logps/rejected": -58.48088073730469,
      "loss": 0.5651,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20270557701587677,
      "rewards/margins": 0.27499350905418396,
      "rewards/rejected": -0.07228794693946838,
      "step": 251
    },
    {
      "epoch": 0.1008,
      "grad_norm": 13.883536338806152,
      "learning_rate": 9.665333333333334e-07,
      "logits/chosen": -2.725827217102051,
      "logits/rejected": -2.6608943939208984,
      "logps/chosen": -79.40562438964844,
      "logps/rejected": -44.887210845947266,
      "loss": 0.5706,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10445823520421982,
      "rewards/margins": 0.2625040113925934,
      "rewards/rejected": -0.15804576873779297,
      "step": 252
    },
    {
      "epoch": 0.1012,
      "grad_norm": 13.792946815490723,
      "learning_rate": 9.664e-07,
      "logits/chosen": -2.620441436767578,
      "logits/rejected": -2.115090847015381,
      "logps/chosen": -133.4053955078125,
      "logps/rejected": -58.2965087890625,
      "loss": 0.465,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31667137145996094,
      "rewards/margins": 0.5250135660171509,
      "rewards/rejected": -0.20834217965602875,
      "step": 253
    },
    {
      "epoch": 0.1016,
      "grad_norm": 11.088953971862793,
      "learning_rate": 9.662666666666668e-07,
      "logits/chosen": -2.807178020477295,
      "logits/rejected": -2.250422477722168,
      "logps/chosen": -86.2173843383789,
      "logps/rejected": -54.9013557434082,
      "loss": 0.5774,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1739753782749176,
      "rewards/margins": 0.24934692680835724,
      "rewards/rejected": -0.07537155598402023,
      "step": 254
    },
    {
      "epoch": 0.102,
      "grad_norm": 11.844483375549316,
      "learning_rate": 9.661333333333331e-07,
      "logits/chosen": -2.736293077468872,
      "logits/rejected": -2.2391159534454346,
      "logps/chosen": -61.40556335449219,
      "logps/rejected": -53.398155212402344,
      "loss": 0.5662,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1166139617562294,
      "rewards/margins": 0.2725318968296051,
      "rewards/rejected": -0.1559179276227951,
      "step": 255
    },
    {
      "epoch": 0.1024,
      "grad_norm": 12.362787246704102,
      "learning_rate": 9.66e-07,
      "logits/chosen": -2.7147250175476074,
      "logits/rejected": -2.4162652492523193,
      "logps/chosen": -81.22846984863281,
      "logps/rejected": -58.85767364501953,
      "loss": 0.5948,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2031753659248352,
      "rewards/margins": 0.20747338235378265,
      "rewards/rejected": -0.004298019222915173,
      "step": 256
    },
    {
      "epoch": 0.1028,
      "grad_norm": 14.310436248779297,
      "learning_rate": 9.658666666666665e-07,
      "logits/chosen": -3.2065136432647705,
      "logits/rejected": -3.1131980419158936,
      "logps/chosen": -46.42744445800781,
      "logps/rejected": -87.22752380371094,
      "loss": 0.6127,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10922852158546448,
      "rewards/margins": 0.16977271437644958,
      "rewards/rejected": -0.060544203966856,
      "step": 257
    },
    {
      "epoch": 0.1032,
      "grad_norm": 11.224837303161621,
      "learning_rate": 9.657333333333333e-07,
      "logits/chosen": -2.581450939178467,
      "logits/rejected": -2.0816686153411865,
      "logps/chosen": -45.537506103515625,
      "logps/rejected": -72.30890655517578,
      "loss": 0.5838,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13282623887062073,
      "rewards/margins": 0.2394033521413803,
      "rewards/rejected": -0.10657711327075958,
      "step": 258
    },
    {
      "epoch": 0.1036,
      "grad_norm": 15.455480575561523,
      "learning_rate": 9.656e-07,
      "logits/chosen": -2.606947183609009,
      "logits/rejected": -2.3036937713623047,
      "logps/chosen": -92.95742797851562,
      "logps/rejected": -127.46038818359375,
      "loss": 0.5532,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2049579620361328,
      "rewards/margins": 0.30480366945266724,
      "rewards/rejected": -0.09984569251537323,
      "step": 259
    },
    {
      "epoch": 0.104,
      "grad_norm": 14.56943416595459,
      "learning_rate": 9.654666666666667e-07,
      "logits/chosen": -2.3152523040771484,
      "logits/rejected": -1.9844529628753662,
      "logps/chosen": -68.8897705078125,
      "logps/rejected": -82.29354095458984,
      "loss": 0.5473,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17326565086841583,
      "rewards/margins": 0.3171043395996094,
      "rewards/rejected": -0.14383868873119354,
      "step": 260
    },
    {
      "epoch": 0.1044,
      "grad_norm": 14.523788452148438,
      "learning_rate": 9.653333333333333e-07,
      "logits/chosen": -2.414365768432617,
      "logits/rejected": -1.8523826599121094,
      "logps/chosen": -116.79238891601562,
      "logps/rejected": -75.55731201171875,
      "loss": 0.4622,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35019874572753906,
      "rewards/margins": 0.5320335626602173,
      "rewards/rejected": -0.18183478713035583,
      "step": 261
    },
    {
      "epoch": 0.1048,
      "grad_norm": 12.18921184539795,
      "learning_rate": 9.651999999999999e-07,
      "logits/chosen": -2.7868642807006836,
      "logits/rejected": -2.27726411819458,
      "logps/chosen": -63.38885498046875,
      "logps/rejected": -66.37667846679688,
      "loss": 0.5284,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15844117105007172,
      "rewards/margins": 0.3648916482925415,
      "rewards/rejected": -0.2064504623413086,
      "step": 262
    },
    {
      "epoch": 0.1052,
      "grad_norm": 11.351016998291016,
      "learning_rate": 9.650666666666667e-07,
      "logits/chosen": -2.390974521636963,
      "logits/rejected": -2.176896810531616,
      "logps/chosen": -73.06753540039062,
      "logps/rejected": -69.82073974609375,
      "loss": 0.5587,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18039283156394958,
      "rewards/margins": 0.291041761636734,
      "rewards/rejected": -0.11064891517162323,
      "step": 263
    },
    {
      "epoch": 0.1056,
      "grad_norm": 10.895576477050781,
      "learning_rate": 9.649333333333333e-07,
      "logits/chosen": -2.737061023712158,
      "logits/rejected": -2.066627025604248,
      "logps/chosen": -52.47587203979492,
      "logps/rejected": -53.72434997558594,
      "loss": 0.6165,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08714409172534943,
      "rewards/margins": 0.15982875227928162,
      "rewards/rejected": -0.07268466800451279,
      "step": 264
    },
    {
      "epoch": 0.106,
      "grad_norm": 11.539926528930664,
      "learning_rate": 9.647999999999999e-07,
      "logits/chosen": -2.7459235191345215,
      "logits/rejected": -2.7650585174560547,
      "logps/chosen": -121.33505249023438,
      "logps/rejected": -45.89909744262695,
      "loss": 0.548,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21744385361671448,
      "rewards/margins": 0.31521666049957275,
      "rewards/rejected": -0.09777279198169708,
      "step": 265
    },
    {
      "epoch": 0.1064,
      "grad_norm": 10.200248718261719,
      "learning_rate": 9.646666666666666e-07,
      "logits/chosen": -2.1453700065612793,
      "logits/rejected": -2.109912872314453,
      "logps/chosen": -86.16777038574219,
      "logps/rejected": -40.84568405151367,
      "loss": 0.6088,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1419219970703125,
      "rewards/margins": 0.17790812253952026,
      "rewards/rejected": -0.03598614037036896,
      "step": 266
    },
    {
      "epoch": 0.1068,
      "grad_norm": 13.282855987548828,
      "learning_rate": 9.645333333333332e-07,
      "logits/chosen": -2.693593978881836,
      "logits/rejected": -2.5922727584838867,
      "logps/chosen": -117.30411529541016,
      "logps/rejected": -45.918540954589844,
      "loss": 0.5144,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27571409940719604,
      "rewards/margins": 0.3981611132621765,
      "rewards/rejected": -0.12244701385498047,
      "step": 267
    },
    {
      "epoch": 0.1072,
      "grad_norm": 11.413549423217773,
      "learning_rate": 9.644e-07,
      "logits/chosen": -2.8888587951660156,
      "logits/rejected": -2.2332396507263184,
      "logps/chosen": -47.05351257324219,
      "logps/rejected": -51.462223052978516,
      "loss": 0.5644,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1175716370344162,
      "rewards/margins": 0.27729302644729614,
      "rewards/rejected": -0.15972137451171875,
      "step": 268
    },
    {
      "epoch": 0.1076,
      "grad_norm": 10.386602401733398,
      "learning_rate": 9.642666666666666e-07,
      "logits/chosen": -2.749262809753418,
      "logits/rejected": -2.5206828117370605,
      "logps/chosen": -44.93049240112305,
      "logps/rejected": -39.34410858154297,
      "loss": 0.6088,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13404332101345062,
      "rewards/margins": 0.1765270233154297,
      "rewards/rejected": -0.04248371347784996,
      "step": 269
    },
    {
      "epoch": 0.108,
      "grad_norm": 13.386124610900879,
      "learning_rate": 9.641333333333332e-07,
      "logits/chosen": -2.11541748046875,
      "logits/rejected": -1.9456334114074707,
      "logps/chosen": -128.56689453125,
      "logps/rejected": -71.74072265625,
      "loss": 0.4768,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3393813967704773,
      "rewards/margins": 0.4929126799106598,
      "rewards/rejected": -0.1535312682390213,
      "step": 270
    },
    {
      "epoch": 0.1084,
      "grad_norm": 12.339521408081055,
      "learning_rate": 9.64e-07,
      "logits/chosen": -2.729220390319824,
      "logits/rejected": -2.2821385860443115,
      "logps/chosen": -58.18528747558594,
      "logps/rejected": -54.176902770996094,
      "loss": 0.5298,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17373314499855042,
      "rewards/margins": 0.35872137546539307,
      "rewards/rejected": -0.18498821556568146,
      "step": 271
    },
    {
      "epoch": 0.1088,
      "grad_norm": 14.892356872558594,
      "learning_rate": 9.638666666666666e-07,
      "logits/chosen": -2.181987762451172,
      "logits/rejected": -2.0555758476257324,
      "logps/chosen": -112.53101348876953,
      "logps/rejected": -93.51414489746094,
      "loss": 0.5033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3639663755893707,
      "rewards/margins": 0.426496684551239,
      "rewards/rejected": -0.06253032386302948,
      "step": 272
    },
    {
      "epoch": 0.1092,
      "grad_norm": 16.575956344604492,
      "learning_rate": 9.637333333333334e-07,
      "logits/chosen": -2.2898645401000977,
      "logits/rejected": -2.1808629035949707,
      "logps/chosen": -119.03189849853516,
      "logps/rejected": -117.4547119140625,
      "loss": 0.518,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31770479679107666,
      "rewards/margins": 0.3885051906108856,
      "rewards/rejected": -0.07080040127038956,
      "step": 273
    },
    {
      "epoch": 0.1096,
      "grad_norm": 16.658960342407227,
      "learning_rate": 9.636e-07,
      "logits/chosen": -2.2473299503326416,
      "logits/rejected": -2.3494081497192383,
      "logps/chosen": -118.08937072753906,
      "logps/rejected": -139.82785034179688,
      "loss": 0.5297,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.30400124192237854,
      "rewards/margins": 0.35982745885849,
      "rewards/rejected": -0.05582618713378906,
      "step": 274
    },
    {
      "epoch": 0.11,
      "grad_norm": 13.855313301086426,
      "learning_rate": 9.634666666666666e-07,
      "logits/chosen": -2.5874741077423096,
      "logits/rejected": -2.229918956756592,
      "logps/chosen": -63.14530944824219,
      "logps/rejected": -64.22936248779297,
      "loss": 0.5276,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19540539383888245,
      "rewards/margins": 0.36700326204299927,
      "rewards/rejected": -0.17159785330295563,
      "step": 275
    },
    {
      "epoch": 0.1104,
      "grad_norm": 11.127725601196289,
      "learning_rate": 9.633333333333334e-07,
      "logits/chosen": -2.5795135498046875,
      "logits/rejected": -2.7034010887145996,
      "logps/chosen": -77.92066955566406,
      "logps/rejected": -51.76694107055664,
      "loss": 0.6116,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15128478407859802,
      "rewards/margins": 0.17759132385253906,
      "rewards/rejected": -0.02630653604865074,
      "step": 276
    },
    {
      "epoch": 0.1108,
      "grad_norm": 11.897578239440918,
      "learning_rate": 9.632e-07,
      "logits/chosen": -2.5387845039367676,
      "logits/rejected": -1.9630539417266846,
      "logps/chosen": -118.51882934570312,
      "logps/rejected": -61.218936920166016,
      "loss": 0.5081,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2297641783952713,
      "rewards/margins": 0.4121883511543274,
      "rewards/rejected": -0.1824241727590561,
      "step": 277
    },
    {
      "epoch": 0.1112,
      "grad_norm": 13.022068977355957,
      "learning_rate": 9.630666666666665e-07,
      "logits/chosen": -2.339823007583618,
      "logits/rejected": -1.9452791213989258,
      "logps/chosen": -94.13188934326172,
      "logps/rejected": -58.43131637573242,
      "loss": 0.4953,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32966727018356323,
      "rewards/margins": 0.4447874128818512,
      "rewards/rejected": -0.11512012779712677,
      "step": 278
    },
    {
      "epoch": 0.1116,
      "grad_norm": 16.16520881652832,
      "learning_rate": 9.629333333333333e-07,
      "logits/chosen": -2.6844329833984375,
      "logits/rejected": -2.569692611694336,
      "logps/chosen": -106.59530639648438,
      "logps/rejected": -84.02323913574219,
      "loss": 0.54,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18657341599464417,
      "rewards/margins": 0.33520472049713135,
      "rewards/rejected": -0.148631289601326,
      "step": 279
    },
    {
      "epoch": 0.112,
      "grad_norm": 11.505144119262695,
      "learning_rate": 9.628e-07,
      "logits/chosen": -2.381596088409424,
      "logits/rejected": -2.0301103591918945,
      "logps/chosen": -60.75823211669922,
      "logps/rejected": -42.608856201171875,
      "loss": 0.5811,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19298726320266724,
      "rewards/margins": 0.24002990126609802,
      "rewards/rejected": -0.04704265668988228,
      "step": 280
    },
    {
      "epoch": 0.1124,
      "grad_norm": 12.947708129882812,
      "learning_rate": 9.626666666666667e-07,
      "logits/chosen": -2.6133742332458496,
      "logits/rejected": -2.68745756149292,
      "logps/chosen": -72.91663360595703,
      "logps/rejected": -64.74745178222656,
      "loss": 0.5797,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.03172721713781357,
      "rewards/margins": 0.24187812209129333,
      "rewards/rejected": -0.2736053466796875,
      "step": 281
    },
    {
      "epoch": 0.1128,
      "grad_norm": 10.15443229675293,
      "learning_rate": 9.625333333333333e-07,
      "logits/chosen": -2.8714637756347656,
      "logits/rejected": -2.623696804046631,
      "logps/chosen": -79.18229675292969,
      "logps/rejected": -41.662025451660156,
      "loss": 0.5804,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0993320494890213,
      "rewards/margins": 0.24142715334892273,
      "rewards/rejected": -0.14209508895874023,
      "step": 282
    },
    {
      "epoch": 0.1132,
      "grad_norm": 13.206673622131348,
      "learning_rate": 9.624e-07,
      "logits/chosen": -2.3570175170898438,
      "logits/rejected": -2.140183925628662,
      "logps/chosen": -85.52045440673828,
      "logps/rejected": -90.3065185546875,
      "loss": 0.545,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23186227679252625,
      "rewards/margins": 0.3263935446739197,
      "rewards/rejected": -0.09453125298023224,
      "step": 283
    },
    {
      "epoch": 0.1136,
      "grad_norm": 12.758453369140625,
      "learning_rate": 9.622666666666667e-07,
      "logits/chosen": -2.8606066703796387,
      "logits/rejected": -2.562542200088501,
      "logps/chosen": -70.24431610107422,
      "logps/rejected": -49.43572998046875,
      "loss": 0.5222,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1956321746110916,
      "rewards/margins": 0.384128212928772,
      "rewards/rejected": -0.18849602341651917,
      "step": 284
    },
    {
      "epoch": 0.114,
      "grad_norm": 11.397730827331543,
      "learning_rate": 9.621333333333333e-07,
      "logits/chosen": -2.598385810852051,
      "logits/rejected": -1.9585115909576416,
      "logps/chosen": -96.2734375,
      "logps/rejected": -72.5282211303711,
      "loss": 0.4983,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3511730432510376,
      "rewards/margins": 0.4397304654121399,
      "rewards/rejected": -0.08855743706226349,
      "step": 285
    },
    {
      "epoch": 0.1144,
      "grad_norm": 13.743648529052734,
      "learning_rate": 9.619999999999999e-07,
      "logits/chosen": -2.4883980751037598,
      "logits/rejected": -2.339099884033203,
      "logps/chosen": -190.8118896484375,
      "logps/rejected": -69.00518798828125,
      "loss": 0.4917,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2861228883266449,
      "rewards/margins": 0.4540244936943054,
      "rewards/rejected": -0.16790160536766052,
      "step": 286
    },
    {
      "epoch": 0.1148,
      "grad_norm": 10.245321273803711,
      "learning_rate": 9.618666666666667e-07,
      "logits/chosen": -2.7588577270507812,
      "logits/rejected": -2.592149257659912,
      "logps/chosen": -82.1906967163086,
      "logps/rejected": -44.89793395996094,
      "loss": 0.553,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2328849732875824,
      "rewards/margins": 0.303628146648407,
      "rewards/rejected": -0.07074318081140518,
      "step": 287
    },
    {
      "epoch": 0.1152,
      "grad_norm": 11.375530242919922,
      "learning_rate": 9.617333333333332e-07,
      "logits/chosen": -2.455472946166992,
      "logits/rejected": -2.406189441680908,
      "logps/chosen": -86.5596694946289,
      "logps/rejected": -50.590423583984375,
      "loss": 0.5843,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18934325873851776,
      "rewards/margins": 0.2332691252231598,
      "rewards/rejected": -0.04392585903406143,
      "step": 288
    },
    {
      "epoch": 0.1156,
      "grad_norm": 13.930374145507812,
      "learning_rate": 9.616e-07,
      "logits/chosen": -2.500839948654175,
      "logits/rejected": -2.0779800415039062,
      "logps/chosen": -103.0843505859375,
      "logps/rejected": -78.87445068359375,
      "loss": 0.4984,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3213230073451996,
      "rewards/margins": 0.4382026791572571,
      "rewards/rejected": -0.1168796569108963,
      "step": 289
    },
    {
      "epoch": 0.116,
      "grad_norm": 10.876916885375977,
      "learning_rate": 9.614666666666666e-07,
      "logits/chosen": -2.7468440532684326,
      "logits/rejected": -2.8252105712890625,
      "logps/chosen": -66.32060241699219,
      "logps/rejected": -35.465633392333984,
      "loss": 0.5276,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2787483334541321,
      "rewards/margins": 0.36833494901657104,
      "rewards/rejected": -0.08958664536476135,
      "step": 290
    },
    {
      "epoch": 0.1164,
      "grad_norm": 11.200733184814453,
      "learning_rate": 9.613333333333334e-07,
      "logits/chosen": -3.091628074645996,
      "logits/rejected": -2.771372079849243,
      "logps/chosen": -75.97880554199219,
      "logps/rejected": -44.81199645996094,
      "loss": 0.5779,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08921241760253906,
      "rewards/margins": 0.24746915698051453,
      "rewards/rejected": -0.15825672447681427,
      "step": 291
    },
    {
      "epoch": 0.1168,
      "grad_norm": 14.34808349609375,
      "learning_rate": 9.612e-07,
      "logits/chosen": -2.251359462738037,
      "logits/rejected": -1.9815106391906738,
      "logps/chosen": -159.7686767578125,
      "logps/rejected": -99.88140869140625,
      "loss": 0.5175,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25996702909469604,
      "rewards/margins": 0.3889825940132141,
      "rewards/rejected": -0.12901553511619568,
      "step": 292
    },
    {
      "epoch": 0.1172,
      "grad_norm": 12.026443481445312,
      "learning_rate": 9.610666666666666e-07,
      "logits/chosen": -2.443911552429199,
      "logits/rejected": -2.204925537109375,
      "logps/chosen": -115.75279235839844,
      "logps/rejected": -57.125946044921875,
      "loss": 0.4901,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32388076186180115,
      "rewards/margins": 0.4609184265136719,
      "rewards/rejected": -0.13703766465187073,
      "step": 293
    },
    {
      "epoch": 0.1176,
      "grad_norm": 11.989630699157715,
      "learning_rate": 9.609333333333332e-07,
      "logits/chosen": -2.318539619445801,
      "logits/rejected": -2.389944553375244,
      "logps/chosen": -93.18744659423828,
      "logps/rejected": -52.4114990234375,
      "loss": 0.4833,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33550339937210083,
      "rewards/margins": 0.47567272186279297,
      "rewards/rejected": -0.14016933739185333,
      "step": 294
    },
    {
      "epoch": 0.118,
      "grad_norm": 12.804281234741211,
      "learning_rate": 9.608e-07,
      "logits/chosen": -2.692420244216919,
      "logits/rejected": -2.3234481811523438,
      "logps/chosen": -74.93116760253906,
      "logps/rejected": -64.7032470703125,
      "loss": 0.5971,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18749141693115234,
      "rewards/margins": 0.2059541642665863,
      "rewards/rejected": -0.018462752923369408,
      "step": 295
    },
    {
      "epoch": 0.1184,
      "grad_norm": 11.60138988494873,
      "learning_rate": 9.606666666666666e-07,
      "logits/chosen": -2.9596920013427734,
      "logits/rejected": -2.062253475189209,
      "logps/chosen": -67.3978271484375,
      "logps/rejected": -76.24171447753906,
      "loss": 0.5472,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20576173067092896,
      "rewards/margins": 0.3169826567173004,
      "rewards/rejected": -0.11122093349695206,
      "step": 296
    },
    {
      "epoch": 0.1188,
      "grad_norm": 17.35449981689453,
      "learning_rate": 9.605333333333334e-07,
      "logits/chosen": -2.3334949016571045,
      "logits/rejected": -2.922187566757202,
      "logps/chosen": -183.2899169921875,
      "logps/rejected": -39.421958923339844,
      "loss": 0.5261,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2773498594760895,
      "rewards/margins": 0.3679012656211853,
      "rewards/rejected": -0.09055137634277344,
      "step": 297
    },
    {
      "epoch": 0.1192,
      "grad_norm": 15.364314079284668,
      "learning_rate": 9.604e-07,
      "logits/chosen": -2.2135796546936035,
      "logits/rejected": -2.356074810028076,
      "logps/chosen": -216.4764862060547,
      "logps/rejected": -70.56707763671875,
      "loss": 0.5503,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23152846097946167,
      "rewards/margins": 0.3124872148036957,
      "rewards/rejected": -0.08095874637365341,
      "step": 298
    },
    {
      "epoch": 0.1196,
      "grad_norm": 14.414264678955078,
      "learning_rate": 9.602666666666667e-07,
      "logits/chosen": -2.393329620361328,
      "logits/rejected": -2.2561445236206055,
      "logps/chosen": -115.15245056152344,
      "logps/rejected": -65.39437866210938,
      "loss": 0.5449,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21345406770706177,
      "rewards/margins": 0.32388851046562195,
      "rewards/rejected": -0.11043444275856018,
      "step": 299
    },
    {
      "epoch": 0.12,
      "grad_norm": 14.127745628356934,
      "learning_rate": 9.601333333333333e-07,
      "logits/chosen": -2.4858765602111816,
      "logits/rejected": -2.9067254066467285,
      "logps/chosen": -127.36309814453125,
      "logps/rejected": -65.28446960449219,
      "loss": 0.5167,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2778301239013672,
      "rewards/margins": 0.3989790081977844,
      "rewards/rejected": -0.12114886939525604,
      "step": 300
    },
    {
      "epoch": 0.1204,
      "grad_norm": 11.31624698638916,
      "learning_rate": 9.6e-07,
      "logits/chosen": -2.710052013397217,
      "logits/rejected": -2.5398049354553223,
      "logps/chosen": -89.34503173828125,
      "logps/rejected": -37.44410705566406,
      "loss": 0.5752,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16841430962085724,
      "rewards/margins": 0.2522117495536804,
      "rewards/rejected": -0.08379745483398438,
      "step": 301
    },
    {
      "epoch": 0.1208,
      "grad_norm": 11.86556625366211,
      "learning_rate": 9.598666666666665e-07,
      "logits/chosen": -2.5224955081939697,
      "logits/rejected": -2.6495378017425537,
      "logps/chosen": -122.7474136352539,
      "logps/rejected": -52.861637115478516,
      "loss": 0.5154,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.28885382413864136,
      "rewards/margins": 0.40966349840164185,
      "rewards/rejected": -0.1208096593618393,
      "step": 302
    },
    {
      "epoch": 0.1212,
      "grad_norm": 14.758208274841309,
      "learning_rate": 9.597333333333333e-07,
      "logits/chosen": -2.61348295211792,
      "logits/rejected": -2.043400287628174,
      "logps/chosen": -96.689453125,
      "logps/rejected": -123.66796875,
      "loss": 0.4452,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3707355558872223,
      "rewards/margins": 0.578417181968689,
      "rewards/rejected": -0.20768165588378906,
      "step": 303
    },
    {
      "epoch": 0.1216,
      "grad_norm": 12.539032936096191,
      "learning_rate": 9.595999999999999e-07,
      "logits/chosen": -2.263493537902832,
      "logits/rejected": -2.184720993041992,
      "logps/chosen": -164.20608520507812,
      "logps/rejected": -58.287315368652344,
      "loss": 0.4909,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3716629147529602,
      "rewards/margins": 0.47022074460983276,
      "rewards/rejected": -0.09855785220861435,
      "step": 304
    },
    {
      "epoch": 0.122,
      "grad_norm": 12.948230743408203,
      "learning_rate": 9.594666666666667e-07,
      "logits/chosen": -2.2045559883117676,
      "logits/rejected": -2.27197265625,
      "logps/chosen": -122.56692504882812,
      "logps/rejected": -64.07986450195312,
      "loss": 0.4986,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3281089663505554,
      "rewards/margins": 0.4366706907749176,
      "rewards/rejected": -0.10856170952320099,
      "step": 305
    },
    {
      "epoch": 0.1224,
      "grad_norm": 12.494832992553711,
      "learning_rate": 9.593333333333333e-07,
      "logits/chosen": -2.713042736053467,
      "logits/rejected": -2.350900650024414,
      "logps/chosen": -91.36799621582031,
      "logps/rejected": -78.91123962402344,
      "loss": 0.5276,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21907255053520203,
      "rewards/margins": 0.3664182722568512,
      "rewards/rejected": -0.14734573662281036,
      "step": 306
    },
    {
      "epoch": 0.1228,
      "grad_norm": 12.374736785888672,
      "learning_rate": 9.592e-07,
      "logits/chosen": -2.5275473594665527,
      "logits/rejected": -2.3308136463165283,
      "logps/chosen": -95.19680786132812,
      "logps/rejected": -46.2239875793457,
      "loss": 0.4731,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3064781129360199,
      "rewards/margins": 0.5053675770759583,
      "rewards/rejected": -0.19888944923877716,
      "step": 307
    },
    {
      "epoch": 0.1232,
      "grad_norm": 14.692665100097656,
      "learning_rate": 9.590666666666667e-07,
      "logits/chosen": -2.5148119926452637,
      "logits/rejected": -2.345013380050659,
      "logps/chosen": -123.57051086425781,
      "logps/rejected": -115.00202941894531,
      "loss": 0.5511,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2235611081123352,
      "rewards/margins": 0.3091875910758972,
      "rewards/rejected": -0.0856265127658844,
      "step": 308
    },
    {
      "epoch": 0.1236,
      "grad_norm": 11.819233894348145,
      "learning_rate": 9.589333333333332e-07,
      "logits/chosen": -2.6334099769592285,
      "logits/rejected": -2.436161756515503,
      "logps/chosen": -121.42669677734375,
      "logps/rejected": -54.64691162109375,
      "loss": 0.4438,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3605896234512329,
      "rewards/margins": 0.5828342437744141,
      "rewards/rejected": -0.22224465012550354,
      "step": 309
    },
    {
      "epoch": 0.124,
      "grad_norm": 13.013739585876465,
      "learning_rate": 9.588e-07,
      "logits/chosen": -2.4400205612182617,
      "logits/rejected": -2.1053237915039062,
      "logps/chosen": -131.06320190429688,
      "logps/rejected": -60.690765380859375,
      "loss": 0.4911,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3392433226108551,
      "rewards/margins": 0.45592767000198364,
      "rewards/rejected": -0.11668434739112854,
      "step": 310
    },
    {
      "epoch": 0.1244,
      "grad_norm": 14.168237686157227,
      "learning_rate": 9.586666666666666e-07,
      "logits/chosen": -2.798041820526123,
      "logits/rejected": -2.2631301879882812,
      "logps/chosen": -71.19357299804688,
      "logps/rejected": -57.049285888671875,
      "loss": 0.5124,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1533992737531662,
      "rewards/margins": 0.40365105867385864,
      "rewards/rejected": -0.25025177001953125,
      "step": 311
    },
    {
      "epoch": 0.1248,
      "grad_norm": 13.66840648651123,
      "learning_rate": 9.585333333333332e-07,
      "logits/chosen": -2.3590822219848633,
      "logits/rejected": -2.2268028259277344,
      "logps/chosen": -121.51599884033203,
      "logps/rejected": -81.8197021484375,
      "loss": 0.41,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4248546361923218,
      "rewards/margins": 0.6801601648330688,
      "rewards/rejected": -0.2553054690361023,
      "step": 312
    },
    {
      "epoch": 0.1252,
      "grad_norm": 9.144800186157227,
      "learning_rate": 9.584e-07,
      "logits/chosen": -2.5937328338623047,
      "logits/rejected": -2.6093220710754395,
      "logps/chosen": -88.7752456665039,
      "logps/rejected": -32.35893249511719,
      "loss": 0.5328,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27880629897117615,
      "rewards/margins": 0.35596904158592224,
      "rewards/rejected": -0.0771627426147461,
      "step": 313
    },
    {
      "epoch": 0.1256,
      "grad_norm": 11.480067253112793,
      "learning_rate": 9.582666666666666e-07,
      "logits/chosen": -2.6348745822906494,
      "logits/rejected": -2.105742931365967,
      "logps/chosen": -79.30473327636719,
      "logps/rejected": -68.44866943359375,
      "loss": 0.5157,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2758018672466278,
      "rewards/margins": 0.3962383568286896,
      "rewards/rejected": -0.12043648213148117,
      "step": 314
    },
    {
      "epoch": 0.126,
      "grad_norm": 13.031890869140625,
      "learning_rate": 9.581333333333332e-07,
      "logits/chosen": -2.38432240486145,
      "logits/rejected": -2.03804087638855,
      "logps/chosen": -93.69805145263672,
      "logps/rejected": -58.83988952636719,
      "loss": 0.5,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23303183913230896,
      "rewards/margins": 0.43355751037597656,
      "rewards/rejected": -0.2005256712436676,
      "step": 315
    },
    {
      "epoch": 0.1264,
      "grad_norm": 15.442197799682617,
      "learning_rate": 9.58e-07,
      "logits/chosen": -2.6408817768096924,
      "logits/rejected": -2.356757879257202,
      "logps/chosen": -139.643798828125,
      "logps/rejected": -93.89179229736328,
      "loss": 0.4697,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3396093547344208,
      "rewards/margins": 0.5117748379707336,
      "rewards/rejected": -0.17216548323631287,
      "step": 316
    },
    {
      "epoch": 0.1268,
      "grad_norm": 11.783806800842285,
      "learning_rate": 9.578666666666666e-07,
      "logits/chosen": -2.450057029724121,
      "logits/rejected": -2.954558849334717,
      "logps/chosen": -94.44992065429688,
      "logps/rejected": -63.26305389404297,
      "loss": 0.5455,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20738202333450317,
      "rewards/margins": 0.32521724700927734,
      "rewards/rejected": -0.11783523857593536,
      "step": 317
    },
    {
      "epoch": 0.1272,
      "grad_norm": 14.069121360778809,
      "learning_rate": 9.577333333333334e-07,
      "logits/chosen": -2.4489121437072754,
      "logits/rejected": -2.604701519012451,
      "logps/chosen": -124.90910339355469,
      "logps/rejected": -106.36441040039062,
      "loss": 0.4764,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41106414794921875,
      "rewards/margins": 0.49994468688964844,
      "rewards/rejected": -0.08888053894042969,
      "step": 318
    },
    {
      "epoch": 0.1276,
      "grad_norm": 13.87526798248291,
      "learning_rate": 9.576e-07,
      "logits/chosen": -2.3954219818115234,
      "logits/rejected": -2.0884156227111816,
      "logps/chosen": -141.67933654785156,
      "logps/rejected": -121.00245666503906,
      "loss": 0.4316,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.44456636905670166,
      "rewards/margins": 0.6168369054794312,
      "rewards/rejected": -0.17227058112621307,
      "step": 319
    },
    {
      "epoch": 0.128,
      "grad_norm": 14.893431663513184,
      "learning_rate": 9.574666666666667e-07,
      "logits/chosen": -2.3207926750183105,
      "logits/rejected": -1.8289262056350708,
      "logps/chosen": -149.63255310058594,
      "logps/rejected": -94.1468734741211,
      "loss": 0.4502,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4229923486709595,
      "rewards/margins": 0.566881537437439,
      "rewards/rejected": -0.14388923346996307,
      "step": 320
    },
    {
      "epoch": 0.1284,
      "grad_norm": 12.483160972595215,
      "learning_rate": 9.573333333333333e-07,
      "logits/chosen": -2.4375243186950684,
      "logits/rejected": -2.3115592002868652,
      "logps/chosen": -153.672607421875,
      "logps/rejected": -62.938602447509766,
      "loss": 0.4616,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4222961366176605,
      "rewards/margins": 0.5338737964630127,
      "rewards/rejected": -0.111577607691288,
      "step": 321
    },
    {
      "epoch": 0.1288,
      "grad_norm": 12.255269050598145,
      "learning_rate": 9.572e-07,
      "logits/chosen": -2.7185068130493164,
      "logits/rejected": -2.311610460281372,
      "logps/chosen": -114.10456085205078,
      "logps/rejected": -99.05104064941406,
      "loss": 0.4575,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33180543780326843,
      "rewards/margins": 0.5450943112373352,
      "rewards/rejected": -0.21328887343406677,
      "step": 322
    },
    {
      "epoch": 0.1292,
      "grad_norm": 14.442930221557617,
      "learning_rate": 9.570666666666665e-07,
      "logits/chosen": -2.682605266571045,
      "logits/rejected": -2.4179482460021973,
      "logps/chosen": -89.25605773925781,
      "logps/rejected": -51.89922332763672,
      "loss": 0.4997,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21683159470558167,
      "rewards/margins": 0.4367899000644684,
      "rewards/rejected": -0.21995830535888672,
      "step": 323
    },
    {
      "epoch": 0.1296,
      "grad_norm": 14.479134559631348,
      "learning_rate": 9.569333333333333e-07,
      "logits/chosen": -2.5268187522888184,
      "logits/rejected": -2.1099557876586914,
      "logps/chosen": -103.29339599609375,
      "logps/rejected": -71.46932983398438,
      "loss": 0.4911,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2946203351020813,
      "rewards/margins": 0.4609830975532532,
      "rewards/rejected": -0.16636276245117188,
      "step": 324
    },
    {
      "epoch": 0.13,
      "grad_norm": 12.61633014678955,
      "learning_rate": 9.567999999999999e-07,
      "logits/chosen": -2.662306070327759,
      "logits/rejected": -2.5297892093658447,
      "logps/chosen": -96.58232116699219,
      "logps/rejected": -51.356361389160156,
      "loss": 0.5367,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2546268403530121,
      "rewards/margins": 0.3419555723667145,
      "rewards/rejected": -0.0873287245631218,
      "step": 325
    },
    {
      "epoch": 0.1304,
      "grad_norm": 16.73124122619629,
      "learning_rate": 9.566666666666667e-07,
      "logits/chosen": -2.601661205291748,
      "logits/rejected": -2.0740904808044434,
      "logps/chosen": -65.95314025878906,
      "logps/rejected": -77.5570297241211,
      "loss": 0.4832,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2322101593017578,
      "rewards/margins": 0.47631171345710754,
      "rewards/rejected": -0.24410152435302734,
      "step": 326
    },
    {
      "epoch": 0.1308,
      "grad_norm": 11.234219551086426,
      "learning_rate": 9.565333333333333e-07,
      "logits/chosen": -2.9359560012817383,
      "logits/rejected": -2.9388327598571777,
      "logps/chosen": -44.48927688598633,
      "logps/rejected": -39.09745407104492,
      "loss": 0.5856,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.137891486287117,
      "rewards/margins": 0.22983330488204956,
      "rewards/rejected": -0.09194183349609375,
      "step": 327
    },
    {
      "epoch": 0.1312,
      "grad_norm": 12.9744291305542,
      "learning_rate": 9.564e-07,
      "logits/chosen": -2.3814525604248047,
      "logits/rejected": -2.0887951850891113,
      "logps/chosen": -114.58306884765625,
      "logps/rejected": -80.9638442993164,
      "loss": 0.4115,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42102470993995667,
      "rewards/margins": 0.6751346588134766,
      "rewards/rejected": -0.2541099786758423,
      "step": 328
    },
    {
      "epoch": 0.1316,
      "grad_norm": 13.618027687072754,
      "learning_rate": 9.562666666666667e-07,
      "logits/chosen": -2.6410305500030518,
      "logits/rejected": -2.538959503173828,
      "logps/chosen": -148.10464477539062,
      "logps/rejected": -46.24601745605469,
      "loss": 0.4464,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3671928644180298,
      "rewards/margins": 0.5757938623428345,
      "rewards/rejected": -0.2086009979248047,
      "step": 329
    },
    {
      "epoch": 0.132,
      "grad_norm": 10.411678314208984,
      "learning_rate": 9.561333333333332e-07,
      "logits/chosen": -2.4503989219665527,
      "logits/rejected": -2.507359504699707,
      "logps/chosen": -82.03646850585938,
      "logps/rejected": -44.783363342285156,
      "loss": 0.5193,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.28093528747558594,
      "rewards/margins": 0.3888433575630188,
      "rewards/rejected": -0.10790806263685226,
      "step": 330
    },
    {
      "epoch": 0.1324,
      "grad_norm": 12.915079116821289,
      "learning_rate": 9.559999999999998e-07,
      "logits/chosen": -2.910338878631592,
      "logits/rejected": -2.3543455600738525,
      "logps/chosen": -75.30183410644531,
      "logps/rejected": -56.438907623291016,
      "loss": 0.4402,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24075832962989807,
      "rewards/margins": 0.59295654296875,
      "rewards/rejected": -0.35219821333885193,
      "step": 331
    },
    {
      "epoch": 0.1328,
      "grad_norm": 11.222806930541992,
      "learning_rate": 9.558666666666666e-07,
      "logits/chosen": -2.8866360187530518,
      "logits/rejected": -2.576742649078369,
      "logps/chosen": -54.66716766357422,
      "logps/rejected": -48.51111602783203,
      "loss": 0.5837,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08385773003101349,
      "rewards/margins": 0.24342060089111328,
      "rewards/rejected": -0.159562885761261,
      "step": 332
    },
    {
      "epoch": 0.1332,
      "grad_norm": 10.09941577911377,
      "learning_rate": 9.557333333333332e-07,
      "logits/chosen": -2.796649932861328,
      "logits/rejected": -2.251561403274536,
      "logps/chosen": -71.37557983398438,
      "logps/rejected": -48.10820770263672,
      "loss": 0.5317,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13990898430347443,
      "rewards/margins": 0.35775434970855713,
      "rewards/rejected": -0.2178453505039215,
      "step": 333
    },
    {
      "epoch": 0.1336,
      "grad_norm": 11.709185600280762,
      "learning_rate": 9.556e-07,
      "logits/chosen": -2.5578160285949707,
      "logits/rejected": -2.2232470512390137,
      "logps/chosen": -87.24746704101562,
      "logps/rejected": -66.82142639160156,
      "loss": 0.5748,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12116280198097229,
      "rewards/margins": 0.25586605072021484,
      "rewards/rejected": -0.13470324873924255,
      "step": 334
    },
    {
      "epoch": 0.134,
      "grad_norm": 11.898077011108398,
      "learning_rate": 9.554666666666666e-07,
      "logits/chosen": -2.7385311126708984,
      "logits/rejected": -2.8369522094726562,
      "logps/chosen": -102.21394348144531,
      "logps/rejected": -34.121864318847656,
      "loss": 0.5107,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2816223204135895,
      "rewards/margins": 0.4085400700569153,
      "rewards/rejected": -0.1269177496433258,
      "step": 335
    },
    {
      "epoch": 0.1344,
      "grad_norm": 11.770340919494629,
      "learning_rate": 9.553333333333334e-07,
      "logits/chosen": -2.913081407546997,
      "logits/rejected": -2.2062034606933594,
      "logps/chosen": -91.413818359375,
      "logps/rejected": -62.82590866088867,
      "loss": 0.4404,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27365607023239136,
      "rewards/margins": 0.5921554565429688,
      "rewards/rejected": -0.3184993863105774,
      "step": 336
    },
    {
      "epoch": 0.1348,
      "grad_norm": 12.445305824279785,
      "learning_rate": 9.552e-07,
      "logits/chosen": -2.560455322265625,
      "logits/rejected": -2.367326498031616,
      "logps/chosen": -149.62417602539062,
      "logps/rejected": -45.7330207824707,
      "loss": 0.5251,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.269461065530777,
      "rewards/margins": 0.37015384435653687,
      "rewards/rejected": -0.1006927564740181,
      "step": 337
    },
    {
      "epoch": 0.1352,
      "grad_norm": 14.065171241760254,
      "learning_rate": 9.550666666666666e-07,
      "logits/chosen": -2.836362361907959,
      "logits/rejected": -2.4691410064697266,
      "logps/chosen": -78.51731872558594,
      "logps/rejected": -68.68856811523438,
      "loss": 0.4564,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2874721586704254,
      "rewards/margins": 0.5536311864852905,
      "rewards/rejected": -0.2661590576171875,
      "step": 338
    },
    {
      "epoch": 0.1356,
      "grad_norm": 10.513916015625,
      "learning_rate": 9.549333333333334e-07,
      "logits/chosen": -2.499610424041748,
      "logits/rejected": -2.204099178314209,
      "logps/chosen": -66.740966796875,
      "logps/rejected": -52.941184997558594,
      "loss": 0.5394,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23801040649414062,
      "rewards/margins": 0.33544790744781494,
      "rewards/rejected": -0.09743747860193253,
      "step": 339
    },
    {
      "epoch": 0.136,
      "grad_norm": 12.48896312713623,
      "learning_rate": 9.548e-07,
      "logits/chosen": -2.9961931705474854,
      "logits/rejected": -3.052536964416504,
      "logps/chosen": -78.35049438476562,
      "logps/rejected": -54.077903747558594,
      "loss": 0.5271,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24654540419578552,
      "rewards/margins": 0.3708093464374542,
      "rewards/rejected": -0.1242639571428299,
      "step": 340
    },
    {
      "epoch": 0.1364,
      "grad_norm": 10.968977928161621,
      "learning_rate": 9.546666666666665e-07,
      "logits/chosen": -2.5606689453125,
      "logits/rejected": -2.4890425205230713,
      "logps/chosen": -114.43965148925781,
      "logps/rejected": -48.58560562133789,
      "loss": 0.4657,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38650551438331604,
      "rewards/margins": 0.5251064300537109,
      "rewards/rejected": -0.1386009156703949,
      "step": 341
    },
    {
      "epoch": 0.1368,
      "grad_norm": 12.858917236328125,
      "learning_rate": 9.545333333333333e-07,
      "logits/chosen": -2.5557193756103516,
      "logits/rejected": -2.558929920196533,
      "logps/chosen": -111.92208099365234,
      "logps/rejected": -62.877288818359375,
      "loss": 0.5104,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24537506699562073,
      "rewards/margins": 0.4071342349052429,
      "rewards/rejected": -0.1617591828107834,
      "step": 342
    },
    {
      "epoch": 0.1372,
      "grad_norm": 12.488982200622559,
      "learning_rate": 9.544e-07,
      "logits/chosen": -2.493851900100708,
      "logits/rejected": -2.2352633476257324,
      "logps/chosen": -106.12617492675781,
      "logps/rejected": -73.96510314941406,
      "loss": 0.4516,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33991050720214844,
      "rewards/margins": 0.5710391998291016,
      "rewards/rejected": -0.23112869262695312,
      "step": 343
    },
    {
      "epoch": 0.1376,
      "grad_norm": 11.9775390625,
      "learning_rate": 9.542666666666667e-07,
      "logits/chosen": -2.7509684562683105,
      "logits/rejected": -2.7483603954315186,
      "logps/chosen": -110.30284881591797,
      "logps/rejected": -59.40380859375,
      "loss": 0.5644,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22580909729003906,
      "rewards/margins": 0.27721816301345825,
      "rewards/rejected": -0.05140905827283859,
      "step": 344
    },
    {
      "epoch": 0.138,
      "grad_norm": 10.822385787963867,
      "learning_rate": 9.541333333333333e-07,
      "logits/chosen": -2.556926727294922,
      "logits/rejected": -2.3116304874420166,
      "logps/chosen": -70.44056701660156,
      "logps/rejected": -60.564422607421875,
      "loss": 0.4966,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27667999267578125,
      "rewards/margins": 0.4423660337924957,
      "rewards/rejected": -0.16568604111671448,
      "step": 345
    },
    {
      "epoch": 0.1384,
      "grad_norm": 11.701420783996582,
      "learning_rate": 9.539999999999999e-07,
      "logits/chosen": -2.3876953125,
      "logits/rejected": -1.9998549222946167,
      "logps/chosen": -102.39129638671875,
      "logps/rejected": -62.268157958984375,
      "loss": 0.5124,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.29911157488822937,
      "rewards/margins": 0.41316720843315125,
      "rewards/rejected": -0.11405563354492188,
      "step": 346
    },
    {
      "epoch": 0.1388,
      "grad_norm": 14.785303115844727,
      "learning_rate": 9.538666666666667e-07,
      "logits/chosen": -2.767218589782715,
      "logits/rejected": -2.39910888671875,
      "logps/chosen": -99.76789855957031,
      "logps/rejected": -105.50625610351562,
      "loss": 0.436,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3430652618408203,
      "rewards/margins": 0.6118900775909424,
      "rewards/rejected": -0.2688247859477997,
      "step": 347
    },
    {
      "epoch": 0.1392,
      "grad_norm": 13.277798652648926,
      "learning_rate": 9.537333333333333e-07,
      "logits/chosen": -2.620966672897339,
      "logits/rejected": -2.1604785919189453,
      "logps/chosen": -48.173614501953125,
      "logps/rejected": -119.27667236328125,
      "loss": 0.5261,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16244134306907654,
      "rewards/margins": 0.3725857734680176,
      "rewards/rejected": -0.21014443039894104,
      "step": 348
    },
    {
      "epoch": 0.1396,
      "grad_norm": 13.118717193603516,
      "learning_rate": 9.536e-07,
      "logits/chosen": -2.361727714538574,
      "logits/rejected": -2.3222012519836426,
      "logps/chosen": -143.0103759765625,
      "logps/rejected": -54.762062072753906,
      "loss": 0.4856,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3940601348876953,
      "rewards/margins": 0.47379419207572937,
      "rewards/rejected": -0.07973404228687286,
      "step": 349
    },
    {
      "epoch": 0.14,
      "grad_norm": 12.305950164794922,
      "learning_rate": 9.534666666666667e-07,
      "logits/chosen": -2.5584497451782227,
      "logits/rejected": -2.1612377166748047,
      "logps/chosen": -109.48782348632812,
      "logps/rejected": -57.859100341796875,
      "loss": 0.4151,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41818007826805115,
      "rewards/margins": 0.6871742010116577,
      "rewards/rejected": -0.26899415254592896,
      "step": 350
    },
    {
      "epoch": 0.1404,
      "grad_norm": 11.604609489440918,
      "learning_rate": 9.533333333333333e-07,
      "logits/chosen": -2.9260787963867188,
      "logits/rejected": -2.952302932739258,
      "logps/chosen": -96.46656799316406,
      "logps/rejected": -56.657188415527344,
      "loss": 0.5934,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11897736042737961,
      "rewards/margins": 0.21424579620361328,
      "rewards/rejected": -0.09526844322681427,
      "step": 351
    },
    {
      "epoch": 0.1408,
      "grad_norm": 10.860391616821289,
      "learning_rate": 9.532e-07,
      "logits/chosen": -2.809479236602783,
      "logits/rejected": -2.2964768409729004,
      "logps/chosen": -41.425140380859375,
      "logps/rejected": -72.64959716796875,
      "loss": 0.5293,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14240723848342896,
      "rewards/margins": 0.3618415892124176,
      "rewards/rejected": -0.21943435072898865,
      "step": 352
    },
    {
      "epoch": 0.1412,
      "grad_norm": 11.775634765625,
      "learning_rate": 9.530666666666666e-07,
      "logits/chosen": -2.5490870475769043,
      "logits/rejected": -2.2176833152770996,
      "logps/chosen": -91.06114196777344,
      "logps/rejected": -60.55158233642578,
      "loss": 0.4886,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.30291634798049927,
      "rewards/margins": 0.4653192460536957,
      "rewards/rejected": -0.1624029129743576,
      "step": 353
    },
    {
      "epoch": 0.1416,
      "grad_norm": 11.381117820739746,
      "learning_rate": 9.529333333333332e-07,
      "logits/chosen": -2.8149914741516113,
      "logits/rejected": -2.6185364723205566,
      "logps/chosen": -88.49345397949219,
      "logps/rejected": -45.69589614868164,
      "loss": 0.5274,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1391771286725998,
      "rewards/margins": 0.36776626110076904,
      "rewards/rejected": -0.22858914732933044,
      "step": 354
    },
    {
      "epoch": 0.142,
      "grad_norm": 11.5503511428833,
      "learning_rate": 9.527999999999999e-07,
      "logits/chosen": -2.690091133117676,
      "logits/rejected": -2.361375093460083,
      "logps/chosen": -125.4832534790039,
      "logps/rejected": -58.805450439453125,
      "loss": 0.4817,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33836138248443604,
      "rewards/margins": 0.48007795214653015,
      "rewards/rejected": -0.14171656966209412,
      "step": 355
    },
    {
      "epoch": 0.1424,
      "grad_norm": 13.929154396057129,
      "learning_rate": 9.526666666666666e-07,
      "logits/chosen": -2.589397430419922,
      "logits/rejected": -2.258889675140381,
      "logps/chosen": -87.20171356201172,
      "logps/rejected": -68.17509460449219,
      "loss": 0.5871,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03711071237921715,
      "rewards/margins": 0.23093223571777344,
      "rewards/rejected": -0.193821519613266,
      "step": 356
    },
    {
      "epoch": 0.1428,
      "grad_norm": 12.588820457458496,
      "learning_rate": 9.525333333333333e-07,
      "logits/chosen": -2.2829766273498535,
      "logits/rejected": -2.2668333053588867,
      "logps/chosen": -108.96803283691406,
      "logps/rejected": -96.94419860839844,
      "loss": 0.4596,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3312217891216278,
      "rewards/margins": 0.5394207239151001,
      "rewards/rejected": -0.2081989347934723,
      "step": 357
    },
    {
      "epoch": 0.1432,
      "grad_norm": 11.45262336730957,
      "learning_rate": 9.524e-07,
      "logits/chosen": -2.5971779823303223,
      "logits/rejected": -2.235278844833374,
      "logps/chosen": -62.25602722167969,
      "logps/rejected": -63.88861083984375,
      "loss": 0.5121,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21723231673240662,
      "rewards/margins": 0.4051893353462219,
      "rewards/rejected": -0.1879570037126541,
      "step": 358
    },
    {
      "epoch": 0.1436,
      "grad_norm": 11.698102951049805,
      "learning_rate": 9.522666666666667e-07,
      "logits/chosen": -2.7651219367980957,
      "logits/rejected": -2.1183102130889893,
      "logps/chosen": -69.30797576904297,
      "logps/rejected": -66.23841857910156,
      "loss": 0.4965,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2888733148574829,
      "rewards/margins": 0.4462154507637024,
      "rewards/rejected": -0.15734215080738068,
      "step": 359
    },
    {
      "epoch": 0.144,
      "grad_norm": 9.2863187789917,
      "learning_rate": 9.521333333333334e-07,
      "logits/chosen": -2.6911067962646484,
      "logits/rejected": -2.2877116203308105,
      "logps/chosen": -68.1795654296875,
      "logps/rejected": -46.03217697143555,
      "loss": 0.5454,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14908751845359802,
      "rewards/margins": 0.332559198141098,
      "rewards/rejected": -0.1834716796875,
      "step": 360
    },
    {
      "epoch": 0.1444,
      "grad_norm": 13.197746276855469,
      "learning_rate": 9.52e-07,
      "logits/chosen": -2.43359375,
      "logits/rejected": -2.156251907348633,
      "logps/chosen": -92.13194274902344,
      "logps/rejected": -76.54979705810547,
      "loss": 0.4749,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3464580774307251,
      "rewards/margins": 0.5060535669326782,
      "rewards/rejected": -0.15959550440311432,
      "step": 361
    },
    {
      "epoch": 0.1448,
      "grad_norm": 16.6657657623291,
      "learning_rate": 9.518666666666666e-07,
      "logits/chosen": -2.4774694442749023,
      "logits/rejected": -2.2397074699401855,
      "logps/chosen": -119.45140838623047,
      "logps/rejected": -70.94500732421875,
      "loss": 0.4358,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35219040513038635,
      "rewards/margins": 0.606468915939331,
      "rewards/rejected": -0.2542785704135895,
      "step": 362
    },
    {
      "epoch": 0.1452,
      "grad_norm": 9.138751029968262,
      "learning_rate": 9.517333333333332e-07,
      "logits/chosen": -2.663532018661499,
      "logits/rejected": -2.5293498039245605,
      "logps/chosen": -58.75925064086914,
      "logps/rejected": -41.68218994140625,
      "loss": 0.4921,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2469472885131836,
      "rewards/margins": 0.4532146453857422,
      "rewards/rejected": -0.2062673568725586,
      "step": 363
    },
    {
      "epoch": 0.1456,
      "grad_norm": 13.39319133758545,
      "learning_rate": 9.515999999999999e-07,
      "logits/chosen": -2.2713279724121094,
      "logits/rejected": -2.1878368854522705,
      "logps/chosen": -121.51321411132812,
      "logps/rejected": -76.95919799804688,
      "loss": 0.4835,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35600167512893677,
      "rewards/margins": 0.47915706038475037,
      "rewards/rejected": -0.12315540015697479,
      "step": 364
    },
    {
      "epoch": 0.146,
      "grad_norm": 10.811914443969727,
      "learning_rate": 9.514666666666666e-07,
      "logits/chosen": -2.5967350006103516,
      "logits/rejected": -2.5094523429870605,
      "logps/chosen": -100.31575012207031,
      "logps/rejected": -51.52782440185547,
      "loss": 0.4595,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32792776823043823,
      "rewards/margins": 0.5391533374786377,
      "rewards/rejected": -0.2112255096435547,
      "step": 365
    },
    {
      "epoch": 0.1464,
      "grad_norm": 9.04461669921875,
      "learning_rate": 9.513333333333333e-07,
      "logits/chosen": -2.820634126663208,
      "logits/rejected": -2.6611156463623047,
      "logps/chosen": -70.61571502685547,
      "logps/rejected": -40.62641525268555,
      "loss": 0.4894,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4200769364833832,
      "rewards/margins": 0.4719334840774536,
      "rewards/rejected": -0.05185651779174805,
      "step": 366
    },
    {
      "epoch": 0.1468,
      "grad_norm": 11.827460289001465,
      "learning_rate": 9.512e-07,
      "logits/chosen": -2.666222333908081,
      "logits/rejected": -2.716580867767334,
      "logps/chosen": -93.2198486328125,
      "logps/rejected": -65.8377456665039,
      "loss": 0.5087,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34169501066207886,
      "rewards/margins": 0.412623792886734,
      "rewards/rejected": -0.07092876732349396,
      "step": 367
    },
    {
      "epoch": 0.1472,
      "grad_norm": 10.450895309448242,
      "learning_rate": 9.510666666666666e-07,
      "logits/chosen": -2.575901508331299,
      "logits/rejected": -2.0299177169799805,
      "logps/chosen": -99.52245330810547,
      "logps/rejected": -79.03073120117188,
      "loss": 0.4501,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3859228193759918,
      "rewards/margins": 0.5797256231307983,
      "rewards/rejected": -0.1938028335571289,
      "step": 368
    },
    {
      "epoch": 0.1476,
      "grad_norm": 10.960719108581543,
      "learning_rate": 9.509333333333333e-07,
      "logits/chosen": -2.425877571105957,
      "logits/rejected": -2.178370952606201,
      "logps/chosen": -93.39266967773438,
      "logps/rejected": -55.726593017578125,
      "loss": 0.4596,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4115825891494751,
      "rewards/margins": 0.5473724603652954,
      "rewards/rejected": -0.1357898712158203,
      "step": 369
    },
    {
      "epoch": 0.148,
      "grad_norm": 13.27357006072998,
      "learning_rate": 9.508e-07,
      "logits/chosen": -2.5878612995147705,
      "logits/rejected": -2.4414429664611816,
      "logps/chosen": -114.25399017333984,
      "logps/rejected": -71.6649169921875,
      "loss": 0.5487,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3727523684501648,
      "rewards/margins": 0.33136558532714844,
      "rewards/rejected": 0.04138679802417755,
      "step": 370
    },
    {
      "epoch": 0.1484,
      "grad_norm": 11.157121658325195,
      "learning_rate": 9.506666666666667e-07,
      "logits/chosen": -2.87400484085083,
      "logits/rejected": -2.721625804901123,
      "logps/chosen": -67.7372817993164,
      "logps/rejected": -75.16002655029297,
      "loss": 0.4802,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.275861918926239,
      "rewards/margins": 0.4874458611011505,
      "rewards/rejected": -0.2115839123725891,
      "step": 371
    },
    {
      "epoch": 0.1488,
      "grad_norm": 9.846426963806152,
      "learning_rate": 9.505333333333333e-07,
      "logits/chosen": -2.5965018272399902,
      "logits/rejected": -2.375580310821533,
      "logps/chosen": -94.99703979492188,
      "logps/rejected": -40.08720397949219,
      "loss": 0.4726,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2694961726665497,
      "rewards/margins": 0.5076263546943665,
      "rewards/rejected": -0.23813018202781677,
      "step": 372
    },
    {
      "epoch": 0.1492,
      "grad_norm": 9.572616577148438,
      "learning_rate": 9.503999999999999e-07,
      "logits/chosen": -2.4367756843566895,
      "logits/rejected": -2.07260799407959,
      "logps/chosen": -89.47264099121094,
      "logps/rejected": -65.69279479980469,
      "loss": 0.4592,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4168228209018707,
      "rewards/margins": 0.5531852841377258,
      "rewards/rejected": -0.1363624632358551,
      "step": 373
    },
    {
      "epoch": 0.1496,
      "grad_norm": 11.693493843078613,
      "learning_rate": 9.502666666666666e-07,
      "logits/chosen": -2.538245677947998,
      "logits/rejected": -2.2447590827941895,
      "logps/chosen": -127.95808410644531,
      "logps/rejected": -66.33396911621094,
      "loss": 0.4235,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5073738098144531,
      "rewards/margins": 0.6533365249633789,
      "rewards/rejected": -0.14596271514892578,
      "step": 374
    },
    {
      "epoch": 0.15,
      "grad_norm": 13.121618270874023,
      "learning_rate": 9.501333333333333e-07,
      "logits/chosen": -2.430488109588623,
      "logits/rejected": -2.001922130584717,
      "logps/chosen": -148.21080017089844,
      "logps/rejected": -77.45086669921875,
      "loss": 0.463,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3312036693096161,
      "rewards/margins": 0.5483282208442688,
      "rewards/rejected": -0.2171245664358139,
      "step": 375
    },
    {
      "epoch": 0.1504,
      "grad_norm": 9.944884300231934,
      "learning_rate": 9.499999999999999e-07,
      "logits/chosen": -2.7913641929626465,
      "logits/rejected": -2.813479423522949,
      "logps/chosen": -60.06739044189453,
      "logps/rejected": -45.689300537109375,
      "loss": 0.5552,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14377327263355255,
      "rewards/margins": 0.29873839020729065,
      "rewards/rejected": -0.1549651175737381,
      "step": 376
    },
    {
      "epoch": 0.1508,
      "grad_norm": 13.364622116088867,
      "learning_rate": 9.498666666666666e-07,
      "logits/chosen": -2.195812463760376,
      "logits/rejected": -1.9889225959777832,
      "logps/chosen": -203.35617065429688,
      "logps/rejected": -70.87503051757812,
      "loss": 0.3968,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6210983395576477,
      "rewards/margins": 0.720205545425415,
      "rewards/rejected": -0.09910717606544495,
      "step": 377
    },
    {
      "epoch": 0.1512,
      "grad_norm": 12.382373809814453,
      "learning_rate": 9.497333333333333e-07,
      "logits/chosen": -2.3840556144714355,
      "logits/rejected": -2.0555810928344727,
      "logps/chosen": -123.6588363647461,
      "logps/rejected": -67.45201873779297,
      "loss": 0.4043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.397433876991272,
      "rewards/margins": 0.698538064956665,
      "rewards/rejected": -0.3011041581630707,
      "step": 378
    },
    {
      "epoch": 0.1516,
      "grad_norm": 11.953441619873047,
      "learning_rate": 9.496e-07,
      "logits/chosen": -2.65299129486084,
      "logits/rejected": -2.7655227184295654,
      "logps/chosen": -66.03634643554688,
      "logps/rejected": -50.9068603515625,
      "loss": 0.4883,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2984781265258789,
      "rewards/margins": 0.46283721923828125,
      "rewards/rejected": -0.16435909271240234,
      "step": 379
    },
    {
      "epoch": 0.152,
      "grad_norm": 11.031218528747559,
      "learning_rate": 9.494666666666667e-07,
      "logits/chosen": -2.8607397079467773,
      "logits/rejected": -2.422365188598633,
      "logps/chosen": -77.03369903564453,
      "logps/rejected": -37.60133361816406,
      "loss": 0.5056,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1905849426984787,
      "rewards/margins": 0.4187345504760742,
      "rewards/rejected": -0.22814959287643433,
      "step": 380
    },
    {
      "epoch": 0.1524,
      "grad_norm": 14.680341720581055,
      "learning_rate": 9.493333333333334e-07,
      "logits/chosen": -2.557929515838623,
      "logits/rejected": -2.313784122467041,
      "logps/chosen": -106.06512451171875,
      "logps/rejected": -77.37745666503906,
      "loss": 0.4546,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38597071170806885,
      "rewards/margins": 0.5590492486953735,
      "rewards/rejected": -0.1730785369873047,
      "step": 381
    },
    {
      "epoch": 0.1528,
      "grad_norm": 14.094982147216797,
      "learning_rate": 9.492e-07,
      "logits/chosen": -2.9827733039855957,
      "logits/rejected": -2.2838642597198486,
      "logps/chosen": -82.55613708496094,
      "logps/rejected": -68.6740493774414,
      "loss": 0.362,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3147178888320923,
      "rewards/margins": 0.8509741425514221,
      "rewards/rejected": -0.5362562537193298,
      "step": 382
    },
    {
      "epoch": 0.1532,
      "grad_norm": 14.41236686706543,
      "learning_rate": 9.490666666666665e-07,
      "logits/chosen": -2.313260555267334,
      "logits/rejected": -2.2165377140045166,
      "logps/chosen": -88.97238159179688,
      "logps/rejected": -100.78238677978516,
      "loss": 0.4833,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3411228060722351,
      "rewards/margins": 0.47616997361183167,
      "rewards/rejected": -0.13504715263843536,
      "step": 383
    },
    {
      "epoch": 0.1536,
      "grad_norm": 15.373909950256348,
      "learning_rate": 9.489333333333332e-07,
      "logits/chosen": -2.6518077850341797,
      "logits/rejected": -2.542996406555176,
      "logps/chosen": -133.0311737060547,
      "logps/rejected": -47.94816589355469,
      "loss": 0.5997,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.08400116860866547,
      "rewards/margins": 0.24773167073726654,
      "rewards/rejected": -0.3317328691482544,
      "step": 384
    },
    {
      "epoch": 0.154,
      "grad_norm": 10.689920425415039,
      "learning_rate": 9.487999999999999e-07,
      "logits/chosen": -2.783719539642334,
      "logits/rejected": -2.5031352043151855,
      "logps/chosen": -114.56718444824219,
      "logps/rejected": -57.899497985839844,
      "loss": 0.4853,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23664703965187073,
      "rewards/margins": 0.47279930114746094,
      "rewards/rejected": -0.2361522763967514,
      "step": 385
    },
    {
      "epoch": 0.1544,
      "grad_norm": 10.036539077758789,
      "learning_rate": 9.486666666666666e-07,
      "logits/chosen": -2.526002883911133,
      "logits/rejected": -2.617183208465576,
      "logps/chosen": -116.58806610107422,
      "logps/rejected": -53.87675857543945,
      "loss": 0.4399,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5089744925498962,
      "rewards/margins": 0.6056400537490845,
      "rewards/rejected": -0.09666557610034943,
      "step": 386
    },
    {
      "epoch": 0.1548,
      "grad_norm": 11.147202491760254,
      "learning_rate": 9.485333333333333e-07,
      "logits/chosen": -2.347318172454834,
      "logits/rejected": -2.3297882080078125,
      "logps/chosen": -144.61048889160156,
      "logps/rejected": -72.87461853027344,
      "loss": 0.4157,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4491539001464844,
      "rewards/margins": 0.6698774099349976,
      "rewards/rejected": -0.22072353959083557,
      "step": 387
    },
    {
      "epoch": 0.1552,
      "grad_norm": 12.678930282592773,
      "learning_rate": 9.484e-07,
      "logits/chosen": -2.317183494567871,
      "logits/rejected": -1.916165828704834,
      "logps/chosen": -130.98367309570312,
      "logps/rejected": -64.16828918457031,
      "loss": 0.4673,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3371315002441406,
      "rewards/margins": 0.5180925726890564,
      "rewards/rejected": -0.18096104264259338,
      "step": 388
    },
    {
      "epoch": 0.1556,
      "grad_norm": 11.817368507385254,
      "learning_rate": 9.482666666666667e-07,
      "logits/chosen": -2.5501487255096436,
      "logits/rejected": -2.329310178756714,
      "logps/chosen": -100.40470123291016,
      "logps/rejected": -72.80441284179688,
      "loss": 0.5279,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24753856658935547,
      "rewards/margins": 0.3675161600112915,
      "rewards/rejected": -0.11997757852077484,
      "step": 389
    },
    {
      "epoch": 0.156,
      "grad_norm": 12.801011085510254,
      "learning_rate": 9.481333333333334e-07,
      "logits/chosen": -2.748366117477417,
      "logits/rejected": -2.7095577716827393,
      "logps/chosen": -66.06402587890625,
      "logps/rejected": -60.29848861694336,
      "loss": 0.4107,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1990985870361328,
      "rewards/margins": 0.6803855895996094,
      "rewards/rejected": -0.48128700256347656,
      "step": 390
    },
    {
      "epoch": 0.1564,
      "grad_norm": 12.091092109680176,
      "learning_rate": 9.479999999999999e-07,
      "logits/chosen": -2.4424288272857666,
      "logits/rejected": -2.328701972961426,
      "logps/chosen": -129.4951934814453,
      "logps/rejected": -87.84547424316406,
      "loss": 0.4203,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4549823999404907,
      "rewards/margins": 0.6507202386856079,
      "rewards/rejected": -0.1957378387451172,
      "step": 391
    },
    {
      "epoch": 0.1568,
      "grad_norm": 14.061968803405762,
      "learning_rate": 9.478666666666666e-07,
      "logits/chosen": -2.3443117141723633,
      "logits/rejected": -2.217369794845581,
      "logps/chosen": -116.78822326660156,
      "logps/rejected": -94.2457275390625,
      "loss": 0.4178,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.26027166843414307,
      "rewards/margins": 0.6573415994644165,
      "rewards/rejected": -0.39706993103027344,
      "step": 392
    },
    {
      "epoch": 0.1572,
      "grad_norm": 11.305595397949219,
      "learning_rate": 9.477333333333332e-07,
      "logits/chosen": -2.7081010341644287,
      "logits/rejected": -2.661410331726074,
      "logps/chosen": -82.92250061035156,
      "logps/rejected": -83.18917846679688,
      "loss": 0.4432,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.36446189880371094,
      "rewards/margins": 0.5887096524238586,
      "rewards/rejected": -0.2242477387189865,
      "step": 393
    },
    {
      "epoch": 0.1576,
      "grad_norm": 10.014634132385254,
      "learning_rate": 9.475999999999999e-07,
      "logits/chosen": -2.8331332206726074,
      "logits/rejected": -2.5874195098876953,
      "logps/chosen": -59.576683044433594,
      "logps/rejected": -31.443405151367188,
      "loss": 0.5101,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2291475385427475,
      "rewards/margins": 0.4200214743614197,
      "rewards/rejected": -0.190873920917511,
      "step": 394
    },
    {
      "epoch": 0.158,
      "grad_norm": 10.5621976852417,
      "learning_rate": 9.474666666666666e-07,
      "logits/chosen": -2.7389330863952637,
      "logits/rejected": -2.125974178314209,
      "logps/chosen": -60.20096969604492,
      "logps/rejected": -56.59432601928711,
      "loss": 0.4728,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24530410766601562,
      "rewards/margins": 0.5034719705581665,
      "rewards/rejected": -0.2581678628921509,
      "step": 395
    },
    {
      "epoch": 0.1584,
      "grad_norm": 19.264875411987305,
      "learning_rate": 9.473333333333333e-07,
      "logits/chosen": -2.0441646575927734,
      "logits/rejected": -2.0209970474243164,
      "logps/chosen": -249.37982177734375,
      "logps/rejected": -100.53041076660156,
      "loss": 0.5051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27841490507125854,
      "rewards/margins": 0.4206504821777344,
      "rewards/rejected": -0.14223557710647583,
      "step": 396
    },
    {
      "epoch": 0.1588,
      "grad_norm": 9.41226577758789,
      "learning_rate": 9.472e-07,
      "logits/chosen": -2.927553653717041,
      "logits/rejected": -2.7529191970825195,
      "logps/chosen": -54.341064453125,
      "logps/rejected": -43.825721740722656,
      "loss": 0.5196,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15153932571411133,
      "rewards/margins": 0.3837265968322754,
      "rewards/rejected": -0.23218727111816406,
      "step": 397
    },
    {
      "epoch": 0.1592,
      "grad_norm": 11.718954086303711,
      "learning_rate": 9.470666666666666e-07,
      "logits/chosen": -2.6212596893310547,
      "logits/rejected": -2.1240034103393555,
      "logps/chosen": -70.97877502441406,
      "logps/rejected": -68.27301025390625,
      "loss": 0.4658,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23931579291820526,
      "rewards/margins": 0.5318643450737,
      "rewards/rejected": -0.2925485670566559,
      "step": 398
    },
    {
      "epoch": 0.1596,
      "grad_norm": 11.890606880187988,
      "learning_rate": 9.469333333333333e-07,
      "logits/chosen": -2.576115131378174,
      "logits/rejected": -2.360321521759033,
      "logps/chosen": -64.46758270263672,
      "logps/rejected": -61.878746032714844,
      "loss": 0.5167,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21107864379882812,
      "rewards/margins": 0.3948707580566406,
      "rewards/rejected": -0.1837921142578125,
      "step": 399
    },
    {
      "epoch": 0.16,
      "grad_norm": 11.94234848022461,
      "learning_rate": 9.468e-07,
      "logits/chosen": -2.301283359527588,
      "logits/rejected": -2.0752758979797363,
      "logps/chosen": -127.92318725585938,
      "logps/rejected": -113.8924331665039,
      "loss": 0.4105,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5106277465820312,
      "rewards/margins": 0.678666353225708,
      "rewards/rejected": -0.16803856194019318,
      "step": 400
    },
    {
      "epoch": 0.1604,
      "grad_norm": 13.785746574401855,
      "learning_rate": 9.466666666666666e-07,
      "logits/chosen": -2.7201175689697266,
      "logits/rejected": -2.165621519088745,
      "logps/chosen": -97.59334564208984,
      "logps/rejected": -87.33570861816406,
      "loss": 0.446,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2627986967563629,
      "rewards/margins": 0.5784237384796143,
      "rewards/rejected": -0.31562501192092896,
      "step": 401
    },
    {
      "epoch": 0.1608,
      "grad_norm": 12.790135383605957,
      "learning_rate": 9.465333333333333e-07,
      "logits/chosen": -2.317722797393799,
      "logits/rejected": -2.0822579860687256,
      "logps/chosen": -132.3009033203125,
      "logps/rejected": -118.7957992553711,
      "loss": 0.3657,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5302276611328125,
      "rewards/margins": 0.8477458953857422,
      "rewards/rejected": -0.3175182342529297,
      "step": 402
    },
    {
      "epoch": 0.1612,
      "grad_norm": 13.253135681152344,
      "learning_rate": 9.464e-07,
      "logits/chosen": -2.6454296112060547,
      "logits/rejected": -2.7764806747436523,
      "logps/chosen": -134.15386962890625,
      "logps/rejected": -54.279632568359375,
      "loss": 0.5697,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2812679409980774,
      "rewards/margins": 0.2661420702934265,
      "rewards/rejected": 0.015125846490263939,
      "step": 403
    },
    {
      "epoch": 0.1616,
      "grad_norm": 11.043745994567871,
      "learning_rate": 9.462666666666666e-07,
      "logits/chosen": -2.8753581047058105,
      "logits/rejected": -2.4998226165771484,
      "logps/chosen": -67.12727355957031,
      "logps/rejected": -66.30949401855469,
      "loss": 0.5008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.26478731632232666,
      "rewards/margins": 0.4526599943637848,
      "rewards/rejected": -0.18787269294261932,
      "step": 404
    },
    {
      "epoch": 0.162,
      "grad_norm": 11.212841033935547,
      "learning_rate": 9.461333333333333e-07,
      "logits/chosen": -2.826277256011963,
      "logits/rejected": -2.127139091491699,
      "logps/chosen": -53.95005416870117,
      "logps/rejected": -67.57255554199219,
      "loss": 0.4656,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22044888138771057,
      "rewards/margins": 0.5238374471664429,
      "rewards/rejected": -0.3033885955810547,
      "step": 405
    },
    {
      "epoch": 0.1624,
      "grad_norm": 9.208495140075684,
      "learning_rate": 9.459999999999999e-07,
      "logits/chosen": -2.8525161743164062,
      "logits/rejected": -2.6437416076660156,
      "logps/chosen": -69.62942504882812,
      "logps/rejected": -40.907535552978516,
      "loss": 0.4583,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3320270776748657,
      "rewards/margins": 0.543069064617157,
      "rewards/rejected": -0.21104203164577484,
      "step": 406
    },
    {
      "epoch": 0.1628,
      "grad_norm": 10.510032653808594,
      "learning_rate": 9.458666666666666e-07,
      "logits/chosen": -2.489717721939087,
      "logits/rejected": -2.165884494781494,
      "logps/chosen": -86.05818176269531,
      "logps/rejected": -39.33564758300781,
      "loss": 0.4588,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3193977475166321,
      "rewards/margins": 0.5467113852500916,
      "rewards/rejected": -0.22731362283229828,
      "step": 407
    },
    {
      "epoch": 0.1632,
      "grad_norm": 12.41373348236084,
      "learning_rate": 9.457333333333333e-07,
      "logits/chosen": -2.692309856414795,
      "logits/rejected": -2.046342611312866,
      "logps/chosen": -60.20420837402344,
      "logps/rejected": -75.15599060058594,
      "loss": 0.4143,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2760845124721527,
      "rewards/margins": 0.677463948726654,
      "rewards/rejected": -0.40137940645217896,
      "step": 408
    },
    {
      "epoch": 0.1636,
      "grad_norm": 9.43962287902832,
      "learning_rate": 9.456e-07,
      "logits/chosen": -2.596247673034668,
      "logits/rejected": -2.2695064544677734,
      "logps/chosen": -85.72418212890625,
      "logps/rejected": -88.97412109375,
      "loss": 0.417,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4916214346885681,
      "rewards/margins": 0.6973102688789368,
      "rewards/rejected": -0.20568886399269104,
      "step": 409
    },
    {
      "epoch": 0.164,
      "grad_norm": 13.101197242736816,
      "learning_rate": 9.454666666666666e-07,
      "logits/chosen": -2.5275774002075195,
      "logits/rejected": -2.2506637573242188,
      "logps/chosen": -88.50439453125,
      "logps/rejected": -79.31001281738281,
      "loss": 0.4499,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3294185698032379,
      "rewards/margins": 0.5681614279747009,
      "rewards/rejected": -0.23874282836914062,
      "step": 410
    },
    {
      "epoch": 0.1644,
      "grad_norm": 12.293061256408691,
      "learning_rate": 9.453333333333333e-07,
      "logits/chosen": -2.491377115249634,
      "logits/rejected": -2.303380250930786,
      "logps/chosen": -245.47581481933594,
      "logps/rejected": -66.03341674804688,
      "loss": 0.3859,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5095748901367188,
      "rewards/margins": 0.7592430114746094,
      "rewards/rejected": -0.24966812133789062,
      "step": 411
    },
    {
      "epoch": 0.1648,
      "grad_norm": 9.803495407104492,
      "learning_rate": 9.452e-07,
      "logits/chosen": -2.68691086769104,
      "logits/rejected": -2.2528488636016846,
      "logps/chosen": -76.92678833007812,
      "logps/rejected": -72.48580932617188,
      "loss": 0.4768,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.43302613496780396,
      "rewards/margins": 0.5291416645050049,
      "rewards/rejected": -0.09611549228429794,
      "step": 412
    },
    {
      "epoch": 0.1652,
      "grad_norm": 11.623213768005371,
      "learning_rate": 9.450666666666667e-07,
      "logits/chosen": -2.691324234008789,
      "logits/rejected": -2.4868640899658203,
      "logps/chosen": -103.14354705810547,
      "logps/rejected": -71.56719207763672,
      "loss": 0.4937,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.36167681217193604,
      "rewards/margins": 0.44920235872268677,
      "rewards/rejected": -0.08752556145191193,
      "step": 413
    },
    {
      "epoch": 0.1656,
      "grad_norm": 12.306676864624023,
      "learning_rate": 9.449333333333332e-07,
      "logits/chosen": -2.484241485595703,
      "logits/rejected": -2.2851908206939697,
      "logps/chosen": -121.92679595947266,
      "logps/rejected": -82.54127502441406,
      "loss": 0.4216,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4269554316997528,
      "rewards/margins": 0.6469913721084595,
      "rewards/rejected": -0.22003594040870667,
      "step": 414
    },
    {
      "epoch": 0.166,
      "grad_norm": 12.18359661102295,
      "learning_rate": 9.447999999999999e-07,
      "logits/chosen": -2.5224263668060303,
      "logits/rejected": -2.1810553073883057,
      "logps/chosen": -71.38673400878906,
      "logps/rejected": -93.32173919677734,
      "loss": 0.4737,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.28898489475250244,
      "rewards/margins": 0.5126078128814697,
      "rewards/rejected": -0.2236228883266449,
      "step": 415
    },
    {
      "epoch": 0.1664,
      "grad_norm": 10.084586143493652,
      "learning_rate": 9.446666666666666e-07,
      "logits/chosen": -2.9795188903808594,
      "logits/rejected": -2.6978869438171387,
      "logps/chosen": -73.3886489868164,
      "logps/rejected": -48.51744079589844,
      "loss": 0.4792,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27365991473197937,
      "rewards/margins": 0.4915662705898285,
      "rewards/rejected": -0.2179063856601715,
      "step": 416
    },
    {
      "epoch": 0.1668,
      "grad_norm": 9.926565170288086,
      "learning_rate": 9.445333333333333e-07,
      "logits/chosen": -2.2346553802490234,
      "logits/rejected": -1.9912216663360596,
      "logps/chosen": -122.16044616699219,
      "logps/rejected": -62.81227111816406,
      "loss": 0.3762,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6503047943115234,
      "rewards/margins": 0.7892223596572876,
      "rewards/rejected": -0.13891753554344177,
      "step": 417
    },
    {
      "epoch": 0.1672,
      "grad_norm": 11.269229888916016,
      "learning_rate": 9.444e-07,
      "logits/chosen": -2.7021265029907227,
      "logits/rejected": -2.759765148162842,
      "logps/chosen": -92.24153137207031,
      "logps/rejected": -51.71355438232422,
      "loss": 0.4575,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31196328997612,
      "rewards/margins": 0.5500635504722595,
      "rewards/rejected": -0.23810023069381714,
      "step": 418
    },
    {
      "epoch": 0.1676,
      "grad_norm": 16.14551544189453,
      "learning_rate": 9.442666666666667e-07,
      "logits/chosen": -2.506646156311035,
      "logits/rejected": -2.930591583251953,
      "logps/chosen": -137.9302978515625,
      "logps/rejected": -57.62528991699219,
      "loss": 0.5143,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3176826536655426,
      "rewards/margins": 0.39695319533348083,
      "rewards/rejected": -0.07927055656909943,
      "step": 419
    },
    {
      "epoch": 0.168,
      "grad_norm": 12.195672035217285,
      "learning_rate": 9.441333333333333e-07,
      "logits/chosen": -2.616513252258301,
      "logits/rejected": -2.251098394393921,
      "logps/chosen": -79.56171417236328,
      "logps/rejected": -70.03626251220703,
      "loss": 0.4474,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38036805391311646,
      "rewards/margins": 0.582105278968811,
      "rewards/rejected": -0.20173722505569458,
      "step": 420
    },
    {
      "epoch": 0.1684,
      "grad_norm": 11.608572959899902,
      "learning_rate": 9.439999999999999e-07,
      "logits/chosen": -2.886786937713623,
      "logits/rejected": -2.5335030555725098,
      "logps/chosen": -77.90668487548828,
      "logps/rejected": -66.12754821777344,
      "loss": 0.412,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3852512538433075,
      "rewards/margins": 0.6945667266845703,
      "rewards/rejected": -0.3093155026435852,
      "step": 421
    },
    {
      "epoch": 0.1688,
      "grad_norm": 9.983085632324219,
      "learning_rate": 9.438666666666666e-07,
      "logits/chosen": -2.7691030502319336,
      "logits/rejected": -2.5020956993103027,
      "logps/chosen": -56.31232452392578,
      "logps/rejected": -55.81193923950195,
      "loss": 0.4543,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.36482277512550354,
      "rewards/margins": 0.5642693042755127,
      "rewards/rejected": -0.19944649934768677,
      "step": 422
    },
    {
      "epoch": 0.1692,
      "grad_norm": 10.354126930236816,
      "learning_rate": 9.437333333333333e-07,
      "logits/chosen": -2.733017921447754,
      "logits/rejected": -2.2196974754333496,
      "logps/chosen": -78.25045013427734,
      "logps/rejected": -56.92967987060547,
      "loss": 0.4853,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3079080581665039,
      "rewards/margins": 0.48061487078666687,
      "rewards/rejected": -0.17270679771900177,
      "step": 423
    },
    {
      "epoch": 0.1696,
      "grad_norm": 11.242383003234863,
      "learning_rate": 9.436e-07,
      "logits/chosen": -2.521798610687256,
      "logits/rejected": -2.281967878341675,
      "logps/chosen": -105.51783752441406,
      "logps/rejected": -86.1606674194336,
      "loss": 0.3704,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4950149655342102,
      "rewards/margins": 0.8094223141670227,
      "rewards/rejected": -0.3144073486328125,
      "step": 424
    },
    {
      "epoch": 0.17,
      "grad_norm": 13.128708839416504,
      "learning_rate": 9.434666666666666e-07,
      "logits/chosen": -2.5369129180908203,
      "logits/rejected": -2.208995819091797,
      "logps/chosen": -78.9636459350586,
      "logps/rejected": -78.679443359375,
      "loss": 0.4151,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31142711639404297,
      "rewards/margins": 0.670292854309082,
      "rewards/rejected": -0.35886576771736145,
      "step": 425
    },
    {
      "epoch": 0.1704,
      "grad_norm": 9.740254402160645,
      "learning_rate": 9.433333333333333e-07,
      "logits/chosen": -2.843966007232666,
      "logits/rejected": -2.4439425468444824,
      "logps/chosen": -84.78956604003906,
      "logps/rejected": -40.22919464111328,
      "loss": 0.4611,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42821618914604187,
      "rewards/margins": 0.5354545712471008,
      "rewards/rejected": -0.10723838955163956,
      "step": 426
    },
    {
      "epoch": 0.1708,
      "grad_norm": 9.945785522460938,
      "learning_rate": 9.432e-07,
      "logits/chosen": -2.6696057319641113,
      "logits/rejected": -2.4801523685455322,
      "logps/chosen": -86.64676666259766,
      "logps/rejected": -55.443702697753906,
      "loss": 0.3858,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6204884052276611,
      "rewards/margins": 0.7591915130615234,
      "rewards/rejected": -0.1387031525373459,
      "step": 427
    },
    {
      "epoch": 0.1712,
      "grad_norm": 9.401264190673828,
      "learning_rate": 9.430666666666667e-07,
      "logits/chosen": -2.5986523628234863,
      "logits/rejected": -2.316436767578125,
      "logps/chosen": -93.53523254394531,
      "logps/rejected": -56.58401870727539,
      "loss": 0.4344,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38328972458839417,
      "rewards/margins": 0.6188669204711914,
      "rewards/rejected": -0.23557721078395844,
      "step": 428
    },
    {
      "epoch": 0.1716,
      "grad_norm": 10.348057746887207,
      "learning_rate": 9.429333333333332e-07,
      "logits/chosen": -2.524691104888916,
      "logits/rejected": -2.1946089267730713,
      "logps/chosen": -81.68675231933594,
      "logps/rejected": -72.06400299072266,
      "loss": 0.4946,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2693571150302887,
      "rewards/margins": 0.4496181607246399,
      "rewards/rejected": -0.1802610456943512,
      "step": 429
    },
    {
      "epoch": 0.172,
      "grad_norm": 9.73289966583252,
      "learning_rate": 9.427999999999999e-07,
      "logits/chosen": -2.9023895263671875,
      "logits/rejected": -2.558760643005371,
      "logps/chosen": -84.24563598632812,
      "logps/rejected": -55.933448791503906,
      "loss": 0.4692,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22261545062065125,
      "rewards/margins": 0.5266891717910767,
      "rewards/rejected": -0.3040737211704254,
      "step": 430
    },
    {
      "epoch": 0.1724,
      "grad_norm": 13.577191352844238,
      "learning_rate": 9.426666666666666e-07,
      "logits/chosen": -2.5502638816833496,
      "logits/rejected": -2.1964528560638428,
      "logps/chosen": -101.61062622070312,
      "logps/rejected": -72.0287857055664,
      "loss": 0.4563,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18786010146141052,
      "rewards/margins": 0.5507259368896484,
      "rewards/rejected": -0.3628658354282379,
      "step": 431
    },
    {
      "epoch": 0.1728,
      "grad_norm": 10.475605964660645,
      "learning_rate": 9.425333333333333e-07,
      "logits/chosen": -2.8347768783569336,
      "logits/rejected": -2.7194900512695312,
      "logps/chosen": -101.12904357910156,
      "logps/rejected": -60.3715934753418,
      "loss": 0.5455,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20135268568992615,
      "rewards/margins": 0.3300771713256836,
      "rewards/rejected": -0.12872448563575745,
      "step": 432
    },
    {
      "epoch": 0.1732,
      "grad_norm": 12.014758110046387,
      "learning_rate": 9.424e-07,
      "logits/chosen": -2.4245080947875977,
      "logits/rejected": -2.1351358890533447,
      "logps/chosen": -136.4957275390625,
      "logps/rejected": -69.24375915527344,
      "loss": 0.408,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42691195011138916,
      "rewards/margins": 0.6888300180435181,
      "rewards/rejected": -0.2619180679321289,
      "step": 433
    },
    {
      "epoch": 0.1736,
      "grad_norm": 10.096010208129883,
      "learning_rate": 9.422666666666667e-07,
      "logits/chosen": -2.6178174018859863,
      "logits/rejected": -2.437835693359375,
      "logps/chosen": -60.20798110961914,
      "logps/rejected": -49.47126770019531,
      "loss": 0.5461,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16094762086868286,
      "rewards/margins": 0.32213956117630005,
      "rewards/rejected": -0.1611919403076172,
      "step": 434
    },
    {
      "epoch": 0.174,
      "grad_norm": 11.82889461517334,
      "learning_rate": 9.421333333333334e-07,
      "logits/chosen": -2.20713472366333,
      "logits/rejected": -1.9259686470031738,
      "logps/chosen": -135.89613342285156,
      "logps/rejected": -81.23898315429688,
      "loss": 0.438,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.44774705171585083,
      "rewards/margins": 0.6081771850585938,
      "rewards/rejected": -0.1604301482439041,
      "step": 435
    },
    {
      "epoch": 0.1744,
      "grad_norm": 8.780935287475586,
      "learning_rate": 9.419999999999999e-07,
      "logits/chosen": -2.502889633178711,
      "logits/rejected": -2.2200303077697754,
      "logps/chosen": -89.33468627929688,
      "logps/rejected": -46.269996643066406,
      "loss": 0.4383,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5275753140449524,
      "rewards/margins": 0.6143020987510681,
      "rewards/rejected": -0.08672676235437393,
      "step": 436
    },
    {
      "epoch": 0.1748,
      "grad_norm": 11.403494834899902,
      "learning_rate": 9.418666666666666e-07,
      "logits/chosen": -2.700645923614502,
      "logits/rejected": -2.6579668521881104,
      "logps/chosen": -96.60026550292969,
      "logps/rejected": -49.414344787597656,
      "loss": 0.5356,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31861457228660583,
      "rewards/margins": 0.34475499391555786,
      "rewards/rejected": -0.026140403002500534,
      "step": 437
    },
    {
      "epoch": 0.1752,
      "grad_norm": 9.715690612792969,
      "learning_rate": 9.417333333333332e-07,
      "logits/chosen": -2.5287582874298096,
      "logits/rejected": -2.1851553916931152,
      "logps/chosen": -108.48775482177734,
      "logps/rejected": -63.220359802246094,
      "loss": 0.399,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4491388201713562,
      "rewards/margins": 0.7473100423812866,
      "rewards/rejected": -0.2981712222099304,
      "step": 438
    },
    {
      "epoch": 0.1756,
      "grad_norm": 13.747886657714844,
      "learning_rate": 9.415999999999999e-07,
      "logits/chosen": -2.424212694168091,
      "logits/rejected": -2.1277031898498535,
      "logps/chosen": -144.65460205078125,
      "logps/rejected": -66.55194091796875,
      "loss": 0.4501,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4127700924873352,
      "rewards/margins": 0.5661301016807556,
      "rewards/rejected": -0.15335997939109802,
      "step": 439
    },
    {
      "epoch": 0.176,
      "grad_norm": 13.097552299499512,
      "learning_rate": 9.414666666666666e-07,
      "logits/chosen": -2.912558078765869,
      "logits/rejected": -2.2255520820617676,
      "logps/chosen": -103.6494140625,
      "logps/rejected": -94.69274139404297,
      "loss": 0.4815,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23095855116844177,
      "rewards/margins": 0.4870712459087372,
      "rewards/rejected": -0.256112664937973,
      "step": 440
    },
    {
      "epoch": 0.1764,
      "grad_norm": 11.103363990783691,
      "learning_rate": 9.413333333333333e-07,
      "logits/chosen": -2.6032910346984863,
      "logits/rejected": -2.226722240447998,
      "logps/chosen": -90.87738037109375,
      "logps/rejected": -60.97471618652344,
      "loss": 0.417,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3110431730747223,
      "rewards/margins": 0.6630754470825195,
      "rewards/rejected": -0.35203230381011963,
      "step": 441
    },
    {
      "epoch": 0.1768,
      "grad_norm": 12.264790534973145,
      "learning_rate": 9.412e-07,
      "logits/chosen": -2.3137078285217285,
      "logits/rejected": -2.003155469894409,
      "logps/chosen": -167.69454956054688,
      "logps/rejected": -155.1247100830078,
      "loss": 0.3636,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.671801745891571,
      "rewards/margins": 0.8261871337890625,
      "rewards/rejected": -0.15438538789749146,
      "step": 442
    },
    {
      "epoch": 0.1772,
      "grad_norm": 12.581709861755371,
      "learning_rate": 9.410666666666667e-07,
      "logits/chosen": -2.6674180030822754,
      "logits/rejected": -1.8438177108764648,
      "logps/chosen": -76.82836151123047,
      "logps/rejected": -103.80489349365234,
      "loss": 0.4186,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4120796322822571,
      "rewards/margins": 0.6550148129463196,
      "rewards/rejected": -0.2429351806640625,
      "step": 443
    },
    {
      "epoch": 0.1776,
      "grad_norm": 8.163325309753418,
      "learning_rate": 9.409333333333333e-07,
      "logits/chosen": -2.613781690597534,
      "logits/rejected": -2.234447956085205,
      "logps/chosen": -68.97537231445312,
      "logps/rejected": -44.94639587402344,
      "loss": 0.5151,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21985721588134766,
      "rewards/margins": 0.4096922278404236,
      "rewards/rejected": -0.18983498215675354,
      "step": 444
    },
    {
      "epoch": 0.178,
      "grad_norm": 10.392021179199219,
      "learning_rate": 9.408e-07,
      "logits/chosen": -2.573357582092285,
      "logits/rejected": -2.313826560974121,
      "logps/chosen": -105.92161560058594,
      "logps/rejected": -52.08386993408203,
      "loss": 0.478,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.43229982256889343,
      "rewards/margins": 0.5574544668197632,
      "rewards/rejected": -0.12515468895435333,
      "step": 445
    },
    {
      "epoch": 0.1784,
      "grad_norm": 11.300704002380371,
      "learning_rate": 9.406666666666666e-07,
      "logits/chosen": -2.6282835006713867,
      "logits/rejected": -2.328784942626953,
      "logps/chosen": -106.92414855957031,
      "logps/rejected": -70.56317138671875,
      "loss": 0.4046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4880245327949524,
      "rewards/margins": 0.6972536444664001,
      "rewards/rejected": -0.20922909677028656,
      "step": 446
    },
    {
      "epoch": 0.1788,
      "grad_norm": 9.095014572143555,
      "learning_rate": 9.405333333333333e-07,
      "logits/chosen": -2.8319478034973145,
      "logits/rejected": -2.543766975402832,
      "logps/chosen": -76.57980346679688,
      "logps/rejected": -28.55872344970703,
      "loss": 0.4641,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3305954039096832,
      "rewards/margins": 0.5268725752830505,
      "rewards/rejected": -0.19627714157104492,
      "step": 447
    },
    {
      "epoch": 0.1792,
      "grad_norm": 9.966409683227539,
      "learning_rate": 9.403999999999999e-07,
      "logits/chosen": -2.668034553527832,
      "logits/rejected": -2.469744920730591,
      "logps/chosen": -100.69225311279297,
      "logps/rejected": -54.748809814453125,
      "loss": 0.4841,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40595972537994385,
      "rewards/margins": 0.47968465089797974,
      "rewards/rejected": -0.07372494041919708,
      "step": 448
    },
    {
      "epoch": 0.1796,
      "grad_norm": 11.124141693115234,
      "learning_rate": 9.402666666666666e-07,
      "logits/chosen": -2.3388803005218506,
      "logits/rejected": -1.8290784358978271,
      "logps/chosen": -151.86744689941406,
      "logps/rejected": -61.69713592529297,
      "loss": 0.3856,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.656353771686554,
      "rewards/margins": 0.7578897476196289,
      "rewards/rejected": -0.10153599083423615,
      "step": 449
    },
    {
      "epoch": 0.18,
      "grad_norm": 12.222729682922363,
      "learning_rate": 9.401333333333333e-07,
      "logits/chosen": -2.4749269485473633,
      "logits/rejected": -2.152956485748291,
      "logps/chosen": -160.951416015625,
      "logps/rejected": -60.495521545410156,
      "loss": 0.418,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42585983872413635,
      "rewards/margins": 0.6564043164253235,
      "rewards/rejected": -0.23054447770118713,
      "step": 450
    },
    {
      "epoch": 0.1804,
      "grad_norm": 10.697981834411621,
      "learning_rate": 9.399999999999999e-07,
      "logits/chosen": -2.2371697425842285,
      "logits/rejected": -2.1530227661132812,
      "logps/chosen": -117.41986083984375,
      "logps/rejected": -51.52892303466797,
      "loss": 0.4247,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4958549737930298,
      "rewards/margins": 0.6437059640884399,
      "rewards/rejected": -0.14785100519657135,
      "step": 451
    },
    {
      "epoch": 0.1808,
      "grad_norm": 10.201029777526855,
      "learning_rate": 9.398666666666666e-07,
      "logits/chosen": -2.757685661315918,
      "logits/rejected": -2.871711254119873,
      "logps/chosen": -88.1996841430664,
      "logps/rejected": -39.072174072265625,
      "loss": 0.511,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24294167757034302,
      "rewards/margins": 0.40854036808013916,
      "rewards/rejected": -0.16559869050979614,
      "step": 452
    },
    {
      "epoch": 0.1812,
      "grad_norm": 11.888409614562988,
      "learning_rate": 9.397333333333333e-07,
      "logits/chosen": -2.697960138320923,
      "logits/rejected": -2.157741069793701,
      "logps/chosen": -86.21051025390625,
      "logps/rejected": -66.15174865722656,
      "loss": 0.3211,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6029144525527954,
      "rewards/margins": 0.9723275899887085,
      "rewards/rejected": -0.36941319704055786,
      "step": 453
    },
    {
      "epoch": 0.1816,
      "grad_norm": 12.778279304504395,
      "learning_rate": 9.396e-07,
      "logits/chosen": -2.353693723678589,
      "logits/rejected": -2.27634596824646,
      "logps/chosen": -84.52932739257812,
      "logps/rejected": -88.34654235839844,
      "loss": 0.3894,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5398285388946533,
      "rewards/margins": 0.7581722140312195,
      "rewards/rejected": -0.21834373474121094,
      "step": 454
    },
    {
      "epoch": 0.182,
      "grad_norm": 12.049359321594238,
      "learning_rate": 9.394666666666667e-07,
      "logits/chosen": -3.000438928604126,
      "logits/rejected": -2.4011402130126953,
      "logps/chosen": -73.05475616455078,
      "logps/rejected": -58.718055725097656,
      "loss": 0.4614,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1266757994890213,
      "rewards/margins": 0.5359222292900085,
      "rewards/rejected": -0.40924644470214844,
      "step": 455
    },
    {
      "epoch": 0.1824,
      "grad_norm": 9.315130233764648,
      "learning_rate": 9.393333333333334e-07,
      "logits/chosen": -2.997183322906494,
      "logits/rejected": -2.8972415924072266,
      "logps/chosen": -85.64353942871094,
      "logps/rejected": -39.50624084472656,
      "loss": 0.5477,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19987565279006958,
      "rewards/margins": 0.31565916538238525,
      "rewards/rejected": -0.11578349769115448,
      "step": 456
    },
    {
      "epoch": 0.1828,
      "grad_norm": 12.656188011169434,
      "learning_rate": 9.391999999999999e-07,
      "logits/chosen": -2.317495822906494,
      "logits/rejected": -2.336653709411621,
      "logps/chosen": -170.75558471679688,
      "logps/rejected": -116.18492126464844,
      "loss": 0.3401,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.647901177406311,
      "rewards/margins": 0.9050499200820923,
      "rewards/rejected": -0.25714874267578125,
      "step": 457
    },
    {
      "epoch": 0.1832,
      "grad_norm": 9.89186954498291,
      "learning_rate": 9.390666666666666e-07,
      "logits/chosen": -2.5542731285095215,
      "logits/rejected": -2.2112789154052734,
      "logps/chosen": -119.06083679199219,
      "logps/rejected": -55.933448791503906,
      "loss": 0.4454,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3815639615058899,
      "rewards/margins": 0.596635103225708,
      "rewards/rejected": -0.21507111191749573,
      "step": 458
    },
    {
      "epoch": 0.1836,
      "grad_norm": 13.773409843444824,
      "learning_rate": 9.389333333333332e-07,
      "logits/chosen": -2.4781792163848877,
      "logits/rejected": -2.796900987625122,
      "logps/chosen": -57.73741912841797,
      "logps/rejected": -52.18201446533203,
      "loss": 0.5133,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38279467821121216,
      "rewards/margins": 0.42202186584472656,
      "rewards/rejected": -0.0392271988093853,
      "step": 459
    },
    {
      "epoch": 0.184,
      "grad_norm": 9.600728034973145,
      "learning_rate": 9.387999999999999e-07,
      "logits/chosen": -2.7641677856445312,
      "logits/rejected": -2.344702959060669,
      "logps/chosen": -105.61701202392578,
      "logps/rejected": -55.593894958496094,
      "loss": 0.3565,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4848839044570923,
      "rewards/margins": 0.8485167026519775,
      "rewards/rejected": -0.36363279819488525,
      "step": 460
    },
    {
      "epoch": 0.1844,
      "grad_norm": 11.441917419433594,
      "learning_rate": 9.386666666666666e-07,
      "logits/chosen": -2.812041759490967,
      "logits/rejected": -2.8498802185058594,
      "logps/chosen": -46.35181427001953,
      "logps/rejected": -59.545936584472656,
      "loss": 0.4416,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13243846595287323,
      "rewards/margins": 0.6037039160728455,
      "rewards/rejected": -0.47126543521881104,
      "step": 461
    },
    {
      "epoch": 0.1848,
      "grad_norm": 11.76026725769043,
      "learning_rate": 9.385333333333333e-07,
      "logits/chosen": -2.634242057800293,
      "logits/rejected": -2.604428768157959,
      "logps/chosen": -95.64555358886719,
      "logps/rejected": -83.48560333251953,
      "loss": 0.4101,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.43185004591941833,
      "rewards/margins": 0.685440182685852,
      "rewards/rejected": -0.25359010696411133,
      "step": 462
    },
    {
      "epoch": 0.1852,
      "grad_norm": 8.692708015441895,
      "learning_rate": 9.384e-07,
      "logits/chosen": -2.5418193340301514,
      "logits/rejected": -2.479755163192749,
      "logps/chosen": -107.0175552368164,
      "logps/rejected": -59.209930419921875,
      "loss": 0.46,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42990171909332275,
      "rewards/margins": 0.5736021995544434,
      "rewards/rejected": -0.143700510263443,
      "step": 463
    },
    {
      "epoch": 0.1856,
      "grad_norm": 10.3139009475708,
      "learning_rate": 9.382666666666667e-07,
      "logits/chosen": -2.5215647220611572,
      "logits/rejected": -2.4669251441955566,
      "logps/chosen": -90.32081604003906,
      "logps/rejected": -59.78844451904297,
      "loss": 0.4338,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5320141315460205,
      "rewards/margins": 0.6262741088867188,
      "rewards/rejected": -0.09426002204418182,
      "step": 464
    },
    {
      "epoch": 0.186,
      "grad_norm": 10.026299476623535,
      "learning_rate": 9.381333333333334e-07,
      "logits/chosen": -2.7601096630096436,
      "logits/rejected": -2.389833927154541,
      "logps/chosen": -112.41559600830078,
      "logps/rejected": -54.280792236328125,
      "loss": 0.3854,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5373110175132751,
      "rewards/margins": 0.7550405859947205,
      "rewards/rejected": -0.2177295684814453,
      "step": 465
    },
    {
      "epoch": 0.1864,
      "grad_norm": 10.184503555297852,
      "learning_rate": 9.379999999999998e-07,
      "logits/chosen": -2.9039759635925293,
      "logits/rejected": -2.437869071960449,
      "logps/chosen": -44.681339263916016,
      "logps/rejected": -55.5157356262207,
      "loss": 0.4886,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21433886885643005,
      "rewards/margins": 0.46558305621147156,
      "rewards/rejected": -0.2512441575527191,
      "step": 466
    },
    {
      "epoch": 0.1868,
      "grad_norm": 10.632787704467773,
      "learning_rate": 9.378666666666665e-07,
      "logits/chosen": -2.3149750232696533,
      "logits/rejected": -2.3051412105560303,
      "logps/chosen": -110.64173889160156,
      "logps/rejected": -85.78191375732422,
      "loss": 0.3739,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6555812954902649,
      "rewards/margins": 0.7957191467285156,
      "rewards/rejected": -0.14013786613941193,
      "step": 467
    },
    {
      "epoch": 0.1872,
      "grad_norm": 11.560853004455566,
      "learning_rate": 9.377333333333332e-07,
      "logits/chosen": -2.262576103210449,
      "logits/rejected": -2.030263900756836,
      "logps/chosen": -129.63937377929688,
      "logps/rejected": -74.07218933105469,
      "loss": 0.3826,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4569908380508423,
      "rewards/margins": 0.7707679867744446,
      "rewards/rejected": -0.3137771487236023,
      "step": 468
    },
    {
      "epoch": 0.1876,
      "grad_norm": 11.389704704284668,
      "learning_rate": 9.375999999999999e-07,
      "logits/chosen": -2.658191204071045,
      "logits/rejected": -2.378321647644043,
      "logps/chosen": -99.0907211303711,
      "logps/rejected": -45.01264190673828,
      "loss": 0.3648,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4040452837944031,
      "rewards/margins": 0.8319045901298523,
      "rewards/rejected": -0.4278593063354492,
      "step": 469
    },
    {
      "epoch": 0.188,
      "grad_norm": 11.59964656829834,
      "learning_rate": 9.374666666666666e-07,
      "logits/chosen": -2.3727657794952393,
      "logits/rejected": -2.379572868347168,
      "logps/chosen": -127.91566467285156,
      "logps/rejected": -128.58360290527344,
      "loss": 0.39,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.49197351932525635,
      "rewards/margins": 0.7429868578910828,
      "rewards/rejected": -0.2510133683681488,
      "step": 470
    },
    {
      "epoch": 0.1884,
      "grad_norm": 8.538603782653809,
      "learning_rate": 9.373333333333333e-07,
      "logits/chosen": -2.877518653869629,
      "logits/rejected": -2.488861560821533,
      "logps/chosen": -48.7914924621582,
      "logps/rejected": -38.27552795410156,
      "loss": 0.4483,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31360453367233276,
      "rewards/margins": 0.5737165212631226,
      "rewards/rejected": -0.2601119875907898,
      "step": 471
    },
    {
      "epoch": 0.1888,
      "grad_norm": 7.991098880767822,
      "learning_rate": 9.372e-07,
      "logits/chosen": -3.0022377967834473,
      "logits/rejected": -2.8484644889831543,
      "logps/chosen": -48.34364318847656,
      "logps/rejected": -27.30832290649414,
      "loss": 0.5174,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27252236008644104,
      "rewards/margins": 0.3989459276199341,
      "rewards/rejected": -0.12642355263233185,
      "step": 472
    },
    {
      "epoch": 0.1892,
      "grad_norm": 11.5154447555542,
      "learning_rate": 9.370666666666667e-07,
      "logits/chosen": -2.337136745452881,
      "logits/rejected": -2.1468546390533447,
      "logps/chosen": -136.10235595703125,
      "logps/rejected": -56.525638580322266,
      "loss": 0.3416,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.536023736000061,
      "rewards/margins": 0.900955080986023,
      "rewards/rejected": -0.3649313151836395,
      "step": 473
    },
    {
      "epoch": 0.1896,
      "grad_norm": 10.562621116638184,
      "learning_rate": 9.369333333333333e-07,
      "logits/chosen": -2.539005756378174,
      "logits/rejected": -2.589776039123535,
      "logps/chosen": -128.50335693359375,
      "logps/rejected": -46.535888671875,
      "loss": 0.4841,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31397363543510437,
      "rewards/margins": 0.47365954518318176,
      "rewards/rejected": -0.1596859097480774,
      "step": 474
    },
    {
      "epoch": 0.19,
      "grad_norm": 12.79675006866455,
      "learning_rate": 9.368e-07,
      "logits/chosen": -2.3294506072998047,
      "logits/rejected": -2.3618903160095215,
      "logps/chosen": -197.2947235107422,
      "logps/rejected": -78.09555053710938,
      "loss": 0.3459,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6688095331192017,
      "rewards/margins": 0.9142841696739197,
      "rewards/rejected": -0.24547462165355682,
      "step": 475
    },
    {
      "epoch": 0.1904,
      "grad_norm": 10.815547943115234,
      "learning_rate": 9.366666666666666e-07,
      "logits/chosen": -2.7540667057037354,
      "logits/rejected": -2.1343281269073486,
      "logps/chosen": -131.61376953125,
      "logps/rejected": -86.17974090576172,
      "loss": 0.2738,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5048120617866516,
      "rewards/margins": 1.1556708812713623,
      "rewards/rejected": -0.6508588790893555,
      "step": 476
    },
    {
      "epoch": 0.1908,
      "grad_norm": 10.151225090026855,
      "learning_rate": 9.365333333333332e-07,
      "logits/chosen": -2.2600955963134766,
      "logits/rejected": -2.0218780040740967,
      "logps/chosen": -149.1782684326172,
      "logps/rejected": -81.72471618652344,
      "loss": 0.3181,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8007446527481079,
      "rewards/margins": 0.9961643218994141,
      "rewards/rejected": -0.19541969895362854,
      "step": 477
    },
    {
      "epoch": 0.1912,
      "grad_norm": 11.650235176086426,
      "learning_rate": 9.363999999999999e-07,
      "logits/chosen": -2.8691444396972656,
      "logits/rejected": -2.2387895584106445,
      "logps/chosen": -70.40171813964844,
      "logps/rejected": -67.07879638671875,
      "loss": 0.3964,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.30444300174713135,
      "rewards/margins": 0.7210575342178345,
      "rewards/rejected": -0.4166145324707031,
      "step": 478
    },
    {
      "epoch": 0.1916,
      "grad_norm": 13.301087379455566,
      "learning_rate": 9.362666666666666e-07,
      "logits/chosen": -2.3437232971191406,
      "logits/rejected": -2.3273515701293945,
      "logps/chosen": -121.86601257324219,
      "logps/rejected": -44.636722564697266,
      "loss": 0.5354,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2233016937971115,
      "rewards/margins": 0.3482893109321594,
      "rewards/rejected": -0.12498760223388672,
      "step": 479
    },
    {
      "epoch": 0.192,
      "grad_norm": 11.434955596923828,
      "learning_rate": 9.361333333333333e-07,
      "logits/chosen": -2.3697128295898438,
      "logits/rejected": -2.721850633621216,
      "logps/chosen": -131.0912322998047,
      "logps/rejected": -49.328392028808594,
      "loss": 0.4116,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5394004583358765,
      "rewards/margins": 0.6748422384262085,
      "rewards/rejected": -0.13544178009033203,
      "step": 480
    },
    {
      "epoch": 0.1924,
      "grad_norm": 11.414440155029297,
      "learning_rate": 9.36e-07,
      "logits/chosen": -2.8426613807678223,
      "logits/rejected": -2.116988182067871,
      "logps/chosen": -63.121761322021484,
      "logps/rejected": -57.44200134277344,
      "loss": 0.4273,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3749248683452606,
      "rewards/margins": 0.629250168800354,
      "rewards/rejected": -0.2543253004550934,
      "step": 481
    },
    {
      "epoch": 0.1928,
      "grad_norm": 9.527587890625,
      "learning_rate": 9.358666666666666e-07,
      "logits/chosen": -2.686464309692383,
      "logits/rejected": -2.208583116531372,
      "logps/chosen": -89.83441162109375,
      "logps/rejected": -63.95352554321289,
      "loss": 0.3872,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5782512426376343,
      "rewards/margins": 0.7513132095336914,
      "rewards/rejected": -0.17306193709373474,
      "step": 482
    },
    {
      "epoch": 0.1932,
      "grad_norm": 10.44820499420166,
      "learning_rate": 9.357333333333333e-07,
      "logits/chosen": -2.6709399223327637,
      "logits/rejected": -2.03458309173584,
      "logps/chosen": -73.97840118408203,
      "logps/rejected": -40.23206329345703,
      "loss": 0.4931,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16940441727638245,
      "rewards/margins": 0.4520953297615051,
      "rewards/rejected": -0.2826909124851227,
      "step": 483
    },
    {
      "epoch": 0.1936,
      "grad_norm": 10.007168769836426,
      "learning_rate": 9.356e-07,
      "logits/chosen": -2.873668670654297,
      "logits/rejected": -2.4075074195861816,
      "logps/chosen": -69.30870056152344,
      "logps/rejected": -59.29573440551758,
      "loss": 0.3646,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4238864779472351,
      "rewards/margins": 0.8238252401351929,
      "rewards/rejected": -0.39993876218795776,
      "step": 484
    },
    {
      "epoch": 0.194,
      "grad_norm": 9.854933738708496,
      "learning_rate": 9.354666666666667e-07,
      "logits/chosen": -2.6532199382781982,
      "logits/rejected": -2.2295851707458496,
      "logps/chosen": -128.61167907714844,
      "logps/rejected": -56.460411071777344,
      "loss": 0.3535,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5062557458877563,
      "rewards/margins": 0.861619234085083,
      "rewards/rejected": -0.3553634583950043,
      "step": 485
    },
    {
      "epoch": 0.1944,
      "grad_norm": 11.977018356323242,
      "learning_rate": 9.353333333333333e-07,
      "logits/chosen": -2.8636250495910645,
      "logits/rejected": -3.3024163246154785,
      "logps/chosen": -76.2791748046875,
      "logps/rejected": -58.70613098144531,
      "loss": 0.4747,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2852360010147095,
      "rewards/margins": 0.525312066078186,
      "rewards/rejected": -0.24007606506347656,
      "step": 486
    },
    {
      "epoch": 0.1948,
      "grad_norm": 10.876298904418945,
      "learning_rate": 9.352e-07,
      "logits/chosen": -2.845456123352051,
      "logits/rejected": -2.1258883476257324,
      "logps/chosen": -58.81696319580078,
      "logps/rejected": -76.83102416992188,
      "loss": 0.3634,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3653898239135742,
      "rewards/margins": 0.8322197198867798,
      "rewards/rejected": -0.46682989597320557,
      "step": 487
    },
    {
      "epoch": 0.1952,
      "grad_norm": 8.700078964233398,
      "learning_rate": 9.350666666666666e-07,
      "logits/chosen": -3.0053882598876953,
      "logits/rejected": -2.7658233642578125,
      "logps/chosen": -73.30735778808594,
      "logps/rejected": -38.78425598144531,
      "loss": 0.443,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.47183915972709656,
      "rewards/margins": 0.589083731174469,
      "rewards/rejected": -0.11724454164505005,
      "step": 488
    },
    {
      "epoch": 0.1956,
      "grad_norm": 10.674995422363281,
      "learning_rate": 9.349333333333332e-07,
      "logits/chosen": -2.3371243476867676,
      "logits/rejected": -2.1670379638671875,
      "logps/chosen": -101.62464904785156,
      "logps/rejected": -54.256011962890625,
      "loss": 0.4128,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.49218103289604187,
      "rewards/margins": 0.6783983707427979,
      "rewards/rejected": -0.1862173080444336,
      "step": 489
    },
    {
      "epoch": 0.196,
      "grad_norm": 8.67339038848877,
      "learning_rate": 9.347999999999999e-07,
      "logits/chosen": -2.688486099243164,
      "logits/rejected": -2.32853102684021,
      "logps/chosen": -50.817726135253906,
      "logps/rejected": -54.38388442993164,
      "loss": 0.3712,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.43424472212791443,
      "rewards/margins": 0.8398144245147705,
      "rewards/rejected": -0.4055696427822113,
      "step": 490
    },
    {
      "epoch": 0.1964,
      "grad_norm": 9.691200256347656,
      "learning_rate": 9.346666666666666e-07,
      "logits/chosen": -2.4511752128601074,
      "logits/rejected": -2.5998446941375732,
      "logps/chosen": -130.72959899902344,
      "logps/rejected": -72.16273498535156,
      "loss": 0.3857,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.459259033203125,
      "rewards/margins": 0.7606300711631775,
      "rewards/rejected": -0.3013710081577301,
      "step": 491
    },
    {
      "epoch": 0.1968,
      "grad_norm": 10.882511138916016,
      "learning_rate": 9.345333333333333e-07,
      "logits/chosen": -2.6056265830993652,
      "logits/rejected": -2.4302053451538086,
      "logps/chosen": -113.3201904296875,
      "logps/rejected": -47.95887756347656,
      "loss": 0.4014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5053505301475525,
      "rewards/margins": 0.7273163199424744,
      "rewards/rejected": -0.22196578979492188,
      "step": 492
    },
    {
      "epoch": 0.1972,
      "grad_norm": 15.69771671295166,
      "learning_rate": 9.344e-07,
      "logits/chosen": -2.9243717193603516,
      "logits/rejected": -2.1713342666625977,
      "logps/chosen": -53.93775939941406,
      "logps/rejected": -43.72106170654297,
      "loss": 0.4538,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23475056886672974,
      "rewards/margins": 0.5556443333625793,
      "rewards/rejected": -0.3208937644958496,
      "step": 493
    },
    {
      "epoch": 0.1976,
      "grad_norm": 11.254279136657715,
      "learning_rate": 9.342666666666667e-07,
      "logits/chosen": -2.426375150680542,
      "logits/rejected": -2.415499210357666,
      "logps/chosen": -65.51893615722656,
      "logps/rejected": -83.33566284179688,
      "loss": 0.3968,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4404735565185547,
      "rewards/margins": 0.7195953130722046,
      "rewards/rejected": -0.2791217863559723,
      "step": 494
    },
    {
      "epoch": 0.198,
      "grad_norm": 10.965363502502441,
      "learning_rate": 9.341333333333333e-07,
      "logits/chosen": -2.435328960418701,
      "logits/rejected": -2.0519614219665527,
      "logps/chosen": -81.50469970703125,
      "logps/rejected": -126.64588928222656,
      "loss": 0.358,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4683435559272766,
      "rewards/margins": 0.8463201522827148,
      "rewards/rejected": -0.37797659635543823,
      "step": 495
    },
    {
      "epoch": 0.1984,
      "grad_norm": 8.056706428527832,
      "learning_rate": 9.34e-07,
      "logits/chosen": -2.683851718902588,
      "logits/rejected": -2.3132967948913574,
      "logps/chosen": -95.44528198242188,
      "logps/rejected": -50.8859977722168,
      "loss": 0.3365,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6230220794677734,
      "rewards/margins": 0.9216688275337219,
      "rewards/rejected": -0.2986467480659485,
      "step": 496
    },
    {
      "epoch": 0.1988,
      "grad_norm": 10.39995002746582,
      "learning_rate": 9.338666666666666e-07,
      "logits/chosen": -2.481379508972168,
      "logits/rejected": -2.1586103439331055,
      "logps/chosen": -119.66529083251953,
      "logps/rejected": -69.67378234863281,
      "loss": 0.3145,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5693061947822571,
      "rewards/margins": 0.9959186911582947,
      "rewards/rejected": -0.4266124963760376,
      "step": 497
    },
    {
      "epoch": 0.1992,
      "grad_norm": 9.346015930175781,
      "learning_rate": 9.337333333333333e-07,
      "logits/chosen": -2.578402042388916,
      "logits/rejected": -2.8467772006988525,
      "logps/chosen": -53.35388946533203,
      "logps/rejected": -52.63319396972656,
      "loss": 0.4889,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.28238314390182495,
      "rewards/margins": 0.4898359179496765,
      "rewards/rejected": -0.20745277404785156,
      "step": 498
    },
    {
      "epoch": 0.1996,
      "grad_norm": 9.983128547668457,
      "learning_rate": 9.335999999999999e-07,
      "logits/chosen": -2.4910287857055664,
      "logits/rejected": -2.549968719482422,
      "logps/chosen": -151.787841796875,
      "logps/rejected": -49.73855209350586,
      "loss": 0.3909,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4272400140762329,
      "rewards/margins": 0.7426793575286865,
      "rewards/rejected": -0.3154393434524536,
      "step": 499
    },
    {
      "epoch": 0.2,
      "grad_norm": 12.930652618408203,
      "learning_rate": 9.334666666666666e-07,
      "logits/chosen": -2.5247645378112793,
      "logits/rejected": -2.541043758392334,
      "logps/chosen": -76.48102569580078,
      "logps/rejected": -117.73420715332031,
      "loss": 0.4949,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3831232190132141,
      "rewards/margins": 0.45501118898391724,
      "rewards/rejected": -0.07188796997070312,
      "step": 500
    },
    {
      "epoch": 0.2004,
      "grad_norm": 12.916738510131836,
      "learning_rate": 9.333333333333333e-07,
      "logits/chosen": -2.5331950187683105,
      "logits/rejected": -2.906513214111328,
      "logps/chosen": -90.62689208984375,
      "logps/rejected": -48.246116638183594,
      "loss": 0.4164,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3499946594238281,
      "rewards/margins": 0.6617019772529602,
      "rewards/rejected": -0.3117073178291321,
      "step": 501
    },
    {
      "epoch": 0.2008,
      "grad_norm": 10.818148612976074,
      "learning_rate": 9.332e-07,
      "logits/chosen": -2.895317554473877,
      "logits/rejected": -2.6499905586242676,
      "logps/chosen": -81.27288818359375,
      "logps/rejected": -71.55078887939453,
      "loss": 0.3602,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42873746156692505,
      "rewards/margins": 0.8473978042602539,
      "rewards/rejected": -0.41866034269332886,
      "step": 502
    },
    {
      "epoch": 0.2012,
      "grad_norm": 12.031880378723145,
      "learning_rate": 9.330666666666667e-07,
      "logits/chosen": -2.1735782623291016,
      "logits/rejected": -2.071632146835327,
      "logps/chosen": -116.36778259277344,
      "logps/rejected": -83.53628540039062,
      "loss": 0.3751,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5788929462432861,
      "rewards/margins": 0.7920137643814087,
      "rewards/rejected": -0.21312084794044495,
      "step": 503
    },
    {
      "epoch": 0.2016,
      "grad_norm": 9.438807487487793,
      "learning_rate": 9.329333333333332e-07,
      "logits/chosen": -2.644528388977051,
      "logits/rejected": -2.4280214309692383,
      "logps/chosen": -119.5462875366211,
      "logps/rejected": -59.79530334472656,
      "loss": 0.3897,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3137870728969574,
      "rewards/margins": 0.7598363757133484,
      "rewards/rejected": -0.4460493326187134,
      "step": 504
    },
    {
      "epoch": 0.202,
      "grad_norm": 9.668205261230469,
      "learning_rate": 9.327999999999999e-07,
      "logits/chosen": -2.6416749954223633,
      "logits/rejected": -2.409416675567627,
      "logps/chosen": -122.77915954589844,
      "logps/rejected": -64.59324645996094,
      "loss": 0.3366,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5406570434570312,
      "rewards/margins": 0.9210348129272461,
      "rewards/rejected": -0.38037776947021484,
      "step": 505
    },
    {
      "epoch": 0.2024,
      "grad_norm": 9.895428657531738,
      "learning_rate": 9.326666666666666e-07,
      "logits/chosen": -2.7195329666137695,
      "logits/rejected": -2.3447155952453613,
      "logps/chosen": -104.05367279052734,
      "logps/rejected": -64.88650512695312,
      "loss": 0.3775,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3079395294189453,
      "rewards/margins": 0.8164392709732056,
      "rewards/rejected": -0.5084997415542603,
      "step": 506
    },
    {
      "epoch": 0.2028,
      "grad_norm": 8.851263046264648,
      "learning_rate": 9.325333333333333e-07,
      "logits/chosen": -2.517137289047241,
      "logits/rejected": -2.5513830184936523,
      "logps/chosen": -113.70530700683594,
      "logps/rejected": -65.69068145751953,
      "loss": 0.3755,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6213575601577759,
      "rewards/margins": 0.8451738357543945,
      "rewards/rejected": -0.22381630539894104,
      "step": 507
    },
    {
      "epoch": 0.2032,
      "grad_norm": 9.653804779052734,
      "learning_rate": 9.324e-07,
      "logits/chosen": -2.2890920639038086,
      "logits/rejected": -2.1125335693359375,
      "logps/chosen": -168.04376220703125,
      "logps/rejected": -128.12828063964844,
      "loss": 0.2878,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7943832874298096,
      "rewards/margins": 1.1000335216522217,
      "rewards/rejected": -0.3056503236293793,
      "step": 508
    },
    {
      "epoch": 0.2036,
      "grad_norm": 9.829620361328125,
      "learning_rate": 9.322666666666667e-07,
      "logits/chosen": -2.6005496978759766,
      "logits/rejected": -2.471290111541748,
      "logps/chosen": -139.16232299804688,
      "logps/rejected": -85.11732482910156,
      "loss": 0.3975,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.47441214323043823,
      "rewards/margins": 0.7352222800254822,
      "rewards/rejected": -0.26081010699272156,
      "step": 509
    },
    {
      "epoch": 0.204,
      "grad_norm": 22.021625518798828,
      "learning_rate": 9.321333333333333e-07,
      "logits/chosen": -2.3634307384490967,
      "logits/rejected": -2.224587917327881,
      "logps/chosen": -125.95115661621094,
      "logps/rejected": -100.883544921875,
      "loss": 0.3832,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.425924688577652,
      "rewards/margins": 0.7638477087020874,
      "rewards/rejected": -0.3379230499267578,
      "step": 510
    },
    {
      "epoch": 0.2044,
      "grad_norm": 10.232246398925781,
      "learning_rate": 9.32e-07,
      "logits/chosen": -2.6832005977630615,
      "logits/rejected": -2.266120433807373,
      "logps/chosen": -111.70115661621094,
      "logps/rejected": -85.97395324707031,
      "loss": 0.3159,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4620906710624695,
      "rewards/margins": 0.9991012811660767,
      "rewards/rejected": -0.5370105504989624,
      "step": 511
    },
    {
      "epoch": 0.2048,
      "grad_norm": 13.27372932434082,
      "learning_rate": 9.318666666666666e-07,
      "logits/chosen": -2.7745137214660645,
      "logits/rejected": -1.9057620763778687,
      "logps/chosen": -57.9487190246582,
      "logps/rejected": -95.72221374511719,
      "loss": 0.3335,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4098176956176758,
      "rewards/margins": 0.9270017743110657,
      "rewards/rejected": -0.5171840786933899,
      "step": 512
    },
    {
      "epoch": 0.2052,
      "grad_norm": 10.313509941101074,
      "learning_rate": 9.317333333333333e-07,
      "logits/chosen": -2.1497690677642822,
      "logits/rejected": -2.0658717155456543,
      "logps/chosen": -125.28197479248047,
      "logps/rejected": -93.13724517822266,
      "loss": 0.3126,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7424726486206055,
      "rewards/margins": 1.0155088901519775,
      "rewards/rejected": -0.2730361819267273,
      "step": 513
    },
    {
      "epoch": 0.2056,
      "grad_norm": 11.504149436950684,
      "learning_rate": 9.315999999999999e-07,
      "logits/chosen": -2.800778388977051,
      "logits/rejected": -2.2259140014648438,
      "logps/chosen": -105.15896606445312,
      "logps/rejected": -65.84982299804688,
      "loss": 0.3929,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5169917941093445,
      "rewards/margins": 0.7395280599594116,
      "rewards/rejected": -0.22253628075122833,
      "step": 514
    },
    {
      "epoch": 0.206,
      "grad_norm": 14.556974411010742,
      "learning_rate": 9.314666666666666e-07,
      "logits/chosen": -2.3772478103637695,
      "logits/rejected": -2.397505283355713,
      "logps/chosen": -126.24075317382812,
      "logps/rejected": -134.89492797851562,
      "loss": 0.3525,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8291091918945312,
      "rewards/margins": 0.867095947265625,
      "rewards/rejected": -0.03798675537109375,
      "step": 515
    },
    {
      "epoch": 0.2064,
      "grad_norm": 8.492018699645996,
      "learning_rate": 9.313333333333333e-07,
      "logits/chosen": -2.726106643676758,
      "logits/rejected": -2.5792813301086426,
      "logps/chosen": -71.28966522216797,
      "logps/rejected": -50.46730041503906,
      "loss": 0.4394,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.44654425978660583,
      "rewards/margins": 0.6062096357345581,
      "rewards/rejected": -0.15966540575027466,
      "step": 516
    },
    {
      "epoch": 0.2068,
      "grad_norm": 12.053488731384277,
      "learning_rate": 9.312e-07,
      "logits/chosen": -2.241337299346924,
      "logits/rejected": -1.9407730102539062,
      "logps/chosen": -158.89553833007812,
      "logps/rejected": -75.28106689453125,
      "loss": 0.3453,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6414138674736023,
      "rewards/margins": 0.917239785194397,
      "rewards/rejected": -0.2758258879184723,
      "step": 517
    },
    {
      "epoch": 0.2072,
      "grad_norm": 9.589030265808105,
      "learning_rate": 9.310666666666667e-07,
      "logits/chosen": -2.4651873111724854,
      "logits/rejected": -2.3190090656280518,
      "logps/chosen": -97.90206909179688,
      "logps/rejected": -72.76799774169922,
      "loss": 0.3584,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40739136934280396,
      "rewards/margins": 0.8439435958862305,
      "rewards/rejected": -0.4365522265434265,
      "step": 518
    },
    {
      "epoch": 0.2076,
      "grad_norm": 10.099507331848145,
      "learning_rate": 9.309333333333333e-07,
      "logits/chosen": -2.34566068649292,
      "logits/rejected": -2.450737953186035,
      "logps/chosen": -144.06399536132812,
      "logps/rejected": -50.051300048828125,
      "loss": 0.4061,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5471084713935852,
      "rewards/margins": 0.6929144263267517,
      "rewards/rejected": -0.1458059400320053,
      "step": 519
    },
    {
      "epoch": 0.208,
      "grad_norm": 12.82739543914795,
      "learning_rate": 9.307999999999999e-07,
      "logits/chosen": -2.8596701622009277,
      "logits/rejected": -2.0863914489746094,
      "logps/chosen": -67.40182495117188,
      "logps/rejected": -83.10847473144531,
      "loss": 0.3204,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3800283670425415,
      "rewards/margins": 1.0019252300262451,
      "rewards/rejected": -0.6218969225883484,
      "step": 520
    },
    {
      "epoch": 0.2084,
      "grad_norm": 10.041839599609375,
      "learning_rate": 9.306666666666666e-07,
      "logits/chosen": -2.625652551651001,
      "logits/rejected": -2.4193027019500732,
      "logps/chosen": -86.17239379882812,
      "logps/rejected": -53.652496337890625,
      "loss": 0.4121,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2643665373325348,
      "rewards/margins": 0.6748148202896118,
      "rewards/rejected": -0.41044825315475464,
      "step": 521
    },
    {
      "epoch": 0.2088,
      "grad_norm": 12.580341339111328,
      "learning_rate": 9.305333333333333e-07,
      "logits/chosen": -2.779646396636963,
      "logits/rejected": -3.0493698120117188,
      "logps/chosen": -110.08999633789062,
      "logps/rejected": -56.8216438293457,
      "loss": 0.4075,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3591255247592926,
      "rewards/margins": 0.6946226358413696,
      "rewards/rejected": -0.33549708127975464,
      "step": 522
    },
    {
      "epoch": 0.2092,
      "grad_norm": 11.628466606140137,
      "learning_rate": 9.303999999999999e-07,
      "logits/chosen": -3.005187511444092,
      "logits/rejected": -2.5682969093322754,
      "logps/chosen": -62.32349395751953,
      "logps/rejected": -71.85089111328125,
      "loss": 0.3642,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19241677224636078,
      "rewards/margins": 0.8520656824111938,
      "rewards/rejected": -0.6596488952636719,
      "step": 523
    },
    {
      "epoch": 0.2096,
      "grad_norm": 8.915990829467773,
      "learning_rate": 9.302666666666666e-07,
      "logits/chosen": -2.7093472480773926,
      "logits/rejected": -2.3139519691467285,
      "logps/chosen": -144.5,
      "logps/rejected": -94.62191772460938,
      "loss": 0.2645,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5287575125694275,
      "rewards/margins": 1.2060524225234985,
      "rewards/rejected": -0.6772949695587158,
      "step": 524
    },
    {
      "epoch": 0.21,
      "grad_norm": 10.297575950622559,
      "learning_rate": 9.301333333333333e-07,
      "logits/chosen": -2.5920283794403076,
      "logits/rejected": -2.4467949867248535,
      "logps/chosen": -60.77479553222656,
      "logps/rejected": -43.405662536621094,
      "loss": 0.5054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1968492567539215,
      "rewards/margins": 0.41927510499954224,
      "rewards/rejected": -0.22242584824562073,
      "step": 525
    },
    {
      "epoch": 0.2104,
      "grad_norm": 7.7698493003845215,
      "learning_rate": 9.3e-07,
      "logits/chosen": -2.7575128078460693,
      "logits/rejected": -2.5678224563598633,
      "logps/chosen": -66.10865783691406,
      "logps/rejected": -42.882301330566406,
      "loss": 0.3978,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45768776535987854,
      "rewards/margins": 0.717510998249054,
      "rewards/rejected": -0.2598232328891754,
      "step": 526
    },
    {
      "epoch": 0.2108,
      "grad_norm": 10.642383575439453,
      "learning_rate": 9.298666666666666e-07,
      "logits/chosen": -2.5028319358825684,
      "logits/rejected": -2.120818853378296,
      "logps/chosen": -90.37262725830078,
      "logps/rejected": -63.95268249511719,
      "loss": 0.3616,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6436840295791626,
      "rewards/margins": 0.8472145199775696,
      "rewards/rejected": -0.20353052020072937,
      "step": 527
    },
    {
      "epoch": 0.2112,
      "grad_norm": 10.661322593688965,
      "learning_rate": 9.297333333333333e-07,
      "logits/chosen": -2.429980754852295,
      "logits/rejected": -2.1665127277374268,
      "logps/chosen": -148.77891540527344,
      "logps/rejected": -101.80194091796875,
      "loss": 0.2949,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7761474847793579,
      "rewards/margins": 1.0782349109649658,
      "rewards/rejected": -0.3020873963832855,
      "step": 528
    },
    {
      "epoch": 0.2116,
      "grad_norm": 9.45925235748291,
      "learning_rate": 9.296e-07,
      "logits/chosen": -2.6065945625305176,
      "logits/rejected": -2.135225534439087,
      "logps/chosen": -88.46296691894531,
      "logps/rejected": -45.681034088134766,
      "loss": 0.3858,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6118713617324829,
      "rewards/margins": 0.771793007850647,
      "rewards/rejected": -0.15992164611816406,
      "step": 529
    },
    {
      "epoch": 0.212,
      "grad_norm": 10.744806289672852,
      "learning_rate": 9.294666666666667e-07,
      "logits/chosen": -2.5525825023651123,
      "logits/rejected": -3.1858115196228027,
      "logps/chosen": -132.05528259277344,
      "logps/rejected": -65.46015930175781,
      "loss": 0.372,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6187499761581421,
      "rewards/margins": 0.7975482940673828,
      "rewards/rejected": -0.17879830300807953,
      "step": 530
    },
    {
      "epoch": 0.2124,
      "grad_norm": 13.405501365661621,
      "learning_rate": 9.293333333333333e-07,
      "logits/chosen": -2.8327016830444336,
      "logits/rejected": -2.2728054523468018,
      "logps/chosen": -75.60957336425781,
      "logps/rejected": -56.548648834228516,
      "loss": 0.3482,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4131927490234375,
      "rewards/margins": 0.8771826028823853,
      "rewards/rejected": -0.46398985385894775,
      "step": 531
    },
    {
      "epoch": 0.2128,
      "grad_norm": 12.672419548034668,
      "learning_rate": 9.292e-07,
      "logits/chosen": -2.8044886589050293,
      "logits/rejected": -2.1894330978393555,
      "logps/chosen": -74.3377685546875,
      "logps/rejected": -80.01473999023438,
      "loss": 0.3663,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.397561252117157,
      "rewards/margins": 0.8330019116401672,
      "rewards/rejected": -0.43544065952301025,
      "step": 532
    },
    {
      "epoch": 0.2132,
      "grad_norm": 8.444952011108398,
      "learning_rate": 9.290666666666666e-07,
      "logits/chosen": -2.632986068725586,
      "logits/rejected": -2.2943975925445557,
      "logps/chosen": -103.53474426269531,
      "logps/rejected": -37.055824279785156,
      "loss": 0.3479,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6909168362617493,
      "rewards/margins": 0.8804985880851746,
      "rewards/rejected": -0.18958178162574768,
      "step": 533
    },
    {
      "epoch": 0.2136,
      "grad_norm": 10.371794700622559,
      "learning_rate": 9.289333333333333e-07,
      "logits/chosen": -2.562460422515869,
      "logits/rejected": -2.5904793739318848,
      "logps/chosen": -143.03477478027344,
      "logps/rejected": -65.42973327636719,
      "loss": 0.4453,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5075680017471313,
      "rewards/margins": 0.5860592126846313,
      "rewards/rejected": -0.0784912109375,
      "step": 534
    },
    {
      "epoch": 0.214,
      "grad_norm": 9.58436107635498,
      "learning_rate": 9.287999999999999e-07,
      "logits/chosen": -2.3909969329833984,
      "logits/rejected": -2.0910215377807617,
      "logps/chosen": -149.00485229492188,
      "logps/rejected": -67.77630615234375,
      "loss": 0.3641,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3780462443828583,
      "rewards/margins": 0.8586950302124023,
      "rewards/rejected": -0.48064881563186646,
      "step": 535
    },
    {
      "epoch": 0.2144,
      "grad_norm": 9.697052955627441,
      "learning_rate": 9.286666666666666e-07,
      "logits/chosen": -2.5992908477783203,
      "logits/rejected": -2.059518814086914,
      "logps/chosen": -129.02407836914062,
      "logps/rejected": -74.63674926757812,
      "loss": 0.2522,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8500492572784424,
      "rewards/margins": 1.2488338947296143,
      "rewards/rejected": -0.39878466725349426,
      "step": 536
    },
    {
      "epoch": 0.2148,
      "grad_norm": 10.371697425842285,
      "learning_rate": 9.285333333333333e-07,
      "logits/chosen": -2.602386474609375,
      "logits/rejected": -2.2976553440093994,
      "logps/chosen": -134.39419555664062,
      "logps/rejected": -85.46891784667969,
      "loss": 0.3482,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7357673645019531,
      "rewards/margins": 0.8811843991279602,
      "rewards/rejected": -0.14541703462600708,
      "step": 537
    },
    {
      "epoch": 0.2152,
      "grad_norm": 9.193082809448242,
      "learning_rate": 9.284e-07,
      "logits/chosen": -2.6767759323120117,
      "logits/rejected": -2.4921715259552,
      "logps/chosen": -137.36138916015625,
      "logps/rejected": -58.27528381347656,
      "loss": 0.378,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4396167993545532,
      "rewards/margins": 0.7855533361434937,
      "rewards/rejected": -0.3459365963935852,
      "step": 538
    },
    {
      "epoch": 0.2156,
      "grad_norm": 8.993059158325195,
      "learning_rate": 9.282666666666667e-07,
      "logits/chosen": -2.4628000259399414,
      "logits/rejected": -2.5863215923309326,
      "logps/chosen": -102.86016845703125,
      "logps/rejected": -35.942169189453125,
      "loss": 0.4122,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5329965949058533,
      "rewards/margins": 0.6823776960372925,
      "rewards/rejected": -0.14938107132911682,
      "step": 539
    },
    {
      "epoch": 0.216,
      "grad_norm": 15.208487510681152,
      "learning_rate": 9.281333333333334e-07,
      "logits/chosen": -2.5202465057373047,
      "logits/rejected": -2.4323208332061768,
      "logps/chosen": -142.55239868164062,
      "logps/rejected": -86.13630676269531,
      "loss": 0.391,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.857160210609436,
      "rewards/margins": 0.7991176843643188,
      "rewards/rejected": 0.058042529970407486,
      "step": 540
    },
    {
      "epoch": 0.2164,
      "grad_norm": 12.082764625549316,
      "learning_rate": 9.28e-07,
      "logits/chosen": -2.8797292709350586,
      "logits/rejected": -2.5625791549682617,
      "logps/chosen": -110.99430847167969,
      "logps/rejected": -60.301483154296875,
      "loss": 0.4287,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5119514465332031,
      "rewards/margins": 0.6748350262641907,
      "rewards/rejected": -0.16288356482982635,
      "step": 541
    },
    {
      "epoch": 0.2168,
      "grad_norm": 11.717619895935059,
      "learning_rate": 9.278666666666665e-07,
      "logits/chosen": -2.7058615684509277,
      "logits/rejected": -3.146732807159424,
      "logps/chosen": -90.80595397949219,
      "logps/rejected": -46.513702392578125,
      "loss": 0.4215,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31418800354003906,
      "rewards/margins": 0.6456911563873291,
      "rewards/rejected": -0.33150309324264526,
      "step": 542
    },
    {
      "epoch": 0.2172,
      "grad_norm": 10.914443016052246,
      "learning_rate": 9.277333333333332e-07,
      "logits/chosen": -2.915844440460205,
      "logits/rejected": -2.3445701599121094,
      "logps/chosen": -59.319908142089844,
      "logps/rejected": -65.16923522949219,
      "loss": 0.391,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12803535163402557,
      "rewards/margins": 0.7402504086494446,
      "rewards/rejected": -0.6122150421142578,
      "step": 543
    },
    {
      "epoch": 0.2176,
      "grad_norm": 9.968667984008789,
      "learning_rate": 9.275999999999999e-07,
      "logits/chosen": -2.9099066257476807,
      "logits/rejected": -2.9417991638183594,
      "logps/chosen": -125.99750518798828,
      "logps/rejected": -39.412635803222656,
      "loss": 0.3927,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5121902227401733,
      "rewards/margins": 0.747204601764679,
      "rewards/rejected": -0.23501434922218323,
      "step": 544
    },
    {
      "epoch": 0.218,
      "grad_norm": 10.551273345947266,
      "learning_rate": 9.274666666666666e-07,
      "logits/chosen": -2.568789005279541,
      "logits/rejected": -2.2321929931640625,
      "logps/chosen": -128.94134521484375,
      "logps/rejected": -91.1597900390625,
      "loss": 0.3309,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6324607729911804,
      "rewards/margins": 0.9845289587974548,
      "rewards/rejected": -0.35206812620162964,
      "step": 545
    },
    {
      "epoch": 0.2184,
      "grad_norm": 8.055283546447754,
      "learning_rate": 9.273333333333333e-07,
      "logits/chosen": -2.49639892578125,
      "logits/rejected": -2.445633888244629,
      "logps/chosen": -90.28211975097656,
      "logps/rejected": -65.52104187011719,
      "loss": 0.3247,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6926544308662415,
      "rewards/margins": 1.003480315208435,
      "rewards/rejected": -0.3108259439468384,
      "step": 546
    },
    {
      "epoch": 0.2188,
      "grad_norm": 11.280632972717285,
      "learning_rate": 9.272e-07,
      "logits/chosen": -2.3776931762695312,
      "logits/rejected": -1.929262399673462,
      "logps/chosen": -131.09432983398438,
      "logps/rejected": -157.525390625,
      "loss": 0.3323,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.584506630897522,
      "rewards/margins": 0.9372135400772095,
      "rewards/rejected": -0.3527069091796875,
      "step": 547
    },
    {
      "epoch": 0.2192,
      "grad_norm": 9.223603248596191,
      "learning_rate": 9.270666666666667e-07,
      "logits/chosen": -2.65126633644104,
      "logits/rejected": -2.3508894443511963,
      "logps/chosen": -67.5748519897461,
      "logps/rejected": -67.7556381225586,
      "loss": 0.4173,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35441702604293823,
      "rewards/margins": 0.6697547435760498,
      "rewards/rejected": -0.31533774733543396,
      "step": 548
    },
    {
      "epoch": 0.2196,
      "grad_norm": 9.696150779724121,
      "learning_rate": 9.269333333333334e-07,
      "logits/chosen": -2.331190586090088,
      "logits/rejected": -2.076488494873047,
      "logps/chosen": -142.9844970703125,
      "logps/rejected": -127.7051010131836,
      "loss": 0.2726,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9112319946289062,
      "rewards/margins": 1.160684585571289,
      "rewards/rejected": -0.2494525909423828,
      "step": 549
    },
    {
      "epoch": 0.22,
      "grad_norm": 9.433667182922363,
      "learning_rate": 9.268e-07,
      "logits/chosen": -2.6508142948150635,
      "logits/rejected": -2.335242748260498,
      "logps/chosen": -89.97872924804688,
      "logps/rejected": -70.43803405761719,
      "loss": 0.333,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6922109723091125,
      "rewards/margins": 0.9288370609283447,
      "rewards/rejected": -0.2366260588169098,
      "step": 550
    },
    {
      "epoch": 0.2204,
      "grad_norm": 8.211977005004883,
      "learning_rate": 9.266666666666665e-07,
      "logits/chosen": -2.4985880851745605,
      "logits/rejected": -2.2854509353637695,
      "logps/chosen": -115.02915954589844,
      "logps/rejected": -42.08000564575195,
      "loss": 0.3347,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7621318697929382,
      "rewards/margins": 0.9586296081542969,
      "rewards/rejected": -0.19649773836135864,
      "step": 551
    },
    {
      "epoch": 0.2208,
      "grad_norm": 10.675625801086426,
      "learning_rate": 9.265333333333332e-07,
      "logits/chosen": -2.6546273231506348,
      "logits/rejected": -2.358541488647461,
      "logps/chosen": -45.29705047607422,
      "logps/rejected": -39.8914680480957,
      "loss": 0.4811,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27524375915527344,
      "rewards/margins": 0.4814489483833313,
      "rewards/rejected": -0.20620518922805786,
      "step": 552
    },
    {
      "epoch": 0.2212,
      "grad_norm": 9.782800674438477,
      "learning_rate": 9.263999999999999e-07,
      "logits/chosen": -2.7782020568847656,
      "logits/rejected": -2.6865928173065186,
      "logps/chosen": -104.2918930053711,
      "logps/rejected": -62.148887634277344,
      "loss": 0.5175,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4447643458843231,
      "rewards/margins": 0.4014982581138611,
      "rewards/rejected": 0.04326610639691353,
      "step": 553
    },
    {
      "epoch": 0.2216,
      "grad_norm": 9.83926010131836,
      "learning_rate": 9.262666666666666e-07,
      "logits/chosen": -2.872434139251709,
      "logits/rejected": -2.4618568420410156,
      "logps/chosen": -32.028541564941406,
      "logps/rejected": -53.0254020690918,
      "loss": 0.3235,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3433145582675934,
      "rewards/margins": 1.023593783378601,
      "rewards/rejected": -0.6802792549133301,
      "step": 554
    },
    {
      "epoch": 0.222,
      "grad_norm": 8.981949806213379,
      "learning_rate": 9.261333333333333e-07,
      "logits/chosen": -2.5133602619171143,
      "logits/rejected": -2.4088401794433594,
      "logps/chosen": -91.21876525878906,
      "logps/rejected": -44.4903564453125,
      "loss": 0.3713,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5483570098876953,
      "rewards/margins": 0.84563809633255,
      "rewards/rejected": -0.29728108644485474,
      "step": 555
    },
    {
      "epoch": 0.2224,
      "grad_norm": 7.726439952850342,
      "learning_rate": 9.26e-07,
      "logits/chosen": -2.362436294555664,
      "logits/rejected": -1.9799302816390991,
      "logps/chosen": -164.139404296875,
      "logps/rejected": -62.03791046142578,
      "loss": 0.2089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0054874420166016,
      "rewards/margins": 1.460565209388733,
      "rewards/rejected": -0.45507773756980896,
      "step": 556
    },
    {
      "epoch": 0.2228,
      "grad_norm": 8.798055648803711,
      "learning_rate": 9.258666666666666e-07,
      "logits/chosen": -2.4999427795410156,
      "logits/rejected": -2.1421802043914795,
      "logps/chosen": -135.14390563964844,
      "logps/rejected": -64.10431671142578,
      "loss": 0.3374,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6006458401679993,
      "rewards/margins": 0.928972065448761,
      "rewards/rejected": -0.3283262252807617,
      "step": 557
    },
    {
      "epoch": 0.2232,
      "grad_norm": 10.081747055053711,
      "learning_rate": 9.257333333333333e-07,
      "logits/chosen": -3.0221266746520996,
      "logits/rejected": -2.3477556705474854,
      "logps/chosen": -47.755592346191406,
      "logps/rejected": -77.81652069091797,
      "loss": 0.3375,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.29016056656837463,
      "rewards/margins": 0.9422423839569092,
      "rewards/rejected": -0.6520818471908569,
      "step": 558
    },
    {
      "epoch": 0.2236,
      "grad_norm": 8.512816429138184,
      "learning_rate": 9.256e-07,
      "logits/chosen": -2.6664180755615234,
      "logits/rejected": -2.637183666229248,
      "logps/chosen": -77.05005645751953,
      "logps/rejected": -40.95585250854492,
      "loss": 0.4886,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23867416381835938,
      "rewards/margins": 0.47109243273735046,
      "rewards/rejected": -0.2324182540178299,
      "step": 559
    },
    {
      "epoch": 0.224,
      "grad_norm": 8.875387191772461,
      "learning_rate": 9.254666666666667e-07,
      "logits/chosen": -2.5560173988342285,
      "logits/rejected": -2.441575050354004,
      "logps/chosen": -105.6398696899414,
      "logps/rejected": -37.18523406982422,
      "loss": 0.4454,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5509389042854309,
      "rewards/margins": 0.6611952781677246,
      "rewards/rejected": -0.1102563887834549,
      "step": 560
    },
    {
      "epoch": 0.2244,
      "grad_norm": 7.924435138702393,
      "learning_rate": 9.253333333333333e-07,
      "logits/chosen": -2.614771842956543,
      "logits/rejected": -2.583667039871216,
      "logps/chosen": -72.9081039428711,
      "logps/rejected": -51.98333740234375,
      "loss": 0.4411,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.427560031414032,
      "rewards/margins": 0.6135739088058472,
      "rewards/rejected": -0.18601389229297638,
      "step": 561
    },
    {
      "epoch": 0.2248,
      "grad_norm": 8.862391471862793,
      "learning_rate": 9.251999999999999e-07,
      "logits/chosen": -2.5736217498779297,
      "logits/rejected": -2.3063805103302,
      "logps/chosen": -97.48020935058594,
      "logps/rejected": -76.2987060546875,
      "loss": 0.3394,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7301521301269531,
      "rewards/margins": 0.9786207675933838,
      "rewards/rejected": -0.24846859276294708,
      "step": 562
    },
    {
      "epoch": 0.2252,
      "grad_norm": 11.683867454528809,
      "learning_rate": 9.250666666666666e-07,
      "logits/chosen": -2.5039663314819336,
      "logits/rejected": -2.2631778717041016,
      "logps/chosen": -88.65534973144531,
      "logps/rejected": -128.00296020507812,
      "loss": 0.3513,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6193397641181946,
      "rewards/margins": 0.8681471347808838,
      "rewards/rejected": -0.24880734086036682,
      "step": 563
    },
    {
      "epoch": 0.2256,
      "grad_norm": 8.85169506072998,
      "learning_rate": 9.249333333333333e-07,
      "logits/chosen": -2.8346633911132812,
      "logits/rejected": -2.7309787273406982,
      "logps/chosen": -62.01713180541992,
      "logps/rejected": -56.33416748046875,
      "loss": 0.4159,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.43037912249565125,
      "rewards/margins": 0.6627048850059509,
      "rewards/rejected": -0.2323257476091385,
      "step": 564
    },
    {
      "epoch": 0.226,
      "grad_norm": 8.083284378051758,
      "learning_rate": 9.247999999999999e-07,
      "logits/chosen": -2.3496572971343994,
      "logits/rejected": -2.1283349990844727,
      "logps/chosen": -186.81365966796875,
      "logps/rejected": -59.62099838256836,
      "loss": 0.2239,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.027788519859314,
      "rewards/margins": 1.3918144702911377,
      "rewards/rejected": -0.36402589082717896,
      "step": 565
    },
    {
      "epoch": 0.2264,
      "grad_norm": 8.075852394104004,
      "learning_rate": 9.246666666666666e-07,
      "logits/chosen": -3.072587251663208,
      "logits/rejected": -2.617614269256592,
      "logps/chosen": -44.50928497314453,
      "logps/rejected": -59.74760818481445,
      "loss": 0.3406,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.29321175813674927,
      "rewards/margins": 0.9234702587127686,
      "rewards/rejected": -0.6302585601806641,
      "step": 566
    },
    {
      "epoch": 0.2268,
      "grad_norm": 8.997126579284668,
      "learning_rate": 9.245333333333333e-07,
      "logits/chosen": -2.8460724353790283,
      "logits/rejected": -2.4103779792785645,
      "logps/chosen": -82.25042724609375,
      "logps/rejected": -34.313358306884766,
      "loss": 0.4178,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40829142928123474,
      "rewards/margins": 0.6591798067092896,
      "rewards/rejected": -0.2508883476257324,
      "step": 567
    },
    {
      "epoch": 0.2272,
      "grad_norm": 9.417064666748047,
      "learning_rate": 9.244e-07,
      "logits/chosen": -2.8846089839935303,
      "logits/rejected": -2.1892008781433105,
      "logps/chosen": -52.051151275634766,
      "logps/rejected": -60.25717544555664,
      "loss": 0.5051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2701210081577301,
      "rewards/margins": 0.4227054715156555,
      "rewards/rejected": -0.15258446335792542,
      "step": 568
    },
    {
      "epoch": 0.2276,
      "grad_norm": 10.837132453918457,
      "learning_rate": 9.242666666666667e-07,
      "logits/chosen": -2.345250129699707,
      "logits/rejected": -2.2767446041107178,
      "logps/chosen": -98.84622192382812,
      "logps/rejected": -103.19805908203125,
      "loss": 0.3303,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4593002200126648,
      "rewards/margins": 0.939243733882904,
      "rewards/rejected": -0.4799434542655945,
      "step": 569
    },
    {
      "epoch": 0.228,
      "grad_norm": 8.973097801208496,
      "learning_rate": 9.241333333333333e-07,
      "logits/chosen": -2.766441822052002,
      "logits/rejected": -2.7123870849609375,
      "logps/chosen": -117.57847595214844,
      "logps/rejected": -52.58989334106445,
      "loss": 0.3229,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5902286767959595,
      "rewards/margins": 0.974552571773529,
      "rewards/rejected": -0.3843238949775696,
      "step": 570
    },
    {
      "epoch": 0.2284,
      "grad_norm": 9.640320777893066,
      "learning_rate": 9.24e-07,
      "logits/chosen": -2.656247615814209,
      "logits/rejected": -2.083434581756592,
      "logps/chosen": -104.05104064941406,
      "logps/rejected": -79.61798858642578,
      "loss": 0.3759,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3173046112060547,
      "rewards/margins": 0.8026891946792603,
      "rewards/rejected": -0.48538458347320557,
      "step": 571
    },
    {
      "epoch": 0.2288,
      "grad_norm": 9.168146133422852,
      "learning_rate": 9.238666666666665e-07,
      "logits/chosen": -2.730559825897217,
      "logits/rejected": -2.5755553245544434,
      "logps/chosen": -56.70951843261719,
      "logps/rejected": -59.06336212158203,
      "loss": 0.425,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2623407542705536,
      "rewards/margins": 0.6459321975708008,
      "rewards/rejected": -0.3835914731025696,
      "step": 572
    },
    {
      "epoch": 0.2292,
      "grad_norm": 10.361621856689453,
      "learning_rate": 9.237333333333332e-07,
      "logits/chosen": -2.5107154846191406,
      "logits/rejected": -2.7495064735412598,
      "logps/chosen": -101.27367401123047,
      "logps/rejected": -45.80467224121094,
      "loss": 0.4087,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38364487886428833,
      "rewards/margins": 0.6837542057037354,
      "rewards/rejected": -0.30010929703712463,
      "step": 573
    },
    {
      "epoch": 0.2296,
      "grad_norm": 11.019545555114746,
      "learning_rate": 9.235999999999999e-07,
      "logits/chosen": -2.7513601779937744,
      "logits/rejected": -2.5164570808410645,
      "logps/chosen": -111.62742614746094,
      "logps/rejected": -41.17027282714844,
      "loss": 0.511,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24260330200195312,
      "rewards/margins": 0.4193143844604492,
      "rewards/rejected": -0.1767110824584961,
      "step": 574
    },
    {
      "epoch": 0.23,
      "grad_norm": 11.26042652130127,
      "learning_rate": 9.234666666666666e-07,
      "logits/chosen": -2.619307279586792,
      "logits/rejected": -2.486135959625244,
      "logps/chosen": -144.59878540039062,
      "logps/rejected": -70.34673309326172,
      "loss": 0.3837,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4610763490200043,
      "rewards/margins": 0.7600795030593872,
      "rewards/rejected": -0.29900312423706055,
      "step": 575
    },
    {
      "epoch": 0.2304,
      "grad_norm": 9.609829902648926,
      "learning_rate": 9.233333333333333e-07,
      "logits/chosen": -2.5427658557891846,
      "logits/rejected": -2.6684017181396484,
      "logps/chosen": -73.65516662597656,
      "logps/rejected": -52.93900680541992,
      "loss": 0.3452,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5588493347167969,
      "rewards/margins": 0.8957480192184448,
      "rewards/rejected": -0.33689871430397034,
      "step": 576
    },
    {
      "epoch": 0.2308,
      "grad_norm": 7.9184770584106445,
      "learning_rate": 9.232e-07,
      "logits/chosen": -2.701423168182373,
      "logits/rejected": -2.2235026359558105,
      "logps/chosen": -83.20405578613281,
      "logps/rejected": -62.41786193847656,
      "loss": 0.3686,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5273306369781494,
      "rewards/margins": 0.8310141563415527,
      "rewards/rejected": -0.30368348956108093,
      "step": 577
    },
    {
      "epoch": 0.2312,
      "grad_norm": 8.262243270874023,
      "learning_rate": 9.230666666666667e-07,
      "logits/chosen": -2.750993251800537,
      "logits/rejected": -2.638631820678711,
      "logps/chosen": -61.148475646972656,
      "logps/rejected": -36.02058792114258,
      "loss": 0.3805,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3425121307373047,
      "rewards/margins": 0.7716529965400696,
      "rewards/rejected": -0.4291408658027649,
      "step": 578
    },
    {
      "epoch": 0.2316,
      "grad_norm": 8.76118278503418,
      "learning_rate": 9.229333333333334e-07,
      "logits/chosen": -2.675917148590088,
      "logits/rejected": -2.696608066558838,
      "logps/chosen": -110.14372253417969,
      "logps/rejected": -72.77377319335938,
      "loss": 0.3155,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.558092474937439,
      "rewards/margins": 1.0521292686462402,
      "rewards/rejected": -0.4940366744995117,
      "step": 579
    },
    {
      "epoch": 0.232,
      "grad_norm": 8.510544776916504,
      "learning_rate": 9.227999999999999e-07,
      "logits/chosen": -2.269947052001953,
      "logits/rejected": -1.9070076942443848,
      "logps/chosen": -112.21769714355469,
      "logps/rejected": -133.05738830566406,
      "loss": 0.2066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9396560788154602,
      "rewards/margins": 1.4784393310546875,
      "rewards/rejected": -0.5387833118438721,
      "step": 580
    },
    {
      "epoch": 0.2324,
      "grad_norm": 9.684575080871582,
      "learning_rate": 9.226666666666666e-07,
      "logits/chosen": -2.8300397396087646,
      "logits/rejected": -2.5658180713653564,
      "logps/chosen": -57.15336990356445,
      "logps/rejected": -39.75598907470703,
      "loss": 0.5083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1626560240983963,
      "rewards/margins": 0.4156538248062134,
      "rewards/rejected": -0.2529977858066559,
      "step": 581
    },
    {
      "epoch": 0.2328,
      "grad_norm": 11.151180267333984,
      "learning_rate": 9.225333333333333e-07,
      "logits/chosen": -2.645451068878174,
      "logits/rejected": -2.4476990699768066,
      "logps/chosen": -52.95248794555664,
      "logps/rejected": -68.38308715820312,
      "loss": 0.4737,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08369521796703339,
      "rewards/margins": 0.5126224756240845,
      "rewards/rejected": -0.4289272427558899,
      "step": 582
    },
    {
      "epoch": 0.2332,
      "grad_norm": 9.83739185333252,
      "learning_rate": 9.224e-07,
      "logits/chosen": -2.750683546066284,
      "logits/rejected": -2.5607593059539795,
      "logps/chosen": -90.75126647949219,
      "logps/rejected": -63.836063385009766,
      "loss": 0.3786,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5408813953399658,
      "rewards/margins": 0.7759864926338196,
      "rewards/rejected": -0.23510512709617615,
      "step": 583
    },
    {
      "epoch": 0.2336,
      "grad_norm": 10.242317199707031,
      "learning_rate": 9.222666666666666e-07,
      "logits/chosen": -2.3232102394104004,
      "logits/rejected": -2.2141947746276855,
      "logps/chosen": -98.89581298828125,
      "logps/rejected": -70.38890075683594,
      "loss": 0.361,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6203243732452393,
      "rewards/margins": 0.8470876812934875,
      "rewards/rejected": -0.22676333785057068,
      "step": 584
    },
    {
      "epoch": 0.234,
      "grad_norm": 8.608278274536133,
      "learning_rate": 9.221333333333333e-07,
      "logits/chosen": -2.677412271499634,
      "logits/rejected": -2.321073532104492,
      "logps/chosen": -99.183349609375,
      "logps/rejected": -51.52027130126953,
      "loss": 0.2661,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.796643853187561,
      "rewards/margins": 1.2510700225830078,
      "rewards/rejected": -0.45442619919776917,
      "step": 585
    },
    {
      "epoch": 0.2344,
      "grad_norm": 10.07006549835205,
      "learning_rate": 9.22e-07,
      "logits/chosen": -2.421802043914795,
      "logits/rejected": -2.063913106918335,
      "logps/chosen": -175.72573852539062,
      "logps/rejected": -58.069740295410156,
      "loss": 0.3412,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6978393793106079,
      "rewards/margins": 0.9009981155395508,
      "rewards/rejected": -0.20315876603126526,
      "step": 586
    },
    {
      "epoch": 0.2348,
      "grad_norm": 9.336174011230469,
      "learning_rate": 9.218666666666666e-07,
      "logits/chosen": -2.57603120803833,
      "logits/rejected": -2.3485360145568848,
      "logps/chosen": -119.40777587890625,
      "logps/rejected": -57.08525085449219,
      "loss": 0.3941,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5909259915351868,
      "rewards/margins": 0.757358968257904,
      "rewards/rejected": -0.1664329469203949,
      "step": 587
    },
    {
      "epoch": 0.2352,
      "grad_norm": 9.082984924316406,
      "learning_rate": 9.217333333333333e-07,
      "logits/chosen": -2.589860439300537,
      "logits/rejected": -2.450615406036377,
      "logps/chosen": -99.02651977539062,
      "logps/rejected": -62.400447845458984,
      "loss": 0.3723,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7087696194648743,
      "rewards/margins": 0.8115299344062805,
      "rewards/rejected": -0.10276031494140625,
      "step": 588
    },
    {
      "epoch": 0.2356,
      "grad_norm": 8.650897979736328,
      "learning_rate": 9.215999999999999e-07,
      "logits/chosen": -2.1698246002197266,
      "logits/rejected": -2.2269158363342285,
      "logps/chosen": -140.97000122070312,
      "logps/rejected": -56.51960372924805,
      "loss": 0.2509,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9905780553817749,
      "rewards/margins": 1.2565014362335205,
      "rewards/rejected": -0.26592332124710083,
      "step": 589
    },
    {
      "epoch": 0.236,
      "grad_norm": 7.748190402984619,
      "learning_rate": 9.214666666666666e-07,
      "logits/chosen": -2.866525173187256,
      "logits/rejected": -2.5847702026367188,
      "logps/chosen": -65.63835906982422,
      "logps/rejected": -38.17726135253906,
      "loss": 0.3819,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.47564947605133057,
      "rewards/margins": 0.7660067677497864,
      "rewards/rejected": -0.2903573215007782,
      "step": 590
    },
    {
      "epoch": 0.2364,
      "grad_norm": 10.143953323364258,
      "learning_rate": 9.213333333333333e-07,
      "logits/chosen": -2.699767589569092,
      "logits/rejected": -3.044283390045166,
      "logps/chosen": -94.80950927734375,
      "logps/rejected": -45.42325210571289,
      "loss": 0.4402,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5271263122558594,
      "rewards/margins": 0.6092917919158936,
      "rewards/rejected": -0.0821654349565506,
      "step": 591
    },
    {
      "epoch": 0.2368,
      "grad_norm": 9.23677921295166,
      "learning_rate": 9.212e-07,
      "logits/chosen": -2.7172441482543945,
      "logits/rejected": -2.477719306945801,
      "logps/chosen": -90.97078704833984,
      "logps/rejected": -53.60137176513672,
      "loss": 0.3402,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2418634444475174,
      "rewards/margins": 0.9206593036651611,
      "rewards/rejected": -0.6787958145141602,
      "step": 592
    },
    {
      "epoch": 0.2372,
      "grad_norm": 9.687689781188965,
      "learning_rate": 9.210666666666667e-07,
      "logits/chosen": -2.664828062057495,
      "logits/rejected": -2.022095203399658,
      "logps/chosen": -121.87980651855469,
      "logps/rejected": -68.47669219970703,
      "loss": 0.3122,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7894737720489502,
      "rewards/margins": 1.0913100242614746,
      "rewards/rejected": -0.301836222410202,
      "step": 593
    },
    {
      "epoch": 0.2376,
      "grad_norm": 8.98975944519043,
      "learning_rate": 9.209333333333333e-07,
      "logits/chosen": -2.645183563232422,
      "logits/rejected": -2.226076126098633,
      "logps/chosen": -123.06879425048828,
      "logps/rejected": -105.07513427734375,
      "loss": 0.274,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0509223937988281,
      "rewards/margins": 1.2148951292037964,
      "rewards/rejected": -0.1639726758003235,
      "step": 594
    },
    {
      "epoch": 0.238,
      "grad_norm": 8.552406311035156,
      "learning_rate": 9.207999999999999e-07,
      "logits/chosen": -2.863283395767212,
      "logits/rejected": -2.3875107765197754,
      "logps/chosen": -60.2899055480957,
      "logps/rejected": -64.74078369140625,
      "loss": 0.3899,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3580320477485657,
      "rewards/margins": 0.7404987812042236,
      "rewards/rejected": -0.38246670365333557,
      "step": 595
    },
    {
      "epoch": 0.2384,
      "grad_norm": 7.362250328063965,
      "learning_rate": 9.206666666666666e-07,
      "logits/chosen": -2.7197771072387695,
      "logits/rejected": -2.284691333770752,
      "logps/chosen": -83.6604232788086,
      "logps/rejected": -56.71753692626953,
      "loss": 0.3183,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6123590469360352,
      "rewards/margins": 0.9960304498672485,
      "rewards/rejected": -0.3836714029312134,
      "step": 596
    },
    {
      "epoch": 0.2388,
      "grad_norm": 9.327925682067871,
      "learning_rate": 9.205333333333333e-07,
      "logits/chosen": -2.5408356189727783,
      "logits/rejected": -2.3306658267974854,
      "logps/chosen": -123.79551696777344,
      "logps/rejected": -74.320556640625,
      "loss": 0.2642,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6998794674873352,
      "rewards/margins": 1.2378867864608765,
      "rewards/rejected": -0.538007378578186,
      "step": 597
    },
    {
      "epoch": 0.2392,
      "grad_norm": 8.507866859436035,
      "learning_rate": 9.203999999999999e-07,
      "logits/chosen": -2.6897497177124023,
      "logits/rejected": -2.1345720291137695,
      "logps/chosen": -68.50732421875,
      "logps/rejected": -45.04315948486328,
      "loss": 0.3603,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40208569169044495,
      "rewards/margins": 0.855076789855957,
      "rewards/rejected": -0.4529911279678345,
      "step": 598
    },
    {
      "epoch": 0.2396,
      "grad_norm": 8.604852676391602,
      "learning_rate": 9.202666666666666e-07,
      "logits/chosen": -2.534822463989258,
      "logits/rejected": -2.978665828704834,
      "logps/chosen": -94.54915618896484,
      "logps/rejected": -83.61782836914062,
      "loss": 0.306,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7811207175254822,
      "rewards/margins": 1.074662446975708,
      "rewards/rejected": -0.29354172945022583,
      "step": 599
    },
    {
      "epoch": 0.24,
      "grad_norm": 11.841209411621094,
      "learning_rate": 9.201333333333333e-07,
      "logits/chosen": -2.233628273010254,
      "logits/rejected": -2.2578208446502686,
      "logps/chosen": -184.9500732421875,
      "logps/rejected": -80.5848159790039,
      "loss": 0.3288,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.698412299156189,
      "rewards/margins": 0.9646259546279907,
      "rewards/rejected": -0.26621362566947937,
      "step": 600
    },
    {
      "epoch": 0.2404,
      "grad_norm": 8.395668983459473,
      "learning_rate": 9.2e-07,
      "logits/chosen": -2.4764280319213867,
      "logits/rejected": -2.1497507095336914,
      "logps/chosen": -89.65589141845703,
      "logps/rejected": -87.68028259277344,
      "loss": 0.2909,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7089164853096008,
      "rewards/margins": 1.0894742012023926,
      "rewards/rejected": -0.380557656288147,
      "step": 601
    },
    {
      "epoch": 0.2408,
      "grad_norm": 8.813131332397461,
      "learning_rate": 9.198666666666667e-07,
      "logits/chosen": -2.5925145149230957,
      "logits/rejected": -2.4430603981018066,
      "logps/chosen": -146.55523681640625,
      "logps/rejected": -47.06536102294922,
      "loss": 0.3272,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5689842700958252,
      "rewards/margins": 0.9800231456756592,
      "rewards/rejected": -0.411038875579834,
      "step": 602
    },
    {
      "epoch": 0.2412,
      "grad_norm": 7.521176815032959,
      "learning_rate": 9.197333333333333e-07,
      "logits/chosen": -2.618198871612549,
      "logits/rejected": -2.0756704807281494,
      "logps/chosen": -77.95329284667969,
      "logps/rejected": -81.30647277832031,
      "loss": 0.2382,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8319091796875,
      "rewards/margins": 1.3340954780578613,
      "rewards/rejected": -0.5021862387657166,
      "step": 603
    },
    {
      "epoch": 0.2416,
      "grad_norm": 9.001187324523926,
      "learning_rate": 9.196e-07,
      "logits/chosen": -2.5032410621643066,
      "logits/rejected": -2.01473069190979,
      "logps/chosen": -89.81489562988281,
      "logps/rejected": -87.71601867675781,
      "loss": 0.3288,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5692951679229736,
      "rewards/margins": 0.9441006183624268,
      "rewards/rejected": -0.3748054504394531,
      "step": 604
    },
    {
      "epoch": 0.242,
      "grad_norm": 12.344193458557129,
      "learning_rate": 9.194666666666666e-07,
      "logits/chosen": -2.4911937713623047,
      "logits/rejected": -2.2364141941070557,
      "logps/chosen": -96.00737762451172,
      "logps/rejected": -75.08281707763672,
      "loss": 0.3364,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.37326890230178833,
      "rewards/margins": 0.9314597845077515,
      "rewards/rejected": -0.5581909418106079,
      "step": 605
    },
    {
      "epoch": 0.2424,
      "grad_norm": 8.476434707641602,
      "learning_rate": 9.193333333333333e-07,
      "logits/chosen": -2.50289249420166,
      "logits/rejected": -2.026719570159912,
      "logps/chosen": -78.08049011230469,
      "logps/rejected": -106.25448608398438,
      "loss": 0.2969,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5490951538085938,
      "rewards/margins": 1.0767688751220703,
      "rewards/rejected": -0.5276737213134766,
      "step": 606
    },
    {
      "epoch": 0.2428,
      "grad_norm": 10.327555656433105,
      "learning_rate": 9.192e-07,
      "logits/chosen": -2.605067253112793,
      "logits/rejected": -2.2532246112823486,
      "logps/chosen": -52.009864807128906,
      "logps/rejected": -65.531494140625,
      "loss": 0.3533,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35399073362350464,
      "rewards/margins": 0.8586366772651672,
      "rewards/rejected": -0.5046459436416626,
      "step": 607
    },
    {
      "epoch": 0.2432,
      "grad_norm": 8.536174774169922,
      "learning_rate": 9.190666666666666e-07,
      "logits/chosen": -2.883713722229004,
      "logits/rejected": -2.514157295227051,
      "logps/chosen": -82.62760925292969,
      "logps/rejected": -57.11970520019531,
      "loss": 0.3711,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6119903326034546,
      "rewards/margins": 0.828565239906311,
      "rewards/rejected": -0.21657486259937286,
      "step": 608
    },
    {
      "epoch": 0.2436,
      "grad_norm": 8.809955596923828,
      "learning_rate": 9.189333333333333e-07,
      "logits/chosen": -2.5584096908569336,
      "logits/rejected": -2.5609569549560547,
      "logps/chosen": -81.31031799316406,
      "logps/rejected": -52.80962371826172,
      "loss": 0.4589,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4412528872489929,
      "rewards/margins": 0.5413472056388855,
      "rewards/rejected": -0.10009431838989258,
      "step": 609
    },
    {
      "epoch": 0.244,
      "grad_norm": 9.924948692321777,
      "learning_rate": 9.187999999999999e-07,
      "logits/chosen": -2.632695198059082,
      "logits/rejected": -2.3646135330200195,
      "logps/chosen": -94.4083251953125,
      "logps/rejected": -91.08122253417969,
      "loss": 0.3116,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6765373349189758,
      "rewards/margins": 1.075402021408081,
      "rewards/rejected": -0.39886474609375,
      "step": 610
    },
    {
      "epoch": 0.2444,
      "grad_norm": 7.543135166168213,
      "learning_rate": 9.186666666666666e-07,
      "logits/chosen": -2.8234944343566895,
      "logits/rejected": -2.8700976371765137,
      "logps/chosen": -115.10539245605469,
      "logps/rejected": -44.51499938964844,
      "loss": 0.2448,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6509335041046143,
      "rewards/margins": 1.2983413934707642,
      "rewards/rejected": -0.6474078893661499,
      "step": 611
    },
    {
      "epoch": 0.2448,
      "grad_norm": 7.883805274963379,
      "learning_rate": 9.185333333333333e-07,
      "logits/chosen": -2.6933979988098145,
      "logits/rejected": -2.651988983154297,
      "logps/chosen": -104.35124206542969,
      "logps/rejected": -55.746337890625,
      "loss": 0.4197,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6355075836181641,
      "rewards/margins": 0.799838662147522,
      "rewards/rejected": -0.16433104872703552,
      "step": 612
    },
    {
      "epoch": 0.2452,
      "grad_norm": 8.62529182434082,
      "learning_rate": 9.184e-07,
      "logits/chosen": -2.3124632835388184,
      "logits/rejected": -2.0806097984313965,
      "logps/chosen": -117.92573547363281,
      "logps/rejected": -70.99585723876953,
      "loss": 0.2719,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.039859414100647,
      "rewards/margins": 1.1878652572631836,
      "rewards/rejected": -0.14800585806369781,
      "step": 613
    },
    {
      "epoch": 0.2456,
      "grad_norm": 8.287251472473145,
      "learning_rate": 9.182666666666667e-07,
      "logits/chosen": -2.5342211723327637,
      "logits/rejected": -2.2941946983337402,
      "logps/chosen": -73.1563949584961,
      "logps/rejected": -71.36193084716797,
      "loss": 0.2918,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9790695905685425,
      "rewards/margins": 1.213974952697754,
      "rewards/rejected": -0.2349054366350174,
      "step": 614
    },
    {
      "epoch": 0.246,
      "grad_norm": 9.9542236328125,
      "learning_rate": 9.181333333333333e-07,
      "logits/chosen": -2.631413459777832,
      "logits/rejected": -2.3010079860687256,
      "logps/chosen": -93.22638702392578,
      "logps/rejected": -42.43943786621094,
      "loss": 0.3889,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4178127348423004,
      "rewards/margins": 0.7444473505020142,
      "rewards/rejected": -0.32663458585739136,
      "step": 615
    },
    {
      "epoch": 0.2464,
      "grad_norm": 12.576099395751953,
      "learning_rate": 9.18e-07,
      "logits/chosen": -2.6229965686798096,
      "logits/rejected": -2.5977392196655273,
      "logps/chosen": -67.91027069091797,
      "logps/rejected": -83.6396484375,
      "loss": 0.3951,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4435417354106903,
      "rewards/margins": 0.7686561942100525,
      "rewards/rejected": -0.3251144587993622,
      "step": 616
    },
    {
      "epoch": 0.2468,
      "grad_norm": 9.847921371459961,
      "learning_rate": 9.178666666666666e-07,
      "logits/chosen": -2.354689598083496,
      "logits/rejected": -2.2867228984832764,
      "logps/chosen": -105.42987060546875,
      "logps/rejected": -52.217796325683594,
      "loss": 0.298,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7775192260742188,
      "rewards/margins": 1.0590574741363525,
      "rewards/rejected": -0.281538188457489,
      "step": 617
    },
    {
      "epoch": 0.2472,
      "grad_norm": 10.298160552978516,
      "learning_rate": 9.177333333333332e-07,
      "logits/chosen": -3.0095129013061523,
      "logits/rejected": -2.411360740661621,
      "logps/chosen": -64.57463836669922,
      "logps/rejected": -56.17361068725586,
      "loss": 0.3925,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27120381593704224,
      "rewards/margins": 0.7472712993621826,
      "rewards/rejected": -0.47606754302978516,
      "step": 618
    },
    {
      "epoch": 0.2476,
      "grad_norm": 6.817875862121582,
      "learning_rate": 9.175999999999999e-07,
      "logits/chosen": -2.503983974456787,
      "logits/rejected": -2.2827301025390625,
      "logps/chosen": -122.9652328491211,
      "logps/rejected": -56.780914306640625,
      "loss": 0.2465,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7764434814453125,
      "rewards/margins": 1.2753139734268188,
      "rewards/rejected": -0.49887049198150635,
      "step": 619
    },
    {
      "epoch": 0.248,
      "grad_norm": 8.195846557617188,
      "learning_rate": 9.174666666666666e-07,
      "logits/chosen": -2.362204074859619,
      "logits/rejected": -2.0227205753326416,
      "logps/chosen": -79.98100280761719,
      "logps/rejected": -63.05207061767578,
      "loss": 0.2537,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8812141418457031,
      "rewards/margins": 1.2428104877471924,
      "rewards/rejected": -0.36159631609916687,
      "step": 620
    },
    {
      "epoch": 0.2484,
      "grad_norm": 9.703004837036133,
      "learning_rate": 9.173333333333333e-07,
      "logits/chosen": -2.5012993812561035,
      "logits/rejected": -1.98103666305542,
      "logps/chosen": -52.197052001953125,
      "logps/rejected": -74.4930191040039,
      "loss": 0.2695,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3894897401332855,
      "rewards/margins": 1.2220646142959595,
      "rewards/rejected": -0.8325748443603516,
      "step": 621
    },
    {
      "epoch": 0.2488,
      "grad_norm": 7.573694229125977,
      "learning_rate": 9.172e-07,
      "logits/chosen": -2.8803815841674805,
      "logits/rejected": -2.1222667694091797,
      "logps/chosen": -61.67554473876953,
      "logps/rejected": -91.81466674804688,
      "loss": 0.2433,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.30693721771240234,
      "rewards/margins": 1.353043556213379,
      "rewards/rejected": -1.0461063385009766,
      "step": 622
    },
    {
      "epoch": 0.2492,
      "grad_norm": 9.021903991699219,
      "learning_rate": 9.170666666666667e-07,
      "logits/chosen": -2.6738243103027344,
      "logits/rejected": -2.4698867797851562,
      "logps/chosen": -84.3331069946289,
      "logps/rejected": -46.0732421875,
      "loss": 0.4213,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33143290877342224,
      "rewards/margins": 0.6789277791976929,
      "rewards/rejected": -0.34749487042427063,
      "step": 623
    },
    {
      "epoch": 0.2496,
      "grad_norm": 9.119163513183594,
      "learning_rate": 9.169333333333334e-07,
      "logits/chosen": -2.819085121154785,
      "logits/rejected": -2.3262388706207275,
      "logps/chosen": -63.59851837158203,
      "logps/rejected": -61.740840911865234,
      "loss": 0.2486,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38737985491752625,
      "rewards/margins": 1.284256935119629,
      "rewards/rejected": -0.896877110004425,
      "step": 624
    },
    {
      "epoch": 0.25,
      "grad_norm": 7.980232238769531,
      "learning_rate": 9.168e-07,
      "logits/chosen": -2.4886252880096436,
      "logits/rejected": -2.5243372917175293,
      "logps/chosen": -99.39308166503906,
      "logps/rejected": -50.51191711425781,
      "loss": 0.3554,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4517694413661957,
      "rewards/margins": 0.9577934145927429,
      "rewards/rejected": -0.5060240030288696,
      "step": 625
    },
    {
      "epoch": 0.2504,
      "grad_norm": 7.1582560539245605,
      "learning_rate": 9.166666666666665e-07,
      "logits/chosen": -2.70917010307312,
      "logits/rejected": -2.5017900466918945,
      "logps/chosen": -102.36439514160156,
      "logps/rejected": -65.41534423828125,
      "loss": 0.2541,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8500602841377258,
      "rewards/margins": 1.2401199340820312,
      "rewards/rejected": -0.3900596797466278,
      "step": 626
    },
    {
      "epoch": 0.2508,
      "grad_norm": 13.274852752685547,
      "learning_rate": 9.165333333333332e-07,
      "logits/chosen": -2.5816311836242676,
      "logits/rejected": -2.5111746788024902,
      "logps/chosen": -189.15298461914062,
      "logps/rejected": -60.78033447265625,
      "loss": 0.3726,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42842331528663635,
      "rewards/margins": 0.8097547888755798,
      "rewards/rejected": -0.3813314437866211,
      "step": 627
    },
    {
      "epoch": 0.2512,
      "grad_norm": 9.158985137939453,
      "learning_rate": 9.163999999999999e-07,
      "logits/chosen": -2.7248611450195312,
      "logits/rejected": -2.593332290649414,
      "logps/chosen": -67.5179443359375,
      "logps/rejected": -48.259639739990234,
      "loss": 0.4152,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.348846435546875,
      "rewards/margins": 0.7938475012779236,
      "rewards/rejected": -0.4450010359287262,
      "step": 628
    },
    {
      "epoch": 0.2516,
      "grad_norm": 7.527793884277344,
      "learning_rate": 9.162666666666666e-07,
      "logits/chosen": -2.4645304679870605,
      "logits/rejected": -2.0602669715881348,
      "logps/chosen": -161.92276000976562,
      "logps/rejected": -86.97877502441406,
      "loss": 0.1917,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2325654029846191,
      "rewards/margins": 1.5664901733398438,
      "rewards/rejected": -0.33392488956451416,
      "step": 629
    },
    {
      "epoch": 0.252,
      "grad_norm": 9.733514785766602,
      "learning_rate": 9.161333333333333e-07,
      "logits/chosen": -2.888111114501953,
      "logits/rejected": -2.336261510848999,
      "logps/chosen": -73.48503112792969,
      "logps/rejected": -52.889076232910156,
      "loss": 0.3639,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38738173246383667,
      "rewards/margins": 0.8454164862632751,
      "rewards/rejected": -0.4580347239971161,
      "step": 630
    },
    {
      "epoch": 0.2524,
      "grad_norm": 7.091159343719482,
      "learning_rate": 9.16e-07,
      "logits/chosen": -2.783496618270874,
      "logits/rejected": -2.4900004863739014,
      "logps/chosen": -55.89020538330078,
      "logps/rejected": -37.850341796875,
      "loss": 0.3989,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39342230558395386,
      "rewards/margins": 0.7214759588241577,
      "rewards/rejected": -0.32805365324020386,
      "step": 631
    },
    {
      "epoch": 0.2528,
      "grad_norm": 7.132486343383789,
      "learning_rate": 9.158666666666667e-07,
      "logits/chosen": -2.70535945892334,
      "logits/rejected": -2.2376503944396973,
      "logps/chosen": -84.91403198242188,
      "logps/rejected": -54.802154541015625,
      "loss": 0.3206,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7429405450820923,
      "rewards/margins": 0.9923231601715088,
      "rewards/rejected": -0.2493826001882553,
      "step": 632
    },
    {
      "epoch": 0.2532,
      "grad_norm": 8.996618270874023,
      "learning_rate": 9.157333333333333e-07,
      "logits/chosen": -2.771984338760376,
      "logits/rejected": -2.387089729309082,
      "logps/chosen": -83.01595306396484,
      "logps/rejected": -68.88850402832031,
      "loss": 0.3513,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6115898489952087,
      "rewards/margins": 0.8758997321128845,
      "rewards/rejected": -0.2643098831176758,
      "step": 633
    },
    {
      "epoch": 0.2536,
      "grad_norm": 10.991135597229004,
      "learning_rate": 9.156e-07,
      "logits/chosen": -2.9285624027252197,
      "logits/rejected": -2.2411766052246094,
      "logps/chosen": -52.019989013671875,
      "logps/rejected": -86.0887451171875,
      "loss": 0.3244,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0014883056282997131,
      "rewards/margins": 0.9764475226402283,
      "rewards/rejected": -0.977935791015625,
      "step": 634
    },
    {
      "epoch": 0.254,
      "grad_norm": 9.15576457977295,
      "learning_rate": 9.154666666666667e-07,
      "logits/chosen": -2.7605137825012207,
      "logits/rejected": -2.27026629447937,
      "logps/chosen": -62.04817199707031,
      "logps/rejected": -36.88854217529297,
      "loss": 0.453,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.449654757976532,
      "rewards/margins": 0.5582002401351929,
      "rewards/rejected": -0.10854549705982208,
      "step": 635
    },
    {
      "epoch": 0.2544,
      "grad_norm": 10.750123023986816,
      "learning_rate": 9.153333333333332e-07,
      "logits/chosen": -2.3430213928222656,
      "logits/rejected": -2.0069680213928223,
      "logps/chosen": -131.80670166015625,
      "logps/rejected": -137.10641479492188,
      "loss": 0.3002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6963748931884766,
      "rewards/margins": 1.0511188507080078,
      "rewards/rejected": -0.35474395751953125,
      "step": 636
    },
    {
      "epoch": 0.2548,
      "grad_norm": 11.156825065612793,
      "learning_rate": 9.151999999999999e-07,
      "logits/chosen": -2.860194683074951,
      "logits/rejected": -2.8359756469726562,
      "logps/chosen": -86.36184692382812,
      "logps/rejected": -69.76904296875,
      "loss": 0.3825,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5085834860801697,
      "rewards/margins": 0.7724329233169556,
      "rewards/rejected": -0.2638494372367859,
      "step": 637
    },
    {
      "epoch": 0.2552,
      "grad_norm": 8.309225082397461,
      "learning_rate": 9.150666666666666e-07,
      "logits/chosen": -2.8365912437438965,
      "logits/rejected": -2.5951602458953857,
      "logps/chosen": -99.21289825439453,
      "logps/rejected": -41.38603973388672,
      "loss": 0.3255,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5424980521202087,
      "rewards/margins": 0.9552124738693237,
      "rewards/rejected": -0.4127143919467926,
      "step": 638
    },
    {
      "epoch": 0.2556,
      "grad_norm": 8.63115119934082,
      "learning_rate": 9.149333333333333e-07,
      "logits/chosen": -2.6924681663513184,
      "logits/rejected": -2.625518798828125,
      "logps/chosen": -68.74024200439453,
      "logps/rejected": -59.89301681518555,
      "loss": 0.4627,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38492223620414734,
      "rewards/margins": 0.5434294939041138,
      "rewards/rejected": -0.15850725769996643,
      "step": 639
    },
    {
      "epoch": 0.256,
      "grad_norm": 7.307701110839844,
      "learning_rate": 9.147999999999999e-07,
      "logits/chosen": -2.3852944374084473,
      "logits/rejected": -2.5496883392333984,
      "logps/chosen": -69.70379638671875,
      "logps/rejected": -60.4590950012207,
      "loss": 0.3369,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8454133868217468,
      "rewards/margins": 1.0024408102035522,
      "rewards/rejected": -0.1570274382829666,
      "step": 640
    },
    {
      "epoch": 0.2564,
      "grad_norm": 7.7743730545043945,
      "learning_rate": 9.146666666666666e-07,
      "logits/chosen": -2.344167709350586,
      "logits/rejected": -1.946789264678955,
      "logps/chosen": -122.7161865234375,
      "logps/rejected": -88.6025390625,
      "loss": 0.2241,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1940808296203613,
      "rewards/margins": 1.381605863571167,
      "rewards/rejected": -0.1875251829624176,
      "step": 641
    },
    {
      "epoch": 0.2568,
      "grad_norm": 8.332330703735352,
      "learning_rate": 9.145333333333333e-07,
      "logits/chosen": -2.892704963684082,
      "logits/rejected": -2.161644220352173,
      "logps/chosen": -51.45726776123047,
      "logps/rejected": -57.785865783691406,
      "loss": 0.2802,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6619037389755249,
      "rewards/margins": 1.1345574855804443,
      "rewards/rejected": -0.4726537764072418,
      "step": 642
    },
    {
      "epoch": 0.2572,
      "grad_norm": 8.500308990478516,
      "learning_rate": 9.144e-07,
      "logits/chosen": -2.7644386291503906,
      "logits/rejected": -2.220057487487793,
      "logps/chosen": -66.95374298095703,
      "logps/rejected": -72.3187484741211,
      "loss": 0.3694,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3963281810283661,
      "rewards/margins": 0.8174841403961182,
      "rewards/rejected": -0.4211559295654297,
      "step": 643
    },
    {
      "epoch": 0.2576,
      "grad_norm": 9.402983665466309,
      "learning_rate": 9.142666666666667e-07,
      "logits/chosen": -2.88042950630188,
      "logits/rejected": -2.717620372772217,
      "logps/chosen": -71.21298217773438,
      "logps/rejected": -39.76593780517578,
      "loss": 0.3747,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4689968228340149,
      "rewards/margins": 0.7929409146308899,
      "rewards/rejected": -0.323944091796875,
      "step": 644
    },
    {
      "epoch": 0.258,
      "grad_norm": 8.270134925842285,
      "learning_rate": 9.141333333333333e-07,
      "logits/chosen": -2.6116256713867188,
      "logits/rejected": -2.1317543983459473,
      "logps/chosen": -87.88072204589844,
      "logps/rejected": -87.90272521972656,
      "loss": 0.2608,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6732925176620483,
      "rewards/margins": 1.2250858545303345,
      "rewards/rejected": -0.5517933368682861,
      "step": 645
    },
    {
      "epoch": 0.2584,
      "grad_norm": 8.111664772033691,
      "learning_rate": 9.14e-07,
      "logits/chosen": -2.2071189880371094,
      "logits/rejected": -1.9563229084014893,
      "logps/chosen": -133.2588653564453,
      "logps/rejected": -138.92715454101562,
      "loss": 0.1942,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8355903625488281,
      "rewards/margins": 1.5531132221221924,
      "rewards/rejected": -0.7175228595733643,
      "step": 646
    },
    {
      "epoch": 0.2588,
      "grad_norm": 10.09813117980957,
      "learning_rate": 9.138666666666666e-07,
      "logits/chosen": -2.7313003540039062,
      "logits/rejected": -2.3465025424957275,
      "logps/chosen": -69.50764465332031,
      "logps/rejected": -52.81050109863281,
      "loss": 0.2758,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3398616909980774,
      "rewards/margins": 1.1471166610717773,
      "rewards/rejected": -0.8072550296783447,
      "step": 647
    },
    {
      "epoch": 0.2592,
      "grad_norm": 8.772397994995117,
      "learning_rate": 9.137333333333332e-07,
      "logits/chosen": -2.527698278427124,
      "logits/rejected": -2.3964409828186035,
      "logps/chosen": -125.03514099121094,
      "logps/rejected": -50.16532897949219,
      "loss": 0.3095,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0112698078155518,
      "rewards/margins": 1.0154173374176025,
      "rewards/rejected": -0.004147626459598541,
      "step": 648
    },
    {
      "epoch": 0.2596,
      "grad_norm": 7.778468132019043,
      "learning_rate": 9.135999999999999e-07,
      "logits/chosen": -2.197326898574829,
      "logits/rejected": -2.0393600463867188,
      "logps/chosen": -88.81478881835938,
      "logps/rejected": -54.982261657714844,
      "loss": 0.2624,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8393436670303345,
      "rewards/margins": 1.209899663925171,
      "rewards/rejected": -0.3705560564994812,
      "step": 649
    },
    {
      "epoch": 0.26,
      "grad_norm": 8.451142311096191,
      "learning_rate": 9.134666666666666e-07,
      "logits/chosen": -2.8283634185791016,
      "logits/rejected": -2.5446324348449707,
      "logps/chosen": -116.47955322265625,
      "logps/rejected": -44.48583984375,
      "loss": 0.3579,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4334980249404907,
      "rewards/margins": 0.8441675305366516,
      "rewards/rejected": -0.4106695353984833,
      "step": 650
    },
    {
      "epoch": 0.2604,
      "grad_norm": 9.54991340637207,
      "learning_rate": 9.133333333333333e-07,
      "logits/chosen": -2.364471912384033,
      "logits/rejected": -2.1411807537078857,
      "logps/chosen": -87.77305603027344,
      "logps/rejected": -63.69035339355469,
      "loss": 0.2662,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7781841158866882,
      "rewards/margins": 1.2700228691101074,
      "rewards/rejected": -0.491838663816452,
      "step": 651
    },
    {
      "epoch": 0.2608,
      "grad_norm": 8.648035049438477,
      "learning_rate": 9.132e-07,
      "logits/chosen": -3.0331687927246094,
      "logits/rejected": -2.5300474166870117,
      "logps/chosen": -84.60098266601562,
      "logps/rejected": -66.02101135253906,
      "loss": 0.3417,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3640899658203125,
      "rewards/margins": 0.898720383644104,
      "rewards/rejected": -0.5346304178237915,
      "step": 652
    },
    {
      "epoch": 0.2612,
      "grad_norm": 9.45324993133545,
      "learning_rate": 9.130666666666667e-07,
      "logits/chosen": -2.7014267444610596,
      "logits/rejected": -2.3217315673828125,
      "logps/chosen": -94.7016372680664,
      "logps/rejected": -59.071598052978516,
      "loss": 0.3523,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21325263381004333,
      "rewards/margins": 0.923850417137146,
      "rewards/rejected": -0.710597813129425,
      "step": 653
    },
    {
      "epoch": 0.2616,
      "grad_norm": 6.650674343109131,
      "learning_rate": 9.129333333333334e-07,
      "logits/chosen": -2.6763153076171875,
      "logits/rejected": -2.3465774059295654,
      "logps/chosen": -105.50534057617188,
      "logps/rejected": -52.20734786987305,
      "loss": 0.2505,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8803631067276001,
      "rewards/margins": 1.2771646976470947,
      "rewards/rejected": -0.39680159091949463,
      "step": 654
    },
    {
      "epoch": 0.262,
      "grad_norm": 10.725052833557129,
      "learning_rate": 9.127999999999999e-07,
      "logits/chosen": -2.2824854850769043,
      "logits/rejected": -2.0764994621276855,
      "logps/chosen": -116.27345275878906,
      "logps/rejected": -110.86559295654297,
      "loss": 0.281,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6647327542304993,
      "rewards/margins": 1.126882553100586,
      "rewards/rejected": -0.46214979887008667,
      "step": 655
    },
    {
      "epoch": 0.2624,
      "grad_norm": 8.536931991577148,
      "learning_rate": 9.126666666666666e-07,
      "logits/chosen": -2.546057939529419,
      "logits/rejected": -2.2508490085601807,
      "logps/chosen": -101.37750244140625,
      "logps/rejected": -66.32781219482422,
      "loss": 0.3656,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5376670956611633,
      "rewards/margins": 0.8641489148139954,
      "rewards/rejected": -0.32648181915283203,
      "step": 656
    },
    {
      "epoch": 0.2628,
      "grad_norm": 8.664356231689453,
      "learning_rate": 9.125333333333332e-07,
      "logits/chosen": -2.350327253341675,
      "logits/rejected": -1.8775100708007812,
      "logps/chosen": -112.04024505615234,
      "logps/rejected": -59.700077056884766,
      "loss": 0.2722,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.835008978843689,
      "rewards/margins": 1.1939188241958618,
      "rewards/rejected": -0.3589097857475281,
      "step": 657
    },
    {
      "epoch": 0.2632,
      "grad_norm": 7.956403732299805,
      "learning_rate": 9.123999999999999e-07,
      "logits/chosen": -2.9901537895202637,
      "logits/rejected": -2.6542820930480957,
      "logps/chosen": -47.621795654296875,
      "logps/rejected": -47.43406677246094,
      "loss": 0.3924,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4110944867134094,
      "rewards/margins": 0.7409154176712036,
      "rewards/rejected": -0.3298209309577942,
      "step": 658
    },
    {
      "epoch": 0.2636,
      "grad_norm": 9.017836570739746,
      "learning_rate": 9.122666666666666e-07,
      "logits/chosen": -2.508286476135254,
      "logits/rejected": -2.5040433406829834,
      "logps/chosen": -150.30123901367188,
      "logps/rejected": -149.51971435546875,
      "loss": 0.2022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0144821405410767,
      "rewards/margins": 1.4962944984436035,
      "rewards/rejected": -0.4818122982978821,
      "step": 659
    },
    {
      "epoch": 0.264,
      "grad_norm": 7.368706703186035,
      "learning_rate": 9.121333333333333e-07,
      "logits/chosen": -2.3358078002929688,
      "logits/rejected": -1.9491894245147705,
      "logps/chosen": -151.57333374023438,
      "logps/rejected": -75.18368530273438,
      "loss": 0.2068,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.250457763671875,
      "rewards/margins": 1.475904107093811,
      "rewards/rejected": -0.22544632852077484,
      "step": 660
    },
    {
      "epoch": 0.2644,
      "grad_norm": 10.765570640563965,
      "learning_rate": 9.12e-07,
      "logits/chosen": -2.559568166732788,
      "logits/rejected": -2.221116542816162,
      "logps/chosen": -65.72882080078125,
      "logps/rejected": -95.13068389892578,
      "loss": 0.34,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4655179977416992,
      "rewards/margins": 0.9177146553993225,
      "rewards/rejected": -0.45219671726226807,
      "step": 661
    },
    {
      "epoch": 0.2648,
      "grad_norm": 8.536861419677734,
      "learning_rate": 9.118666666666667e-07,
      "logits/chosen": -2.722385883331299,
      "logits/rejected": -3.0106711387634277,
      "logps/chosen": -126.32310485839844,
      "logps/rejected": -36.878238677978516,
      "loss": 0.3341,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9074639081954956,
      "rewards/margins": 0.989998459815979,
      "rewards/rejected": -0.08253464847803116,
      "step": 662
    },
    {
      "epoch": 0.2652,
      "grad_norm": 8.566712379455566,
      "learning_rate": 9.117333333333333e-07,
      "logits/chosen": -2.7126078605651855,
      "logits/rejected": -2.6532254219055176,
      "logps/chosen": -101.00393676757812,
      "logps/rejected": -51.093605041503906,
      "loss": 0.2894,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4812862277030945,
      "rewards/margins": 1.0922391414642334,
      "rewards/rejected": -0.6109529733657837,
      "step": 663
    },
    {
      "epoch": 0.2656,
      "grad_norm": 8.052389144897461,
      "learning_rate": 9.115999999999999e-07,
      "logits/chosen": -2.6846396923065186,
      "logits/rejected": -2.441615104675293,
      "logps/chosen": -53.801918029785156,
      "logps/rejected": -33.860206604003906,
      "loss": 0.4292,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2656402587890625,
      "rewards/margins": 0.6246358752250671,
      "rewards/rejected": -0.35899561643600464,
      "step": 664
    },
    {
      "epoch": 0.266,
      "grad_norm": 6.815395355224609,
      "learning_rate": 9.114666666666666e-07,
      "logits/chosen": -2.7338714599609375,
      "logits/rejected": -2.417962074279785,
      "logps/chosen": -87.64007568359375,
      "logps/rejected": -65.84630584716797,
      "loss": 0.2557,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8452335596084595,
      "rewards/margins": 1.3583602905273438,
      "rewards/rejected": -0.513126790523529,
      "step": 665
    },
    {
      "epoch": 0.2664,
      "grad_norm": 11.417457580566406,
      "learning_rate": 9.113333333333333e-07,
      "logits/chosen": -2.5566964149475098,
      "logits/rejected": -2.5454509258270264,
      "logps/chosen": -173.4673614501953,
      "logps/rejected": -60.357330322265625,
      "loss": 0.3766,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3776336908340454,
      "rewards/margins": 0.7931249737739563,
      "rewards/rejected": -0.4154913127422333,
      "step": 666
    },
    {
      "epoch": 0.2668,
      "grad_norm": 9.143900871276855,
      "learning_rate": 9.112e-07,
      "logits/chosen": -2.8405680656433105,
      "logits/rejected": -2.4733619689941406,
      "logps/chosen": -77.73018646240234,
      "logps/rejected": -49.465850830078125,
      "loss": 0.3496,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6504303216934204,
      "rewards/margins": 0.8711690902709961,
      "rewards/rejected": -0.22073879837989807,
      "step": 667
    },
    {
      "epoch": 0.2672,
      "grad_norm": 10.670350074768066,
      "learning_rate": 9.110666666666666e-07,
      "logits/chosen": -2.9368667602539062,
      "logits/rejected": -2.370920181274414,
      "logps/chosen": -74.76475524902344,
      "logps/rejected": -79.64141845703125,
      "loss": 0.4225,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45539894700050354,
      "rewards/margins": 0.6664301156997681,
      "rewards/rejected": -0.21103116869926453,
      "step": 668
    },
    {
      "epoch": 0.2676,
      "grad_norm": 10.220210075378418,
      "learning_rate": 9.109333333333333e-07,
      "logits/chosen": -2.497842788696289,
      "logits/rejected": -2.1052329540252686,
      "logps/chosen": -101.52265930175781,
      "logps/rejected": -135.77981567382812,
      "loss": 0.2744,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6997448205947876,
      "rewards/margins": 1.159986972808838,
      "rewards/rejected": -0.4602420926094055,
      "step": 669
    },
    {
      "epoch": 0.268,
      "grad_norm": 5.903913497924805,
      "learning_rate": 9.108e-07,
      "logits/chosen": -2.581331253051758,
      "logits/rejected": -2.1376495361328125,
      "logps/chosen": -108.97779846191406,
      "logps/rejected": -66.07969665527344,
      "loss": 0.1768,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2099144458770752,
      "rewards/margins": 1.7000668048858643,
      "rewards/rejected": -0.49015235900878906,
      "step": 670
    },
    {
      "epoch": 0.2684,
      "grad_norm": 5.580234527587891,
      "learning_rate": 9.106666666666666e-07,
      "logits/chosen": -2.6048526763916016,
      "logits/rejected": -2.176938056945801,
      "logps/chosen": -97.55269622802734,
      "logps/rejected": -71.05937957763672,
      "loss": 0.1974,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.201059341430664,
      "rewards/margins": 1.643294334411621,
      "rewards/rejected": -0.44223499298095703,
      "step": 671
    },
    {
      "epoch": 0.2688,
      "grad_norm": 8.134696960449219,
      "learning_rate": 9.105333333333333e-07,
      "logits/chosen": -2.700568199157715,
      "logits/rejected": -2.366812229156494,
      "logps/chosen": -76.04386901855469,
      "logps/rejected": -51.7369270324707,
      "loss": 0.3916,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5428058505058289,
      "rewards/margins": 0.8376357555389404,
      "rewards/rejected": -0.29482996463775635,
      "step": 672
    },
    {
      "epoch": 0.2692,
      "grad_norm": 9.530714988708496,
      "learning_rate": 9.103999999999999e-07,
      "logits/chosen": -2.7644574642181396,
      "logits/rejected": -2.11974835395813,
      "logps/chosen": -98.31758117675781,
      "logps/rejected": -69.48467254638672,
      "loss": 0.342,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40757352113723755,
      "rewards/margins": 0.9654102325439453,
      "rewards/rejected": -0.5578367710113525,
      "step": 673
    },
    {
      "epoch": 0.2696,
      "grad_norm": 7.618128776550293,
      "learning_rate": 9.102666666666666e-07,
      "logits/chosen": -2.6079535484313965,
      "logits/rejected": -2.329089879989624,
      "logps/chosen": -92.49787902832031,
      "logps/rejected": -58.03523254394531,
      "loss": 0.3012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6758807897567749,
      "rewards/margins": 1.0456631183624268,
      "rewards/rejected": -0.3697822690010071,
      "step": 674
    },
    {
      "epoch": 0.27,
      "grad_norm": 6.903770446777344,
      "learning_rate": 9.101333333333333e-07,
      "logits/chosen": -2.8543312549591064,
      "logits/rejected": -2.499926805496216,
      "logps/chosen": -37.333988189697266,
      "logps/rejected": -48.05663299560547,
      "loss": 0.3965,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.380132794380188,
      "rewards/margins": 0.7695649266242981,
      "rewards/rejected": -0.3894321620464325,
      "step": 675
    },
    {
      "epoch": 0.2704,
      "grad_norm": 10.569628715515137,
      "learning_rate": 9.1e-07,
      "logits/chosen": -2.9798402786254883,
      "logits/rejected": -2.6941044330596924,
      "logps/chosen": -84.58895111083984,
      "logps/rejected": -65.12042236328125,
      "loss": 0.4778,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2668870985507965,
      "rewards/margins": 0.4906812906265259,
      "rewards/rejected": -0.22379419207572937,
      "step": 676
    },
    {
      "epoch": 0.2708,
      "grad_norm": 11.455023765563965,
      "learning_rate": 9.098666666666667e-07,
      "logits/chosen": -2.1860852241516113,
      "logits/rejected": -1.9062511920928955,
      "logps/chosen": -116.81417846679688,
      "logps/rejected": -94.51181030273438,
      "loss": 0.3644,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7463020086288452,
      "rewards/margins": 0.8670623898506165,
      "rewards/rejected": -0.12076035141944885,
      "step": 677
    },
    {
      "epoch": 0.2712,
      "grad_norm": 9.416482925415039,
      "learning_rate": 9.097333333333332e-07,
      "logits/chosen": -2.8271565437316895,
      "logits/rejected": -2.5100159645080566,
      "logps/chosen": -81.88389587402344,
      "logps/rejected": -69.84562683105469,
      "loss": 0.2684,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4247016906738281,
      "rewards/margins": 1.264634370803833,
      "rewards/rejected": -0.8399326801300049,
      "step": 678
    },
    {
      "epoch": 0.2716,
      "grad_norm": 7.305862903594971,
      "learning_rate": 9.095999999999999e-07,
      "logits/chosen": -2.566800594329834,
      "logits/rejected": -2.259935140609741,
      "logps/chosen": -142.40328979492188,
      "logps/rejected": -61.64849090576172,
      "loss": 0.2087,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0395557880401611,
      "rewards/margins": 1.5311455726623535,
      "rewards/rejected": -0.4915897250175476,
      "step": 679
    },
    {
      "epoch": 0.272,
      "grad_norm": 8.228394508361816,
      "learning_rate": 9.094666666666666e-07,
      "logits/chosen": -2.5568838119506836,
      "logits/rejected": -2.565122127532959,
      "logps/chosen": -114.11248779296875,
      "logps/rejected": -43.54880142211914,
      "loss": 0.3334,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7530895471572876,
      "rewards/margins": 0.9918835163116455,
      "rewards/rejected": -0.23879395425319672,
      "step": 680
    },
    {
      "epoch": 0.2724,
      "grad_norm": 8.196431159973145,
      "learning_rate": 9.093333333333333e-07,
      "logits/chosen": -2.536935329437256,
      "logits/rejected": -2.6466751098632812,
      "logps/chosen": -111.1824951171875,
      "logps/rejected": -56.666725158691406,
      "loss": 0.2852,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7625350952148438,
      "rewards/margins": 1.1145490407943726,
      "rewards/rejected": -0.3520139753818512,
      "step": 681
    },
    {
      "epoch": 0.2728,
      "grad_norm": 8.491299629211426,
      "learning_rate": 9.092e-07,
      "logits/chosen": -2.619776725769043,
      "logits/rejected": -2.853778839111328,
      "logps/chosen": -104.62635040283203,
      "logps/rejected": -102.4649887084961,
      "loss": 0.2878,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5939353704452515,
      "rewards/margins": 1.1207164525985718,
      "rewards/rejected": -0.5267810821533203,
      "step": 682
    },
    {
      "epoch": 0.2732,
      "grad_norm": 8.639056205749512,
      "learning_rate": 9.090666666666666e-07,
      "logits/chosen": -2.7107348442077637,
      "logits/rejected": -2.6807522773742676,
      "logps/chosen": -84.17391204833984,
      "logps/rejected": -40.970603942871094,
      "loss": 0.4473,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3225361108779907,
      "rewards/margins": 0.5730663537979126,
      "rewards/rejected": -0.2505302429199219,
      "step": 683
    },
    {
      "epoch": 0.2736,
      "grad_norm": 5.989324569702148,
      "learning_rate": 9.089333333333333e-07,
      "logits/chosen": -2.5938782691955566,
      "logits/rejected": -2.415959358215332,
      "logps/chosen": -79.0789794921875,
      "logps/rejected": -52.70210266113281,
      "loss": 0.2816,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8079785704612732,
      "rewards/margins": 1.2463269233703613,
      "rewards/rejected": -0.4383484125137329,
      "step": 684
    },
    {
      "epoch": 0.274,
      "grad_norm": 9.358270645141602,
      "learning_rate": 9.088e-07,
      "logits/chosen": -2.38814640045166,
      "logits/rejected": -1.9753150939941406,
      "logps/chosen": -68.75477600097656,
      "logps/rejected": -131.54197692871094,
      "loss": 0.2484,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8738561868667603,
      "rewards/margins": 1.2741613388061523,
      "rewards/rejected": -0.4003051817417145,
      "step": 685
    },
    {
      "epoch": 0.2744,
      "grad_norm": 6.269294261932373,
      "learning_rate": 9.086666666666666e-07,
      "logits/chosen": -2.557387351989746,
      "logits/rejected": -2.1105573177337646,
      "logps/chosen": -93.5920639038086,
      "logps/rejected": -58.36585235595703,
      "loss": 0.2185,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8313392996788025,
      "rewards/margins": 1.4296257495880127,
      "rewards/rejected": -0.5982864499092102,
      "step": 686
    },
    {
      "epoch": 0.2748,
      "grad_norm": 7.9317402839660645,
      "learning_rate": 9.085333333333333e-07,
      "logits/chosen": -2.4459972381591797,
      "logits/rejected": -2.5037670135498047,
      "logps/chosen": -114.50458526611328,
      "logps/rejected": -56.902618408203125,
      "loss": 0.2519,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9290916919708252,
      "rewards/margins": 1.2536773681640625,
      "rewards/rejected": -0.3245857357978821,
      "step": 687
    },
    {
      "epoch": 0.2752,
      "grad_norm": 6.915687084197998,
      "learning_rate": 9.084e-07,
      "logits/chosen": -2.366206407546997,
      "logits/rejected": -2.0371172428131104,
      "logps/chosen": -164.69210815429688,
      "logps/rejected": -79.74718475341797,
      "loss": 0.1874,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1781253814697266,
      "rewards/margins": 1.5892524719238281,
      "rewards/rejected": -0.41112709045410156,
      "step": 688
    },
    {
      "epoch": 0.2756,
      "grad_norm": 7.5348615646362305,
      "learning_rate": 9.082666666666666e-07,
      "logits/chosen": -2.5467424392700195,
      "logits/rejected": -2.6028733253479004,
      "logps/chosen": -126.63209533691406,
      "logps/rejected": -84.16777801513672,
      "loss": 0.2309,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0713001489639282,
      "rewards/margins": 1.3779289722442627,
      "rewards/rejected": -0.3066288232803345,
      "step": 689
    },
    {
      "epoch": 0.276,
      "grad_norm": 11.440092086791992,
      "learning_rate": 9.081333333333333e-07,
      "logits/chosen": -2.616072654724121,
      "logits/rejected": -2.1543705463409424,
      "logps/chosen": -89.96337127685547,
      "logps/rejected": -202.4186553955078,
      "loss": 0.3018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7270931005477905,
      "rewards/margins": 1.0432875156402588,
      "rewards/rejected": -0.3161943554878235,
      "step": 690
    },
    {
      "epoch": 0.2764,
      "grad_norm": 12.509612083435059,
      "learning_rate": 9.08e-07,
      "logits/chosen": -2.3720860481262207,
      "logits/rejected": -1.952451467514038,
      "logps/chosen": -143.66456604003906,
      "logps/rejected": -96.73790740966797,
      "loss": 0.3263,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6424585580825806,
      "rewards/margins": 1.0103204250335693,
      "rewards/rejected": -0.36786195635795593,
      "step": 691
    },
    {
      "epoch": 0.2768,
      "grad_norm": 8.443336486816406,
      "learning_rate": 9.078666666666666e-07,
      "logits/chosen": -2.6705410480499268,
      "logits/rejected": -2.5464210510253906,
      "logps/chosen": -63.871253967285156,
      "logps/rejected": -86.43479919433594,
      "loss": 0.3118,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5919641852378845,
      "rewards/margins": 1.0090811252593994,
      "rewards/rejected": -0.4171169400215149,
      "step": 692
    },
    {
      "epoch": 0.2772,
      "grad_norm": 6.8921308517456055,
      "learning_rate": 9.077333333333332e-07,
      "logits/chosen": -2.280123233795166,
      "logits/rejected": -2.0813775062561035,
      "logps/chosen": -125.52230834960938,
      "logps/rejected": -63.178253173828125,
      "loss": 0.2289,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6552311182022095,
      "rewards/margins": 1.3618290424346924,
      "rewards/rejected": -0.7065979242324829,
      "step": 693
    },
    {
      "epoch": 0.2776,
      "grad_norm": 6.52280330657959,
      "learning_rate": 9.075999999999999e-07,
      "logits/chosen": -2.8099093437194824,
      "logits/rejected": -2.255204200744629,
      "logps/chosen": -74.66770935058594,
      "logps/rejected": -66.93145751953125,
      "loss": 0.2385,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6205343008041382,
      "rewards/margins": 1.3153669834136963,
      "rewards/rejected": -0.6948326826095581,
      "step": 694
    },
    {
      "epoch": 0.278,
      "grad_norm": 7.386650562286377,
      "learning_rate": 9.074666666666666e-07,
      "logits/chosen": -2.60726261138916,
      "logits/rejected": -2.5711517333984375,
      "logps/chosen": -150.14718627929688,
      "logps/rejected": -40.88633346557617,
      "loss": 0.2637,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8146716952323914,
      "rewards/margins": 1.255291223526001,
      "rewards/rejected": -0.44061946868896484,
      "step": 695
    },
    {
      "epoch": 0.2784,
      "grad_norm": 6.796104431152344,
      "learning_rate": 9.073333333333333e-07,
      "logits/chosen": -2.4485361576080322,
      "logits/rejected": -2.0746917724609375,
      "logps/chosen": -85.05853271484375,
      "logps/rejected": -75.87619018554688,
      "loss": 0.2095,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8222541809082031,
      "rewards/margins": 1.4567310810089111,
      "rewards/rejected": -0.6344768404960632,
      "step": 696
    },
    {
      "epoch": 0.2788,
      "grad_norm": 6.761829376220703,
      "learning_rate": 9.072e-07,
      "logits/chosen": -2.443953514099121,
      "logits/rejected": -2.0595412254333496,
      "logps/chosen": -113.15026092529297,
      "logps/rejected": -56.72134780883789,
      "loss": 0.2234,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7598609924316406,
      "rewards/margins": 1.3873302936553955,
      "rewards/rejected": -0.6274692416191101,
      "step": 697
    },
    {
      "epoch": 0.2792,
      "grad_norm": 8.101503372192383,
      "learning_rate": 9.070666666666667e-07,
      "logits/chosen": -2.687436103820801,
      "logits/rejected": -2.60512638092041,
      "logps/chosen": -101.79621887207031,
      "logps/rejected": -112.20714569091797,
      "loss": 0.3213,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7930073142051697,
      "rewards/margins": 1.1620155572891235,
      "rewards/rejected": -0.36900824308395386,
      "step": 698
    },
    {
      "epoch": 0.2796,
      "grad_norm": 10.763395309448242,
      "learning_rate": 9.069333333333334e-07,
      "logits/chosen": -2.4388651847839355,
      "logits/rejected": -2.4945406913757324,
      "logps/chosen": -101.97941589355469,
      "logps/rejected": -52.159236907958984,
      "loss": 0.3014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31295567750930786,
      "rewards/margins": 1.2094074487686157,
      "rewards/rejected": -0.8964517712593079,
      "step": 699
    },
    {
      "epoch": 0.28,
      "grad_norm": 9.979459762573242,
      "learning_rate": 9.068e-07,
      "logits/chosen": -2.141903877258301,
      "logits/rejected": -2.199712038040161,
      "logps/chosen": -177.3167266845703,
      "logps/rejected": -92.11550903320312,
      "loss": 0.1977,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1355422735214233,
      "rewards/margins": 1.5575478076934814,
      "rewards/rejected": -0.42200547456741333,
      "step": 700
    },
    {
      "epoch": 0.2804,
      "grad_norm": 7.339066028594971,
      "learning_rate": 9.066666666666665e-07,
      "logits/chosen": -2.3594307899475098,
      "logits/rejected": -1.8951932191848755,
      "logps/chosen": -95.06901550292969,
      "logps/rejected": -123.74298858642578,
      "loss": 0.2047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1165775060653687,
      "rewards/margins": 1.4841721057891846,
      "rewards/rejected": -0.36759454011917114,
      "step": 701
    },
    {
      "epoch": 0.2808,
      "grad_norm": 9.767937660217285,
      "learning_rate": 9.065333333333332e-07,
      "logits/chosen": -2.6829519271850586,
      "logits/rejected": -2.5563158988952637,
      "logps/chosen": -113.54592895507812,
      "logps/rejected": -44.89360046386719,
      "loss": 0.3454,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6624065637588501,
      "rewards/margins": 0.9214003086090088,
      "rewards/rejected": -0.2589937150478363,
      "step": 702
    },
    {
      "epoch": 0.2812,
      "grad_norm": 7.405606269836426,
      "learning_rate": 9.063999999999999e-07,
      "logits/chosen": -2.9015350341796875,
      "logits/rejected": -2.5672645568847656,
      "logps/chosen": -55.63751220703125,
      "logps/rejected": -70.8500747680664,
      "loss": 0.3902,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24126702547073364,
      "rewards/margins": 0.7423670291900635,
      "rewards/rejected": -0.5011000037193298,
      "step": 703
    },
    {
      "epoch": 0.2816,
      "grad_norm": 8.571554183959961,
      "learning_rate": 9.062666666666666e-07,
      "logits/chosen": -2.322681427001953,
      "logits/rejected": -1.7891125679016113,
      "logps/chosen": -116.61558532714844,
      "logps/rejected": -82.70753479003906,
      "loss": 0.2299,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8888733386993408,
      "rewards/margins": 1.4106113910675049,
      "rewards/rejected": -0.5217380523681641,
      "step": 704
    },
    {
      "epoch": 0.282,
      "grad_norm": 5.749636650085449,
      "learning_rate": 9.061333333333333e-07,
      "logits/chosen": -2.8502519130706787,
      "logits/rejected": -2.288383960723877,
      "logps/chosen": -77.5805435180664,
      "logps/rejected": -53.82117462158203,
      "loss": 0.2785,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5540221929550171,
      "rewards/margins": 1.1921889781951904,
      "rewards/rejected": -0.6381667852401733,
      "step": 705
    },
    {
      "epoch": 0.2824,
      "grad_norm": 7.379798412322998,
      "learning_rate": 9.06e-07,
      "logits/chosen": -2.3544044494628906,
      "logits/rejected": -2.228013038635254,
      "logps/chosen": -84.70083618164062,
      "logps/rejected": -58.52172088623047,
      "loss": 0.2726,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7734905481338501,
      "rewards/margins": 1.1689817905426025,
      "rewards/rejected": -0.39549124240875244,
      "step": 706
    },
    {
      "epoch": 0.2828,
      "grad_norm": 8.256163597106934,
      "learning_rate": 9.058666666666667e-07,
      "logits/chosen": -2.4879133701324463,
      "logits/rejected": -2.3807106018066406,
      "logps/chosen": -78.39889526367188,
      "logps/rejected": -68.33383178710938,
      "loss": 0.3799,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7402998208999634,
      "rewards/margins": 0.9762826561927795,
      "rewards/rejected": -0.23598289489746094,
      "step": 707
    },
    {
      "epoch": 0.2832,
      "grad_norm": 8.139470100402832,
      "learning_rate": 9.057333333333333e-07,
      "logits/chosen": -2.4061837196350098,
      "logits/rejected": -2.1677567958831787,
      "logps/chosen": -93.484375,
      "logps/rejected": -65.65884399414062,
      "loss": 0.2606,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5916996002197266,
      "rewards/margins": 1.2157883644104004,
      "rewards/rejected": -0.624088704586029,
      "step": 708
    },
    {
      "epoch": 0.2836,
      "grad_norm": 10.004318237304688,
      "learning_rate": 9.056e-07,
      "logits/chosen": -2.519327163696289,
      "logits/rejected": -2.4599056243896484,
      "logps/chosen": -150.15499877929688,
      "logps/rejected": -73.81718444824219,
      "loss": 0.294,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6356498599052429,
      "rewards/margins": 1.1237194538116455,
      "rewards/rejected": -0.4880695343017578,
      "step": 709
    },
    {
      "epoch": 0.284,
      "grad_norm": 7.849724292755127,
      "learning_rate": 9.054666666666666e-07,
      "logits/chosen": -2.7651174068450928,
      "logits/rejected": -2.6637706756591797,
      "logps/chosen": -91.64726257324219,
      "logps/rejected": -60.88707733154297,
      "loss": 0.3481,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5801149606704712,
      "rewards/margins": 0.8854387402534485,
      "rewards/rejected": -0.3053238093852997,
      "step": 710
    },
    {
      "epoch": 0.2844,
      "grad_norm": 8.554779052734375,
      "learning_rate": 9.053333333333332e-07,
      "logits/chosen": -2.637470245361328,
      "logits/rejected": -2.1338865756988525,
      "logps/chosen": -53.500282287597656,
      "logps/rejected": -50.91928482055664,
      "loss": 0.3891,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5282869338989258,
      "rewards/margins": 0.8442701101303101,
      "rewards/rejected": -0.31598320603370667,
      "step": 711
    },
    {
      "epoch": 0.2848,
      "grad_norm": 7.907318115234375,
      "learning_rate": 9.051999999999999e-07,
      "logits/chosen": -2.8262691497802734,
      "logits/rejected": -2.52687931060791,
      "logps/chosen": -90.42880249023438,
      "logps/rejected": -71.04180145263672,
      "loss": 0.2249,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6270862817764282,
      "rewards/margins": 1.3856549263000488,
      "rewards/rejected": -0.7585687637329102,
      "step": 712
    },
    {
      "epoch": 0.2852,
      "grad_norm": 9.893486022949219,
      "learning_rate": 9.050666666666666e-07,
      "logits/chosen": -2.5543229579925537,
      "logits/rejected": -2.241856575012207,
      "logps/chosen": -151.24557495117188,
      "logps/rejected": -74.74024200439453,
      "loss": 0.3212,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7813316583633423,
      "rewards/margins": 1.0717740058898926,
      "rewards/rejected": -0.2904422879219055,
      "step": 713
    },
    {
      "epoch": 0.2856,
      "grad_norm": 6.149257183074951,
      "learning_rate": 9.049333333333333e-07,
      "logits/chosen": -2.6554102897644043,
      "logits/rejected": -2.152508020401001,
      "logps/chosen": -86.20240783691406,
      "logps/rejected": -69.81405639648438,
      "loss": 0.1882,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8041797876358032,
      "rewards/margins": 1.579007625579834,
      "rewards/rejected": -0.774827778339386,
      "step": 714
    },
    {
      "epoch": 0.286,
      "grad_norm": 7.509435176849365,
      "learning_rate": 9.048e-07,
      "logits/chosen": -2.3589911460876465,
      "logits/rejected": -2.134117603302002,
      "logps/chosen": -109.14823913574219,
      "logps/rejected": -70.22251892089844,
      "loss": 0.2106,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8578780889511108,
      "rewards/margins": 1.4509702920913696,
      "rewards/rejected": -0.5930922031402588,
      "step": 715
    },
    {
      "epoch": 0.2864,
      "grad_norm": 8.085662841796875,
      "learning_rate": 9.046666666666666e-07,
      "logits/chosen": -2.713113784790039,
      "logits/rejected": -2.6109228134155273,
      "logps/chosen": -100.8210678100586,
      "logps/rejected": -68.16549682617188,
      "loss": 0.2602,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9849166870117188,
      "rewards/margins": 1.3329623937606812,
      "rewards/rejected": -0.3480457663536072,
      "step": 716
    },
    {
      "epoch": 0.2868,
      "grad_norm": 10.629135131835938,
      "learning_rate": 9.045333333333333e-07,
      "logits/chosen": -3.0323944091796875,
      "logits/rejected": -2.1228132247924805,
      "logps/chosen": -50.49766540527344,
      "logps/rejected": -85.53923034667969,
      "loss": 0.2535,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42310696840286255,
      "rewards/margins": 1.2575641870498657,
      "rewards/rejected": -0.8344572186470032,
      "step": 717
    },
    {
      "epoch": 0.2872,
      "grad_norm": 9.047268867492676,
      "learning_rate": 9.044e-07,
      "logits/chosen": -2.754828453063965,
      "logits/rejected": -3.05971097946167,
      "logps/chosen": -111.19802856445312,
      "logps/rejected": -36.63920974731445,
      "loss": 0.3085,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8045356273651123,
      "rewards/margins": 1.0234054327011108,
      "rewards/rejected": -0.21886979043483734,
      "step": 718
    },
    {
      "epoch": 0.2876,
      "grad_norm": 7.28971529006958,
      "learning_rate": 9.042666666666667e-07,
      "logits/chosen": -2.7079555988311768,
      "logits/rejected": -2.061452865600586,
      "logps/chosen": -88.50738525390625,
      "logps/rejected": -81.62200927734375,
      "loss": 0.2593,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6343170404434204,
      "rewards/margins": 1.2526432275772095,
      "rewards/rejected": -0.6183261871337891,
      "step": 719
    },
    {
      "epoch": 0.288,
      "grad_norm": 8.247762680053711,
      "learning_rate": 9.041333333333334e-07,
      "logits/chosen": -2.7760982513427734,
      "logits/rejected": -2.480404853820801,
      "logps/chosen": -134.94680786132812,
      "logps/rejected": -66.62188720703125,
      "loss": 0.2459,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6246941089630127,
      "rewards/margins": 1.3072495460510254,
      "rewards/rejected": -0.6825554370880127,
      "step": 720
    },
    {
      "epoch": 0.2884,
      "grad_norm": 14.181028366088867,
      "learning_rate": 9.039999999999999e-07,
      "logits/chosen": -2.523439884185791,
      "logits/rejected": -2.4991602897644043,
      "logps/chosen": -139.57711791992188,
      "logps/rejected": -53.01476287841797,
      "loss": 0.3578,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4900127649307251,
      "rewards/margins": 0.846653938293457,
      "rewards/rejected": -0.3566412031650543,
      "step": 721
    },
    {
      "epoch": 0.2888,
      "grad_norm": 8.083633422851562,
      "learning_rate": 9.038666666666666e-07,
      "logits/chosen": -2.840791702270508,
      "logits/rejected": -2.4470162391662598,
      "logps/chosen": -96.30170440673828,
      "logps/rejected": -80.2275390625,
      "loss": 0.2677,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5920222997665405,
      "rewards/margins": 1.2059506177902222,
      "rewards/rejected": -0.6139282584190369,
      "step": 722
    },
    {
      "epoch": 0.2892,
      "grad_norm": 9.094335556030273,
      "learning_rate": 9.037333333333333e-07,
      "logits/chosen": -2.4481053352355957,
      "logits/rejected": -1.9477474689483643,
      "logps/chosen": -78.56172180175781,
      "logps/rejected": -57.63764953613281,
      "loss": 0.3359,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5820404291152954,
      "rewards/margins": 0.9187830686569214,
      "rewards/rejected": -0.3367425799369812,
      "step": 723
    },
    {
      "epoch": 0.2896,
      "grad_norm": 7.346125602722168,
      "learning_rate": 9.035999999999999e-07,
      "logits/chosen": -2.5806140899658203,
      "logits/rejected": -2.247767686843872,
      "logps/chosen": -60.00076675415039,
      "logps/rejected": -68.6451416015625,
      "loss": 0.3051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42142564058303833,
      "rewards/margins": 1.0448763370513916,
      "rewards/rejected": -0.6234506368637085,
      "step": 724
    },
    {
      "epoch": 0.29,
      "grad_norm": 8.740726470947266,
      "learning_rate": 9.034666666666666e-07,
      "logits/chosen": -2.7918686866760254,
      "logits/rejected": -2.23384428024292,
      "logps/chosen": -56.30121612548828,
      "logps/rejected": -53.929439544677734,
      "loss": 0.309,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.545427143573761,
      "rewards/margins": 1.0781720876693726,
      "rewards/rejected": -0.5327450037002563,
      "step": 725
    },
    {
      "epoch": 0.2904,
      "grad_norm": 6.811424732208252,
      "learning_rate": 9.033333333333333e-07,
      "logits/chosen": -2.573882579803467,
      "logits/rejected": -2.2405548095703125,
      "logps/chosen": -81.52352905273438,
      "logps/rejected": -55.50724792480469,
      "loss": 0.2518,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.790283203125,
      "rewards/margins": 1.257047176361084,
      "rewards/rejected": -0.4667639136314392,
      "step": 726
    },
    {
      "epoch": 0.2908,
      "grad_norm": 6.237963676452637,
      "learning_rate": 9.032e-07,
      "logits/chosen": -2.3264355659484863,
      "logits/rejected": -2.110527992248535,
      "logps/chosen": -185.07781982421875,
      "logps/rejected": -114.62826538085938,
      "loss": 0.1762,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1890395879745483,
      "rewards/margins": 1.7458477020263672,
      "rewards/rejected": -0.5568081140518188,
      "step": 727
    },
    {
      "epoch": 0.2912,
      "grad_norm": 9.384868621826172,
      "learning_rate": 9.030666666666667e-07,
      "logits/chosen": -2.772392749786377,
      "logits/rejected": -2.521284818649292,
      "logps/chosen": -166.80300903320312,
      "logps/rejected": -64.04943084716797,
      "loss": 0.2502,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4137108027935028,
      "rewards/margins": 1.2983267307281494,
      "rewards/rejected": -0.884615957736969,
      "step": 728
    },
    {
      "epoch": 0.2916,
      "grad_norm": 13.9273099899292,
      "learning_rate": 9.029333333333334e-07,
      "logits/chosen": -2.7238833904266357,
      "logits/rejected": -2.3087639808654785,
      "logps/chosen": -71.50462341308594,
      "logps/rejected": -89.40652465820312,
      "loss": 0.4459,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4435710906982422,
      "rewards/margins": 0.6527041792869568,
      "rewards/rejected": -0.2091330587863922,
      "step": 729
    },
    {
      "epoch": 0.292,
      "grad_norm": 7.545376777648926,
      "learning_rate": 9.028e-07,
      "logits/chosen": -2.816263198852539,
      "logits/rejected": -2.9683079719543457,
      "logps/chosen": -80.19145202636719,
      "logps/rejected": -41.22601318359375,
      "loss": 0.2881,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6106289029121399,
      "rewards/margins": 1.096935749053955,
      "rewards/rejected": -0.4863067865371704,
      "step": 730
    },
    {
      "epoch": 0.2924,
      "grad_norm": 5.885869026184082,
      "learning_rate": 9.026666666666665e-07,
      "logits/chosen": -2.9122512340545654,
      "logits/rejected": -2.7673697471618652,
      "logps/chosen": -86.3035888671875,
      "logps/rejected": -56.41545486450195,
      "loss": 0.293,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3889952003955841,
      "rewards/margins": 1.3581409454345703,
      "rewards/rejected": -0.9691457748413086,
      "step": 731
    },
    {
      "epoch": 0.2928,
      "grad_norm": 8.739847183227539,
      "learning_rate": 9.025333333333332e-07,
      "logits/chosen": -2.718491554260254,
      "logits/rejected": -2.4581942558288574,
      "logps/chosen": -52.982391357421875,
      "logps/rejected": -68.99472045898438,
      "loss": 0.3682,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33945178985595703,
      "rewards/margins": 0.9735414385795593,
      "rewards/rejected": -0.6340896487236023,
      "step": 732
    },
    {
      "epoch": 0.2932,
      "grad_norm": 5.67936372756958,
      "learning_rate": 9.023999999999999e-07,
      "logits/chosen": -2.7346482276916504,
      "logits/rejected": -2.3775086402893066,
      "logps/chosen": -115.82313537597656,
      "logps/rejected": -53.887027740478516,
      "loss": 0.2131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.907758355140686,
      "rewards/margins": 1.4665663242340088,
      "rewards/rejected": -0.5588080286979675,
      "step": 733
    },
    {
      "epoch": 0.2936,
      "grad_norm": 6.3167524337768555,
      "learning_rate": 9.022666666666666e-07,
      "logits/chosen": -2.734769344329834,
      "logits/rejected": -2.3182802200317383,
      "logps/chosen": -99.61814880371094,
      "logps/rejected": -90.68860626220703,
      "loss": 0.2041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9483921527862549,
      "rewards/margins": 1.5460288524627686,
      "rewards/rejected": -0.5976368188858032,
      "step": 734
    },
    {
      "epoch": 0.294,
      "grad_norm": 7.718618392944336,
      "learning_rate": 9.021333333333333e-07,
      "logits/chosen": -2.6961231231689453,
      "logits/rejected": -2.6723287105560303,
      "logps/chosen": -76.46514129638672,
      "logps/rejected": -56.466487884521484,
      "loss": 0.4172,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32592469453811646,
      "rewards/margins": 0.6792594790458679,
      "rewards/rejected": -0.35333481431007385,
      "step": 735
    },
    {
      "epoch": 0.2944,
      "grad_norm": 10.81557559967041,
      "learning_rate": 9.02e-07,
      "logits/chosen": -2.37554931640625,
      "logits/rejected": -2.578768730163574,
      "logps/chosen": -129.7819061279297,
      "logps/rejected": -60.111228942871094,
      "loss": 0.2929,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7315323352813721,
      "rewards/margins": 1.0843522548675537,
      "rewards/rejected": -0.35281991958618164,
      "step": 736
    },
    {
      "epoch": 0.2948,
      "grad_norm": 7.313334941864014,
      "learning_rate": 9.018666666666667e-07,
      "logits/chosen": -2.713963031768799,
      "logits/rejected": -2.6831679344177246,
      "logps/chosen": -86.78471374511719,
      "logps/rejected": -30.666881561279297,
      "loss": 0.3223,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6087757349014282,
      "rewards/margins": 0.9667224884033203,
      "rewards/rejected": -0.3579467833042145,
      "step": 737
    },
    {
      "epoch": 0.2952,
      "grad_norm": 7.945868968963623,
      "learning_rate": 9.017333333333334e-07,
      "logits/chosen": -2.9315667152404785,
      "logits/rejected": -2.5839343070983887,
      "logps/chosen": -55.33158874511719,
      "logps/rejected": -60.85956954956055,
      "loss": 0.286,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.48665258288383484,
      "rewards/margins": 1.1283891201019287,
      "rewards/rejected": -0.641736626625061,
      "step": 738
    },
    {
      "epoch": 0.2956,
      "grad_norm": 6.317264556884766,
      "learning_rate": 9.015999999999999e-07,
      "logits/chosen": -2.480071544647217,
      "logits/rejected": -2.1184277534484863,
      "logps/chosen": -100.20500183105469,
      "logps/rejected": -102.47216796875,
      "loss": 0.186,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9506741166114807,
      "rewards/margins": 1.7222908735275269,
      "rewards/rejected": -0.7716167569160461,
      "step": 739
    },
    {
      "epoch": 0.296,
      "grad_norm": 7.541189193725586,
      "learning_rate": 9.014666666666666e-07,
      "logits/chosen": -2.404848098754883,
      "logits/rejected": -2.2438368797302246,
      "logps/chosen": -144.03089904785156,
      "logps/rejected": -78.7430419921875,
      "loss": 0.2149,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7434967160224915,
      "rewards/margins": 1.4295628070831299,
      "rewards/rejected": -0.6860660314559937,
      "step": 740
    },
    {
      "epoch": 0.2964,
      "grad_norm": 6.749744892120361,
      "learning_rate": 9.013333333333333e-07,
      "logits/chosen": -2.6732497215270996,
      "logits/rejected": -2.2026190757751465,
      "logps/chosen": -125.8379898071289,
      "logps/rejected": -84.8037109375,
      "loss": 0.174,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3689804077148438,
      "rewards/margins": 1.762899398803711,
      "rewards/rejected": -0.3939189910888672,
      "step": 741
    },
    {
      "epoch": 0.2968,
      "grad_norm": 7.5069804191589355,
      "learning_rate": 9.011999999999999e-07,
      "logits/chosen": -2.571533679962158,
      "logits/rejected": -2.0907795429229736,
      "logps/chosen": -134.4679412841797,
      "logps/rejected": -71.93775177001953,
      "loss": 0.2595,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7589786648750305,
      "rewards/margins": 1.2710273265838623,
      "rewards/rejected": -0.5120487213134766,
      "step": 742
    },
    {
      "epoch": 0.2972,
      "grad_norm": 10.88237190246582,
      "learning_rate": 9.010666666666666e-07,
      "logits/chosen": -2.530947208404541,
      "logits/rejected": -1.9832721948623657,
      "logps/chosen": -163.31004333496094,
      "logps/rejected": -104.2197036743164,
      "loss": 0.3299,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6497929096221924,
      "rewards/margins": 0.9457108974456787,
      "rewards/rejected": -0.2959180772304535,
      "step": 743
    },
    {
      "epoch": 0.2976,
      "grad_norm": 6.868620872497559,
      "learning_rate": 9.009333333333333e-07,
      "logits/chosen": -2.7869231700897217,
      "logits/rejected": -2.585127830505371,
      "logps/chosen": -68.60799407958984,
      "logps/rejected": -35.93799591064453,
      "loss": 0.3336,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4574587047100067,
      "rewards/margins": 0.9437280893325806,
      "rewards/rejected": -0.48626938462257385,
      "step": 744
    },
    {
      "epoch": 0.298,
      "grad_norm": 8.11440658569336,
      "learning_rate": 9.008e-07,
      "logits/chosen": -2.8880972862243652,
      "logits/rejected": -2.5196547508239746,
      "logps/chosen": -100.2083511352539,
      "logps/rejected": -36.85550308227539,
      "loss": 0.3334,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4810377359390259,
      "rewards/margins": 0.9285468459129333,
      "rewards/rejected": -0.44750910997390747,
      "step": 745
    },
    {
      "epoch": 0.2984,
      "grad_norm": 7.131343841552734,
      "learning_rate": 9.006666666666666e-07,
      "logits/chosen": -2.9102954864501953,
      "logits/rejected": -2.7817366123199463,
      "logps/chosen": -56.753326416015625,
      "logps/rejected": -51.4869384765625,
      "loss": 0.3649,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5928112268447876,
      "rewards/margins": 0.8419780731201172,
      "rewards/rejected": -0.24916687607765198,
      "step": 746
    },
    {
      "epoch": 0.2988,
      "grad_norm": 6.204801559448242,
      "learning_rate": 9.005333333333333e-07,
      "logits/chosen": -2.7478976249694824,
      "logits/rejected": -2.075070858001709,
      "logps/chosen": -76.71873474121094,
      "logps/rejected": -71.75800323486328,
      "loss": 0.1863,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7720718383789062,
      "rewards/margins": 1.6128352880477905,
      "rewards/rejected": -0.8407634496688843,
      "step": 747
    },
    {
      "epoch": 0.2992,
      "grad_norm": 10.548720359802246,
      "learning_rate": 9.004e-07,
      "logits/chosen": -2.5749406814575195,
      "logits/rejected": -2.4639127254486084,
      "logps/chosen": -111.48954772949219,
      "logps/rejected": -51.482479095458984,
      "loss": 0.3713,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6392242312431335,
      "rewards/margins": 0.8066492080688477,
      "rewards/rejected": -0.16742496192455292,
      "step": 748
    },
    {
      "epoch": 0.2996,
      "grad_norm": 7.196898460388184,
      "learning_rate": 9.002666666666666e-07,
      "logits/chosen": -2.5775372982025146,
      "logits/rejected": -2.455315589904785,
      "logps/chosen": -132.8561248779297,
      "logps/rejected": -48.15062713623047,
      "loss": 0.2298,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8988437652587891,
      "rewards/margins": 1.3623520135879517,
      "rewards/rejected": -0.4635082185268402,
      "step": 749
    },
    {
      "epoch": 0.3,
      "grad_norm": 8.085476875305176,
      "learning_rate": 9.001333333333333e-07,
      "logits/chosen": -2.8848719596862793,
      "logits/rejected": -2.567204475402832,
      "logps/chosen": -84.18673706054688,
      "logps/rejected": -43.94105529785156,
      "loss": 0.3705,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.37423285841941833,
      "rewards/margins": 0.8348708152770996,
      "rewards/rejected": -0.4606379568576813,
      "step": 750
    },
    {
      "epoch": 0.3004,
      "grad_norm": 13.896806716918945,
      "learning_rate": 9e-07,
      "logits/chosen": -2.7528152465820312,
      "logits/rejected": -3.0556936264038086,
      "logps/chosen": -78.92964172363281,
      "logps/rejected": -87.2989273071289,
      "loss": 0.2294,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9933645129203796,
      "rewards/margins": 1.3599326610565186,
      "rewards/rejected": -0.3665681779384613,
      "step": 751
    },
    {
      "epoch": 0.3008,
      "grad_norm": 6.616849899291992,
      "learning_rate": 8.998666666666667e-07,
      "logits/chosen": -2.678673267364502,
      "logits/rejected": -2.228010892868042,
      "logps/chosen": -121.83843231201172,
      "logps/rejected": -60.965789794921875,
      "loss": 0.228,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.80929034948349,
      "rewards/margins": 1.408384919166565,
      "rewards/rejected": -0.599094569683075,
      "step": 752
    },
    {
      "epoch": 0.3012,
      "grad_norm": 7.3444037437438965,
      "learning_rate": 8.997333333333333e-07,
      "logits/chosen": -2.4151365756988525,
      "logits/rejected": -2.2729482650756836,
      "logps/chosen": -116.29081726074219,
      "logps/rejected": -83.54830169677734,
      "loss": 0.2008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8198410272598267,
      "rewards/margins": 1.5123329162597656,
      "rewards/rejected": -0.6924919486045837,
      "step": 753
    },
    {
      "epoch": 0.3016,
      "grad_norm": 6.946570873260498,
      "learning_rate": 8.995999999999999e-07,
      "logits/chosen": -2.6965932846069336,
      "logits/rejected": -2.2388806343078613,
      "logps/chosen": -167.738037109375,
      "logps/rejected": -89.93268585205078,
      "loss": 0.1726,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2053269147872925,
      "rewards/margins": 1.7092045545578003,
      "rewards/rejected": -0.5038776397705078,
      "step": 754
    },
    {
      "epoch": 0.302,
      "grad_norm": 10.388171195983887,
      "learning_rate": 8.994666666666666e-07,
      "logits/chosen": -2.297956943511963,
      "logits/rejected": -2.109140396118164,
      "logps/chosen": -164.58877563476562,
      "logps/rejected": -87.42314910888672,
      "loss": 0.2514,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7517166137695312,
      "rewards/margins": 1.3781193494796753,
      "rewards/rejected": -0.6264026761054993,
      "step": 755
    },
    {
      "epoch": 0.3024,
      "grad_norm": 8.4502534866333,
      "learning_rate": 8.993333333333333e-07,
      "logits/chosen": -2.9249792098999023,
      "logits/rejected": -2.758791923522949,
      "logps/chosen": -101.76899719238281,
      "logps/rejected": -45.12401580810547,
      "loss": 0.3442,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5125350952148438,
      "rewards/margins": 0.902450680732727,
      "rewards/rejected": -0.3899155855178833,
      "step": 756
    },
    {
      "epoch": 0.3028,
      "grad_norm": 5.808495998382568,
      "learning_rate": 8.992e-07,
      "logits/chosen": -2.624826431274414,
      "logits/rejected": -2.2092666625976562,
      "logps/chosen": -72.63581848144531,
      "logps/rejected": -97.73638153076172,
      "loss": 0.1772,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9997463226318359,
      "rewards/margins": 1.6564793586730957,
      "rewards/rejected": -0.6567329168319702,
      "step": 757
    },
    {
      "epoch": 0.3032,
      "grad_norm": 6.7344865798950195,
      "learning_rate": 8.990666666666666e-07,
      "logits/chosen": -2.4159388542175293,
      "logits/rejected": -2.1907460689544678,
      "logps/chosen": -134.3792724609375,
      "logps/rejected": -101.6212158203125,
      "loss": 0.1706,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2693428993225098,
      "rewards/margins": 1.6921744346618652,
      "rewards/rejected": -0.42283153533935547,
      "step": 758
    },
    {
      "epoch": 0.3036,
      "grad_norm": 4.566797256469727,
      "learning_rate": 8.989333333333333e-07,
      "logits/chosen": -2.6369361877441406,
      "logits/rejected": -2.5918736457824707,
      "logps/chosen": -139.05535888671875,
      "logps/rejected": -73.31631469726562,
      "loss": 0.1551,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4683501720428467,
      "rewards/margins": 1.9028687477111816,
      "rewards/rejected": -0.43451863527297974,
      "step": 759
    },
    {
      "epoch": 0.304,
      "grad_norm": 4.3818488121032715,
      "learning_rate": 8.988e-07,
      "logits/chosen": -2.5497655868530273,
      "logits/rejected": -2.264972686767578,
      "logps/chosen": -96.42190551757812,
      "logps/rejected": -96.74689483642578,
      "loss": 0.1065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2474751472473145,
      "rewards/margins": 2.188232421875,
      "rewards/rejected": -0.9407573938369751,
      "step": 760
    },
    {
      "epoch": 0.3044,
      "grad_norm": 6.756950378417969,
      "learning_rate": 8.986666666666666e-07,
      "logits/chosen": -2.502277374267578,
      "logits/rejected": -1.8609037399291992,
      "logps/chosen": -139.94212341308594,
      "logps/rejected": -159.4227294921875,
      "loss": 0.1468,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2248234748840332,
      "rewards/margins": 1.8451133966445923,
      "rewards/rejected": -0.6202899813652039,
      "step": 761
    },
    {
      "epoch": 0.3048,
      "grad_norm": 7.262303352355957,
      "learning_rate": 8.985333333333333e-07,
      "logits/chosen": -2.5442166328430176,
      "logits/rejected": -2.331808090209961,
      "logps/chosen": -92.19696044921875,
      "logps/rejected": -90.67669677734375,
      "loss": 0.2544,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1072450876235962,
      "rewards/margins": 1.4614709615707397,
      "rewards/rejected": -0.35422584414482117,
      "step": 762
    },
    {
      "epoch": 0.3052,
      "grad_norm": 6.9715256690979,
      "learning_rate": 8.983999999999999e-07,
      "logits/chosen": -2.842066764831543,
      "logits/rejected": -2.6029157638549805,
      "logps/chosen": -91.86813354492188,
      "logps/rejected": -69.1793212890625,
      "loss": 0.2705,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5362497568130493,
      "rewards/margins": 1.2726751565933228,
      "rewards/rejected": -0.7364253997802734,
      "step": 763
    },
    {
      "epoch": 0.3056,
      "grad_norm": 6.639444828033447,
      "learning_rate": 8.982666666666666e-07,
      "logits/chosen": -2.3508214950561523,
      "logits/rejected": -2.2313177585601807,
      "logps/chosen": -149.9759979248047,
      "logps/rejected": -78.91419982910156,
      "loss": 0.2064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2531265020370483,
      "rewards/margins": 1.5616772174835205,
      "rewards/rejected": -0.3085506558418274,
      "step": 764
    },
    {
      "epoch": 0.306,
      "grad_norm": 7.881855010986328,
      "learning_rate": 8.981333333333333e-07,
      "logits/chosen": -2.633554458618164,
      "logits/rejected": -2.446404457092285,
      "logps/chosen": -99.48638153076172,
      "logps/rejected": -56.08729553222656,
      "loss": 0.2923,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8610820770263672,
      "rewards/margins": 1.0964243412017822,
      "rewards/rejected": -0.23534221947193146,
      "step": 765
    },
    {
      "epoch": 0.3064,
      "grad_norm": 7.730654716491699,
      "learning_rate": 8.98e-07,
      "logits/chosen": -2.523947238922119,
      "logits/rejected": -2.306161642074585,
      "logps/chosen": -56.77448654174805,
      "logps/rejected": -59.6641845703125,
      "loss": 0.2405,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5722774267196655,
      "rewards/margins": 1.360029935836792,
      "rewards/rejected": -0.7877525091171265,
      "step": 766
    },
    {
      "epoch": 0.3068,
      "grad_norm": 8.163651466369629,
      "learning_rate": 8.978666666666667e-07,
      "logits/chosen": -2.449178695678711,
      "logits/rejected": -2.046588182449341,
      "logps/chosen": -88.13780212402344,
      "logps/rejected": -76.73057556152344,
      "loss": 0.2334,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35794201493263245,
      "rewards/margins": 1.3464463949203491,
      "rewards/rejected": -0.9885044097900391,
      "step": 767
    },
    {
      "epoch": 0.3072,
      "grad_norm": 6.906193256378174,
      "learning_rate": 8.977333333333333e-07,
      "logits/chosen": -2.632310390472412,
      "logits/rejected": -2.341705322265625,
      "logps/chosen": -69.98936462402344,
      "logps/rejected": -40.01313781738281,
      "loss": 0.2588,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9420093297958374,
      "rewards/margins": 1.2417047023773193,
      "rewards/rejected": -0.2996954023838043,
      "step": 768
    },
    {
      "epoch": 0.3076,
      "grad_norm": 8.937348365783691,
      "learning_rate": 8.975999999999999e-07,
      "logits/chosen": -2.4846301078796387,
      "logits/rejected": -2.490629196166992,
      "logps/chosen": -145.27003479003906,
      "logps/rejected": -55.8658447265625,
      "loss": 0.2977,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7048676013946533,
      "rewards/margins": 1.064859390258789,
      "rewards/rejected": -0.3599918484687805,
      "step": 769
    },
    {
      "epoch": 0.308,
      "grad_norm": 6.112175941467285,
      "learning_rate": 8.974666666666666e-07,
      "logits/chosen": -2.81559419631958,
      "logits/rejected": -2.3094983100891113,
      "logps/chosen": -95.55073547363281,
      "logps/rejected": -68.52017211914062,
      "loss": 0.1826,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8410763144493103,
      "rewards/margins": 1.6196434497833252,
      "rewards/rejected": -0.7785671353340149,
      "step": 770
    },
    {
      "epoch": 0.3084,
      "grad_norm": 6.188553333282471,
      "learning_rate": 8.973333333333333e-07,
      "logits/chosen": -2.984691619873047,
      "logits/rejected": -2.451913356781006,
      "logps/chosen": -37.89564514160156,
      "logps/rejected": -53.4818229675293,
      "loss": 0.2652,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35887566208839417,
      "rewards/margins": 1.1996662616729736,
      "rewards/rejected": -0.8407905697822571,
      "step": 771
    },
    {
      "epoch": 0.3088,
      "grad_norm": 7.920069694519043,
      "learning_rate": 8.972e-07,
      "logits/chosen": -2.881930351257324,
      "logits/rejected": -2.3347887992858887,
      "logps/chosen": -99.49642944335938,
      "logps/rejected": -71.40538024902344,
      "loss": 0.2131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6298969388008118,
      "rewards/margins": 1.4391703605651855,
      "rewards/rejected": -0.809273362159729,
      "step": 772
    },
    {
      "epoch": 0.3092,
      "grad_norm": 7.501291275024414,
      "learning_rate": 8.970666666666667e-07,
      "logits/chosen": -2.9128549098968506,
      "logits/rejected": -2.4957497119903564,
      "logps/chosen": -55.15476608276367,
      "logps/rejected": -48.574466705322266,
      "loss": 0.2773,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.604826807975769,
      "rewards/margins": 1.1411852836608887,
      "rewards/rejected": -0.5363584756851196,
      "step": 773
    },
    {
      "epoch": 0.3096,
      "grad_norm": 11.053499221801758,
      "learning_rate": 8.969333333333333e-07,
      "logits/chosen": -2.313347578048706,
      "logits/rejected": -2.3122634887695312,
      "logps/chosen": -109.98641967773438,
      "logps/rejected": -56.223876953125,
      "loss": 0.4687,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08871765434741974,
      "rewards/margins": 0.5526806116104126,
      "rewards/rejected": -0.6413982510566711,
      "step": 774
    },
    {
      "epoch": 0.31,
      "grad_norm": 7.458407878875732,
      "learning_rate": 8.968e-07,
      "logits/chosen": -2.6854770183563232,
      "logits/rejected": -2.4202489852905273,
      "logps/chosen": -91.53843688964844,
      "logps/rejected": -76.38694763183594,
      "loss": 0.2744,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.660900890827179,
      "rewards/margins": 1.1540799140930176,
      "rewards/rejected": -0.49317896366119385,
      "step": 775
    },
    {
      "epoch": 0.3104,
      "grad_norm": 8.373902320861816,
      "learning_rate": 8.966666666666666e-07,
      "logits/chosen": -2.8832454681396484,
      "logits/rejected": -2.627331256866455,
      "logps/chosen": -76.49574279785156,
      "logps/rejected": -51.10267639160156,
      "loss": 0.2274,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6066499948501587,
      "rewards/margins": 1.3653228282928467,
      "rewards/rejected": -0.7586729526519775,
      "step": 776
    },
    {
      "epoch": 0.3108,
      "grad_norm": 6.999855041503906,
      "learning_rate": 8.965333333333332e-07,
      "logits/chosen": -2.5199084281921387,
      "logits/rejected": -2.137585163116455,
      "logps/chosen": -88.50587463378906,
      "logps/rejected": -93.4415283203125,
      "loss": 0.2315,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7872581481933594,
      "rewards/margins": 1.350565791130066,
      "rewards/rejected": -0.5633075833320618,
      "step": 777
    },
    {
      "epoch": 0.3112,
      "grad_norm": 6.958653926849365,
      "learning_rate": 8.963999999999999e-07,
      "logits/chosen": -2.693066120147705,
      "logits/rejected": -2.4209794998168945,
      "logps/chosen": -99.79360961914062,
      "logps/rejected": -62.49409484863281,
      "loss": 0.2399,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6426963806152344,
      "rewards/margins": 1.3120529651641846,
      "rewards/rejected": -0.6693565845489502,
      "step": 778
    },
    {
      "epoch": 0.3116,
      "grad_norm": 8.078139305114746,
      "learning_rate": 8.962666666666666e-07,
      "logits/chosen": -2.6154885292053223,
      "logits/rejected": -2.5551400184631348,
      "logps/chosen": -120.83432006835938,
      "logps/rejected": -67.35116577148438,
      "loss": 0.223,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.536566972732544,
      "rewards/margins": 1.4207651615142822,
      "rewards/rejected": -0.8841981887817383,
      "step": 779
    },
    {
      "epoch": 0.312,
      "grad_norm": 6.583934307098389,
      "learning_rate": 8.961333333333333e-07,
      "logits/chosen": -2.5494649410247803,
      "logits/rejected": -2.4042701721191406,
      "logps/chosen": -83.66366577148438,
      "logps/rejected": -35.02458953857422,
      "loss": 0.2474,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8898962140083313,
      "rewards/margins": 1.346017837524414,
      "rewards/rejected": -0.456121563911438,
      "step": 780
    },
    {
      "epoch": 0.3124,
      "grad_norm": 8.08295726776123,
      "learning_rate": 8.96e-07,
      "logits/chosen": -2.794790506362915,
      "logits/rejected": -2.457855224609375,
      "logps/chosen": -103.86965942382812,
      "logps/rejected": -45.720603942871094,
      "loss": 0.2948,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4538721442222595,
      "rewards/margins": 1.0758860111236572,
      "rewards/rejected": -0.6220138669013977,
      "step": 781
    },
    {
      "epoch": 0.3128,
      "grad_norm": 5.575552940368652,
      "learning_rate": 8.958666666666667e-07,
      "logits/chosen": -2.802363872528076,
      "logits/rejected": -2.3230037689208984,
      "logps/chosen": -75.40699768066406,
      "logps/rejected": -72.71189880371094,
      "loss": 0.1812,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8627743124961853,
      "rewards/margins": 1.67447829246521,
      "rewards/rejected": -0.8117039203643799,
      "step": 782
    },
    {
      "epoch": 0.3132,
      "grad_norm": 7.957990646362305,
      "learning_rate": 8.957333333333334e-07,
      "logits/chosen": -2.8768930435180664,
      "logits/rejected": -2.57826566696167,
      "logps/chosen": -75.64248657226562,
      "logps/rejected": -56.78424835205078,
      "loss": 0.2909,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.37035274505615234,
      "rewards/margins": 1.095208764076233,
      "rewards/rejected": -0.7248560190200806,
      "step": 783
    },
    {
      "epoch": 0.3136,
      "grad_norm": 5.210983753204346,
      "learning_rate": 8.955999999999999e-07,
      "logits/chosen": -2.5217390060424805,
      "logits/rejected": -2.441293239593506,
      "logps/chosen": -122.93872833251953,
      "logps/rejected": -61.50157928466797,
      "loss": 0.1803,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2393803596496582,
      "rewards/margins": 1.662644624710083,
      "rewards/rejected": -0.4232643246650696,
      "step": 784
    },
    {
      "epoch": 0.314,
      "grad_norm": 6.308104991912842,
      "learning_rate": 8.954666666666666e-07,
      "logits/chosen": -2.9165525436401367,
      "logits/rejected": -3.105700969696045,
      "logps/chosen": -53.67245101928711,
      "logps/rejected": -33.93899154663086,
      "loss": 0.3303,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7896659970283508,
      "rewards/margins": 0.9437333941459656,
      "rewards/rejected": -0.15406742691993713,
      "step": 785
    },
    {
      "epoch": 0.3144,
      "grad_norm": 6.0650105476379395,
      "learning_rate": 8.953333333333332e-07,
      "logits/chosen": -2.481293201446533,
      "logits/rejected": -2.118490219116211,
      "logps/chosen": -74.32994079589844,
      "logps/rejected": -136.42503356933594,
      "loss": 0.1295,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1219249963760376,
      "rewards/margins": 2.0082733631134033,
      "rewards/rejected": -0.8863483667373657,
      "step": 786
    },
    {
      "epoch": 0.3148,
      "grad_norm": 10.056273460388184,
      "learning_rate": 8.951999999999999e-07,
      "logits/chosen": -2.327404737472534,
      "logits/rejected": -2.1409482955932617,
      "logps/chosen": -137.2958221435547,
      "logps/rejected": -62.02166748046875,
      "loss": 0.3093,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8404346704483032,
      "rewards/margins": 1.042905569076538,
      "rewards/rejected": -0.20247097313404083,
      "step": 787
    },
    {
      "epoch": 0.3152,
      "grad_norm": 9.831399917602539,
      "learning_rate": 8.950666666666666e-07,
      "logits/chosen": -2.603484630584717,
      "logits/rejected": -2.431993007659912,
      "logps/chosen": -69.4738540649414,
      "logps/rejected": -137.61322021484375,
      "loss": 0.3733,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6972160339355469,
      "rewards/margins": 0.8713958859443665,
      "rewards/rejected": -0.1741798371076584,
      "step": 788
    },
    {
      "epoch": 0.3156,
      "grad_norm": 7.851890563964844,
      "learning_rate": 8.949333333333333e-07,
      "logits/chosen": -2.578274726867676,
      "logits/rejected": -2.237581253051758,
      "logps/chosen": -207.04415893554688,
      "logps/rejected": -81.88096618652344,
      "loss": 0.2389,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6916977167129517,
      "rewards/margins": 1.3644459247589111,
      "rewards/rejected": -0.6727482080459595,
      "step": 789
    },
    {
      "epoch": 0.316,
      "grad_norm": 10.676763534545898,
      "learning_rate": 8.948e-07,
      "logits/chosen": -2.4379920959472656,
      "logits/rejected": -2.0170695781707764,
      "logps/chosen": -67.26722717285156,
      "logps/rejected": -127.41734313964844,
      "loss": 0.3093,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5609615445137024,
      "rewards/margins": 1.112443447113037,
      "rewards/rejected": -0.5514820218086243,
      "step": 790
    },
    {
      "epoch": 0.3164,
      "grad_norm": 7.13830041885376,
      "learning_rate": 8.946666666666667e-07,
      "logits/chosen": -2.7978270053863525,
      "logits/rejected": -2.4934539794921875,
      "logps/chosen": -78.9093246459961,
      "logps/rejected": -62.627784729003906,
      "loss": 0.3334,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.669904351234436,
      "rewards/margins": 0.9971987009048462,
      "rewards/rejected": -0.32729434967041016,
      "step": 791
    },
    {
      "epoch": 0.3168,
      "grad_norm": 5.769348621368408,
      "learning_rate": 8.945333333333333e-07,
      "logits/chosen": -2.3708949089050293,
      "logits/rejected": -2.287838935852051,
      "logps/chosen": -105.8002700805664,
      "logps/rejected": -69.0576171875,
      "loss": 0.1902,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0724300146102905,
      "rewards/margins": 1.5651241540908813,
      "rewards/rejected": -0.49269410967826843,
      "step": 792
    },
    {
      "epoch": 0.3172,
      "grad_norm": 5.280757904052734,
      "learning_rate": 8.944e-07,
      "logits/chosen": -2.7702953815460205,
      "logits/rejected": -2.412677049636841,
      "logps/chosen": -111.61485290527344,
      "logps/rejected": -62.19666290283203,
      "loss": 0.1552,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1285980939865112,
      "rewards/margins": 1.8422057628631592,
      "rewards/rejected": -0.7136076092720032,
      "step": 793
    },
    {
      "epoch": 0.3176,
      "grad_norm": 6.228093147277832,
      "learning_rate": 8.942666666666667e-07,
      "logits/chosen": -2.4042866230010986,
      "logits/rejected": -2.28610897064209,
      "logps/chosen": -113.57437133789062,
      "logps/rejected": -88.58372497558594,
      "loss": 0.1763,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2117867469787598,
      "rewards/margins": 1.654254674911499,
      "rewards/rejected": -0.4424680769443512,
      "step": 794
    },
    {
      "epoch": 0.318,
      "grad_norm": 9.635610580444336,
      "learning_rate": 8.941333333333333e-07,
      "logits/chosen": -2.6628570556640625,
      "logits/rejected": -2.5775399208068848,
      "logps/chosen": -104.66206359863281,
      "logps/rejected": -39.893150329589844,
      "loss": 0.3601,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33388596773147583,
      "rewards/margins": 0.8371639251708984,
      "rewards/rejected": -0.5032779574394226,
      "step": 795
    },
    {
      "epoch": 0.3184,
      "grad_norm": 5.869877815246582,
      "learning_rate": 8.939999999999999e-07,
      "logits/chosen": -2.5619406700134277,
      "logits/rejected": -2.2488350868225098,
      "logps/chosen": -110.34123229980469,
      "logps/rejected": -66.36968231201172,
      "loss": 0.1793,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1547253131866455,
      "rewards/margins": 1.7009207010269165,
      "rewards/rejected": -0.546195387840271,
      "step": 796
    },
    {
      "epoch": 0.3188,
      "grad_norm": 7.2033305168151855,
      "learning_rate": 8.938666666666666e-07,
      "logits/chosen": -3.089804172515869,
      "logits/rejected": -3.223066806793213,
      "logps/chosen": -45.9089241027832,
      "logps/rejected": -43.36564636230469,
      "loss": 0.425,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.37192633748054504,
      "rewards/margins": 0.66668301820755,
      "rewards/rejected": -0.2947567105293274,
      "step": 797
    },
    {
      "epoch": 0.3192,
      "grad_norm": 6.4284348487854,
      "learning_rate": 8.937333333333333e-07,
      "logits/chosen": -2.8025195598602295,
      "logits/rejected": -2.7615818977355957,
      "logps/chosen": -74.66809844970703,
      "logps/rejected": -58.33994674682617,
      "loss": 0.2371,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6590555310249329,
      "rewards/margins": 1.323520302772522,
      "rewards/rejected": -0.6644647717475891,
      "step": 798
    },
    {
      "epoch": 0.3196,
      "grad_norm": 7.552264213562012,
      "learning_rate": 8.935999999999999e-07,
      "logits/chosen": -2.813225746154785,
      "logits/rejected": -2.4481101036071777,
      "logps/chosen": -79.70016479492188,
      "logps/rejected": -82.7483139038086,
      "loss": 0.188,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8637065291404724,
      "rewards/margins": 1.57892644405365,
      "rewards/rejected": -0.7152199149131775,
      "step": 799
    },
    {
      "epoch": 0.32,
      "grad_norm": 5.191232681274414,
      "learning_rate": 8.934666666666666e-07,
      "logits/chosen": -3.037692070007324,
      "logits/rejected": -2.7084782123565674,
      "logps/chosen": -57.99483871459961,
      "logps/rejected": -54.53160858154297,
      "loss": 0.2313,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7051452398300171,
      "rewards/margins": 1.5123982429504395,
      "rewards/rejected": -0.8072529435157776,
      "step": 800
    },
    {
      "epoch": 0.3204,
      "grad_norm": 6.2277607917785645,
      "learning_rate": 8.933333333333333e-07,
      "logits/chosen": -2.7954306602478027,
      "logits/rejected": -2.433084011077881,
      "logps/chosen": -72.19369506835938,
      "logps/rejected": -57.528648376464844,
      "loss": 0.199,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.893598198890686,
      "rewards/margins": 1.5308197736740112,
      "rewards/rejected": -0.6372215747833252,
      "step": 801
    },
    {
      "epoch": 0.3208,
      "grad_norm": 8.305296897888184,
      "learning_rate": 8.932e-07,
      "logits/chosen": -2.7831950187683105,
      "logits/rejected": -2.6486334800720215,
      "logps/chosen": -58.131263732910156,
      "logps/rejected": -28.85354995727539,
      "loss": 0.4083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5333750247955322,
      "rewards/margins": 0.6908483505249023,
      "rewards/rejected": -0.1574733853340149,
      "step": 802
    },
    {
      "epoch": 0.3212,
      "grad_norm": 4.56040620803833,
      "learning_rate": 8.930666666666667e-07,
      "logits/chosen": -2.391615867614746,
      "logits/rejected": -1.9960671663284302,
      "logps/chosen": -96.43989562988281,
      "logps/rejected": -75.71080017089844,
      "loss": 0.125,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.261529564857483,
      "rewards/margins": 2.0169856548309326,
      "rewards/rejected": -0.7554562091827393,
      "step": 803
    },
    {
      "epoch": 0.3216,
      "grad_norm": 6.271476745605469,
      "learning_rate": 8.929333333333334e-07,
      "logits/chosen": -2.6387271881103516,
      "logits/rejected": -2.4303884506225586,
      "logps/chosen": -139.84854125976562,
      "logps/rejected": -64.65866088867188,
      "loss": 0.1896,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5649925470352173,
      "rewards/margins": 1.5664077997207642,
      "rewards/rejected": -1.0014152526855469,
      "step": 804
    },
    {
      "epoch": 0.322,
      "grad_norm": 7.521568298339844,
      "learning_rate": 8.928e-07,
      "logits/chosen": -2.7085585594177246,
      "logits/rejected": -2.4229812622070312,
      "logps/chosen": -69.61073303222656,
      "logps/rejected": -42.622215270996094,
      "loss": 0.3359,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5310035943984985,
      "rewards/margins": 0.9199774265289307,
      "rewards/rejected": -0.38897383213043213,
      "step": 805
    },
    {
      "epoch": 0.3224,
      "grad_norm": 5.365137100219727,
      "learning_rate": 8.926666666666666e-07,
      "logits/chosen": -2.613680124282837,
      "logits/rejected": -2.1232495307922363,
      "logps/chosen": -116.22994995117188,
      "logps/rejected": -59.94751739501953,
      "loss": 0.1312,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2663848400115967,
      "rewards/margins": 1.9688427448272705,
      "rewards/rejected": -0.7024577856063843,
      "step": 806
    },
    {
      "epoch": 0.3228,
      "grad_norm": 9.314889907836914,
      "learning_rate": 8.925333333333332e-07,
      "logits/chosen": -2.4821696281433105,
      "logits/rejected": -2.914647102355957,
      "logps/chosen": -121.0781478881836,
      "logps/rejected": -57.338714599609375,
      "loss": 0.2764,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7424942255020142,
      "rewards/margins": 1.1444127559661865,
      "rewards/rejected": -0.40191859006881714,
      "step": 807
    },
    {
      "epoch": 0.3232,
      "grad_norm": 9.012591361999512,
      "learning_rate": 8.923999999999999e-07,
      "logits/chosen": -2.709306240081787,
      "logits/rejected": -2.668400764465332,
      "logps/chosen": -86.30191040039062,
      "logps/rejected": -30.303266525268555,
      "loss": 0.5021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06309852749109268,
      "rewards/margins": 0.43520528078079224,
      "rewards/rejected": -0.37210676074028015,
      "step": 808
    },
    {
      "epoch": 0.3236,
      "grad_norm": 10.939990043640137,
      "learning_rate": 8.922666666666666e-07,
      "logits/chosen": -2.413313865661621,
      "logits/rejected": -2.139552593231201,
      "logps/chosen": -161.42218017578125,
      "logps/rejected": -94.02955627441406,
      "loss": 0.2971,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6474125385284424,
      "rewards/margins": 1.1628845930099487,
      "rewards/rejected": -0.5154720544815063,
      "step": 809
    },
    {
      "epoch": 0.324,
      "grad_norm": 5.1905388832092285,
      "learning_rate": 8.921333333333333e-07,
      "logits/chosen": -2.4711685180664062,
      "logits/rejected": -2.1094679832458496,
      "logps/chosen": -120.12840270996094,
      "logps/rejected": -86.46894836425781,
      "loss": 0.131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2113395929336548,
      "rewards/margins": 1.9661403894424438,
      "rewards/rejected": -0.7548007965087891,
      "step": 810
    },
    {
      "epoch": 0.3244,
      "grad_norm": 6.897722244262695,
      "learning_rate": 8.92e-07,
      "logits/chosen": -2.8807952404022217,
      "logits/rejected": -2.644207000732422,
      "logps/chosen": -36.75543212890625,
      "logps/rejected": -62.110107421875,
      "loss": 0.2492,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35809576511383057,
      "rewards/margins": 1.445957899093628,
      "rewards/rejected": -1.0878621339797974,
      "step": 811
    },
    {
      "epoch": 0.3248,
      "grad_norm": 5.544550895690918,
      "learning_rate": 8.918666666666667e-07,
      "logits/chosen": -2.6658835411071777,
      "logits/rejected": -2.1991357803344727,
      "logps/chosen": -58.676490783691406,
      "logps/rejected": -52.22293472290039,
      "loss": 0.2174,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8408746719360352,
      "rewards/margins": 1.478973150253296,
      "rewards/rejected": -0.6380985379219055,
      "step": 812
    },
    {
      "epoch": 0.3252,
      "grad_norm": 4.2588396072387695,
      "learning_rate": 8.917333333333334e-07,
      "logits/chosen": -2.3258094787597656,
      "logits/rejected": -1.8270481824874878,
      "logps/chosen": -144.64015197753906,
      "logps/rejected": -89.437744140625,
      "loss": 0.1115,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4565235376358032,
      "rewards/margins": 2.205198287963867,
      "rewards/rejected": -0.748674750328064,
      "step": 813
    },
    {
      "epoch": 0.3256,
      "grad_norm": 8.223502159118652,
      "learning_rate": 8.915999999999999e-07,
      "logits/chosen": -2.5302340984344482,
      "logits/rejected": -2.0424556732177734,
      "logps/chosen": -99.44088745117188,
      "logps/rejected": -150.10916137695312,
      "loss": 0.1796,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7875312566757202,
      "rewards/margins": 1.6468340158462524,
      "rewards/rejected": -0.8593026995658875,
      "step": 814
    },
    {
      "epoch": 0.326,
      "grad_norm": 5.446645259857178,
      "learning_rate": 8.914666666666665e-07,
      "logits/chosen": -2.896904468536377,
      "logits/rejected": -2.439253330230713,
      "logps/chosen": -60.751243591308594,
      "logps/rejected": -79.94818115234375,
      "loss": 0.173,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9368734359741211,
      "rewards/margins": 1.7263084650039673,
      "rewards/rejected": -0.7894350290298462,
      "step": 815
    },
    {
      "epoch": 0.3264,
      "grad_norm": 8.55532455444336,
      "learning_rate": 8.913333333333332e-07,
      "logits/chosen": -2.7967991828918457,
      "logits/rejected": -2.4045939445495605,
      "logps/chosen": -70.24110412597656,
      "logps/rejected": -44.74588394165039,
      "loss": 0.4001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23937340080738068,
      "rewards/margins": 0.7231804132461548,
      "rewards/rejected": -0.4838069975376129,
      "step": 816
    },
    {
      "epoch": 0.3268,
      "grad_norm": 5.013756275177002,
      "learning_rate": 8.911999999999999e-07,
      "logits/chosen": -2.740828037261963,
      "logits/rejected": -2.441652297973633,
      "logps/chosen": -79.48439025878906,
      "logps/rejected": -78.92830657958984,
      "loss": 0.146,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7891204953193665,
      "rewards/margins": 1.8522496223449707,
      "rewards/rejected": -1.0631290674209595,
      "step": 817
    },
    {
      "epoch": 0.3272,
      "grad_norm": 4.531281471252441,
      "learning_rate": 8.910666666666666e-07,
      "logits/chosen": -2.7711033821105957,
      "logits/rejected": -2.17941951751709,
      "logps/chosen": -53.66361618041992,
      "logps/rejected": -63.3206901550293,
      "loss": 0.1736,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8278194665908813,
      "rewards/margins": 1.6637046337127686,
      "rewards/rejected": -0.8358852863311768,
      "step": 818
    },
    {
      "epoch": 0.3276,
      "grad_norm": 7.29666805267334,
      "learning_rate": 8.909333333333333e-07,
      "logits/chosen": -2.806917190551758,
      "logits/rejected": -2.3891069889068604,
      "logps/chosen": -90.38981628417969,
      "logps/rejected": -51.136558532714844,
      "loss": 0.2458,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7803503274917603,
      "rewards/margins": 1.3601690530776978,
      "rewards/rejected": -0.5798187255859375,
      "step": 819
    },
    {
      "epoch": 0.328,
      "grad_norm": 7.7762298583984375,
      "learning_rate": 8.908e-07,
      "logits/chosen": -2.471616506576538,
      "logits/rejected": -1.9324204921722412,
      "logps/chosen": -126.82582092285156,
      "logps/rejected": -68.77972412109375,
      "loss": 0.172,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9555069208145142,
      "rewards/margins": 1.6945793628692627,
      "rewards/rejected": -0.7390724420547485,
      "step": 820
    },
    {
      "epoch": 0.3284,
      "grad_norm": 5.6939568519592285,
      "learning_rate": 8.906666666666667e-07,
      "logits/chosen": -2.652179718017578,
      "logits/rejected": -2.2857367992401123,
      "logps/chosen": -71.99662780761719,
      "logps/rejected": -69.42374420166016,
      "loss": 0.1721,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1304081678390503,
      "rewards/margins": 1.7473230361938477,
      "rewards/rejected": -0.6169149875640869,
      "step": 821
    },
    {
      "epoch": 0.3288,
      "grad_norm": 6.1263885498046875,
      "learning_rate": 8.905333333333333e-07,
      "logits/chosen": -2.5091848373413086,
      "logits/rejected": -1.9387482404708862,
      "logps/chosen": -73.44493865966797,
      "logps/rejected": -83.62369537353516,
      "loss": 0.1587,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8840477466583252,
      "rewards/margins": 1.8089349269866943,
      "rewards/rejected": -0.9248872995376587,
      "step": 822
    },
    {
      "epoch": 0.3292,
      "grad_norm": 6.8114705085754395,
      "learning_rate": 8.904e-07,
      "logits/chosen": -2.7310919761657715,
      "logits/rejected": -2.5117685794830322,
      "logps/chosen": -82.42868041992188,
      "logps/rejected": -88.14846801757812,
      "loss": 0.2256,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8734794855117798,
      "rewards/margins": 1.4304310083389282,
      "rewards/rejected": -0.5569515228271484,
      "step": 823
    },
    {
      "epoch": 0.3296,
      "grad_norm": 8.964524269104004,
      "learning_rate": 8.902666666666666e-07,
      "logits/chosen": -2.539496898651123,
      "logits/rejected": -2.5755186080932617,
      "logps/chosen": -57.70244216918945,
      "logps/rejected": -77.9219970703125,
      "loss": 0.2957,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6535375714302063,
      "rewards/margins": 1.0672760009765625,
      "rewards/rejected": -0.4137384295463562,
      "step": 824
    },
    {
      "epoch": 0.33,
      "grad_norm": 8.004593849182129,
      "learning_rate": 8.901333333333333e-07,
      "logits/chosen": -2.885354518890381,
      "logits/rejected": -2.5769271850585938,
      "logps/chosen": -77.41102600097656,
      "logps/rejected": -48.9891357421875,
      "loss": 0.3202,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5433666110038757,
      "rewards/margins": 0.9777639508247375,
      "rewards/rejected": -0.4343973398208618,
      "step": 825
    },
    {
      "epoch": 0.3304,
      "grad_norm": 6.329350471496582,
      "learning_rate": 8.9e-07,
      "logits/chosen": -2.6940908432006836,
      "logits/rejected": -2.2967824935913086,
      "logps/chosen": -84.17025756835938,
      "logps/rejected": -77.61286163330078,
      "loss": 0.1833,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9060360193252563,
      "rewards/margins": 1.617292881011963,
      "rewards/rejected": -0.7112568020820618,
      "step": 826
    },
    {
      "epoch": 0.3308,
      "grad_norm": 6.322478771209717,
      "learning_rate": 8.898666666666666e-07,
      "logits/chosen": -2.527801036834717,
      "logits/rejected": -2.389619827270508,
      "logps/chosen": -106.45114135742188,
      "logps/rejected": -38.35457992553711,
      "loss": 0.297,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8301300406455994,
      "rewards/margins": 1.1561732292175293,
      "rewards/rejected": -0.3260432183742523,
      "step": 827
    },
    {
      "epoch": 0.3312,
      "grad_norm": 4.343417167663574,
      "learning_rate": 8.897333333333333e-07,
      "logits/chosen": -2.6149051189422607,
      "logits/rejected": -2.2659502029418945,
      "logps/chosen": -98.8585433959961,
      "logps/rejected": -144.09326171875,
      "loss": 0.0901,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1871131658554077,
      "rewards/margins": 2.373933792114258,
      "rewards/rejected": -1.18682062625885,
      "step": 828
    },
    {
      "epoch": 0.3316,
      "grad_norm": 5.9399189949035645,
      "learning_rate": 8.895999999999999e-07,
      "logits/chosen": -2.9448258876800537,
      "logits/rejected": -2.7364213466644287,
      "logps/chosen": -38.82740020751953,
      "logps/rejected": -46.065277099609375,
      "loss": 0.2731,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4883789122104645,
      "rewards/margins": 1.2921793460845947,
      "rewards/rejected": -0.8038004040718079,
      "step": 829
    },
    {
      "epoch": 0.332,
      "grad_norm": 7.353891372680664,
      "learning_rate": 8.894666666666666e-07,
      "logits/chosen": -2.5284032821655273,
      "logits/rejected": -2.2296526432037354,
      "logps/chosen": -220.10179138183594,
      "logps/rejected": -47.96319580078125,
      "loss": 0.1948,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0766724348068237,
      "rewards/margins": 1.6070091724395752,
      "rewards/rejected": -0.5303367972373962,
      "step": 830
    },
    {
      "epoch": 0.3324,
      "grad_norm": 6.163100719451904,
      "learning_rate": 8.893333333333333e-07,
      "logits/chosen": -2.698596954345703,
      "logits/rejected": -2.348156452178955,
      "logps/chosen": -94.72796630859375,
      "logps/rejected": -78.25415802001953,
      "loss": 0.2128,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6813600659370422,
      "rewards/margins": 1.5073370933532715,
      "rewards/rejected": -0.8259769678115845,
      "step": 831
    },
    {
      "epoch": 0.3328,
      "grad_norm": 8.093260765075684,
      "learning_rate": 8.892e-07,
      "logits/chosen": -2.668260097503662,
      "logits/rejected": -2.342285633087158,
      "logps/chosen": -65.06546020507812,
      "logps/rejected": -44.48500061035156,
      "loss": 0.3764,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3659713864326477,
      "rewards/margins": 0.7866640090942383,
      "rewards/rejected": -0.4206926226615906,
      "step": 832
    },
    {
      "epoch": 0.3332,
      "grad_norm": 10.137481689453125,
      "learning_rate": 8.890666666666666e-07,
      "logits/chosen": -2.943267345428467,
      "logits/rejected": -2.7778263092041016,
      "logps/chosen": -74.95943450927734,
      "logps/rejected": -137.86195373535156,
      "loss": 0.2401,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8892860412597656,
      "rewards/margins": 1.3154363632202148,
      "rewards/rejected": -0.4261503219604492,
      "step": 833
    },
    {
      "epoch": 0.3336,
      "grad_norm": 7.3796257972717285,
      "learning_rate": 8.889333333333333e-07,
      "logits/chosen": -2.4839320182800293,
      "logits/rejected": -2.5473790168762207,
      "logps/chosen": -134.4930877685547,
      "logps/rejected": -50.407470703125,
      "loss": 0.2559,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0634734630584717,
      "rewards/margins": 1.247042179107666,
      "rewards/rejected": -0.1835685670375824,
      "step": 834
    },
    {
      "epoch": 0.334,
      "grad_norm": 7.930920600891113,
      "learning_rate": 8.888e-07,
      "logits/chosen": -2.7650020122528076,
      "logits/rejected": -2.587329626083374,
      "logps/chosen": -108.14249420166016,
      "logps/rejected": -71.20845794677734,
      "loss": 0.2799,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8966827392578125,
      "rewards/margins": 1.1305432319641113,
      "rewards/rejected": -0.23386038839817047,
      "step": 835
    },
    {
      "epoch": 0.3344,
      "grad_norm": 7.59163761138916,
      "learning_rate": 8.886666666666667e-07,
      "logits/chosen": -2.6707916259765625,
      "logits/rejected": -1.995053768157959,
      "logps/chosen": -77.70402526855469,
      "logps/rejected": -69.98130798339844,
      "loss": 0.2424,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9742552042007446,
      "rewards/margins": 1.4199609756469727,
      "rewards/rejected": -0.4457058012485504,
      "step": 836
    },
    {
      "epoch": 0.3348,
      "grad_norm": 6.376014709472656,
      "learning_rate": 8.885333333333332e-07,
      "logits/chosen": -2.6290717124938965,
      "logits/rejected": -1.9856066703796387,
      "logps/chosen": -97.25645446777344,
      "logps/rejected": -95.76716613769531,
      "loss": 0.1519,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8083574771881104,
      "rewards/margins": 1.817130446434021,
      "rewards/rejected": -1.0087730884552002,
      "step": 837
    },
    {
      "epoch": 0.3352,
      "grad_norm": 5.6509785652160645,
      "learning_rate": 8.883999999999999e-07,
      "logits/chosen": -2.5293331146240234,
      "logits/rejected": -2.268627166748047,
      "logps/chosen": -129.59652709960938,
      "logps/rejected": -53.36917495727539,
      "loss": 0.1858,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1884132623672485,
      "rewards/margins": 1.6134583950042725,
      "rewards/rejected": -0.4250450134277344,
      "step": 838
    },
    {
      "epoch": 0.3356,
      "grad_norm": 6.62676477432251,
      "learning_rate": 8.882666666666666e-07,
      "logits/chosen": -2.544948101043701,
      "logits/rejected": -2.568136215209961,
      "logps/chosen": -99.94377136230469,
      "logps/rejected": -38.38682556152344,
      "loss": 0.2966,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4938076138496399,
      "rewards/margins": 1.0796470642089844,
      "rewards/rejected": -0.5858395099639893,
      "step": 839
    },
    {
      "epoch": 0.336,
      "grad_norm": 6.598437786102295,
      "learning_rate": 8.881333333333333e-07,
      "logits/chosen": -2.8210043907165527,
      "logits/rejected": -2.762022018432617,
      "logps/chosen": -59.921478271484375,
      "logps/rejected": -38.158355712890625,
      "loss": 0.2738,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8484436273574829,
      "rewards/margins": 1.1632072925567627,
      "rewards/rejected": -0.3147636651992798,
      "step": 840
    },
    {
      "epoch": 0.3364,
      "grad_norm": 6.592311382293701,
      "learning_rate": 8.88e-07,
      "logits/chosen": -2.835491418838501,
      "logits/rejected": -2.4817512035369873,
      "logps/chosen": -78.86821746826172,
      "logps/rejected": -56.71833038330078,
      "loss": 0.2281,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7680959701538086,
      "rewards/margins": 1.3749902248382568,
      "rewards/rejected": -0.606894314289093,
      "step": 841
    },
    {
      "epoch": 0.3368,
      "grad_norm": 7.566858768463135,
      "learning_rate": 8.878666666666667e-07,
      "logits/chosen": -2.970149040222168,
      "logits/rejected": -2.4686174392700195,
      "logps/chosen": -134.31521606445312,
      "logps/rejected": -60.75164031982422,
      "loss": 0.2757,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6088088750839233,
      "rewards/margins": 1.1920183897018433,
      "rewards/rejected": -0.5832093954086304,
      "step": 842
    },
    {
      "epoch": 0.3372,
      "grad_norm": 4.82465124130249,
      "learning_rate": 8.877333333333333e-07,
      "logits/chosen": -2.671766757965088,
      "logits/rejected": -2.2747411727905273,
      "logps/chosen": -82.0482177734375,
      "logps/rejected": -56.580230712890625,
      "loss": 0.1593,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2044233083724976,
      "rewards/margins": 1.8291311264038086,
      "rewards/rejected": -0.624707818031311,
      "step": 843
    },
    {
      "epoch": 0.3376,
      "grad_norm": 10.935766220092773,
      "learning_rate": 8.875999999999999e-07,
      "logits/chosen": -3.0658340454101562,
      "logits/rejected": -2.8742403984069824,
      "logps/chosen": -41.62095642089844,
      "logps/rejected": -40.99079895019531,
      "loss": 0.5823,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08206558227539062,
      "rewards/margins": 0.25020962953567505,
      "rewards/rejected": -0.16814404726028442,
      "step": 844
    },
    {
      "epoch": 0.338,
      "grad_norm": 5.714205265045166,
      "learning_rate": 8.874666666666666e-07,
      "logits/chosen": -2.685865640640259,
      "logits/rejected": -2.1669089794158936,
      "logps/chosen": -73.62738037109375,
      "logps/rejected": -77.27120971679688,
      "loss": 0.2146,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0381107330322266,
      "rewards/margins": 1.581763744354248,
      "rewards/rejected": -0.5436528921127319,
      "step": 845
    },
    {
      "epoch": 0.3384,
      "grad_norm": 6.41314697265625,
      "learning_rate": 8.873333333333333e-07,
      "logits/chosen": -3.0246453285217285,
      "logits/rejected": -2.442873477935791,
      "logps/chosen": -68.35852813720703,
      "logps/rejected": -50.674598693847656,
      "loss": 0.2713,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5206020474433899,
      "rewards/margins": 1.1729700565338135,
      "rewards/rejected": -0.6523679494857788,
      "step": 846
    },
    {
      "epoch": 0.3388,
      "grad_norm": 7.745274066925049,
      "learning_rate": 8.872e-07,
      "logits/chosen": -2.857745885848999,
      "logits/rejected": -2.643211841583252,
      "logps/chosen": -101.70957946777344,
      "logps/rejected": -52.411922454833984,
      "loss": 0.2495,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7445472478866577,
      "rewards/margins": 1.4902477264404297,
      "rewards/rejected": -0.745700478553772,
      "step": 847
    },
    {
      "epoch": 0.3392,
      "grad_norm": 10.053194046020508,
      "learning_rate": 8.870666666666666e-07,
      "logits/chosen": -2.553800582885742,
      "logits/rejected": -2.3983230590820312,
      "logps/chosen": -153.16259765625,
      "logps/rejected": -85.29167175292969,
      "loss": 0.3823,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15298329293727875,
      "rewards/margins": 0.7890629172325134,
      "rewards/rejected": -0.6360796093940735,
      "step": 848
    },
    {
      "epoch": 0.3396,
      "grad_norm": 7.0891194343566895,
      "learning_rate": 8.869333333333333e-07,
      "logits/chosen": -2.917250394821167,
      "logits/rejected": -2.630500316619873,
      "logps/chosen": -44.06990051269531,
      "logps/rejected": -41.225643157958984,
      "loss": 0.3561,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5416750311851501,
      "rewards/margins": 0.8530949354171753,
      "rewards/rejected": -0.31141987442970276,
      "step": 849
    },
    {
      "epoch": 0.34,
      "grad_norm": 8.437056541442871,
      "learning_rate": 8.868e-07,
      "logits/chosen": -2.9219794273376465,
      "logits/rejected": -2.639298439025879,
      "logps/chosen": -56.33708190917969,
      "logps/rejected": -50.15876388549805,
      "loss": 0.3809,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21018199622631073,
      "rewards/margins": 0.9721617102622986,
      "rewards/rejected": -0.7619796991348267,
      "step": 850
    },
    {
      "epoch": 0.3404,
      "grad_norm": 10.80112075805664,
      "learning_rate": 8.866666666666667e-07,
      "logits/chosen": -2.4249050617218018,
      "logits/rejected": -2.662050724029541,
      "logps/chosen": -140.3026123046875,
      "logps/rejected": -88.84978485107422,
      "loss": 0.3183,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4902458190917969,
      "rewards/margins": 0.9922985434532166,
      "rewards/rejected": -0.5020526647567749,
      "step": 851
    },
    {
      "epoch": 0.3408,
      "grad_norm": 5.090244770050049,
      "learning_rate": 8.865333333333332e-07,
      "logits/chosen": -2.2453794479370117,
      "logits/rejected": -1.88569974899292,
      "logps/chosen": -178.18768310546875,
      "logps/rejected": -108.49515533447266,
      "loss": 0.1181,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.432233452796936,
      "rewards/margins": 2.196207284927368,
      "rewards/rejected": -0.7639738321304321,
      "step": 852
    },
    {
      "epoch": 0.3412,
      "grad_norm": 6.943408966064453,
      "learning_rate": 8.863999999999999e-07,
      "logits/chosen": -2.77461838722229,
      "logits/rejected": -2.4462742805480957,
      "logps/chosen": -86.65074920654297,
      "logps/rejected": -57.5273323059082,
      "loss": 0.2112,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8776174783706665,
      "rewards/margins": 1.511082410812378,
      "rewards/rejected": -0.6334648132324219,
      "step": 853
    },
    {
      "epoch": 0.3416,
      "grad_norm": 6.100443363189697,
      "learning_rate": 8.862666666666666e-07,
      "logits/chosen": -2.9974589347839355,
      "logits/rejected": -2.678281784057617,
      "logps/chosen": -55.48499298095703,
      "logps/rejected": -51.51874542236328,
      "loss": 0.2164,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7627986669540405,
      "rewards/margins": 1.542128562927246,
      "rewards/rejected": -0.7793298959732056,
      "step": 854
    },
    {
      "epoch": 0.342,
      "grad_norm": 5.7184977531433105,
      "learning_rate": 8.861333333333333e-07,
      "logits/chosen": -2.697279453277588,
      "logits/rejected": -2.3427693843841553,
      "logps/chosen": -87.24388122558594,
      "logps/rejected": -60.51306915283203,
      "loss": 0.1677,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0422443151474,
      "rewards/margins": 1.790191411972046,
      "rewards/rejected": -0.747947096824646,
      "step": 855
    },
    {
      "epoch": 0.3424,
      "grad_norm": 4.92352294921875,
      "learning_rate": 8.86e-07,
      "logits/chosen": -2.6881179809570312,
      "logits/rejected": -2.1271090507507324,
      "logps/chosen": -92.14889526367188,
      "logps/rejected": -69.02444458007812,
      "loss": 0.1439,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9908010363578796,
      "rewards/margins": 1.9590327739715576,
      "rewards/rejected": -0.9682317972183228,
      "step": 856
    },
    {
      "epoch": 0.3428,
      "grad_norm": 6.764903545379639,
      "learning_rate": 8.858666666666667e-07,
      "logits/chosen": -2.5360822677612305,
      "logits/rejected": -2.3978867530822754,
      "logps/chosen": -82.14277648925781,
      "logps/rejected": -67.02996826171875,
      "loss": 0.2242,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7811946868896484,
      "rewards/margins": 1.396773099899292,
      "rewards/rejected": -0.615578293800354,
      "step": 857
    },
    {
      "epoch": 0.3432,
      "grad_norm": 10.131627082824707,
      "learning_rate": 8.857333333333334e-07,
      "logits/chosen": -2.487908363342285,
      "logits/rejected": -2.556490898132324,
      "logps/chosen": -152.27276611328125,
      "logps/rejected": -118.37202453613281,
      "loss": 0.2672,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6082596182823181,
      "rewards/margins": 1.1837332248687744,
      "rewards/rejected": -0.5754736065864563,
      "step": 858
    },
    {
      "epoch": 0.3436,
      "grad_norm": 5.013906002044678,
      "learning_rate": 8.856e-07,
      "logits/chosen": -2.2828574180603027,
      "logits/rejected": -2.2239131927490234,
      "logps/chosen": -137.02777099609375,
      "logps/rejected": -66.09288024902344,
      "loss": 0.1207,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4087836742401123,
      "rewards/margins": 2.0996575355529785,
      "rewards/rejected": -0.6908737421035767,
      "step": 859
    },
    {
      "epoch": 0.344,
      "grad_norm": 11.872915267944336,
      "learning_rate": 8.854666666666666e-07,
      "logits/chosen": -2.907742977142334,
      "logits/rejected": -2.7055954933166504,
      "logps/chosen": -76.29222869873047,
      "logps/rejected": -44.53196716308594,
      "loss": 0.4459,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.47032833099365234,
      "rewards/margins": 0.5768851041793823,
      "rewards/rejected": -0.10655680298805237,
      "step": 860
    },
    {
      "epoch": 0.3444,
      "grad_norm": 4.157952308654785,
      "learning_rate": 8.853333333333332e-07,
      "logits/chosen": -2.655489921569824,
      "logits/rejected": -2.4648945331573486,
      "logps/chosen": -76.3755874633789,
      "logps/rejected": -97.04763793945312,
      "loss": 0.1219,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9544443488121033,
      "rewards/margins": 2.06070613861084,
      "rewards/rejected": -1.1062618494033813,
      "step": 861
    },
    {
      "epoch": 0.3448,
      "grad_norm": 5.692549705505371,
      "learning_rate": 8.851999999999999e-07,
      "logits/chosen": -2.676945209503174,
      "logits/rejected": -2.312699794769287,
      "logps/chosen": -53.09124755859375,
      "logps/rejected": -53.688629150390625,
      "loss": 0.1832,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7826358675956726,
      "rewards/margins": 1.6292881965637207,
      "rewards/rejected": -0.8466522693634033,
      "step": 862
    },
    {
      "epoch": 0.3452,
      "grad_norm": 5.7477192878723145,
      "learning_rate": 8.850666666666666e-07,
      "logits/chosen": -2.6545495986938477,
      "logits/rejected": -2.3053994178771973,
      "logps/chosen": -131.28125,
      "logps/rejected": -75.68789672851562,
      "loss": 0.1455,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0409218072891235,
      "rewards/margins": 1.9017348289489746,
      "rewards/rejected": -0.8608129620552063,
      "step": 863
    },
    {
      "epoch": 0.3456,
      "grad_norm": 5.968624591827393,
      "learning_rate": 8.849333333333333e-07,
      "logits/chosen": -2.719451904296875,
      "logits/rejected": -2.0214107036590576,
      "logps/chosen": -113.37545776367188,
      "logps/rejected": -118.51020050048828,
      "loss": 0.1517,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1945873498916626,
      "rewards/margins": 1.850329875946045,
      "rewards/rejected": -0.6557426452636719,
      "step": 864
    },
    {
      "epoch": 0.346,
      "grad_norm": 5.34737491607666,
      "learning_rate": 8.848e-07,
      "logits/chosen": -2.994112491607666,
      "logits/rejected": -2.3443355560302734,
      "logps/chosen": -57.1835823059082,
      "logps/rejected": -50.67841339111328,
      "loss": 0.2111,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5459621548652649,
      "rewards/margins": 1.524850606918335,
      "rewards/rejected": -0.9788885116577148,
      "step": 865
    },
    {
      "epoch": 0.3464,
      "grad_norm": 5.619293689727783,
      "learning_rate": 8.846666666666667e-07,
      "logits/chosen": -2.5622901916503906,
      "logits/rejected": -2.1126086711883545,
      "logps/chosen": -64.60800170898438,
      "logps/rejected": -70.31916809082031,
      "loss": 0.1645,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9109611511230469,
      "rewards/margins": 1.7448055744171143,
      "rewards/rejected": -0.8338444232940674,
      "step": 866
    },
    {
      "epoch": 0.3468,
      "grad_norm": 7.181883335113525,
      "learning_rate": 8.845333333333333e-07,
      "logits/chosen": -3.078947067260742,
      "logits/rejected": -2.4895882606506348,
      "logps/chosen": -68.07415008544922,
      "logps/rejected": -46.86460876464844,
      "loss": 0.3355,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5561620593070984,
      "rewards/margins": 0.9580198526382446,
      "rewards/rejected": -0.40185776352882385,
      "step": 867
    },
    {
      "epoch": 0.3472,
      "grad_norm": 7.844759941101074,
      "learning_rate": 8.844e-07,
      "logits/chosen": -2.8587260246276855,
      "logits/rejected": -2.619518995285034,
      "logps/chosen": -91.92696380615234,
      "logps/rejected": -107.76890563964844,
      "loss": 0.2588,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0235000848770142,
      "rewards/margins": 1.4916435480117798,
      "rewards/rejected": -0.4681434631347656,
      "step": 868
    },
    {
      "epoch": 0.3476,
      "grad_norm": 6.806194305419922,
      "learning_rate": 8.842666666666666e-07,
      "logits/chosen": -2.4686341285705566,
      "logits/rejected": -2.0190045833587646,
      "logps/chosen": -90.87892150878906,
      "logps/rejected": -74.65367126464844,
      "loss": 0.2509,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8008894324302673,
      "rewards/margins": 1.5465012788772583,
      "rewards/rejected": -0.7456119060516357,
      "step": 869
    },
    {
      "epoch": 0.348,
      "grad_norm": 6.21120548248291,
      "learning_rate": 8.841333333333333e-07,
      "logits/chosen": -2.5718183517456055,
      "logits/rejected": -2.231349468231201,
      "logps/chosen": -110.10562133789062,
      "logps/rejected": -101.95903015136719,
      "loss": 0.1755,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8054966330528259,
      "rewards/margins": 1.6862133741378784,
      "rewards/rejected": -0.8807166814804077,
      "step": 870
    },
    {
      "epoch": 0.3484,
      "grad_norm": 6.184316158294678,
      "learning_rate": 8.839999999999999e-07,
      "logits/chosen": -2.6096503734588623,
      "logits/rejected": -2.327878952026367,
      "logps/chosen": -122.88971710205078,
      "logps/rejected": -73.8941879272461,
      "loss": 0.1731,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9570892453193665,
      "rewards/margins": 1.7090332508087158,
      "rewards/rejected": -0.7519439458847046,
      "step": 871
    },
    {
      "epoch": 0.3488,
      "grad_norm": 7.721854209899902,
      "learning_rate": 8.838666666666666e-07,
      "logits/chosen": -2.770718574523926,
      "logits/rejected": -2.8692662715911865,
      "logps/chosen": -78.71932983398438,
      "logps/rejected": -44.83345413208008,
      "loss": 0.3461,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5259494781494141,
      "rewards/margins": 0.8878246545791626,
      "rewards/rejected": -0.36187514662742615,
      "step": 872
    },
    {
      "epoch": 0.3492,
      "grad_norm": 7.2224578857421875,
      "learning_rate": 8.837333333333333e-07,
      "logits/chosen": -2.8594284057617188,
      "logits/rejected": -2.2639737129211426,
      "logps/chosen": -79.96818542480469,
      "logps/rejected": -71.86737060546875,
      "loss": 0.2499,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7916183471679688,
      "rewards/margins": 1.4241832494735718,
      "rewards/rejected": -0.632564902305603,
      "step": 873
    },
    {
      "epoch": 0.3496,
      "grad_norm": 5.546360969543457,
      "learning_rate": 8.836e-07,
      "logits/chosen": -2.9474050998687744,
      "logits/rejected": -2.8225791454315186,
      "logps/chosen": -55.02674102783203,
      "logps/rejected": -80.18203735351562,
      "loss": 0.1902,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6469376087188721,
      "rewards/margins": 1.5797655582427979,
      "rewards/rejected": -0.9328279495239258,
      "step": 874
    },
    {
      "epoch": 0.35,
      "grad_norm": 7.5540313720703125,
      "learning_rate": 8.834666666666666e-07,
      "logits/chosen": -2.7686643600463867,
      "logits/rejected": -2.426715850830078,
      "logps/chosen": -132.27337646484375,
      "logps/rejected": -97.77778625488281,
      "loss": 0.2159,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2831611633300781,
      "rewards/margins": 1.4721767902374268,
      "rewards/rejected": -1.1890156269073486,
      "step": 875
    },
    {
      "epoch": 0.3504,
      "grad_norm": 6.5184855461120605,
      "learning_rate": 8.833333333333333e-07,
      "logits/chosen": -2.8468592166900635,
      "logits/rejected": -2.6750717163085938,
      "logps/chosen": -64.36951446533203,
      "logps/rejected": -45.68926239013672,
      "loss": 0.251,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6599039435386658,
      "rewards/margins": 1.2586779594421387,
      "rewards/rejected": -0.5987739562988281,
      "step": 876
    },
    {
      "epoch": 0.3508,
      "grad_norm": 6.048834323883057,
      "learning_rate": 8.832e-07,
      "logits/chosen": -3.0076584815979004,
      "logits/rejected": -2.6162686347961426,
      "logps/chosen": -38.497352600097656,
      "logps/rejected": -68.83251190185547,
      "loss": 0.2022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4507185220718384,
      "rewards/margins": 1.682093858718872,
      "rewards/rejected": -1.2313753366470337,
      "step": 877
    },
    {
      "epoch": 0.3512,
      "grad_norm": 7.9874372482299805,
      "learning_rate": 8.830666666666667e-07,
      "logits/chosen": -2.8447835445404053,
      "logits/rejected": -2.542581081390381,
      "logps/chosen": -77.69154357910156,
      "logps/rejected": -32.683868408203125,
      "loss": 0.3243,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6305557489395142,
      "rewards/margins": 0.9810352325439453,
      "rewards/rejected": -0.35047951340675354,
      "step": 878
    },
    {
      "epoch": 0.3516,
      "grad_norm": 5.526493072509766,
      "learning_rate": 8.829333333333334e-07,
      "logits/chosen": -2.6074187755584717,
      "logits/rejected": -2.147571325302124,
      "logps/chosen": -122.81373596191406,
      "logps/rejected": -105.44019317626953,
      "loss": 0.1331,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2906360626220703,
      "rewards/margins": 1.9518508911132812,
      "rewards/rejected": -0.6612148284912109,
      "step": 879
    },
    {
      "epoch": 0.352,
      "grad_norm": 5.912474155426025,
      "learning_rate": 8.827999999999999e-07,
      "logits/chosen": -2.3041749000549316,
      "logits/rejected": -2.195302963256836,
      "logps/chosen": -162.7237548828125,
      "logps/rejected": -129.68661499023438,
      "loss": 0.1126,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4629058837890625,
      "rewards/margins": 2.1417863368988037,
      "rewards/rejected": -0.6788803339004517,
      "step": 880
    },
    {
      "epoch": 0.3524,
      "grad_norm": 11.47774600982666,
      "learning_rate": 8.826666666666666e-07,
      "logits/chosen": -2.689119338989258,
      "logits/rejected": -2.5170741081237793,
      "logps/chosen": -103.97547149658203,
      "logps/rejected": -54.393096923828125,
      "loss": 0.4662,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.041174307465553284,
      "rewards/margins": 0.5214076042175293,
      "rewards/rejected": -0.5625818967819214,
      "step": 881
    },
    {
      "epoch": 0.3528,
      "grad_norm": 7.537147045135498,
      "learning_rate": 8.825333333333332e-07,
      "logits/chosen": -2.662482976913452,
      "logits/rejected": -2.2570505142211914,
      "logps/chosen": -83.84749603271484,
      "logps/rejected": -77.08415222167969,
      "loss": 0.171,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7577335834503174,
      "rewards/margins": 1.9140046834945679,
      "rewards/rejected": -1.15627121925354,
      "step": 882
    },
    {
      "epoch": 0.3532,
      "grad_norm": 7.6370038986206055,
      "learning_rate": 8.823999999999999e-07,
      "logits/chosen": -3.035737991333008,
      "logits/rejected": -3.053500175476074,
      "logps/chosen": -84.50611114501953,
      "logps/rejected": -55.616676330566406,
      "loss": 0.2333,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6012411117553711,
      "rewards/margins": 1.3459020853042603,
      "rewards/rejected": -0.7446609735488892,
      "step": 883
    },
    {
      "epoch": 0.3536,
      "grad_norm": 6.300713539123535,
      "learning_rate": 8.822666666666666e-07,
      "logits/chosen": -2.9309284687042236,
      "logits/rejected": -2.414445400238037,
      "logps/chosen": -80.4672622680664,
      "logps/rejected": -67.63468933105469,
      "loss": 0.2414,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8710007071495056,
      "rewards/margins": 1.457800030708313,
      "rewards/rejected": -0.5867992639541626,
      "step": 884
    },
    {
      "epoch": 0.354,
      "grad_norm": 4.632341384887695,
      "learning_rate": 8.821333333333333e-07,
      "logits/chosen": -2.2033228874206543,
      "logits/rejected": -1.9997367858886719,
      "logps/chosen": -272.81256103515625,
      "logps/rejected": -89.96394348144531,
      "loss": 0.0843,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3875824213027954,
      "rewards/margins": 2.4418718814849854,
      "rewards/rejected": -1.05428946018219,
      "step": 885
    },
    {
      "epoch": 0.3544,
      "grad_norm": 6.064400672912598,
      "learning_rate": 8.82e-07,
      "logits/chosen": -2.50059175491333,
      "logits/rejected": -2.210418462753296,
      "logps/chosen": -127.11837768554688,
      "logps/rejected": -90.02113342285156,
      "loss": 0.1397,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5113708972930908,
      "rewards/margins": 1.9415146112442017,
      "rewards/rejected": -0.4301437735557556,
      "step": 886
    },
    {
      "epoch": 0.3548,
      "grad_norm": 5.698045253753662,
      "learning_rate": 8.818666666666667e-07,
      "logits/chosen": -2.5592617988586426,
      "logits/rejected": -2.4188852310180664,
      "logps/chosen": -109.60394287109375,
      "logps/rejected": -73.88404846191406,
      "loss": 0.1897,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2283000946044922,
      "rewards/margins": 1.640665888786316,
      "rewards/rejected": -0.41236573457717896,
      "step": 887
    },
    {
      "epoch": 0.3552,
      "grad_norm": 6.530707359313965,
      "learning_rate": 8.817333333333334e-07,
      "logits/chosen": -2.768014907836914,
      "logits/rejected": -2.672384023666382,
      "logps/chosen": -139.42996215820312,
      "logps/rejected": -52.578941345214844,
      "loss": 0.19,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7515892386436462,
      "rewards/margins": 1.7956221103668213,
      "rewards/rejected": -1.0440328121185303,
      "step": 888
    },
    {
      "epoch": 0.3556,
      "grad_norm": 5.344115257263184,
      "learning_rate": 8.816000000000001e-07,
      "logits/chosen": -2.7551255226135254,
      "logits/rejected": -2.3510947227478027,
      "logps/chosen": -122.09901428222656,
      "logps/rejected": -65.84890747070312,
      "loss": 0.1452,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9315819144248962,
      "rewards/margins": 1.890805959701538,
      "rewards/rejected": -0.9592241048812866,
      "step": 889
    },
    {
      "epoch": 0.356,
      "grad_norm": 7.384401798248291,
      "learning_rate": 8.814666666666665e-07,
      "logits/chosen": -2.7285003662109375,
      "logits/rejected": -2.401498794555664,
      "logps/chosen": -85.67324829101562,
      "logps/rejected": -39.06993103027344,
      "loss": 0.2595,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7262897491455078,
      "rewards/margins": 1.2290196418762207,
      "rewards/rejected": -0.5027297735214233,
      "step": 890
    },
    {
      "epoch": 0.3564,
      "grad_norm": 7.330716609954834,
      "learning_rate": 8.813333333333332e-07,
      "logits/chosen": -2.7716031074523926,
      "logits/rejected": -2.917171001434326,
      "logps/chosen": -46.01896286010742,
      "logps/rejected": -39.231536865234375,
      "loss": 0.4071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4440479278564453,
      "rewards/margins": 0.6900256872177124,
      "rewards/rejected": -0.24597778916358948,
      "step": 891
    },
    {
      "epoch": 0.3568,
      "grad_norm": 4.914818286895752,
      "learning_rate": 8.811999999999999e-07,
      "logits/chosen": -2.5997185707092285,
      "logits/rejected": -2.2075624465942383,
      "logps/chosen": -77.26994323730469,
      "logps/rejected": -62.81467819213867,
      "loss": 0.1312,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9035919308662415,
      "rewards/margins": 1.9664143323898315,
      "rewards/rejected": -1.0628223419189453,
      "step": 892
    },
    {
      "epoch": 0.3572,
      "grad_norm": 8.270576477050781,
      "learning_rate": 8.810666666666666e-07,
      "logits/chosen": -2.773921489715576,
      "logits/rejected": -2.3095102310180664,
      "logps/chosen": -98.71570587158203,
      "logps/rejected": -105.129150390625,
      "loss": 0.2305,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8205516934394836,
      "rewards/margins": 1.3502388000488281,
      "rewards/rejected": -0.5296871662139893,
      "step": 893
    },
    {
      "epoch": 0.3576,
      "grad_norm": 4.591333389282227,
      "learning_rate": 8.809333333333333e-07,
      "logits/chosen": -2.48297119140625,
      "logits/rejected": -2.108651638031006,
      "logps/chosen": -105.56002807617188,
      "logps/rejected": -126.5811767578125,
      "loss": 0.1147,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1465603113174438,
      "rewards/margins": 2.192934513092041,
      "rewards/rejected": -1.0463742017745972,
      "step": 894
    },
    {
      "epoch": 0.358,
      "grad_norm": 3.517443895339966,
      "learning_rate": 8.808e-07,
      "logits/chosen": -2.40556001663208,
      "logits/rejected": -2.096423864364624,
      "logps/chosen": -110.27753448486328,
      "logps/rejected": -56.879798889160156,
      "loss": 0.0877,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4605919122695923,
      "rewards/margins": 2.397587299346924,
      "rewards/rejected": -0.936995267868042,
      "step": 895
    },
    {
      "epoch": 0.3584,
      "grad_norm": 5.178258419036865,
      "learning_rate": 8.806666666666667e-07,
      "logits/chosen": -2.703535795211792,
      "logits/rejected": -2.1367149353027344,
      "logps/chosen": -122.82571411132812,
      "logps/rejected": -85.08653259277344,
      "loss": 0.1097,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8181850910186768,
      "rewards/margins": 2.1642308235168457,
      "rewards/rejected": -1.3460458517074585,
      "step": 896
    },
    {
      "epoch": 0.3588,
      "grad_norm": 4.941173553466797,
      "learning_rate": 8.805333333333333e-07,
      "logits/chosen": -2.431872844696045,
      "logits/rejected": -1.9957501888275146,
      "logps/chosen": -88.70252990722656,
      "logps/rejected": -61.60181427001953,
      "loss": 0.1325,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0783398151397705,
      "rewards/margins": 1.993241310119629,
      "rewards/rejected": -0.9149015545845032,
      "step": 897
    },
    {
      "epoch": 0.3592,
      "grad_norm": 7.282949924468994,
      "learning_rate": 8.804e-07,
      "logits/chosen": -2.6694092750549316,
      "logits/rejected": -2.2334518432617188,
      "logps/chosen": -149.75135803222656,
      "logps/rejected": -62.64683532714844,
      "loss": 0.1822,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2875289916992188,
      "rewards/margins": 1.7565090656280518,
      "rewards/rejected": -0.46898001432418823,
      "step": 898
    },
    {
      "epoch": 0.3596,
      "grad_norm": 8.532246589660645,
      "learning_rate": 8.802666666666666e-07,
      "logits/chosen": -3.002295970916748,
      "logits/rejected": -2.477647304534912,
      "logps/chosen": -85.6427001953125,
      "logps/rejected": -65.53582763671875,
      "loss": 0.2643,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3757438659667969,
      "rewards/margins": 1.1963441371917725,
      "rewards/rejected": -0.8206003308296204,
      "step": 899
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.851438283920288,
      "learning_rate": 8.801333333333332e-07,
      "logits/chosen": -2.426992893218994,
      "logits/rejected": -2.0630316734313965,
      "logps/chosen": -161.33224487304688,
      "logps/rejected": -62.4190673828125,
      "loss": 0.0893,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6322189569473267,
      "rewards/margins": 2.3705573081970215,
      "rewards/rejected": -0.73833829164505,
      "step": 900
    },
    {
      "epoch": 0.3604,
      "grad_norm": 5.000965595245361,
      "learning_rate": 8.799999999999999e-07,
      "logits/chosen": -2.4434704780578613,
      "logits/rejected": -1.8591465950012207,
      "logps/chosen": -96.94718170166016,
      "logps/rejected": -89.69679260253906,
      "loss": 0.1427,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1644607782363892,
      "rewards/margins": 1.8795063495635986,
      "rewards/rejected": -0.7150455713272095,
      "step": 901
    },
    {
      "epoch": 0.3608,
      "grad_norm": 5.592586517333984,
      "learning_rate": 8.798666666666666e-07,
      "logits/chosen": -2.865602493286133,
      "logits/rejected": -2.307265043258667,
      "logps/chosen": -62.50869369506836,
      "logps/rejected": -54.173919677734375,
      "loss": 0.1894,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8287076950073242,
      "rewards/margins": 1.573927402496338,
      "rewards/rejected": -0.7452195882797241,
      "step": 902
    },
    {
      "epoch": 0.3612,
      "grad_norm": 4.822542190551758,
      "learning_rate": 8.797333333333333e-07,
      "logits/chosen": -2.4434080123901367,
      "logits/rejected": -1.984512448310852,
      "logps/chosen": -147.61810302734375,
      "logps/rejected": -81.32627868652344,
      "loss": 0.1191,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0984333753585815,
      "rewards/margins": 2.0762643814086914,
      "rewards/rejected": -0.9778308868408203,
      "step": 903
    },
    {
      "epoch": 0.3616,
      "grad_norm": 8.323970794677734,
      "learning_rate": 8.796e-07,
      "logits/chosen": -2.6744956970214844,
      "logits/rejected": -2.3694777488708496,
      "logps/chosen": -69.56340026855469,
      "logps/rejected": -53.84583282470703,
      "loss": 0.2889,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.750261127948761,
      "rewards/margins": 1.2943464517593384,
      "rewards/rejected": -0.5440853238105774,
      "step": 904
    },
    {
      "epoch": 0.362,
      "grad_norm": 6.561922550201416,
      "learning_rate": 8.794666666666666e-07,
      "logits/chosen": -2.3644447326660156,
      "logits/rejected": -1.9873454570770264,
      "logps/chosen": -167.44338989257812,
      "logps/rejected": -87.38737487792969,
      "loss": 0.1341,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.191595435142517,
      "rewards/margins": 2.0006909370422363,
      "rewards/rejected": -0.8090956211090088,
      "step": 905
    },
    {
      "epoch": 0.3624,
      "grad_norm": 6.999905586242676,
      "learning_rate": 8.793333333333333e-07,
      "logits/chosen": -2.392045497894287,
      "logits/rejected": -2.2926933765411377,
      "logps/chosen": -60.727203369140625,
      "logps/rejected": -92.72966003417969,
      "loss": 0.185,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8536859750747681,
      "rewards/margins": 1.7142534255981445,
      "rewards/rejected": -0.8605674505233765,
      "step": 906
    },
    {
      "epoch": 0.3628,
      "grad_norm": 7.241806507110596,
      "learning_rate": 8.792e-07,
      "logits/chosen": -2.59883451461792,
      "logits/rejected": -1.9694315195083618,
      "logps/chosen": -116.343017578125,
      "logps/rejected": -75.97901916503906,
      "loss": 0.2223,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9899342060089111,
      "rewards/margins": 1.4321930408477783,
      "rewards/rejected": -0.4422588348388672,
      "step": 907
    },
    {
      "epoch": 0.3632,
      "grad_norm": 6.531543731689453,
      "learning_rate": 8.790666666666666e-07,
      "logits/chosen": -3.130575656890869,
      "logits/rejected": -2.654810905456543,
      "logps/chosen": -41.920806884765625,
      "logps/rejected": -49.002899169921875,
      "loss": 0.2624,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7105274200439453,
      "rewards/margins": 1.2059946060180664,
      "rewards/rejected": -0.4954671859741211,
      "step": 908
    },
    {
      "epoch": 0.3636,
      "grad_norm": 6.453675746917725,
      "learning_rate": 8.789333333333333e-07,
      "logits/chosen": -2.4816384315490723,
      "logits/rejected": -2.230591297149658,
      "logps/chosen": -132.1696014404297,
      "logps/rejected": -76.40951538085938,
      "loss": 0.1438,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8265228271484375,
      "rewards/margins": 1.9681098461151123,
      "rewards/rejected": -1.1415870189666748,
      "step": 909
    },
    {
      "epoch": 0.364,
      "grad_norm": 7.475526809692383,
      "learning_rate": 8.788e-07,
      "logits/chosen": -2.6297221183776855,
      "logits/rejected": -2.791034698486328,
      "logps/chosen": -151.86676025390625,
      "logps/rejected": -86.10723876953125,
      "loss": 0.2193,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8881286382675171,
      "rewards/margins": 1.4843089580535889,
      "rewards/rejected": -0.5961803793907166,
      "step": 910
    },
    {
      "epoch": 0.3644,
      "grad_norm": 5.8569488525390625,
      "learning_rate": 8.786666666666666e-07,
      "logits/chosen": -2.1768949031829834,
      "logits/rejected": -2.1943044662475586,
      "logps/chosen": -174.41348266601562,
      "logps/rejected": -75.39736938476562,
      "loss": 0.127,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2784981727600098,
      "rewards/margins": 2.0232858657836914,
      "rewards/rejected": -0.7447878122329712,
      "step": 911
    },
    {
      "epoch": 0.3648,
      "grad_norm": 6.2027153968811035,
      "learning_rate": 8.785333333333333e-07,
      "logits/chosen": -2.515310049057007,
      "logits/rejected": -2.193760871887207,
      "logps/chosen": -121.87684631347656,
      "logps/rejected": -196.33633422851562,
      "loss": 0.1343,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.409260630607605,
      "rewards/margins": 1.986279845237732,
      "rewards/rejected": -0.5770190954208374,
      "step": 912
    },
    {
      "epoch": 0.3652,
      "grad_norm": 5.0700154304504395,
      "learning_rate": 8.783999999999999e-07,
      "logits/chosen": -2.945193290710449,
      "logits/rejected": -2.6145524978637695,
      "logps/chosen": -59.04494857788086,
      "logps/rejected": -57.73485565185547,
      "loss": 0.2191,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.524688720703125,
      "rewards/margins": 1.9715039730072021,
      "rewards/rejected": -1.4468151330947876,
      "step": 913
    },
    {
      "epoch": 0.3656,
      "grad_norm": 6.059854984283447,
      "learning_rate": 8.782666666666666e-07,
      "logits/chosen": -2.944312572479248,
      "logits/rejected": -2.2773327827453613,
      "logps/chosen": -60.169891357421875,
      "logps/rejected": -79.48538208007812,
      "loss": 0.1821,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7860250473022461,
      "rewards/margins": 1.6256825923919678,
      "rewards/rejected": -0.8396576046943665,
      "step": 914
    },
    {
      "epoch": 0.366,
      "grad_norm": 6.235060691833496,
      "learning_rate": 8.781333333333333e-07,
      "logits/chosen": -2.879943370819092,
      "logits/rejected": -2.6764426231384277,
      "logps/chosen": -59.20071792602539,
      "logps/rejected": -37.17142868041992,
      "loss": 0.302,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7423073649406433,
      "rewards/margins": 1.1187422275543213,
      "rewards/rejected": -0.37643492221832275,
      "step": 915
    },
    {
      "epoch": 0.3664,
      "grad_norm": 6.819204807281494,
      "learning_rate": 8.78e-07,
      "logits/chosen": -2.475515842437744,
      "logits/rejected": -2.103713274002075,
      "logps/chosen": -63.91425704956055,
      "logps/rejected": -97.53392791748047,
      "loss": 0.1921,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8734219074249268,
      "rewards/margins": 1.5866992473602295,
      "rewards/rejected": -0.7132774591445923,
      "step": 916
    },
    {
      "epoch": 0.3668,
      "grad_norm": 4.747186183929443,
      "learning_rate": 8.778666666666667e-07,
      "logits/chosen": -2.810018301010132,
      "logits/rejected": -2.500248432159424,
      "logps/chosen": -184.442138671875,
      "logps/rejected": -73.1895523071289,
      "loss": 0.0955,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7568057775497437,
      "rewards/margins": 2.4172019958496094,
      "rewards/rejected": -1.6603960990905762,
      "step": 917
    },
    {
      "epoch": 0.3672,
      "grad_norm": 6.708521842956543,
      "learning_rate": 8.777333333333333e-07,
      "logits/chosen": -2.681356906890869,
      "logits/rejected": -2.174591541290283,
      "logps/chosen": -61.48982238769531,
      "logps/rejected": -129.27197265625,
      "loss": 0.1348,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8328623175621033,
      "rewards/margins": 2.0544795989990234,
      "rewards/rejected": -1.2216172218322754,
      "step": 918
    },
    {
      "epoch": 0.3676,
      "grad_norm": 8.88549518585205,
      "learning_rate": 8.776e-07,
      "logits/chosen": -2.3977456092834473,
      "logits/rejected": -2.1209304332733154,
      "logps/chosen": -198.75918579101562,
      "logps/rejected": -94.92910766601562,
      "loss": 0.1764,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8025120496749878,
      "rewards/margins": 1.7628967761993408,
      "rewards/rejected": -0.960384726524353,
      "step": 919
    },
    {
      "epoch": 0.368,
      "grad_norm": 4.813003063201904,
      "learning_rate": 8.774666666666666e-07,
      "logits/chosen": -2.670565128326416,
      "logits/rejected": -2.3654470443725586,
      "logps/chosen": -104.8655014038086,
      "logps/rejected": -66.8692398071289,
      "loss": 0.1482,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1554760932922363,
      "rewards/margins": 1.8339831829071045,
      "rewards/rejected": -0.6785070896148682,
      "step": 920
    },
    {
      "epoch": 0.3684,
      "grad_norm": 6.273841381072998,
      "learning_rate": 8.773333333333332e-07,
      "logits/chosen": -3.177182674407959,
      "logits/rejected": -2.7596001625061035,
      "logps/chosen": -42.48402786254883,
      "logps/rejected": -70.73331451416016,
      "loss": 0.1759,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2175038456916809,
      "rewards/margins": 1.677303433418274,
      "rewards/rejected": -1.4597995281219482,
      "step": 921
    },
    {
      "epoch": 0.3688,
      "grad_norm": 9.385233879089355,
      "learning_rate": 8.771999999999999e-07,
      "logits/chosen": -2.1645631790161133,
      "logits/rejected": -1.910970687866211,
      "logps/chosen": -280.2900390625,
      "logps/rejected": -107.11036682128906,
      "loss": 0.162,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.035051703453064,
      "rewards/margins": 1.8401612043380737,
      "rewards/rejected": -0.805109441280365,
      "step": 922
    },
    {
      "epoch": 0.3692,
      "grad_norm": 6.334534645080566,
      "learning_rate": 8.770666666666666e-07,
      "logits/chosen": -2.7655317783355713,
      "logits/rejected": -2.5371603965759277,
      "logps/chosen": -70.24061584472656,
      "logps/rejected": -58.3215446472168,
      "loss": 0.2789,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5770576596260071,
      "rewards/margins": 1.1869969367980957,
      "rewards/rejected": -0.6099393963813782,
      "step": 923
    },
    {
      "epoch": 0.3696,
      "grad_norm": 6.858563423156738,
      "learning_rate": 8.769333333333333e-07,
      "logits/chosen": -2.3056578636169434,
      "logits/rejected": -2.229640483856201,
      "logps/chosen": -243.52005004882812,
      "logps/rejected": -83.63014221191406,
      "loss": 0.1612,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.92113196849823,
      "rewards/margins": 1.7451651096343994,
      "rewards/rejected": -0.8240332007408142,
      "step": 924
    },
    {
      "epoch": 0.37,
      "grad_norm": 7.250875949859619,
      "learning_rate": 8.768e-07,
      "logits/chosen": -2.8266947269439697,
      "logits/rejected": -2.591827392578125,
      "logps/chosen": -83.42491149902344,
      "logps/rejected": -71.35157775878906,
      "loss": 0.277,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.499362587928772,
      "rewards/margins": 1.3094666004180908,
      "rewards/rejected": -0.8101040124893188,
      "step": 925
    },
    {
      "epoch": 0.3704,
      "grad_norm": 8.52674388885498,
      "learning_rate": 8.766666666666667e-07,
      "logits/chosen": -2.808156967163086,
      "logits/rejected": -2.5851759910583496,
      "logps/chosen": -145.91220092773438,
      "logps/rejected": -103.09274291992188,
      "loss": 0.207,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8437523245811462,
      "rewards/margins": 1.4761632680892944,
      "rewards/rejected": -0.632411003112793,
      "step": 926
    },
    {
      "epoch": 0.3708,
      "grad_norm": 5.790505886077881,
      "learning_rate": 8.765333333333333e-07,
      "logits/chosen": -3.136061668395996,
      "logits/rejected": -2.92889404296875,
      "logps/chosen": -43.97969055175781,
      "logps/rejected": -51.721763610839844,
      "loss": 0.2542,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7066606283187866,
      "rewards/margins": 1.243260145187378,
      "rewards/rejected": -0.5365995168685913,
      "step": 927
    },
    {
      "epoch": 0.3712,
      "grad_norm": 7.129263877868652,
      "learning_rate": 8.763999999999999e-07,
      "logits/chosen": -2.4859166145324707,
      "logits/rejected": -2.138516902923584,
      "logps/chosen": -74.95762634277344,
      "logps/rejected": -109.3319091796875,
      "loss": 0.2493,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2825782597064972,
      "rewards/margins": 1.2749805450439453,
      "rewards/rejected": -0.9924022555351257,
      "step": 928
    },
    {
      "epoch": 0.3716,
      "grad_norm": 6.593860626220703,
      "learning_rate": 8.762666666666666e-07,
      "logits/chosen": -3.0231518745422363,
      "logits/rejected": -2.842597484588623,
      "logps/chosen": -67.85828399658203,
      "logps/rejected": -50.1309700012207,
      "loss": 0.2665,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8294441103935242,
      "rewards/margins": 1.191070556640625,
      "rewards/rejected": -0.36162644624710083,
      "step": 929
    },
    {
      "epoch": 0.372,
      "grad_norm": 6.076473236083984,
      "learning_rate": 8.761333333333333e-07,
      "logits/chosen": -2.565455913543701,
      "logits/rejected": -2.2924275398254395,
      "logps/chosen": -143.96530151367188,
      "logps/rejected": -86.23373413085938,
      "loss": 0.1777,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0757019519805908,
      "rewards/margins": 1.6413456201553345,
      "rewards/rejected": -0.5656437277793884,
      "step": 930
    },
    {
      "epoch": 0.3724,
      "grad_norm": 7.597269058227539,
      "learning_rate": 8.76e-07,
      "logits/chosen": -2.940319538116455,
      "logits/rejected": -2.5939855575561523,
      "logps/chosen": -44.494842529296875,
      "logps/rejected": -43.461063385009766,
      "loss": 0.3034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.629351019859314,
      "rewards/margins": 1.0445024967193604,
      "rewards/rejected": -0.4151514172554016,
      "step": 931
    },
    {
      "epoch": 0.3728,
      "grad_norm": 5.148863792419434,
      "learning_rate": 8.758666666666666e-07,
      "logits/chosen": -2.6203463077545166,
      "logits/rejected": -2.159219980239868,
      "logps/chosen": -69.75382995605469,
      "logps/rejected": -117.98725891113281,
      "loss": 0.1374,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2738710641860962,
      "rewards/margins": 1.9424121379852295,
      "rewards/rejected": -0.6685410737991333,
      "step": 932
    },
    {
      "epoch": 0.3732,
      "grad_norm": 5.858977317810059,
      "learning_rate": 8.757333333333333e-07,
      "logits/chosen": -2.44803524017334,
      "logits/rejected": -1.933605432510376,
      "logps/chosen": -129.65972900390625,
      "logps/rejected": -142.10076904296875,
      "loss": 0.118,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.521616816520691,
      "rewards/margins": 2.192129611968994,
      "rewards/rejected": -0.6705127954483032,
      "step": 933
    },
    {
      "epoch": 0.3736,
      "grad_norm": 6.555991172790527,
      "learning_rate": 8.756e-07,
      "logits/chosen": -2.525784969329834,
      "logits/rejected": -2.0671989917755127,
      "logps/chosen": -114.02840423583984,
      "logps/rejected": -54.43730545043945,
      "loss": 0.2793,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1670663356781006,
      "rewards/margins": 1.5708889961242676,
      "rewards/rejected": -0.40382272005081177,
      "step": 934
    },
    {
      "epoch": 0.374,
      "grad_norm": 4.210930347442627,
      "learning_rate": 8.754666666666666e-07,
      "logits/chosen": -2.3468451499938965,
      "logits/rejected": -2.432284355163574,
      "logps/chosen": -146.06480407714844,
      "logps/rejected": -52.54340362548828,
      "loss": 0.1089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5537993907928467,
      "rewards/margins": 2.27113676071167,
      "rewards/rejected": -0.7173373699188232,
      "step": 935
    },
    {
      "epoch": 0.3744,
      "grad_norm": 10.010007858276367,
      "learning_rate": 8.753333333333332e-07,
      "logits/chosen": -3.137831687927246,
      "logits/rejected": -2.4377853870391846,
      "logps/chosen": -40.76087188720703,
      "logps/rejected": -65.68405151367188,
      "loss": 0.2509,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.397246390581131,
      "rewards/margins": 1.3319575786590576,
      "rewards/rejected": -0.9347112774848938,
      "step": 936
    },
    {
      "epoch": 0.3748,
      "grad_norm": 9.970911026000977,
      "learning_rate": 8.751999999999999e-07,
      "logits/chosen": -3.056697368621826,
      "logits/rejected": -3.152367115020752,
      "logps/chosen": -76.40802764892578,
      "logps/rejected": -64.14082336425781,
      "loss": 0.3729,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7786312103271484,
      "rewards/margins": 1.0866116285324097,
      "rewards/rejected": -0.30798035860061646,
      "step": 937
    },
    {
      "epoch": 0.3752,
      "grad_norm": 8.07138442993164,
      "learning_rate": 8.750666666666666e-07,
      "logits/chosen": -2.95863676071167,
      "logits/rejected": -2.3776755332946777,
      "logps/chosen": -62.08233642578125,
      "logps/rejected": -56.898887634277344,
      "loss": 0.257,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.755866289138794,
      "rewards/margins": 1.2562954425811768,
      "rewards/rejected": -0.5004291534423828,
      "step": 938
    },
    {
      "epoch": 0.3756,
      "grad_norm": 6.398451328277588,
      "learning_rate": 8.749333333333333e-07,
      "logits/chosen": -2.8994994163513184,
      "logits/rejected": -3.079624652862549,
      "logps/chosen": -100.8250503540039,
      "logps/rejected": -54.9033317565918,
      "loss": 0.1539,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9717731475830078,
      "rewards/margins": 1.7936168909072876,
      "rewards/rejected": -0.8218437433242798,
      "step": 939
    },
    {
      "epoch": 0.376,
      "grad_norm": 5.725541114807129,
      "learning_rate": 8.748e-07,
      "logits/chosen": -2.8314156532287598,
      "logits/rejected": -2.2802765369415283,
      "logps/chosen": -65.48311614990234,
      "logps/rejected": -72.68955993652344,
      "loss": 0.1783,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1857355833053589,
      "rewards/margins": 1.6393159627914429,
      "rewards/rejected": -0.453580379486084,
      "step": 940
    },
    {
      "epoch": 0.3764,
      "grad_norm": 5.334782123565674,
      "learning_rate": 8.746666666666667e-07,
      "logits/chosen": -2.729731559753418,
      "logits/rejected": -2.0901474952697754,
      "logps/chosen": -104.80915832519531,
      "logps/rejected": -70.15399169921875,
      "loss": 0.127,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.335837960243225,
      "rewards/margins": 2.0067646503448486,
      "rewards/rejected": -0.6709266901016235,
      "step": 941
    },
    {
      "epoch": 0.3768,
      "grad_norm": 6.0039849281311035,
      "learning_rate": 8.745333333333334e-07,
      "logits/chosen": -2.5602807998657227,
      "logits/rejected": -2.059150457382202,
      "logps/chosen": -79.5755844116211,
      "logps/rejected": -81.91683197021484,
      "loss": 0.1679,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.886853814125061,
      "rewards/margins": 1.9429181814193726,
      "rewards/rejected": -1.056064486503601,
      "step": 942
    },
    {
      "epoch": 0.3772,
      "grad_norm": 5.957550048828125,
      "learning_rate": 8.743999999999999e-07,
      "logits/chosen": -2.545649290084839,
      "logits/rejected": -2.226205825805664,
      "logps/chosen": -154.59817504882812,
      "logps/rejected": -88.83810424804688,
      "loss": 0.1229,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7112358212471008,
      "rewards/margins": 2.035066604614258,
      "rewards/rejected": -1.3238308429718018,
      "step": 943
    },
    {
      "epoch": 0.3776,
      "grad_norm": 6.032373905181885,
      "learning_rate": 8.742666666666666e-07,
      "logits/chosen": -2.935276985168457,
      "logits/rejected": -2.3362936973571777,
      "logps/chosen": -63.245521545410156,
      "logps/rejected": -65.31108093261719,
      "loss": 0.1583,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.949009895324707,
      "rewards/margins": 1.834505558013916,
      "rewards/rejected": -0.8854956030845642,
      "step": 944
    },
    {
      "epoch": 0.378,
      "grad_norm": 4.719686031341553,
      "learning_rate": 8.741333333333333e-07,
      "logits/chosen": -2.89285945892334,
      "logits/rejected": -2.342930316925049,
      "logps/chosen": -107.33984375,
      "logps/rejected": -72.81736755371094,
      "loss": 0.1445,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7223438620567322,
      "rewards/margins": 1.9318832159042358,
      "rewards/rejected": -1.2095394134521484,
      "step": 945
    },
    {
      "epoch": 0.3784,
      "grad_norm": 6.77597188949585,
      "learning_rate": 8.739999999999999e-07,
      "logits/chosen": -2.8034543991088867,
      "logits/rejected": -2.6201276779174805,
      "logps/chosen": -82.97139739990234,
      "logps/rejected": -127.01115417480469,
      "loss": 0.2107,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9465904831886292,
      "rewards/margins": 1.6006889343261719,
      "rewards/rejected": -0.6540985107421875,
      "step": 946
    },
    {
      "epoch": 0.3788,
      "grad_norm": 6.661035060882568,
      "learning_rate": 8.738666666666666e-07,
      "logits/chosen": -2.789332866668701,
      "logits/rejected": -2.5865538120269775,
      "logps/chosen": -45.916709899902344,
      "logps/rejected": -50.216373443603516,
      "loss": 0.2927,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33418482542037964,
      "rewards/margins": 1.0859160423278809,
      "rewards/rejected": -0.7517311573028564,
      "step": 947
    },
    {
      "epoch": 0.3792,
      "grad_norm": 6.548311233520508,
      "learning_rate": 8.737333333333333e-07,
      "logits/chosen": -2.5782690048217773,
      "logits/rejected": -2.243723154067993,
      "logps/chosen": -127.55078125,
      "logps/rejected": -124.15309143066406,
      "loss": 0.1736,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8491779565811157,
      "rewards/margins": 1.7512900829315186,
      "rewards/rejected": -0.9021121859550476,
      "step": 948
    },
    {
      "epoch": 0.3796,
      "grad_norm": 5.302330493927002,
      "learning_rate": 8.736e-07,
      "logits/chosen": -2.663623332977295,
      "logits/rejected": -2.43522310256958,
      "logps/chosen": -105.30517578125,
      "logps/rejected": -56.11470031738281,
      "loss": 0.1038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1991249322891235,
      "rewards/margins": 2.217247247695923,
      "rewards/rejected": -1.0181223154067993,
      "step": 949
    },
    {
      "epoch": 0.38,
      "grad_norm": 4.19089937210083,
      "learning_rate": 8.734666666666666e-07,
      "logits/chosen": -2.8580169677734375,
      "logits/rejected": -2.7386460304260254,
      "logps/chosen": -76.07984924316406,
      "logps/rejected": -49.888206481933594,
      "loss": 0.1337,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2673542499542236,
      "rewards/margins": 1.9531311988830566,
      "rewards/rejected": -0.6857770681381226,
      "step": 950
    },
    {
      "epoch": 0.3804,
      "grad_norm": 4.0214996337890625,
      "learning_rate": 8.733333333333333e-07,
      "logits/chosen": -2.4168033599853516,
      "logits/rejected": -2.045470952987671,
      "logps/chosen": -144.9339599609375,
      "logps/rejected": -83.54417419433594,
      "loss": 0.0929,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3214317560195923,
      "rewards/margins": 2.4414138793945312,
      "rewards/rejected": -1.1199822425842285,
      "step": 951
    },
    {
      "epoch": 0.3808,
      "grad_norm": 5.284055709838867,
      "learning_rate": 8.732e-07,
      "logits/chosen": -2.6955201625823975,
      "logits/rejected": -2.449265956878662,
      "logps/chosen": -113.5772705078125,
      "logps/rejected": -53.71759796142578,
      "loss": 0.1828,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2606301307678223,
      "rewards/margins": 1.8936699628829956,
      "rewards/rejected": -0.6330398917198181,
      "step": 952
    },
    {
      "epoch": 0.3812,
      "grad_norm": 5.653260231018066,
      "learning_rate": 8.730666666666666e-07,
      "logits/chosen": -2.5849411487579346,
      "logits/rejected": -2.259817600250244,
      "logps/chosen": -68.93695831298828,
      "logps/rejected": -66.43582916259766,
      "loss": 0.2,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1729767322540283,
      "rewards/margins": 1.6965420246124268,
      "rewards/rejected": -0.5235652923583984,
      "step": 953
    },
    {
      "epoch": 0.3816,
      "grad_norm": 7.444116115570068,
      "learning_rate": 8.729333333333333e-07,
      "logits/chosen": -3.0475776195526123,
      "logits/rejected": -2.482595443725586,
      "logps/chosen": -67.29268646240234,
      "logps/rejected": -62.233436584472656,
      "loss": 0.2307,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8307590484619141,
      "rewards/margins": 1.3515970706939697,
      "rewards/rejected": -0.5208380222320557,
      "step": 954
    },
    {
      "epoch": 0.382,
      "grad_norm": 7.713837623596191,
      "learning_rate": 8.728e-07,
      "logits/chosen": -2.9677512645721436,
      "logits/rejected": -2.316390037536621,
      "logps/chosen": -88.94361877441406,
      "logps/rejected": -49.49806213378906,
      "loss": 0.2535,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7299566268920898,
      "rewards/margins": 1.2456250190734863,
      "rewards/rejected": -0.515668511390686,
      "step": 955
    },
    {
      "epoch": 0.3824,
      "grad_norm": 4.723278045654297,
      "learning_rate": 8.726666666666666e-07,
      "logits/chosen": -2.291262626647949,
      "logits/rejected": -2.403003215789795,
      "logps/chosen": -104.73817443847656,
      "logps/rejected": -80.83831787109375,
      "loss": 0.1106,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8029754161834717,
      "rewards/margins": 2.193082571029663,
      "rewards/rejected": -0.3901071548461914,
      "step": 956
    },
    {
      "epoch": 0.3828,
      "grad_norm": 6.556835174560547,
      "learning_rate": 8.725333333333333e-07,
      "logits/chosen": -2.5124411582946777,
      "logits/rejected": -1.9974067211151123,
      "logps/chosen": -124.92411804199219,
      "logps/rejected": -83.1195068359375,
      "loss": 0.1524,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5948879718780518,
      "rewards/margins": 1.8181155920028687,
      "rewards/rejected": -1.2232277393341064,
      "step": 957
    },
    {
      "epoch": 0.3832,
      "grad_norm": 5.734649181365967,
      "learning_rate": 8.723999999999999e-07,
      "logits/chosen": -2.8155558109283447,
      "logits/rejected": -2.804302930831909,
      "logps/chosen": -57.8125114440918,
      "logps/rejected": -50.0216064453125,
      "loss": 0.23,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6461658477783203,
      "rewards/margins": 1.6440050601959229,
      "rewards/rejected": -0.9978392124176025,
      "step": 958
    },
    {
      "epoch": 0.3836,
      "grad_norm": 4.4523820877075195,
      "learning_rate": 8.722666666666666e-07,
      "logits/chosen": -2.6709823608398438,
      "logits/rejected": -2.2367029190063477,
      "logps/chosen": -67.29917907714844,
      "logps/rejected": -99.59089660644531,
      "loss": 0.152,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1894584894180298,
      "rewards/margins": 2.165238380432129,
      "rewards/rejected": -0.9757797718048096,
      "step": 959
    },
    {
      "epoch": 0.384,
      "grad_norm": 8.858838081359863,
      "learning_rate": 8.721333333333333e-07,
      "logits/chosen": -2.941591262817383,
      "logits/rejected": -2.82267427444458,
      "logps/chosen": -76.90930938720703,
      "logps/rejected": -44.057071685791016,
      "loss": 0.2561,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0552825927734375,
      "rewards/margins": 1.2894847393035889,
      "rewards/rejected": -0.23420219123363495,
      "step": 960
    },
    {
      "epoch": 0.3844,
      "grad_norm": 4.99636697769165,
      "learning_rate": 8.72e-07,
      "logits/chosen": -2.578272819519043,
      "logits/rejected": -2.3307554721832275,
      "logps/chosen": -88.71958923339844,
      "logps/rejected": -41.71125030517578,
      "loss": 0.1679,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9030708074569702,
      "rewards/margins": 1.7563350200653076,
      "rewards/rejected": -0.8532642126083374,
      "step": 961
    },
    {
      "epoch": 0.3848,
      "grad_norm": 5.117876052856445,
      "learning_rate": 8.718666666666667e-07,
      "logits/chosen": -2.562129020690918,
      "logits/rejected": -2.600215435028076,
      "logps/chosen": -100.96953582763672,
      "logps/rejected": -57.65878677368164,
      "loss": 0.17,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1966760158538818,
      "rewards/margins": 1.7435694932937622,
      "rewards/rejected": -0.5468934774398804,
      "step": 962
    },
    {
      "epoch": 0.3852,
      "grad_norm": 6.28602933883667,
      "learning_rate": 8.717333333333334e-07,
      "logits/chosen": -2.8052473068237305,
      "logits/rejected": -2.7961158752441406,
      "logps/chosen": -85.10501861572266,
      "logps/rejected": -42.91856384277344,
      "loss": 0.2208,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7358356714248657,
      "rewards/margins": 1.4390270709991455,
      "rewards/rejected": -0.7031913995742798,
      "step": 963
    },
    {
      "epoch": 0.3856,
      "grad_norm": 5.813769340515137,
      "learning_rate": 8.716e-07,
      "logits/chosen": -2.7974743843078613,
      "logits/rejected": -2.4992332458496094,
      "logps/chosen": -97.34524536132812,
      "logps/rejected": -123.00519561767578,
      "loss": 0.1558,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7987571954727173,
      "rewards/margins": 1.8315870761871338,
      "rewards/rejected": -1.0328298807144165,
      "step": 964
    },
    {
      "epoch": 0.386,
      "grad_norm": 7.3365583419799805,
      "learning_rate": 8.714666666666665e-07,
      "logits/chosen": -2.898311138153076,
      "logits/rejected": -2.095128059387207,
      "logps/chosen": -72.73185729980469,
      "logps/rejected": -63.733455657958984,
      "loss": 0.2429,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6147619485855103,
      "rewards/margins": 1.2921547889709473,
      "rewards/rejected": -0.6773929595947266,
      "step": 965
    },
    {
      "epoch": 0.3864,
      "grad_norm": 6.095955848693848,
      "learning_rate": 8.713333333333332e-07,
      "logits/chosen": -2.798210382461548,
      "logits/rejected": -2.7262349128723145,
      "logps/chosen": -74.25667572021484,
      "logps/rejected": -53.405364990234375,
      "loss": 0.2045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7549623250961304,
      "rewards/margins": 1.4958093166351318,
      "rewards/rejected": -0.7408469915390015,
      "step": 966
    },
    {
      "epoch": 0.3868,
      "grad_norm": 6.883148193359375,
      "learning_rate": 8.711999999999999e-07,
      "logits/chosen": -2.8087687492370605,
      "logits/rejected": -2.2032761573791504,
      "logps/chosen": -106.83847045898438,
      "logps/rejected": -89.38593292236328,
      "loss": 0.1626,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34209346771240234,
      "rewards/margins": 1.7343707084655762,
      "rewards/rejected": -1.3922772407531738,
      "step": 967
    },
    {
      "epoch": 0.3872,
      "grad_norm": 5.695356845855713,
      "learning_rate": 8.710666666666666e-07,
      "logits/chosen": -3.242013692855835,
      "logits/rejected": -2.970071315765381,
      "logps/chosen": -41.40290069580078,
      "logps/rejected": -50.528621673583984,
      "loss": 0.2211,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5658652186393738,
      "rewards/margins": 1.3988677263259888,
      "rewards/rejected": -0.8330024480819702,
      "step": 968
    },
    {
      "epoch": 0.3876,
      "grad_norm": 7.92154598236084,
      "learning_rate": 8.709333333333333e-07,
      "logits/chosen": -2.8303110599517822,
      "logits/rejected": -2.193270206451416,
      "logps/chosen": -112.2707748413086,
      "logps/rejected": -90.95590209960938,
      "loss": 0.2388,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.47580644488334656,
      "rewards/margins": 1.4291954040527344,
      "rewards/rejected": -0.9533889293670654,
      "step": 969
    },
    {
      "epoch": 0.388,
      "grad_norm": 7.109565258026123,
      "learning_rate": 8.708e-07,
      "logits/chosen": -2.98073148727417,
      "logits/rejected": -2.6641488075256348,
      "logps/chosen": -81.35861206054688,
      "logps/rejected": -52.60948944091797,
      "loss": 0.2224,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45398980379104614,
      "rewards/margins": 1.6401773691177368,
      "rewards/rejected": -1.1861876249313354,
      "step": 970
    },
    {
      "epoch": 0.3884,
      "grad_norm": 4.563551902770996,
      "learning_rate": 8.706666666666667e-07,
      "logits/chosen": -2.6802330017089844,
      "logits/rejected": -2.008694648742676,
      "logps/chosen": -99.59532928466797,
      "logps/rejected": -69.915771484375,
      "loss": 0.1039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9313681125640869,
      "rewards/margins": 2.2336201667785645,
      "rewards/rejected": -1.3022520542144775,
      "step": 971
    },
    {
      "epoch": 0.3888,
      "grad_norm": 5.367600917816162,
      "learning_rate": 8.705333333333334e-07,
      "logits/chosen": -2.9497134685516357,
      "logits/rejected": -2.7987587451934814,
      "logps/chosen": -61.61463928222656,
      "logps/rejected": -40.742652893066406,
      "loss": 0.2584,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7167562246322632,
      "rewards/margins": 1.339586615562439,
      "rewards/rejected": -0.6228303909301758,
      "step": 972
    },
    {
      "epoch": 0.3892,
      "grad_norm": 7.368346214294434,
      "learning_rate": 8.704e-07,
      "logits/chosen": -2.6216487884521484,
      "logits/rejected": -2.0953638553619385,
      "logps/chosen": -109.74604797363281,
      "logps/rejected": -105.47409057617188,
      "loss": 0.2275,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6471913456916809,
      "rewards/margins": 1.4341260194778442,
      "rewards/rejected": -0.7869346737861633,
      "step": 973
    },
    {
      "epoch": 0.3896,
      "grad_norm": 7.024961948394775,
      "learning_rate": 8.702666666666665e-07,
      "logits/chosen": -2.8917582035064697,
      "logits/rejected": -2.479753017425537,
      "logps/chosen": -49.66730499267578,
      "logps/rejected": -51.73515319824219,
      "loss": 0.2859,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5976575613021851,
      "rewards/margins": 1.106526494026184,
      "rewards/rejected": -0.5088688731193542,
      "step": 974
    },
    {
      "epoch": 0.39,
      "grad_norm": 4.87937593460083,
      "learning_rate": 8.701333333333332e-07,
      "logits/chosen": -2.8518362045288086,
      "logits/rejected": -2.6251397132873535,
      "logps/chosen": -71.07688903808594,
      "logps/rejected": -64.99114990234375,
      "loss": 0.1554,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9719394445419312,
      "rewards/margins": 1.9586788415908813,
      "rewards/rejected": -0.9867393374443054,
      "step": 975
    },
    {
      "epoch": 0.3904,
      "grad_norm": 5.656957626342773,
      "learning_rate": 8.699999999999999e-07,
      "logits/chosen": -2.6454100608825684,
      "logits/rejected": -2.0905821323394775,
      "logps/chosen": -120.17784118652344,
      "logps/rejected": -46.80760955810547,
      "loss": 0.1426,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2038981914520264,
      "rewards/margins": 1.9990262985229492,
      "rewards/rejected": -0.7951280474662781,
      "step": 976
    },
    {
      "epoch": 0.3908,
      "grad_norm": 4.979617595672607,
      "learning_rate": 8.698666666666666e-07,
      "logits/chosen": -2.8319268226623535,
      "logits/rejected": -2.5888023376464844,
      "logps/chosen": -56.34031677246094,
      "logps/rejected": -59.18065643310547,
      "loss": 0.1768,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5371357202529907,
      "rewards/margins": 1.7189571857452393,
      "rewards/rejected": -1.1818214654922485,
      "step": 977
    },
    {
      "epoch": 0.3912,
      "grad_norm": 5.398275852203369,
      "learning_rate": 8.697333333333333e-07,
      "logits/chosen": -2.750751495361328,
      "logits/rejected": -2.4734859466552734,
      "logps/chosen": -132.1473388671875,
      "logps/rejected": -100.23445129394531,
      "loss": 0.1338,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7239872217178345,
      "rewards/margins": 1.9802043437957764,
      "rewards/rejected": -1.2562172412872314,
      "step": 978
    },
    {
      "epoch": 0.3916,
      "grad_norm": 4.572668552398682,
      "learning_rate": 8.696e-07,
      "logits/chosen": -2.7451229095458984,
      "logits/rejected": -2.212873935699463,
      "logps/chosen": -82.5506362915039,
      "logps/rejected": -69.12680053710938,
      "loss": 0.1452,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3009724617004395,
      "rewards/margins": 2.0167477130889893,
      "rewards/rejected": -0.7157753109931946,
      "step": 979
    },
    {
      "epoch": 0.392,
      "grad_norm": 6.0005669593811035,
      "learning_rate": 8.694666666666667e-07,
      "logits/chosen": -2.8107657432556152,
      "logits/rejected": -2.464435338973999,
      "logps/chosen": -64.10537719726562,
      "logps/rejected": -67.6341323852539,
      "loss": 0.1654,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0739080905914307,
      "rewards/margins": 1.7216553688049316,
      "rewards/rejected": -0.6477472186088562,
      "step": 980
    },
    {
      "epoch": 0.3924,
      "grad_norm": 6.064698696136475,
      "learning_rate": 8.693333333333333e-07,
      "logits/chosen": -2.952043056488037,
      "logits/rejected": -2.7882542610168457,
      "logps/chosen": -78.9455337524414,
      "logps/rejected": -50.25938415527344,
      "loss": 0.214,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6167993545532227,
      "rewards/margins": 1.4472618103027344,
      "rewards/rejected": -0.8304623961448669,
      "step": 981
    },
    {
      "epoch": 0.3928,
      "grad_norm": 6.340956687927246,
      "learning_rate": 8.692e-07,
      "logits/chosen": -2.643575668334961,
      "logits/rejected": -2.1467902660369873,
      "logps/chosen": -48.27458953857422,
      "logps/rejected": -67.31533813476562,
      "loss": 0.2151,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6339424252510071,
      "rewards/margins": 1.433275818824768,
      "rewards/rejected": -0.799333393573761,
      "step": 982
    },
    {
      "epoch": 0.3932,
      "grad_norm": 4.4226250648498535,
      "learning_rate": 8.690666666666667e-07,
      "logits/chosen": -2.724486827850342,
      "logits/rejected": -2.093820333480835,
      "logps/chosen": -67.280517578125,
      "logps/rejected": -68.33989715576172,
      "loss": 0.1391,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9245180487632751,
      "rewards/margins": 1.9229596853256226,
      "rewards/rejected": -0.9984416961669922,
      "step": 983
    },
    {
      "epoch": 0.3936,
      "grad_norm": 6.23267936706543,
      "learning_rate": 8.689333333333333e-07,
      "logits/chosen": -2.5896387100219727,
      "logits/rejected": -2.1865286827087402,
      "logps/chosen": -50.683101654052734,
      "logps/rejected": -89.80494689941406,
      "loss": 0.2057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9082474112510681,
      "rewards/margins": 1.4896198511123657,
      "rewards/rejected": -0.5813724994659424,
      "step": 984
    },
    {
      "epoch": 0.394,
      "grad_norm": 10.346944808959961,
      "learning_rate": 8.687999999999999e-07,
      "logits/chosen": -3.056504726409912,
      "logits/rejected": -2.811279058456421,
      "logps/chosen": -58.93798828125,
      "logps/rejected": -66.27070617675781,
      "loss": 0.3307,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.259286493062973,
      "rewards/margins": 0.9377282857894897,
      "rewards/rejected": -0.6784418225288391,
      "step": 985
    },
    {
      "epoch": 0.3944,
      "grad_norm": 7.053318500518799,
      "learning_rate": 8.686666666666666e-07,
      "logits/chosen": -2.5776124000549316,
      "logits/rejected": -2.218158721923828,
      "logps/chosen": -113.44157409667969,
      "logps/rejected": -110.65792083740234,
      "loss": 0.1973,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4183425903320312,
      "rewards/margins": 1.6644409894943237,
      "rewards/rejected": -0.2460983395576477,
      "step": 986
    },
    {
      "epoch": 0.3948,
      "grad_norm": 4.075630187988281,
      "learning_rate": 8.685333333333333e-07,
      "logits/chosen": -2.563246726989746,
      "logits/rejected": -2.23046612739563,
      "logps/chosen": -47.74718475341797,
      "logps/rejected": -63.2021484375,
      "loss": 0.1029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1354200839996338,
      "rewards/margins": 2.2588093280792236,
      "rewards/rejected": -1.1233892440795898,
      "step": 987
    },
    {
      "epoch": 0.3952,
      "grad_norm": 6.010193347930908,
      "learning_rate": 8.683999999999999e-07,
      "logits/chosen": -3.0646767616271973,
      "logits/rejected": -2.988685131072998,
      "logps/chosen": -55.53048324584961,
      "logps/rejected": -39.937198638916016,
      "loss": 0.2579,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7398496866226196,
      "rewards/margins": 1.2248611450195312,
      "rewards/rejected": -0.485011488199234,
      "step": 988
    },
    {
      "epoch": 0.3956,
      "grad_norm": 4.071185111999512,
      "learning_rate": 8.682666666666666e-07,
      "logits/chosen": -2.4423437118530273,
      "logits/rejected": -2.0118165016174316,
      "logps/chosen": -184.06875610351562,
      "logps/rejected": -74.27545928955078,
      "loss": 0.0852,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4792640209197998,
      "rewards/margins": 2.422483444213867,
      "rewards/rejected": -0.9432194232940674,
      "step": 989
    },
    {
      "epoch": 0.396,
      "grad_norm": 5.225976943969727,
      "learning_rate": 8.681333333333333e-07,
      "logits/chosen": -2.5433740615844727,
      "logits/rejected": -2.129751205444336,
      "logps/chosen": -141.2436065673828,
      "logps/rejected": -115.30207061767578,
      "loss": 0.1685,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2802561521530151,
      "rewards/margins": 1.975832223892212,
      "rewards/rejected": -0.6955760717391968,
      "step": 990
    },
    {
      "epoch": 0.3964,
      "grad_norm": 6.7334113121032715,
      "learning_rate": 8.68e-07,
      "logits/chosen": -2.997800350189209,
      "logits/rejected": -2.354106903076172,
      "logps/chosen": -49.32048034667969,
      "logps/rejected": -79.51324462890625,
      "loss": 0.1785,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6489108800888062,
      "rewards/margins": 1.9143307209014893,
      "rewards/rejected": -1.265419840812683,
      "step": 991
    },
    {
      "epoch": 0.3968,
      "grad_norm": 3.6524155139923096,
      "learning_rate": 8.678666666666667e-07,
      "logits/chosen": -2.350003480911255,
      "logits/rejected": -1.9805891513824463,
      "logps/chosen": -161.40577697753906,
      "logps/rejected": -70.99726104736328,
      "loss": 0.0864,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6552543640136719,
      "rewards/margins": 2.4050424098968506,
      "rewards/rejected": -0.7497881054878235,
      "step": 992
    },
    {
      "epoch": 0.3972,
      "grad_norm": 3.6316683292388916,
      "learning_rate": 8.677333333333333e-07,
      "logits/chosen": -2.8646411895751953,
      "logits/rejected": -2.397782802581787,
      "logps/chosen": -70.45438385009766,
      "logps/rejected": -61.739044189453125,
      "loss": 0.0868,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6358314752578735,
      "rewards/margins": 2.4004201889038086,
      "rewards/rejected": -1.7645888328552246,
      "step": 993
    },
    {
      "epoch": 0.3976,
      "grad_norm": 3.484469175338745,
      "learning_rate": 8.676e-07,
      "logits/chosen": -2.7070016860961914,
      "logits/rejected": -2.3264107704162598,
      "logps/chosen": -103.56809997558594,
      "logps/rejected": -95.78862762451172,
      "loss": 0.0724,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1659462451934814,
      "rewards/margins": 2.5965397357940674,
      "rewards/rejected": -1.430593490600586,
      "step": 994
    },
    {
      "epoch": 0.398,
      "grad_norm": 3.2968127727508545,
      "learning_rate": 8.674666666666667e-07,
      "logits/chosen": -2.7563233375549316,
      "logits/rejected": -2.281672954559326,
      "logps/chosen": -95.29473114013672,
      "logps/rejected": -132.6685333251953,
      "loss": 0.0762,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1683156490325928,
      "rewards/margins": 2.550485610961914,
      "rewards/rejected": -1.3821697235107422,
      "step": 995
    },
    {
      "epoch": 0.3984,
      "grad_norm": 5.702269077301025,
      "learning_rate": 8.673333333333332e-07,
      "logits/chosen": -2.9259843826293945,
      "logits/rejected": -2.7505173683166504,
      "logps/chosen": -64.61163330078125,
      "logps/rejected": -53.857852935791016,
      "loss": 0.1905,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1408544778823853,
      "rewards/margins": 1.5615291595458984,
      "rewards/rejected": -0.42067471146583557,
      "step": 996
    },
    {
      "epoch": 0.3988,
      "grad_norm": 5.268892288208008,
      "learning_rate": 8.671999999999999e-07,
      "logits/chosen": -2.533100128173828,
      "logits/rejected": -2.0726044178009033,
      "logps/chosen": -61.62455749511719,
      "logps/rejected": -70.6248550415039,
      "loss": 0.1395,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0139684677124023,
      "rewards/margins": 1.9325112104415894,
      "rewards/rejected": -0.9185426831245422,
      "step": 997
    },
    {
      "epoch": 0.3992,
      "grad_norm": 5.541822910308838,
      "learning_rate": 8.670666666666666e-07,
      "logits/chosen": -2.781607151031494,
      "logits/rejected": -2.8729071617126465,
      "logps/chosen": -95.81129455566406,
      "logps/rejected": -62.563697814941406,
      "loss": 0.1945,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8524937033653259,
      "rewards/margins": 1.6011886596679688,
      "rewards/rejected": -0.7486950159072876,
      "step": 998
    },
    {
      "epoch": 0.3996,
      "grad_norm": 4.966738224029541,
      "learning_rate": 8.669333333333333e-07,
      "logits/chosen": -2.7758231163024902,
      "logits/rejected": -2.3369429111480713,
      "logps/chosen": -68.64093017578125,
      "logps/rejected": -94.62098693847656,
      "loss": 0.1455,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5431903600692749,
      "rewards/margins": 1.9190380573272705,
      "rewards/rejected": -1.3758476972579956,
      "step": 999
    },
    {
      "epoch": 0.4,
      "grad_norm": 4.604214191436768,
      "learning_rate": 8.668e-07,
      "logits/chosen": -2.8453469276428223,
      "logits/rejected": -2.2821168899536133,
      "logps/chosen": -80.79519653320312,
      "logps/rejected": -60.766441345214844,
      "loss": 0.1081,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7824138402938843,
      "rewards/margins": 2.1809630393981934,
      "rewards/rejected": -1.3985493183135986,
      "step": 1000
    },
    {
      "epoch": 0.4004,
      "grad_norm": 3.775970458984375,
      "learning_rate": 8.666666666666667e-07,
      "logits/chosen": -2.8710641860961914,
      "logits/rejected": -2.378533363342285,
      "logps/chosen": -72.9114761352539,
      "logps/rejected": -80.80615234375,
      "loss": 0.0881,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8387050628662109,
      "rewards/margins": 2.6807403564453125,
      "rewards/rejected": -1.8420352935791016,
      "step": 1001
    },
    {
      "epoch": 0.4008,
      "grad_norm": 4.79300594329834,
      "learning_rate": 8.665333333333334e-07,
      "logits/chosen": -2.7631516456604004,
      "logits/rejected": -2.270613670349121,
      "logps/chosen": -86.48231506347656,
      "logps/rejected": -71.35093688964844,
      "loss": 0.1683,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.180905818939209,
      "rewards/margins": 1.8677597045898438,
      "rewards/rejected": -0.6868540048599243,
      "step": 1002
    },
    {
      "epoch": 0.4012,
      "grad_norm": 3.6449804306030273,
      "learning_rate": 8.663999999999999e-07,
      "logits/chosen": -2.8394367694854736,
      "logits/rejected": -2.439551830291748,
      "logps/chosen": -89.7911376953125,
      "logps/rejected": -60.81350326538086,
      "loss": 0.0961,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2077770233154297,
      "rewards/margins": 2.320098876953125,
      "rewards/rejected": -1.1123216152191162,
      "step": 1003
    },
    {
      "epoch": 0.4016,
      "grad_norm": 5.786550045013428,
      "learning_rate": 8.662666666666666e-07,
      "logits/chosen": -2.455998420715332,
      "logits/rejected": -2.177076578140259,
      "logps/chosen": -97.27970123291016,
      "logps/rejected": -49.527671813964844,
      "loss": 0.2217,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8138920068740845,
      "rewards/margins": 1.395082712173462,
      "rewards/rejected": -0.5811907052993774,
      "step": 1004
    },
    {
      "epoch": 0.402,
      "grad_norm": 6.436371326446533,
      "learning_rate": 8.661333333333333e-07,
      "logits/chosen": -2.6833572387695312,
      "logits/rejected": -2.546783924102783,
      "logps/chosen": -110.32832336425781,
      "logps/rejected": -126.41394805908203,
      "loss": 0.1912,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1528453826904297,
      "rewards/margins": 2.1354551315307617,
      "rewards/rejected": -0.9826098084449768,
      "step": 1005
    },
    {
      "epoch": 0.4024,
      "grad_norm": 7.960711479187012,
      "learning_rate": 8.659999999999999e-07,
      "logits/chosen": -2.6147499084472656,
      "logits/rejected": -2.485445261001587,
      "logps/chosen": -106.2618408203125,
      "logps/rejected": -93.64955139160156,
      "loss": 0.1793,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8490204215049744,
      "rewards/margins": 1.7467564344406128,
      "rewards/rejected": -0.8977359533309937,
      "step": 1006
    },
    {
      "epoch": 0.4028,
      "grad_norm": 6.531599044799805,
      "learning_rate": 8.658666666666666e-07,
      "logits/chosen": -3.116602659225464,
      "logits/rejected": -2.290012836456299,
      "logps/chosen": -56.41143798828125,
      "logps/rejected": -60.74434280395508,
      "loss": 0.1266,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9681905508041382,
      "rewards/margins": 2.017411231994629,
      "rewards/rejected": -1.0492206811904907,
      "step": 1007
    },
    {
      "epoch": 0.4032,
      "grad_norm": 7.727779865264893,
      "learning_rate": 8.657333333333333e-07,
      "logits/chosen": -2.576991558074951,
      "logits/rejected": -2.0707502365112305,
      "logps/chosen": -78.69312286376953,
      "logps/rejected": -217.9151153564453,
      "loss": 0.1222,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8040945529937744,
      "rewards/margins": 2.0425450801849365,
      "rewards/rejected": -1.2384506464004517,
      "step": 1008
    },
    {
      "epoch": 0.4036,
      "grad_norm": 5.587708950042725,
      "learning_rate": 8.656e-07,
      "logits/chosen": -2.5765509605407715,
      "logits/rejected": -2.273057222366333,
      "logps/chosen": -72.46549224853516,
      "logps/rejected": -70.70696258544922,
      "loss": 0.1691,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8668043613433838,
      "rewards/margins": 1.7221589088439941,
      "rewards/rejected": -0.8553545475006104,
      "step": 1009
    },
    {
      "epoch": 0.404,
      "grad_norm": 5.459868431091309,
      "learning_rate": 8.654666666666667e-07,
      "logits/chosen": -2.6790966987609863,
      "logits/rejected": -2.378330945968628,
      "logps/chosen": -83.90863800048828,
      "logps/rejected": -60.32377243041992,
      "loss": 0.1706,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0322569608688354,
      "rewards/margins": 1.6981654167175293,
      "rewards/rejected": -0.6659084558486938,
      "step": 1010
    },
    {
      "epoch": 0.4044,
      "grad_norm": 7.349857330322266,
      "learning_rate": 8.653333333333333e-07,
      "logits/chosen": -2.643165349960327,
      "logits/rejected": -2.5420403480529785,
      "logps/chosen": -105.24488067626953,
      "logps/rejected": -58.71646499633789,
      "loss": 0.2778,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7895001173019409,
      "rewards/margins": 1.3144493103027344,
      "rewards/rejected": -0.5249492526054382,
      "step": 1011
    },
    {
      "epoch": 0.4048,
      "grad_norm": 5.595363616943359,
      "learning_rate": 8.651999999999999e-07,
      "logits/chosen": -2.9312186241149902,
      "logits/rejected": -2.784353017807007,
      "logps/chosen": -66.95304870605469,
      "logps/rejected": -53.83393859863281,
      "loss": 0.1768,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5738117098808289,
      "rewards/margins": 1.6598964929580688,
      "rewards/rejected": -1.0860848426818848,
      "step": 1012
    },
    {
      "epoch": 0.4052,
      "grad_norm": 4.256060600280762,
      "learning_rate": 8.650666666666666e-07,
      "logits/chosen": -2.754885196685791,
      "logits/rejected": -2.5106797218322754,
      "logps/chosen": -77.63230895996094,
      "logps/rejected": -74.18756866455078,
      "loss": 0.1174,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8577167987823486,
      "rewards/margins": 2.0876121520996094,
      "rewards/rejected": -1.2298953533172607,
      "step": 1013
    },
    {
      "epoch": 0.4056,
      "grad_norm": 3.071261167526245,
      "learning_rate": 8.649333333333333e-07,
      "logits/chosen": -2.3283917903900146,
      "logits/rejected": -2.185333728790283,
      "logps/chosen": -107.61334228515625,
      "logps/rejected": -81.17776489257812,
      "loss": 0.0584,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.859225869178772,
      "rewards/margins": 2.8113605976104736,
      "rewards/rejected": -0.9521347284317017,
      "step": 1014
    },
    {
      "epoch": 0.406,
      "grad_norm": 4.870991230010986,
      "learning_rate": 8.648e-07,
      "logits/chosen": -2.689333915710449,
      "logits/rejected": -2.3537707328796387,
      "logps/chosen": -79.6829605102539,
      "logps/rejected": -56.09159469604492,
      "loss": 0.1426,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1902663707733154,
      "rewards/margins": 1.8762571811676025,
      "rewards/rejected": -0.6859906911849976,
      "step": 1015
    },
    {
      "epoch": 0.4064,
      "grad_norm": 4.192580223083496,
      "learning_rate": 8.646666666666667e-07,
      "logits/chosen": -2.913516044616699,
      "logits/rejected": -2.5222456455230713,
      "logps/chosen": -112.29328918457031,
      "logps/rejected": -71.4862060546875,
      "loss": 0.1194,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.168831706047058,
      "rewards/margins": 2.401299476623535,
      "rewards/rejected": -1.2324680089950562,
      "step": 1016
    },
    {
      "epoch": 0.4068,
      "grad_norm": 3.9195661544799805,
      "learning_rate": 8.645333333333333e-07,
      "logits/chosen": -2.753016710281372,
      "logits/rejected": -2.2621002197265625,
      "logps/chosen": -82.22157287597656,
      "logps/rejected": -47.63341522216797,
      "loss": 0.1277,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3110744953155518,
      "rewards/margins": 2.089522123336792,
      "rewards/rejected": -0.7784477472305298,
      "step": 1017
    },
    {
      "epoch": 0.4072,
      "grad_norm": 4.765135765075684,
      "learning_rate": 8.643999999999999e-07,
      "logits/chosen": -2.786489963531494,
      "logits/rejected": -2.8777096271514893,
      "logps/chosen": -76.01483917236328,
      "logps/rejected": -47.71628952026367,
      "loss": 0.1464,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1583654880523682,
      "rewards/margins": 1.917616844177246,
      "rewards/rejected": -0.7592514157295227,
      "step": 1018
    },
    {
      "epoch": 0.4076,
      "grad_norm": 6.380139350891113,
      "learning_rate": 8.642666666666666e-07,
      "logits/chosen": -2.7972590923309326,
      "logits/rejected": -2.434694766998291,
      "logps/chosen": -57.97892761230469,
      "logps/rejected": -63.705081939697266,
      "loss": 0.2178,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6651099920272827,
      "rewards/margins": 1.4263098239898682,
      "rewards/rejected": -0.7611997723579407,
      "step": 1019
    },
    {
      "epoch": 0.408,
      "grad_norm": 6.411212921142578,
      "learning_rate": 8.641333333333333e-07,
      "logits/chosen": -2.7664785385131836,
      "logits/rejected": -2.344521999359131,
      "logps/chosen": -113.1333236694336,
      "logps/rejected": -48.746009826660156,
      "loss": 0.2012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7926356792449951,
      "rewards/margins": 1.5072240829467773,
      "rewards/rejected": -0.7145884037017822,
      "step": 1020
    },
    {
      "epoch": 0.4084,
      "grad_norm": 6.912511348724365,
      "learning_rate": 8.639999999999999e-07,
      "logits/chosen": -2.55224871635437,
      "logits/rejected": -2.1882638931274414,
      "logps/chosen": -72.35969543457031,
      "logps/rejected": -99.99888610839844,
      "loss": 0.2027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7943757772445679,
      "rewards/margins": 1.7370424270629883,
      "rewards/rejected": -0.9426666498184204,
      "step": 1021
    },
    {
      "epoch": 0.4088,
      "grad_norm": 4.342099666595459,
      "learning_rate": 8.638666666666666e-07,
      "logits/chosen": -2.8822407722473145,
      "logits/rejected": -2.813293933868408,
      "logps/chosen": -84.34818267822266,
      "logps/rejected": -65.07830047607422,
      "loss": 0.0907,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.467359185218811,
      "rewards/margins": 2.431023120880127,
      "rewards/rejected": -0.9636638760566711,
      "step": 1022
    },
    {
      "epoch": 0.4092,
      "grad_norm": 5.084989547729492,
      "learning_rate": 8.637333333333333e-07,
      "logits/chosen": -2.847410202026367,
      "logits/rejected": -2.6000723838806152,
      "logps/chosen": -83.94284057617188,
      "logps/rejected": -61.87375259399414,
      "loss": 0.1413,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.072887897491455,
      "rewards/margins": 2.0474138259887695,
      "rewards/rejected": -0.974526047706604,
      "step": 1023
    },
    {
      "epoch": 0.4096,
      "grad_norm": 6.62729024887085,
      "learning_rate": 8.636e-07,
      "logits/chosen": -2.8211162090301514,
      "logits/rejected": -2.319167375564575,
      "logps/chosen": -65.2165756225586,
      "logps/rejected": -65.58355712890625,
      "loss": 0.249,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0097395181655884,
      "rewards/margins": 1.404698371887207,
      "rewards/rejected": -0.39495888352394104,
      "step": 1024
    },
    {
      "epoch": 0.41,
      "grad_norm": 5.340769290924072,
      "learning_rate": 8.634666666666667e-07,
      "logits/chosen": -2.561861276626587,
      "logits/rejected": -2.5624771118164062,
      "logps/chosen": -90.2411880493164,
      "logps/rejected": -81.59223175048828,
      "loss": 0.1815,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0835567712783813,
      "rewards/margins": 1.7925350666046143,
      "rewards/rejected": -0.7089782953262329,
      "step": 1025
    },
    {
      "epoch": 0.4104,
      "grad_norm": 5.121625900268555,
      "learning_rate": 8.633333333333333e-07,
      "logits/chosen": -2.8172168731689453,
      "logits/rejected": -2.550626754760742,
      "logps/chosen": -65.62846374511719,
      "logps/rejected": -58.03926086425781,
      "loss": 0.1778,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9317167401313782,
      "rewards/margins": 1.7991361618041992,
      "rewards/rejected": -0.867419421672821,
      "step": 1026
    },
    {
      "epoch": 0.4108,
      "grad_norm": 4.594574451446533,
      "learning_rate": 8.632e-07,
      "logits/chosen": -2.6785569190979004,
      "logits/rejected": -2.2672359943389893,
      "logps/chosen": -143.765380859375,
      "logps/rejected": -72.31327819824219,
      "loss": 0.1203,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1272170543670654,
      "rewards/margins": 2.2566192150115967,
      "rewards/rejected": -1.1294021606445312,
      "step": 1027
    },
    {
      "epoch": 0.4112,
      "grad_norm": 5.136465549468994,
      "learning_rate": 8.630666666666666e-07,
      "logits/chosen": -2.697178840637207,
      "logits/rejected": -2.2066690921783447,
      "logps/chosen": -68.1240234375,
      "logps/rejected": -61.97216033935547,
      "loss": 0.2437,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8468360304832458,
      "rewards/margins": 1.7356438636779785,
      "rewards/rejected": -0.8888077735900879,
      "step": 1028
    },
    {
      "epoch": 0.4116,
      "grad_norm": 4.207601070404053,
      "learning_rate": 8.629333333333333e-07,
      "logits/chosen": -2.794699192047119,
      "logits/rejected": -2.6576948165893555,
      "logps/chosen": -73.62355041503906,
      "logps/rejected": -114.9322738647461,
      "loss": 0.1097,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2660725116729736,
      "rewards/margins": 2.2454655170440674,
      "rewards/rejected": -0.9793930053710938,
      "step": 1029
    },
    {
      "epoch": 0.412,
      "grad_norm": 4.039687633514404,
      "learning_rate": 8.628e-07,
      "logits/chosen": -2.636627197265625,
      "logits/rejected": -2.0680112838745117,
      "logps/chosen": -100.10145568847656,
      "logps/rejected": -57.67479705810547,
      "loss": 0.1172,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0640206336975098,
      "rewards/margins": 2.097362518310547,
      "rewards/rejected": -1.0333420038223267,
      "step": 1030
    },
    {
      "epoch": 0.4124,
      "grad_norm": 5.989223957061768,
      "learning_rate": 8.626666666666666e-07,
      "logits/chosen": -2.7882494926452637,
      "logits/rejected": -2.525698184967041,
      "logps/chosen": -65.0123291015625,
      "logps/rejected": -54.39151382446289,
      "loss": 0.1662,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8538566827774048,
      "rewards/margins": 1.7545143365859985,
      "rewards/rejected": -0.9006576538085938,
      "step": 1031
    },
    {
      "epoch": 0.4128,
      "grad_norm": 6.789302825927734,
      "learning_rate": 8.625333333333333e-07,
      "logits/chosen": -2.9722847938537598,
      "logits/rejected": -2.5872464179992676,
      "logps/chosen": -51.15462112426758,
      "logps/rejected": -62.56228256225586,
      "loss": 0.256,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4009096026420593,
      "rewards/margins": 1.313123106956482,
      "rewards/rejected": -0.9122135043144226,
      "step": 1032
    },
    {
      "epoch": 0.4132,
      "grad_norm": 5.568002223968506,
      "learning_rate": 8.624e-07,
      "logits/chosen": -2.916311264038086,
      "logits/rejected": -2.4404025077819824,
      "logps/chosen": -82.32361602783203,
      "logps/rejected": -48.940433502197266,
      "loss": 0.1886,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9458290338516235,
      "rewards/margins": 1.5725773572921753,
      "rewards/rejected": -0.626748263835907,
      "step": 1033
    },
    {
      "epoch": 0.4136,
      "grad_norm": 6.296119689941406,
      "learning_rate": 8.622666666666666e-07,
      "logits/chosen": -2.674072265625,
      "logits/rejected": -2.4633822441101074,
      "logps/chosen": -126.81617736816406,
      "logps/rejected": -57.420082092285156,
      "loss": 0.1871,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7231723666191101,
      "rewards/margins": 1.5848519802093506,
      "rewards/rejected": -0.8616796731948853,
      "step": 1034
    },
    {
      "epoch": 0.414,
      "grad_norm": 5.2782487869262695,
      "learning_rate": 8.621333333333333e-07,
      "logits/chosen": -2.670565128326416,
      "logits/rejected": -2.548731803894043,
      "logps/chosen": -63.80998229980469,
      "logps/rejected": -54.275978088378906,
      "loss": 0.18,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9616819620132446,
      "rewards/margins": 1.726128339767456,
      "rewards/rejected": -0.7644462585449219,
      "step": 1035
    },
    {
      "epoch": 0.4144,
      "grad_norm": 5.9547247886657715,
      "learning_rate": 8.62e-07,
      "logits/chosen": -2.5529751777648926,
      "logits/rejected": -2.1292972564697266,
      "logps/chosen": -56.41530990600586,
      "logps/rejected": -97.58935546875,
      "loss": 0.1667,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1933128833770752,
      "rewards/margins": 2.1379120349884033,
      "rewards/rejected": -0.9445992112159729,
      "step": 1036
    },
    {
      "epoch": 0.4148,
      "grad_norm": 1.730185627937317,
      "learning_rate": 8.618666666666667e-07,
      "logits/chosen": -2.7311229705810547,
      "logits/rejected": -2.2831473350524902,
      "logps/chosen": -88.91551208496094,
      "logps/rejected": -68.29901885986328,
      "loss": 0.0378,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9358322620391846,
      "rewards/margins": 3.2568275928497314,
      "rewards/rejected": -1.3209953308105469,
      "step": 1037
    },
    {
      "epoch": 0.4152,
      "grad_norm": 5.040512561798096,
      "learning_rate": 8.617333333333333e-07,
      "logits/chosen": -2.8328752517700195,
      "logits/rejected": -2.3482136726379395,
      "logps/chosen": -139.59255981445312,
      "logps/rejected": -95.48395538330078,
      "loss": 0.1043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4482688903808594,
      "rewards/margins": 2.218282699584961,
      "rewards/rejected": -1.7700138092041016,
      "step": 1038
    },
    {
      "epoch": 0.4156,
      "grad_norm": 6.506497383117676,
      "learning_rate": 8.616e-07,
      "logits/chosen": -2.749157428741455,
      "logits/rejected": -2.764082193374634,
      "logps/chosen": -113.90814208984375,
      "logps/rejected": -63.88361358642578,
      "loss": 0.1828,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0488742589950562,
      "rewards/margins": 1.6618785858154297,
      "rewards/rejected": -0.6130043268203735,
      "step": 1039
    },
    {
      "epoch": 0.416,
      "grad_norm": 6.006869316101074,
      "learning_rate": 8.614666666666666e-07,
      "logits/chosen": -2.9159374237060547,
      "logits/rejected": -2.51979923248291,
      "logps/chosen": -41.12589645385742,
      "logps/rejected": -53.92002868652344,
      "loss": 0.2319,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5446632504463196,
      "rewards/margins": 1.3650462627410889,
      "rewards/rejected": -0.8203830718994141,
      "step": 1040
    },
    {
      "epoch": 0.4164,
      "grad_norm": 6.153031349182129,
      "learning_rate": 8.613333333333332e-07,
      "logits/chosen": -2.6096529960632324,
      "logits/rejected": -2.2926578521728516,
      "logps/chosen": -102.31124114990234,
      "logps/rejected": -61.242332458496094,
      "loss": 0.1632,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.849151611328125,
      "rewards/margins": 1.7565041780471802,
      "rewards/rejected": -0.9073524475097656,
      "step": 1041
    },
    {
      "epoch": 0.4168,
      "grad_norm": 6.385153293609619,
      "learning_rate": 8.611999999999999e-07,
      "logits/chosen": -2.1856236457824707,
      "logits/rejected": -2.129626750946045,
      "logps/chosen": -190.23275756835938,
      "logps/rejected": -205.46849060058594,
      "loss": 0.0891,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3720276355743408,
      "rewards/margins": 2.4283032417297363,
      "rewards/rejected": -1.0562756061553955,
      "step": 1042
    },
    {
      "epoch": 0.4172,
      "grad_norm": 4.1182451248168945,
      "learning_rate": 8.610666666666666e-07,
      "logits/chosen": -2.9488887786865234,
      "logits/rejected": -2.827792167663574,
      "logps/chosen": -106.00802612304688,
      "logps/rejected": -51.94540786743164,
      "loss": 0.1261,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7151750922203064,
      "rewards/margins": 2.03763484954834,
      "rewards/rejected": -1.3224598169326782,
      "step": 1043
    },
    {
      "epoch": 0.4176,
      "grad_norm": 5.328967094421387,
      "learning_rate": 8.609333333333333e-07,
      "logits/chosen": -2.859661102294922,
      "logits/rejected": -2.36234188079834,
      "logps/chosen": -60.80620574951172,
      "logps/rejected": -54.374290466308594,
      "loss": 0.1952,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8600322008132935,
      "rewards/margins": 1.676530361175537,
      "rewards/rejected": -0.8164982199668884,
      "step": 1044
    },
    {
      "epoch": 0.418,
      "grad_norm": 2.612529754638672,
      "learning_rate": 8.608e-07,
      "logits/chosen": -2.5700106620788574,
      "logits/rejected": -2.191899538040161,
      "logps/chosen": -74.00921630859375,
      "logps/rejected": -77.47911834716797,
      "loss": 0.0689,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.268008828163147,
      "rewards/margins": 2.677967071533203,
      "rewards/rejected": -1.4099581241607666,
      "step": 1045
    },
    {
      "epoch": 0.4184,
      "grad_norm": 4.584943771362305,
      "learning_rate": 8.606666666666667e-07,
      "logits/chosen": -2.2666878700256348,
      "logits/rejected": -1.8387424945831299,
      "logps/chosen": -138.43377685546875,
      "logps/rejected": -53.93299102783203,
      "loss": 0.0863,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.875131368637085,
      "rewards/margins": 2.5876734256744385,
      "rewards/rejected": -0.7125419974327087,
      "step": 1046
    },
    {
      "epoch": 0.4188,
      "grad_norm": 2.6055126190185547,
      "learning_rate": 8.605333333333334e-07,
      "logits/chosen": -2.696885108947754,
      "logits/rejected": -2.187380790710449,
      "logps/chosen": -63.34038162231445,
      "logps/rejected": -123.79025268554688,
      "loss": 0.0521,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2057983875274658,
      "rewards/margins": 2.9833030700683594,
      "rewards/rejected": -1.777504801750183,
      "step": 1047
    },
    {
      "epoch": 0.4192,
      "grad_norm": 4.859528064727783,
      "learning_rate": 8.604000000000001e-07,
      "logits/chosen": -2.526299238204956,
      "logits/rejected": -2.1808650493621826,
      "logps/chosen": -74.38324737548828,
      "logps/rejected": -89.66060638427734,
      "loss": 0.136,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9597177505493164,
      "rewards/margins": 1.9413232803344727,
      "rewards/rejected": -0.9816055297851562,
      "step": 1048
    },
    {
      "epoch": 0.4196,
      "grad_norm": 10.782916069030762,
      "learning_rate": 8.602666666666665e-07,
      "logits/chosen": -2.708134889602661,
      "logits/rejected": -2.4634315967559814,
      "logps/chosen": -91.7720947265625,
      "logps/rejected": -63.43577194213867,
      "loss": 0.2319,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5409290790557861,
      "rewards/margins": 1.6952157020568848,
      "rewards/rejected": -1.1542866230010986,
      "step": 1049
    },
    {
      "epoch": 0.42,
      "grad_norm": 6.163350582122803,
      "learning_rate": 8.601333333333332e-07,
      "logits/chosen": -3.0479462146759033,
      "logits/rejected": -3.048952102661133,
      "logps/chosen": -25.89562225341797,
      "logps/rejected": -58.19200134277344,
      "loss": 0.2674,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4330906867980957,
      "rewards/margins": 1.4161887168884277,
      "rewards/rejected": -0.9830980896949768,
      "step": 1050
    },
    {
      "epoch": 0.4204,
      "grad_norm": 4.331696510314941,
      "learning_rate": 8.599999999999999e-07,
      "logits/chosen": -2.70375919342041,
      "logits/rejected": -2.2345080375671387,
      "logps/chosen": -67.59674072265625,
      "logps/rejected": -70.04458618164062,
      "loss": 0.1201,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1210520267486572,
      "rewards/margins": 2.1092238426208496,
      "rewards/rejected": -0.9881718158721924,
      "step": 1051
    },
    {
      "epoch": 0.4208,
      "grad_norm": 4.86457633972168,
      "learning_rate": 8.598666666666666e-07,
      "logits/chosen": -2.693392276763916,
      "logits/rejected": -2.511967897415161,
      "logps/chosen": -69.8205337524414,
      "logps/rejected": -57.620243072509766,
      "loss": 0.1578,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9374153017997742,
      "rewards/margins": 1.8817412853240967,
      "rewards/rejected": -0.9443260431289673,
      "step": 1052
    },
    {
      "epoch": 0.4212,
      "grad_norm": 2.320164442062378,
      "learning_rate": 8.597333333333333e-07,
      "logits/chosen": -2.7847232818603516,
      "logits/rejected": -2.319218397140503,
      "logps/chosen": -68.9250259399414,
      "logps/rejected": -61.379173278808594,
      "loss": 0.0635,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.106014609336853,
      "rewards/margins": 2.728766918182373,
      "rewards/rejected": -1.6227521896362305,
      "step": 1053
    },
    {
      "epoch": 0.4216,
      "grad_norm": 4.319024085998535,
      "learning_rate": 8.596e-07,
      "logits/chosen": -2.677165985107422,
      "logits/rejected": -2.2784347534179688,
      "logps/chosen": -93.91112518310547,
      "logps/rejected": -74.46620178222656,
      "loss": 0.1075,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8508694171905518,
      "rewards/margins": 2.2563698291778564,
      "rewards/rejected": -1.4055004119873047,
      "step": 1054
    },
    {
      "epoch": 0.422,
      "grad_norm": 5.984969615936279,
      "learning_rate": 8.594666666666667e-07,
      "logits/chosen": -3.0549569129943848,
      "logits/rejected": -2.7019271850585938,
      "logps/chosen": -44.58810043334961,
      "logps/rejected": -53.14710235595703,
      "loss": 0.2401,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6777462959289551,
      "rewards/margins": 1.311553955078125,
      "rewards/rejected": -0.6338075399398804,
      "step": 1055
    },
    {
      "epoch": 0.4224,
      "grad_norm": 7.027063846588135,
      "learning_rate": 8.593333333333333e-07,
      "logits/chosen": -2.751838445663452,
      "logits/rejected": -2.509702205657959,
      "logps/chosen": -48.31641387939453,
      "logps/rejected": -72.98036193847656,
      "loss": 0.1686,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8008478283882141,
      "rewards/margins": 1.6948423385620117,
      "rewards/rejected": -0.8939945101737976,
      "step": 1056
    },
    {
      "epoch": 0.4228,
      "grad_norm": 6.676568984985352,
      "learning_rate": 8.592e-07,
      "logits/chosen": -2.761911392211914,
      "logits/rejected": -2.3265514373779297,
      "logps/chosen": -114.60845947265625,
      "logps/rejected": -95.7547607421875,
      "loss": 0.1679,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6765491962432861,
      "rewards/margins": 1.7218971252441406,
      "rewards/rejected": -1.0453479290008545,
      "step": 1057
    },
    {
      "epoch": 0.4232,
      "grad_norm": 6.7162089347839355,
      "learning_rate": 8.590666666666667e-07,
      "logits/chosen": -2.678971290588379,
      "logits/rejected": -2.521533250808716,
      "logps/chosen": -85.21633911132812,
      "logps/rejected": -75.61515808105469,
      "loss": 0.2016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.660317063331604,
      "rewards/margins": 1.5466587543487549,
      "rewards/rejected": -0.8863416910171509,
      "step": 1058
    },
    {
      "epoch": 0.4236,
      "grad_norm": 5.048719882965088,
      "learning_rate": 8.589333333333332e-07,
      "logits/chosen": -2.567628860473633,
      "logits/rejected": -2.502671480178833,
      "logps/chosen": -92.38432312011719,
      "logps/rejected": -70.07472229003906,
      "loss": 0.1746,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1954593658447266,
      "rewards/margins": 1.9326081275939941,
      "rewards/rejected": -0.7371487021446228,
      "step": 1059
    },
    {
      "epoch": 0.424,
      "grad_norm": 4.622991561889648,
      "learning_rate": 8.587999999999999e-07,
      "logits/chosen": -2.8983564376831055,
      "logits/rejected": -2.187868118286133,
      "logps/chosen": -120.22177124023438,
      "logps/rejected": -62.96202850341797,
      "loss": 0.1161,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9123653173446655,
      "rewards/margins": 2.12337064743042,
      "rewards/rejected": -1.2110052108764648,
      "step": 1060
    },
    {
      "epoch": 0.4244,
      "grad_norm": 5.00534725189209,
      "learning_rate": 8.586666666666666e-07,
      "logits/chosen": -3.003992795944214,
      "logits/rejected": -2.4799203872680664,
      "logps/chosen": -66.31123352050781,
      "logps/rejected": -64.37036895751953,
      "loss": 0.1624,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6119991540908813,
      "rewards/margins": 1.8245397806167603,
      "rewards/rejected": -1.212540626525879,
      "step": 1061
    },
    {
      "epoch": 0.4248,
      "grad_norm": 9.565311431884766,
      "learning_rate": 8.585333333333333e-07,
      "logits/chosen": -2.952517509460449,
      "logits/rejected": -2.443608283996582,
      "logps/chosen": -76.02772521972656,
      "logps/rejected": -73.37245178222656,
      "loss": 0.2926,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3195075988769531,
      "rewards/margins": 1.4314208030700684,
      "rewards/rejected": -1.1119133234024048,
      "step": 1062
    },
    {
      "epoch": 0.4252,
      "grad_norm": 7.103618144989014,
      "learning_rate": 8.584e-07,
      "logits/chosen": -2.655306577682495,
      "logits/rejected": -2.4578840732574463,
      "logps/chosen": -90.3035659790039,
      "logps/rejected": -54.1217041015625,
      "loss": 0.1947,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0792484283447266,
      "rewards/margins": 1.7335031032562256,
      "rewards/rejected": -0.6542545557022095,
      "step": 1063
    },
    {
      "epoch": 0.4256,
      "grad_norm": 3.05299711227417,
      "learning_rate": 8.582666666666666e-07,
      "logits/chosen": -2.5892486572265625,
      "logits/rejected": -2.0768637657165527,
      "logps/chosen": -66.350830078125,
      "logps/rejected": -98.6929702758789,
      "loss": 0.0721,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.315847396850586,
      "rewards/margins": 2.6190128326416016,
      "rewards/rejected": -1.303165316581726,
      "step": 1064
    },
    {
      "epoch": 0.426,
      "grad_norm": 1.5459535121917725,
      "learning_rate": 8.581333333333333e-07,
      "logits/chosen": -2.457066774368286,
      "logits/rejected": -1.9442421197891235,
      "logps/chosen": -184.96612548828125,
      "logps/rejected": -97.35140228271484,
      "loss": 0.0298,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.370318651199341,
      "rewards/margins": 3.5079665184020996,
      "rewards/rejected": -1.1376479864120483,
      "step": 1065
    },
    {
      "epoch": 0.4264,
      "grad_norm": 7.122569561004639,
      "learning_rate": 8.58e-07,
      "logits/chosen": -2.7767677307128906,
      "logits/rejected": -2.483654022216797,
      "logps/chosen": -105.42457580566406,
      "logps/rejected": -55.42232894897461,
      "loss": 0.2673,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20824165642261505,
      "rewards/margins": 1.2813620567321777,
      "rewards/rejected": -1.073120355606079,
      "step": 1066
    },
    {
      "epoch": 0.4268,
      "grad_norm": 5.294683456420898,
      "learning_rate": 8.578666666666667e-07,
      "logits/chosen": -2.6681299209594727,
      "logits/rejected": -2.141409158706665,
      "logps/chosen": -76.35153198242188,
      "logps/rejected": -96.00978088378906,
      "loss": 0.1098,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7506707906723022,
      "rewards/margins": 2.154728412628174,
      "rewards/rejected": -1.4040577411651611,
      "step": 1067
    },
    {
      "epoch": 0.4272,
      "grad_norm": 3.2742714881896973,
      "learning_rate": 8.577333333333333e-07,
      "logits/chosen": -2.9178524017333984,
      "logits/rejected": -2.5108096599578857,
      "logps/chosen": -67.72706604003906,
      "logps/rejected": -72.01285552978516,
      "loss": 0.0895,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.948359489440918,
      "rewards/margins": 2.3683290481567383,
      "rewards/rejected": -1.4199695587158203,
      "step": 1068
    },
    {
      "epoch": 0.4276,
      "grad_norm": 5.739933967590332,
      "learning_rate": 8.576e-07,
      "logits/chosen": -2.8494248390197754,
      "logits/rejected": -2.3055436611175537,
      "logps/chosen": -58.862937927246094,
      "logps/rejected": -65.44277954101562,
      "loss": 0.1684,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5619783401489258,
      "rewards/margins": 1.9411664009094238,
      "rewards/rejected": -1.3791881799697876,
      "step": 1069
    },
    {
      "epoch": 0.428,
      "grad_norm": 3.160222291946411,
      "learning_rate": 8.574666666666666e-07,
      "logits/chosen": -2.328343391418457,
      "logits/rejected": -2.194230318069458,
      "logps/chosen": -138.43426513671875,
      "logps/rejected": -88.08955383300781,
      "loss": 0.0656,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0078861713409424,
      "rewards/margins": 3.322465181350708,
      "rewards/rejected": -1.3145790100097656,
      "step": 1070
    },
    {
      "epoch": 0.4284,
      "grad_norm": 6.49201774597168,
      "learning_rate": 8.573333333333332e-07,
      "logits/chosen": -3.2122349739074707,
      "logits/rejected": -2.584608554840088,
      "logps/chosen": -61.398902893066406,
      "logps/rejected": -47.9580078125,
      "loss": 0.191,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7626296877861023,
      "rewards/margins": 1.5855735540390015,
      "rewards/rejected": -0.822943925857544,
      "step": 1071
    },
    {
      "epoch": 0.4288,
      "grad_norm": 5.849695682525635,
      "learning_rate": 8.571999999999999e-07,
      "logits/chosen": -2.486509323120117,
      "logits/rejected": -2.1352202892303467,
      "logps/chosen": -64.09898376464844,
      "logps/rejected": -67.43901062011719,
      "loss": 0.1451,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9609371423721313,
      "rewards/margins": 1.871567964553833,
      "rewards/rejected": -0.9106308221817017,
      "step": 1072
    },
    {
      "epoch": 0.4292,
      "grad_norm": 2.7740442752838135,
      "learning_rate": 8.570666666666666e-07,
      "logits/chosen": -2.4496355056762695,
      "logits/rejected": -1.9207998514175415,
      "logps/chosen": -147.99185180664062,
      "logps/rejected": -67.73019409179688,
      "loss": 0.061,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.654242753982544,
      "rewards/margins": 2.791980266571045,
      "rewards/rejected": -1.1377376317977905,
      "step": 1073
    },
    {
      "epoch": 0.4296,
      "grad_norm": 4.981552600860596,
      "learning_rate": 8.569333333333333e-07,
      "logits/chosen": -2.8127360343933105,
      "logits/rejected": -2.1402149200439453,
      "logps/chosen": -91.39994812011719,
      "logps/rejected": -104.09300231933594,
      "loss": 0.1303,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2012230157852173,
      "rewards/margins": 2.17087984085083,
      "rewards/rejected": -0.969656765460968,
      "step": 1074
    },
    {
      "epoch": 0.43,
      "grad_norm": 7.076417922973633,
      "learning_rate": 8.568e-07,
      "logits/chosen": -2.9699313640594482,
      "logits/rejected": -2.842879295349121,
      "logps/chosen": -81.36043548583984,
      "logps/rejected": -27.102731704711914,
      "loss": 0.2257,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.455897569656372,
      "rewards/margins": 1.6071574687957764,
      "rewards/rejected": -0.15126000344753265,
      "step": 1075
    },
    {
      "epoch": 0.4304,
      "grad_norm": 11.920120239257812,
      "learning_rate": 8.566666666666667e-07,
      "logits/chosen": -2.7304134368896484,
      "logits/rejected": -3.2871711254119873,
      "logps/chosen": -101.25251770019531,
      "logps/rejected": -85.44318389892578,
      "loss": 0.2485,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3510403037071228,
      "rewards/margins": 1.6467654705047607,
      "rewards/rejected": -1.2957252264022827,
      "step": 1076
    },
    {
      "epoch": 0.4308,
      "grad_norm": 3.311032772064209,
      "learning_rate": 8.565333333333334e-07,
      "logits/chosen": -2.523947238922119,
      "logits/rejected": -2.025218963623047,
      "logps/chosen": -143.12744140625,
      "logps/rejected": -90.01385498046875,
      "loss": 0.0734,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6538124084472656,
      "rewards/margins": 2.803317070007324,
      "rewards/rejected": -1.1495044231414795,
      "step": 1077
    },
    {
      "epoch": 0.4312,
      "grad_norm": 6.713950157165527,
      "learning_rate": 8.564e-07,
      "logits/chosen": -2.8014912605285645,
      "logits/rejected": -2.509845733642578,
      "logps/chosen": -53.84138488769531,
      "logps/rejected": -100.82467651367188,
      "loss": 0.1764,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2249174118041992,
      "rewards/margins": 2.0971548557281494,
      "rewards/rejected": -0.8722374439239502,
      "step": 1078
    },
    {
      "epoch": 0.4316,
      "grad_norm": 8.017008781433105,
      "learning_rate": 8.562666666666666e-07,
      "logits/chosen": -2.595093250274658,
      "logits/rejected": -1.9787909984588623,
      "logps/chosen": -118.50572204589844,
      "logps/rejected": -77.66354370117188,
      "loss": 0.2535,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1134915351867676,
      "rewards/margins": 1.7120110988616943,
      "rewards/rejected": -0.5985195636749268,
      "step": 1079
    },
    {
      "epoch": 0.432,
      "grad_norm": 4.530889987945557,
      "learning_rate": 8.561333333333332e-07,
      "logits/chosen": -2.893500328063965,
      "logits/rejected": -2.475261926651001,
      "logps/chosen": -73.53307342529297,
      "logps/rejected": -50.445068359375,
      "loss": 0.1464,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45082181692123413,
      "rewards/margins": 1.9937183856964111,
      "rewards/rejected": -1.5428966283798218,
      "step": 1080
    },
    {
      "epoch": 0.4324,
      "grad_norm": 4.364170551300049,
      "learning_rate": 8.559999999999999e-07,
      "logits/chosen": -2.888530731201172,
      "logits/rejected": -2.525303840637207,
      "logps/chosen": -78.02762603759766,
      "logps/rejected": -50.79780960083008,
      "loss": 0.1233,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1689916849136353,
      "rewards/margins": 2.0332274436950684,
      "rewards/rejected": -0.8642356991767883,
      "step": 1081
    },
    {
      "epoch": 0.4328,
      "grad_norm": 3.8647942543029785,
      "learning_rate": 8.558666666666666e-07,
      "logits/chosen": -2.575650453567505,
      "logits/rejected": -2.0879809856414795,
      "logps/chosen": -63.401180267333984,
      "logps/rejected": -81.8353042602539,
      "loss": 0.0847,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9468754529953003,
      "rewards/margins": 2.5314180850982666,
      "rewards/rejected": -1.5845426321029663,
      "step": 1082
    },
    {
      "epoch": 0.4332,
      "grad_norm": 6.180243015289307,
      "learning_rate": 8.557333333333333e-07,
      "logits/chosen": -2.950896739959717,
      "logits/rejected": -2.3993747234344482,
      "logps/chosen": -66.70126342773438,
      "logps/rejected": -60.39609146118164,
      "loss": 0.1397,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6584892272949219,
      "rewards/margins": 1.99296236038208,
      "rewards/rejected": -1.3344731330871582,
      "step": 1083
    },
    {
      "epoch": 0.4336,
      "grad_norm": 2.4060709476470947,
      "learning_rate": 8.556e-07,
      "logits/chosen": -2.3608458042144775,
      "logits/rejected": -1.8821508884429932,
      "logps/chosen": -132.96038818359375,
      "logps/rejected": -77.60594177246094,
      "loss": 0.0516,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.660942792892456,
      "rewards/margins": 2.954723596572876,
      "rewards/rejected": -1.29378080368042,
      "step": 1084
    },
    {
      "epoch": 0.434,
      "grad_norm": 5.033281326293945,
      "learning_rate": 8.554666666666667e-07,
      "logits/chosen": -2.943021774291992,
      "logits/rejected": -2.432373523712158,
      "logps/chosen": -31.583969116210938,
      "logps/rejected": -91.8039321899414,
      "loss": 0.1666,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.48114871978759766,
      "rewards/margins": 1.8303861618041992,
      "rewards/rejected": -1.3492374420166016,
      "step": 1085
    },
    {
      "epoch": 0.4344,
      "grad_norm": 3.461397886276245,
      "learning_rate": 8.553333333333333e-07,
      "logits/chosen": -2.581547737121582,
      "logits/rejected": -1.8680949211120605,
      "logps/chosen": -79.97361755371094,
      "logps/rejected": -94.20497131347656,
      "loss": 0.0782,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6416584253311157,
      "rewards/margins": 2.5165023803710938,
      "rewards/rejected": -0.874843955039978,
      "step": 1086
    },
    {
      "epoch": 0.4348,
      "grad_norm": 3.0554752349853516,
      "learning_rate": 8.551999999999999e-07,
      "logits/chosen": -2.715200424194336,
      "logits/rejected": -2.5643491744995117,
      "logps/chosen": -77.55366516113281,
      "logps/rejected": -62.35806655883789,
      "loss": 0.0935,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7871639728546143,
      "rewards/margins": 2.579749345779419,
      "rewards/rejected": -0.7925853729248047,
      "step": 1087
    },
    {
      "epoch": 0.4352,
      "grad_norm": 6.579430103302002,
      "learning_rate": 8.550666666666666e-07,
      "logits/chosen": -2.725409507751465,
      "logits/rejected": -2.584080696105957,
      "logps/chosen": -93.50862121582031,
      "logps/rejected": -40.52714157104492,
      "loss": 0.2062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6997653841972351,
      "rewards/margins": 1.4879326820373535,
      "rewards/rejected": -0.7881672978401184,
      "step": 1088
    },
    {
      "epoch": 0.4356,
      "grad_norm": 9.25210189819336,
      "learning_rate": 8.549333333333333e-07,
      "logits/chosen": -2.5515336990356445,
      "logits/rejected": -2.4377822875976562,
      "logps/chosen": -85.3912353515625,
      "logps/rejected": -55.420440673828125,
      "loss": 0.308,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4181537926197052,
      "rewards/margins": 1.3351726531982422,
      "rewards/rejected": -0.9170189499855042,
      "step": 1089
    },
    {
      "epoch": 0.436,
      "grad_norm": 5.622596740722656,
      "learning_rate": 8.548e-07,
      "logits/chosen": -2.706732749938965,
      "logits/rejected": -2.869534492492676,
      "logps/chosen": -141.9071044921875,
      "logps/rejected": -57.01570129394531,
      "loss": 0.1231,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9234939813613892,
      "rewards/margins": 2.068707227706909,
      "rewards/rejected": -1.1452131271362305,
      "step": 1090
    },
    {
      "epoch": 0.4364,
      "grad_norm": 4.3941168785095215,
      "learning_rate": 8.546666666666666e-07,
      "logits/chosen": -2.8768413066864014,
      "logits/rejected": -2.251400947570801,
      "logps/chosen": -85.38764953613281,
      "logps/rejected": -65.07440948486328,
      "loss": 0.1255,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6575218439102173,
      "rewards/margins": 2.0653574466705322,
      "rewards/rejected": -1.407835602760315,
      "step": 1091
    },
    {
      "epoch": 0.4368,
      "grad_norm": 1.8594411611557007,
      "learning_rate": 8.545333333333333e-07,
      "logits/chosen": -2.7378756999969482,
      "logits/rejected": -2.191288948059082,
      "logps/chosen": -101.36732482910156,
      "logps/rejected": -103.50582885742188,
      "loss": 0.0387,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6695305109024048,
      "rewards/margins": 3.2684168815612793,
      "rewards/rejected": -1.598886489868164,
      "step": 1092
    },
    {
      "epoch": 0.4372,
      "grad_norm": 5.7710795402526855,
      "learning_rate": 8.544e-07,
      "logits/chosen": -2.27278470993042,
      "logits/rejected": -1.8459415435791016,
      "logps/chosen": -173.7492218017578,
      "logps/rejected": -66.10670471191406,
      "loss": 0.1652,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7570274472236633,
      "rewards/margins": 1.7807071208953857,
      "rewards/rejected": -1.0236797332763672,
      "step": 1093
    },
    {
      "epoch": 0.4376,
      "grad_norm": 4.086742401123047,
      "learning_rate": 8.542666666666666e-07,
      "logits/chosen": -2.8942465782165527,
      "logits/rejected": -2.486787796020508,
      "logps/chosen": -79.4337158203125,
      "logps/rejected": -58.56737518310547,
      "loss": 0.113,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.400722861289978,
      "rewards/margins": 2.4161953926086426,
      "rewards/rejected": -1.015472650527954,
      "step": 1094
    },
    {
      "epoch": 0.438,
      "grad_norm": 3.6835241317749023,
      "learning_rate": 8.541333333333333e-07,
      "logits/chosen": -2.5563559532165527,
      "logits/rejected": -2.0942578315734863,
      "logps/chosen": -70.36244201660156,
      "logps/rejected": -64.35164642333984,
      "loss": 0.0983,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.352299451828003,
      "rewards/margins": 2.274986743927002,
      "rewards/rejected": -0.9226871728897095,
      "step": 1095
    },
    {
      "epoch": 0.4384,
      "grad_norm": 2.60286283493042,
      "learning_rate": 8.539999999999999e-07,
      "logits/chosen": -2.530088424682617,
      "logits/rejected": -2.033620834350586,
      "logps/chosen": -127.94195556640625,
      "logps/rejected": -139.46835327148438,
      "loss": 0.0509,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7644932270050049,
      "rewards/margins": 2.9938502311706543,
      "rewards/rejected": -1.2293572425842285,
      "step": 1096
    },
    {
      "epoch": 0.4388,
      "grad_norm": 2.649449348449707,
      "learning_rate": 8.538666666666666e-07,
      "logits/chosen": -2.8666152954101562,
      "logits/rejected": -2.464664936065674,
      "logps/chosen": -60.59849166870117,
      "logps/rejected": -76.23135375976562,
      "loss": 0.0634,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3800819516181946,
      "rewards/margins": 2.796579360961914,
      "rewards/rejected": -2.416497230529785,
      "step": 1097
    },
    {
      "epoch": 0.4392,
      "grad_norm": 5.414391040802002,
      "learning_rate": 8.537333333333333e-07,
      "logits/chosen": -2.914912223815918,
      "logits/rejected": -2.528602123260498,
      "logps/chosen": -102.72914123535156,
      "logps/rejected": -57.60651397705078,
      "loss": 0.1441,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8684948086738586,
      "rewards/margins": 1.9359015226364136,
      "rewards/rejected": -1.0674066543579102,
      "step": 1098
    },
    {
      "epoch": 0.4396,
      "grad_norm": 5.67188835144043,
      "learning_rate": 8.536e-07,
      "logits/chosen": -2.9217369556427,
      "logits/rejected": -2.5630733966827393,
      "logps/chosen": -92.31692504882812,
      "logps/rejected": -59.7746467590332,
      "loss": 0.1614,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5660703778266907,
      "rewards/margins": 1.7467679977416992,
      "rewards/rejected": -1.1806976795196533,
      "step": 1099
    },
    {
      "epoch": 0.44,
      "grad_norm": 6.887584686279297,
      "learning_rate": 8.534666666666667e-07,
      "logits/chosen": -2.9003944396972656,
      "logits/rejected": -2.80771541595459,
      "logps/chosen": -66.86489868164062,
      "logps/rejected": -53.20587158203125,
      "loss": 0.2779,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5843402743339539,
      "rewards/margins": 1.7350373268127441,
      "rewards/rejected": -1.1506969928741455,
      "step": 1100
    },
    {
      "epoch": 0.4404,
      "grad_norm": 3.7617814540863037,
      "learning_rate": 8.533333333333334e-07,
      "logits/chosen": -2.6922812461853027,
      "logits/rejected": -2.013376235961914,
      "logps/chosen": -68.38602447509766,
      "logps/rejected": -81.28856658935547,
      "loss": 0.104,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3490959405899048,
      "rewards/margins": 2.3600430488586426,
      "rewards/rejected": -1.0109469890594482,
      "step": 1101
    },
    {
      "epoch": 0.4408,
      "grad_norm": 5.7168378829956055,
      "learning_rate": 8.531999999999999e-07,
      "logits/chosen": -2.6479458808898926,
      "logits/rejected": -2.339791774749756,
      "logps/chosen": -80.27256774902344,
      "logps/rejected": -90.97846984863281,
      "loss": 0.1543,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.789333164691925,
      "rewards/margins": 2.069810152053833,
      "rewards/rejected": -1.2804769277572632,
      "step": 1102
    },
    {
      "epoch": 0.4412,
      "grad_norm": 6.2031660079956055,
      "learning_rate": 8.530666666666666e-07,
      "logits/chosen": -2.602639675140381,
      "logits/rejected": -2.1561784744262695,
      "logps/chosen": -145.88783264160156,
      "logps/rejected": -67.3995361328125,
      "loss": 0.1843,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8104496002197266,
      "rewards/margins": 1.6777582168579102,
      "rewards/rejected": -0.8673086166381836,
      "step": 1103
    },
    {
      "epoch": 0.4416,
      "grad_norm": 2.0966949462890625,
      "learning_rate": 8.529333333333333e-07,
      "logits/chosen": -2.813889265060425,
      "logits/rejected": -2.437398910522461,
      "logps/chosen": -109.55828094482422,
      "logps/rejected": -70.860595703125,
      "loss": 0.0402,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0627371072769165,
      "rewards/margins": 3.2208123207092285,
      "rewards/rejected": -2.1580753326416016,
      "step": 1104
    },
    {
      "epoch": 0.442,
      "grad_norm": 3.2843573093414307,
      "learning_rate": 8.528e-07,
      "logits/chosen": -2.5613327026367188,
      "logits/rejected": -1.9996967315673828,
      "logps/chosen": -67.41078186035156,
      "logps/rejected": -74.39653015136719,
      "loss": 0.1073,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4246256351470947,
      "rewards/margins": 2.2562007904052734,
      "rewards/rejected": -0.8315750360488892,
      "step": 1105
    },
    {
      "epoch": 0.4424,
      "grad_norm": 3.539764404296875,
      "learning_rate": 8.526666666666666e-07,
      "logits/chosen": -3.1473684310913086,
      "logits/rejected": -2.3518242835998535,
      "logps/chosen": -34.4267692565918,
      "logps/rejected": -74.7095947265625,
      "loss": 0.0877,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9313963055610657,
      "rewards/margins": 2.4075117111206055,
      "rewards/rejected": -1.4761154651641846,
      "step": 1106
    },
    {
      "epoch": 0.4428,
      "grad_norm": 3.9356305599212646,
      "learning_rate": 8.525333333333333e-07,
      "logits/chosen": -2.385244846343994,
      "logits/rejected": -2.0091097354888916,
      "logps/chosen": -148.38694763183594,
      "logps/rejected": -102.67941284179688,
      "loss": 0.091,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2273391485214233,
      "rewards/margins": 2.7322258949279785,
      "rewards/rejected": -1.5048866271972656,
      "step": 1107
    },
    {
      "epoch": 0.4432,
      "grad_norm": 4.4162702560424805,
      "learning_rate": 8.524e-07,
      "logits/chosen": -2.5085129737854004,
      "logits/rejected": -2.3867719173431396,
      "logps/chosen": -126.7100830078125,
      "logps/rejected": -59.36741638183594,
      "loss": 0.1232,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.686771035194397,
      "rewards/margins": 2.1644034385681152,
      "rewards/rejected": -0.4776325225830078,
      "step": 1108
    },
    {
      "epoch": 0.4436,
      "grad_norm": 5.402316093444824,
      "learning_rate": 8.522666666666666e-07,
      "logits/chosen": -2.801701068878174,
      "logits/rejected": -2.305774211883545,
      "logps/chosen": -90.46359252929688,
      "logps/rejected": -71.55796813964844,
      "loss": 0.1658,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.666307270526886,
      "rewards/margins": 1.713789939880371,
      "rewards/rejected": -1.0474827289581299,
      "step": 1109
    },
    {
      "epoch": 0.444,
      "grad_norm": 11.766378402709961,
      "learning_rate": 8.521333333333333e-07,
      "logits/chosen": -2.361959934234619,
      "logits/rejected": -2.3579165935516357,
      "logps/chosen": -188.36135864257812,
      "logps/rejected": -47.49762725830078,
      "loss": 0.1358,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2011628150939941,
      "rewards/margins": 2.1062612533569336,
      "rewards/rejected": -0.905098557472229,
      "step": 1110
    },
    {
      "epoch": 0.4444,
      "grad_norm": 3.194180488586426,
      "learning_rate": 8.52e-07,
      "logits/chosen": -2.2615418434143066,
      "logits/rejected": -1.821804165840149,
      "logps/chosen": -134.68251037597656,
      "logps/rejected": -112.39146423339844,
      "loss": 0.0661,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5052895545959473,
      "rewards/margins": 2.690796375274658,
      "rewards/rejected": -1.185506820678711,
      "step": 1111
    },
    {
      "epoch": 0.4448,
      "grad_norm": 3.7199690341949463,
      "learning_rate": 8.518666666666666e-07,
      "logits/chosen": -2.884549617767334,
      "logits/rejected": -2.232104778289795,
      "logps/chosen": -55.877159118652344,
      "logps/rejected": -70.96728515625,
      "loss": 0.0812,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9007009863853455,
      "rewards/margins": 2.482273578643799,
      "rewards/rejected": -1.5815725326538086,
      "step": 1112
    },
    {
      "epoch": 0.4452,
      "grad_norm": 4.719064712524414,
      "learning_rate": 8.517333333333333e-07,
      "logits/chosen": -2.545307159423828,
      "logits/rejected": -2.207418918609619,
      "logps/chosen": -115.88204956054688,
      "logps/rejected": -72.28621673583984,
      "loss": 0.1433,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2561657428741455,
      "rewards/margins": 2.046391010284424,
      "rewards/rejected": -0.7902252078056335,
      "step": 1113
    },
    {
      "epoch": 0.4456,
      "grad_norm": 3.449359655380249,
      "learning_rate": 8.516e-07,
      "logits/chosen": -2.5754029750823975,
      "logits/rejected": -2.093888759613037,
      "logps/chosen": -111.21582794189453,
      "logps/rejected": -119.92340087890625,
      "loss": 0.0829,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2086708545684814,
      "rewards/margins": 2.4494824409484863,
      "rewards/rejected": -1.2408115863800049,
      "step": 1114
    },
    {
      "epoch": 0.446,
      "grad_norm": 3.9693617820739746,
      "learning_rate": 8.514666666666666e-07,
      "logits/chosen": -3.0396409034729004,
      "logits/rejected": -2.790224552154541,
      "logps/chosen": -85.58816528320312,
      "logps/rejected": -35.363670349121094,
      "loss": 0.1181,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.609784722328186,
      "rewards/margins": 2.1915602684020996,
      "rewards/rejected": -0.5817754864692688,
      "step": 1115
    },
    {
      "epoch": 0.4464,
      "grad_norm": 2.435598611831665,
      "learning_rate": 8.513333333333333e-07,
      "logits/chosen": -2.3319122791290283,
      "logits/rejected": -1.875295639038086,
      "logps/chosen": -77.70521545410156,
      "logps/rejected": -124.53309631347656,
      "loss": 0.0529,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5734996795654297,
      "rewards/margins": 3.0737733840942383,
      "rewards/rejected": -1.5002734661102295,
      "step": 1116
    },
    {
      "epoch": 0.4468,
      "grad_norm": 5.247194290161133,
      "learning_rate": 8.511999999999999e-07,
      "logits/chosen": -2.958768129348755,
      "logits/rejected": -2.806598424911499,
      "logps/chosen": -45.52103042602539,
      "logps/rejected": -46.76521682739258,
      "loss": 0.1852,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4059638977050781,
      "rewards/margins": 1.769658088684082,
      "rewards/rejected": -1.3636940717697144,
      "step": 1117
    },
    {
      "epoch": 0.4472,
      "grad_norm": 4.141635417938232,
      "learning_rate": 8.510666666666666e-07,
      "logits/chosen": -2.547070026397705,
      "logits/rejected": -2.0486629009246826,
      "logps/chosen": -60.64593505859375,
      "logps/rejected": -68.15988159179688,
      "loss": 0.1441,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1790554523468018,
      "rewards/margins": 1.9185595512390137,
      "rewards/rejected": -0.7395042181015015,
      "step": 1118
    },
    {
      "epoch": 0.4476,
      "grad_norm": 2.4928715229034424,
      "learning_rate": 8.509333333333333e-07,
      "logits/chosen": -2.6429100036621094,
      "logits/rejected": -2.1449859142303467,
      "logps/chosen": -118.07205200195312,
      "logps/rejected": -92.3865737915039,
      "loss": 0.0427,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9169452786445618,
      "rewards/margins": 3.3534109592437744,
      "rewards/rejected": -2.4364657402038574,
      "step": 1119
    },
    {
      "epoch": 0.448,
      "grad_norm": 2.7422008514404297,
      "learning_rate": 8.508e-07,
      "logits/chosen": -2.404757499694824,
      "logits/rejected": -2.475832939147949,
      "logps/chosen": -100.19908905029297,
      "logps/rejected": -87.56864166259766,
      "loss": 0.0702,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5162816047668457,
      "rewards/margins": 2.635986804962158,
      "rewards/rejected": -1.1197052001953125,
      "step": 1120
    },
    {
      "epoch": 0.4484,
      "grad_norm": 6.152276039123535,
      "learning_rate": 8.506666666666667e-07,
      "logits/chosen": -2.8771510124206543,
      "logits/rejected": -2.718283176422119,
      "logps/chosen": -76.50048828125,
      "logps/rejected": -42.19874572753906,
      "loss": 0.2147,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6213194131851196,
      "rewards/margins": 1.4399487972259521,
      "rewards/rejected": -0.818629264831543,
      "step": 1121
    },
    {
      "epoch": 0.4488,
      "grad_norm": 2.589226007461548,
      "learning_rate": 8.505333333333334e-07,
      "logits/chosen": -2.615401029586792,
      "logits/rejected": -2.0846009254455566,
      "logps/chosen": -106.73289489746094,
      "logps/rejected": -63.382041931152344,
      "loss": 0.0646,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5460388660430908,
      "rewards/margins": 2.9262447357177734,
      "rewards/rejected": -1.380205750465393,
      "step": 1122
    },
    {
      "epoch": 0.4492,
      "grad_norm": 2.247802257537842,
      "learning_rate": 8.504e-07,
      "logits/chosen": -2.824782371520996,
      "logits/rejected": -2.2341666221618652,
      "logps/chosen": -69.56938934326172,
      "logps/rejected": -69.3385009765625,
      "loss": 0.0649,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1739659309387207,
      "rewards/margins": 3.109208345413208,
      "rewards/rejected": -0.9352422952651978,
      "step": 1123
    },
    {
      "epoch": 0.4496,
      "grad_norm": 3.835388660430908,
      "learning_rate": 8.502666666666665e-07,
      "logits/chosen": -2.6628077030181885,
      "logits/rejected": -2.764314651489258,
      "logps/chosen": -82.69413757324219,
      "logps/rejected": -64.00885009765625,
      "loss": 0.099,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6473434567451477,
      "rewards/margins": 2.2650346755981445,
      "rewards/rejected": -1.6176912784576416,
      "step": 1124
    },
    {
      "epoch": 0.45,
      "grad_norm": 7.683136940002441,
      "learning_rate": 8.501333333333332e-07,
      "logits/chosen": -2.7402141094207764,
      "logits/rejected": -2.265547513961792,
      "logps/chosen": -81.20469665527344,
      "logps/rejected": -58.22632598876953,
      "loss": 0.2843,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12407741695642471,
      "rewards/margins": 1.1532045602798462,
      "rewards/rejected": -1.0291271209716797,
      "step": 1125
    },
    {
      "epoch": 0.4504,
      "grad_norm": 6.412479877471924,
      "learning_rate": 8.499999999999999e-07,
      "logits/chosen": -2.744932174682617,
      "logits/rejected": -2.606224298477173,
      "logps/chosen": -139.1912078857422,
      "logps/rejected": -57.14762878417969,
      "loss": 0.1851,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6020111441612244,
      "rewards/margins": 1.908280849456787,
      "rewards/rejected": -1.306269645690918,
      "step": 1126
    },
    {
      "epoch": 0.4508,
      "grad_norm": 3.948357582092285,
      "learning_rate": 8.498666666666666e-07,
      "logits/chosen": -2.6107280254364014,
      "logits/rejected": -2.1797537803649902,
      "logps/chosen": -129.73204040527344,
      "logps/rejected": -72.31236267089844,
      "loss": 0.0901,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9183313846588135,
      "rewards/margins": 2.372304916381836,
      "rewards/rejected": -1.4539735317230225,
      "step": 1127
    },
    {
      "epoch": 0.4512,
      "grad_norm": 2.9456169605255127,
      "learning_rate": 8.497333333333333e-07,
      "logits/chosen": -2.69792103767395,
      "logits/rejected": -1.8101954460144043,
      "logps/chosen": -93.96560668945312,
      "logps/rejected": -89.91814422607422,
      "loss": 0.0514,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7492429614067078,
      "rewards/margins": 3.111603260040283,
      "rewards/rejected": -2.3623602390289307,
      "step": 1128
    },
    {
      "epoch": 0.4516,
      "grad_norm": 6.3246002197265625,
      "learning_rate": 8.496e-07,
      "logits/chosen": -2.2960352897644043,
      "logits/rejected": -2.2217471599578857,
      "logps/chosen": -61.47462844848633,
      "logps/rejected": -48.89216613769531,
      "loss": 0.2443,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.49130862951278687,
      "rewards/margins": 1.3326208591461182,
      "rewards/rejected": -0.8413122296333313,
      "step": 1129
    },
    {
      "epoch": 0.452,
      "grad_norm": 4.349446773529053,
      "learning_rate": 8.494666666666667e-07,
      "logits/chosen": -2.8387022018432617,
      "logits/rejected": -2.406803607940674,
      "logps/chosen": -53.49087142944336,
      "logps/rejected": -53.83287811279297,
      "loss": 0.1377,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0000873804092407,
      "rewards/margins": 1.9865580797195435,
      "rewards/rejected": -0.9864708185195923,
      "step": 1130
    },
    {
      "epoch": 0.4524,
      "grad_norm": 5.935053825378418,
      "learning_rate": 8.493333333333334e-07,
      "logits/chosen": -2.362851142883301,
      "logits/rejected": -1.6935677528381348,
      "logps/chosen": -88.51118469238281,
      "logps/rejected": -101.50607299804688,
      "loss": 0.1589,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8104736804962158,
      "rewards/margins": 1.7620662450790405,
      "rewards/rejected": -0.9515926241874695,
      "step": 1131
    },
    {
      "epoch": 0.4528,
      "grad_norm": 1.9679619073867798,
      "learning_rate": 8.492e-07,
      "logits/chosen": -2.5018253326416016,
      "logits/rejected": -2.1632049083709717,
      "logps/chosen": -116.31300354003906,
      "logps/rejected": -81.00786590576172,
      "loss": 0.0457,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9718372821807861,
      "rewards/margins": 3.0772783756256104,
      "rewards/rejected": -1.1054410934448242,
      "step": 1132
    },
    {
      "epoch": 0.4532,
      "grad_norm": 6.095795631408691,
      "learning_rate": 8.490666666666666e-07,
      "logits/chosen": -2.859684944152832,
      "logits/rejected": -2.6989240646362305,
      "logps/chosen": -88.58938598632812,
      "logps/rejected": -38.73707962036133,
      "loss": 0.2138,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8968216180801392,
      "rewards/margins": 1.4343602657318115,
      "rewards/rejected": -0.5375387072563171,
      "step": 1133
    },
    {
      "epoch": 0.4536,
      "grad_norm": 3.048905611038208,
      "learning_rate": 8.489333333333332e-07,
      "logits/chosen": -2.527700185775757,
      "logits/rejected": -2.374699354171753,
      "logps/chosen": -142.22756958007812,
      "logps/rejected": -68.03822326660156,
      "loss": 0.0634,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9928115606307983,
      "rewards/margins": 2.727091073989868,
      "rewards/rejected": -1.7342795133590698,
      "step": 1134
    },
    {
      "epoch": 0.454,
      "grad_norm": 1.7045023441314697,
      "learning_rate": 8.487999999999999e-07,
      "logits/chosen": -2.6135993003845215,
      "logits/rejected": -2.0410313606262207,
      "logps/chosen": -54.317962646484375,
      "logps/rejected": -59.45454406738281,
      "loss": 0.0383,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4266703128814697,
      "rewards/margins": 3.264659881591797,
      "rewards/rejected": -1.8379895687103271,
      "step": 1135
    },
    {
      "epoch": 0.4544,
      "grad_norm": 3.182887554168701,
      "learning_rate": 8.486666666666666e-07,
      "logits/chosen": -2.5139851570129395,
      "logits/rejected": -2.24153995513916,
      "logps/chosen": -117.96405029296875,
      "logps/rejected": -79.37605285644531,
      "loss": 0.0768,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.24705970287323,
      "rewards/margins": 2.647459030151367,
      "rewards/rejected": -1.4003994464874268,
      "step": 1136
    },
    {
      "epoch": 0.4548,
      "grad_norm": 1.6998600959777832,
      "learning_rate": 8.485333333333333e-07,
      "logits/chosen": -2.4553914070129395,
      "logits/rejected": -1.7680761814117432,
      "logps/chosen": -75.90774536132812,
      "logps/rejected": -130.02560424804688,
      "loss": 0.0287,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.592108964920044,
      "rewards/margins": 3.5576064586639404,
      "rewards/rejected": -1.965497612953186,
      "step": 1137
    },
    {
      "epoch": 0.4552,
      "grad_norm": 3.402329921722412,
      "learning_rate": 8.484e-07,
      "logits/chosen": -2.5753345489501953,
      "logits/rejected": -2.5196375846862793,
      "logps/chosen": -83.83341217041016,
      "logps/rejected": -86.49124145507812,
      "loss": 0.1067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4353454113006592,
      "rewards/margins": 2.572159767150879,
      "rewards/rejected": -1.1368142366409302,
      "step": 1138
    },
    {
      "epoch": 0.4556,
      "grad_norm": 4.763241767883301,
      "learning_rate": 8.482666666666666e-07,
      "logits/chosen": -2.816722869873047,
      "logits/rejected": -2.574634552001953,
      "logps/chosen": -78.12538146972656,
      "logps/rejected": -86.63668060302734,
      "loss": 0.107,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8513160943984985,
      "rewards/margins": 2.567831039428711,
      "rewards/rejected": -1.7165149450302124,
      "step": 1139
    },
    {
      "epoch": 0.456,
      "grad_norm": 5.817946434020996,
      "learning_rate": 8.481333333333333e-07,
      "logits/chosen": -2.6617393493652344,
      "logits/rejected": -2.2398734092712402,
      "logps/chosen": -121.14494323730469,
      "logps/rejected": -52.88706970214844,
      "loss": 0.1746,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5189793109893799,
      "rewards/margins": 1.6581709384918213,
      "rewards/rejected": -1.1391916275024414,
      "step": 1140
    },
    {
      "epoch": 0.4564,
      "grad_norm": 6.910388469696045,
      "learning_rate": 8.48e-07,
      "logits/chosen": -2.541041851043701,
      "logits/rejected": -2.384810447692871,
      "logps/chosen": -86.17001342773438,
      "logps/rejected": -59.635746002197266,
      "loss": 0.1654,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.794284462928772,
      "rewards/margins": 2.3376882076263428,
      "rewards/rejected": -1.5434038639068604,
      "step": 1141
    },
    {
      "epoch": 0.4568,
      "grad_norm": 2.7776691913604736,
      "learning_rate": 8.478666666666667e-07,
      "logits/chosen": -2.837757110595703,
      "logits/rejected": -2.276472330093384,
      "logps/chosen": -74.26687622070312,
      "logps/rejected": -101.15971374511719,
      "loss": 0.0466,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0138723850250244,
      "rewards/margins": 3.1313517093658447,
      "rewards/rejected": -2.1174793243408203,
      "step": 1142
    },
    {
      "epoch": 0.4572,
      "grad_norm": 1.8110069036483765,
      "learning_rate": 8.477333333333332e-07,
      "logits/chosen": -2.465010166168213,
      "logits/rejected": -1.8483538627624512,
      "logps/chosen": -123.44184875488281,
      "logps/rejected": -85.3268051147461,
      "loss": 0.034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8844704627990723,
      "rewards/margins": 3.3732128143310547,
      "rewards/rejected": -1.488742470741272,
      "step": 1143
    },
    {
      "epoch": 0.4576,
      "grad_norm": 1.0169591903686523,
      "learning_rate": 8.475999999999999e-07,
      "logits/chosen": -2.2575106620788574,
      "logits/rejected": -1.912976622581482,
      "logps/chosen": -186.10479736328125,
      "logps/rejected": -81.0294418334961,
      "loss": 0.0172,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.546454668045044,
      "rewards/margins": 4.2084760665893555,
      "rewards/rejected": -1.6620213985443115,
      "step": 1144
    },
    {
      "epoch": 0.458,
      "grad_norm": 4.068718433380127,
      "learning_rate": 8.474666666666666e-07,
      "logits/chosen": -2.9444665908813477,
      "logits/rejected": -2.322441577911377,
      "logps/chosen": -49.062355041503906,
      "logps/rejected": -71.37367248535156,
      "loss": 0.1224,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9915993213653564,
      "rewards/margins": 2.1289377212524414,
      "rewards/rejected": -1.1373382806777954,
      "step": 1145
    },
    {
      "epoch": 0.4584,
      "grad_norm": 5.7501726150512695,
      "learning_rate": 8.473333333333333e-07,
      "logits/chosen": -2.5658113956451416,
      "logits/rejected": -2.249814987182617,
      "logps/chosen": -118.35517883300781,
      "logps/rejected": -69.2130126953125,
      "loss": 0.1637,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8264366388320923,
      "rewards/margins": 2.091679573059082,
      "rewards/rejected": -1.2652430534362793,
      "step": 1146
    },
    {
      "epoch": 0.4588,
      "grad_norm": 2.8671562671661377,
      "learning_rate": 8.471999999999999e-07,
      "logits/chosen": -2.619746685028076,
      "logits/rejected": -2.088623046875,
      "logps/chosen": -112.65129089355469,
      "logps/rejected": -60.396018981933594,
      "loss": 0.0524,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2707605361938477,
      "rewards/margins": 3.1124393939971924,
      "rewards/rejected": -0.841679036617279,
      "step": 1147
    },
    {
      "epoch": 0.4592,
      "grad_norm": 3.7893259525299072,
      "learning_rate": 8.470666666666666e-07,
      "logits/chosen": -2.5494985580444336,
      "logits/rejected": -2.002821683883667,
      "logps/chosen": -116.76788330078125,
      "logps/rejected": -77.01194763183594,
      "loss": 0.1012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8962312936782837,
      "rewards/margins": 2.2407870292663574,
      "rewards/rejected": -1.3445556163787842,
      "step": 1148
    },
    {
      "epoch": 0.4596,
      "grad_norm": 1.9864386320114136,
      "learning_rate": 8.469333333333333e-07,
      "logits/chosen": -2.6037750244140625,
      "logits/rejected": -2.175788402557373,
      "logps/chosen": -89.1205825805664,
      "logps/rejected": -110.47518920898438,
      "loss": 0.0441,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6276111602783203,
      "rewards/margins": 3.1070878505706787,
      "rewards/rejected": -1.4794765710830688,
      "step": 1149
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.4729115962982178,
      "learning_rate": 8.468e-07,
      "logits/chosen": -2.4413280487060547,
      "logits/rejected": -1.9196267127990723,
      "logps/chosen": -90.85577392578125,
      "logps/rejected": -72.78700256347656,
      "loss": 0.0839,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2929801940917969,
      "rewards/margins": 2.459789276123047,
      "rewards/rejected": -1.1668089628219604,
      "step": 1150
    },
    {
      "epoch": 0.4604,
      "grad_norm": 3.533210515975952,
      "learning_rate": 8.466666666666667e-07,
      "logits/chosen": -2.48203182220459,
      "logits/rejected": -2.00258469581604,
      "logps/chosen": -79.89599609375,
      "logps/rejected": -61.27885818481445,
      "loss": 0.0929,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1953670978546143,
      "rewards/margins": 2.458834171295166,
      "rewards/rejected": -1.2634671926498413,
      "step": 1151
    },
    {
      "epoch": 0.4608,
      "grad_norm": 2.404458522796631,
      "learning_rate": 8.465333333333334e-07,
      "logits/chosen": -2.935791015625,
      "logits/rejected": -2.4969401359558105,
      "logps/chosen": -116.8267593383789,
      "logps/rejected": -66.63023376464844,
      "loss": 0.0541,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0362296104431152,
      "rewards/margins": 2.9029054641723633,
      "rewards/rejected": -1.8666757345199585,
      "step": 1152
    },
    {
      "epoch": 0.4612,
      "grad_norm": 2.083442211151123,
      "learning_rate": 8.464e-07,
      "logits/chosen": -2.5019783973693848,
      "logits/rejected": -2.1564998626708984,
      "logps/chosen": -146.38555908203125,
      "logps/rejected": -78.64325714111328,
      "loss": 0.0457,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.962167501449585,
      "rewards/margins": 3.0683610439300537,
      "rewards/rejected": -1.1061935424804688,
      "step": 1153
    },
    {
      "epoch": 0.4616,
      "grad_norm": 3.1220712661743164,
      "learning_rate": 8.462666666666665e-07,
      "logits/chosen": -2.7583847045898438,
      "logits/rejected": -2.5159642696380615,
      "logps/chosen": -86.85343170166016,
      "logps/rejected": -63.38028335571289,
      "loss": 0.0852,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8824160099029541,
      "rewards/margins": 2.446866512298584,
      "rewards/rejected": -1.5644506216049194,
      "step": 1154
    },
    {
      "epoch": 0.462,
      "grad_norm": 4.993041515350342,
      "learning_rate": 8.461333333333332e-07,
      "logits/chosen": -2.9057395458221436,
      "logits/rejected": -2.577239513397217,
      "logps/chosen": -53.054832458496094,
      "logps/rejected": -62.76714324951172,
      "loss": 0.2094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6162687540054321,
      "rewards/margins": 1.9262816905975342,
      "rewards/rejected": -1.310012936592102,
      "step": 1155
    },
    {
      "epoch": 0.4624,
      "grad_norm": 4.84158992767334,
      "learning_rate": 8.459999999999999e-07,
      "logits/chosen": -2.5535972118377686,
      "logits/rejected": -2.149190664291382,
      "logps/chosen": -148.05398559570312,
      "logps/rejected": -56.670597076416016,
      "loss": 0.1214,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.192110538482666,
      "rewards/margins": 2.0842885971069336,
      "rewards/rejected": -0.892177939414978,
      "step": 1156
    },
    {
      "epoch": 0.4628,
      "grad_norm": 3.4290826320648193,
      "learning_rate": 8.458666666666666e-07,
      "logits/chosen": -2.6747941970825195,
      "logits/rejected": -2.6073973178863525,
      "logps/chosen": -67.71595001220703,
      "logps/rejected": -121.97212219238281,
      "loss": 0.0587,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1228234767913818,
      "rewards/margins": 2.8175015449523926,
      "rewards/rejected": -1.6946780681610107,
      "step": 1157
    },
    {
      "epoch": 0.4632,
      "grad_norm": 3.1694631576538086,
      "learning_rate": 8.457333333333333e-07,
      "logits/chosen": -2.540224552154541,
      "logits/rejected": -2.020963191986084,
      "logps/chosen": -114.4665298461914,
      "logps/rejected": -76.75167083740234,
      "loss": 0.0716,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5198192596435547,
      "rewards/margins": 2.6231889724731445,
      "rewards/rejected": -1.1033695936203003,
      "step": 1158
    },
    {
      "epoch": 0.4636,
      "grad_norm": 4.968832492828369,
      "learning_rate": 8.456e-07,
      "logits/chosen": -2.8681890964508057,
      "logits/rejected": -2.795398712158203,
      "logps/chosen": -59.84644317626953,
      "logps/rejected": -37.6140022277832,
      "loss": 0.1978,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7049877643585205,
      "rewards/margins": 1.543653130531311,
      "rewards/rejected": -0.8386654257774353,
      "step": 1159
    },
    {
      "epoch": 0.464,
      "grad_norm": 3.773670196533203,
      "learning_rate": 8.454666666666667e-07,
      "logits/chosen": -2.9715042114257812,
      "logits/rejected": -2.4179601669311523,
      "logps/chosen": -78.98261260986328,
      "logps/rejected": -58.181732177734375,
      "loss": 0.0983,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7197093963623047,
      "rewards/margins": 2.299236297607422,
      "rewards/rejected": -1.5795269012451172,
      "step": 1160
    },
    {
      "epoch": 0.4644,
      "grad_norm": 3.886780023574829,
      "learning_rate": 8.453333333333334e-07,
      "logits/chosen": -2.6270318031311035,
      "logits/rejected": -2.132249593734741,
      "logps/chosen": -130.450927734375,
      "logps/rejected": -88.52608489990234,
      "loss": 0.0914,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0380547046661377,
      "rewards/margins": 2.391335964202881,
      "rewards/rejected": -1.353281021118164,
      "step": 1161
    },
    {
      "epoch": 0.4648,
      "grad_norm": 7.281112194061279,
      "learning_rate": 8.451999999999999e-07,
      "logits/chosen": -2.882312536239624,
      "logits/rejected": -2.382767915725708,
      "logps/chosen": -77.04519653320312,
      "logps/rejected": -107.87938690185547,
      "loss": 0.1626,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0469738245010376,
      "rewards/margins": 1.9125211238861084,
      "rewards/rejected": -0.8655474185943604,
      "step": 1162
    },
    {
      "epoch": 0.4652,
      "grad_norm": 2.330711603164673,
      "learning_rate": 8.450666666666666e-07,
      "logits/chosen": -2.8572921752929688,
      "logits/rejected": -2.5752406120300293,
      "logps/chosen": -120.44513702392578,
      "logps/rejected": -89.99274444580078,
      "loss": 0.046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4345039129257202,
      "rewards/margins": 3.7087268829345703,
      "rewards/rejected": -2.2742228507995605,
      "step": 1163
    },
    {
      "epoch": 0.4656,
      "grad_norm": 2.126408100128174,
      "learning_rate": 8.449333333333332e-07,
      "logits/chosen": -2.535480499267578,
      "logits/rejected": -2.1369717121124268,
      "logps/chosen": -108.4820327758789,
      "logps/rejected": -87.62114715576172,
      "loss": 0.0466,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8903881311416626,
      "rewards/margins": 3.3496313095092773,
      "rewards/rejected": -1.4592432975769043,
      "step": 1164
    },
    {
      "epoch": 0.466,
      "grad_norm": 1.5557119846343994,
      "learning_rate": 8.447999999999999e-07,
      "logits/chosen": -2.738351821899414,
      "logits/rejected": -2.34409236907959,
      "logps/chosen": -129.8013458251953,
      "logps/rejected": -85.53994750976562,
      "loss": 0.031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2945525646209717,
      "rewards/margins": 3.4750161170959473,
      "rewards/rejected": -2.1804635524749756,
      "step": 1165
    },
    {
      "epoch": 0.4664,
      "grad_norm": 5.731334209442139,
      "learning_rate": 8.446666666666666e-07,
      "logits/chosen": -2.5017170906066895,
      "logits/rejected": -2.0777924060821533,
      "logps/chosen": -124.16178894042969,
      "logps/rejected": -113.09074401855469,
      "loss": 0.0719,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0352039337158203,
      "rewards/margins": 2.9073612689971924,
      "rewards/rejected": -1.872157335281372,
      "step": 1166
    },
    {
      "epoch": 0.4668,
      "grad_norm": 5.853996276855469,
      "learning_rate": 8.445333333333333e-07,
      "logits/chosen": -2.544750690460205,
      "logits/rejected": -2.3022968769073486,
      "logps/chosen": -100.75062561035156,
      "logps/rejected": -54.781517028808594,
      "loss": 0.2008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8198230862617493,
      "rewards/margins": 1.798823356628418,
      "rewards/rejected": -0.9790002107620239,
      "step": 1167
    },
    {
      "epoch": 0.4672,
      "grad_norm": 2.9322140216827393,
      "learning_rate": 8.444e-07,
      "logits/chosen": -2.422790050506592,
      "logits/rejected": -1.9492418766021729,
      "logps/chosen": -77.85093688964844,
      "logps/rejected": -69.40282440185547,
      "loss": 0.0635,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1673779487609863,
      "rewards/margins": 3.175961971282959,
      "rewards/rejected": -2.0085840225219727,
      "step": 1168
    },
    {
      "epoch": 0.4676,
      "grad_norm": 4.00445556640625,
      "learning_rate": 8.442666666666667e-07,
      "logits/chosen": -2.5474648475646973,
      "logits/rejected": -2.5592432022094727,
      "logps/chosen": -83.21207427978516,
      "logps/rejected": -47.0135383605957,
      "loss": 0.1082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8635179400444031,
      "rewards/margins": 2.1704397201538086,
      "rewards/rejected": -1.3069216012954712,
      "step": 1169
    },
    {
      "epoch": 0.468,
      "grad_norm": 2.071176767349243,
      "learning_rate": 8.441333333333333e-07,
      "logits/chosen": -2.3446192741394043,
      "logits/rejected": -1.9586083889007568,
      "logps/chosen": -84.96635437011719,
      "logps/rejected": -81.6142578125,
      "loss": 0.0391,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.765479326248169,
      "rewards/margins": 3.2540946006774902,
      "rewards/rejected": -1.4886152744293213,
      "step": 1170
    },
    {
      "epoch": 0.4684,
      "grad_norm": 5.8449907302856445,
      "learning_rate": 8.439999999999999e-07,
      "logits/chosen": -2.314626693725586,
      "logits/rejected": -2.400101661682129,
      "logps/chosen": -65.90678405761719,
      "logps/rejected": -77.62086486816406,
      "loss": 0.1492,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1984539031982422,
      "rewards/margins": 1.8396706581115723,
      "rewards/rejected": -0.6412168741226196,
      "step": 1171
    },
    {
      "epoch": 0.4688,
      "grad_norm": 3.2876882553100586,
      "learning_rate": 8.438666666666666e-07,
      "logits/chosen": -2.7386889457702637,
      "logits/rejected": -2.277015209197998,
      "logps/chosen": -103.41526794433594,
      "logps/rejected": -91.57247161865234,
      "loss": 0.0855,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4662270545959473,
      "rewards/margins": 2.9406213760375977,
      "rewards/rejected": -1.4743943214416504,
      "step": 1172
    },
    {
      "epoch": 0.4692,
      "grad_norm": 1.4286854267120361,
      "learning_rate": 8.437333333333333e-07,
      "logits/chosen": -2.6860761642456055,
      "logits/rejected": -2.052797555923462,
      "logps/chosen": -96.45814514160156,
      "logps/rejected": -91.99951171875,
      "loss": 0.0247,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.480474829673767,
      "rewards/margins": 3.690825939178467,
      "rewards/rejected": -2.2103512287139893,
      "step": 1173
    },
    {
      "epoch": 0.4696,
      "grad_norm": 3.0948069095611572,
      "learning_rate": 8.436e-07,
      "logits/chosen": -2.5597710609436035,
      "logits/rejected": -2.2271623611450195,
      "logps/chosen": -111.48783874511719,
      "logps/rejected": -104.83720397949219,
      "loss": 0.0753,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3014370203018188,
      "rewards/margins": 2.713440418243408,
      "rewards/rejected": -1.4120032787322998,
      "step": 1174
    },
    {
      "epoch": 0.47,
      "grad_norm": 5.427163600921631,
      "learning_rate": 8.434666666666666e-07,
      "logits/chosen": -2.5984153747558594,
      "logits/rejected": -1.9583895206451416,
      "logps/chosen": -89.03650665283203,
      "logps/rejected": -81.07855224609375,
      "loss": 0.1484,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.26987385749816895,
      "rewards/margins": 1.9126191139221191,
      "rewards/rejected": -1.6427452564239502,
      "step": 1175
    },
    {
      "epoch": 0.4704,
      "grad_norm": 4.962302207946777,
      "learning_rate": 8.433333333333333e-07,
      "logits/chosen": -2.7280359268188477,
      "logits/rejected": -2.4032583236694336,
      "logps/chosen": -88.37469482421875,
      "logps/rejected": -105.01748657226562,
      "loss": 0.0674,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6088110208511353,
      "rewards/margins": 3.075526714324951,
      "rewards/rejected": -1.4667155742645264,
      "step": 1176
    },
    {
      "epoch": 0.4708,
      "grad_norm": 4.12287712097168,
      "learning_rate": 8.431999999999999e-07,
      "logits/chosen": -2.8366711139678955,
      "logits/rejected": -2.5862786769866943,
      "logps/chosen": -44.01966094970703,
      "logps/rejected": -65.99019622802734,
      "loss": 0.111,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3207572102546692,
      "rewards/margins": 2.1503775119781494,
      "rewards/rejected": -1.8296202421188354,
      "step": 1177
    },
    {
      "epoch": 0.4712,
      "grad_norm": 5.558802604675293,
      "learning_rate": 8.430666666666666e-07,
      "logits/chosen": -2.826253652572632,
      "logits/rejected": -2.2806026935577393,
      "logps/chosen": -55.167057037353516,
      "logps/rejected": -71.7974853515625,
      "loss": 0.1494,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5923425555229187,
      "rewards/margins": 1.9675124883651733,
      "rewards/rejected": -1.3751699924468994,
      "step": 1178
    },
    {
      "epoch": 0.4716,
      "grad_norm": 3.4365594387054443,
      "learning_rate": 8.429333333333333e-07,
      "logits/chosen": -2.7678608894348145,
      "logits/rejected": -2.1989870071411133,
      "logps/chosen": -69.54258728027344,
      "logps/rejected": -61.63359832763672,
      "loss": 0.108,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3394750356674194,
      "rewards/margins": 2.4637656211853027,
      "rewards/rejected": -1.1242904663085938,
      "step": 1179
    },
    {
      "epoch": 0.472,
      "grad_norm": 2.4103567600250244,
      "learning_rate": 8.428e-07,
      "logits/chosen": -2.4397687911987305,
      "logits/rejected": -1.887474775314331,
      "logps/chosen": -131.29571533203125,
      "logps/rejected": -77.48709106445312,
      "loss": 0.0502,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.309293031692505,
      "rewards/margins": 3.5765771865844727,
      "rewards/rejected": -1.2672840356826782,
      "step": 1180
    },
    {
      "epoch": 0.4724,
      "grad_norm": 5.921075820922852,
      "learning_rate": 8.426666666666666e-07,
      "logits/chosen": -2.9220352172851562,
      "logits/rejected": -2.5268144607543945,
      "logps/chosen": -54.017356872558594,
      "logps/rejected": -40.662841796875,
      "loss": 0.2224,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.69891357421875,
      "rewards/margins": 1.4026026725769043,
      "rewards/rejected": -0.7036890387535095,
      "step": 1181
    },
    {
      "epoch": 0.4728,
      "grad_norm": 2.1295106410980225,
      "learning_rate": 8.425333333333333e-07,
      "logits/chosen": -2.7332096099853516,
      "logits/rejected": -2.1816463470458984,
      "logps/chosen": -91.77079010009766,
      "logps/rejected": -87.10950469970703,
      "loss": 0.0389,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6690073013305664,
      "rewards/margins": 3.500516414642334,
      "rewards/rejected": -1.8315091133117676,
      "step": 1182
    },
    {
      "epoch": 0.4732,
      "grad_norm": 3.138822078704834,
      "learning_rate": 8.424e-07,
      "logits/chosen": -2.6222400665283203,
      "logits/rejected": -2.0844907760620117,
      "logps/chosen": -73.95967864990234,
      "logps/rejected": -68.24446868896484,
      "loss": 0.0931,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6146687269210815,
      "rewards/margins": 2.722123861312866,
      "rewards/rejected": -1.1074550151824951,
      "step": 1183
    },
    {
      "epoch": 0.4736,
      "grad_norm": 5.483786106109619,
      "learning_rate": 8.422666666666667e-07,
      "logits/chosen": -2.5906646251678467,
      "logits/rejected": -2.2199959754943848,
      "logps/chosen": -115.5325927734375,
      "logps/rejected": -62.89631652832031,
      "loss": 0.1382,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.946759045124054,
      "rewards/margins": 2.147656202316284,
      "rewards/rejected": -1.200897216796875,
      "step": 1184
    },
    {
      "epoch": 0.474,
      "grad_norm": 3.375704765319824,
      "learning_rate": 8.421333333333333e-07,
      "logits/chosen": -2.583434581756592,
      "logits/rejected": -2.399914264678955,
      "logps/chosen": -85.85575866699219,
      "logps/rejected": -65.31831359863281,
      "loss": 0.0864,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.885819673538208,
      "rewards/margins": 2.430206298828125,
      "rewards/rejected": -0.5443866848945618,
      "step": 1185
    },
    {
      "epoch": 0.4744,
      "grad_norm": 1.9621217250823975,
      "learning_rate": 8.419999999999999e-07,
      "logits/chosen": -2.7770071029663086,
      "logits/rejected": -2.205928325653076,
      "logps/chosen": -48.613914489746094,
      "logps/rejected": -65.19522094726562,
      "loss": 0.0535,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3123235702514648,
      "rewards/margins": 3.0605149269104004,
      "rewards/rejected": -1.7481911182403564,
      "step": 1186
    },
    {
      "epoch": 0.4748,
      "grad_norm": 2.82704496383667,
      "learning_rate": 8.418666666666666e-07,
      "logits/chosen": -2.342414140701294,
      "logits/rejected": -1.8074092864990234,
      "logps/chosen": -168.61058044433594,
      "logps/rejected": -76.84361267089844,
      "loss": 0.0524,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3655579090118408,
      "rewards/margins": 2.9246914386749268,
      "rewards/rejected": -1.559133529663086,
      "step": 1187
    },
    {
      "epoch": 0.4752,
      "grad_norm": 3.018862009048462,
      "learning_rate": 8.417333333333333e-07,
      "logits/chosen": -2.7182040214538574,
      "logits/rejected": -2.2904162406921387,
      "logps/chosen": -107.50057220458984,
      "logps/rejected": -66.58362579345703,
      "loss": 0.0796,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3690330982208252,
      "rewards/margins": 2.9533803462982178,
      "rewards/rejected": -1.5843472480773926,
      "step": 1188
    },
    {
      "epoch": 0.4756,
      "grad_norm": 3.194446086883545,
      "learning_rate": 8.416e-07,
      "logits/chosen": -2.806365966796875,
      "logits/rejected": -2.357349157333374,
      "logps/chosen": -68.37580871582031,
      "logps/rejected": -85.67806243896484,
      "loss": 0.0861,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7956483364105225,
      "rewards/margins": 2.5917208194732666,
      "rewards/rejected": -0.7960724234580994,
      "step": 1189
    },
    {
      "epoch": 0.476,
      "grad_norm": 7.344733715057373,
      "learning_rate": 8.414666666666667e-07,
      "logits/chosen": -2.391848087310791,
      "logits/rejected": -2.137833595275879,
      "logps/chosen": -206.7415771484375,
      "logps/rejected": -106.47640991210938,
      "loss": 0.1422,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4983017146587372,
      "rewards/margins": 2.12676739692688,
      "rewards/rejected": -1.6284656524658203,
      "step": 1190
    },
    {
      "epoch": 0.4764,
      "grad_norm": 2.276627540588379,
      "learning_rate": 8.413333333333333e-07,
      "logits/chosen": -2.481940269470215,
      "logits/rejected": -1.9998583793640137,
      "logps/chosen": -112.60856628417969,
      "logps/rejected": -78.83065795898438,
      "loss": 0.0436,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.921417236328125,
      "rewards/margins": 3.3660171031951904,
      "rewards/rejected": -1.4445998668670654,
      "step": 1191
    },
    {
      "epoch": 0.4768,
      "grad_norm": 3.9920949935913086,
      "learning_rate": 8.411999999999999e-07,
      "logits/chosen": -2.7319605350494385,
      "logits/rejected": -2.2100605964660645,
      "logps/chosen": -110.22919464111328,
      "logps/rejected": -55.915130615234375,
      "loss": 0.1083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.051491618156433,
      "rewards/margins": 2.232107162475586,
      "rewards/rejected": -1.1806156635284424,
      "step": 1192
    },
    {
      "epoch": 0.4772,
      "grad_norm": 8.301424026489258,
      "learning_rate": 8.410666666666666e-07,
      "logits/chosen": -2.5191168785095215,
      "logits/rejected": -2.5883829593658447,
      "logps/chosen": -119.92232513427734,
      "logps/rejected": -164.47337341308594,
      "loss": 0.1758,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7594139575958252,
      "rewards/margins": 1.6694600582122803,
      "rewards/rejected": -0.9100460410118103,
      "step": 1193
    },
    {
      "epoch": 0.4776,
      "grad_norm": 2.788510322570801,
      "learning_rate": 8.409333333333333e-07,
      "logits/chosen": -2.3288164138793945,
      "logits/rejected": -1.6917674541473389,
      "logps/chosen": -105.16938781738281,
      "logps/rejected": -107.77774810791016,
      "loss": 0.0491,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4769607782363892,
      "rewards/margins": 2.9940876960754395,
      "rewards/rejected": -1.5171267986297607,
      "step": 1194
    },
    {
      "epoch": 0.478,
      "grad_norm": 2.670938491821289,
      "learning_rate": 8.408e-07,
      "logits/chosen": -2.9679160118103027,
      "logits/rejected": -2.357456684112549,
      "logps/chosen": -82.48284912109375,
      "logps/rejected": -100.83555603027344,
      "loss": 0.0528,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6491379141807556,
      "rewards/margins": 3.193480968475342,
      "rewards/rejected": -2.5443432331085205,
      "step": 1195
    },
    {
      "epoch": 0.4784,
      "grad_norm": 1.8439743518829346,
      "learning_rate": 8.406666666666667e-07,
      "logits/chosen": -2.603860378265381,
      "logits/rejected": -1.9739656448364258,
      "logps/chosen": -174.76217651367188,
      "logps/rejected": -70.45330810546875,
      "loss": 0.0356,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.003592014312744,
      "rewards/margins": 3.4956014156341553,
      "rewards/rejected": -1.4920094013214111,
      "step": 1196
    },
    {
      "epoch": 0.4788,
      "grad_norm": 4.643980979919434,
      "learning_rate": 8.405333333333333e-07,
      "logits/chosen": -2.340362548828125,
      "logits/rejected": -2.1500463485717773,
      "logps/chosen": -66.55984497070312,
      "logps/rejected": -98.77653503417969,
      "loss": 0.0963,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6626051068305969,
      "rewards/margins": 2.3684446811676025,
      "rewards/rejected": -1.7058396339416504,
      "step": 1197
    },
    {
      "epoch": 0.4792,
      "grad_norm": 2.7038285732269287,
      "learning_rate": 8.404e-07,
      "logits/chosen": -2.359909772872925,
      "logits/rejected": -1.920724868774414,
      "logps/chosen": -124.59384155273438,
      "logps/rejected": -88.42585754394531,
      "loss": 0.0515,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5549007654190063,
      "rewards/margins": 2.9928770065307617,
      "rewards/rejected": -1.437976360321045,
      "step": 1198
    },
    {
      "epoch": 0.4796,
      "grad_norm": 9.916738510131836,
      "learning_rate": 8.402666666666667e-07,
      "logits/chosen": -2.4930243492126465,
      "logits/rejected": -2.1138148307800293,
      "logps/chosen": -109.12723541259766,
      "logps/rejected": -59.3050537109375,
      "loss": 0.189,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5354161262512207,
      "rewards/margins": 2.1618242263793945,
      "rewards/rejected": -0.6264082193374634,
      "step": 1199
    },
    {
      "epoch": 0.48,
      "grad_norm": 9.520841598510742,
      "learning_rate": 8.401333333333332e-07,
      "logits/chosen": -2.476766586303711,
      "logits/rejected": -2.5342893600463867,
      "logps/chosen": -113.37734985351562,
      "logps/rejected": -84.58349609375,
      "loss": 0.1773,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.264013648033142,
      "rewards/margins": 1.9766967296600342,
      "rewards/rejected": -0.7126831412315369,
      "step": 1200
    },
    {
      "epoch": 0.4804,
      "grad_norm": 2.3119308948516846,
      "learning_rate": 8.399999999999999e-07,
      "logits/chosen": -2.343353271484375,
      "logits/rejected": -2.060598134994507,
      "logps/chosen": -74.962890625,
      "logps/rejected": -68.7669906616211,
      "loss": 0.0786,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0140419006347656,
      "rewards/margins": 2.522637367248535,
      "rewards/rejected": -1.5085954666137695,
      "step": 1201
    },
    {
      "epoch": 0.4808,
      "grad_norm": 6.421412467956543,
      "learning_rate": 8.398666666666666e-07,
      "logits/chosen": -2.8858842849731445,
      "logits/rejected": -2.6056594848632812,
      "logps/chosen": -57.912109375,
      "logps/rejected": -49.43811798095703,
      "loss": 0.1669,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7370555996894836,
      "rewards/margins": 1.7111220359802246,
      "rewards/rejected": -0.9740663766860962,
      "step": 1202
    },
    {
      "epoch": 0.4812,
      "grad_norm": 2.8290321826934814,
      "learning_rate": 8.397333333333333e-07,
      "logits/chosen": -2.6983940601348877,
      "logits/rejected": -2.138378381729126,
      "logps/chosen": -88.3763656616211,
      "logps/rejected": -68.11160278320312,
      "loss": 0.094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.326826572418213,
      "rewards/margins": 2.6772890090942383,
      "rewards/rejected": -1.3504624366760254,
      "step": 1203
    },
    {
      "epoch": 0.4816,
      "grad_norm": 3.601285219192505,
      "learning_rate": 8.396e-07,
      "logits/chosen": -2.6907856464385986,
      "logits/rejected": -2.5128276348114014,
      "logps/chosen": -73.5903091430664,
      "logps/rejected": -59.250343322753906,
      "loss": 0.0732,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2242735624313354,
      "rewards/margins": 2.7955574989318848,
      "rewards/rejected": -1.5712838172912598,
      "step": 1204
    },
    {
      "epoch": 0.482,
      "grad_norm": 2.0287554264068604,
      "learning_rate": 8.394666666666667e-07,
      "logits/chosen": -2.7371625900268555,
      "logits/rejected": -2.3391919136047363,
      "logps/chosen": -80.68394470214844,
      "logps/rejected": -108.84794616699219,
      "loss": 0.0507,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5537292957305908,
      "rewards/margins": 3.150653123855591,
      "rewards/rejected": -1.596923828125,
      "step": 1205
    },
    {
      "epoch": 0.4824,
      "grad_norm": 1.6693370342254639,
      "learning_rate": 8.393333333333334e-07,
      "logits/chosen": -2.6978445053100586,
      "logits/rejected": -2.1639769077301025,
      "logps/chosen": -74.47390747070312,
      "logps/rejected": -85.43283081054688,
      "loss": 0.0383,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2518603801727295,
      "rewards/margins": 3.8579599857330322,
      "rewards/rejected": -2.6060996055603027,
      "step": 1206
    },
    {
      "epoch": 0.4828,
      "grad_norm": 3.00671124458313,
      "learning_rate": 8.391999999999999e-07,
      "logits/chosen": -2.3928093910217285,
      "logits/rejected": -1.6512223482131958,
      "logps/chosen": -92.05792236328125,
      "logps/rejected": -91.60804748535156,
      "loss": 0.0646,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7304210662841797,
      "rewards/margins": 2.7321388721466064,
      "rewards/rejected": -1.0017178058624268,
      "step": 1207
    },
    {
      "epoch": 0.4832,
      "grad_norm": 4.151494979858398,
      "learning_rate": 8.390666666666666e-07,
      "logits/chosen": -3.024264335632324,
      "logits/rejected": -2.867544174194336,
      "logps/chosen": -56.05439758300781,
      "logps/rejected": -58.94287872314453,
      "loss": 0.105,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2265946865081787,
      "rewards/margins": 2.2205147743225098,
      "rewards/rejected": -0.9939202070236206,
      "step": 1208
    },
    {
      "epoch": 0.4836,
      "grad_norm": 5.096672058105469,
      "learning_rate": 8.389333333333332e-07,
      "logits/chosen": -2.786705493927002,
      "logits/rejected": -2.2395498752593994,
      "logps/chosen": -76.89602661132812,
      "logps/rejected": -53.87956237792969,
      "loss": 0.1513,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7101160287857056,
      "rewards/margins": 1.8504574298858643,
      "rewards/rejected": -1.1403414011001587,
      "step": 1209
    },
    {
      "epoch": 0.484,
      "grad_norm": 4.557374000549316,
      "learning_rate": 8.387999999999999e-07,
      "logits/chosen": -2.7981648445129395,
      "logits/rejected": -2.5264029502868652,
      "logps/chosen": -94.40037536621094,
      "logps/rejected": -52.64191436767578,
      "loss": 0.1529,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6217371225357056,
      "rewards/margins": 1.965540885925293,
      "rewards/rejected": -1.3438037633895874,
      "step": 1210
    },
    {
      "epoch": 0.4844,
      "grad_norm": 3.1563310623168945,
      "learning_rate": 8.386666666666666e-07,
      "logits/chosen": -2.7094101905822754,
      "logits/rejected": -2.181838035583496,
      "logps/chosen": -93.0130844116211,
      "logps/rejected": -63.378238677978516,
      "loss": 0.064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7322453260421753,
      "rewards/margins": 3.0770764350891113,
      "rewards/rejected": -1.344831109046936,
      "step": 1211
    },
    {
      "epoch": 0.4848,
      "grad_norm": 2.2718987464904785,
      "learning_rate": 8.385333333333333e-07,
      "logits/chosen": -2.7814769744873047,
      "logits/rejected": -2.215848684310913,
      "logps/chosen": -63.90016174316406,
      "logps/rejected": -66.59342956542969,
      "loss": 0.0554,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7532860040664673,
      "rewards/margins": 2.989529848098755,
      "rewards/rejected": -2.236243963241577,
      "step": 1212
    },
    {
      "epoch": 0.4852,
      "grad_norm": 2.3188698291778564,
      "learning_rate": 8.384e-07,
      "logits/chosen": -2.6113343238830566,
      "logits/rejected": -2.0525593757629395,
      "logps/chosen": -98.24742126464844,
      "logps/rejected": -121.68164825439453,
      "loss": 0.0342,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9589229822158813,
      "rewards/margins": 3.454618453979492,
      "rewards/rejected": -2.4956955909729004,
      "step": 1213
    },
    {
      "epoch": 0.4856,
      "grad_norm": 2.5145695209503174,
      "learning_rate": 8.382666666666667e-07,
      "logits/chosen": -2.577956199645996,
      "logits/rejected": -2.260359287261963,
      "logps/chosen": -99.13471984863281,
      "logps/rejected": -71.30393981933594,
      "loss": 0.05,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8721225261688232,
      "rewards/margins": 3.3102054595947266,
      "rewards/rejected": -1.4380826950073242,
      "step": 1214
    },
    {
      "epoch": 0.486,
      "grad_norm": 1.738860845565796,
      "learning_rate": 8.381333333333333e-07,
      "logits/chosen": -2.6538076400756836,
      "logits/rejected": -2.2926387786865234,
      "logps/chosen": -71.8875732421875,
      "logps/rejected": -77.18706512451172,
      "loss": 0.0324,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5252461433410645,
      "rewards/margins": 3.559551239013672,
      "rewards/rejected": -2.0343050956726074,
      "step": 1215
    },
    {
      "epoch": 0.4864,
      "grad_norm": 3.3478803634643555,
      "learning_rate": 8.38e-07,
      "logits/chosen": -2.571291208267212,
      "logits/rejected": -2.156831741333008,
      "logps/chosen": -86.60614013671875,
      "logps/rejected": -64.32555389404297,
      "loss": 0.0829,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2823543548583984,
      "rewards/margins": 2.5185399055480957,
      "rewards/rejected": -1.2361856698989868,
      "step": 1216
    },
    {
      "epoch": 0.4868,
      "grad_norm": 3.271594285964966,
      "learning_rate": 8.378666666666667e-07,
      "logits/chosen": -2.8751049041748047,
      "logits/rejected": -2.2646336555480957,
      "logps/chosen": -72.17375946044922,
      "logps/rejected": -56.63896179199219,
      "loss": 0.081,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9877287149429321,
      "rewards/margins": 2.4734559059143066,
      "rewards/rejected": -1.485727071762085,
      "step": 1217
    },
    {
      "epoch": 0.4872,
      "grad_norm": 4.915582180023193,
      "learning_rate": 8.377333333333333e-07,
      "logits/chosen": -2.659862995147705,
      "logits/rejected": -2.4780445098876953,
      "logps/chosen": -133.21517944335938,
      "logps/rejected": -68.49517059326172,
      "loss": 0.1128,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5454265475273132,
      "rewards/margins": 2.1669487953186035,
      "rewards/rejected": -1.6215221881866455,
      "step": 1218
    },
    {
      "epoch": 0.4876,
      "grad_norm": 2.832322120666504,
      "learning_rate": 8.375999999999999e-07,
      "logits/chosen": -2.6512184143066406,
      "logits/rejected": -2.2982802391052246,
      "logps/chosen": -102.67401885986328,
      "logps/rejected": -74.42245483398438,
      "loss": 0.0883,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8662728071212769,
      "rewards/margins": 3.0530576705932617,
      "rewards/rejected": -1.1867847442626953,
      "step": 1219
    },
    {
      "epoch": 0.488,
      "grad_norm": 4.067518711090088,
      "learning_rate": 8.374666666666666e-07,
      "logits/chosen": -2.6922316551208496,
      "logits/rejected": -2.267019748687744,
      "logps/chosen": -83.98053741455078,
      "logps/rejected": -65.80229187011719,
      "loss": 0.1169,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1564342975616455,
      "rewards/margins": 2.218684196472168,
      "rewards/rejected": -1.062249779701233,
      "step": 1220
    },
    {
      "epoch": 0.4884,
      "grad_norm": 2.637301206588745,
      "learning_rate": 8.373333333333333e-07,
      "logits/chosen": -3.00331711769104,
      "logits/rejected": -2.4587457180023193,
      "logps/chosen": -47.52532958984375,
      "logps/rejected": -64.51397705078125,
      "loss": 0.0805,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1369026899337769,
      "rewards/margins": 3.4936838150024414,
      "rewards/rejected": -2.356781244277954,
      "step": 1221
    },
    {
      "epoch": 0.4888,
      "grad_norm": 3.766456127166748,
      "learning_rate": 8.372e-07,
      "logits/chosen": -2.5707411766052246,
      "logits/rejected": -2.264716386795044,
      "logps/chosen": -46.98295974731445,
      "logps/rejected": -58.97682189941406,
      "loss": 0.1074,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3538392782211304,
      "rewards/margins": 2.3413286209106445,
      "rewards/rejected": -0.9874891638755798,
      "step": 1222
    },
    {
      "epoch": 0.4892,
      "grad_norm": 3.0109386444091797,
      "learning_rate": 8.370666666666666e-07,
      "logits/chosen": -2.1933188438415527,
      "logits/rejected": -1.5627541542053223,
      "logps/chosen": -131.16949462890625,
      "logps/rejected": -88.26666259765625,
      "loss": 0.0573,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4726471900939941,
      "rewards/margins": 2.846273422241211,
      "rewards/rejected": -1.3736263513565063,
      "step": 1223
    },
    {
      "epoch": 0.4896,
      "grad_norm": 6.043292999267578,
      "learning_rate": 8.369333333333333e-07,
      "logits/chosen": -2.1924777030944824,
      "logits/rejected": -1.8392064571380615,
      "logps/chosen": -139.60211181640625,
      "logps/rejected": -63.759979248046875,
      "loss": 0.1227,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9333629608154297,
      "rewards/margins": 2.2093346118927,
      "rewards/rejected": -1.2759716510772705,
      "step": 1224
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.958336114883423,
      "learning_rate": 8.368e-07,
      "logits/chosen": -2.8007280826568604,
      "logits/rejected": -2.4470858573913574,
      "logps/chosen": -102.281982421875,
      "logps/rejected": -61.87230682373047,
      "loss": 0.088,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8445522785186768,
      "rewards/margins": 2.4457902908325195,
      "rewards/rejected": -1.6012380123138428,
      "step": 1225
    },
    {
      "epoch": 0.4904,
      "grad_norm": 4.921269416809082,
      "learning_rate": 8.366666666666667e-07,
      "logits/chosen": -2.2120916843414307,
      "logits/rejected": -1.787106990814209,
      "logps/chosen": -154.18490600585938,
      "logps/rejected": -139.69972229003906,
      "loss": 0.0967,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40469324588775635,
      "rewards/margins": 2.379481554031372,
      "rewards/rejected": -1.9747883081436157,
      "step": 1226
    },
    {
      "epoch": 0.4908,
      "grad_norm": 3.077183723449707,
      "learning_rate": 8.365333333333334e-07,
      "logits/chosen": -2.6942548751831055,
      "logits/rejected": -2.1182727813720703,
      "logps/chosen": -82.68553161621094,
      "logps/rejected": -62.6556510925293,
      "loss": 0.0887,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.579659342765808,
      "rewards/margins": 2.848799228668213,
      "rewards/rejected": -1.2691400051116943,
      "step": 1227
    },
    {
      "epoch": 0.4912,
      "grad_norm": 2.5514843463897705,
      "learning_rate": 8.363999999999999e-07,
      "logits/chosen": -2.5658717155456543,
      "logits/rejected": -1.9620952606201172,
      "logps/chosen": -55.901214599609375,
      "logps/rejected": -70.50071716308594,
      "loss": 0.0656,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.718569040298462,
      "rewards/margins": 2.6924827098846436,
      "rewards/rejected": -0.9739136099815369,
      "step": 1228
    },
    {
      "epoch": 0.4916,
      "grad_norm": 5.711231231689453,
      "learning_rate": 8.362666666666666e-07,
      "logits/chosen": -2.778463840484619,
      "logits/rejected": -2.3200011253356934,
      "logps/chosen": -82.1985855102539,
      "logps/rejected": -61.45796203613281,
      "loss": 0.1606,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.379800021648407,
      "rewards/margins": 1.7988941669464111,
      "rewards/rejected": -1.4190940856933594,
      "step": 1229
    },
    {
      "epoch": 0.492,
      "grad_norm": 4.843697547912598,
      "learning_rate": 8.361333333333332e-07,
      "logits/chosen": -2.4348816871643066,
      "logits/rejected": -2.354276657104492,
      "logps/chosen": -142.65467834472656,
      "logps/rejected": -62.603267669677734,
      "loss": 0.1485,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9373764991760254,
      "rewards/margins": 2.160597324371338,
      "rewards/rejected": -1.2232208251953125,
      "step": 1230
    },
    {
      "epoch": 0.4924,
      "grad_norm": 1.140041470527649,
      "learning_rate": 8.359999999999999e-07,
      "logits/chosen": -2.4788763523101807,
      "logits/rejected": -2.107093095779419,
      "logps/chosen": -151.75282287597656,
      "logps/rejected": -101.32975006103516,
      "loss": 0.0172,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3707618713378906,
      "rewards/margins": 4.100373268127441,
      "rewards/rejected": -2.7296111583709717,
      "step": 1231
    },
    {
      "epoch": 0.4928,
      "grad_norm": 2.3595149517059326,
      "learning_rate": 8.358666666666666e-07,
      "logits/chosen": -2.5608346462249756,
      "logits/rejected": -2.286879062652588,
      "logps/chosen": -84.39802551269531,
      "logps/rejected": -74.29302215576172,
      "loss": 0.0422,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4482312202453613,
      "rewards/margins": 3.3093037605285645,
      "rewards/rejected": -1.8610725402832031,
      "step": 1232
    },
    {
      "epoch": 0.4932,
      "grad_norm": 4.676490306854248,
      "learning_rate": 8.357333333333333e-07,
      "logits/chosen": -2.6440675258636475,
      "logits/rejected": -2.37406849861145,
      "logps/chosen": -57.05372619628906,
      "logps/rejected": -68.3302001953125,
      "loss": 0.1194,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.997530996799469,
      "rewards/margins": 2.4417471885681152,
      "rewards/rejected": -1.444216251373291,
      "step": 1233
    },
    {
      "epoch": 0.4936,
      "grad_norm": 6.087475299835205,
      "learning_rate": 8.356e-07,
      "logits/chosen": -2.887138843536377,
      "logits/rejected": -2.603940010070801,
      "logps/chosen": -69.44164276123047,
      "logps/rejected": -32.1759033203125,
      "loss": 0.143,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4450680017471313,
      "rewards/margins": 2.1780872344970703,
      "rewards/rejected": -0.7330193519592285,
      "step": 1234
    },
    {
      "epoch": 0.494,
      "grad_norm": 4.0810136795043945,
      "learning_rate": 8.354666666666667e-07,
      "logits/chosen": -2.591313123703003,
      "logits/rejected": -2.224092960357666,
      "logps/chosen": -46.61328125,
      "logps/rejected": -57.354827880859375,
      "loss": 0.1235,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0504496097564697,
      "rewards/margins": 2.1256065368652344,
      "rewards/rejected": -1.075156807899475,
      "step": 1235
    },
    {
      "epoch": 0.4944,
      "grad_norm": 2.1269636154174805,
      "learning_rate": 8.353333333333334e-07,
      "logits/chosen": -2.5365729331970215,
      "logits/rejected": -2.183861017227173,
      "logps/chosen": -94.76338195800781,
      "logps/rejected": -135.20458984375,
      "loss": 0.0482,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9074245691299438,
      "rewards/margins": 3.4570388793945312,
      "rewards/rejected": -1.549614429473877,
      "step": 1236
    },
    {
      "epoch": 0.4948,
      "grad_norm": 1.7185982465744019,
      "learning_rate": 8.352000000000001e-07,
      "logits/chosen": -2.6250264644622803,
      "logits/rejected": -2.3006112575531006,
      "logps/chosen": -55.7026481628418,
      "logps/rejected": -100.21272277832031,
      "loss": 0.0405,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6389732360839844,
      "rewards/margins": 3.312971591949463,
      "rewards/rejected": -1.6739983558654785,
      "step": 1237
    },
    {
      "epoch": 0.4952,
      "grad_norm": 3.922053098678589,
      "learning_rate": 8.350666666666665e-07,
      "logits/chosen": -2.733034610748291,
      "logits/rejected": -2.3640215396881104,
      "logps/chosen": -72.28245544433594,
      "logps/rejected": -68.11895751953125,
      "loss": 0.1304,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0160869359970093,
      "rewards/margins": 2.62971830368042,
      "rewards/rejected": -1.613631248474121,
      "step": 1238
    },
    {
      "epoch": 0.4956,
      "grad_norm": 4.669595718383789,
      "learning_rate": 8.349333333333332e-07,
      "logits/chosen": -2.554185628890991,
      "logits/rejected": -2.197066068649292,
      "logps/chosen": -106.91239929199219,
      "logps/rejected": -66.7581787109375,
      "loss": 0.1179,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7920387387275696,
      "rewards/margins": 2.3314526081085205,
      "rewards/rejected": -1.5394139289855957,
      "step": 1239
    },
    {
      "epoch": 0.496,
      "grad_norm": 1.3529354333877563,
      "learning_rate": 8.347999999999999e-07,
      "logits/chosen": -2.688192129135132,
      "logits/rejected": -1.9964041709899902,
      "logps/chosen": -84.99261474609375,
      "logps/rejected": -102.46649169921875,
      "loss": 0.0199,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3002864122390747,
      "rewards/margins": 4.043844223022461,
      "rewards/rejected": -2.743557929992676,
      "step": 1240
    },
    {
      "epoch": 0.4964,
      "grad_norm": 5.418173789978027,
      "learning_rate": 8.346666666666666e-07,
      "logits/chosen": -2.964691162109375,
      "logits/rejected": -2.5704262256622314,
      "logps/chosen": -75.33380889892578,
      "logps/rejected": -74.63795471191406,
      "loss": 0.1165,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2416197061538696,
      "rewards/margins": 2.4086928367614746,
      "rewards/rejected": -1.1670730113983154,
      "step": 1241
    },
    {
      "epoch": 0.4968,
      "grad_norm": 2.0021750926971436,
      "learning_rate": 8.345333333333333e-07,
      "logits/chosen": -2.6088171005249023,
      "logits/rejected": -2.0038952827453613,
      "logps/chosen": -48.278202056884766,
      "logps/rejected": -71.78770446777344,
      "loss": 0.0554,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1770199537277222,
      "rewards/margins": 2.986647844314575,
      "rewards/rejected": -1.8096280097961426,
      "step": 1242
    },
    {
      "epoch": 0.4972,
      "grad_norm": 1.8775322437286377,
      "learning_rate": 8.344e-07,
      "logits/chosen": -2.7041516304016113,
      "logits/rejected": -2.054547071456909,
      "logps/chosen": -93.28932189941406,
      "logps/rejected": -114.98644256591797,
      "loss": 0.0296,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4831234216690063,
      "rewards/margins": 3.5454330444335938,
      "rewards/rejected": -2.062309741973877,
      "step": 1243
    },
    {
      "epoch": 0.4976,
      "grad_norm": 7.9671783447265625,
      "learning_rate": 8.342666666666667e-07,
      "logits/chosen": -2.5789542198181152,
      "logits/rejected": -2.552731513977051,
      "logps/chosen": -117.07007598876953,
      "logps/rejected": -69.11161804199219,
      "loss": 0.2133,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08629035949707031,
      "rewards/margins": 1.4856523275375366,
      "rewards/rejected": -1.571942687034607,
      "step": 1244
    },
    {
      "epoch": 0.498,
      "grad_norm": 4.396586894989014,
      "learning_rate": 8.341333333333333e-07,
      "logits/chosen": -2.4505457878112793,
      "logits/rejected": -2.115156650543213,
      "logps/chosen": -86.31188201904297,
      "logps/rejected": -86.71211242675781,
      "loss": 0.1228,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1486148834228516,
      "rewards/margins": 2.522975444793701,
      "rewards/rejected": -1.3743605613708496,
      "step": 1245
    },
    {
      "epoch": 0.4984,
      "grad_norm": 1.4587758779525757,
      "learning_rate": 8.34e-07,
      "logits/chosen": -2.4696455001831055,
      "logits/rejected": -1.9636313915252686,
      "logps/chosen": -90.76739501953125,
      "logps/rejected": -84.25228881835938,
      "loss": 0.0332,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6137351989746094,
      "rewards/margins": 3.4066848754882812,
      "rewards/rejected": -1.7929496765136719,
      "step": 1246
    },
    {
      "epoch": 0.4988,
      "grad_norm": 6.8762898445129395,
      "learning_rate": 8.338666666666666e-07,
      "logits/chosen": -2.4828405380249023,
      "logits/rejected": -2.5328943729400635,
      "logps/chosen": -66.84890747070312,
      "logps/rejected": -39.98443603515625,
      "loss": 0.2088,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7672214508056641,
      "rewards/margins": 1.490828514099121,
      "rewards/rejected": -0.7236069440841675,
      "step": 1247
    },
    {
      "epoch": 0.4992,
      "grad_norm": 2.8454980850219727,
      "learning_rate": 8.337333333333333e-07,
      "logits/chosen": -2.9397873878479004,
      "logits/rejected": -2.4950637817382812,
      "logps/chosen": -56.47815704345703,
      "logps/rejected": -70.9207763671875,
      "loss": 0.0567,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7656444907188416,
      "rewards/margins": 2.995398759841919,
      "rewards/rejected": -2.2297542095184326,
      "step": 1248
    },
    {
      "epoch": 0.4996,
      "grad_norm": 4.375667095184326,
      "learning_rate": 8.335999999999999e-07,
      "logits/chosen": -2.9708328247070312,
      "logits/rejected": -2.5323996543884277,
      "logps/chosen": -49.49968719482422,
      "logps/rejected": -81.41658782958984,
      "loss": 0.1,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9877951145172119,
      "rewards/margins": 2.3252458572387695,
      "rewards/rejected": -1.3374507427215576,
      "step": 1249
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.7388863563537598,
      "learning_rate": 8.334666666666666e-07,
      "logits/chosen": -2.522832155227661,
      "logits/rejected": -2.219108819961548,
      "logps/chosen": -81.55233001708984,
      "logps/rejected": -93.66654968261719,
      "loss": 0.0649,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3257662057876587,
      "rewards/margins": 3.3969829082489014,
      "rewards/rejected": -2.071216583251953,
      "step": 1250
    },
    {
      "epoch": 0.5004,
      "grad_norm": 3.3240950107574463,
      "learning_rate": 8.333333333333333e-07,
      "logits/chosen": -2.731590986251831,
      "logits/rejected": -2.0861175060272217,
      "logps/chosen": -70.47555541992188,
      "logps/rejected": -52.41518020629883,
      "loss": 0.0613,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4317104816436768,
      "rewards/margins": 3.1169614791870117,
      "rewards/rejected": -1.685251235961914,
      "step": 1251
    },
    {
      "epoch": 0.5008,
      "grad_norm": 6.655162811279297,
      "learning_rate": 8.332e-07,
      "logits/chosen": -2.4627444744110107,
      "logits/rejected": -2.2254514694213867,
      "logps/chosen": -147.73703002929688,
      "logps/rejected": -64.74683380126953,
      "loss": 0.1683,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6330524682998657,
      "rewards/margins": 1.7515681982040405,
      "rewards/rejected": -1.1185157299041748,
      "step": 1252
    },
    {
      "epoch": 0.5012,
      "grad_norm": 3.74989652633667,
      "learning_rate": 8.330666666666666e-07,
      "logits/chosen": -2.6886391639709473,
      "logits/rejected": -2.2750723361968994,
      "logps/chosen": -92.97197723388672,
      "logps/rejected": -79.36669158935547,
      "loss": 0.0624,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25954627990722656,
      "rewards/margins": 2.955183982849121,
      "rewards/rejected": -2.6956377029418945,
      "step": 1253
    },
    {
      "epoch": 0.5016,
      "grad_norm": 3.566894292831421,
      "learning_rate": 8.329333333333333e-07,
      "logits/chosen": -2.9820337295532227,
      "logits/rejected": -2.366018533706665,
      "logps/chosen": -59.320884704589844,
      "logps/rejected": -71.20814514160156,
      "loss": 0.0818,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7250242829322815,
      "rewards/margins": 2.9891164302825928,
      "rewards/rejected": -2.264091968536377,
      "step": 1254
    },
    {
      "epoch": 0.502,
      "grad_norm": 4.389764785766602,
      "learning_rate": 8.328e-07,
      "logits/chosen": -2.9139065742492676,
      "logits/rejected": -2.918917655944824,
      "logps/chosen": -54.96652603149414,
      "logps/rejected": -43.33830261230469,
      "loss": 0.1142,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9920310974121094,
      "rewards/margins": 2.3722829818725586,
      "rewards/rejected": -1.3802517652511597,
      "step": 1255
    },
    {
      "epoch": 0.5024,
      "grad_norm": 2.911543369293213,
      "learning_rate": 8.326666666666666e-07,
      "logits/chosen": -2.4789323806762695,
      "logits/rejected": -1.9233615398406982,
      "logps/chosen": -132.1672821044922,
      "logps/rejected": -116.1150131225586,
      "loss": 0.0384,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4951962232589722,
      "rewards/margins": 3.325594902038574,
      "rewards/rejected": -1.8303985595703125,
      "step": 1256
    },
    {
      "epoch": 0.5028,
      "grad_norm": 1.2104606628417969,
      "learning_rate": 8.325333333333333e-07,
      "logits/chosen": -2.6805098056793213,
      "logits/rejected": -1.9749886989593506,
      "logps/chosen": -49.44932556152344,
      "logps/rejected": -83.70857238769531,
      "loss": 0.0213,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6944401264190674,
      "rewards/margins": 4.110639572143555,
      "rewards/rejected": -2.4161996841430664,
      "step": 1257
    },
    {
      "epoch": 0.5032,
      "grad_norm": 1.8760528564453125,
      "learning_rate": 8.324e-07,
      "logits/chosen": -2.5889928340911865,
      "logits/rejected": -2.0574846267700195,
      "logps/chosen": -108.6655044555664,
      "logps/rejected": -106.86711120605469,
      "loss": 0.0357,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8268852233886719,
      "rewards/margins": 3.382249355316162,
      "rewards/rejected": -2.5553641319274902,
      "step": 1258
    },
    {
      "epoch": 0.5036,
      "grad_norm": 2.2852554321289062,
      "learning_rate": 8.322666666666667e-07,
      "logits/chosen": -2.7376198768615723,
      "logits/rejected": -2.342097282409668,
      "logps/chosen": -67.45327758789062,
      "logps/rejected": -71.013916015625,
      "loss": 0.0628,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.650524377822876,
      "rewards/margins": 2.7714712619781494,
      "rewards/rejected": -2.1209468841552734,
      "step": 1259
    },
    {
      "epoch": 0.504,
      "grad_norm": 2.914109945297241,
      "learning_rate": 8.321333333333332e-07,
      "logits/chosen": -2.5105860233306885,
      "logits/rejected": -2.1867833137512207,
      "logps/chosen": -123.16436004638672,
      "logps/rejected": -79.68536376953125,
      "loss": 0.0761,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9194958209991455,
      "rewards/margins": 2.9114327430725098,
      "rewards/rejected": -1.9919369220733643,
      "step": 1260
    },
    {
      "epoch": 0.5044,
      "grad_norm": 0.9780391454696655,
      "learning_rate": 8.319999999999999e-07,
      "logits/chosen": -2.686122179031372,
      "logits/rejected": -2.1307592391967773,
      "logps/chosen": -116.09368133544922,
      "logps/rejected": -130.9449462890625,
      "loss": 0.0149,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.366614580154419,
      "rewards/margins": 4.2106757164001465,
      "rewards/rejected": -2.8440613746643066,
      "step": 1261
    },
    {
      "epoch": 0.5048,
      "grad_norm": 4.579705715179443,
      "learning_rate": 8.318666666666666e-07,
      "logits/chosen": -2.8281774520874023,
      "logits/rejected": -2.7782297134399414,
      "logps/chosen": -88.23432159423828,
      "logps/rejected": -42.534400939941406,
      "loss": 0.1728,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7867881655693054,
      "rewards/margins": 1.790088415145874,
      "rewards/rejected": -1.003300428390503,
      "step": 1262
    },
    {
      "epoch": 0.5052,
      "grad_norm": 2.619816780090332,
      "learning_rate": 8.317333333333333e-07,
      "logits/chosen": -2.4552364349365234,
      "logits/rejected": -2.2598869800567627,
      "logps/chosen": -82.65193176269531,
      "logps/rejected": -97.04307556152344,
      "loss": 0.0419,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.028737783432007,
      "rewards/margins": 3.5210323333740234,
      "rewards/rejected": -1.4922947883605957,
      "step": 1263
    },
    {
      "epoch": 0.5056,
      "grad_norm": 3.979813814163208,
      "learning_rate": 8.316e-07,
      "logits/chosen": -3.0595757961273193,
      "logits/rejected": -2.4986460208892822,
      "logps/chosen": -41.34307098388672,
      "logps/rejected": -63.220726013183594,
      "loss": 0.1326,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.30765706300735474,
      "rewards/margins": 2.0540237426757812,
      "rewards/rejected": -1.7463667392730713,
      "step": 1264
    },
    {
      "epoch": 0.506,
      "grad_norm": 0.88423091173172,
      "learning_rate": 8.314666666666667e-07,
      "logits/chosen": -2.6543166637420654,
      "logits/rejected": -2.1116621494293213,
      "logps/chosen": -102.2423324584961,
      "logps/rejected": -85.2412338256836,
      "loss": 0.0166,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5797066688537598,
      "rewards/margins": 4.1382575035095215,
      "rewards/rejected": -2.5585508346557617,
      "step": 1265
    },
    {
      "epoch": 0.5064,
      "grad_norm": 3.553286552429199,
      "learning_rate": 8.313333333333333e-07,
      "logits/chosen": -2.605599880218506,
      "logits/rejected": -2.073143720626831,
      "logps/chosen": -101.42342376708984,
      "logps/rejected": -62.2342643737793,
      "loss": 0.1198,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0367244482040405,
      "rewards/margins": 2.2088122367858887,
      "rewards/rejected": -1.1720879077911377,
      "step": 1266
    },
    {
      "epoch": 0.5068,
      "grad_norm": 0.6135173439979553,
      "learning_rate": 8.312e-07,
      "logits/chosen": -2.7604012489318848,
      "logits/rejected": -1.9271175861358643,
      "logps/chosen": -83.33576965332031,
      "logps/rejected": -104.05536651611328,
      "loss": 0.0108,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9600112438201904,
      "rewards/margins": 4.532625675201416,
      "rewards/rejected": -2.5726144313812256,
      "step": 1267
    },
    {
      "epoch": 0.5072,
      "grad_norm": 4.162322521209717,
      "learning_rate": 8.310666666666666e-07,
      "logits/chosen": -2.757589340209961,
      "logits/rejected": -2.765491008758545,
      "logps/chosen": -79.68025970458984,
      "logps/rejected": -47.97135543823242,
      "loss": 0.1236,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1081234216690063,
      "rewards/margins": 2.090193271636963,
      "rewards/rejected": -0.9820698499679565,
      "step": 1268
    },
    {
      "epoch": 0.5076,
      "grad_norm": 1.3322131633758545,
      "learning_rate": 8.309333333333333e-07,
      "logits/chosen": -2.2600607872009277,
      "logits/rejected": -1.9237185716629028,
      "logps/chosen": -71.12741088867188,
      "logps/rejected": -118.90786743164062,
      "loss": 0.0208,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.533002495765686,
      "rewards/margins": 3.934980630874634,
      "rewards/rejected": -2.401978015899658,
      "step": 1269
    },
    {
      "epoch": 0.508,
      "grad_norm": 5.316807746887207,
      "learning_rate": 8.308e-07,
      "logits/chosen": -2.875426769256592,
      "logits/rejected": -2.573995590209961,
      "logps/chosen": -56.2373046875,
      "logps/rejected": -39.76915740966797,
      "loss": 0.1591,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9038753509521484,
      "rewards/margins": 1.8529459238052368,
      "rewards/rejected": -0.9490706920623779,
      "step": 1270
    },
    {
      "epoch": 0.5084,
      "grad_norm": 3.9179208278656006,
      "learning_rate": 8.306666666666666e-07,
      "logits/chosen": -2.675248146057129,
      "logits/rejected": -2.38277268409729,
      "logps/chosen": -68.00405883789062,
      "logps/rejected": -64.77375793457031,
      "loss": 0.1232,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.055616855621338,
      "rewards/margins": 2.457836866378784,
      "rewards/rejected": -1.4022200107574463,
      "step": 1271
    },
    {
      "epoch": 0.5088,
      "grad_norm": 4.859702110290527,
      "learning_rate": 8.305333333333333e-07,
      "logits/chosen": -2.546043872833252,
      "logits/rejected": -2.123074531555176,
      "logps/chosen": -92.03010559082031,
      "logps/rejected": -92.40715026855469,
      "loss": 0.0854,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8735272288322449,
      "rewards/margins": 3.267814874649048,
      "rewards/rejected": -2.394287586212158,
      "step": 1272
    },
    {
      "epoch": 0.5092,
      "grad_norm": 3.4855148792266846,
      "learning_rate": 8.304e-07,
      "logits/chosen": -2.752136707305908,
      "logits/rejected": -2.2261838912963867,
      "logps/chosen": -75.32633972167969,
      "logps/rejected": -73.98008728027344,
      "loss": 0.0821,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.376386821269989,
      "rewards/margins": 2.5106310844421387,
      "rewards/rejected": -2.134244203567505,
      "step": 1273
    },
    {
      "epoch": 0.5096,
      "grad_norm": 2.2312889099121094,
      "learning_rate": 8.302666666666667e-07,
      "logits/chosen": -2.7428460121154785,
      "logits/rejected": -2.2471585273742676,
      "logps/chosen": -116.66753387451172,
      "logps/rejected": -101.20213317871094,
      "loss": 0.0352,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.035768985748291,
      "rewards/margins": 3.3539955615997314,
      "rewards/rejected": -2.3182265758514404,
      "step": 1274
    },
    {
      "epoch": 0.51,
      "grad_norm": 3.5832276344299316,
      "learning_rate": 8.301333333333332e-07,
      "logits/chosen": -2.837355613708496,
      "logits/rejected": -2.488018274307251,
      "logps/chosen": -62.961769104003906,
      "logps/rejected": -65.56729888916016,
      "loss": 0.0934,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3862197995185852,
      "rewards/margins": 2.435722589492798,
      "rewards/rejected": -2.0495028495788574,
      "step": 1275
    },
    {
      "epoch": 0.5104,
      "grad_norm": 2.0468685626983643,
      "learning_rate": 8.299999999999999e-07,
      "logits/chosen": -2.368762969970703,
      "logits/rejected": -1.7296481132507324,
      "logps/chosen": -56.28361892700195,
      "logps/rejected": -95.37615203857422,
      "loss": 0.0358,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7652904987335205,
      "rewards/margins": 3.393476963043213,
      "rewards/rejected": -1.6281864643096924,
      "step": 1276
    },
    {
      "epoch": 0.5108,
      "grad_norm": 3.336840867996216,
      "learning_rate": 8.298666666666666e-07,
      "logits/chosen": -2.148223876953125,
      "logits/rejected": -2.057133674621582,
      "logps/chosen": -51.84518051147461,
      "logps/rejected": -115.88127136230469,
      "loss": 0.048,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1140961647033691,
      "rewards/margins": 3.017098903656006,
      "rewards/rejected": -1.9030029773712158,
      "step": 1277
    },
    {
      "epoch": 0.5112,
      "grad_norm": 1.6521286964416504,
      "learning_rate": 8.297333333333333e-07,
      "logits/chosen": -2.563170909881592,
      "logits/rejected": -1.8145263195037842,
      "logps/chosen": -153.8864288330078,
      "logps/rejected": -84.84072875976562,
      "loss": 0.0347,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5280307531356812,
      "rewards/margins": 3.344741106033325,
      "rewards/rejected": -1.8167102336883545,
      "step": 1278
    },
    {
      "epoch": 0.5116,
      "grad_norm": 6.05903959274292,
      "learning_rate": 8.296e-07,
      "logits/chosen": -2.7168807983398438,
      "logits/rejected": -2.5376029014587402,
      "logps/chosen": -64.81005859375,
      "logps/rejected": -55.54475784301758,
      "loss": 0.1447,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.753285825252533,
      "rewards/margins": 2.4312875270843506,
      "rewards/rejected": -1.6780016422271729,
      "step": 1279
    },
    {
      "epoch": 0.512,
      "grad_norm": 5.0586066246032715,
      "learning_rate": 8.294666666666667e-07,
      "logits/chosen": -2.675166130065918,
      "logits/rejected": -2.279780626296997,
      "logps/chosen": -65.0081787109375,
      "logps/rejected": -74.92647552490234,
      "loss": 0.1126,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.770434558391571,
      "rewards/margins": 2.3119616508483887,
      "rewards/rejected": -1.5415270328521729,
      "step": 1280
    },
    {
      "epoch": 0.5124,
      "grad_norm": 5.436563491821289,
      "learning_rate": 8.293333333333333e-07,
      "logits/chosen": -2.5100178718566895,
      "logits/rejected": -2.1711056232452393,
      "logps/chosen": -84.3099594116211,
      "logps/rejected": -59.980979919433594,
      "loss": 0.1596,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.605991780757904,
      "rewards/margins": 2.0717835426330566,
      "rewards/rejected": -1.4657917022705078,
      "step": 1281
    },
    {
      "epoch": 0.5128,
      "grad_norm": 4.128960132598877,
      "learning_rate": 8.292e-07,
      "logits/chosen": -2.6935367584228516,
      "logits/rejected": -2.0290181636810303,
      "logps/chosen": -83.14154052734375,
      "logps/rejected": -77.33740997314453,
      "loss": 0.0888,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1020878553390503,
      "rewards/margins": 3.4207136631011963,
      "rewards/rejected": -2.3186259269714355,
      "step": 1282
    },
    {
      "epoch": 0.5132,
      "grad_norm": 2.9617176055908203,
      "learning_rate": 8.290666666666666e-07,
      "logits/chosen": -2.7277722358703613,
      "logits/rejected": -2.0541558265686035,
      "logps/chosen": -69.3409652709961,
      "logps/rejected": -94.31137084960938,
      "loss": 0.0735,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0534372329711914,
      "rewards/margins": 2.671189308166504,
      "rewards/rejected": -1.6177523136138916,
      "step": 1283
    },
    {
      "epoch": 0.5136,
      "grad_norm": 2.9879441261291504,
      "learning_rate": 8.289333333333332e-07,
      "logits/chosen": -2.1460611820220947,
      "logits/rejected": -1.9071295261383057,
      "logps/chosen": -97.93643188476562,
      "logps/rejected": -57.85896301269531,
      "loss": 0.0868,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.629015564918518,
      "rewards/margins": 2.471345901489258,
      "rewards/rejected": -0.8423302173614502,
      "step": 1284
    },
    {
      "epoch": 0.514,
      "grad_norm": 3.05302357673645,
      "learning_rate": 8.287999999999999e-07,
      "logits/chosen": -2.588682174682617,
      "logits/rejected": -2.359823226928711,
      "logps/chosen": -66.85991668701172,
      "logps/rejected": -73.26605224609375,
      "loss": 0.0905,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9376309514045715,
      "rewards/margins": 2.9432482719421387,
      "rewards/rejected": -2.005617380142212,
      "step": 1285
    },
    {
      "epoch": 0.5144,
      "grad_norm": 2.6840877532958984,
      "learning_rate": 8.286666666666666e-07,
      "logits/chosen": -2.481975793838501,
      "logits/rejected": -2.529111623764038,
      "logps/chosen": -84.17364501953125,
      "logps/rejected": -107.67605590820312,
      "loss": 0.068,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4343719482421875,
      "rewards/margins": 2.789114475250244,
      "rewards/rejected": -1.3547425270080566,
      "step": 1286
    },
    {
      "epoch": 0.5148,
      "grad_norm": 4.33276891708374,
      "learning_rate": 8.285333333333333e-07,
      "logits/chosen": -2.379974365234375,
      "logits/rejected": -2.1068432331085205,
      "logps/chosen": -129.33575439453125,
      "logps/rejected": -97.45072937011719,
      "loss": 0.104,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8299087285995483,
      "rewards/margins": 2.212857723236084,
      "rewards/rejected": -3.042766571044922,
      "step": 1287
    },
    {
      "epoch": 0.5152,
      "grad_norm": 2.2642431259155273,
      "learning_rate": 8.284e-07,
      "logits/chosen": -2.729048252105713,
      "logits/rejected": -2.1070876121520996,
      "logps/chosen": -80.73944091796875,
      "logps/rejected": -73.46096801757812,
      "loss": 0.0434,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7373775243759155,
      "rewards/margins": 3.526292562484741,
      "rewards/rejected": -1.7889151573181152,
      "step": 1288
    },
    {
      "epoch": 0.5156,
      "grad_norm": 0.811804473400116,
      "learning_rate": 8.282666666666667e-07,
      "logits/chosen": -2.622617721557617,
      "logits/rejected": -1.8692939281463623,
      "logps/chosen": -117.52943420410156,
      "logps/rejected": -82.96733093261719,
      "loss": 0.012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4623920917510986,
      "rewards/margins": 4.474963188171387,
      "rewards/rejected": -3.012571334838867,
      "step": 1289
    },
    {
      "epoch": 0.516,
      "grad_norm": 2.182656764984131,
      "learning_rate": 8.281333333333334e-07,
      "logits/chosen": -2.708782196044922,
      "logits/rejected": -1.9574289321899414,
      "logps/chosen": -74.99098205566406,
      "logps/rejected": -74.08769226074219,
      "loss": 0.0529,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9969255328178406,
      "rewards/margins": 3.0780787467956543,
      "rewards/rejected": -2.081153154373169,
      "step": 1290
    },
    {
      "epoch": 0.5164,
      "grad_norm": 3.107844829559326,
      "learning_rate": 8.28e-07,
      "logits/chosen": -2.97743558883667,
      "logits/rejected": -2.534228801727295,
      "logps/chosen": -48.062679290771484,
      "logps/rejected": -93.88607788085938,
      "loss": 0.0706,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7091615796089172,
      "rewards/margins": 2.946290969848633,
      "rewards/rejected": -2.2371294498443604,
      "step": 1291
    },
    {
      "epoch": 0.5168,
      "grad_norm": 0.5618013143539429,
      "learning_rate": 8.278666666666666e-07,
      "logits/chosen": -2.7916390895843506,
      "logits/rejected": -2.235778570175171,
      "logps/chosen": -81.55379486083984,
      "logps/rejected": -100.83060455322266,
      "loss": 0.0102,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4480280876159668,
      "rewards/margins": 4.630541801452637,
      "rewards/rejected": -3.182513475418091,
      "step": 1292
    },
    {
      "epoch": 0.5172,
      "grad_norm": 1.3494367599487305,
      "learning_rate": 8.277333333333333e-07,
      "logits/chosen": -2.630913734436035,
      "logits/rejected": -1.9295635223388672,
      "logps/chosen": -110.3519058227539,
      "logps/rejected": -81.67292785644531,
      "loss": 0.023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6292824745178223,
      "rewards/margins": 3.767979621887207,
      "rewards/rejected": -2.1386971473693848,
      "step": 1293
    },
    {
      "epoch": 0.5176,
      "grad_norm": 5.420792102813721,
      "learning_rate": 8.275999999999999e-07,
      "logits/chosen": -2.656719207763672,
      "logits/rejected": -2.1761789321899414,
      "logps/chosen": -88.6884536743164,
      "logps/rejected": -79.17782592773438,
      "loss": 0.1177,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0607845783233643,
      "rewards/margins": 2.984145164489746,
      "rewards/rejected": -1.9233604669570923,
      "step": 1294
    },
    {
      "epoch": 0.518,
      "grad_norm": 3.8213930130004883,
      "learning_rate": 8.274666666666666e-07,
      "logits/chosen": -2.6587975025177,
      "logits/rejected": -2.7655818462371826,
      "logps/chosen": -124.11018371582031,
      "logps/rejected": -77.24505615234375,
      "loss": 0.089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7595260739326477,
      "rewards/margins": 2.444169759750366,
      "rewards/rejected": -1.6846436262130737,
      "step": 1295
    },
    {
      "epoch": 0.5184,
      "grad_norm": 2.092439651489258,
      "learning_rate": 8.273333333333333e-07,
      "logits/chosen": -2.551368236541748,
      "logits/rejected": -2.4825825691223145,
      "logps/chosen": -94.53402709960938,
      "logps/rejected": -132.63534545898438,
      "loss": 0.0371,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6015548706054688,
      "rewards/margins": 3.6021370887756348,
      "rewards/rejected": -2.000582218170166,
      "step": 1296
    },
    {
      "epoch": 0.5188,
      "grad_norm": 1.1412032842636108,
      "learning_rate": 8.272e-07,
      "logits/chosen": -2.9202418327331543,
      "logits/rejected": -2.118532180786133,
      "logps/chosen": -47.37671661376953,
      "logps/rejected": -127.1612777709961,
      "loss": 0.0178,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5921400189399719,
      "rewards/margins": 4.028137683868408,
      "rewards/rejected": -3.435997724533081,
      "step": 1297
    },
    {
      "epoch": 0.5192,
      "grad_norm": 1.60928213596344,
      "learning_rate": 8.270666666666666e-07,
      "logits/chosen": -2.4980344772338867,
      "logits/rejected": -1.9204347133636475,
      "logps/chosen": -93.54238891601562,
      "logps/rejected": -173.32582092285156,
      "loss": 0.0217,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9520206451416016,
      "rewards/margins": 4.066840171813965,
      "rewards/rejected": -2.114819288253784,
      "step": 1298
    },
    {
      "epoch": 0.5196,
      "grad_norm": 1.5844134092330933,
      "learning_rate": 8.269333333333333e-07,
      "logits/chosen": -2.812084197998047,
      "logits/rejected": -2.0193252563476562,
      "logps/chosen": -81.43879699707031,
      "logps/rejected": -87.88455963134766,
      "loss": 0.0317,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5947539806365967,
      "rewards/margins": 3.483922004699707,
      "rewards/rejected": -1.8891682624816895,
      "step": 1299
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.6635212898254395,
      "learning_rate": 8.268e-07,
      "logits/chosen": -2.6196627616882324,
      "logits/rejected": -1.9383132457733154,
      "logps/chosen": -91.44151306152344,
      "logps/rejected": -88.12311553955078,
      "loss": 0.0372,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6147994995117188,
      "rewards/margins": 3.349599599838257,
      "rewards/rejected": -1.734800100326538,
      "step": 1300
    },
    {
      "epoch": 0.5204,
      "grad_norm": 0.9136253595352173,
      "learning_rate": 8.266666666666667e-07,
      "logits/chosen": -2.4437294006347656,
      "logits/rejected": -1.9457664489746094,
      "logps/chosen": -136.8710479736328,
      "logps/rejected": -79.78857421875,
      "loss": 0.0145,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.206226348876953,
      "rewards/margins": 4.229730606079102,
      "rewards/rejected": -2.0235042572021484,
      "step": 1301
    },
    {
      "epoch": 0.5208,
      "grad_norm": 1.8167041540145874,
      "learning_rate": 8.265333333333333e-07,
      "logits/chosen": -2.8778128623962402,
      "logits/rejected": -2.235567808151245,
      "logps/chosen": -52.753631591796875,
      "logps/rejected": -96.19146728515625,
      "loss": 0.0317,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0203983783721924,
      "rewards/margins": 3.533334493637085,
      "rewards/rejected": -2.5129361152648926,
      "step": 1302
    },
    {
      "epoch": 0.5212,
      "grad_norm": 2.993710517883301,
      "learning_rate": 8.263999999999999e-07,
      "logits/chosen": -2.496041774749756,
      "logits/rejected": -2.1596455574035645,
      "logps/chosen": -104.4606704711914,
      "logps/rejected": -79.12974548339844,
      "loss": 0.0694,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9515531659126282,
      "rewards/margins": 2.671246290206909,
      "rewards/rejected": -1.7196929454803467,
      "step": 1303
    },
    {
      "epoch": 0.5216,
      "grad_norm": 1.4749796390533447,
      "learning_rate": 8.262666666666666e-07,
      "logits/chosen": -2.8491458892822266,
      "logits/rejected": -2.0031301975250244,
      "logps/chosen": -74.8507080078125,
      "logps/rejected": -107.73239135742188,
      "loss": 0.0209,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3355587124824524,
      "rewards/margins": 3.8904037475585938,
      "rewards/rejected": -3.554845094680786,
      "step": 1304
    },
    {
      "epoch": 0.522,
      "grad_norm": 6.355597019195557,
      "learning_rate": 8.261333333333333e-07,
      "logits/chosen": -2.495481252670288,
      "logits/rejected": -2.4857845306396484,
      "logps/chosen": -70.11122131347656,
      "logps/rejected": -108.07566833496094,
      "loss": 0.1984,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9520750641822815,
      "rewards/margins": 2.6812222003936768,
      "rewards/rejected": -1.72914719581604,
      "step": 1305
    },
    {
      "epoch": 0.5224,
      "grad_norm": 2.6687428951263428,
      "learning_rate": 8.259999999999999e-07,
      "logits/chosen": -2.421921968460083,
      "logits/rejected": -2.127981185913086,
      "logps/chosen": -109.92422485351562,
      "logps/rejected": -81.57262420654297,
      "loss": 0.0544,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7344002723693848,
      "rewards/margins": 2.957811117172241,
      "rewards/rejected": -1.2234110832214355,
      "step": 1306
    },
    {
      "epoch": 0.5228,
      "grad_norm": 0.6958805918693542,
      "learning_rate": 8.258666666666666e-07,
      "logits/chosen": -2.34896183013916,
      "logits/rejected": -2.2872860431671143,
      "logps/chosen": -134.91812133789062,
      "logps/rejected": -74.22219848632812,
      "loss": 0.01,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1429696083068848,
      "rewards/margins": 4.596432685852051,
      "rewards/rejected": -2.453463315963745,
      "step": 1307
    },
    {
      "epoch": 0.5232,
      "grad_norm": 1.3676589727401733,
      "learning_rate": 8.257333333333333e-07,
      "logits/chosen": -2.7457027435302734,
      "logits/rejected": -2.172079086303711,
      "logps/chosen": -54.794227600097656,
      "logps/rejected": -84.94381713867188,
      "loss": 0.0206,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2819738388061523,
      "rewards/margins": 4.386898994445801,
      "rewards/rejected": -3.1049253940582275,
      "step": 1308
    },
    {
      "epoch": 0.5236,
      "grad_norm": 2.2270007133483887,
      "learning_rate": 8.256e-07,
      "logits/chosen": -2.500349998474121,
      "logits/rejected": -2.0775134563446045,
      "logps/chosen": -58.14696502685547,
      "logps/rejected": -96.30179595947266,
      "loss": 0.0535,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2180248498916626,
      "rewards/margins": 3.129714012145996,
      "rewards/rejected": -1.911689043045044,
      "step": 1309
    },
    {
      "epoch": 0.524,
      "grad_norm": 3.4265542030334473,
      "learning_rate": 8.254666666666667e-07,
      "logits/chosen": -3.030851125717163,
      "logits/rejected": -2.279468297958374,
      "logps/chosen": -52.13067626953125,
      "logps/rejected": -75.76982879638672,
      "loss": 0.0818,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39484158158302307,
      "rewards/margins": 2.952162742614746,
      "rewards/rejected": -2.557321310043335,
      "step": 1310
    },
    {
      "epoch": 0.5244,
      "grad_norm": 1.3754992485046387,
      "learning_rate": 8.253333333333334e-07,
      "logits/chosen": -2.6637558937072754,
      "logits/rejected": -2.0757977962493896,
      "logps/chosen": -81.62748718261719,
      "logps/rejected": -62.64506912231445,
      "loss": 0.0285,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8109583854675293,
      "rewards/margins": 3.7051095962524414,
      "rewards/rejected": -1.894151210784912,
      "step": 1311
    },
    {
      "epoch": 0.5248,
      "grad_norm": 3.284599542617798,
      "learning_rate": 8.252000000000001e-07,
      "logits/chosen": -2.6012768745422363,
      "logits/rejected": -2.400556802749634,
      "logps/chosen": -63.446372985839844,
      "logps/rejected": -70.88735961914062,
      "loss": 0.0583,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.480309247970581,
      "rewards/margins": 2.8159544467926025,
      "rewards/rejected": -1.3356451988220215,
      "step": 1312
    },
    {
      "epoch": 0.5252,
      "grad_norm": 3.9183835983276367,
      "learning_rate": 8.250666666666665e-07,
      "logits/chosen": -2.78406023979187,
      "logits/rejected": -2.394601821899414,
      "logps/chosen": -93.3139877319336,
      "logps/rejected": -54.26076126098633,
      "loss": 0.0955,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1172786951065063,
      "rewards/margins": 2.5110127925872803,
      "rewards/rejected": -1.3937339782714844,
      "step": 1313
    },
    {
      "epoch": 0.5256,
      "grad_norm": 1.6245120763778687,
      "learning_rate": 8.249333333333332e-07,
      "logits/chosen": -2.7871108055114746,
      "logits/rejected": -2.284024238586426,
      "logps/chosen": -119.3758544921875,
      "logps/rejected": -87.39873504638672,
      "loss": 0.0296,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8446220755577087,
      "rewards/margins": 3.5094399452209473,
      "rewards/rejected": -2.6648178100585938,
      "step": 1314
    },
    {
      "epoch": 0.526,
      "grad_norm": 1.854775309562683,
      "learning_rate": 8.247999999999999e-07,
      "logits/chosen": -2.731431007385254,
      "logits/rejected": -2.2212507724761963,
      "logps/chosen": -77.39598846435547,
      "logps/rejected": -81.80245971679688,
      "loss": 0.0239,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0589795112609863,
      "rewards/margins": 3.7222180366516113,
      "rewards/rejected": -2.663238525390625,
      "step": 1315
    },
    {
      "epoch": 0.5264,
      "grad_norm": 1.4557020664215088,
      "learning_rate": 8.246666666666666e-07,
      "logits/chosen": -2.329289436340332,
      "logits/rejected": -1.7647855281829834,
      "logps/chosen": -144.28201293945312,
      "logps/rejected": -111.22540283203125,
      "loss": 0.0211,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5844762325286865,
      "rewards/margins": 3.860034704208374,
      "rewards/rejected": -2.2755584716796875,
      "step": 1316
    },
    {
      "epoch": 0.5268,
      "grad_norm": 1.446414589881897,
      "learning_rate": 8.245333333333333e-07,
      "logits/chosen": -2.6496386528015137,
      "logits/rejected": -2.2172727584838867,
      "logps/chosen": -94.59257507324219,
      "logps/rejected": -101.95390319824219,
      "loss": 0.0248,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2947548031806946,
      "rewards/margins": 3.767500877380371,
      "rewards/rejected": -3.472745895385742,
      "step": 1317
    },
    {
      "epoch": 0.5272,
      "grad_norm": 4.1807355880737305,
      "learning_rate": 8.244e-07,
      "logits/chosen": -2.8889994621276855,
      "logits/rejected": -2.4325432777404785,
      "logps/chosen": -79.9964599609375,
      "logps/rejected": -74.09957122802734,
      "loss": 0.0834,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33502960205078125,
      "rewards/margins": 2.592935085296631,
      "rewards/rejected": -2.2579054832458496,
      "step": 1318
    },
    {
      "epoch": 0.5276,
      "grad_norm": 5.434140682220459,
      "learning_rate": 8.242666666666667e-07,
      "logits/chosen": -3.1125974655151367,
      "logits/rejected": -2.836402416229248,
      "logps/chosen": -40.99720001220703,
      "logps/rejected": -42.11766052246094,
      "loss": 0.1679,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8252432346343994,
      "rewards/margins": 1.9568915367126465,
      "rewards/rejected": -1.131648302078247,
      "step": 1319
    },
    {
      "epoch": 0.528,
      "grad_norm": 5.2136077880859375,
      "learning_rate": 8.241333333333334e-07,
      "logits/chosen": -2.7370710372924805,
      "logits/rejected": -2.1245529651641846,
      "logps/chosen": -90.15640258789062,
      "logps/rejected": -57.00254821777344,
      "loss": 0.1044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8437719941139221,
      "rewards/margins": 2.5486021041870117,
      "rewards/rejected": -1.7048301696777344,
      "step": 1320
    },
    {
      "epoch": 0.5284,
      "grad_norm": 4.182143211364746,
      "learning_rate": 8.24e-07,
      "logits/chosen": -2.562756299972534,
      "logits/rejected": -2.282681465148926,
      "logps/chosen": -115.57696533203125,
      "logps/rejected": -56.86717987060547,
      "loss": 0.0881,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5844272375106812,
      "rewards/margins": 2.3870081901550293,
      "rewards/rejected": -1.8025809526443481,
      "step": 1321
    },
    {
      "epoch": 0.5288,
      "grad_norm": 4.326892852783203,
      "learning_rate": 8.238666666666666e-07,
      "logits/chosen": -2.880983352661133,
      "logits/rejected": -2.5566229820251465,
      "logps/chosen": -88.64093017578125,
      "logps/rejected": -58.55704879760742,
      "loss": 0.0905,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0291996002197266,
      "rewards/margins": 2.499678611755371,
      "rewards/rejected": -1.470479130744934,
      "step": 1322
    },
    {
      "epoch": 0.5292,
      "grad_norm": 4.6729559898376465,
      "learning_rate": 8.237333333333332e-07,
      "logits/chosen": -2.6927437782287598,
      "logits/rejected": -2.442812919616699,
      "logps/chosen": -99.44990539550781,
      "logps/rejected": -49.863807678222656,
      "loss": 0.1107,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2584576606750488,
      "rewards/margins": 2.1858601570129395,
      "rewards/rejected": -0.9274024963378906,
      "step": 1323
    },
    {
      "epoch": 0.5296,
      "grad_norm": 1.4544904232025146,
      "learning_rate": 8.235999999999999e-07,
      "logits/chosen": -2.3386707305908203,
      "logits/rejected": -1.9718282222747803,
      "logps/chosen": -154.18560791015625,
      "logps/rejected": -96.40873718261719,
      "loss": 0.0225,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.312917709350586,
      "rewards/margins": 4.049500465393066,
      "rewards/rejected": -2.7365829944610596,
      "step": 1324
    },
    {
      "epoch": 0.53,
      "grad_norm": 5.154081344604492,
      "learning_rate": 8.234666666666666e-07,
      "logits/chosen": -2.443455219268799,
      "logits/rejected": -2.0938844680786133,
      "logps/chosen": -164.44287109375,
      "logps/rejected": -63.77272415161133,
      "loss": 0.0765,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.063132405281067,
      "rewards/margins": 2.924840211868286,
      "rewards/rejected": -1.8617076873779297,
      "step": 1325
    },
    {
      "epoch": 0.5304,
      "grad_norm": 4.530820846557617,
      "learning_rate": 8.233333333333333e-07,
      "logits/chosen": -2.830204486846924,
      "logits/rejected": -2.777186155319214,
      "logps/chosen": -51.75350570678711,
      "logps/rejected": -40.002315521240234,
      "loss": 0.1442,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8158749341964722,
      "rewards/margins": 1.8657782077789307,
      "rewards/rejected": -1.0499032735824585,
      "step": 1326
    },
    {
      "epoch": 0.5308,
      "grad_norm": 1.5023020505905151,
      "learning_rate": 8.232e-07,
      "logits/chosen": -2.592435836791992,
      "logits/rejected": -1.8767063617706299,
      "logps/chosen": -122.4009780883789,
      "logps/rejected": -107.10237121582031,
      "loss": 0.0266,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.437554121017456,
      "rewards/margins": 3.6124329566955566,
      "rewards/rejected": -2.1748790740966797,
      "step": 1327
    },
    {
      "epoch": 0.5312,
      "grad_norm": 0.757851243019104,
      "learning_rate": 8.230666666666666e-07,
      "logits/chosen": -2.4561915397644043,
      "logits/rejected": -1.6944642066955566,
      "logps/chosen": -84.77442169189453,
      "logps/rejected": -183.7716522216797,
      "loss": 0.0104,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0060486793518066,
      "rewards/margins": 4.857913494110107,
      "rewards/rejected": -2.851864814758301,
      "step": 1328
    },
    {
      "epoch": 0.5316,
      "grad_norm": 7.0799479484558105,
      "learning_rate": 8.229333333333333e-07,
      "logits/chosen": -2.3488175868988037,
      "logits/rejected": -2.1170244216918945,
      "logps/chosen": -206.73106384277344,
      "logps/rejected": -116.70909118652344,
      "loss": 0.1212,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7536346316337585,
      "rewards/margins": 2.5495972633361816,
      "rewards/rejected": -1.7959625720977783,
      "step": 1329
    },
    {
      "epoch": 0.532,
      "grad_norm": 2.416437864303589,
      "learning_rate": 8.228e-07,
      "logits/chosen": -2.471630811691284,
      "logits/rejected": -2.377957820892334,
      "logps/chosen": -103.50096893310547,
      "logps/rejected": -109.25839233398438,
      "loss": 0.0466,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.991828203201294,
      "rewards/margins": 3.043707847595215,
      "rewards/rejected": -2.0518798828125,
      "step": 1330
    },
    {
      "epoch": 0.5324,
      "grad_norm": 1.043546438217163,
      "learning_rate": 8.226666666666666e-07,
      "logits/chosen": -2.570265531539917,
      "logits/rejected": -1.6373040676116943,
      "logps/chosen": -86.26551818847656,
      "logps/rejected": -76.31303405761719,
      "loss": 0.0206,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.34564208984375,
      "rewards/margins": 3.882262706756592,
      "rewards/rejected": -1.5366207361221313,
      "step": 1331
    },
    {
      "epoch": 0.5328,
      "grad_norm": 9.432662963867188,
      "learning_rate": 8.225333333333333e-07,
      "logits/chosen": -2.9168217182159424,
      "logits/rejected": -2.847900390625,
      "logps/chosen": -127.67205047607422,
      "logps/rejected": -60.05413055419922,
      "loss": 0.2148,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34834060072898865,
      "rewards/margins": 1.6810184717178345,
      "rewards/rejected": -1.3326778411865234,
      "step": 1332
    },
    {
      "epoch": 0.5332,
      "grad_norm": 1.0946753025054932,
      "learning_rate": 8.224e-07,
      "logits/chosen": -2.6413097381591797,
      "logits/rejected": -1.8480069637298584,
      "logps/chosen": -69.29888916015625,
      "logps/rejected": -104.30886840820312,
      "loss": 0.0222,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4229599237442017,
      "rewards/margins": 3.8734850883483887,
      "rewards/rejected": -2.4505248069763184,
      "step": 1333
    },
    {
      "epoch": 0.5336,
      "grad_norm": 5.543163299560547,
      "learning_rate": 8.222666666666666e-07,
      "logits/chosen": -2.807835102081299,
      "logits/rejected": -2.439138174057007,
      "logps/chosen": -53.52289962768555,
      "logps/rejected": -89.85812377929688,
      "loss": 0.1462,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.198506161570549,
      "rewards/margins": 2.2836694717407227,
      "rewards/rejected": -2.085163116455078,
      "step": 1334
    },
    {
      "epoch": 0.534,
      "grad_norm": 3.9512102603912354,
      "learning_rate": 8.221333333333333e-07,
      "logits/chosen": -3.0200204849243164,
      "logits/rejected": -2.4501914978027344,
      "logps/chosen": -66.3905029296875,
      "logps/rejected": -77.38777160644531,
      "loss": 0.0795,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6910238265991211,
      "rewards/margins": 3.445078134536743,
      "rewards/rejected": -2.754054307937622,
      "step": 1335
    },
    {
      "epoch": 0.5344,
      "grad_norm": 1.7344175577163696,
      "learning_rate": 8.219999999999999e-07,
      "logits/chosen": -2.2709126472473145,
      "logits/rejected": -1.8168854713439941,
      "logps/chosen": -138.3464813232422,
      "logps/rejected": -93.53988647460938,
      "loss": 0.0257,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.044008255004883,
      "rewards/margins": 3.9500296115875244,
      "rewards/rejected": -1.9060211181640625,
      "step": 1336
    },
    {
      "epoch": 0.5348,
      "grad_norm": 1.902968168258667,
      "learning_rate": 8.218666666666666e-07,
      "logits/chosen": -2.430309295654297,
      "logits/rejected": -1.9295507669448853,
      "logps/chosen": -101.8927001953125,
      "logps/rejected": -70.2757339477539,
      "loss": 0.0398,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.572950839996338,
      "rewards/margins": 3.704345703125,
      "rewards/rejected": -2.131394863128662,
      "step": 1337
    },
    {
      "epoch": 0.5352,
      "grad_norm": 2.7488455772399902,
      "learning_rate": 8.217333333333333e-07,
      "logits/chosen": -2.939338445663452,
      "logits/rejected": -2.4143528938293457,
      "logps/chosen": -53.744693756103516,
      "logps/rejected": -60.64386749267578,
      "loss": 0.0551,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6482370495796204,
      "rewards/margins": 3.066497802734375,
      "rewards/rejected": -2.4182608127593994,
      "step": 1338
    },
    {
      "epoch": 0.5356,
      "grad_norm": 1.3763477802276611,
      "learning_rate": 8.216e-07,
      "logits/chosen": -2.6833670139312744,
      "logits/rejected": -2.145078420639038,
      "logps/chosen": -85.21746063232422,
      "logps/rejected": -87.87461853027344,
      "loss": 0.02,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7268486022949219,
      "rewards/margins": 3.9327969551086426,
      "rewards/rejected": -3.2059483528137207,
      "step": 1339
    },
    {
      "epoch": 0.536,
      "grad_norm": 0.7281699776649475,
      "learning_rate": 8.214666666666667e-07,
      "logits/chosen": -2.497645378112793,
      "logits/rejected": -2.2494659423828125,
      "logps/chosen": -102.88043212890625,
      "logps/rejected": -103.13923645019531,
      "loss": 0.0084,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.336775541305542,
      "rewards/margins": 4.775516510009766,
      "rewards/rejected": -2.4387407302856445,
      "step": 1340
    },
    {
      "epoch": 0.5364,
      "grad_norm": 3.2520558834075928,
      "learning_rate": 8.213333333333333e-07,
      "logits/chosen": -2.8553824424743652,
      "logits/rejected": -2.563983678817749,
      "logps/chosen": -55.362117767333984,
      "logps/rejected": -80.87142944335938,
      "loss": 0.0646,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3909628987312317,
      "rewards/margins": 2.72931170463562,
      "rewards/rejected": -2.338348865509033,
      "step": 1341
    },
    {
      "epoch": 0.5368,
      "grad_norm": 2.548887014389038,
      "learning_rate": 8.212e-07,
      "logits/chosen": -3.0944864749908447,
      "logits/rejected": -2.6211705207824707,
      "logps/chosen": -49.855674743652344,
      "logps/rejected": -75.21561431884766,
      "loss": 0.0483,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6741842031478882,
      "rewards/margins": 3.1345818042755127,
      "rewards/rejected": -2.460397720336914,
      "step": 1342
    },
    {
      "epoch": 0.5372,
      "grad_norm": 1.7894657850265503,
      "learning_rate": 8.210666666666666e-07,
      "logits/chosen": -2.651489734649658,
      "logits/rejected": -2.40517520904541,
      "logps/chosen": -82.90982055664062,
      "logps/rejected": -77.00994110107422,
      "loss": 0.0467,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5655262470245361,
      "rewards/margins": 3.5944461822509766,
      "rewards/rejected": -2.0289201736450195,
      "step": 1343
    },
    {
      "epoch": 0.5376,
      "grad_norm": 3.619957447052002,
      "learning_rate": 8.209333333333332e-07,
      "logits/chosen": -2.8299858570098877,
      "logits/rejected": -2.413405418395996,
      "logps/chosen": -115.00703430175781,
      "logps/rejected": -83.1578369140625,
      "loss": 0.0907,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.622998058795929,
      "rewards/margins": 2.899724006652832,
      "rewards/rejected": -2.276726007461548,
      "step": 1344
    },
    {
      "epoch": 0.538,
      "grad_norm": 0.8933003544807434,
      "learning_rate": 8.207999999999999e-07,
      "logits/chosen": -2.8840229511260986,
      "logits/rejected": -2.4870738983154297,
      "logps/chosen": -81.64053344726562,
      "logps/rejected": -89.8852310180664,
      "loss": 0.0167,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8332836627960205,
      "rewards/margins": 4.256950855255127,
      "rewards/rejected": -3.4236671924591064,
      "step": 1345
    },
    {
      "epoch": 0.5384,
      "grad_norm": 4.670989990234375,
      "learning_rate": 8.206666666666666e-07,
      "logits/chosen": -2.8304152488708496,
      "logits/rejected": -2.2949438095092773,
      "logps/chosen": -83.73336791992188,
      "logps/rejected": -76.26792907714844,
      "loss": 0.1041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07769469916820526,
      "rewards/margins": 2.2260382175445557,
      "rewards/rejected": -2.148343563079834,
      "step": 1346
    },
    {
      "epoch": 0.5388,
      "grad_norm": 5.561738967895508,
      "learning_rate": 8.205333333333333e-07,
      "logits/chosen": -3.055811882019043,
      "logits/rejected": -2.7438364028930664,
      "logps/chosen": -64.98512268066406,
      "logps/rejected": -48.450889587402344,
      "loss": 0.1541,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5982145071029663,
      "rewards/margins": 2.0832695960998535,
      "rewards/rejected": -1.4850549697875977,
      "step": 1347
    },
    {
      "epoch": 0.5392,
      "grad_norm": 1.4990900754928589,
      "learning_rate": 8.204e-07,
      "logits/chosen": -2.662590980529785,
      "logits/rejected": -2.3470659255981445,
      "logps/chosen": -74.20005798339844,
      "logps/rejected": -197.23944091796875,
      "loss": 0.0187,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4218307733535767,
      "rewards/margins": 4.944250106811523,
      "rewards/rejected": -3.5224194526672363,
      "step": 1348
    },
    {
      "epoch": 0.5396,
      "grad_norm": 0.7656073570251465,
      "learning_rate": 8.202666666666667e-07,
      "logits/chosen": -2.8012850284576416,
      "logits/rejected": -1.9980273246765137,
      "logps/chosen": -54.12283706665039,
      "logps/rejected": -101.6106948852539,
      "loss": 0.0151,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.518396258354187,
      "rewards/margins": 4.264918327331543,
      "rewards/rejected": -2.7465219497680664,
      "step": 1349
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.3109922409057617,
      "learning_rate": 8.201333333333333e-07,
      "logits/chosen": -2.8013675212860107,
      "logits/rejected": -2.3707971572875977,
      "logps/chosen": -77.13407897949219,
      "logps/rejected": -72.35484313964844,
      "loss": 0.0714,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0353152751922607,
      "rewards/margins": 3.5555419921875,
      "rewards/rejected": -2.5202267169952393,
      "step": 1350
    },
    {
      "epoch": 0.5404,
      "grad_norm": 4.822047710418701,
      "learning_rate": 8.199999999999999e-07,
      "logits/chosen": -2.548689365386963,
      "logits/rejected": -2.265565872192383,
      "logps/chosen": -71.8478775024414,
      "logps/rejected": -73.91647338867188,
      "loss": 0.1159,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9143207669258118,
      "rewards/margins": 2.590404748916626,
      "rewards/rejected": -1.676084041595459,
      "step": 1351
    },
    {
      "epoch": 0.5408,
      "grad_norm": 1.4948152303695679,
      "learning_rate": 8.198666666666666e-07,
      "logits/chosen": -2.726088285446167,
      "logits/rejected": -2.3340744972229004,
      "logps/chosen": -69.86048889160156,
      "logps/rejected": -79.32318115234375,
      "loss": 0.0264,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2391341924667358,
      "rewards/margins": 4.007223129272461,
      "rewards/rejected": -2.7680890560150146,
      "step": 1352
    },
    {
      "epoch": 0.5412,
      "grad_norm": 1.6716926097869873,
      "learning_rate": 8.197333333333333e-07,
      "logits/chosen": -2.5278313159942627,
      "logits/rejected": -2.2356221675872803,
      "logps/chosen": -85.24765014648438,
      "logps/rejected": -73.3515396118164,
      "loss": 0.0302,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.390156626701355,
      "rewards/margins": 3.504972219467163,
      "rewards/rejected": -2.1148154735565186,
      "step": 1353
    },
    {
      "epoch": 0.5416,
      "grad_norm": 2.0024306774139404,
      "learning_rate": 8.196e-07,
      "logits/chosen": -2.662679672241211,
      "logits/rejected": -2.2772603034973145,
      "logps/chosen": -97.45892333984375,
      "logps/rejected": -122.16655731201172,
      "loss": 0.0369,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4560261964797974,
      "rewards/margins": 3.665487051010132,
      "rewards/rejected": -2.209460735321045,
      "step": 1354
    },
    {
      "epoch": 0.542,
      "grad_norm": 2.5648956298828125,
      "learning_rate": 8.194666666666666e-07,
      "logits/chosen": -3.020677089691162,
      "logits/rejected": -2.473222255706787,
      "logps/chosen": -51.02899932861328,
      "logps/rejected": -62.31427764892578,
      "loss": 0.0476,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1201331615447998,
      "rewards/margins": 3.133978843688965,
      "rewards/rejected": -2.013845682144165,
      "step": 1355
    },
    {
      "epoch": 0.5424,
      "grad_norm": 2.333096981048584,
      "learning_rate": 8.193333333333333e-07,
      "logits/chosen": -3.0543203353881836,
      "logits/rejected": -2.5166068077087402,
      "logps/chosen": -45.09162139892578,
      "logps/rejected": -53.863887786865234,
      "loss": 0.0517,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9973418712615967,
      "rewards/margins": 2.9659409523010254,
      "rewards/rejected": -1.9685990810394287,
      "step": 1356
    },
    {
      "epoch": 0.5428,
      "grad_norm": 2.3853096961975098,
      "learning_rate": 8.192e-07,
      "logits/chosen": -2.884207248687744,
      "logits/rejected": -2.514326572418213,
      "logps/chosen": -84.25454711914062,
      "logps/rejected": -59.80731964111328,
      "loss": 0.0511,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9167938232421875,
      "rewards/margins": 3.0689070224761963,
      "rewards/rejected": -2.152113199234009,
      "step": 1357
    },
    {
      "epoch": 0.5432,
      "grad_norm": 2.555741786956787,
      "learning_rate": 8.190666666666667e-07,
      "logits/chosen": -2.570608139038086,
      "logits/rejected": -2.214954376220703,
      "logps/chosen": -58.75233459472656,
      "logps/rejected": -84.57139587402344,
      "loss": 0.063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.399680733680725,
      "rewards/margins": 2.906050443649292,
      "rewards/rejected": -1.5063698291778564,
      "step": 1358
    },
    {
      "epoch": 0.5436,
      "grad_norm": 2.5258500576019287,
      "learning_rate": 8.189333333333332e-07,
      "logits/chosen": -2.819124221801758,
      "logits/rejected": -2.547835350036621,
      "logps/chosen": -62.615135192871094,
      "logps/rejected": -65.36795043945312,
      "loss": 0.0596,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2751209735870361,
      "rewards/margins": 2.790736198425293,
      "rewards/rejected": -1.5156151056289673,
      "step": 1359
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.8240275979042053,
      "learning_rate": 8.187999999999999e-07,
      "logits/chosen": -2.3497347831726074,
      "logits/rejected": -2.1314899921417236,
      "logps/chosen": -114.98910522460938,
      "logps/rejected": -152.25070190429688,
      "loss": 0.0097,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7717869281768799,
      "rewards/margins": 5.37291145324707,
      "rewards/rejected": -3.6011245250701904,
      "step": 1360
    },
    {
      "epoch": 0.5444,
      "grad_norm": 3.6881911754608154,
      "learning_rate": 8.186666666666666e-07,
      "logits/chosen": -2.9442105293273926,
      "logits/rejected": -2.6263325214385986,
      "logps/chosen": -67.53935241699219,
      "logps/rejected": -65.17937469482422,
      "loss": 0.0805,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9919185638427734,
      "rewards/margins": 2.5003597736358643,
      "rewards/rejected": -1.5084412097930908,
      "step": 1361
    },
    {
      "epoch": 0.5448,
      "grad_norm": 6.3621039390563965,
      "learning_rate": 8.185333333333333e-07,
      "logits/chosen": -2.6551523208618164,
      "logits/rejected": -2.4317684173583984,
      "logps/chosen": -58.17863845825195,
      "logps/rejected": -43.20036697387695,
      "loss": 0.1293,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6204849481582642,
      "rewards/margins": 2.1253130435943604,
      "rewards/rejected": -1.5048279762268066,
      "step": 1362
    },
    {
      "epoch": 0.5452,
      "grad_norm": 4.246640682220459,
      "learning_rate": 8.184e-07,
      "logits/chosen": -2.8065223693847656,
      "logits/rejected": -2.636859893798828,
      "logps/chosen": -123.28131103515625,
      "logps/rejected": -72.35076141357422,
      "loss": 0.0763,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9297336339950562,
      "rewards/margins": 3.191681146621704,
      "rewards/rejected": -2.2619473934173584,
      "step": 1363
    },
    {
      "epoch": 0.5456,
      "grad_norm": 1.0400961637496948,
      "learning_rate": 8.182666666666667e-07,
      "logits/chosen": -2.898033618927002,
      "logits/rejected": -2.2339611053466797,
      "logps/chosen": -55.67237091064453,
      "logps/rejected": -92.00086212158203,
      "loss": 0.0185,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2130541801452637,
      "rewards/margins": 3.9890570640563965,
      "rewards/rejected": -2.776002883911133,
      "step": 1364
    },
    {
      "epoch": 0.546,
      "grad_norm": 2.6170973777770996,
      "learning_rate": 8.181333333333334e-07,
      "logits/chosen": -2.830437660217285,
      "logits/rejected": -2.3399930000305176,
      "logps/chosen": -90.68359375,
      "logps/rejected": -74.10769653320312,
      "loss": 0.0458,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1689316034317017,
      "rewards/margins": 3.235919952392578,
      "rewards/rejected": -2.066988468170166,
      "step": 1365
    },
    {
      "epoch": 0.5464,
      "grad_norm": 1.8653184175491333,
      "learning_rate": 8.179999999999999e-07,
      "logits/chosen": -2.2043404579162598,
      "logits/rejected": -1.7972331047058105,
      "logps/chosen": -127.82386779785156,
      "logps/rejected": -155.8286590576172,
      "loss": 0.0237,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8484535217285156,
      "rewards/margins": 4.306962966918945,
      "rewards/rejected": -2.4585092067718506,
      "step": 1366
    },
    {
      "epoch": 0.5468,
      "grad_norm": 2.9998300075531006,
      "learning_rate": 8.178666666666666e-07,
      "logits/chosen": -2.6748123168945312,
      "logits/rejected": -2.2740743160247803,
      "logps/chosen": -79.14787292480469,
      "logps/rejected": -80.54450988769531,
      "loss": 0.0536,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32041245698928833,
      "rewards/margins": 3.0065932273864746,
      "rewards/rejected": -2.686180591583252,
      "step": 1367
    },
    {
      "epoch": 0.5472,
      "grad_norm": 3.9335618019104004,
      "learning_rate": 8.177333333333333e-07,
      "logits/chosen": -2.7006256580352783,
      "logits/rejected": -2.237670421600342,
      "logps/chosen": -127.52288818359375,
      "logps/rejected": -92.19340515136719,
      "loss": 0.0855,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7459938526153564,
      "rewards/margins": 3.038792610168457,
      "rewards/rejected": -2.2927987575531006,
      "step": 1368
    },
    {
      "epoch": 0.5476,
      "grad_norm": 4.0437092781066895,
      "learning_rate": 8.175999999999999e-07,
      "logits/chosen": -2.36423921585083,
      "logits/rejected": -1.792057752609253,
      "logps/chosen": -90.91266632080078,
      "logps/rejected": -158.16262817382812,
      "loss": 0.0729,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.931403398513794,
      "rewards/margins": 3.0057730674743652,
      "rewards/rejected": -2.0743699073791504,
      "step": 1369
    },
    {
      "epoch": 0.548,
      "grad_norm": 4.139529705047607,
      "learning_rate": 8.174666666666666e-07,
      "logits/chosen": -2.8784947395324707,
      "logits/rejected": -2.5237393379211426,
      "logps/chosen": -46.087013244628906,
      "logps/rejected": -62.23670196533203,
      "loss": 0.0957,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5918434262275696,
      "rewards/margins": 2.299964427947998,
      "rewards/rejected": -1.7081210613250732,
      "step": 1370
    },
    {
      "epoch": 0.5484,
      "grad_norm": 2.4904816150665283,
      "learning_rate": 8.173333333333333e-07,
      "logits/chosen": -2.7207791805267334,
      "logits/rejected": -2.1283345222473145,
      "logps/chosen": -74.56867980957031,
      "logps/rejected": -105.23802185058594,
      "loss": 0.0376,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1315947771072388,
      "rewards/margins": 3.560817003250122,
      "rewards/rejected": -2.4292221069335938,
      "step": 1371
    },
    {
      "epoch": 0.5488,
      "grad_norm": 2.339015245437622,
      "learning_rate": 8.172e-07,
      "logits/chosen": -2.8386433124542236,
      "logits/rejected": -2.355727195739746,
      "logps/chosen": -59.806968688964844,
      "logps/rejected": -73.5626220703125,
      "loss": 0.0466,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6505237817764282,
      "rewards/margins": 3.513650894165039,
      "rewards/rejected": -2.8631272315979004,
      "step": 1372
    },
    {
      "epoch": 0.5492,
      "grad_norm": 3.0623512268066406,
      "learning_rate": 8.170666666666667e-07,
      "logits/chosen": -2.351048231124878,
      "logits/rejected": -1.836146354675293,
      "logps/chosen": -133.46324157714844,
      "logps/rejected": -90.45777893066406,
      "loss": 0.0404,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1322658061981201,
      "rewards/margins": 3.6218957901000977,
      "rewards/rejected": -2.4896299839019775,
      "step": 1373
    },
    {
      "epoch": 0.5496,
      "grad_norm": 8.435561180114746,
      "learning_rate": 8.169333333333333e-07,
      "logits/chosen": -2.946789026260376,
      "logits/rejected": -2.589221954345703,
      "logps/chosen": -103.04884338378906,
      "logps/rejected": -59.331626892089844,
      "loss": 0.1375,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3328481912612915,
      "rewards/margins": 2.220181941986084,
      "rewards/rejected": -1.887333869934082,
      "step": 1374
    },
    {
      "epoch": 0.55,
      "grad_norm": 4.752422332763672,
      "learning_rate": 8.168e-07,
      "logits/chosen": -2.3862504959106445,
      "logits/rejected": -2.075530529022217,
      "logps/chosen": -88.53227996826172,
      "logps/rejected": -59.489990234375,
      "loss": 0.1169,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6158710718154907,
      "rewards/margins": 2.1252591609954834,
      "rewards/rejected": -1.5093879699707031,
      "step": 1375
    },
    {
      "epoch": 0.5504,
      "grad_norm": 2.5578858852386475,
      "learning_rate": 8.166666666666666e-07,
      "logits/chosen": -2.44136118888855,
      "logits/rejected": -1.7527143955230713,
      "logps/chosen": -144.42184448242188,
      "logps/rejected": -94.73918151855469,
      "loss": 0.0336,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.146052598953247,
      "rewards/margins": 3.5557899475097656,
      "rewards/rejected": -2.4097373485565186,
      "step": 1376
    },
    {
      "epoch": 0.5508,
      "grad_norm": 1.9577382802963257,
      "learning_rate": 8.165333333333333e-07,
      "logits/chosen": -3.048656463623047,
      "logits/rejected": -2.2973814010620117,
      "logps/chosen": -40.16067123413086,
      "logps/rejected": -55.081199645996094,
      "loss": 0.0526,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9624091982841492,
      "rewards/margins": 3.1631662845611572,
      "rewards/rejected": -2.2007570266723633,
      "step": 1377
    },
    {
      "epoch": 0.5512,
      "grad_norm": 3.276027202606201,
      "learning_rate": 8.163999999999999e-07,
      "logits/chosen": -2.8817930221557617,
      "logits/rejected": -2.683915138244629,
      "logps/chosen": -83.649169921875,
      "logps/rejected": -75.02938842773438,
      "loss": 0.0836,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6837036609649658,
      "rewards/margins": 2.4659855365753174,
      "rewards/rejected": -1.7822818756103516,
      "step": 1378
    },
    {
      "epoch": 0.5516,
      "grad_norm": 3.1028549671173096,
      "learning_rate": 8.162666666666666e-07,
      "logits/chosen": -2.9122562408447266,
      "logits/rejected": -2.5079822540283203,
      "logps/chosen": -47.17727279663086,
      "logps/rejected": -76.9608154296875,
      "loss": 0.0663,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32310354709625244,
      "rewards/margins": 2.7613110542297363,
      "rewards/rejected": -2.4382073879241943,
      "step": 1379
    },
    {
      "epoch": 0.552,
      "grad_norm": 4.11600399017334,
      "learning_rate": 8.161333333333333e-07,
      "logits/chosen": -2.739362955093384,
      "logits/rejected": -2.6046361923217773,
      "logps/chosen": -98.76429748535156,
      "logps/rejected": -69.35453033447266,
      "loss": 0.09,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8702682256698608,
      "rewards/margins": 2.869905948638916,
      "rewards/rejected": -1.9996376037597656,
      "step": 1380
    },
    {
      "epoch": 0.5524,
      "grad_norm": 2.369784355163574,
      "learning_rate": 8.159999999999999e-07,
      "logits/chosen": -2.6262707710266113,
      "logits/rejected": -2.372671365737915,
      "logps/chosen": -54.634246826171875,
      "logps/rejected": -94.2126235961914,
      "loss": 0.0562,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3835397958755493,
      "rewards/margins": 3.974565267562866,
      "rewards/rejected": -2.5910255908966064,
      "step": 1381
    },
    {
      "epoch": 0.5528,
      "grad_norm": 0.8721905946731567,
      "learning_rate": 8.158666666666666e-07,
      "logits/chosen": -2.5642151832580566,
      "logits/rejected": -2.026785373687744,
      "logps/chosen": -60.103233337402344,
      "logps/rejected": -82.82184600830078,
      "loss": 0.0155,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.621455430984497,
      "rewards/margins": 4.173893928527832,
      "rewards/rejected": -2.552438497543335,
      "step": 1382
    },
    {
      "epoch": 0.5532,
      "grad_norm": 1.7890512943267822,
      "learning_rate": 8.157333333333333e-07,
      "logits/chosen": -2.903744697570801,
      "logits/rejected": -2.29805850982666,
      "logps/chosen": -78.15736389160156,
      "logps/rejected": -98.08609008789062,
      "loss": 0.0318,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.28058966994285583,
      "rewards/margins": 3.8380322456359863,
      "rewards/rejected": -3.5574426651000977,
      "step": 1383
    },
    {
      "epoch": 0.5536,
      "grad_norm": 3.590721845626831,
      "learning_rate": 8.156e-07,
      "logits/chosen": -2.8083229064941406,
      "logits/rejected": -2.5658011436462402,
      "logps/chosen": -74.04622650146484,
      "logps/rejected": -74.42021942138672,
      "loss": 0.0685,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6456478238105774,
      "rewards/margins": 3.054379940032959,
      "rewards/rejected": -2.4087319374084473,
      "step": 1384
    },
    {
      "epoch": 0.554,
      "grad_norm": 1.6820034980773926,
      "learning_rate": 8.154666666666667e-07,
      "logits/chosen": -2.935102939605713,
      "logits/rejected": -2.2917323112487793,
      "logps/chosen": -47.48162078857422,
      "logps/rejected": -80.08041381835938,
      "loss": 0.0381,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7486303448677063,
      "rewards/margins": 3.681833028793335,
      "rewards/rejected": -2.9332027435302734,
      "step": 1385
    },
    {
      "epoch": 0.5544,
      "grad_norm": 11.399232864379883,
      "learning_rate": 8.153333333333334e-07,
      "logits/chosen": -2.9204769134521484,
      "logits/rejected": -2.5544822216033936,
      "logps/chosen": -69.37723541259766,
      "logps/rejected": -87.67852783203125,
      "loss": 0.1855,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5983794927597046,
      "rewards/margins": 1.7146766185760498,
      "rewards/rejected": -1.1162971258163452,
      "step": 1386
    },
    {
      "epoch": 0.5548,
      "grad_norm": 5.301432132720947,
      "learning_rate": 8.152e-07,
      "logits/chosen": -2.6446025371551514,
      "logits/rejected": -2.631653308868408,
      "logps/chosen": -85.6560287475586,
      "logps/rejected": -47.44199752807617,
      "loss": 0.1211,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7320545315742493,
      "rewards/margins": 2.068645477294922,
      "rewards/rejected": -1.3365907669067383,
      "step": 1387
    },
    {
      "epoch": 0.5552,
      "grad_norm": 4.092735290527344,
      "learning_rate": 8.150666666666666e-07,
      "logits/chosen": -2.917241096496582,
      "logits/rejected": -2.4254817962646484,
      "logps/chosen": -63.375240325927734,
      "logps/rejected": -56.57636642456055,
      "loss": 0.0986,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4893035888671875,
      "rewards/margins": 2.4571094512939453,
      "rewards/rejected": -1.9678058624267578,
      "step": 1388
    },
    {
      "epoch": 0.5556,
      "grad_norm": 2.6282248497009277,
      "learning_rate": 8.149333333333332e-07,
      "logits/chosen": -2.4556918144226074,
      "logits/rejected": -1.6389633417129517,
      "logps/chosen": -96.14230346679688,
      "logps/rejected": -89.82157897949219,
      "loss": 0.0558,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2936056852340698,
      "rewards/margins": 3.4570906162261963,
      "rewards/rejected": -2.163485050201416,
      "step": 1389
    },
    {
      "epoch": 0.556,
      "grad_norm": 2.84662127494812,
      "learning_rate": 8.147999999999999e-07,
      "logits/chosen": -2.5504965782165527,
      "logits/rejected": -2.4298181533813477,
      "logps/chosen": -97.88299560546875,
      "logps/rejected": -100.16781616210938,
      "loss": 0.0679,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7645962238311768,
      "rewards/margins": 2.9912452697753906,
      "rewards/rejected": -2.2266488075256348,
      "step": 1390
    },
    {
      "epoch": 0.5564,
      "grad_norm": 5.283847808837891,
      "learning_rate": 8.146666666666666e-07,
      "logits/chosen": -2.7430686950683594,
      "logits/rejected": -2.47282338142395,
      "logps/chosen": -115.12811279296875,
      "logps/rejected": -65.32189178466797,
      "loss": 0.1326,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2501625418663025,
      "rewards/margins": 2.207228660583496,
      "rewards/rejected": -1.9570660591125488,
      "step": 1391
    },
    {
      "epoch": 0.5568,
      "grad_norm": 0.7379933595657349,
      "learning_rate": 8.145333333333333e-07,
      "logits/chosen": -2.574563980102539,
      "logits/rejected": -2.185854911804199,
      "logps/chosen": -90.28457641601562,
      "logps/rejected": -131.27978515625,
      "loss": 0.0101,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1229833364486694,
      "rewards/margins": 4.648780822753906,
      "rewards/rejected": -3.5257973670959473,
      "step": 1392
    },
    {
      "epoch": 0.5572,
      "grad_norm": 2.493191957473755,
      "learning_rate": 8.144e-07,
      "logits/chosen": -2.972543478012085,
      "logits/rejected": -2.418158531188965,
      "logps/chosen": -54.86886978149414,
      "logps/rejected": -78.85328674316406,
      "loss": 0.056,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0304094552993774,
      "rewards/margins": 3.7746002674102783,
      "rewards/rejected": -2.7441906929016113,
      "step": 1393
    },
    {
      "epoch": 0.5576,
      "grad_norm": 15.714158058166504,
      "learning_rate": 8.142666666666667e-07,
      "logits/chosen": -2.638057231903076,
      "logits/rejected": -2.0616278648376465,
      "logps/chosen": -164.5955810546875,
      "logps/rejected": -79.09612274169922,
      "loss": 0.2342,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.07242658734321594,
      "rewards/margins": 1.67036771774292,
      "rewards/rejected": -1.742794394493103,
      "step": 1394
    },
    {
      "epoch": 0.558,
      "grad_norm": 2.296351194381714,
      "learning_rate": 8.141333333333334e-07,
      "logits/chosen": -2.900575637817383,
      "logits/rejected": -2.6203866004943848,
      "logps/chosen": -46.58134078979492,
      "logps/rejected": -86.73207092285156,
      "loss": 0.0343,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6764847040176392,
      "rewards/margins": 4.350583553314209,
      "rewards/rejected": -3.6740989685058594,
      "step": 1395
    },
    {
      "epoch": 0.5584,
      "grad_norm": 6.602912902832031,
      "learning_rate": 8.14e-07,
      "logits/chosen": -2.975816249847412,
      "logits/rejected": -2.606142997741699,
      "logps/chosen": -39.383365631103516,
      "logps/rejected": -60.90877914428711,
      "loss": 0.1906,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3773006498813629,
      "rewards/margins": 2.8863296508789062,
      "rewards/rejected": -2.509028911590576,
      "step": 1396
    },
    {
      "epoch": 0.5588,
      "grad_norm": 2.5928962230682373,
      "learning_rate": 8.138666666666665e-07,
      "logits/chosen": -2.553576707839966,
      "logits/rejected": -1.9648480415344238,
      "logps/chosen": -107.12457275390625,
      "logps/rejected": -111.15153503417969,
      "loss": 0.0401,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.46581345796585083,
      "rewards/margins": 3.786215305328369,
      "rewards/rejected": -3.320401668548584,
      "step": 1397
    },
    {
      "epoch": 0.5592,
      "grad_norm": 2.611659288406372,
      "learning_rate": 8.137333333333332e-07,
      "logits/chosen": -2.7556114196777344,
      "logits/rejected": -2.1822502613067627,
      "logps/chosen": -51.544288635253906,
      "logps/rejected": -69.64486694335938,
      "loss": 0.0533,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0399740934371948,
      "rewards/margins": 3.3194680213928223,
      "rewards/rejected": -2.279493808746338,
      "step": 1398
    },
    {
      "epoch": 0.5596,
      "grad_norm": 0.6157659888267517,
      "learning_rate": 8.135999999999999e-07,
      "logits/chosen": -2.3925344944000244,
      "logits/rejected": -2.2118091583251953,
      "logps/chosen": -90.34742736816406,
      "logps/rejected": -98.9985580444336,
      "loss": 0.0071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3333215713500977,
      "rewards/margins": 5.183420181274414,
      "rewards/rejected": -2.8500988483428955,
      "step": 1399
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.37039998173713684,
      "learning_rate": 8.134666666666666e-07,
      "logits/chosen": -2.668741226196289,
      "logits/rejected": -1.893247127532959,
      "logps/chosen": -107.23004150390625,
      "logps/rejected": -142.01220703125,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6499532461166382,
      "rewards/margins": 5.590761184692383,
      "rewards/rejected": -3.9408082962036133,
      "step": 1400
    },
    {
      "epoch": 0.5604,
      "grad_norm": 0.9373632073402405,
      "learning_rate": 8.133333333333333e-07,
      "logits/chosen": -2.4790608882904053,
      "logits/rejected": -1.5626883506774902,
      "logps/chosen": -131.55128479003906,
      "logps/rejected": -84.55432891845703,
      "loss": 0.0126,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.68565034866333,
      "rewards/margins": 4.369598865509033,
      "rewards/rejected": -2.683948516845703,
      "step": 1401
    },
    {
      "epoch": 0.5608,
      "grad_norm": 1.000826120376587,
      "learning_rate": 8.132e-07,
      "logits/chosen": -2.766244411468506,
      "logits/rejected": -2.4585304260253906,
      "logps/chosen": -86.15650939941406,
      "logps/rejected": -89.8831787109375,
      "loss": 0.0186,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.843253493309021,
      "rewards/margins": 4.022478103637695,
      "rewards/rejected": -3.1792244911193848,
      "step": 1402
    },
    {
      "epoch": 0.5612,
      "grad_norm": 3.517468214035034,
      "learning_rate": 8.130666666666667e-07,
      "logits/chosen": -2.8015332221984863,
      "logits/rejected": -2.634657859802246,
      "logps/chosen": -78.70867156982422,
      "logps/rejected": -71.05415344238281,
      "loss": 0.0686,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5925278067588806,
      "rewards/margins": 2.6531150341033936,
      "rewards/rejected": -2.0605874061584473,
      "step": 1403
    },
    {
      "epoch": 0.5616,
      "grad_norm": 1.8351845741271973,
      "learning_rate": 8.129333333333333e-07,
      "logits/chosen": -3.0392627716064453,
      "logits/rejected": -2.736530065536499,
      "logps/chosen": -83.58153533935547,
      "logps/rejected": -82.08860778808594,
      "loss": 0.0289,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7672936916351318,
      "rewards/margins": 5.014928817749023,
      "rewards/rejected": -3.2476348876953125,
      "step": 1404
    },
    {
      "epoch": 0.562,
      "grad_norm": 6.943952560424805,
      "learning_rate": 8.128e-07,
      "logits/chosen": -2.553893566131592,
      "logits/rejected": -1.8187440633773804,
      "logps/chosen": -106.8486099243164,
      "logps/rejected": -64.99024963378906,
      "loss": 0.0996,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.29351696372032166,
      "rewards/margins": 2.29457688331604,
      "rewards/rejected": -2.0010600090026855,
      "step": 1405
    },
    {
      "epoch": 0.5624,
      "grad_norm": 2.900561571121216,
      "learning_rate": 8.126666666666666e-07,
      "logits/chosen": -2.9036951065063477,
      "logits/rejected": -2.572580337524414,
      "logps/chosen": -53.04253005981445,
      "logps/rejected": -76.3957748413086,
      "loss": 0.0798,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45236778259277344,
      "rewards/margins": 3.052004814147949,
      "rewards/rejected": -2.599637031555176,
      "step": 1406
    },
    {
      "epoch": 0.5628,
      "grad_norm": 0.8028630614280701,
      "learning_rate": 8.125333333333333e-07,
      "logits/chosen": -2.4280123710632324,
      "logits/rejected": -1.491743564605713,
      "logps/chosen": -92.22219848632812,
      "logps/rejected": -135.802734375,
      "loss": 0.0089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0409207344055176,
      "rewards/margins": 5.188449382781982,
      "rewards/rejected": -3.147528648376465,
      "step": 1407
    },
    {
      "epoch": 0.5632,
      "grad_norm": 0.6295016407966614,
      "learning_rate": 8.123999999999999e-07,
      "logits/chosen": -2.5840611457824707,
      "logits/rejected": -1.6024799346923828,
      "logps/chosen": -91.11585235595703,
      "logps/rejected": -94.55781555175781,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2225918769836426,
      "rewards/margins": 4.93726921081543,
      "rewards/rejected": -2.714677095413208,
      "step": 1408
    },
    {
      "epoch": 0.5636,
      "grad_norm": 5.440205097198486,
      "learning_rate": 8.122666666666666e-07,
      "logits/chosen": -2.169975757598877,
      "logits/rejected": -2.205631732940674,
      "logps/chosen": -81.17139434814453,
      "logps/rejected": -50.3455924987793,
      "loss": 0.1733,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7460548281669617,
      "rewards/margins": 2.19506573677063,
      "rewards/rejected": -1.449010968208313,
      "step": 1409
    },
    {
      "epoch": 0.564,
      "grad_norm": 0.49237877130508423,
      "learning_rate": 8.121333333333333e-07,
      "logits/chosen": -2.5806221961975098,
      "logits/rejected": -1.7011504173278809,
      "logps/chosen": -98.50468444824219,
      "logps/rejected": -92.85128784179688,
      "loss": 0.0059,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7365806102752686,
      "rewards/margins": 5.162182331085205,
      "rewards/rejected": -3.4256014823913574,
      "step": 1410
    },
    {
      "epoch": 0.5644,
      "grad_norm": 2.5496103763580322,
      "learning_rate": 8.12e-07,
      "logits/chosen": -3.1795105934143066,
      "logits/rejected": -2.4508118629455566,
      "logps/chosen": -50.556114196777344,
      "logps/rejected": -94.42042541503906,
      "loss": 0.0414,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6949217319488525,
      "rewards/margins": 3.2956366539001465,
      "rewards/rejected": -2.600714921951294,
      "step": 1411
    },
    {
      "epoch": 0.5648,
      "grad_norm": 1.1272375583648682,
      "learning_rate": 8.118666666666666e-07,
      "logits/chosen": -2.5423192977905273,
      "logits/rejected": -1.8633272647857666,
      "logps/chosen": -93.51045989990234,
      "logps/rejected": -89.84019470214844,
      "loss": 0.0156,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.716761827468872,
      "rewards/margins": 4.156085968017578,
      "rewards/rejected": -2.439324378967285,
      "step": 1412
    },
    {
      "epoch": 0.5652,
      "grad_norm": 1.2408185005187988,
      "learning_rate": 8.117333333333333e-07,
      "logits/chosen": -2.6437697410583496,
      "logits/rejected": -2.294930934906006,
      "logps/chosen": -88.68798065185547,
      "logps/rejected": -99.088623046875,
      "loss": 0.0216,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3756589889526367,
      "rewards/margins": 3.834604024887085,
      "rewards/rejected": -2.4589452743530273,
      "step": 1413
    },
    {
      "epoch": 0.5656,
      "grad_norm": 0.9688474535942078,
      "learning_rate": 8.116e-07,
      "logits/chosen": -2.637786865234375,
      "logits/rejected": -1.8776546716690063,
      "logps/chosen": -99.42143249511719,
      "logps/rejected": -96.98013305664062,
      "loss": 0.0133,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.017477035522461,
      "rewards/margins": 4.399805545806885,
      "rewards/rejected": -3.382328510284424,
      "step": 1414
    },
    {
      "epoch": 0.566,
      "grad_norm": 2.8949642181396484,
      "learning_rate": 8.114666666666667e-07,
      "logits/chosen": -2.530211925506592,
      "logits/rejected": -2.1374335289001465,
      "logps/chosen": -92.50222778320312,
      "logps/rejected": -78.89047241210938,
      "loss": 0.0453,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6684422492980957,
      "rewards/margins": 3.872730016708374,
      "rewards/rejected": -2.2042877674102783,
      "step": 1415
    },
    {
      "epoch": 0.5664,
      "grad_norm": 2.2006683349609375,
      "learning_rate": 8.113333333333333e-07,
      "logits/chosen": -2.4939911365509033,
      "logits/rejected": -2.473045825958252,
      "logps/chosen": -126.76954650878906,
      "logps/rejected": -58.87134552001953,
      "loss": 0.0377,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.114782691001892,
      "rewards/margins": 3.4872970581054688,
      "rewards/rejected": -2.3725147247314453,
      "step": 1416
    },
    {
      "epoch": 0.5668,
      "grad_norm": 3.0220489501953125,
      "learning_rate": 8.112e-07,
      "logits/chosen": -2.7719998359680176,
      "logits/rejected": -2.4813199043273926,
      "logps/chosen": -53.45771789550781,
      "logps/rejected": -104.16505432128906,
      "loss": 0.0318,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0537344217300415,
      "rewards/margins": 4.231241226196289,
      "rewards/rejected": -3.177506923675537,
      "step": 1417
    },
    {
      "epoch": 0.5672,
      "grad_norm": 1.331718921661377,
      "learning_rate": 8.110666666666667e-07,
      "logits/chosen": -2.761706829071045,
      "logits/rejected": -1.9925930500030518,
      "logps/chosen": -91.75302124023438,
      "logps/rejected": -94.39279174804688,
      "loss": 0.021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.833813488483429,
      "rewards/margins": 4.1810221672058105,
      "rewards/rejected": -3.3472084999084473,
      "step": 1418
    },
    {
      "epoch": 0.5676,
      "grad_norm": 4.492128372192383,
      "learning_rate": 8.109333333333332e-07,
      "logits/chosen": -2.800717830657959,
      "logits/rejected": -2.6382017135620117,
      "logps/chosen": -54.21592330932617,
      "logps/rejected": -60.92560577392578,
      "loss": 0.0954,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3322027325630188,
      "rewards/margins": 2.3852710723876953,
      "rewards/rejected": -2.0530683994293213,
      "step": 1419
    },
    {
      "epoch": 0.568,
      "grad_norm": 9.779640197753906,
      "learning_rate": 8.107999999999999e-07,
      "logits/chosen": -2.9997310638427734,
      "logits/rejected": -2.767284631729126,
      "logps/chosen": -85.33006286621094,
      "logps/rejected": -43.18794250488281,
      "loss": 0.2031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4931613802909851,
      "rewards/margins": 1.626065731048584,
      "rewards/rejected": -1.132904291152954,
      "step": 1420
    },
    {
      "epoch": 0.5684,
      "grad_norm": 2.764535903930664,
      "learning_rate": 8.106666666666666e-07,
      "logits/chosen": -2.5480825901031494,
      "logits/rejected": -2.1092042922973633,
      "logps/chosen": -111.57337951660156,
      "logps/rejected": -115.59477233886719,
      "loss": 0.0392,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.036839246749878,
      "rewards/margins": 3.968695640563965,
      "rewards/rejected": -2.931856155395508,
      "step": 1421
    },
    {
      "epoch": 0.5688,
      "grad_norm": 2.406925678253174,
      "learning_rate": 8.105333333333333e-07,
      "logits/chosen": -2.6710257530212402,
      "logits/rejected": -2.111057996749878,
      "logps/chosen": -95.47820281982422,
      "logps/rejected": -76.68121337890625,
      "loss": 0.0482,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15512236952781677,
      "rewards/margins": 3.082686424255371,
      "rewards/rejected": -2.9275641441345215,
      "step": 1422
    },
    {
      "epoch": 0.5692,
      "grad_norm": 0.7440053820610046,
      "learning_rate": 8.104e-07,
      "logits/chosen": -2.6440110206604004,
      "logits/rejected": -2.323887825012207,
      "logps/chosen": -98.28823852539062,
      "logps/rejected": -98.21923828125,
      "loss": 0.0119,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.716867446899414,
      "rewards/margins": 4.553993225097656,
      "rewards/rejected": -2.837125778198242,
      "step": 1423
    },
    {
      "epoch": 0.5696,
      "grad_norm": 0.41164711117744446,
      "learning_rate": 8.102666666666667e-07,
      "logits/chosen": -2.495253562927246,
      "logits/rejected": -2.0331947803497314,
      "logps/chosen": -120.85243225097656,
      "logps/rejected": -78.9281997680664,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5831069946289062,
      "rewards/margins": 5.297952651977539,
      "rewards/rejected": -2.7148451805114746,
      "step": 1424
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.2716968059539795,
      "learning_rate": 8.101333333333334e-07,
      "logits/chosen": -2.633739948272705,
      "logits/rejected": -2.5238735675811768,
      "logps/chosen": -94.79393005371094,
      "logps/rejected": -136.20364379882812,
      "loss": 0.0275,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4941126108169556,
      "rewards/margins": 5.219864845275879,
      "rewards/rejected": -3.725752592086792,
      "step": 1425
    },
    {
      "epoch": 0.5704,
      "grad_norm": 0.8657292127609253,
      "learning_rate": 8.1e-07,
      "logits/chosen": -2.603935718536377,
      "logits/rejected": -1.91990065574646,
      "logps/chosen": -101.04069519042969,
      "logps/rejected": -97.7493896484375,
      "loss": 0.0127,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24918386340141296,
      "rewards/margins": 4.460468292236328,
      "rewards/rejected": -4.211284637451172,
      "step": 1426
    },
    {
      "epoch": 0.5708,
      "grad_norm": 0.25921928882598877,
      "learning_rate": 8.098666666666666e-07,
      "logits/chosen": -2.3631386756896973,
      "logits/rejected": -1.6747479438781738,
      "logps/chosen": -134.4078826904297,
      "logps/rejected": -108.42982482910156,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2202651500701904,
      "rewards/margins": 5.679882526397705,
      "rewards/rejected": -3.4596171379089355,
      "step": 1427
    },
    {
      "epoch": 0.5712,
      "grad_norm": 0.7362534999847412,
      "learning_rate": 8.097333333333333e-07,
      "logits/chosen": -2.6298789978027344,
      "logits/rejected": -2.2510790824890137,
      "logps/chosen": -98.73004150390625,
      "logps/rejected": -152.88510131835938,
      "loss": 0.0112,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7373325824737549,
      "rewards/margins": 4.506409645080566,
      "rewards/rejected": -2.7690773010253906,
      "step": 1428
    },
    {
      "epoch": 0.5716,
      "grad_norm": 4.555141925811768,
      "learning_rate": 8.095999999999999e-07,
      "logits/chosen": -2.6607391834259033,
      "logits/rejected": -2.228620767593384,
      "logps/chosen": -92.196044921875,
      "logps/rejected": -84.77264404296875,
      "loss": 0.0955,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.32247698307037354,
      "rewards/margins": 2.3045763969421387,
      "rewards/rejected": -2.6270532608032227,
      "step": 1429
    },
    {
      "epoch": 0.572,
      "grad_norm": 4.339455604553223,
      "learning_rate": 8.094666666666666e-07,
      "logits/chosen": -2.860527992248535,
      "logits/rejected": -2.8099918365478516,
      "logps/chosen": -69.87834930419922,
      "logps/rejected": -58.064022064208984,
      "loss": 0.124,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4997970461845398,
      "rewards/margins": 2.1663825511932373,
      "rewards/rejected": -1.6665854454040527,
      "step": 1430
    },
    {
      "epoch": 0.5724,
      "grad_norm": 1.2891093492507935,
      "learning_rate": 8.093333333333333e-07,
      "logits/chosen": -2.8254826068878174,
      "logits/rejected": -2.603705406188965,
      "logps/chosen": -117.17137145996094,
      "logps/rejected": -59.54648208618164,
      "loss": 0.0278,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.39110267162323,
      "rewards/margins": 3.5719218254089355,
      "rewards/rejected": -2.180819034576416,
      "step": 1431
    },
    {
      "epoch": 0.5728,
      "grad_norm": 3.754106044769287,
      "learning_rate": 8.092e-07,
      "logits/chosen": -2.915048599243164,
      "logits/rejected": -2.303541898727417,
      "logps/chosen": -77.03064727783203,
      "logps/rejected": -72.8919677734375,
      "loss": 0.0777,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8856751322746277,
      "rewards/margins": 3.0832955837249756,
      "rewards/rejected": -2.197620391845703,
      "step": 1432
    },
    {
      "epoch": 0.5732,
      "grad_norm": 1.5807183980941772,
      "learning_rate": 8.090666666666667e-07,
      "logits/chosen": -2.597228527069092,
      "logits/rejected": -2.232739210128784,
      "logps/chosen": -127.220458984375,
      "logps/rejected": -151.96990966796875,
      "loss": 0.0189,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7278350591659546,
      "rewards/margins": 5.419295310974121,
      "rewards/rejected": -4.691460609436035,
      "step": 1433
    },
    {
      "epoch": 0.5736,
      "grad_norm": 2.778623104095459,
      "learning_rate": 8.089333333333333e-07,
      "logits/chosen": -2.732421875,
      "logits/rejected": -2.589655876159668,
      "logps/chosen": -97.52973175048828,
      "logps/rejected": -75.46025085449219,
      "loss": 0.0595,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2467150688171387,
      "rewards/margins": 3.2703189849853516,
      "rewards/rejected": -2.023603677749634,
      "step": 1434
    },
    {
      "epoch": 0.574,
      "grad_norm": 0.5646270513534546,
      "learning_rate": 8.087999999999999e-07,
      "logits/chosen": -3.031839370727539,
      "logits/rejected": -2.450899124145508,
      "logps/chosen": -50.418128967285156,
      "logps/rejected": -116.13307189941406,
      "loss": 0.0074,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8117386102676392,
      "rewards/margins": 4.9365410804748535,
      "rewards/rejected": -4.124802589416504,
      "step": 1435
    },
    {
      "epoch": 0.5744,
      "grad_norm": 1.9987492561340332,
      "learning_rate": 8.086666666666666e-07,
      "logits/chosen": -2.7005341053009033,
      "logits/rejected": -2.118439197540283,
      "logps/chosen": -94.74885559082031,
      "logps/rejected": -102.88005065917969,
      "loss": 0.0247,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.203420639038086,
      "rewards/margins": 4.123447895050049,
      "rewards/rejected": -2.920027256011963,
      "step": 1436
    },
    {
      "epoch": 0.5748,
      "grad_norm": 1.8321622610092163,
      "learning_rate": 8.085333333333333e-07,
      "logits/chosen": -2.5971264839172363,
      "logits/rejected": -1.8324792385101318,
      "logps/chosen": -86.60908508300781,
      "logps/rejected": -112.92273712158203,
      "loss": 0.0217,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2446002960205078,
      "rewards/margins": 4.732207775115967,
      "rewards/rejected": -3.487607717514038,
      "step": 1437
    },
    {
      "epoch": 0.5752,
      "grad_norm": 10.079665184020996,
      "learning_rate": 8.084e-07,
      "logits/chosen": -2.788018226623535,
      "logits/rejected": -2.0586917400360107,
      "logps/chosen": -120.25807189941406,
      "logps/rejected": -110.15484619140625,
      "loss": 0.128,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8768424987792969,
      "rewards/margins": 2.9183733463287354,
      "rewards/rejected": -2.0415308475494385,
      "step": 1438
    },
    {
      "epoch": 0.5756,
      "grad_norm": 2.546389579772949,
      "learning_rate": 8.082666666666667e-07,
      "logits/chosen": -2.6052932739257812,
      "logits/rejected": -2.7296900749206543,
      "logps/chosen": -108.20189666748047,
      "logps/rejected": -130.83999633789062,
      "loss": 0.035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.117244005203247,
      "rewards/margins": 3.440237522125244,
      "rewards/rejected": -2.322993516921997,
      "step": 1439
    },
    {
      "epoch": 0.576,
      "grad_norm": 5.821719169616699,
      "learning_rate": 8.081333333333333e-07,
      "logits/chosen": -3.003035545349121,
      "logits/rejected": -2.555018424987793,
      "logps/chosen": -62.700862884521484,
      "logps/rejected": -63.654415130615234,
      "loss": 0.1394,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08875274658203125,
      "rewards/margins": 2.0590639114379883,
      "rewards/rejected": -1.9703110456466675,
      "step": 1440
    },
    {
      "epoch": 0.5764,
      "grad_norm": 3.1000797748565674,
      "learning_rate": 8.08e-07,
      "logits/chosen": -2.9451587200164795,
      "logits/rejected": -2.845050096511841,
      "logps/chosen": -83.24702453613281,
      "logps/rejected": -101.75210571289062,
      "loss": 0.0599,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5278335809707642,
      "rewards/margins": 3.071441173553467,
      "rewards/rejected": -2.543607711791992,
      "step": 1441
    },
    {
      "epoch": 0.5768,
      "grad_norm": 2.755983352661133,
      "learning_rate": 8.078666666666666e-07,
      "logits/chosen": -2.8875348567962646,
      "logits/rejected": -2.333907127380371,
      "logps/chosen": -91.52670288085938,
      "logps/rejected": -74.65382385253906,
      "loss": 0.0384,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5340965390205383,
      "rewards/margins": 3.728823184967041,
      "rewards/rejected": -3.1947264671325684,
      "step": 1442
    },
    {
      "epoch": 0.5772,
      "grad_norm": 0.6321365833282471,
      "learning_rate": 8.077333333333333e-07,
      "logits/chosen": -2.63547945022583,
      "logits/rejected": -1.9926207065582275,
      "logps/chosen": -75.90594482421875,
      "logps/rejected": -91.9107437133789,
      "loss": 0.0091,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5866872072219849,
      "rewards/margins": 4.764286994934082,
      "rewards/rejected": -3.177600145339966,
      "step": 1443
    },
    {
      "epoch": 0.5776,
      "grad_norm": 6.6211113929748535,
      "learning_rate": 8.075999999999999e-07,
      "logits/chosen": -2.87723970413208,
      "logits/rejected": -2.5956599712371826,
      "logps/chosen": -56.44727325439453,
      "logps/rejected": -48.63484191894531,
      "loss": 0.1659,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6053188443183899,
      "rewards/margins": 2.0248594284057617,
      "rewards/rejected": -1.419540524482727,
      "step": 1444
    },
    {
      "epoch": 0.578,
      "grad_norm": 6.05468225479126,
      "learning_rate": 8.074666666666666e-07,
      "logits/chosen": -2.8886642456054688,
      "logits/rejected": -2.8323957920074463,
      "logps/chosen": -91.01456451416016,
      "logps/rejected": -43.45368194580078,
      "loss": 0.131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4148704409599304,
      "rewards/margins": 2.075653076171875,
      "rewards/rejected": -1.6607825756072998,
      "step": 1445
    },
    {
      "epoch": 0.5784,
      "grad_norm": 1.9418659210205078,
      "learning_rate": 8.073333333333333e-07,
      "logits/chosen": -2.9011616706848145,
      "logits/rejected": -2.3749542236328125,
      "logps/chosen": -67.93559265136719,
      "logps/rejected": -66.74295043945312,
      "loss": 0.0411,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.180601954460144,
      "rewards/margins": 3.4575984477996826,
      "rewards/rejected": -2.276996612548828,
      "step": 1446
    },
    {
      "epoch": 0.5788,
      "grad_norm": 1.7635165452957153,
      "learning_rate": 8.072e-07,
      "logits/chosen": -2.827871799468994,
      "logits/rejected": -2.4561727046966553,
      "logps/chosen": -77.5425796508789,
      "logps/rejected": -75.38985443115234,
      "loss": 0.0385,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.712498128414154,
      "rewards/margins": 3.512430191040039,
      "rewards/rejected": -2.7999320030212402,
      "step": 1447
    },
    {
      "epoch": 0.5792,
      "grad_norm": 1.3702515363693237,
      "learning_rate": 8.070666666666667e-07,
      "logits/chosen": -2.9231865406036377,
      "logits/rejected": -2.5740623474121094,
      "logps/chosen": -73.95604705810547,
      "logps/rejected": -55.76624298095703,
      "loss": 0.0278,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7307941913604736,
      "rewards/margins": 3.658914804458618,
      "rewards/rejected": -1.9281206130981445,
      "step": 1448
    },
    {
      "epoch": 0.5796,
      "grad_norm": 2.1550920009613037,
      "learning_rate": 8.069333333333333e-07,
      "logits/chosen": -2.7969729900360107,
      "logits/rejected": -2.4495296478271484,
      "logps/chosen": -120.85690307617188,
      "logps/rejected": -81.98225402832031,
      "loss": 0.0425,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7785370349884033,
      "rewards/margins": 3.141242027282715,
      "rewards/rejected": -2.3627047538757324,
      "step": 1449
    },
    {
      "epoch": 0.58,
      "grad_norm": 4.92629337310791,
      "learning_rate": 8.067999999999999e-07,
      "logits/chosen": -2.5452728271484375,
      "logits/rejected": -2.1173079013824463,
      "logps/chosen": -153.49853515625,
      "logps/rejected": -97.52275848388672,
      "loss": 0.065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6147476434707642,
      "rewards/margins": 3.933302402496338,
      "rewards/rejected": -3.3185548782348633,
      "step": 1450
    },
    {
      "epoch": 0.5804,
      "grad_norm": 3.3348543643951416,
      "learning_rate": 8.066666666666666e-07,
      "logits/chosen": -2.45908784866333,
      "logits/rejected": -1.9930171966552734,
      "logps/chosen": -60.62857437133789,
      "logps/rejected": -83.8776626586914,
      "loss": 0.0559,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0446392297744751,
      "rewards/margins": 3.178159236907959,
      "rewards/rejected": -3.1335201263427734,
      "step": 1451
    },
    {
      "epoch": 0.5808,
      "grad_norm": 8.547327995300293,
      "learning_rate": 8.065333333333333e-07,
      "logits/chosen": -2.4682912826538086,
      "logits/rejected": -1.8985158205032349,
      "logps/chosen": -185.47125244140625,
      "logps/rejected": -88.90779876708984,
      "loss": 0.1051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2903931140899658,
      "rewards/margins": 2.983456611633301,
      "rewards/rejected": -2.693063735961914,
      "step": 1452
    },
    {
      "epoch": 0.5812,
      "grad_norm": 15.909732818603516,
      "learning_rate": 8.064e-07,
      "logits/chosen": -2.569796085357666,
      "logits/rejected": -2.397679090499878,
      "logps/chosen": -225.3336181640625,
      "logps/rejected": -119.4830551147461,
      "loss": 0.2075,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7581233978271484,
      "rewards/margins": 1.5345501899719238,
      "rewards/rejected": -2.2926735877990723,
      "step": 1453
    },
    {
      "epoch": 0.5816,
      "grad_norm": 4.397445201873779,
      "learning_rate": 8.062666666666666e-07,
      "logits/chosen": -2.7642159461975098,
      "logits/rejected": -2.301175594329834,
      "logps/chosen": -50.472957611083984,
      "logps/rejected": -102.40919494628906,
      "loss": 0.0762,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.29997777938842773,
      "rewards/margins": 3.4886138439178467,
      "rewards/rejected": -3.7885916233062744,
      "step": 1454
    },
    {
      "epoch": 0.582,
      "grad_norm": 1.5632532835006714,
      "learning_rate": 8.061333333333333e-07,
      "logits/chosen": -2.6756551265716553,
      "logits/rejected": -2.645324230194092,
      "logps/chosen": -101.90589904785156,
      "logps/rejected": -133.4476776123047,
      "loss": 0.0099,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9260728359222412,
      "rewards/margins": 5.1937031745910645,
      "rewards/rejected": -3.2676303386688232,
      "step": 1455
    },
    {
      "epoch": 0.5824,
      "grad_norm": 1.2847084999084473,
      "learning_rate": 8.06e-07,
      "logits/chosen": -2.6971254348754883,
      "logits/rejected": -2.0465331077575684,
      "logps/chosen": -116.99888610839844,
      "logps/rejected": -102.43212890625,
      "loss": 0.0189,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2298709154129028,
      "rewards/margins": 4.345712184906006,
      "rewards/rejected": -3.1158413887023926,
      "step": 1456
    },
    {
      "epoch": 0.5828,
      "grad_norm": 2.901416063308716,
      "learning_rate": 8.058666666666666e-07,
      "logits/chosen": -2.7743945121765137,
      "logits/rejected": -2.2498562335968018,
      "logps/chosen": -89.48370361328125,
      "logps/rejected": -63.64891815185547,
      "loss": 0.0618,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8090473413467407,
      "rewards/margins": 3.3721299171447754,
      "rewards/rejected": -2.563082695007324,
      "step": 1457
    },
    {
      "epoch": 0.5832,
      "grad_norm": 2.2288405895233154,
      "learning_rate": 8.057333333333333e-07,
      "logits/chosen": -2.853489398956299,
      "logits/rejected": -2.2597031593322754,
      "logps/chosen": -72.02336120605469,
      "logps/rejected": -67.41523742675781,
      "loss": 0.0422,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8716655969619751,
      "rewards/margins": 3.4832496643066406,
      "rewards/rejected": -2.611583948135376,
      "step": 1458
    },
    {
      "epoch": 0.5836,
      "grad_norm": 3.6083712577819824,
      "learning_rate": 8.056e-07,
      "logits/chosen": -2.8440663814544678,
      "logits/rejected": -2.1818041801452637,
      "logps/chosen": -106.96568298339844,
      "logps/rejected": -87.5757827758789,
      "loss": 0.0767,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8718816637992859,
      "rewards/margins": 3.7940144538879395,
      "rewards/rejected": -2.922132730484009,
      "step": 1459
    },
    {
      "epoch": 0.584,
      "grad_norm": 2.3918111324310303,
      "learning_rate": 8.054666666666667e-07,
      "logits/chosen": -2.9216394424438477,
      "logits/rejected": -2.0825581550598145,
      "logps/chosen": -56.73856735229492,
      "logps/rejected": -80.08500671386719,
      "loss": 0.0455,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.775892436504364,
      "rewards/margins": 3.4171886444091797,
      "rewards/rejected": -2.64129638671875,
      "step": 1460
    },
    {
      "epoch": 0.5844,
      "grad_norm": 1.71184504032135,
      "learning_rate": 8.053333333333333e-07,
      "logits/chosen": -2.8159847259521484,
      "logits/rejected": -2.5013821125030518,
      "logps/chosen": -91.2174072265625,
      "logps/rejected": -49.52839279174805,
      "loss": 0.0377,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5610138177871704,
      "rewards/margins": 3.2895729541778564,
      "rewards/rejected": -1.7285592555999756,
      "step": 1461
    },
    {
      "epoch": 0.5848,
      "grad_norm": 1.916223168373108,
      "learning_rate": 8.052e-07,
      "logits/chosen": -2.148174285888672,
      "logits/rejected": -1.6083989143371582,
      "logps/chosen": -145.53131103515625,
      "logps/rejected": -162.24575805664062,
      "loss": 0.0245,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5615280270576477,
      "rewards/margins": 3.6984779834747314,
      "rewards/rejected": -3.1369500160217285,
      "step": 1462
    },
    {
      "epoch": 0.5852,
      "grad_norm": 0.6812806725502014,
      "learning_rate": 8.050666666666666e-07,
      "logits/chosen": -2.359924793243408,
      "logits/rejected": -1.6233868598937988,
      "logps/chosen": -88.73065185546875,
      "logps/rejected": -104.69353485107422,
      "loss": 0.0079,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4235954284667969,
      "rewards/margins": 4.9389448165893555,
      "rewards/rejected": -3.5153496265411377,
      "step": 1463
    },
    {
      "epoch": 0.5856,
      "grad_norm": 3.9498965740203857,
      "learning_rate": 8.049333333333332e-07,
      "logits/chosen": -2.5542073249816895,
      "logits/rejected": -2.327319383621216,
      "logps/chosen": -97.00852966308594,
      "logps/rejected": -106.27664947509766,
      "loss": 0.0686,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20884132385253906,
      "rewards/margins": 3.460092544555664,
      "rewards/rejected": -3.251251220703125,
      "step": 1464
    },
    {
      "epoch": 0.586,
      "grad_norm": 4.335489273071289,
      "learning_rate": 8.047999999999999e-07,
      "logits/chosen": -2.9862754344940186,
      "logits/rejected": -2.6071619987487793,
      "logps/chosen": -55.76959228515625,
      "logps/rejected": -47.43328094482422,
      "loss": 0.1049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2639065086841583,
      "rewards/margins": 2.2050135135650635,
      "rewards/rejected": -1.9411070346832275,
      "step": 1465
    },
    {
      "epoch": 0.5864,
      "grad_norm": 3.4605720043182373,
      "learning_rate": 8.046666666666666e-07,
      "logits/chosen": -2.5564844608306885,
      "logits/rejected": -2.1257548332214355,
      "logps/chosen": -94.68072509765625,
      "logps/rejected": -76.13026428222656,
      "loss": 0.0571,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.29194945096969604,
      "rewards/margins": 3.6521658897399902,
      "rewards/rejected": -3.3602163791656494,
      "step": 1466
    },
    {
      "epoch": 0.5868,
      "grad_norm": 6.732084274291992,
      "learning_rate": 8.045333333333333e-07,
      "logits/chosen": -3.0316004753112793,
      "logits/rejected": -2.6143298149108887,
      "logps/chosen": -42.165679931640625,
      "logps/rejected": -59.01972198486328,
      "loss": 0.1466,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33412665128707886,
      "rewards/margins": 2.0503578186035156,
      "rewards/rejected": -1.716231107711792,
      "step": 1467
    },
    {
      "epoch": 0.5872,
      "grad_norm": 4.789153099060059,
      "learning_rate": 8.044e-07,
      "logits/chosen": -2.8962998390197754,
      "logits/rejected": -2.535222053527832,
      "logps/chosen": -54.05928421020508,
      "logps/rejected": -70.19989776611328,
      "loss": 0.0908,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25089606642723083,
      "rewards/margins": 3.2840936183929443,
      "rewards/rejected": -3.0331976413726807,
      "step": 1468
    },
    {
      "epoch": 0.5876,
      "grad_norm": 3.0125033855438232,
      "learning_rate": 8.042666666666667e-07,
      "logits/chosen": -2.5928828716278076,
      "logits/rejected": -2.787996768951416,
      "logps/chosen": -149.45669555664062,
      "logps/rejected": -61.773460388183594,
      "loss": 0.042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2640869617462158,
      "rewards/margins": 3.5043411254882812,
      "rewards/rejected": -2.2402541637420654,
      "step": 1469
    },
    {
      "epoch": 0.588,
      "grad_norm": 0.8510174751281738,
      "learning_rate": 8.041333333333334e-07,
      "logits/chosen": -2.9702248573303223,
      "logits/rejected": -2.535322666168213,
      "logps/chosen": -67.21109008789062,
      "logps/rejected": -100.81163024902344,
      "loss": 0.0108,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16330891847610474,
      "rewards/margins": 4.573531627655029,
      "rewards/rejected": -4.410223007202148,
      "step": 1470
    },
    {
      "epoch": 0.5884,
      "grad_norm": 18.279882431030273,
      "learning_rate": 8.04e-07,
      "logits/chosen": -2.320446491241455,
      "logits/rejected": -1.8368399143218994,
      "logps/chosen": -257.86572265625,
      "logps/rejected": -123.40388488769531,
      "loss": 0.184,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08414226770401001,
      "rewards/margins": 3.2430362701416016,
      "rewards/rejected": -3.1588940620422363,
      "step": 1471
    },
    {
      "epoch": 0.5888,
      "grad_norm": 0.19783055782318115,
      "learning_rate": 8.038666666666665e-07,
      "logits/chosen": -2.729184150695801,
      "logits/rejected": -2.15193510055542,
      "logps/chosen": -82.43783569335938,
      "logps/rejected": -114.38690185546875,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7196396589279175,
      "rewards/margins": 6.480238914489746,
      "rewards/rejected": -4.760599136352539,
      "step": 1472
    },
    {
      "epoch": 0.5892,
      "grad_norm": 10.63310432434082,
      "learning_rate": 8.037333333333332e-07,
      "logits/chosen": -2.748765468597412,
      "logits/rejected": -2.3778345584869385,
      "logps/chosen": -101.06121826171875,
      "logps/rejected": -63.38959503173828,
      "loss": 0.1724,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5988563895225525,
      "rewards/margins": 2.6138155460357666,
      "rewards/rejected": -2.0149593353271484,
      "step": 1473
    },
    {
      "epoch": 0.5896,
      "grad_norm": 6.952134609222412,
      "learning_rate": 8.035999999999999e-07,
      "logits/chosen": -2.7094531059265137,
      "logits/rejected": -2.289660692214966,
      "logps/chosen": -105.75154113769531,
      "logps/rejected": -105.34822082519531,
      "loss": 0.1339,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19581031799316406,
      "rewards/margins": 3.142472267150879,
      "rewards/rejected": -2.946661949157715,
      "step": 1474
    },
    {
      "epoch": 0.59,
      "grad_norm": 4.737460613250732,
      "learning_rate": 8.034666666666666e-07,
      "logits/chosen": -2.671649217605591,
      "logits/rejected": -2.6623494625091553,
      "logps/chosen": -51.92817687988281,
      "logps/rejected": -39.99025344848633,
      "loss": 0.1199,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6333490610122681,
      "rewards/margins": 2.096118450164795,
      "rewards/rejected": -1.4627692699432373,
      "step": 1475
    },
    {
      "epoch": 0.5904,
      "grad_norm": 3.4934449195861816,
      "learning_rate": 8.033333333333333e-07,
      "logits/chosen": -2.548515558242798,
      "logits/rejected": -2.14438533782959,
      "logps/chosen": -135.1900634765625,
      "logps/rejected": -68.82821655273438,
      "loss": 0.0692,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9080631732940674,
      "rewards/margins": 3.3727378845214844,
      "rewards/rejected": -2.464674711227417,
      "step": 1476
    },
    {
      "epoch": 0.5908,
      "grad_norm": 8.996220588684082,
      "learning_rate": 8.032e-07,
      "logits/chosen": -2.7278034687042236,
      "logits/rejected": -2.6540000438690186,
      "logps/chosen": -65.7686538696289,
      "logps/rejected": -53.96453857421875,
      "loss": 0.323,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.21943017840385437,
      "rewards/margins": 1.5674238204956055,
      "rewards/rejected": -1.7868540287017822,
      "step": 1477
    },
    {
      "epoch": 0.5912,
      "grad_norm": 10.452479362487793,
      "learning_rate": 8.030666666666667e-07,
      "logits/chosen": -2.858077049255371,
      "logits/rejected": -2.4976654052734375,
      "logps/chosen": -96.6364974975586,
      "logps/rejected": -63.345420837402344,
      "loss": 0.1657,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06977139413356781,
      "rewards/margins": 2.117493152618408,
      "rewards/rejected": -2.0477216243743896,
      "step": 1478
    },
    {
      "epoch": 0.5916,
      "grad_norm": 1.6415092945098877,
      "learning_rate": 8.029333333333334e-07,
      "logits/chosen": -2.854985237121582,
      "logits/rejected": -2.3933959007263184,
      "logps/chosen": -86.42585754394531,
      "logps/rejected": -154.26327514648438,
      "loss": 0.0224,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2278697490692139,
      "rewards/margins": 4.623935699462891,
      "rewards/rejected": -3.3960657119750977,
      "step": 1479
    },
    {
      "epoch": 0.592,
      "grad_norm": 1.9222283363342285,
      "learning_rate": 8.028e-07,
      "logits/chosen": -2.9559743404388428,
      "logits/rejected": -2.264331340789795,
      "logps/chosen": -42.95105743408203,
      "logps/rejected": -76.63034057617188,
      "loss": 0.0333,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.479017436504364,
      "rewards/margins": 3.428936719894409,
      "rewards/rejected": -2.9499192237854004,
      "step": 1480
    },
    {
      "epoch": 0.5924,
      "grad_norm": 2.1308701038360596,
      "learning_rate": 8.026666666666667e-07,
      "logits/chosen": -2.64902925491333,
      "logits/rejected": -2.3225369453430176,
      "logps/chosen": -89.90914916992188,
      "logps/rejected": -98.35797119140625,
      "loss": 0.0268,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3876754641532898,
      "rewards/margins": 4.353879928588867,
      "rewards/rejected": -3.9662041664123535,
      "step": 1481
    },
    {
      "epoch": 0.5928,
      "grad_norm": 0.5855944156646729,
      "learning_rate": 8.025333333333332e-07,
      "logits/chosen": -2.635836124420166,
      "logits/rejected": -2.2184252738952637,
      "logps/chosen": -122.15007781982422,
      "logps/rejected": -114.27686309814453,
      "loss": 0.0084,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0329567193984985,
      "rewards/margins": 4.795195579528809,
      "rewards/rejected": -3.7622387409210205,
      "step": 1482
    },
    {
      "epoch": 0.5932,
      "grad_norm": 1.6477289199829102,
      "learning_rate": 8.023999999999999e-07,
      "logits/chosen": -2.693138837814331,
      "logits/rejected": -2.3143458366394043,
      "logps/chosen": -93.17875671386719,
      "logps/rejected": -88.38006591796875,
      "loss": 0.0253,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4683693051338196,
      "rewards/margins": 3.6669557094573975,
      "rewards/rejected": -3.1985864639282227,
      "step": 1483
    },
    {
      "epoch": 0.5936,
      "grad_norm": 4.417359352111816,
      "learning_rate": 8.022666666666666e-07,
      "logits/chosen": -3.022164821624756,
      "logits/rejected": -2.799558639526367,
      "logps/chosen": -78.55052185058594,
      "logps/rejected": -97.0113754272461,
      "loss": 0.0628,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5075035095214844,
      "rewards/margins": 3.0250496864318848,
      "rewards/rejected": -2.5175461769104004,
      "step": 1484
    },
    {
      "epoch": 0.594,
      "grad_norm": 2.1604678630828857,
      "learning_rate": 8.021333333333333e-07,
      "logits/chosen": -2.699204444885254,
      "logits/rejected": -2.4287564754486084,
      "logps/chosen": -78.30284118652344,
      "logps/rejected": -83.28504943847656,
      "loss": 0.0403,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2125598192214966,
      "rewards/margins": 3.4099831581115723,
      "rewards/rejected": -2.197423219680786,
      "step": 1485
    },
    {
      "epoch": 0.5944,
      "grad_norm": 8.998624801635742,
      "learning_rate": 8.02e-07,
      "logits/chosen": -2.7087502479553223,
      "logits/rejected": -2.3624496459960938,
      "logps/chosen": -114.21820068359375,
      "logps/rejected": -60.30120849609375,
      "loss": 0.1936,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7732681035995483,
      "rewards/margins": 2.4702634811401367,
      "rewards/rejected": -1.6969953775405884,
      "step": 1486
    },
    {
      "epoch": 0.5948,
      "grad_norm": 0.6017744541168213,
      "learning_rate": 8.018666666666666e-07,
      "logits/chosen": -2.7375659942626953,
      "logits/rejected": -1.8688082695007324,
      "logps/chosen": -74.28174591064453,
      "logps/rejected": -71.38307189941406,
      "loss": 0.0101,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9575140476226807,
      "rewards/margins": 4.713041305541992,
      "rewards/rejected": -2.7555274963378906,
      "step": 1487
    },
    {
      "epoch": 0.5952,
      "grad_norm": 1.7073395252227783,
      "learning_rate": 8.017333333333333e-07,
      "logits/chosen": -2.9332337379455566,
      "logits/rejected": -2.260098457336426,
      "logps/chosen": -62.98508071899414,
      "logps/rejected": -90.77100372314453,
      "loss": 0.0204,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6677879691123962,
      "rewards/margins": 5.1136474609375,
      "rewards/rejected": -4.445859909057617,
      "step": 1488
    },
    {
      "epoch": 0.5956,
      "grad_norm": 2.6341493129730225,
      "learning_rate": 8.016e-07,
      "logits/chosen": -2.6387581825256348,
      "logits/rejected": -2.085665702819824,
      "logps/chosen": -113.4664077758789,
      "logps/rejected": -89.01399993896484,
      "loss": 0.0507,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.033449362963438034,
      "rewards/margins": 3.133671760559082,
      "rewards/rejected": -3.10022234916687,
      "step": 1489
    },
    {
      "epoch": 0.596,
      "grad_norm": 0.9432960152626038,
      "learning_rate": 8.014666666666667e-07,
      "logits/chosen": -2.5752615928649902,
      "logits/rejected": -1.75828218460083,
      "logps/chosen": -152.3695068359375,
      "logps/rejected": -105.5329360961914,
      "loss": 0.0131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0113853216171265,
      "rewards/margins": 4.331489562988281,
      "rewards/rejected": -3.3201045989990234,
      "step": 1490
    },
    {
      "epoch": 0.5964,
      "grad_norm": 1.9502228498458862,
      "learning_rate": 8.013333333333333e-07,
      "logits/chosen": -2.4936394691467285,
      "logits/rejected": -1.6839983463287354,
      "logps/chosen": -114.7551040649414,
      "logps/rejected": -85.28607177734375,
      "loss": 0.0296,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1719512939453125,
      "rewards/margins": 3.510683536529541,
      "rewards/rejected": -2.3387322425842285,
      "step": 1491
    },
    {
      "epoch": 0.5968,
      "grad_norm": 4.802055835723877,
      "learning_rate": 8.012e-07,
      "logits/chosen": -2.9086570739746094,
      "logits/rejected": -2.394659996032715,
      "logps/chosen": -39.78187942504883,
      "logps/rejected": -73.07367706298828,
      "loss": 0.0964,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.016330435872077942,
      "rewards/margins": 2.6178507804870605,
      "rewards/rejected": -2.601520538330078,
      "step": 1492
    },
    {
      "epoch": 0.5972,
      "grad_norm": 2.404829740524292,
      "learning_rate": 8.010666666666666e-07,
      "logits/chosen": -3.1490261554718018,
      "logits/rejected": -2.9805750846862793,
      "logps/chosen": -73.10406494140625,
      "logps/rejected": -52.368682861328125,
      "loss": 0.0509,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6615475416183472,
      "rewards/margins": 2.965590238571167,
      "rewards/rejected": -2.3040428161621094,
      "step": 1493
    },
    {
      "epoch": 0.5976,
      "grad_norm": 9.36246109008789,
      "learning_rate": 8.009333333333333e-07,
      "logits/chosen": -2.7778162956237793,
      "logits/rejected": -2.8432374000549316,
      "logps/chosen": -86.07013702392578,
      "logps/rejected": -63.305877685546875,
      "loss": 0.2342,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.17022095620632172,
      "rewards/margins": 1.4648072719573975,
      "rewards/rejected": -1.63502836227417,
      "step": 1494
    },
    {
      "epoch": 0.598,
      "grad_norm": 3.174909830093384,
      "learning_rate": 8.007999999999999e-07,
      "logits/chosen": -3.104081153869629,
      "logits/rejected": -2.6217057704925537,
      "logps/chosen": -75.47642517089844,
      "logps/rejected": -116.18309020996094,
      "loss": 0.0437,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1380016803741455,
      "rewards/margins": 4.387088775634766,
      "rewards/rejected": -3.249086856842041,
      "step": 1495
    },
    {
      "epoch": 0.5984,
      "grad_norm": 2.9677367210388184,
      "learning_rate": 8.006666666666666e-07,
      "logits/chosen": -2.91369891166687,
      "logits/rejected": -2.8616480827331543,
      "logps/chosen": -66.2750244140625,
      "logps/rejected": -45.529754638671875,
      "loss": 0.0626,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8547136783599854,
      "rewards/margins": 2.7420191764831543,
      "rewards/rejected": -1.8873053789138794,
      "step": 1496
    },
    {
      "epoch": 0.5988,
      "grad_norm": 5.663913726806641,
      "learning_rate": 8.005333333333333e-07,
      "logits/chosen": -2.339946746826172,
      "logits/rejected": -2.6230053901672363,
      "logps/chosen": -53.0861930847168,
      "logps/rejected": -96.28328704833984,
      "loss": 0.1448,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6405424475669861,
      "rewards/margins": 3.3817050457000732,
      "rewards/rejected": -2.7411625385284424,
      "step": 1497
    },
    {
      "epoch": 0.5992,
      "grad_norm": 5.259328365325928,
      "learning_rate": 8.004e-07,
      "logits/chosen": -2.6216931343078613,
      "logits/rejected": -2.29422664642334,
      "logps/chosen": -110.06354522705078,
      "logps/rejected": -68.62466430664062,
      "loss": 0.1183,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2173675298690796,
      "rewards/margins": 3.328714370727539,
      "rewards/rejected": -2.11134672164917,
      "step": 1498
    },
    {
      "epoch": 0.5996,
      "grad_norm": 7.7526164054870605,
      "learning_rate": 8.002666666666667e-07,
      "logits/chosen": -2.774463176727295,
      "logits/rejected": -2.4636857509613037,
      "logps/chosen": -95.33203125,
      "logps/rejected": -71.3740234375,
      "loss": 0.168,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3405349850654602,
      "rewards/margins": 1.8713291883468628,
      "rewards/rejected": -1.5307941436767578,
      "step": 1499
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.260788917541504,
      "learning_rate": 8.001333333333334e-07,
      "logits/chosen": -2.7671761512756348,
      "logits/rejected": -2.064527988433838,
      "logps/chosen": -85.06489562988281,
      "logps/rejected": -82.36268615722656,
      "loss": 0.0305,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3604249954223633,
      "rewards/margins": 3.5229032039642334,
      "rewards/rejected": -2.16247820854187,
      "step": 1500
    },
    {
      "epoch": 0.6004,
      "grad_norm": 6.721920967102051,
      "learning_rate": 8e-07,
      "logits/chosen": -2.7021484375,
      "logits/rejected": -2.221829891204834,
      "logps/chosen": -77.04920196533203,
      "logps/rejected": -83.8685073852539,
      "loss": 0.1345,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1303665190935135,
      "rewards/margins": 2.0150818824768066,
      "rewards/rejected": -2.1454484462738037,
      "step": 1501
    },
    {
      "epoch": 0.6008,
      "grad_norm": 1.3586198091506958,
      "learning_rate": 7.998666666666665e-07,
      "logits/chosen": -2.7875800132751465,
      "logits/rejected": -2.296261787414551,
      "logps/chosen": -96.06048583984375,
      "logps/rejected": -102.42778015136719,
      "loss": 0.0182,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9890155792236328,
      "rewards/margins": 4.328937530517578,
      "rewards/rejected": -3.3399219512939453,
      "step": 1502
    },
    {
      "epoch": 0.6012,
      "grad_norm": 2.664787530899048,
      "learning_rate": 7.997333333333332e-07,
      "logits/chosen": -2.9636192321777344,
      "logits/rejected": -2.43379282951355,
      "logps/chosen": -51.543766021728516,
      "logps/rejected": -87.05496978759766,
      "loss": 0.0445,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23029977083206177,
      "rewards/margins": 3.2103829383850098,
      "rewards/rejected": -2.9800829887390137,
      "step": 1503
    },
    {
      "epoch": 0.6016,
      "grad_norm": 0.6415873765945435,
      "learning_rate": 7.995999999999999e-07,
      "logits/chosen": -2.7253665924072266,
      "logits/rejected": -2.029082775115967,
      "logps/chosen": -96.79573822021484,
      "logps/rejected": -86.91012573242188,
      "loss": 0.0108,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5708014965057373,
      "rewards/margins": 4.7176103591918945,
      "rewards/rejected": -3.1468091011047363,
      "step": 1504
    },
    {
      "epoch": 0.602,
      "grad_norm": 0.6565555930137634,
      "learning_rate": 7.994666666666666e-07,
      "logits/chosen": -2.542090654373169,
      "logits/rejected": -1.6456398963928223,
      "logps/chosen": -133.07003784179688,
      "logps/rejected": -93.58522033691406,
      "loss": 0.0077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1936378479003906,
      "rewards/margins": 5.647366523742676,
      "rewards/rejected": -3.453728675842285,
      "step": 1505
    },
    {
      "epoch": 0.6024,
      "grad_norm": 0.2681574523448944,
      "learning_rate": 7.993333333333333e-07,
      "logits/chosen": -2.980574369430542,
      "logits/rejected": -2.510059118270874,
      "logps/chosen": -57.885581970214844,
      "logps/rejected": -99.52711486816406,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.752872109413147,
      "rewards/margins": 5.858043670654297,
      "rewards/rejected": -5.105171203613281,
      "step": 1506
    },
    {
      "epoch": 0.6028,
      "grad_norm": 5.639052391052246,
      "learning_rate": 7.992e-07,
      "logits/chosen": -2.674539089202881,
      "logits/rejected": -2.1406517028808594,
      "logps/chosen": -88.28816223144531,
      "logps/rejected": -86.0570297241211,
      "loss": 0.0984,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1658065766096115,
      "rewards/margins": 3.051492691040039,
      "rewards/rejected": -2.885686159133911,
      "step": 1507
    },
    {
      "epoch": 0.6032,
      "grad_norm": 3.4140655994415283,
      "learning_rate": 7.990666666666667e-07,
      "logits/chosen": -2.848717212677002,
      "logits/rejected": -2.496951103210449,
      "logps/chosen": -113.43791198730469,
      "logps/rejected": -90.92672729492188,
      "loss": 0.0567,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7395736575126648,
      "rewards/margins": 3.130141258239746,
      "rewards/rejected": -2.3905673027038574,
      "step": 1508
    },
    {
      "epoch": 0.6036,
      "grad_norm": 0.6945479512214661,
      "learning_rate": 7.989333333333334e-07,
      "logits/chosen": -2.4671034812927246,
      "logits/rejected": -2.044827699661255,
      "logps/chosen": -100.76763916015625,
      "logps/rejected": -144.31919860839844,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.171176552772522,
      "rewards/margins": 5.141496658325195,
      "rewards/rejected": -3.970320224761963,
      "step": 1509
    },
    {
      "epoch": 0.604,
      "grad_norm": 2.966787815093994,
      "learning_rate": 7.987999999999999e-07,
      "logits/chosen": -2.790736675262451,
      "logits/rejected": -2.4235706329345703,
      "logps/chosen": -98.44538879394531,
      "logps/rejected": -83.14273071289062,
      "loss": 0.0592,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2491517961025238,
      "rewards/margins": 3.004944324493408,
      "rewards/rejected": -2.7557926177978516,
      "step": 1510
    },
    {
      "epoch": 0.6044,
      "grad_norm": 1.571384310722351,
      "learning_rate": 7.986666666666666e-07,
      "logits/chosen": -2.571760654449463,
      "logits/rejected": -2.195387125015259,
      "logps/chosen": -78.9214859008789,
      "logps/rejected": -91.11151123046875,
      "loss": 0.0219,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9477288722991943,
      "rewards/margins": 4.065717697143555,
      "rewards/rejected": -2.1179890632629395,
      "step": 1511
    },
    {
      "epoch": 0.6048,
      "grad_norm": 0.7631224989891052,
      "learning_rate": 7.985333333333333e-07,
      "logits/chosen": -2.820840358734131,
      "logits/rejected": -2.194645643234253,
      "logps/chosen": -102.06785583496094,
      "logps/rejected": -85.47398376464844,
      "loss": 0.0124,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.663783073425293,
      "rewards/margins": 4.4921417236328125,
      "rewards/rejected": -2.8283586502075195,
      "step": 1512
    },
    {
      "epoch": 0.6052,
      "grad_norm": 1.7177550792694092,
      "learning_rate": 7.984e-07,
      "logits/chosen": -3.0564322471618652,
      "logits/rejected": -2.829531192779541,
      "logps/chosen": -85.4269790649414,
      "logps/rejected": -64.60193634033203,
      "loss": 0.0275,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3613094091415405,
      "rewards/margins": 3.8526108264923096,
      "rewards/rejected": -2.4913015365600586,
      "step": 1513
    },
    {
      "epoch": 0.6056,
      "grad_norm": 2.615469217300415,
      "learning_rate": 7.982666666666666e-07,
      "logits/chosen": -2.887301445007324,
      "logits/rejected": -2.4295520782470703,
      "logps/chosen": -97.04707336425781,
      "logps/rejected": -78.00119018554688,
      "loss": 0.05,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06671410799026489,
      "rewards/margins": 2.9865565299987793,
      "rewards/rejected": -2.91984224319458,
      "step": 1514
    },
    {
      "epoch": 0.606,
      "grad_norm": 0.4155694842338562,
      "learning_rate": 7.981333333333333e-07,
      "logits/chosen": -2.6097121238708496,
      "logits/rejected": -1.9776561260223389,
      "logps/chosen": -56.69674301147461,
      "logps/rejected": -99.17703247070312,
      "loss": 0.0055,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4388017654418945,
      "rewards/margins": 5.239169120788574,
      "rewards/rejected": -3.8003673553466797,
      "step": 1515
    },
    {
      "epoch": 0.6064,
      "grad_norm": 5.5930352210998535,
      "learning_rate": 7.98e-07,
      "logits/chosen": -2.695120334625244,
      "logits/rejected": -2.3665659427642822,
      "logps/chosen": -115.12240600585938,
      "logps/rejected": -94.53907775878906,
      "loss": 0.0778,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.07958146929740906,
      "rewards/margins": 3.3755595684051514,
      "rewards/rejected": -3.455141067504883,
      "step": 1516
    },
    {
      "epoch": 0.6068,
      "grad_norm": 2.6704680919647217,
      "learning_rate": 7.978666666666666e-07,
      "logits/chosen": -3.2165510654449463,
      "logits/rejected": -2.626811981201172,
      "logps/chosen": -50.70564270019531,
      "logps/rejected": -83.66722869873047,
      "loss": 0.0412,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4600076675415039,
      "rewards/margins": 3.6782894134521484,
      "rewards/rejected": -3.2182817459106445,
      "step": 1517
    },
    {
      "epoch": 0.6072,
      "grad_norm": 7.602166175842285,
      "learning_rate": 7.977333333333333e-07,
      "logits/chosen": -2.8993449211120605,
      "logits/rejected": -2.7173078060150146,
      "logps/chosen": -104.05119323730469,
      "logps/rejected": -68.41293334960938,
      "loss": 0.2348,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6626743078231812,
      "rewards/margins": 1.7348607778549194,
      "rewards/rejected": -2.3975350856781006,
      "step": 1518
    },
    {
      "epoch": 0.6076,
      "grad_norm": 5.307825088500977,
      "learning_rate": 7.975999999999999e-07,
      "logits/chosen": -2.5649383068084717,
      "logits/rejected": -2.5962133407592773,
      "logps/chosen": -139.80426025390625,
      "logps/rejected": -92.7403564453125,
      "loss": 0.0857,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3971443176269531,
      "rewards/margins": 2.714092254638672,
      "rewards/rejected": -2.3169479370117188,
      "step": 1519
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.8418384194374084,
      "learning_rate": 7.974666666666666e-07,
      "logits/chosen": -2.6936776638031006,
      "logits/rejected": -1.9403449296951294,
      "logps/chosen": -176.08432006835938,
      "logps/rejected": -105.9269027709961,
      "loss": 0.011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9668461084365845,
      "rewards/margins": 4.5863037109375,
      "rewards/rejected": -3.619457721710205,
      "step": 1520
    },
    {
      "epoch": 0.6084,
      "grad_norm": 4.674019813537598,
      "learning_rate": 7.973333333333333e-07,
      "logits/chosen": -3.137507915496826,
      "logits/rejected": -2.4710521697998047,
      "logps/chosen": -57.57172393798828,
      "logps/rejected": -70.72477722167969,
      "loss": 0.0675,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.037110909819602966,
      "rewards/margins": 2.8290083408355713,
      "rewards/rejected": -2.866119384765625,
      "step": 1521
    },
    {
      "epoch": 0.6088,
      "grad_norm": 1.8301122188568115,
      "learning_rate": 7.972e-07,
      "logits/chosen": -2.8759498596191406,
      "logits/rejected": -2.383798599243164,
      "logps/chosen": -75.59710693359375,
      "logps/rejected": -153.454345703125,
      "loss": 0.0299,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7663968801498413,
      "rewards/margins": 3.8782031536102295,
      "rewards/rejected": -3.1118061542510986,
      "step": 1522
    },
    {
      "epoch": 0.6092,
      "grad_norm": 1.5240070819854736,
      "learning_rate": 7.970666666666667e-07,
      "logits/chosen": -2.762974977493286,
      "logits/rejected": -2.022263288497925,
      "logps/chosen": -123.05963134765625,
      "logps/rejected": -98.62382507324219,
      "loss": 0.0232,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3798089027404785,
      "rewards/margins": 4.034570217132568,
      "rewards/rejected": -2.65476131439209,
      "step": 1523
    },
    {
      "epoch": 0.6096,
      "grad_norm": 1.6214920282363892,
      "learning_rate": 7.969333333333333e-07,
      "logits/chosen": -2.5732054710388184,
      "logits/rejected": -1.8906733989715576,
      "logps/chosen": -119.99320983886719,
      "logps/rejected": -92.54835510253906,
      "loss": 0.0256,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.07328146696090698,
      "rewards/margins": 3.6712565422058105,
      "rewards/rejected": -3.7445380687713623,
      "step": 1524
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5731810927391052,
      "learning_rate": 7.967999999999999e-07,
      "logits/chosen": -2.7265987396240234,
      "logits/rejected": -2.1374049186706543,
      "logps/chosen": -69.85789489746094,
      "logps/rejected": -84.47869110107422,
      "loss": 0.0086,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3137489557266235,
      "rewards/margins": 4.774318695068359,
      "rewards/rejected": -3.460569381713867,
      "step": 1525
    },
    {
      "epoch": 0.6104,
      "grad_norm": 0.46545544266700745,
      "learning_rate": 7.966666666666666e-07,
      "logits/chosen": -2.7907443046569824,
      "logits/rejected": -2.069715738296509,
      "logps/chosen": -72.92086791992188,
      "logps/rejected": -104.76681518554688,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5515894889831543,
      "rewards/margins": 6.380304336547852,
      "rewards/rejected": -4.828714370727539,
      "step": 1526
    },
    {
      "epoch": 0.6108,
      "grad_norm": 0.33962616324424744,
      "learning_rate": 7.965333333333333e-07,
      "logits/chosen": -2.843317985534668,
      "logits/rejected": -1.7591063976287842,
      "logps/chosen": -66.37158203125,
      "logps/rejected": -120.30592346191406,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.587290644645691,
      "rewards/margins": 5.5908427238464355,
      "rewards/rejected": -4.003551959991455,
      "step": 1527
    },
    {
      "epoch": 0.6112,
      "grad_norm": 4.164681911468506,
      "learning_rate": 7.964e-07,
      "logits/chosen": -3.107936382293701,
      "logits/rejected": -2.5533194541931152,
      "logps/chosen": -53.02525329589844,
      "logps/rejected": -57.7037239074707,
      "loss": 0.0806,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3941364288330078,
      "rewards/margins": 2.5332775115966797,
      "rewards/rejected": -2.139141082763672,
      "step": 1528
    },
    {
      "epoch": 0.6116,
      "grad_norm": 0.3058817386627197,
      "learning_rate": 7.962666666666666e-07,
      "logits/chosen": -2.5703368186950684,
      "logits/rejected": -1.9902727603912354,
      "logps/chosen": -83.74954223632812,
      "logps/rejected": -133.36805725097656,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3687806129455566,
      "rewards/margins": 5.8788299560546875,
      "rewards/rejected": -3.51004958152771,
      "step": 1529
    },
    {
      "epoch": 0.612,
      "grad_norm": 1.4860665798187256,
      "learning_rate": 7.961333333333333e-07,
      "logits/chosen": -2.3815739154815674,
      "logits/rejected": -1.801925778388977,
      "logps/chosen": -210.9869384765625,
      "logps/rejected": -112.17471313476562,
      "loss": 0.0237,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34928208589553833,
      "rewards/margins": 3.7773709297180176,
      "rewards/rejected": -3.428088665008545,
      "step": 1530
    },
    {
      "epoch": 0.6124,
      "grad_norm": 0.968101441860199,
      "learning_rate": 7.96e-07,
      "logits/chosen": -2.487957715988159,
      "logits/rejected": -2.1744918823242188,
      "logps/chosen": -98.4889907836914,
      "logps/rejected": -84.2958984375,
      "loss": 0.0129,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1825225353240967,
      "rewards/margins": 4.3420729637146,
      "rewards/rejected": -2.159550428390503,
      "step": 1531
    },
    {
      "epoch": 0.6128,
      "grad_norm": 8.723103523254395,
      "learning_rate": 7.958666666666666e-07,
      "logits/chosen": -2.9808151721954346,
      "logits/rejected": -2.540802240371704,
      "logps/chosen": -115.58958435058594,
      "logps/rejected": -88.7203140258789,
      "loss": 0.1235,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8071796894073486,
      "rewards/margins": 2.661858320236206,
      "rewards/rejected": -1.854678750038147,
      "step": 1532
    },
    {
      "epoch": 0.6132,
      "grad_norm": 1.0156229734420776,
      "learning_rate": 7.957333333333333e-07,
      "logits/chosen": -2.8143856525421143,
      "logits/rejected": -2.651101589202881,
      "logps/chosen": -91.66802978515625,
      "logps/rejected": -86.67398071289062,
      "loss": 0.0157,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.247450590133667,
      "rewards/margins": 4.1465911865234375,
      "rewards/rejected": -2.8991405963897705,
      "step": 1533
    },
    {
      "epoch": 0.6136,
      "grad_norm": 0.6003435254096985,
      "learning_rate": 7.956e-07,
      "logits/chosen": -2.6442949771881104,
      "logits/rejected": -2.011198043823242,
      "logps/chosen": -110.29568481445312,
      "logps/rejected": -88.80257415771484,
      "loss": 0.0093,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8948535919189453,
      "rewards/margins": 4.694332599639893,
      "rewards/rejected": -2.7994790077209473,
      "step": 1534
    },
    {
      "epoch": 0.614,
      "grad_norm": 1.3701473474502563,
      "learning_rate": 7.954666666666666e-07,
      "logits/chosen": -3.036160707473755,
      "logits/rejected": -2.3947348594665527,
      "logps/chosen": -65.69551086425781,
      "logps/rejected": -95.01078796386719,
      "loss": 0.0227,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3565020561218262,
      "rewards/margins": 5.019588947296143,
      "rewards/rejected": -3.6630868911743164,
      "step": 1535
    },
    {
      "epoch": 0.6144,
      "grad_norm": 7.811258792877197,
      "learning_rate": 7.953333333333333e-07,
      "logits/chosen": -2.8977179527282715,
      "logits/rejected": -2.5295467376708984,
      "logps/chosen": -94.2695083618164,
      "logps/rejected": -54.208194732666016,
      "loss": 0.1157,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5111774206161499,
      "rewards/margins": 2.802288055419922,
      "rewards/rejected": -2.2911107540130615,
      "step": 1536
    },
    {
      "epoch": 0.6148,
      "grad_norm": 0.28081440925598145,
      "learning_rate": 7.952e-07,
      "logits/chosen": -2.661850929260254,
      "logits/rejected": -2.061175584793091,
      "logps/chosen": -108.85381317138672,
      "logps/rejected": -138.4485626220703,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15130996704101562,
      "rewards/margins": 5.734333038330078,
      "rewards/rejected": -5.5830230712890625,
      "step": 1537
    },
    {
      "epoch": 0.6152,
      "grad_norm": 1.4418158531188965,
      "learning_rate": 7.950666666666666e-07,
      "logits/chosen": -3.182342052459717,
      "logits/rejected": -2.270040988922119,
      "logps/chosen": -46.27799987792969,
      "logps/rejected": -91.41371154785156,
      "loss": 0.0197,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4027748107910156,
      "rewards/margins": 3.966862440109253,
      "rewards/rejected": -3.564087390899658,
      "step": 1538
    },
    {
      "epoch": 0.6156,
      "grad_norm": 2.088984489440918,
      "learning_rate": 7.949333333333333e-07,
      "logits/chosen": -2.9078476428985596,
      "logits/rejected": -2.5407729148864746,
      "logps/chosen": -101.82377624511719,
      "logps/rejected": -79.67515563964844,
      "loss": 0.0355,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3324819803237915,
      "rewards/margins": 3.412775993347168,
      "rewards/rejected": -3.080293893814087,
      "step": 1539
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.17554554343223572,
      "learning_rate": 7.947999999999999e-07,
      "logits/chosen": -2.572187900543213,
      "logits/rejected": -2.0245280265808105,
      "logps/chosen": -157.77252197265625,
      "logps/rejected": -146.16041564941406,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5242012739181519,
      "rewards/margins": 6.36420202255249,
      "rewards/rejected": -4.840000629425049,
      "step": 1540
    },
    {
      "epoch": 0.6164,
      "grad_norm": 0.5236327052116394,
      "learning_rate": 7.946666666666666e-07,
      "logits/chosen": -2.8822519779205322,
      "logits/rejected": -2.455209255218506,
      "logps/chosen": -136.64517211914062,
      "logps/rejected": -120.09036254882812,
      "loss": 0.0068,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9903969168663025,
      "rewards/margins": 5.483939170837402,
      "rewards/rejected": -4.493542671203613,
      "step": 1541
    },
    {
      "epoch": 0.6168,
      "grad_norm": 6.014910697937012,
      "learning_rate": 7.945333333333333e-07,
      "logits/chosen": -3.011965274810791,
      "logits/rejected": -3.1835989952087402,
      "logps/chosen": -72.95372009277344,
      "logps/rejected": -55.68345642089844,
      "loss": 0.1535,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12878723442554474,
      "rewards/margins": 2.455203056335449,
      "rewards/rejected": -2.326416015625,
      "step": 1542
    },
    {
      "epoch": 0.6172,
      "grad_norm": 0.9452234506607056,
      "learning_rate": 7.944e-07,
      "logits/chosen": -2.9611310958862305,
      "logits/rejected": -2.469937801361084,
      "logps/chosen": -58.527793884277344,
      "logps/rejected": -117.61894226074219,
      "loss": 0.0139,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3349101543426514,
      "rewards/margins": 5.214537620544434,
      "rewards/rejected": -3.8796277046203613,
      "step": 1543
    },
    {
      "epoch": 0.6176,
      "grad_norm": 2.0790650844573975,
      "learning_rate": 7.942666666666667e-07,
      "logits/chosen": -2.773367166519165,
      "logits/rejected": -2.422028064727783,
      "logps/chosen": -185.4827880859375,
      "logps/rejected": -88.5020751953125,
      "loss": 0.0311,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.44493943452835083,
      "rewards/margins": 3.4881784915924072,
      "rewards/rejected": -3.043239116668701,
      "step": 1544
    },
    {
      "epoch": 0.618,
      "grad_norm": 3.342085123062134,
      "learning_rate": 7.941333333333334e-07,
      "logits/chosen": -2.6360859870910645,
      "logits/rejected": -1.9841485023498535,
      "logps/chosen": -146.58572387695312,
      "logps/rejected": -79.00971984863281,
      "loss": 0.0642,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8952316641807556,
      "rewards/margins": 3.9536943435668945,
      "rewards/rejected": -3.058462619781494,
      "step": 1545
    },
    {
      "epoch": 0.6184,
      "grad_norm": 16.840877532958984,
      "learning_rate": 7.94e-07,
      "logits/chosen": -2.9021482467651367,
      "logits/rejected": -2.520045518875122,
      "logps/chosen": -114.72134399414062,
      "logps/rejected": -117.65377807617188,
      "loss": 0.1962,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6531864404678345,
      "rewards/margins": 3.6846506595611572,
      "rewards/rejected": -5.337837219238281,
      "step": 1546
    },
    {
      "epoch": 0.6188,
      "grad_norm": 75.13468933105469,
      "learning_rate": 7.938666666666667e-07,
      "logits/chosen": -2.5696141719818115,
      "logits/rejected": -2.3370375633239746,
      "logps/chosen": -192.3741455078125,
      "logps/rejected": -92.03713989257812,
      "loss": 1.1182,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -2.2469704151153564,
      "rewards/margins": 1.461276650428772,
      "rewards/rejected": -3.708247184753418,
      "step": 1547
    },
    {
      "epoch": 0.6192,
      "grad_norm": 0.9524763226509094,
      "learning_rate": 7.937333333333332e-07,
      "logits/chosen": -2.789670944213867,
      "logits/rejected": -2.40962553024292,
      "logps/chosen": -55.26570129394531,
      "logps/rejected": -68.63508605957031,
      "loss": 0.0146,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6998521685600281,
      "rewards/margins": 4.498382568359375,
      "rewards/rejected": -3.798530340194702,
      "step": 1548
    },
    {
      "epoch": 0.6196,
      "grad_norm": 0.2615079879760742,
      "learning_rate": 7.935999999999999e-07,
      "logits/chosen": -2.5006139278411865,
      "logits/rejected": -1.688100814819336,
      "logps/chosen": -106.48390197753906,
      "logps/rejected": -152.6664581298828,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7388180494308472,
      "rewards/margins": 6.2730207443237305,
      "rewards/rejected": -4.534202575683594,
      "step": 1549
    },
    {
      "epoch": 0.62,
      "grad_norm": 4.199456691741943,
      "learning_rate": 7.934666666666666e-07,
      "logits/chosen": -2.9553885459899902,
      "logits/rejected": -2.618102788925171,
      "logps/chosen": -55.8065071105957,
      "logps/rejected": -74.7682113647461,
      "loss": 0.0846,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45198899507522583,
      "rewards/margins": 2.775113105773926,
      "rewards/rejected": -2.3231239318847656,
      "step": 1550
    },
    {
      "epoch": 0.6204,
      "grad_norm": 0.6613688468933105,
      "learning_rate": 7.933333333333333e-07,
      "logits/chosen": -2.544499397277832,
      "logits/rejected": -1.7448526620864868,
      "logps/chosen": -195.32199096679688,
      "logps/rejected": -124.05076599121094,
      "loss": 0.0068,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9509834051132202,
      "rewards/margins": 4.996004104614258,
      "rewards/rejected": -4.045021057128906,
      "step": 1551
    },
    {
      "epoch": 0.6208,
      "grad_norm": 1.2220757007598877,
      "learning_rate": 7.932e-07,
      "logits/chosen": -2.859029769897461,
      "logits/rejected": -2.092075824737549,
      "logps/chosen": -109.44435119628906,
      "logps/rejected": -174.35679626464844,
      "loss": 0.0177,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4327023029327393,
      "rewards/margins": 4.95664119720459,
      "rewards/rejected": -3.5239391326904297,
      "step": 1552
    },
    {
      "epoch": 0.6212,
      "grad_norm": 1.2340309619903564,
      "learning_rate": 7.930666666666667e-07,
      "logits/chosen": -2.7363414764404297,
      "logits/rejected": -2.2117815017700195,
      "logps/chosen": -126.11402130126953,
      "logps/rejected": -159.73114013671875,
      "loss": 0.0174,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5699348449707031,
      "rewards/margins": 4.256772518157959,
      "rewards/rejected": -3.686837673187256,
      "step": 1553
    },
    {
      "epoch": 0.6216,
      "grad_norm": 1.7837964296340942,
      "learning_rate": 7.929333333333334e-07,
      "logits/chosen": -2.774200916290283,
      "logits/rejected": -2.3319590091705322,
      "logps/chosen": -78.04479217529297,
      "logps/rejected": -82.07915496826172,
      "loss": 0.0297,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3846985101699829,
      "rewards/margins": 3.5180962085723877,
      "rewards/rejected": -3.1333975791931152,
      "step": 1554
    },
    {
      "epoch": 0.622,
      "grad_norm": 3.1115622520446777,
      "learning_rate": 7.928e-07,
      "logits/chosen": -2.7429075241088867,
      "logits/rejected": -2.3555350303649902,
      "logps/chosen": -93.69795989990234,
      "logps/rejected": -91.75916290283203,
      "loss": 0.0434,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6665054559707642,
      "rewards/margins": 4.467167377471924,
      "rewards/rejected": -2.800662040710449,
      "step": 1555
    },
    {
      "epoch": 0.6224,
      "grad_norm": 1.9971308708190918,
      "learning_rate": 7.926666666666666e-07,
      "logits/chosen": -2.7070565223693848,
      "logits/rejected": -2.344403028488159,
      "logps/chosen": -75.70845031738281,
      "logps/rejected": -121.57391357421875,
      "loss": 0.0212,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9449352622032166,
      "rewards/margins": 4.301446914672852,
      "rewards/rejected": -3.3565115928649902,
      "step": 1556
    },
    {
      "epoch": 0.6228,
      "grad_norm": 1.6468689441680908,
      "learning_rate": 7.925333333333332e-07,
      "logits/chosen": -2.784386396408081,
      "logits/rejected": -2.2102534770965576,
      "logps/chosen": -77.43208312988281,
      "logps/rejected": -81.35432434082031,
      "loss": 0.0269,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5649695992469788,
      "rewards/margins": 4.103780746459961,
      "rewards/rejected": -3.538811206817627,
      "step": 1557
    },
    {
      "epoch": 0.6232,
      "grad_norm": 5.048250198364258,
      "learning_rate": 7.923999999999999e-07,
      "logits/chosen": -2.092344284057617,
      "logits/rejected": -1.984964370727539,
      "logps/chosen": -108.75830078125,
      "logps/rejected": -92.2877197265625,
      "loss": 0.082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3221489191055298,
      "rewards/margins": 2.996066093444824,
      "rewards/rejected": -2.673917293548584,
      "step": 1558
    },
    {
      "epoch": 0.6236,
      "grad_norm": 2.5172817707061768,
      "learning_rate": 7.922666666666666e-07,
      "logits/chosen": -2.8278870582580566,
      "logits/rejected": -2.39835262298584,
      "logps/chosen": -167.08151245117188,
      "logps/rejected": -93.72381591796875,
      "loss": 0.0384,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9861782789230347,
      "rewards/margins": 3.2647953033447266,
      "rewards/rejected": -2.2786171436309814,
      "step": 1559
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.8174726963043213,
      "learning_rate": 7.921333333333333e-07,
      "logits/chosen": -2.3722004890441895,
      "logits/rejected": -1.6748592853546143,
      "logps/chosen": -147.4224090576172,
      "logps/rejected": -159.67578125,
      "loss": 0.0067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5786323547363281,
      "rewards/margins": 5.630147933959961,
      "rewards/rejected": -5.051515579223633,
      "step": 1560
    },
    {
      "epoch": 0.6244,
      "grad_norm": 0.6489421725273132,
      "learning_rate": 7.92e-07,
      "logits/chosen": -2.808800458908081,
      "logits/rejected": -1.8521792888641357,
      "logps/chosen": -109.48210144042969,
      "logps/rejected": -87.46890258789062,
      "loss": 0.01,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2512165307998657,
      "rewards/margins": 4.743269443511963,
      "rewards/rejected": -3.4920530319213867,
      "step": 1561
    },
    {
      "epoch": 0.6248,
      "grad_norm": 0.2873803973197937,
      "learning_rate": 7.918666666666667e-07,
      "logits/chosen": -2.6364710330963135,
      "logits/rejected": -1.8575725555419922,
      "logps/chosen": -171.53033447265625,
      "logps/rejected": -191.26458740234375,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9497169852256775,
      "rewards/margins": 6.594503402709961,
      "rewards/rejected": -5.6447858810424805,
      "step": 1562
    },
    {
      "epoch": 0.6252,
      "grad_norm": 2.2288694381713867,
      "learning_rate": 7.917333333333333e-07,
      "logits/chosen": -2.5762758255004883,
      "logits/rejected": -2.5222768783569336,
      "logps/chosen": -73.63896179199219,
      "logps/rejected": -114.06489562988281,
      "loss": 0.0324,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1347382068634033,
      "rewards/margins": 4.765702247619629,
      "rewards/rejected": -3.6309638023376465,
      "step": 1563
    },
    {
      "epoch": 0.6256,
      "grad_norm": 2.4755022525787354,
      "learning_rate": 7.916e-07,
      "logits/chosen": -3.0149989128112793,
      "logits/rejected": -2.495460271835327,
      "logps/chosen": -61.4609489440918,
      "logps/rejected": -79.01404571533203,
      "loss": 0.0355,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.059212490916252136,
      "rewards/margins": 3.429440498352051,
      "rewards/rejected": -3.3702280521392822,
      "step": 1564
    },
    {
      "epoch": 0.626,
      "grad_norm": 3.321688652038574,
      "learning_rate": 7.914666666666667e-07,
      "logits/chosen": -2.4548215866088867,
      "logits/rejected": -2.0829672813415527,
      "logps/chosen": -141.48583984375,
      "logps/rejected": -108.39480590820312,
      "loss": 0.0343,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1347549855709076,
      "rewards/margins": 4.339634895324707,
      "rewards/rejected": -4.474390029907227,
      "step": 1565
    },
    {
      "epoch": 0.6264,
      "grad_norm": 2.2344541549682617,
      "learning_rate": 7.913333333333332e-07,
      "logits/chosen": -2.8746368885040283,
      "logits/rejected": -2.4554476737976074,
      "logps/chosen": -85.01760864257812,
      "logps/rejected": -104.99334716796875,
      "loss": 0.0347,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6517825722694397,
      "rewards/margins": 4.43428897857666,
      "rewards/rejected": -3.782505989074707,
      "step": 1566
    },
    {
      "epoch": 0.6268,
      "grad_norm": 0.7256587147712708,
      "learning_rate": 7.911999999999999e-07,
      "logits/chosen": -3.010526418685913,
      "logits/rejected": -2.460681915283203,
      "logps/chosen": -64.54439544677734,
      "logps/rejected": -101.87263488769531,
      "loss": 0.0085,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0713839530944824,
      "rewards/margins": 4.761288642883301,
      "rewards/rejected": -3.6899044513702393,
      "step": 1567
    },
    {
      "epoch": 0.6272,
      "grad_norm": 3.367461681365967,
      "learning_rate": 7.910666666666666e-07,
      "logits/chosen": -2.7046995162963867,
      "logits/rejected": -2.479358673095703,
      "logps/chosen": -94.0093002319336,
      "logps/rejected": -59.082061767578125,
      "loss": 0.0617,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20536690950393677,
      "rewards/margins": 2.845550537109375,
      "rewards/rejected": -2.640183687210083,
      "step": 1568
    },
    {
      "epoch": 0.6276,
      "grad_norm": 3.922889471054077,
      "learning_rate": 7.909333333333333e-07,
      "logits/chosen": -3.051175117492676,
      "logits/rejected": -2.688852310180664,
      "logps/chosen": -67.10722351074219,
      "logps/rejected": -60.923885345458984,
      "loss": 0.0928,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17769813537597656,
      "rewards/margins": 2.3559792041778564,
      "rewards/rejected": -2.17828106880188,
      "step": 1569
    },
    {
      "epoch": 0.628,
      "grad_norm": 8.944154739379883,
      "learning_rate": 7.907999999999999e-07,
      "logits/chosen": -2.5571372509002686,
      "logits/rejected": -2.5706896781921387,
      "logps/chosen": -84.25341796875,
      "logps/rejected": -83.36651611328125,
      "loss": 0.1726,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2601453959941864,
      "rewards/margins": 1.7875235080718994,
      "rewards/rejected": -2.047668933868408,
      "step": 1570
    },
    {
      "epoch": 0.6284,
      "grad_norm": 1.6082699298858643,
      "learning_rate": 7.906666666666666e-07,
      "logits/chosen": -2.9158191680908203,
      "logits/rejected": -2.5538034439086914,
      "logps/chosen": -42.27238845825195,
      "logps/rejected": -84.23599243164062,
      "loss": 0.0327,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0285017490386963,
      "rewards/margins": 4.10030460357666,
      "rewards/rejected": -3.071803092956543,
      "step": 1571
    },
    {
      "epoch": 0.6288,
      "grad_norm": 1.5630524158477783,
      "learning_rate": 7.905333333333333e-07,
      "logits/chosen": -2.818546772003174,
      "logits/rejected": -2.803306818008423,
      "logps/chosen": -76.38569641113281,
      "logps/rejected": -102.47914123535156,
      "loss": 0.0248,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8943172693252563,
      "rewards/margins": 3.7354753017425537,
      "rewards/rejected": -2.841157913208008,
      "step": 1572
    },
    {
      "epoch": 0.6292,
      "grad_norm": 1.5484753847122192,
      "learning_rate": 7.904e-07,
      "logits/chosen": -2.642040729522705,
      "logits/rejected": -1.8663444519042969,
      "logps/chosen": -94.79109191894531,
      "logps/rejected": -92.5571060180664,
      "loss": 0.0236,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9167255163192749,
      "rewards/margins": 3.7553296089172363,
      "rewards/rejected": -2.838603973388672,
      "step": 1573
    },
    {
      "epoch": 0.6296,
      "grad_norm": 1.3482097387313843,
      "learning_rate": 7.902666666666667e-07,
      "logits/chosen": -3.002812385559082,
      "logits/rejected": -2.975153923034668,
      "logps/chosen": -62.13805389404297,
      "logps/rejected": -67.07319641113281,
      "loss": 0.0235,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6964653134346008,
      "rewards/margins": 3.7574191093444824,
      "rewards/rejected": -3.0609536170959473,
      "step": 1574
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.8729459643363953,
      "learning_rate": 7.901333333333334e-07,
      "logits/chosen": -2.981839179992676,
      "logits/rejected": -2.7521743774414062,
      "logps/chosen": -71.18707275390625,
      "logps/rejected": -90.27403259277344,
      "loss": 0.0126,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9916183948516846,
      "rewards/margins": 5.230724334716797,
      "rewards/rejected": -4.239105701446533,
      "step": 1575
    },
    {
      "epoch": 0.6304,
      "grad_norm": 0.06176295503973961,
      "learning_rate": 7.9e-07,
      "logits/chosen": -2.841130256652832,
      "logits/rejected": -2.224398612976074,
      "logps/chosen": -106.56326293945312,
      "logps/rejected": -183.97767639160156,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3222938776016235,
      "rewards/margins": 8.153684616088867,
      "rewards/rejected": -6.831390380859375,
      "step": 1576
    },
    {
      "epoch": 0.6308,
      "grad_norm": 5.163203239440918,
      "learning_rate": 7.898666666666666e-07,
      "logits/chosen": -2.5300707817077637,
      "logits/rejected": -1.8235291242599487,
      "logps/chosen": -126.11590576171875,
      "logps/rejected": -85.80162048339844,
      "loss": 0.0578,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9914578199386597,
      "rewards/margins": 4.468899726867676,
      "rewards/rejected": -3.4774422645568848,
      "step": 1577
    },
    {
      "epoch": 0.6312,
      "grad_norm": 2.649681806564331,
      "learning_rate": 7.897333333333332e-07,
      "logits/chosen": -3.131509304046631,
      "logits/rejected": -2.6142172813415527,
      "logps/chosen": -66.20550537109375,
      "logps/rejected": -67.86454772949219,
      "loss": 0.0676,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3380463123321533,
      "rewards/margins": 3.850925922393799,
      "rewards/rejected": -2.5128798484802246,
      "step": 1578
    },
    {
      "epoch": 0.6316,
      "grad_norm": 5.8688530921936035,
      "learning_rate": 7.895999999999999e-07,
      "logits/chosen": -2.93306303024292,
      "logits/rejected": -2.611786127090454,
      "logps/chosen": -53.031532287597656,
      "logps/rejected": -70.65501403808594,
      "loss": 0.0851,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13445664942264557,
      "rewards/margins": 2.4528892040252686,
      "rewards/rejected": -2.318432569503784,
      "step": 1579
    },
    {
      "epoch": 0.632,
      "grad_norm": 0.47308456897735596,
      "learning_rate": 7.894666666666666e-07,
      "logits/chosen": -2.464783191680908,
      "logits/rejected": -1.981247901916504,
      "logps/chosen": -84.71318817138672,
      "logps/rejected": -108.76164245605469,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5967059135437012,
      "rewards/margins": 5.399438858032227,
      "rewards/rejected": -3.8027329444885254,
      "step": 1580
    },
    {
      "epoch": 0.6324,
      "grad_norm": 2.3831064701080322,
      "learning_rate": 7.893333333333333e-07,
      "logits/chosen": -2.5996627807617188,
      "logits/rejected": -2.246142864227295,
      "logps/chosen": -93.92559814453125,
      "logps/rejected": -121.66716003417969,
      "loss": 0.0398,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06741559505462646,
      "rewards/margins": 3.2838377952575684,
      "rewards/rejected": -3.2164223194122314,
      "step": 1581
    },
    {
      "epoch": 0.6328,
      "grad_norm": 5.360423564910889,
      "learning_rate": 7.892e-07,
      "logits/chosen": -2.7775673866271973,
      "logits/rejected": -2.308863878250122,
      "logps/chosen": -148.83529663085938,
      "logps/rejected": -107.59471130371094,
      "loss": 0.0848,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35772743821144104,
      "rewards/margins": 3.601746082305908,
      "rewards/rejected": -3.2440185546875,
      "step": 1582
    },
    {
      "epoch": 0.6332,
      "grad_norm": 3.0589182376861572,
      "learning_rate": 7.890666666666667e-07,
      "logits/chosen": -2.589998245239258,
      "logits/rejected": -2.041402578353882,
      "logps/chosen": -89.04316711425781,
      "logps/rejected": -109.83940124511719,
      "loss": 0.0582,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2050853967666626,
      "rewards/margins": 4.568884372711182,
      "rewards/rejected": -3.3637986183166504,
      "step": 1583
    },
    {
      "epoch": 0.6336,
      "grad_norm": 6.3409247398376465,
      "learning_rate": 7.889333333333334e-07,
      "logits/chosen": -2.7052807807922363,
      "logits/rejected": -2.791818141937256,
      "logps/chosen": -134.7596435546875,
      "logps/rejected": -63.77275085449219,
      "loss": 0.0863,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34469300508499146,
      "rewards/margins": 2.634519338607788,
      "rewards/rejected": -2.2898263931274414,
      "step": 1584
    },
    {
      "epoch": 0.634,
      "grad_norm": 2.3051910400390625,
      "learning_rate": 7.887999999999999e-07,
      "logits/chosen": -3.1136748790740967,
      "logits/rejected": -2.4693779945373535,
      "logps/chosen": -53.058013916015625,
      "logps/rejected": -107.40957641601562,
      "loss": 0.0241,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7848846912384033,
      "rewards/margins": 4.62071418762207,
      "rewards/rejected": -3.835829734802246,
      "step": 1585
    },
    {
      "epoch": 0.6344,
      "grad_norm": 0.45171526074409485,
      "learning_rate": 7.886666666666666e-07,
      "logits/chosen": -2.500915050506592,
      "logits/rejected": -1.6882230043411255,
      "logps/chosen": -160.282470703125,
      "logps/rejected": -105.34861755371094,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9310927391052246,
      "rewards/margins": 6.3815107345581055,
      "rewards/rejected": -4.450417518615723,
      "step": 1586
    },
    {
      "epoch": 0.6348,
      "grad_norm": 2.9981470108032227,
      "learning_rate": 7.885333333333332e-07,
      "logits/chosen": -2.8108954429626465,
      "logits/rejected": -2.458627223968506,
      "logps/chosen": -63.883975982666016,
      "logps/rejected": -73.78459167480469,
      "loss": 0.0599,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.43949392437934875,
      "rewards/margins": 2.796825885772705,
      "rewards/rejected": -2.3573317527770996,
      "step": 1587
    },
    {
      "epoch": 0.6352,
      "grad_norm": 0.41679075360298157,
      "learning_rate": 7.883999999999999e-07,
      "logits/chosen": -2.84197998046875,
      "logits/rejected": -2.1172451972961426,
      "logps/chosen": -116.88406372070312,
      "logps/rejected": -111.30420684814453,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8620296120643616,
      "rewards/margins": 5.950872421264648,
      "rewards/rejected": -5.088842391967773,
      "step": 1588
    },
    {
      "epoch": 0.6356,
      "grad_norm": 1.1297274827957153,
      "learning_rate": 7.882666666666666e-07,
      "logits/chosen": -2.4846699237823486,
      "logits/rejected": -1.8334236145019531,
      "logps/chosen": -111.05641174316406,
      "logps/rejected": -136.83090209960938,
      "loss": 0.014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7161365747451782,
      "rewards/margins": 4.967917442321777,
      "rewards/rejected": -4.2517805099487305,
      "step": 1589
    },
    {
      "epoch": 0.636,
      "grad_norm": 0.8458700180053711,
      "learning_rate": 7.881333333333333e-07,
      "logits/chosen": -3.0606751441955566,
      "logits/rejected": -2.48722505569458,
      "logps/chosen": -80.3626480102539,
      "logps/rejected": -83.88175201416016,
      "loss": 0.0111,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9669445157051086,
      "rewards/margins": 4.503830909729004,
      "rewards/rejected": -3.536886692047119,
      "step": 1590
    },
    {
      "epoch": 0.6364,
      "grad_norm": 1.7474186420440674,
      "learning_rate": 7.88e-07,
      "logits/chosen": -2.9445323944091797,
      "logits/rejected": -2.242495536804199,
      "logps/chosen": -45.27822494506836,
      "logps/rejected": -101.79862976074219,
      "loss": 0.0259,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5521534085273743,
      "rewards/margins": 4.1747565269470215,
      "rewards/rejected": -3.622602939605713,
      "step": 1591
    },
    {
      "epoch": 0.6368,
      "grad_norm": 0.12651941180229187,
      "learning_rate": 7.878666666666667e-07,
      "logits/chosen": -2.734884262084961,
      "logits/rejected": -2.0686426162719727,
      "logps/chosen": -99.48451232910156,
      "logps/rejected": -121.91822052001953,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3623287677764893,
      "rewards/margins": 6.680706977844238,
      "rewards/rejected": -5.318378448486328,
      "step": 1592
    },
    {
      "epoch": 0.6372,
      "grad_norm": 1.1314839124679565,
      "learning_rate": 7.877333333333333e-07,
      "logits/chosen": -3.1604528427124023,
      "logits/rejected": -2.757680654525757,
      "logps/chosen": -37.67411422729492,
      "logps/rejected": -70.71607208251953,
      "loss": 0.023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.245697259902954,
      "rewards/margins": 4.248734951019287,
      "rewards/rejected": -3.003037691116333,
      "step": 1593
    },
    {
      "epoch": 0.6376,
      "grad_norm": 2.126462459564209,
      "learning_rate": 7.875999999999999e-07,
      "logits/chosen": -2.5725598335266113,
      "logits/rejected": -2.265409469604492,
      "logps/chosen": -187.92408752441406,
      "logps/rejected": -108.6226577758789,
      "loss": 0.025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6182754635810852,
      "rewards/margins": 4.548391819000244,
      "rewards/rejected": -3.9301161766052246,
      "step": 1594
    },
    {
      "epoch": 0.638,
      "grad_norm": 1.3376461267471313,
      "learning_rate": 7.874666666666666e-07,
      "logits/chosen": -2.792628288269043,
      "logits/rejected": -2.3399178981781006,
      "logps/chosen": -122.16504669189453,
      "logps/rejected": -117.25991821289062,
      "loss": 0.0189,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4122631549835205,
      "rewards/margins": 4.289106369018555,
      "rewards/rejected": -2.876842975616455,
      "step": 1595
    },
    {
      "epoch": 0.6384,
      "grad_norm": 1.6242778301239014,
      "learning_rate": 7.873333333333333e-07,
      "logits/chosen": -2.8559417724609375,
      "logits/rejected": -2.2723865509033203,
      "logps/chosen": -80.22211456298828,
      "logps/rejected": -108.19796752929688,
      "loss": 0.0186,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5935331583023071,
      "rewards/margins": 4.153676986694336,
      "rewards/rejected": -2.5601439476013184,
      "step": 1596
    },
    {
      "epoch": 0.6388,
      "grad_norm": 2.875433921813965,
      "learning_rate": 7.872e-07,
      "logits/chosen": -3.0356357097625732,
      "logits/rejected": -2.7638139724731445,
      "logps/chosen": -65.3543930053711,
      "logps/rejected": -101.61589813232422,
      "loss": 0.0383,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6933792233467102,
      "rewards/margins": 4.170947551727295,
      "rewards/rejected": -3.4775683879852295,
      "step": 1597
    },
    {
      "epoch": 0.6392,
      "grad_norm": 1.8066847324371338,
      "learning_rate": 7.870666666666666e-07,
      "logits/chosen": -2.615795135498047,
      "logits/rejected": -2.1210122108459473,
      "logps/chosen": -111.42766571044922,
      "logps/rejected": -96.44577026367188,
      "loss": 0.0214,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.07500763237476349,
      "rewards/margins": 4.3119988441467285,
      "rewards/rejected": -4.387006759643555,
      "step": 1598
    },
    {
      "epoch": 0.6396,
      "grad_norm": 0.5395947694778442,
      "learning_rate": 7.869333333333333e-07,
      "logits/chosen": -2.8294460773468018,
      "logits/rejected": -2.1503090858459473,
      "logps/chosen": -74.30882263183594,
      "logps/rejected": -103.65501403808594,
      "loss": 0.0061,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0984455347061157,
      "rewards/margins": 5.316946029663086,
      "rewards/rejected": -4.21850061416626,
      "step": 1599
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.4991728067398071,
      "learning_rate": 7.868e-07,
      "logits/chosen": -2.702479839324951,
      "logits/rejected": -1.9981722831726074,
      "logps/chosen": -105.56137084960938,
      "logps/rejected": -99.60816955566406,
      "loss": 0.0177,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.986572265625,
      "rewards/margins": 4.311448097229004,
      "rewards/rejected": -3.3248753547668457,
      "step": 1600
    },
    {
      "epoch": 0.6404,
      "grad_norm": 2.7562601566314697,
      "learning_rate": 7.866666666666666e-07,
      "logits/chosen": -2.8127877712249756,
      "logits/rejected": -2.4983270168304443,
      "logps/chosen": -121.22520446777344,
      "logps/rejected": -126.76557159423828,
      "loss": 0.0273,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.612015962600708,
      "rewards/margins": 4.328908443450928,
      "rewards/rejected": -3.7168922424316406,
      "step": 1601
    },
    {
      "epoch": 0.6408,
      "grad_norm": 0.4653206169605255,
      "learning_rate": 7.865333333333333e-07,
      "logits/chosen": -2.542994260787964,
      "logits/rejected": -1.8565691709518433,
      "logps/chosen": -110.62681579589844,
      "logps/rejected": -94.3406982421875,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.516223192214966,
      "rewards/margins": 6.065442085266113,
      "rewards/rejected": -3.5492186546325684,
      "step": 1602
    },
    {
      "epoch": 0.6412,
      "grad_norm": 19.355403900146484,
      "learning_rate": 7.864e-07,
      "logits/chosen": -2.3544790744781494,
      "logits/rejected": -2.1389715671539307,
      "logps/chosen": -130.7767791748047,
      "logps/rejected": -129.20892333984375,
      "loss": 0.2169,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8857380747795105,
      "rewards/margins": 2.071397304534912,
      "rewards/rejected": -2.9571354389190674,
      "step": 1603
    },
    {
      "epoch": 0.6416,
      "grad_norm": 1.6395360231399536,
      "learning_rate": 7.862666666666666e-07,
      "logits/chosen": -2.6938140392303467,
      "logits/rejected": -2.0122060775756836,
      "logps/chosen": -78.84940338134766,
      "logps/rejected": -87.85252380371094,
      "loss": 0.0296,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.377084344625473,
      "rewards/margins": 3.7554636001586914,
      "rewards/rejected": -3.3783793449401855,
      "step": 1604
    },
    {
      "epoch": 0.642,
      "grad_norm": 0.9996694922447205,
      "learning_rate": 7.861333333333333e-07,
      "logits/chosen": -2.6893622875213623,
      "logits/rejected": -1.8840789794921875,
      "logps/chosen": -190.7816162109375,
      "logps/rejected": -135.163330078125,
      "loss": 0.0085,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1184463500976562,
      "rewards/margins": 6.4958977699279785,
      "rewards/rejected": -5.377451419830322,
      "step": 1605
    },
    {
      "epoch": 0.6424,
      "grad_norm": 0.9360650777816772,
      "learning_rate": 7.86e-07,
      "logits/chosen": -2.980398654937744,
      "logits/rejected": -2.4889183044433594,
      "logps/chosen": -76.5162582397461,
      "logps/rejected": -95.35307312011719,
      "loss": 0.0113,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24078255891799927,
      "rewards/margins": 4.503734588623047,
      "rewards/rejected": -4.262951850891113,
      "step": 1606
    },
    {
      "epoch": 0.6428,
      "grad_norm": 0.9994831681251526,
      "learning_rate": 7.858666666666667e-07,
      "logits/chosen": -2.5930795669555664,
      "logits/rejected": -2.2233104705810547,
      "logps/chosen": -202.2817840576172,
      "logps/rejected": -128.94467163085938,
      "loss": 0.0101,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4096500277519226,
      "rewards/margins": 4.652347087860107,
      "rewards/rejected": -4.242696762084961,
      "step": 1607
    },
    {
      "epoch": 0.6432,
      "grad_norm": 0.7637736201286316,
      "learning_rate": 7.857333333333332e-07,
      "logits/chosen": -2.9161887168884277,
      "logits/rejected": -2.3822288513183594,
      "logps/chosen": -102.78456115722656,
      "logps/rejected": -121.32339477539062,
      "loss": 0.0088,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22061768174171448,
      "rewards/margins": 4.9459099769592285,
      "rewards/rejected": -4.725292205810547,
      "step": 1608
    },
    {
      "epoch": 0.6436,
      "grad_norm": 4.533402442932129,
      "learning_rate": 7.855999999999999e-07,
      "logits/chosen": -2.898336887359619,
      "logits/rejected": -2.5976781845092773,
      "logps/chosen": -115.57258605957031,
      "logps/rejected": -78.33012390136719,
      "loss": 0.0489,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38689079880714417,
      "rewards/margins": 3.4678359031677246,
      "rewards/rejected": -3.0809450149536133,
      "step": 1609
    },
    {
      "epoch": 0.644,
      "grad_norm": 1.5145716667175293,
      "learning_rate": 7.854666666666666e-07,
      "logits/chosen": -2.803961753845215,
      "logits/rejected": -2.6230363845825195,
      "logps/chosen": -81.1867904663086,
      "logps/rejected": -97.29340362548828,
      "loss": 0.0228,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.14247970283031464,
      "rewards/margins": 3.8963119983673096,
      "rewards/rejected": -4.038791656494141,
      "step": 1610
    },
    {
      "epoch": 0.6444,
      "grad_norm": 4.811858654022217,
      "learning_rate": 7.853333333333333e-07,
      "logits/chosen": -2.8307251930236816,
      "logits/rejected": -2.383507490158081,
      "logps/chosen": -76.7587890625,
      "logps/rejected": -84.42882537841797,
      "loss": 0.0573,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6184530258178711,
      "rewards/margins": 2.872814178466797,
      "rewards/rejected": -3.491267204284668,
      "step": 1611
    },
    {
      "epoch": 0.6448,
      "grad_norm": 2.9196763038635254,
      "learning_rate": 7.852e-07,
      "logits/chosen": -2.8947296142578125,
      "logits/rejected": -2.257864475250244,
      "logps/chosen": -96.9125747680664,
      "logps/rejected": -92.73291778564453,
      "loss": 0.027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42640113830566406,
      "rewards/margins": 4.259210109710693,
      "rewards/rejected": -3.8328089714050293,
      "step": 1612
    },
    {
      "epoch": 0.6452,
      "grad_norm": 0.2167728841304779,
      "learning_rate": 7.850666666666666e-07,
      "logits/chosen": -2.528048515319824,
      "logits/rejected": -1.962857723236084,
      "logps/chosen": -121.81840515136719,
      "logps/rejected": -115.6590805053711,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.25724196434021,
      "rewards/margins": 6.776086807250977,
      "rewards/rejected": -4.5188446044921875,
      "step": 1613
    },
    {
      "epoch": 0.6456,
      "grad_norm": 7.108586311340332,
      "learning_rate": 7.849333333333333e-07,
      "logits/chosen": -3.0167441368103027,
      "logits/rejected": -2.3653504848480225,
      "logps/chosen": -105.60250854492188,
      "logps/rejected": -81.38050079345703,
      "loss": 0.0722,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.289341539144516,
      "rewards/margins": 3.4481873512268066,
      "rewards/rejected": -3.158845901489258,
      "step": 1614
    },
    {
      "epoch": 0.646,
      "grad_norm": 0.8780753016471863,
      "learning_rate": 7.848e-07,
      "logits/chosen": -2.578968048095703,
      "logits/rejected": -2.0547642707824707,
      "logps/chosen": -97.22137451171875,
      "logps/rejected": -101.36619567871094,
      "loss": 0.0133,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7422196865081787,
      "rewards/margins": 4.813348293304443,
      "rewards/rejected": -3.0711288452148438,
      "step": 1615
    },
    {
      "epoch": 0.6464,
      "grad_norm": 5.517170429229736,
      "learning_rate": 7.846666666666666e-07,
      "logits/chosen": -2.744943141937256,
      "logits/rejected": -2.32082200050354,
      "logps/chosen": -141.2023468017578,
      "logps/rejected": -98.29243469238281,
      "loss": 0.0695,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6176528930664062,
      "rewards/margins": 3.8235418796539307,
      "rewards/rejected": -3.2058889865875244,
      "step": 1616
    },
    {
      "epoch": 0.6468,
      "grad_norm": 14.168854713439941,
      "learning_rate": 7.845333333333333e-07,
      "logits/chosen": -2.7566511631011963,
      "logits/rejected": -2.7070493698120117,
      "logps/chosen": -109.142333984375,
      "logps/rejected": -70.6322021484375,
      "loss": 0.2048,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.40861549973487854,
      "rewards/margins": 1.694809913635254,
      "rewards/rejected": -2.1034252643585205,
      "step": 1617
    },
    {
      "epoch": 0.6472,
      "grad_norm": 1.7021887302398682,
      "learning_rate": 7.844e-07,
      "logits/chosen": -2.716771364212036,
      "logits/rejected": -1.9920685291290283,
      "logps/chosen": -120.32716369628906,
      "logps/rejected": -84.41465759277344,
      "loss": 0.0231,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39568063616752625,
      "rewards/margins": 3.7946293354034424,
      "rewards/rejected": -3.3989486694335938,
      "step": 1618
    },
    {
      "epoch": 0.6476,
      "grad_norm": 2.6224279403686523,
      "learning_rate": 7.842666666666666e-07,
      "logits/chosen": -3.03690242767334,
      "logits/rejected": -2.8470213413238525,
      "logps/chosen": -73.07156372070312,
      "logps/rejected": -95.0825424194336,
      "loss": 0.0487,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6748844385147095,
      "rewards/margins": 4.431313991546631,
      "rewards/rejected": -3.756429433822632,
      "step": 1619
    },
    {
      "epoch": 0.648,
      "grad_norm": 1.1496504545211792,
      "learning_rate": 7.841333333333333e-07,
      "logits/chosen": -2.681525945663452,
      "logits/rejected": -2.6959822177886963,
      "logps/chosen": -123.33197021484375,
      "logps/rejected": -91.94757843017578,
      "loss": 0.0139,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6436759829521179,
      "rewards/margins": 4.888162136077881,
      "rewards/rejected": -4.244485855102539,
      "step": 1620
    },
    {
      "epoch": 0.6484,
      "grad_norm": 0.6610074639320374,
      "learning_rate": 7.84e-07,
      "logits/chosen": -2.608391284942627,
      "logits/rejected": -2.069629192352295,
      "logps/chosen": -89.11526489257812,
      "logps/rejected": -129.9111328125,
      "loss": 0.0089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9912750720977783,
      "rewards/margins": 5.607400417327881,
      "rewards/rejected": -4.616125583648682,
      "step": 1621
    },
    {
      "epoch": 0.6488,
      "grad_norm": 0.0688176229596138,
      "learning_rate": 7.838666666666667e-07,
      "logits/chosen": -2.8235931396484375,
      "logits/rejected": -2.238677501678467,
      "logps/chosen": -114.07825469970703,
      "logps/rejected": -165.40000915527344,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14979171752929688,
      "rewards/margins": 8.621060371398926,
      "rewards/rejected": -8.471268653869629,
      "step": 1622
    },
    {
      "epoch": 0.6492,
      "grad_norm": 7.066525459289551,
      "learning_rate": 7.837333333333332e-07,
      "logits/chosen": -2.737520217895508,
      "logits/rejected": -2.1956169605255127,
      "logps/chosen": -48.168766021728516,
      "logps/rejected": -107.78441619873047,
      "loss": 0.128,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14151859283447266,
      "rewards/margins": 4.741451740264893,
      "rewards/rejected": -4.59993314743042,
      "step": 1623
    },
    {
      "epoch": 0.6496,
      "grad_norm": 0.8824242353439331,
      "learning_rate": 7.835999999999999e-07,
      "logits/chosen": -2.9817073345184326,
      "logits/rejected": -2.397573471069336,
      "logps/chosen": -55.59980773925781,
      "logps/rejected": -88.18524932861328,
      "loss": 0.0136,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1198112964630127,
      "rewards/margins": 4.36279296875,
      "rewards/rejected": -3.242981433868408,
      "step": 1624
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.22422781586647034,
      "learning_rate": 7.834666666666666e-07,
      "logits/chosen": -2.5758187770843506,
      "logits/rejected": -2.178389310836792,
      "logps/chosen": -70.5195083618164,
      "logps/rejected": -128.5117950439453,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9360508918762207,
      "rewards/margins": 6.231308937072754,
      "rewards/rejected": -4.295257568359375,
      "step": 1625
    },
    {
      "epoch": 0.6504,
      "grad_norm": 0.20717830955982208,
      "learning_rate": 7.833333333333333e-07,
      "logits/chosen": -2.760007619857788,
      "logits/rejected": -2.030343532562256,
      "logps/chosen": -98.70571899414062,
      "logps/rejected": -166.64041137695312,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2075122594833374,
      "rewards/margins": 5.99256706237793,
      "rewards/rejected": -4.7850542068481445,
      "step": 1626
    },
    {
      "epoch": 0.6508,
      "grad_norm": 1.0874031782150269,
      "learning_rate": 7.832e-07,
      "logits/chosen": -2.7314672470092773,
      "logits/rejected": -2.275876045227051,
      "logps/chosen": -97.32186889648438,
      "logps/rejected": -88.7785415649414,
      "loss": 0.0158,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5082629919052124,
      "rewards/margins": 4.703943729400635,
      "rewards/rejected": -3.195680618286133,
      "step": 1627
    },
    {
      "epoch": 0.6512,
      "grad_norm": 2.6123626232147217,
      "learning_rate": 7.830666666666667e-07,
      "logits/chosen": -2.9473118782043457,
      "logits/rejected": -2.926677703857422,
      "logps/chosen": -100.91560363769531,
      "logps/rejected": -62.253231048583984,
      "loss": 0.0515,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6315708160400391,
      "rewards/margins": 2.9590418338775635,
      "rewards/rejected": -2.3274710178375244,
      "step": 1628
    },
    {
      "epoch": 0.6516,
      "grad_norm": 13.09637451171875,
      "learning_rate": 7.829333333333334e-07,
      "logits/chosen": -2.485055446624756,
      "logits/rejected": -2.06735897064209,
      "logps/chosen": -183.92127990722656,
      "logps/rejected": -102.0574951171875,
      "loss": 0.1242,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5465469360351562,
      "rewards/margins": 3.26989483833313,
      "rewards/rejected": -4.816441535949707,
      "step": 1629
    },
    {
      "epoch": 0.652,
      "grad_norm": 0.5074093341827393,
      "learning_rate": 7.828e-07,
      "logits/chosen": -3.2322072982788086,
      "logits/rejected": -2.6610007286071777,
      "logps/chosen": -49.483001708984375,
      "logps/rejected": -117.12084197998047,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9444071054458618,
      "rewards/margins": 6.067253112792969,
      "rewards/rejected": -5.1228461265563965,
      "step": 1630
    },
    {
      "epoch": 0.6524,
      "grad_norm": 0.6753920316696167,
      "learning_rate": 7.826666666666666e-07,
      "logits/chosen": -2.775777816772461,
      "logits/rejected": -2.1513609886169434,
      "logps/chosen": -97.43219757080078,
      "logps/rejected": -137.93775939941406,
      "loss": 0.0073,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3863366842269897,
      "rewards/margins": 6.134472846984863,
      "rewards/rejected": -4.748136043548584,
      "step": 1631
    },
    {
      "epoch": 0.6528,
      "grad_norm": 1.230582594871521,
      "learning_rate": 7.825333333333332e-07,
      "logits/chosen": -2.959364891052246,
      "logits/rejected": -2.545149326324463,
      "logps/chosen": -52.061927795410156,
      "logps/rejected": -96.8260498046875,
      "loss": 0.0188,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7308202981948853,
      "rewards/margins": 4.966758728027344,
      "rewards/rejected": -4.23593807220459,
      "step": 1632
    },
    {
      "epoch": 0.6532,
      "grad_norm": 0.660787045955658,
      "learning_rate": 7.823999999999999e-07,
      "logits/chosen": -2.9130125045776367,
      "logits/rejected": -2.138329267501831,
      "logps/chosen": -74.53364562988281,
      "logps/rejected": -106.59152221679688,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1203594207763672,
      "rewards/margins": 5.410036087036133,
      "rewards/rejected": -4.289676666259766,
      "step": 1633
    },
    {
      "epoch": 0.6536,
      "grad_norm": 3.349691867828369,
      "learning_rate": 7.822666666666666e-07,
      "logits/chosen": -3.036472797393799,
      "logits/rejected": -2.5629653930664062,
      "logps/chosen": -49.31719207763672,
      "logps/rejected": -73.66426849365234,
      "loss": 0.0792,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08667317032814026,
      "rewards/margins": 2.63207745552063,
      "rewards/rejected": -2.7187507152557373,
      "step": 1634
    },
    {
      "epoch": 0.654,
      "grad_norm": 5.340961456298828,
      "learning_rate": 7.821333333333333e-07,
      "logits/chosen": -3.085218667984009,
      "logits/rejected": -2.6746909618377686,
      "logps/chosen": -54.23868942260742,
      "logps/rejected": -87.22968292236328,
      "loss": 0.0707,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2043609619140625,
      "rewards/margins": 3.3903567790985107,
      "rewards/rejected": -3.1859958171844482,
      "step": 1635
    },
    {
      "epoch": 0.6544,
      "grad_norm": 6.38564395904541,
      "learning_rate": 7.82e-07,
      "logits/chosen": -2.818671703338623,
      "logits/rejected": -2.2624330520629883,
      "logps/chosen": -100.4974365234375,
      "logps/rejected": -107.5937728881836,
      "loss": 0.0879,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0028822422027588,
      "rewards/margins": 4.371415138244629,
      "rewards/rejected": -3.368533134460449,
      "step": 1636
    },
    {
      "epoch": 0.6548,
      "grad_norm": 3.402235746383667,
      "learning_rate": 7.818666666666667e-07,
      "logits/chosen": -3.0079636573791504,
      "logits/rejected": -2.679910898208618,
      "logps/chosen": -46.78929138183594,
      "logps/rejected": -78.50250244140625,
      "loss": 0.0825,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4990547299385071,
      "rewards/margins": 2.9757776260375977,
      "rewards/rejected": -3.47483229637146,
      "step": 1637
    },
    {
      "epoch": 0.6552,
      "grad_norm": 0.5156183242797852,
      "learning_rate": 7.817333333333333e-07,
      "logits/chosen": -3.0528697967529297,
      "logits/rejected": -2.383523941040039,
      "logps/chosen": -75.00897216796875,
      "logps/rejected": -109.4549560546875,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3910476565361023,
      "rewards/margins": 5.77583122253418,
      "rewards/rejected": -5.3847832679748535,
      "step": 1638
    },
    {
      "epoch": 0.6556,
      "grad_norm": 2.3331756591796875,
      "learning_rate": 7.816e-07,
      "logits/chosen": -2.806825876235962,
      "logits/rejected": -2.809479236602783,
      "logps/chosen": -73.91961669921875,
      "logps/rejected": -180.13223266601562,
      "loss": 0.0411,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.081322431564331,
      "rewards/margins": 3.9807658195495605,
      "rewards/rejected": -2.8994433879852295,
      "step": 1639
    },
    {
      "epoch": 0.656,
      "grad_norm": 4.735572338104248,
      "learning_rate": 7.814666666666666e-07,
      "logits/chosen": -3.1002936363220215,
      "logits/rejected": -2.5598936080932617,
      "logps/chosen": -91.99051666259766,
      "logps/rejected": -63.62694549560547,
      "loss": 0.0585,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3482372462749481,
      "rewards/margins": 3.4892029762268066,
      "rewards/rejected": -3.140965700149536,
      "step": 1640
    },
    {
      "epoch": 0.6564,
      "grad_norm": 1.1323693990707397,
      "learning_rate": 7.813333333333332e-07,
      "logits/chosen": -2.738175630569458,
      "logits/rejected": -2.3249125480651855,
      "logps/chosen": -111.391845703125,
      "logps/rejected": -102.84434509277344,
      "loss": 0.0141,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3249332904815674,
      "rewards/margins": 5.3904547691345215,
      "rewards/rejected": -4.065521717071533,
      "step": 1641
    },
    {
      "epoch": 0.6568,
      "grad_norm": 2.1039414405822754,
      "learning_rate": 7.811999999999999e-07,
      "logits/chosen": -3.179293155670166,
      "logits/rejected": -2.6872825622558594,
      "logps/chosen": -50.576332092285156,
      "logps/rejected": -68.0700454711914,
      "loss": 0.033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6177940368652344,
      "rewards/margins": 3.5254690647125244,
      "rewards/rejected": -2.907674789428711,
      "step": 1642
    },
    {
      "epoch": 0.6572,
      "grad_norm": 12.117118835449219,
      "learning_rate": 7.810666666666666e-07,
      "logits/chosen": -2.4671449661254883,
      "logits/rejected": -2.167616844177246,
      "logps/chosen": -164.52638244628906,
      "logps/rejected": -114.66480255126953,
      "loss": 0.1122,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9341720342636108,
      "rewards/margins": 2.6466100215911865,
      "rewards/rejected": -3.580781936645508,
      "step": 1643
    },
    {
      "epoch": 0.6576,
      "grad_norm": 4.248092174530029,
      "learning_rate": 7.809333333333333e-07,
      "logits/chosen": -2.831087112426758,
      "logits/rejected": -2.4722299575805664,
      "logps/chosen": -75.84226989746094,
      "logps/rejected": -74.46293640136719,
      "loss": 0.0738,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05195045471191406,
      "rewards/margins": 3.364346981048584,
      "rewards/rejected": -3.31239652633667,
      "step": 1644
    },
    {
      "epoch": 0.658,
      "grad_norm": 3.68153715133667,
      "learning_rate": 7.808e-07,
      "logits/chosen": -2.8002405166625977,
      "logits/rejected": -2.499429702758789,
      "logps/chosen": -68.86708068847656,
      "logps/rejected": -79.19512939453125,
      "loss": 0.0473,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7472854852676392,
      "rewards/margins": 3.492790699005127,
      "rewards/rejected": -2.7455053329467773,
      "step": 1645
    },
    {
      "epoch": 0.6584,
      "grad_norm": 0.5378289818763733,
      "learning_rate": 7.806666666666666e-07,
      "logits/chosen": -3.201103925704956,
      "logits/rejected": -2.614382743835449,
      "logps/chosen": -81.67334747314453,
      "logps/rejected": -100.64546966552734,
      "loss": 0.0057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0480873584747314,
      "rewards/margins": 5.959265232086182,
      "rewards/rejected": -4.911178112030029,
      "step": 1646
    },
    {
      "epoch": 0.6588,
      "grad_norm": 1.849172592163086,
      "learning_rate": 7.805333333333333e-07,
      "logits/chosen": -2.8210396766662598,
      "logits/rejected": -2.2446117401123047,
      "logps/chosen": -136.7799072265625,
      "logps/rejected": -83.13896942138672,
      "loss": 0.0368,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.11783771216869354,
      "rewards/margins": 3.434373140335083,
      "rewards/rejected": -3.552210807800293,
      "step": 1647
    },
    {
      "epoch": 0.6592,
      "grad_norm": 2.7324373722076416,
      "learning_rate": 7.804e-07,
      "logits/chosen": -2.7070679664611816,
      "logits/rejected": -2.2221109867095947,
      "logps/chosen": -166.33444213867188,
      "logps/rejected": -103.41824340820312,
      "loss": 0.0361,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9752590656280518,
      "rewards/margins": 3.3783934116363525,
      "rewards/rejected": -4.353652477264404,
      "step": 1648
    },
    {
      "epoch": 0.6596,
      "grad_norm": 4.690195560455322,
      "learning_rate": 7.802666666666667e-07,
      "logits/chosen": -3.2618656158447266,
      "logits/rejected": -2.785275459289551,
      "logps/chosen": -56.932411193847656,
      "logps/rejected": -91.94355773925781,
      "loss": 0.0606,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2491232007741928,
      "rewards/margins": 4.145941257476807,
      "rewards/rejected": -3.896817922592163,
      "step": 1649
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.7614569664001465,
      "learning_rate": 7.801333333333334e-07,
      "logits/chosen": -2.983433723449707,
      "logits/rejected": -2.6542019844055176,
      "logps/chosen": -72.4013900756836,
      "logps/rejected": -83.80950927734375,
      "loss": 0.0102,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0907840728759766,
      "rewards/margins": 5.472565650939941,
      "rewards/rejected": -4.381781578063965,
      "step": 1650
    },
    {
      "epoch": 0.6604,
      "grad_norm": 0.8788268566131592,
      "learning_rate": 7.799999999999999e-07,
      "logits/chosen": -2.714514970779419,
      "logits/rejected": -2.403773784637451,
      "logps/chosen": -83.3624038696289,
      "logps/rejected": -67.52740478515625,
      "loss": 0.0126,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9467601776123047,
      "rewards/margins": 4.374451637268066,
      "rewards/rejected": -3.42769193649292,
      "step": 1651
    },
    {
      "epoch": 0.6608,
      "grad_norm": 3.3127472400665283,
      "learning_rate": 7.798666666666666e-07,
      "logits/chosen": -2.8432931900024414,
      "logits/rejected": -2.469961643218994,
      "logps/chosen": -61.39314651489258,
      "logps/rejected": -140.0240478515625,
      "loss": 0.0497,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5245454907417297,
      "rewards/margins": 5.238171100616455,
      "rewards/rejected": -4.713625431060791,
      "step": 1652
    },
    {
      "epoch": 0.6612,
      "grad_norm": 1.5750579833984375,
      "learning_rate": 7.797333333333332e-07,
      "logits/chosen": -3.0670623779296875,
      "logits/rejected": -2.7962265014648438,
      "logps/chosen": -88.46733093261719,
      "logps/rejected": -81.69709777832031,
      "loss": 0.0268,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.46728211641311646,
      "rewards/margins": 3.7056541442871094,
      "rewards/rejected": -3.2383720874786377,
      "step": 1653
    },
    {
      "epoch": 0.6616,
      "grad_norm": 16.955650329589844,
      "learning_rate": 7.795999999999999e-07,
      "logits/chosen": -2.9292168617248535,
      "logits/rejected": -2.480721950531006,
      "logps/chosen": -103.23583221435547,
      "logps/rejected": -88.43202209472656,
      "loss": 0.1444,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.506752073764801,
      "rewards/margins": 2.4843368530273438,
      "rewards/rejected": -2.9910888671875,
      "step": 1654
    },
    {
      "epoch": 0.662,
      "grad_norm": 1.8892014026641846,
      "learning_rate": 7.794666666666666e-07,
      "logits/chosen": -3.073474884033203,
      "logits/rejected": -2.5862865447998047,
      "logps/chosen": -60.29655456542969,
      "logps/rejected": -82.4352798461914,
      "loss": 0.0225,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.37995851039886475,
      "rewards/margins": 4.921284198760986,
      "rewards/rejected": -4.541325569152832,
      "step": 1655
    },
    {
      "epoch": 0.6624,
      "grad_norm": 1.8867586851119995,
      "learning_rate": 7.793333333333333e-07,
      "logits/chosen": -2.8544211387634277,
      "logits/rejected": -2.1232805252075195,
      "logps/chosen": -104.79873657226562,
      "logps/rejected": -115.83499145507812,
      "loss": 0.02,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04616588354110718,
      "rewards/margins": 4.383664131164551,
      "rewards/rejected": -4.337498188018799,
      "step": 1656
    },
    {
      "epoch": 0.6628,
      "grad_norm": 1.9053924083709717,
      "learning_rate": 7.792e-07,
      "logits/chosen": -2.941469669342041,
      "logits/rejected": -2.593507766723633,
      "logps/chosen": -138.83111572265625,
      "logps/rejected": -95.23648071289062,
      "loss": 0.0221,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3672736883163452,
      "rewards/margins": 4.112851142883301,
      "rewards/rejected": -3.745577812194824,
      "step": 1657
    },
    {
      "epoch": 0.6632,
      "grad_norm": 24.38728141784668,
      "learning_rate": 7.790666666666667e-07,
      "logits/chosen": -2.6488704681396484,
      "logits/rejected": -2.8858842849731445,
      "logps/chosen": -147.8062744140625,
      "logps/rejected": -69.30419921875,
      "loss": 0.2652,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.1275134086608887,
      "rewards/margins": 1.252087116241455,
      "rewards/rejected": -3.3796005249023438,
      "step": 1658
    },
    {
      "epoch": 0.6636,
      "grad_norm": 3.330261707305908,
      "learning_rate": 7.789333333333334e-07,
      "logits/chosen": -3.013169288635254,
      "logits/rejected": -2.3629565238952637,
      "logps/chosen": -63.939308166503906,
      "logps/rejected": -101.23028564453125,
      "loss": 0.0274,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07039681077003479,
      "rewards/margins": 4.883554935455322,
      "rewards/rejected": -4.81315803527832,
      "step": 1659
    },
    {
      "epoch": 0.664,
      "grad_norm": 6.29743766784668,
      "learning_rate": 7.788000000000001e-07,
      "logits/chosen": -2.8855433464050293,
      "logits/rejected": -2.166734218597412,
      "logps/chosen": -131.33282470703125,
      "logps/rejected": -117.9273910522461,
      "loss": 0.096,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10841330885887146,
      "rewards/margins": 4.6024274826049805,
      "rewards/rejected": -4.710840702056885,
      "step": 1660
    },
    {
      "epoch": 0.6644,
      "grad_norm": 0.36077868938446045,
      "learning_rate": 7.786666666666665e-07,
      "logits/chosen": -2.958493709564209,
      "logits/rejected": -2.218334197998047,
      "logps/chosen": -76.83436584472656,
      "logps/rejected": -102.58119201660156,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.129337787628174,
      "rewards/margins": 6.6283278465271,
      "rewards/rejected": -4.498989582061768,
      "step": 1661
    },
    {
      "epoch": 0.6648,
      "grad_norm": 1.0936001539230347,
      "learning_rate": 7.785333333333332e-07,
      "logits/chosen": -3.0448431968688965,
      "logits/rejected": -2.747872829437256,
      "logps/chosen": -53.79473114013672,
      "logps/rejected": -66.93380737304688,
      "loss": 0.0168,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.147591233253479,
      "rewards/margins": 4.08036994934082,
      "rewards/rejected": -2.9327785968780518,
      "step": 1662
    },
    {
      "epoch": 0.6652,
      "grad_norm": 4.928318977355957,
      "learning_rate": 7.783999999999999e-07,
      "logits/chosen": -2.736781597137451,
      "logits/rejected": -2.6027541160583496,
      "logps/chosen": -96.70777893066406,
      "logps/rejected": -84.94783020019531,
      "loss": 0.0698,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.23002663254737854,
      "rewards/margins": 3.384707450866699,
      "rewards/rejected": -3.614733934402466,
      "step": 1663
    },
    {
      "epoch": 0.6656,
      "grad_norm": 4.306027889251709,
      "learning_rate": 7.782666666666666e-07,
      "logits/chosen": -2.7061548233032227,
      "logits/rejected": -2.189168930053711,
      "logps/chosen": -124.30569458007812,
      "logps/rejected": -98.13735961914062,
      "loss": 0.0601,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.28198930621147156,
      "rewards/margins": 3.933222532272339,
      "rewards/rejected": -3.651233196258545,
      "step": 1664
    },
    {
      "epoch": 0.666,
      "grad_norm": 0.8957919478416443,
      "learning_rate": 7.781333333333333e-07,
      "logits/chosen": -2.5235867500305176,
      "logits/rejected": -1.9042484760284424,
      "logps/chosen": -173.12734985351562,
      "logps/rejected": -133.7755584716797,
      "loss": 0.0077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4160873591899872,
      "rewards/margins": 5.58027458190918,
      "rewards/rejected": -5.99636173248291,
      "step": 1665
    },
    {
      "epoch": 0.6664,
      "grad_norm": 0.7764805555343628,
      "learning_rate": 7.78e-07,
      "logits/chosen": -2.85184383392334,
      "logits/rejected": -2.5010299682617188,
      "logps/chosen": -131.72122192382812,
      "logps/rejected": -136.65606689453125,
      "loss": 0.0083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.31686630845069885,
      "rewards/margins": 5.321292877197266,
      "rewards/rejected": -5.638158798217773,
      "step": 1666
    },
    {
      "epoch": 0.6668,
      "grad_norm": 0.18438994884490967,
      "learning_rate": 7.778666666666667e-07,
      "logits/chosen": -2.633469343185425,
      "logits/rejected": -2.121854782104492,
      "logps/chosen": -124.84886169433594,
      "logps/rejected": -135.4189910888672,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6635181903839111,
      "rewards/margins": 6.64542818069458,
      "rewards/rejected": -5.98190975189209,
      "step": 1667
    },
    {
      "epoch": 0.6672,
      "grad_norm": 1.7497446537017822,
      "learning_rate": 7.777333333333334e-07,
      "logits/chosen": -3.1309752464294434,
      "logits/rejected": -2.768460273742676,
      "logps/chosen": -41.903663635253906,
      "logps/rejected": -63.49711608886719,
      "loss": 0.0287,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9252067804336548,
      "rewards/margins": 3.847428321838379,
      "rewards/rejected": -2.9222214221954346,
      "step": 1668
    },
    {
      "epoch": 0.6676,
      "grad_norm": 1.3427104949951172,
      "learning_rate": 7.776e-07,
      "logits/chosen": -2.713657855987549,
      "logits/rejected": -2.143789529800415,
      "logps/chosen": -125.60679626464844,
      "logps/rejected": -119.65515899658203,
      "loss": 0.0121,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2322372198104858,
      "rewards/margins": 5.854929447174072,
      "rewards/rejected": -4.622692108154297,
      "step": 1669
    },
    {
      "epoch": 0.668,
      "grad_norm": 0.7135933637619019,
      "learning_rate": 7.774666666666666e-07,
      "logits/chosen": -2.5543839931488037,
      "logits/rejected": -2.137784481048584,
      "logps/chosen": -147.62939453125,
      "logps/rejected": -138.39830017089844,
      "loss": 0.0071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2823783755302429,
      "rewards/margins": 5.182999610900879,
      "rewards/rejected": -5.4653778076171875,
      "step": 1670
    },
    {
      "epoch": 0.6684,
      "grad_norm": 3.0428853034973145,
      "learning_rate": 7.773333333333333e-07,
      "logits/chosen": -2.293964385986328,
      "logits/rejected": -1.8618674278259277,
      "logps/chosen": -138.32391357421875,
      "logps/rejected": -112.6334228515625,
      "loss": 0.0248,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4742538630962372,
      "rewards/margins": 5.116159915924072,
      "rewards/rejected": -4.641905784606934,
      "step": 1671
    },
    {
      "epoch": 0.6688,
      "grad_norm": 1.954738736152649,
      "learning_rate": 7.771999999999999e-07,
      "logits/chosen": -2.9851739406585693,
      "logits/rejected": -2.790740489959717,
      "logps/chosen": -71.64549255371094,
      "logps/rejected": -77.84453582763672,
      "loss": 0.0343,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1815384030342102,
      "rewards/margins": 3.416224241256714,
      "rewards/rejected": -3.2346858978271484,
      "step": 1672
    },
    {
      "epoch": 0.6692,
      "grad_norm": 6.982907295227051,
      "learning_rate": 7.770666666666666e-07,
      "logits/chosen": -3.126246452331543,
      "logits/rejected": -2.8255503177642822,
      "logps/chosen": -54.31684875488281,
      "logps/rejected": -68.22957611083984,
      "loss": 0.1274,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.537824273109436,
      "rewards/margins": 2.772470474243164,
      "rewards/rejected": -3.3102946281433105,
      "step": 1673
    },
    {
      "epoch": 0.6696,
      "grad_norm": 0.0747503712773323,
      "learning_rate": 7.769333333333333e-07,
      "logits/chosen": -2.8354196548461914,
      "logits/rejected": -1.9161922931671143,
      "logps/chosen": -74.23492431640625,
      "logps/rejected": -151.2122802734375,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45310288667678833,
      "rewards/margins": 7.5045342445373535,
      "rewards/rejected": -7.051431655883789,
      "step": 1674
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.0578773021697998,
      "learning_rate": 7.768e-07,
      "logits/chosen": -2.9029147624969482,
      "logits/rejected": -2.065481424331665,
      "logps/chosen": -95.43241882324219,
      "logps/rejected": -108.87999725341797,
      "loss": 0.0105,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33568230271339417,
      "rewards/margins": 4.906644821166992,
      "rewards/rejected": -4.570962905883789,
      "step": 1675
    },
    {
      "epoch": 0.6704,
      "grad_norm": 0.6644914746284485,
      "learning_rate": 7.766666666666666e-07,
      "logits/chosen": -3.0368540287017822,
      "logits/rejected": -2.547393321990967,
      "logps/chosen": -72.92456817626953,
      "logps/rejected": -97.56190490722656,
      "loss": 0.0088,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1361820697784424,
      "rewards/margins": 4.961353302001953,
      "rewards/rejected": -3.82517147064209,
      "step": 1676
    },
    {
      "epoch": 0.6708,
      "grad_norm": 45.41827392578125,
      "learning_rate": 7.765333333333333e-07,
      "logits/chosen": -2.855982780456543,
      "logits/rejected": -2.696549654006958,
      "logps/chosen": -119.70468139648438,
      "logps/rejected": -68.65914916992188,
      "loss": 0.67,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -1.4953724145889282,
      "rewards/margins": 2.364708185195923,
      "rewards/rejected": -3.8600807189941406,
      "step": 1677
    },
    {
      "epoch": 0.6712,
      "grad_norm": 1.437076449394226,
      "learning_rate": 7.764e-07,
      "logits/chosen": -2.5228278636932373,
      "logits/rejected": -2.4333443641662598,
      "logps/chosen": -154.13491821289062,
      "logps/rejected": -109.67571258544922,
      "loss": 0.0154,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3494179248809814,
      "rewards/margins": 5.200026035308838,
      "rewards/rejected": -3.8506078720092773,
      "step": 1678
    },
    {
      "epoch": 0.6716,
      "grad_norm": 47.97740936279297,
      "learning_rate": 7.762666666666666e-07,
      "logits/chosen": -2.4969358444213867,
      "logits/rejected": -2.278325080871582,
      "logps/chosen": -200.14187622070312,
      "logps/rejected": -79.70767211914062,
      "loss": 0.4422,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -2.1219482421875,
      "rewards/margins": 1.6076951026916504,
      "rewards/rejected": -3.7296433448791504,
      "step": 1679
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.5146377682685852,
      "learning_rate": 7.761333333333333e-07,
      "logits/chosen": -2.7141318321228027,
      "logits/rejected": -1.8750944137573242,
      "logps/chosen": -103.23439025878906,
      "logps/rejected": -112.44967651367188,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.35527765750885,
      "rewards/margins": 5.377805233001709,
      "rewards/rejected": -4.022527694702148,
      "step": 1680
    },
    {
      "epoch": 0.6724,
      "grad_norm": 0.28460386395454407,
      "learning_rate": 7.76e-07,
      "logits/chosen": -2.8136281967163086,
      "logits/rejected": -2.096074104309082,
      "logps/chosen": -103.0038070678711,
      "logps/rejected": -127.75167846679688,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4357174038887024,
      "rewards/margins": 5.706252098083496,
      "rewards/rejected": -5.270534515380859,
      "step": 1681
    },
    {
      "epoch": 0.6728,
      "grad_norm": 1.7326390743255615,
      "learning_rate": 7.758666666666667e-07,
      "logits/chosen": -3.224614381790161,
      "logits/rejected": -2.82934832572937,
      "logps/chosen": -53.77549743652344,
      "logps/rejected": -86.47820281982422,
      "loss": 0.0232,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3986394703388214,
      "rewards/margins": 3.932969331741333,
      "rewards/rejected": -3.534329891204834,
      "step": 1682
    },
    {
      "epoch": 0.6732,
      "grad_norm": 6.323135852813721,
      "learning_rate": 7.757333333333333e-07,
      "logits/chosen": -2.4512782096862793,
      "logits/rejected": -2.0193934440612793,
      "logps/chosen": -196.06129455566406,
      "logps/rejected": -126.35303497314453,
      "loss": 0.0524,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.088518500328064,
      "rewards/margins": 4.384664535522461,
      "rewards/rejected": -5.4731831550598145,
      "step": 1683
    },
    {
      "epoch": 0.6736,
      "grad_norm": 3.2349469661712646,
      "learning_rate": 7.755999999999999e-07,
      "logits/chosen": -3.275315284729004,
      "logits/rejected": -2.9470348358154297,
      "logps/chosen": -60.40925598144531,
      "logps/rejected": -84.55836486816406,
      "loss": 0.055,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.21337205171585083,
      "rewards/margins": 3.935671806335449,
      "rewards/rejected": -4.149044036865234,
      "step": 1684
    },
    {
      "epoch": 0.674,
      "grad_norm": 0.21568483114242554,
      "learning_rate": 7.754666666666666e-07,
      "logits/chosen": -2.4784021377563477,
      "logits/rejected": -1.9384195804595947,
      "logps/chosen": -88.57903289794922,
      "logps/rejected": -143.99478149414062,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5791700482368469,
      "rewards/margins": 7.2399210929870605,
      "rewards/rejected": -6.660750865936279,
      "step": 1685
    },
    {
      "epoch": 0.6744,
      "grad_norm": 0.10175251960754395,
      "learning_rate": 7.753333333333333e-07,
      "logits/chosen": -2.5387587547302246,
      "logits/rejected": -1.7504093647003174,
      "logps/chosen": -88.05604553222656,
      "logps/rejected": -141.85137939453125,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3032307624816895,
      "rewards/margins": 7.294623374938965,
      "rewards/rejected": -5.991393089294434,
      "step": 1686
    },
    {
      "epoch": 0.6748,
      "grad_norm": 3.790327548980713,
      "learning_rate": 7.752e-07,
      "logits/chosen": -2.793856620788574,
      "logits/rejected": -2.4680821895599365,
      "logps/chosen": -107.03034973144531,
      "logps/rejected": -173.37310791015625,
      "loss": 0.0435,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5428131222724915,
      "rewards/margins": 4.404000282287598,
      "rewards/rejected": -3.86118745803833,
      "step": 1687
    },
    {
      "epoch": 0.6752,
      "grad_norm": 1.721964955329895,
      "learning_rate": 7.750666666666667e-07,
      "logits/chosen": -2.5187182426452637,
      "logits/rejected": -2.136584758758545,
      "logps/chosen": -193.64404296875,
      "logps/rejected": -93.23849487304688,
      "loss": 0.0183,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.12070691585540771,
      "rewards/margins": 4.012843132019043,
      "rewards/rejected": -4.133549690246582,
      "step": 1688
    },
    {
      "epoch": 0.6756,
      "grad_norm": 4.95621919631958,
      "learning_rate": 7.749333333333333e-07,
      "logits/chosen": -3.2007856369018555,
      "logits/rejected": -2.7877180576324463,
      "logps/chosen": -71.92513275146484,
      "logps/rejected": -63.13334655761719,
      "loss": 0.0822,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5027259588241577,
      "rewards/margins": 2.4940011501312256,
      "rewards/rejected": -2.996727228164673,
      "step": 1689
    },
    {
      "epoch": 0.676,
      "grad_norm": 0.6397088170051575,
      "learning_rate": 7.748e-07,
      "logits/chosen": -2.9418678283691406,
      "logits/rejected": -2.420125961303711,
      "logps/chosen": -88.97941589355469,
      "logps/rejected": -123.4618148803711,
      "loss": 0.0072,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4833106994628906,
      "rewards/margins": 6.429617404937744,
      "rewards/rejected": -5.9463067054748535,
      "step": 1690
    },
    {
      "epoch": 0.6764,
      "grad_norm": 0.8631293773651123,
      "learning_rate": 7.746666666666666e-07,
      "logits/chosen": -2.7732925415039062,
      "logits/rejected": -2.2768468856811523,
      "logps/chosen": -68.96643829345703,
      "logps/rejected": -124.31831359863281,
      "loss": 0.011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9474319219589233,
      "rewards/margins": 5.456439971923828,
      "rewards/rejected": -4.509007453918457,
      "step": 1691
    },
    {
      "epoch": 0.6768,
      "grad_norm": 0.4606117010116577,
      "learning_rate": 7.745333333333333e-07,
      "logits/chosen": -3.204890727996826,
      "logits/rejected": -2.587584972381592,
      "logps/chosen": -50.7889518737793,
      "logps/rejected": -107.62757110595703,
      "loss": 0.0048,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27751654386520386,
      "rewards/margins": 5.815616130828857,
      "rewards/rejected": -5.53809928894043,
      "step": 1692
    },
    {
      "epoch": 0.6772,
      "grad_norm": 0.6204129457473755,
      "learning_rate": 7.743999999999999e-07,
      "logits/chosen": -2.513211488723755,
      "logits/rejected": -1.9094278812408447,
      "logps/chosen": -155.4268798828125,
      "logps/rejected": -100.75141143798828,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0495003461837769,
      "rewards/margins": 5.751637935638428,
      "rewards/rejected": -4.702137470245361,
      "step": 1693
    },
    {
      "epoch": 0.6776,
      "grad_norm": 0.15918892621994019,
      "learning_rate": 7.742666666666666e-07,
      "logits/chosen": -2.9983768463134766,
      "logits/rejected": -2.2973852157592773,
      "logps/chosen": -72.52337646484375,
      "logps/rejected": -120.11314392089844,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7915359735488892,
      "rewards/margins": 6.844015121459961,
      "rewards/rejected": -6.052479267120361,
      "step": 1694
    },
    {
      "epoch": 0.678,
      "grad_norm": 0.44748231768608093,
      "learning_rate": 7.741333333333333e-07,
      "logits/chosen": -2.728076934814453,
      "logits/rejected": -2.357109785079956,
      "logps/chosen": -74.1905288696289,
      "logps/rejected": -94.30695343017578,
      "loss": 0.006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9718742370605469,
      "rewards/margins": 5.659792423248291,
      "rewards/rejected": -4.687918186187744,
      "step": 1695
    },
    {
      "epoch": 0.6784,
      "grad_norm": 0.10488945990800858,
      "learning_rate": 7.74e-07,
      "logits/chosen": -2.9386215209960938,
      "logits/rejected": -1.9865062236785889,
      "logps/chosen": -86.25946044921875,
      "logps/rejected": -112.52286529541016,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6654858589172363,
      "rewards/margins": 7.115208148956299,
      "rewards/rejected": -5.4497222900390625,
      "step": 1696
    },
    {
      "epoch": 0.6788,
      "grad_norm": 0.9290452599525452,
      "learning_rate": 7.738666666666667e-07,
      "logits/chosen": -2.7853922843933105,
      "logits/rejected": -1.700854778289795,
      "logps/chosen": -106.20691680908203,
      "logps/rejected": -90.3818359375,
      "loss": 0.0101,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0733261108398438,
      "rewards/margins": 5.436525344848633,
      "rewards/rejected": -4.363199234008789,
      "step": 1697
    },
    {
      "epoch": 0.6792,
      "grad_norm": 0.6799826622009277,
      "learning_rate": 7.737333333333333e-07,
      "logits/chosen": -2.7234623432159424,
      "logits/rejected": -2.191347122192383,
      "logps/chosen": -118.32372283935547,
      "logps/rejected": -117.80589294433594,
      "loss": 0.0096,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9199764728546143,
      "rewards/margins": 5.034526824951172,
      "rewards/rejected": -4.114550590515137,
      "step": 1698
    },
    {
      "epoch": 0.6796,
      "grad_norm": 31.949188232421875,
      "learning_rate": 7.735999999999999e-07,
      "logits/chosen": -2.6946053504943848,
      "logits/rejected": -2.1745071411132812,
      "logps/chosen": -129.05242919921875,
      "logps/rejected": -127.39521789550781,
      "loss": 0.4145,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -2.0738048553466797,
      "rewards/margins": 4.200708866119385,
      "rewards/rejected": -6.274514198303223,
      "step": 1699
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.18668213486671448,
      "learning_rate": 7.734666666666666e-07,
      "logits/chosen": -2.6884348392486572,
      "logits/rejected": -1.8662388324737549,
      "logps/chosen": -115.13874053955078,
      "logps/rejected": -160.28912353515625,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2183380126953125,
      "rewards/margins": 6.9460344314575195,
      "rewards/rejected": -5.727696418762207,
      "step": 1700
    },
    {
      "epoch": 0.6804,
      "grad_norm": 5.553641319274902,
      "learning_rate": 7.733333333333333e-07,
      "logits/chosen": -3.065311908721924,
      "logits/rejected": -2.783919334411621,
      "logps/chosen": -59.26036834716797,
      "logps/rejected": -98.21549987792969,
      "loss": 0.073,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.757150411605835,
      "rewards/margins": 5.154722690582275,
      "rewards/rejected": -4.3975725173950195,
      "step": 1701
    },
    {
      "epoch": 0.6808,
      "grad_norm": 2.419247627258301,
      "learning_rate": 7.732e-07,
      "logits/chosen": -2.92763352394104,
      "logits/rejected": -2.2544052600860596,
      "logps/chosen": -92.78318786621094,
      "logps/rejected": -85.03878784179688,
      "loss": 0.0317,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3568679988384247,
      "rewards/margins": 4.2143025398254395,
      "rewards/rejected": -3.8574342727661133,
      "step": 1702
    },
    {
      "epoch": 0.6812,
      "grad_norm": 0.3195573389530182,
      "learning_rate": 7.730666666666667e-07,
      "logits/chosen": -2.6118335723876953,
      "logits/rejected": -2.079618453979492,
      "logps/chosen": -83.05204772949219,
      "logps/rejected": -147.03375244140625,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.941372275352478,
      "rewards/margins": 7.894464492797852,
      "rewards/rejected": -5.953092098236084,
      "step": 1703
    },
    {
      "epoch": 0.6816,
      "grad_norm": 0.48690325021743774,
      "learning_rate": 7.729333333333333e-07,
      "logits/chosen": -2.6962714195251465,
      "logits/rejected": -2.3608760833740234,
      "logps/chosen": -150.5263671875,
      "logps/rejected": -92.94561767578125,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4589812755584717,
      "rewards/margins": 5.803363800048828,
      "rewards/rejected": -4.344382286071777,
      "step": 1704
    },
    {
      "epoch": 0.682,
      "grad_norm": 3.4197487831115723,
      "learning_rate": 7.728e-07,
      "logits/chosen": -2.6680660247802734,
      "logits/rejected": -2.2361536026000977,
      "logps/chosen": -133.661865234375,
      "logps/rejected": -103.86248779296875,
      "loss": 0.0415,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5428638458251953,
      "rewards/margins": 3.75046968460083,
      "rewards/rejected": -4.293333530426025,
      "step": 1705
    },
    {
      "epoch": 0.6824,
      "grad_norm": 0.5725760459899902,
      "learning_rate": 7.726666666666666e-07,
      "logits/chosen": -2.5707015991210938,
      "logits/rejected": -1.9604716300964355,
      "logps/chosen": -123.90768432617188,
      "logps/rejected": -106.97369384765625,
      "loss": 0.0079,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8737773895263672,
      "rewards/margins": 5.812834739685059,
      "rewards/rejected": -4.939057350158691,
      "step": 1706
    },
    {
      "epoch": 0.6828,
      "grad_norm": 0.6128212213516235,
      "learning_rate": 7.725333333333332e-07,
      "logits/chosen": -2.534660816192627,
      "logits/rejected": -1.9847893714904785,
      "logps/chosen": -130.89576721191406,
      "logps/rejected": -152.83990478515625,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2815173864364624,
      "rewards/margins": 5.09553337097168,
      "rewards/rejected": -4.814016342163086,
      "step": 1707
    },
    {
      "epoch": 0.6832,
      "grad_norm": 13.277605056762695,
      "learning_rate": 7.723999999999999e-07,
      "logits/chosen": -3.1854615211486816,
      "logits/rejected": -2.984217882156372,
      "logps/chosen": -91.00537872314453,
      "logps/rejected": -61.202537536621094,
      "loss": 0.1797,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.43998491764068604,
      "rewards/margins": 2.1704280376434326,
      "rewards/rejected": -2.610413074493408,
      "step": 1708
    },
    {
      "epoch": 0.6836,
      "grad_norm": 2.669362783432007,
      "learning_rate": 7.722666666666666e-07,
      "logits/chosen": -2.797764778137207,
      "logits/rejected": -2.1530160903930664,
      "logps/chosen": -70.4323959350586,
      "logps/rejected": -135.6609344482422,
      "loss": 0.0347,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.426896333694458,
      "rewards/margins": 5.593998908996582,
      "rewards/rejected": -4.167102336883545,
      "step": 1709
    },
    {
      "epoch": 0.684,
      "grad_norm": 2.45108699798584,
      "learning_rate": 7.721333333333333e-07,
      "logits/chosen": -2.72343111038208,
      "logits/rejected": -2.3685073852539062,
      "logps/chosen": -53.25188446044922,
      "logps/rejected": -70.68498992919922,
      "loss": 0.0354,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.633653461933136,
      "rewards/margins": 4.005249500274658,
      "rewards/rejected": -3.371596336364746,
      "step": 1710
    },
    {
      "epoch": 0.6844,
      "grad_norm": 4.292700290679932,
      "learning_rate": 7.72e-07,
      "logits/chosen": -2.807769298553467,
      "logits/rejected": -2.5463461875915527,
      "logps/chosen": -105.52294921875,
      "logps/rejected": -83.40715026855469,
      "loss": 0.0777,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5474255084991455,
      "rewards/margins": 3.466310501098633,
      "rewards/rejected": -2.9188849925994873,
      "step": 1711
    },
    {
      "epoch": 0.6848,
      "grad_norm": 0.42561623454093933,
      "learning_rate": 7.718666666666667e-07,
      "logits/chosen": -2.4467005729675293,
      "logits/rejected": -2.2566657066345215,
      "logps/chosen": -124.19486999511719,
      "logps/rejected": -113.4658203125,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9071261882781982,
      "rewards/margins": 5.422939300537109,
      "rewards/rejected": -3.515813112258911,
      "step": 1712
    },
    {
      "epoch": 0.6852,
      "grad_norm": 0.757865846157074,
      "learning_rate": 7.717333333333334e-07,
      "logits/chosen": -2.8812179565429688,
      "logits/rejected": -2.1982381343841553,
      "logps/chosen": -90.00741577148438,
      "logps/rejected": -92.95191955566406,
      "loss": 0.0095,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2241203486919403,
      "rewards/margins": 4.652122497558594,
      "rewards/rejected": -4.876242637634277,
      "step": 1713
    },
    {
      "epoch": 0.6856,
      "grad_norm": 0.26125288009643555,
      "learning_rate": 7.716e-07,
      "logits/chosen": -2.965756416320801,
      "logits/rejected": -2.4327259063720703,
      "logps/chosen": -81.32312774658203,
      "logps/rejected": -111.95716857910156,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.635206401348114,
      "rewards/margins": 6.610641956329346,
      "rewards/rejected": -5.975435256958008,
      "step": 1714
    },
    {
      "epoch": 0.686,
      "grad_norm": 8.099614143371582,
      "learning_rate": 7.714666666666666e-07,
      "logits/chosen": -2.8218319416046143,
      "logits/rejected": -2.2289538383483887,
      "logps/chosen": -88.72574615478516,
      "logps/rejected": -76.326171875,
      "loss": 0.163,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08190956711769104,
      "rewards/margins": 3.2329940795898438,
      "rewards/rejected": -3.314903736114502,
      "step": 1715
    },
    {
      "epoch": 0.6864,
      "grad_norm": 7.337899684906006,
      "learning_rate": 7.713333333333333e-07,
      "logits/chosen": -2.5480194091796875,
      "logits/rejected": -2.3460299968719482,
      "logps/chosen": -191.80064392089844,
      "logps/rejected": -73.54887390136719,
      "loss": 0.1227,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7150543332099915,
      "rewards/margins": 2.11224365234375,
      "rewards/rejected": -2.8272979259490967,
      "step": 1716
    },
    {
      "epoch": 0.6868,
      "grad_norm": 3.8732240200042725,
      "learning_rate": 7.711999999999999e-07,
      "logits/chosen": -3.0904698371887207,
      "logits/rejected": -2.746716022491455,
      "logps/chosen": -54.967952728271484,
      "logps/rejected": -65.76296997070312,
      "loss": 0.0605,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9768840670585632,
      "rewards/margins": 3.8754820823669434,
      "rewards/rejected": -2.8985979557037354,
      "step": 1717
    },
    {
      "epoch": 0.6872,
      "grad_norm": 1.494871735572815,
      "learning_rate": 7.710666666666666e-07,
      "logits/chosen": -2.8069252967834473,
      "logits/rejected": -2.2259087562561035,
      "logps/chosen": -85.94650268554688,
      "logps/rejected": -110.31979370117188,
      "loss": 0.0174,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3308708071708679,
      "rewards/margins": 5.642621040344238,
      "rewards/rejected": -5.973491668701172,
      "step": 1718
    },
    {
      "epoch": 0.6876,
      "grad_norm": 0.4646351933479309,
      "learning_rate": 7.709333333333333e-07,
      "logits/chosen": -3.079965353012085,
      "logits/rejected": -2.804300308227539,
      "logps/chosen": -95.03585815429688,
      "logps/rejected": -189.635986328125,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8076137900352478,
      "rewards/margins": 5.430328369140625,
      "rewards/rejected": -4.622714042663574,
      "step": 1719
    },
    {
      "epoch": 0.688,
      "grad_norm": 29.065841674804688,
      "learning_rate": 7.708e-07,
      "logits/chosen": -2.6989450454711914,
      "logits/rejected": -2.2081379890441895,
      "logps/chosen": -147.1270294189453,
      "logps/rejected": -88.72229766845703,
      "loss": 0.3558,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.412774085998535,
      "rewards/margins": 1.478129506111145,
      "rewards/rejected": -3.8909034729003906,
      "step": 1720
    },
    {
      "epoch": 0.6884,
      "grad_norm": 1.1028786897659302,
      "learning_rate": 7.706666666666667e-07,
      "logits/chosen": -2.8940367698669434,
      "logits/rejected": -2.657864570617676,
      "logps/chosen": -109.54177856445312,
      "logps/rejected": -109.45524597167969,
      "loss": 0.0118,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5591962933540344,
      "rewards/margins": 5.005100727081299,
      "rewards/rejected": -4.445904731750488,
      "step": 1721
    },
    {
      "epoch": 0.6888,
      "grad_norm": 17.880970001220703,
      "learning_rate": 7.705333333333333e-07,
      "logits/chosen": -2.551086902618408,
      "logits/rejected": -1.9149706363677979,
      "logps/chosen": -213.01553344726562,
      "logps/rejected": -136.0430450439453,
      "loss": 0.1653,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8549392223358154,
      "rewards/margins": 4.4710283279418945,
      "rewards/rejected": -6.325967788696289,
      "step": 1722
    },
    {
      "epoch": 0.6892,
      "grad_norm": 0.08983920514583588,
      "learning_rate": 7.704e-07,
      "logits/chosen": -3.0073838233947754,
      "logits/rejected": -2.341334581375122,
      "logps/chosen": -73.76519012451172,
      "logps/rejected": -109.77729797363281,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9264965057373047,
      "rewards/margins": 7.1402788162231445,
      "rewards/rejected": -6.21378231048584,
      "step": 1723
    },
    {
      "epoch": 0.6896,
      "grad_norm": 0.05828556418418884,
      "learning_rate": 7.702666666666667e-07,
      "logits/chosen": -2.452836036682129,
      "logits/rejected": -1.6334586143493652,
      "logps/chosen": -124.97736358642578,
      "logps/rejected": -131.34991455078125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2010681629180908,
      "rewards/margins": 7.840939521789551,
      "rewards/rejected": -6.639871120452881,
      "step": 1724
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.4584277272224426,
      "learning_rate": 7.701333333333333e-07,
      "logits/chosen": -2.6539695262908936,
      "logits/rejected": -2.444269895553589,
      "logps/chosen": -131.1642608642578,
      "logps/rejected": -137.6075439453125,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.865678071975708,
      "rewards/margins": 5.9937567710876465,
      "rewards/rejected": -5.128078460693359,
      "step": 1725
    },
    {
      "epoch": 0.6904,
      "grad_norm": 0.42901375889778137,
      "learning_rate": 7.699999999999999e-07,
      "logits/chosen": -2.58770751953125,
      "logits/rejected": -1.8007230758666992,
      "logps/chosen": -128.7963409423828,
      "logps/rejected": -109.00949096679688,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9205510020256042,
      "rewards/margins": 5.529503345489502,
      "rewards/rejected": -4.608952522277832,
      "step": 1726
    },
    {
      "epoch": 0.6908,
      "grad_norm": 16.689329147338867,
      "learning_rate": 7.698666666666666e-07,
      "logits/chosen": -2.8166446685791016,
      "logits/rejected": -2.630721092224121,
      "logps/chosen": -105.98871612548828,
      "logps/rejected": -94.12692260742188,
      "loss": 0.2997,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1295766830444336,
      "rewards/margins": 3.7135026454925537,
      "rewards/rejected": -4.843079566955566,
      "step": 1727
    },
    {
      "epoch": 0.6912,
      "grad_norm": 2.421361207962036,
      "learning_rate": 7.697333333333333e-07,
      "logits/chosen": -2.7116990089416504,
      "logits/rejected": -2.3783977031707764,
      "logps/chosen": -88.32210540771484,
      "logps/rejected": -73.08651733398438,
      "loss": 0.0328,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14369849860668182,
      "rewards/margins": 3.6816153526306152,
      "rewards/rejected": -3.537916898727417,
      "step": 1728
    },
    {
      "epoch": 0.6916,
      "grad_norm": 0.16103775799274445,
      "learning_rate": 7.695999999999999e-07,
      "logits/chosen": -2.8690781593322754,
      "logits/rejected": -2.4660425186157227,
      "logps/chosen": -124.43515014648438,
      "logps/rejected": -133.32949829101562,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.349822998046875,
      "rewards/margins": 6.6342267990112305,
      "rewards/rejected": -6.9840497970581055,
      "step": 1729
    },
    {
      "epoch": 0.692,
      "grad_norm": 0.11424374580383301,
      "learning_rate": 7.694666666666666e-07,
      "logits/chosen": -3.1199398040771484,
      "logits/rejected": -2.599073886871338,
      "logps/chosen": -90.98490905761719,
      "logps/rejected": -144.6468505859375,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1889774352312088,
      "rewards/margins": 7.135479927062988,
      "rewards/rejected": -6.946502208709717,
      "step": 1730
    },
    {
      "epoch": 0.6924,
      "grad_norm": 4.295002460479736,
      "learning_rate": 7.693333333333333e-07,
      "logits/chosen": -2.922086238861084,
      "logits/rejected": -2.689676284790039,
      "logps/chosen": -56.38691711425781,
      "logps/rejected": -64.01861572265625,
      "loss": 0.0906,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3407604694366455,
      "rewards/margins": 3.1131319999694824,
      "rewards/rejected": -2.772371530532837,
      "step": 1731
    },
    {
      "epoch": 0.6928,
      "grad_norm": 0.1262548714876175,
      "learning_rate": 7.692e-07,
      "logits/chosen": -3.01399827003479,
      "logits/rejected": -2.198662519454956,
      "logps/chosen": -77.52249145507812,
      "logps/rejected": -181.35379028320312,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8606048822402954,
      "rewards/margins": 7.140654563903809,
      "rewards/rejected": -6.2800493240356445,
      "step": 1732
    },
    {
      "epoch": 0.6932,
      "grad_norm": 0.560990035533905,
      "learning_rate": 7.690666666666667e-07,
      "logits/chosen": -3.4301657676696777,
      "logits/rejected": -2.949763298034668,
      "logps/chosen": -56.70262145996094,
      "logps/rejected": -89.04853820800781,
      "loss": 0.0067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.02364981174469,
      "rewards/margins": 5.099560737609863,
      "rewards/rejected": -4.075910568237305,
      "step": 1733
    },
    {
      "epoch": 0.6936,
      "grad_norm": 1.4382025003433228,
      "learning_rate": 7.689333333333334e-07,
      "logits/chosen": -2.5497140884399414,
      "logits/rejected": -1.924851655960083,
      "logps/chosen": -63.67066192626953,
      "logps/rejected": -127.14278411865234,
      "loss": 0.0134,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.17755280435085297,
      "rewards/margins": 4.882861137390137,
      "rewards/rejected": -5.060413837432861,
      "step": 1734
    },
    {
      "epoch": 0.694,
      "grad_norm": 0.9644919633865356,
      "learning_rate": 7.688000000000001e-07,
      "logits/chosen": -2.8190526962280273,
      "logits/rejected": -2.4545392990112305,
      "logps/chosen": -136.57032775878906,
      "logps/rejected": -90.63101196289062,
      "loss": 0.0133,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7846611142158508,
      "rewards/margins": 4.822105884552002,
      "rewards/rejected": -4.037444591522217,
      "step": 1735
    },
    {
      "epoch": 0.6944,
      "grad_norm": 1.7341651916503906,
      "learning_rate": 7.686666666666666e-07,
      "logits/chosen": -3.00575590133667,
      "logits/rejected": -2.250046730041504,
      "logps/chosen": -101.13923645019531,
      "logps/rejected": -126.84017944335938,
      "loss": 0.0155,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9321754574775696,
      "rewards/margins": 6.235264778137207,
      "rewards/rejected": -5.303089141845703,
      "step": 1736
    },
    {
      "epoch": 0.6948,
      "grad_norm": 1.5350791215896606,
      "learning_rate": 7.685333333333332e-07,
      "logits/chosen": -2.991187572479248,
      "logits/rejected": -2.6087019443511963,
      "logps/chosen": -105.89273834228516,
      "logps/rejected": -107.32977294921875,
      "loss": 0.015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2902374267578125,
      "rewards/margins": 5.049612045288086,
      "rewards/rejected": -4.759374618530273,
      "step": 1737
    },
    {
      "epoch": 0.6952,
      "grad_norm": 1.102891445159912,
      "learning_rate": 7.683999999999999e-07,
      "logits/chosen": -3.058396339416504,
      "logits/rejected": -2.507777214050293,
      "logps/chosen": -62.1312370300293,
      "logps/rejected": -71.61952209472656,
      "loss": 0.0167,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.756727397441864,
      "rewards/margins": 4.206620693206787,
      "rewards/rejected": -3.4498934745788574,
      "step": 1738
    },
    {
      "epoch": 0.6956,
      "grad_norm": 0.9426502585411072,
      "learning_rate": 7.682666666666666e-07,
      "logits/chosen": -2.9779059886932373,
      "logits/rejected": -2.485600709915161,
      "logps/chosen": -74.92672729492188,
      "logps/rejected": -93.14649963378906,
      "loss": 0.0094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.570387065410614,
      "rewards/margins": 5.2796220779418945,
      "rewards/rejected": -4.709235191345215,
      "step": 1739
    },
    {
      "epoch": 0.696,
      "grad_norm": 2.4507176876068115,
      "learning_rate": 7.681333333333333e-07,
      "logits/chosen": -2.9927875995635986,
      "logits/rejected": -2.7500534057617188,
      "logps/chosen": -61.79399490356445,
      "logps/rejected": -66.53229522705078,
      "loss": 0.0441,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6432029604911804,
      "rewards/margins": 3.334587812423706,
      "rewards/rejected": -2.691384792327881,
      "step": 1740
    },
    {
      "epoch": 0.6964,
      "grad_norm": 1.4409617185592651,
      "learning_rate": 7.68e-07,
      "logits/chosen": -2.9430971145629883,
      "logits/rejected": -2.45009183883667,
      "logps/chosen": -69.15967559814453,
      "logps/rejected": -113.10543823242188,
      "loss": 0.0187,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6374412775039673,
      "rewards/margins": 5.024137020111084,
      "rewards/rejected": -4.386695861816406,
      "step": 1741
    },
    {
      "epoch": 0.6968,
      "grad_norm": 1.826829195022583,
      "learning_rate": 7.678666666666667e-07,
      "logits/chosen": -2.643559694290161,
      "logits/rejected": -2.0551700592041016,
      "logps/chosen": -172.871826171875,
      "logps/rejected": -98.25817108154297,
      "loss": 0.0235,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10416831076145172,
      "rewards/margins": 3.7678956985473633,
      "rewards/rejected": -3.6637277603149414,
      "step": 1742
    },
    {
      "epoch": 0.6972,
      "grad_norm": 0.8996192216873169,
      "learning_rate": 7.677333333333334e-07,
      "logits/chosen": -3.27657413482666,
      "logits/rejected": -2.8534345626831055,
      "logps/chosen": -52.387210845947266,
      "logps/rejected": -70.43838500976562,
      "loss": 0.0134,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2862058877944946,
      "rewards/margins": 4.377625465393066,
      "rewards/rejected": -3.0914196968078613,
      "step": 1743
    },
    {
      "epoch": 0.6976,
      "grad_norm": 1.0457123517990112,
      "learning_rate": 7.676e-07,
      "logits/chosen": -2.872962713241577,
      "logits/rejected": -1.985827088356018,
      "logps/chosen": -128.94491577148438,
      "logps/rejected": -132.44544982910156,
      "loss": 0.0104,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3305648863315582,
      "rewards/margins": 6.5797271728515625,
      "rewards/rejected": -6.249161720275879,
      "step": 1744
    },
    {
      "epoch": 0.698,
      "grad_norm": 1.553432822227478,
      "learning_rate": 7.674666666666666e-07,
      "logits/chosen": -3.0967345237731934,
      "logits/rejected": -2.719780921936035,
      "logps/chosen": -66.00315856933594,
      "logps/rejected": -107.53355407714844,
      "loss": 0.0198,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7232391834259033,
      "rewards/margins": 4.563667297363281,
      "rewards/rejected": -3.840427875518799,
      "step": 1745
    },
    {
      "epoch": 0.6984,
      "grad_norm": 4.553788661956787,
      "learning_rate": 7.673333333333332e-07,
      "logits/chosen": -3.08059024810791,
      "logits/rejected": -2.552687168121338,
      "logps/chosen": -53.525390625,
      "logps/rejected": -82.1463394165039,
      "loss": 0.0781,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10675258934497833,
      "rewards/margins": 4.244627952575684,
      "rewards/rejected": -4.351380348205566,
      "step": 1746
    },
    {
      "epoch": 0.6988,
      "grad_norm": 1.4604688882827759,
      "learning_rate": 7.671999999999999e-07,
      "logits/chosen": -2.994676113128662,
      "logits/rejected": -2.6705543994903564,
      "logps/chosen": -153.08718872070312,
      "logps/rejected": -104.20249938964844,
      "loss": 0.0171,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.292327880859375,
      "rewards/margins": 4.159336090087891,
      "rewards/rejected": -4.451663970947266,
      "step": 1747
    },
    {
      "epoch": 0.6992,
      "grad_norm": 6.400981903076172,
      "learning_rate": 7.670666666666666e-07,
      "logits/chosen": -2.6194989681243896,
      "logits/rejected": -2.0383923053741455,
      "logps/chosen": -130.97047424316406,
      "logps/rejected": -134.33885192871094,
      "loss": 0.0667,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.09828221797943115,
      "rewards/margins": 4.45557165145874,
      "rewards/rejected": -4.553853988647461,
      "step": 1748
    },
    {
      "epoch": 0.6996,
      "grad_norm": 3.230177402496338,
      "learning_rate": 7.669333333333333e-07,
      "logits/chosen": -3.097884178161621,
      "logits/rejected": -2.894080638885498,
      "logps/chosen": -80.91673278808594,
      "logps/rejected": -100.15150451660156,
      "loss": 0.0404,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7455555200576782,
      "rewards/margins": 3.833958148956299,
      "rewards/rejected": -3.08840274810791,
      "step": 1749
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.6163508892059326,
      "learning_rate": 7.668e-07,
      "logits/chosen": -2.4631781578063965,
      "logits/rejected": -1.8016717433929443,
      "logps/chosen": -206.94931030273438,
      "logps/rejected": -112.95133209228516,
      "loss": 0.0235,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4384910762310028,
      "rewards/margins": 4.422286510467529,
      "rewards/rejected": -4.860777378082275,
      "step": 1750
    },
    {
      "epoch": 0.7004,
      "grad_norm": 1.2072874307632446,
      "learning_rate": 7.666666666666667e-07,
      "logits/chosen": -2.925466537475586,
      "logits/rejected": -2.5796637535095215,
      "logps/chosen": -49.50342559814453,
      "logps/rejected": -111.73571014404297,
      "loss": 0.0119,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5800164937973022,
      "rewards/margins": 5.544832229614258,
      "rewards/rejected": -4.964815616607666,
      "step": 1751
    },
    {
      "epoch": 0.7008,
      "grad_norm": 0.48711657524108887,
      "learning_rate": 7.665333333333333e-07,
      "logits/chosen": -3.000826358795166,
      "logits/rejected": -2.548412799835205,
      "logps/chosen": -96.29258728027344,
      "logps/rejected": -123.505615234375,
      "loss": 0.005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3822933435440063,
      "rewards/margins": 5.353232383728027,
      "rewards/rejected": -3.9709386825561523,
      "step": 1752
    },
    {
      "epoch": 0.7012,
      "grad_norm": 0.04188069701194763,
      "learning_rate": 7.664e-07,
      "logits/chosen": -2.8108372688293457,
      "logits/rejected": -2.06630539894104,
      "logps/chosen": -62.55927658081055,
      "logps/rejected": -161.81689453125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3959048986434937,
      "rewards/margins": 8.387624740600586,
      "rewards/rejected": -6.9917192459106445,
      "step": 1753
    },
    {
      "epoch": 0.7016,
      "grad_norm": 2.2110061645507812,
      "learning_rate": 7.662666666666666e-07,
      "logits/chosen": -3.141611099243164,
      "logits/rejected": -2.712553024291992,
      "logps/chosen": -43.38334655761719,
      "logps/rejected": -107.6863021850586,
      "loss": 0.0232,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.28044795989990234,
      "rewards/margins": 3.757689952850342,
      "rewards/rejected": -4.038137912750244,
      "step": 1754
    },
    {
      "epoch": 0.702,
      "grad_norm": 5.359715938568115,
      "learning_rate": 7.661333333333333e-07,
      "logits/chosen": -2.7083818912506104,
      "logits/rejected": -2.407223701477051,
      "logps/chosen": -75.09276580810547,
      "logps/rejected": -96.83638000488281,
      "loss": 0.098,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19881859421730042,
      "rewards/margins": 4.926482677459717,
      "rewards/rejected": -4.727663993835449,
      "step": 1755
    },
    {
      "epoch": 0.7024,
      "grad_norm": 1.249752402305603,
      "learning_rate": 7.66e-07,
      "logits/chosen": -2.5581018924713135,
      "logits/rejected": -2.017970561981201,
      "logps/chosen": -106.90571594238281,
      "logps/rejected": -114.13422393798828,
      "loss": 0.0111,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1723661571741104,
      "rewards/margins": 4.9141058921813965,
      "rewards/rejected": -4.741739749908447,
      "step": 1756
    },
    {
      "epoch": 0.7028,
      "grad_norm": 1.3757816553115845,
      "learning_rate": 7.658666666666666e-07,
      "logits/chosen": -3.2495245933532715,
      "logits/rejected": -2.3267884254455566,
      "logps/chosen": -56.80465316772461,
      "logps/rejected": -98.34046173095703,
      "loss": 0.0195,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08705797046422958,
      "rewards/margins": 4.811556816101074,
      "rewards/rejected": -4.724498748779297,
      "step": 1757
    },
    {
      "epoch": 0.7032,
      "grad_norm": 0.8928340673446655,
      "learning_rate": 7.657333333333333e-07,
      "logits/chosen": -2.4729654788970947,
      "logits/rejected": -1.6345393657684326,
      "logps/chosen": -105.45718383789062,
      "logps/rejected": -135.38552856445312,
      "loss": 0.006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0080982446670532,
      "rewards/margins": 5.605533599853516,
      "rewards/rejected": -4.597434997558594,
      "step": 1758
    },
    {
      "epoch": 0.7036,
      "grad_norm": 3.420703172683716,
      "learning_rate": 7.655999999999999e-07,
      "logits/chosen": -3.1285176277160645,
      "logits/rejected": -2.610548973083496,
      "logps/chosen": -43.85287094116211,
      "logps/rejected": -81.75137329101562,
      "loss": 0.0482,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.40842723846435547,
      "rewards/margins": 3.5569875240325928,
      "rewards/rejected": -3.965414524078369,
      "step": 1759
    },
    {
      "epoch": 0.704,
      "grad_norm": 21.502649307250977,
      "learning_rate": 7.654666666666666e-07,
      "logits/chosen": -3.1732709407806396,
      "logits/rejected": -2.716897964477539,
      "logps/chosen": -65.69309997558594,
      "logps/rejected": -67.94033813476562,
      "loss": 0.2696,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10629534721374512,
      "rewards/margins": 2.9807045459747314,
      "rewards/rejected": -2.8744091987609863,
      "step": 1760
    },
    {
      "epoch": 0.7044,
      "grad_norm": 0.30929988622665405,
      "learning_rate": 7.653333333333333e-07,
      "logits/chosen": -2.6530404090881348,
      "logits/rejected": -1.8977596759796143,
      "logps/chosen": -99.67189025878906,
      "logps/rejected": -131.03024291992188,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7384323477745056,
      "rewards/margins": 6.014188766479492,
      "rewards/rejected": -5.275756359100342,
      "step": 1761
    },
    {
      "epoch": 0.7048,
      "grad_norm": 1.6527764797210693,
      "learning_rate": 7.652e-07,
      "logits/chosen": -3.080272674560547,
      "logits/rejected": -2.67490816116333,
      "logps/chosen": -74.30980682373047,
      "logps/rejected": -89.34162902832031,
      "loss": 0.0203,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21502643823623657,
      "rewards/margins": 4.731741428375244,
      "rewards/rejected": -4.516715049743652,
      "step": 1762
    },
    {
      "epoch": 0.7052,
      "grad_norm": 15.283522605895996,
      "learning_rate": 7.650666666666667e-07,
      "logits/chosen": -2.7012362480163574,
      "logits/rejected": -2.3542585372924805,
      "logps/chosen": -146.67001342773438,
      "logps/rejected": -76.4287109375,
      "loss": 0.0936,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0099849700927734,
      "rewards/margins": 2.7729854583740234,
      "rewards/rejected": -3.782970428466797,
      "step": 1763
    },
    {
      "epoch": 0.7056,
      "grad_norm": 0.43821826577186584,
      "learning_rate": 7.649333333333333e-07,
      "logits/chosen": -2.8960275650024414,
      "logits/rejected": -1.9475724697113037,
      "logps/chosen": -85.77444458007812,
      "logps/rejected": -100.5963134765625,
      "loss": 0.0051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7765674591064453,
      "rewards/margins": 5.758823871612549,
      "rewards/rejected": -4.9822564125061035,
      "step": 1764
    },
    {
      "epoch": 0.706,
      "grad_norm": 1.1349092721939087,
      "learning_rate": 7.648e-07,
      "logits/chosen": -2.777512311935425,
      "logits/rejected": -2.235034227371216,
      "logps/chosen": -90.89007568359375,
      "logps/rejected": -85.77590942382812,
      "loss": 0.0172,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6795982122421265,
      "rewards/margins": 4.121983051300049,
      "rewards/rejected": -3.442384719848633,
      "step": 1765
    },
    {
      "epoch": 0.7064,
      "grad_norm": 0.8581187129020691,
      "learning_rate": 7.646666666666667e-07,
      "logits/chosen": -2.8840768337249756,
      "logits/rejected": -2.3075127601623535,
      "logps/chosen": -93.7579345703125,
      "logps/rejected": -117.91110229492188,
      "loss": 0.0114,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1566307097673416,
      "rewards/margins": 6.455531597137451,
      "rewards/rejected": -6.612162113189697,
      "step": 1766
    },
    {
      "epoch": 0.7068,
      "grad_norm": 0.13871563971042633,
      "learning_rate": 7.645333333333332e-07,
      "logits/chosen": -2.5998988151550293,
      "logits/rejected": -1.9455757141113281,
      "logps/chosen": -117.09524536132812,
      "logps/rejected": -143.37054443359375,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12486916780471802,
      "rewards/margins": 6.938188552856445,
      "rewards/rejected": -6.813319206237793,
      "step": 1767
    },
    {
      "epoch": 0.7072,
      "grad_norm": 0.13189028203487396,
      "learning_rate": 7.643999999999999e-07,
      "logits/chosen": -2.567941904067993,
      "logits/rejected": -2.0712718963623047,
      "logps/chosen": -81.68437957763672,
      "logps/rejected": -157.13999938964844,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38576623797416687,
      "rewards/margins": 7.190290451049805,
      "rewards/rejected": -6.8045244216918945,
      "step": 1768
    },
    {
      "epoch": 0.7076,
      "grad_norm": 0.08455213159322739,
      "learning_rate": 7.642666666666666e-07,
      "logits/chosen": -2.5371291637420654,
      "logits/rejected": -1.6821160316467285,
      "logps/chosen": -141.3282928466797,
      "logps/rejected": -151.8006591796875,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3735427856445312,
      "rewards/margins": 8.014442443847656,
      "rewards/rejected": -6.640899658203125,
      "step": 1769
    },
    {
      "epoch": 0.708,
      "grad_norm": 0.3086300790309906,
      "learning_rate": 7.641333333333333e-07,
      "logits/chosen": -2.782348155975342,
      "logits/rejected": -2.0882785320281982,
      "logps/chosen": -89.1658935546875,
      "logps/rejected": -104.67897033691406,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8572731018066406,
      "rewards/margins": 6.6526103019714355,
      "rewards/rejected": -5.795337200164795,
      "step": 1770
    },
    {
      "epoch": 0.7084,
      "grad_norm": 0.6745410561561584,
      "learning_rate": 7.64e-07,
      "logits/chosen": -3.020294189453125,
      "logits/rejected": -2.803692102432251,
      "logps/chosen": -68.91729736328125,
      "logps/rejected": -79.72126770019531,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6983475089073181,
      "rewards/margins": 5.157646179199219,
      "rewards/rejected": -4.459298133850098,
      "step": 1771
    },
    {
      "epoch": 0.7088,
      "grad_norm": 0.6091638207435608,
      "learning_rate": 7.638666666666667e-07,
      "logits/chosen": -2.686333656311035,
      "logits/rejected": -2.1163389682769775,
      "logps/chosen": -98.10658264160156,
      "logps/rejected": -99.9134750366211,
      "loss": 0.0068,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5282951593399048,
      "rewards/margins": 4.995272636413574,
      "rewards/rejected": -4.466977119445801,
      "step": 1772
    },
    {
      "epoch": 0.7092,
      "grad_norm": 0.06497446447610855,
      "learning_rate": 7.637333333333333e-07,
      "logits/chosen": -2.8850059509277344,
      "logits/rejected": -1.9235888719558716,
      "logps/chosen": -102.12088012695312,
      "logps/rejected": -187.5148468017578,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03738556429743767,
      "rewards/margins": 8.146129608154297,
      "rewards/rejected": -8.108744621276855,
      "step": 1773
    },
    {
      "epoch": 0.7096,
      "grad_norm": 0.2356010228395462,
      "learning_rate": 7.635999999999999e-07,
      "logits/chosen": -3.039328098297119,
      "logits/rejected": -2.6732852458953857,
      "logps/chosen": -57.250946044921875,
      "logps/rejected": -169.17843627929688,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5551576614379883,
      "rewards/margins": 8.601173400878906,
      "rewards/rejected": -8.046014785766602,
      "step": 1774
    },
    {
      "epoch": 0.71,
      "grad_norm": 5.979287147521973,
      "learning_rate": 7.634666666666666e-07,
      "logits/chosen": -2.5751962661743164,
      "logits/rejected": -2.6019906997680664,
      "logps/chosen": -153.28549194335938,
      "logps/rejected": -145.44384765625,
      "loss": 0.0622,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.395047664642334,
      "rewards/margins": 3.470541000366211,
      "rewards/rejected": -5.865589141845703,
      "step": 1775
    },
    {
      "epoch": 0.7104,
      "grad_norm": 3.7902698516845703,
      "learning_rate": 7.633333333333333e-07,
      "logits/chosen": -2.6495633125305176,
      "logits/rejected": -2.065845489501953,
      "logps/chosen": -89.20750427246094,
      "logps/rejected": -96.9063949584961,
      "loss": 0.0624,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19765892624855042,
      "rewards/margins": 2.7562732696533203,
      "rewards/rejected": -2.5586142539978027,
      "step": 1776
    },
    {
      "epoch": 0.7108,
      "grad_norm": 1.959280252456665,
      "learning_rate": 7.632e-07,
      "logits/chosen": -2.871993064880371,
      "logits/rejected": -2.235518217086792,
      "logps/chosen": -98.20558166503906,
      "logps/rejected": -97.48236846923828,
      "loss": 0.0225,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8720605969429016,
      "rewards/margins": 3.976325750350952,
      "rewards/rejected": -4.848386287689209,
      "step": 1777
    },
    {
      "epoch": 0.7112,
      "grad_norm": 0.038369905203580856,
      "learning_rate": 7.630666666666666e-07,
      "logits/chosen": -2.957345485687256,
      "logits/rejected": -2.3940815925598145,
      "logps/chosen": -88.21038818359375,
      "logps/rejected": -143.52618408203125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5405250787734985,
      "rewards/margins": 8.296440124511719,
      "rewards/rejected": -7.755914688110352,
      "step": 1778
    },
    {
      "epoch": 0.7116,
      "grad_norm": 0.3297785818576813,
      "learning_rate": 7.629333333333333e-07,
      "logits/chosen": -2.7558116912841797,
      "logits/rejected": -2.4398980140686035,
      "logps/chosen": -82.77229309082031,
      "logps/rejected": -100.42105102539062,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.025990493595600128,
      "rewards/margins": 5.573031425476074,
      "rewards/rejected": -5.599021911621094,
      "step": 1779
    },
    {
      "epoch": 0.712,
      "grad_norm": 2.0362184047698975,
      "learning_rate": 7.628e-07,
      "logits/chosen": -2.8437411785125732,
      "logits/rejected": -2.489375352859497,
      "logps/chosen": -64.46908569335938,
      "logps/rejected": -90.9691162109375,
      "loss": 0.0398,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9342222213745117,
      "rewards/margins": 5.02984619140625,
      "rewards/rejected": -4.095623970031738,
      "step": 1780
    },
    {
      "epoch": 0.7124,
      "grad_norm": 0.09264621138572693,
      "learning_rate": 7.626666666666667e-07,
      "logits/chosen": -2.5476560592651367,
      "logits/rejected": -1.7826530933380127,
      "logps/chosen": -151.03367614746094,
      "logps/rejected": -164.87973022460938,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4694565236568451,
      "rewards/margins": 7.482753276824951,
      "rewards/rejected": -7.013297080993652,
      "step": 1781
    },
    {
      "epoch": 0.7128,
      "grad_norm": 1.1871899366378784,
      "learning_rate": 7.625333333333332e-07,
      "logits/chosen": -3.0999481678009033,
      "logits/rejected": -2.786038875579834,
      "logps/chosen": -62.724609375,
      "logps/rejected": -89.01690673828125,
      "loss": 0.0111,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.142189383506775,
      "rewards/margins": 4.688416481018066,
      "rewards/rejected": -3.546226978302002,
      "step": 1782
    },
    {
      "epoch": 0.7132,
      "grad_norm": 0.6372397541999817,
      "learning_rate": 7.623999999999999e-07,
      "logits/chosen": -2.859304904937744,
      "logits/rejected": -2.16719651222229,
      "logps/chosen": -67.91664123535156,
      "logps/rejected": -82.26106262207031,
      "loss": 0.0079,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5253616571426392,
      "rewards/margins": 5.701225280761719,
      "rewards/rejected": -4.175863742828369,
      "step": 1783
    },
    {
      "epoch": 0.7136,
      "grad_norm": 5.241418838500977,
      "learning_rate": 7.622666666666666e-07,
      "logits/chosen": -2.585041046142578,
      "logits/rejected": -1.938596487045288,
      "logps/chosen": -46.369728088378906,
      "logps/rejected": -134.13348388671875,
      "loss": 0.0517,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.103151798248291,
      "rewards/margins": 5.011179447174072,
      "rewards/rejected": -3.9080276489257812,
      "step": 1784
    },
    {
      "epoch": 0.714,
      "grad_norm": 0.5860961675643921,
      "learning_rate": 7.621333333333333e-07,
      "logits/chosen": -2.8422675132751465,
      "logits/rejected": -2.360729932785034,
      "logps/chosen": -133.01641845703125,
      "logps/rejected": -79.9400634765625,
      "loss": 0.0088,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2668941020965576,
      "rewards/margins": 6.0567708015441895,
      "rewards/rejected": -4.789876461029053,
      "step": 1785
    },
    {
      "epoch": 0.7144,
      "grad_norm": 1.6400374174118042,
      "learning_rate": 7.62e-07,
      "logits/chosen": -3.025775909423828,
      "logits/rejected": -2.7977890968322754,
      "logps/chosen": -67.67194366455078,
      "logps/rejected": -75.36201477050781,
      "loss": 0.0278,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4424474537372589,
      "rewards/margins": 3.8875513076782227,
      "rewards/rejected": -3.445103883743286,
      "step": 1786
    },
    {
      "epoch": 0.7148,
      "grad_norm": 132.41392517089844,
      "learning_rate": 7.618666666666667e-07,
      "logits/chosen": -2.2953336238861084,
      "logits/rejected": -1.8470847606658936,
      "logps/chosen": -240.04148864746094,
      "logps/rejected": -131.35800170898438,
      "loss": 2.2801,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -3.6196603775024414,
      "rewards/margins": 2.3123021125793457,
      "rewards/rejected": -5.931962490081787,
      "step": 1787
    },
    {
      "epoch": 0.7152,
      "grad_norm": 5.406885623931885,
      "learning_rate": 7.617333333333334e-07,
      "logits/chosen": -3.0550270080566406,
      "logits/rejected": -2.7593326568603516,
      "logps/chosen": -73.3651123046875,
      "logps/rejected": -64.66160583496094,
      "loss": 0.0963,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15771427750587463,
      "rewards/margins": 2.722123622894287,
      "rewards/rejected": -2.5644092559814453,
      "step": 1788
    },
    {
      "epoch": 0.7156,
      "grad_norm": 0.8626241683959961,
      "learning_rate": 7.616e-07,
      "logits/chosen": -2.797173500061035,
      "logits/rejected": -2.1063649654388428,
      "logps/chosen": -115.09270477294922,
      "logps/rejected": -100.53656005859375,
      "loss": 0.0106,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39622992277145386,
      "rewards/margins": 4.544710159301758,
      "rewards/rejected": -4.148480415344238,
      "step": 1789
    },
    {
      "epoch": 0.716,
      "grad_norm": 3.2310333251953125,
      "learning_rate": 7.614666666666666e-07,
      "logits/chosen": -2.496914863586426,
      "logits/rejected": -1.802860140800476,
      "logps/chosen": -137.5948944091797,
      "logps/rejected": -144.5262451171875,
      "loss": 0.0353,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6127208471298218,
      "rewards/margins": 6.013147354125977,
      "rewards/rejected": -6.625868320465088,
      "step": 1790
    },
    {
      "epoch": 0.7164,
      "grad_norm": 0.1376052051782608,
      "learning_rate": 7.613333333333333e-07,
      "logits/chosen": -2.5088939666748047,
      "logits/rejected": -1.7887051105499268,
      "logps/chosen": -103.61224365234375,
      "logps/rejected": -166.14111328125,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.32224541902542114,
      "rewards/margins": 6.959857940673828,
      "rewards/rejected": -7.282103538513184,
      "step": 1791
    },
    {
      "epoch": 0.7168,
      "grad_norm": 0.9343101382255554,
      "learning_rate": 7.611999999999999e-07,
      "logits/chosen": -2.859990358352661,
      "logits/rejected": -2.005669116973877,
      "logps/chosen": -101.80194854736328,
      "logps/rejected": -116.90543365478516,
      "loss": 0.0088,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3725229501724243,
      "rewards/margins": 5.365213394165039,
      "rewards/rejected": -4.992690086364746,
      "step": 1792
    },
    {
      "epoch": 0.7172,
      "grad_norm": 0.4867303967475891,
      "learning_rate": 7.610666666666666e-07,
      "logits/chosen": -2.7787599563598633,
      "logits/rejected": -1.6897246837615967,
      "logps/chosen": -88.75679779052734,
      "logps/rejected": -103.54010009765625,
      "loss": 0.0057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7684788107872009,
      "rewards/margins": 5.763564109802246,
      "rewards/rejected": -4.995085716247559,
      "step": 1793
    },
    {
      "epoch": 0.7176,
      "grad_norm": 1.8147410154342651,
      "learning_rate": 7.609333333333333e-07,
      "logits/chosen": -2.671041488647461,
      "logits/rejected": -2.268935203552246,
      "logps/chosen": -127.04943084716797,
      "logps/rejected": -109.48194122314453,
      "loss": 0.0206,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8400436639785767,
      "rewards/margins": 4.380279541015625,
      "rewards/rejected": -3.540235996246338,
      "step": 1794
    },
    {
      "epoch": 0.718,
      "grad_norm": 0.22678548097610474,
      "learning_rate": 7.608e-07,
      "logits/chosen": -2.6674609184265137,
      "logits/rejected": -2.0564982891082764,
      "logps/chosen": -93.932373046875,
      "logps/rejected": -111.54753112792969,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6825160980224609,
      "rewards/margins": 7.03076171875,
      "rewards/rejected": -6.348245620727539,
      "step": 1795
    },
    {
      "epoch": 0.7184,
      "grad_norm": 0.20275607705116272,
      "learning_rate": 7.606666666666667e-07,
      "logits/chosen": -2.894367218017578,
      "logits/rejected": -2.082183837890625,
      "logps/chosen": -55.96820068359375,
      "logps/rejected": -96.22178649902344,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6525897979736328,
      "rewards/margins": 7.257608413696289,
      "rewards/rejected": -5.605018615722656,
      "step": 1796
    },
    {
      "epoch": 0.7188,
      "grad_norm": 0.6728909015655518,
      "learning_rate": 7.605333333333333e-07,
      "logits/chosen": -3.0293478965759277,
      "logits/rejected": -2.5309810638427734,
      "logps/chosen": -70.68260192871094,
      "logps/rejected": -99.80402374267578,
      "loss": 0.006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31846731901168823,
      "rewards/margins": 5.471807479858398,
      "rewards/rejected": -5.1533403396606445,
      "step": 1797
    },
    {
      "epoch": 0.7192,
      "grad_norm": 4.801822662353516,
      "learning_rate": 7.604e-07,
      "logits/chosen": -2.778337001800537,
      "logits/rejected": -2.3457820415496826,
      "logps/chosen": -113.51268005371094,
      "logps/rejected": -167.73687744140625,
      "loss": 0.0455,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4295288026332855,
      "rewards/margins": 3.929295539855957,
      "rewards/rejected": -4.358824253082275,
      "step": 1798
    },
    {
      "epoch": 0.7196,
      "grad_norm": 0.09495219588279724,
      "learning_rate": 7.602666666666666e-07,
      "logits/chosen": -3.0129361152648926,
      "logits/rejected": -2.3651936054229736,
      "logps/chosen": -77.06549835205078,
      "logps/rejected": -114.957763671875,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4514600038528442,
      "rewards/margins": 7.939885139465332,
      "rewards/rejected": -6.4884257316589355,
      "step": 1799
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.1358087956905365,
      "learning_rate": 7.601333333333333e-07,
      "logits/chosen": -2.58225679397583,
      "logits/rejected": -2.067007064819336,
      "logps/chosen": -74.75846862792969,
      "logps/rejected": -138.46185302734375,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.655413031578064,
      "rewards/margins": 7.329459190368652,
      "rewards/rejected": -6.674046039581299,
      "step": 1800
    },
    {
      "epoch": 0.7204,
      "grad_norm": 0.9488378763198853,
      "learning_rate": 7.599999999999999e-07,
      "logits/chosen": -3.0585474967956543,
      "logits/rejected": -2.5011911392211914,
      "logps/chosen": -84.59848022460938,
      "logps/rejected": -100.10774993896484,
      "loss": 0.0106,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9762989282608032,
      "rewards/margins": 5.361409664154053,
      "rewards/rejected": -4.385110855102539,
      "step": 1801
    },
    {
      "epoch": 0.7208,
      "grad_norm": 0.17572781443595886,
      "learning_rate": 7.598666666666666e-07,
      "logits/chosen": -2.8285083770751953,
      "logits/rejected": -2.4450433254241943,
      "logps/chosen": -130.90322875976562,
      "logps/rejected": -110.61026000976562,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2667205333709717,
      "rewards/margins": 7.091495513916016,
      "rewards/rejected": -5.824774742126465,
      "step": 1802
    },
    {
      "epoch": 0.7212,
      "grad_norm": 0.7785034775733948,
      "learning_rate": 7.597333333333333e-07,
      "logits/chosen": -2.7583608627319336,
      "logits/rejected": -2.300623893737793,
      "logps/chosen": -101.31011199951172,
      "logps/rejected": -104.18566131591797,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3020482063293457,
      "rewards/margins": 6.831786632537842,
      "rewards/rejected": -5.529738426208496,
      "step": 1803
    },
    {
      "epoch": 0.7216,
      "grad_norm": 0.48961886763572693,
      "learning_rate": 7.596e-07,
      "logits/chosen": -2.7989537715911865,
      "logits/rejected": -2.0722010135650635,
      "logps/chosen": -91.56517791748047,
      "logps/rejected": -100.56544494628906,
      "loss": 0.0049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1190025806427002,
      "rewards/margins": 5.328490257263184,
      "rewards/rejected": -4.209487438201904,
      "step": 1804
    },
    {
      "epoch": 0.722,
      "grad_norm": 84.57123565673828,
      "learning_rate": 7.594666666666666e-07,
      "logits/chosen": -2.2303414344787598,
      "logits/rejected": -1.7772810459136963,
      "logps/chosen": -216.65493774414062,
      "logps/rejected": -142.51597595214844,
      "loss": 1.3404,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -4.271287441253662,
      "rewards/margins": 1.8578107357025146,
      "rewards/rejected": -6.129097938537598,
      "step": 1805
    },
    {
      "epoch": 0.7224,
      "grad_norm": 1.5279624462127686,
      "learning_rate": 7.593333333333333e-07,
      "logits/chosen": -3.1811013221740723,
      "logits/rejected": -2.775704860687256,
      "logps/chosen": -65.6893539428711,
      "logps/rejected": -73.16292572021484,
      "loss": 0.0217,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.659501314163208,
      "rewards/margins": 3.8319618701934814,
      "rewards/rejected": -3.1724605560302734,
      "step": 1806
    },
    {
      "epoch": 0.7228,
      "grad_norm": 1.6846646070480347,
      "learning_rate": 7.592e-07,
      "logits/chosen": -2.8080320358276367,
      "logits/rejected": -2.406525135040283,
      "logps/chosen": -117.02159118652344,
      "logps/rejected": -113.98042297363281,
      "loss": 0.0132,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026893258094787598,
      "rewards/margins": 4.740106105804443,
      "rewards/rejected": -4.713212966918945,
      "step": 1807
    },
    {
      "epoch": 0.7232,
      "grad_norm": 0.21332935988903046,
      "learning_rate": 7.590666666666667e-07,
      "logits/chosen": -3.095818519592285,
      "logits/rejected": -2.603043556213379,
      "logps/chosen": -45.414772033691406,
      "logps/rejected": -83.79154968261719,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7963027954101562,
      "rewards/margins": 5.917901992797852,
      "rewards/rejected": -4.121599197387695,
      "step": 1808
    },
    {
      "epoch": 0.7236,
      "grad_norm": 0.11301898956298828,
      "learning_rate": 7.589333333333334e-07,
      "logits/chosen": -2.942997932434082,
      "logits/rejected": -2.198523998260498,
      "logps/chosen": -94.48967742919922,
      "logps/rejected": -137.1463623046875,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3390098810195923,
      "rewards/margins": 8.622718811035156,
      "rewards/rejected": -7.283708572387695,
      "step": 1809
    },
    {
      "epoch": 0.724,
      "grad_norm": 0.9494963884353638,
      "learning_rate": 7.588e-07,
      "logits/chosen": -2.7796945571899414,
      "logits/rejected": -2.5311999320983887,
      "logps/chosen": -105.39056396484375,
      "logps/rejected": -111.46086120605469,
      "loss": 0.0107,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8228220343589783,
      "rewards/margins": 4.659387588500977,
      "rewards/rejected": -5.482209205627441,
      "step": 1810
    },
    {
      "epoch": 0.7244,
      "grad_norm": 0.3087080717086792,
      "learning_rate": 7.586666666666666e-07,
      "logits/chosen": -2.9162323474884033,
      "logits/rejected": -2.3935940265655518,
      "logps/chosen": -97.27737426757812,
      "logps/rejected": -118.15519714355469,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6122909784317017,
      "rewards/margins": 6.623807430267334,
      "rewards/rejected": -6.011516571044922,
      "step": 1811
    },
    {
      "epoch": 0.7248,
      "grad_norm": 1.8388129472732544,
      "learning_rate": 7.585333333333332e-07,
      "logits/chosen": -2.6240134239196777,
      "logits/rejected": -2.2957253456115723,
      "logps/chosen": -125.66001892089844,
      "logps/rejected": -193.7679443359375,
      "loss": 0.0228,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2202427089214325,
      "rewards/margins": 4.439791679382324,
      "rewards/rejected": -4.21954870223999,
      "step": 1812
    },
    {
      "epoch": 0.7252,
      "grad_norm": 0.4288097023963928,
      "learning_rate": 7.583999999999999e-07,
      "logits/chosen": -2.5359716415405273,
      "logits/rejected": -2.071592330932617,
      "logps/chosen": -116.47404479980469,
      "logps/rejected": -132.34054565429688,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9081524610519409,
      "rewards/margins": 5.900620460510254,
      "rewards/rejected": -4.992467880249023,
      "step": 1813
    },
    {
      "epoch": 0.7256,
      "grad_norm": 1.037634253501892,
      "learning_rate": 7.582666666666666e-07,
      "logits/chosen": -3.106226682662964,
      "logits/rejected": -2.572629928588867,
      "logps/chosen": -105.75897216796875,
      "logps/rejected": -102.7520751953125,
      "loss": 0.0102,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.24630223214626312,
      "rewards/margins": 5.330662727355957,
      "rewards/rejected": -5.57696533203125,
      "step": 1814
    },
    {
      "epoch": 0.726,
      "grad_norm": 1.392089605331421,
      "learning_rate": 7.581333333333333e-07,
      "logits/chosen": -2.5675246715545654,
      "logits/rejected": -1.9467344284057617,
      "logps/chosen": -120.79423522949219,
      "logps/rejected": -124.56834411621094,
      "loss": 0.0135,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6836040616035461,
      "rewards/margins": 4.8923020362854,
      "rewards/rejected": -4.208698272705078,
      "step": 1815
    },
    {
      "epoch": 0.7264,
      "grad_norm": 0.522321343421936,
      "learning_rate": 7.58e-07,
      "logits/chosen": -2.8259174823760986,
      "logits/rejected": -1.9075486660003662,
      "logps/chosen": -123.90444946289062,
      "logps/rejected": -218.98583984375,
      "loss": 0.0048,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.22261390089988708,
      "rewards/margins": 8.598599433898926,
      "rewards/rejected": -8.821213722229004,
      "step": 1816
    },
    {
      "epoch": 0.7268,
      "grad_norm": 0.30358192324638367,
      "learning_rate": 7.578666666666667e-07,
      "logits/chosen": -3.280092716217041,
      "logits/rejected": -2.6516544818878174,
      "logps/chosen": -56.81584167480469,
      "logps/rejected": -99.90571594238281,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5319010019302368,
      "rewards/margins": 5.748941898345947,
      "rewards/rejected": -5.217041015625,
      "step": 1817
    },
    {
      "epoch": 0.7272,
      "grad_norm": 1.6613857746124268,
      "learning_rate": 7.577333333333334e-07,
      "logits/chosen": -3.259784460067749,
      "logits/rejected": -2.912700653076172,
      "logps/chosen": -49.190208435058594,
      "logps/rejected": -100.02494812011719,
      "loss": 0.0181,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2038519382476807,
      "rewards/margins": 5.399798393249512,
      "rewards/rejected": -4.195946216583252,
      "step": 1818
    },
    {
      "epoch": 0.7276,
      "grad_norm": 1.4798413515090942,
      "learning_rate": 7.576000000000001e-07,
      "logits/chosen": -2.5535097122192383,
      "logits/rejected": -1.9828026294708252,
      "logps/chosen": -108.49608612060547,
      "logps/rejected": -135.79673767089844,
      "loss": 0.014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1213551759719849,
      "rewards/margins": 6.21124267578125,
      "rewards/rejected": -5.089887619018555,
      "step": 1819
    },
    {
      "epoch": 0.728,
      "grad_norm": 2.9723150730133057,
      "learning_rate": 7.574666666666665e-07,
      "logits/chosen": -2.629021167755127,
      "logits/rejected": -2.6851906776428223,
      "logps/chosen": -122.14395141601562,
      "logps/rejected": -73.65351867675781,
      "loss": 0.0412,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5670604705810547,
      "rewards/margins": 3.3036139011383057,
      "rewards/rejected": -2.736553430557251,
      "step": 1820
    },
    {
      "epoch": 0.7284,
      "grad_norm": 0.45841529965400696,
      "learning_rate": 7.573333333333332e-07,
      "logits/chosen": -2.8257479667663574,
      "logits/rejected": -2.4561917781829834,
      "logps/chosen": -80.43992614746094,
      "logps/rejected": -84.76972961425781,
      "loss": 0.0079,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3330562710762024,
      "rewards/margins": 4.9971466064453125,
      "rewards/rejected": -4.664090633392334,
      "step": 1821
    },
    {
      "epoch": 0.7288,
      "grad_norm": 0.14098556339740753,
      "learning_rate": 7.571999999999999e-07,
      "logits/chosen": -2.9394655227661133,
      "logits/rejected": -2.1619741916656494,
      "logps/chosen": -122.38442993164062,
      "logps/rejected": -163.03109741210938,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.344395637512207,
      "rewards/margins": 6.846336364746094,
      "rewards/rejected": -8.1907320022583,
      "step": 1822
    },
    {
      "epoch": 0.7292,
      "grad_norm": 1.4520834684371948,
      "learning_rate": 7.570666666666666e-07,
      "logits/chosen": -2.6815123558044434,
      "logits/rejected": -2.1656405925750732,
      "logps/chosen": -134.64279174804688,
      "logps/rejected": -116.96131134033203,
      "loss": 0.0108,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8406429886817932,
      "rewards/margins": 6.566932201385498,
      "rewards/rejected": -5.72628927230835,
      "step": 1823
    },
    {
      "epoch": 0.7296,
      "grad_norm": 0.07010778784751892,
      "learning_rate": 7.569333333333333e-07,
      "logits/chosen": -3.2699978351593018,
      "logits/rejected": -2.4937291145324707,
      "logps/chosen": -78.79115295410156,
      "logps/rejected": -143.11776733398438,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3586282730102539,
      "rewards/margins": 7.578000068664551,
      "rewards/rejected": -7.936628341674805,
      "step": 1824
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.640458106994629,
      "learning_rate": 7.568e-07,
      "logits/chosen": -3.0030393600463867,
      "logits/rejected": -2.6423308849334717,
      "logps/chosen": -95.8050537109375,
      "logps/rejected": -94.54539489746094,
      "loss": 0.0219,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3028831481933594,
      "rewards/margins": 4.5456156730651855,
      "rewards/rejected": -4.848498821258545,
      "step": 1825
    },
    {
      "epoch": 0.7304,
      "grad_norm": 2.7050700187683105,
      "learning_rate": 7.566666666666667e-07,
      "logits/chosen": -3.1010608673095703,
      "logits/rejected": -2.5373036861419678,
      "logps/chosen": -43.498321533203125,
      "logps/rejected": -109.42049407958984,
      "loss": 0.02,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3206527829170227,
      "rewards/margins": 4.7814764976501465,
      "rewards/rejected": -5.1021294593811035,
      "step": 1826
    },
    {
      "epoch": 0.7308,
      "grad_norm": 0.84914231300354,
      "learning_rate": 7.565333333333333e-07,
      "logits/chosen": -2.719644546508789,
      "logits/rejected": -2.59181547164917,
      "logps/chosen": -76.40701293945312,
      "logps/rejected": -86.179443359375,
      "loss": 0.0117,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9961422085762024,
      "rewards/margins": 4.446407318115234,
      "rewards/rejected": -3.4502649307250977,
      "step": 1827
    },
    {
      "epoch": 0.7312,
      "grad_norm": 2.08586049079895,
      "learning_rate": 7.564e-07,
      "logits/chosen": -3.20959210395813,
      "logits/rejected": -2.663079261779785,
      "logps/chosen": -70.32069396972656,
      "logps/rejected": -81.66371154785156,
      "loss": 0.0264,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21476173400878906,
      "rewards/margins": 4.491999626159668,
      "rewards/rejected": -4.277237892150879,
      "step": 1828
    },
    {
      "epoch": 0.7316,
      "grad_norm": 0.07582129538059235,
      "learning_rate": 7.562666666666666e-07,
      "logits/chosen": -3.007356882095337,
      "logits/rejected": -2.1849818229675293,
      "logps/chosen": -58.11628723144531,
      "logps/rejected": -117.39981079101562,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.417099952697754,
      "rewards/margins": 7.75541877746582,
      "rewards/rejected": -6.338318824768066,
      "step": 1829
    },
    {
      "epoch": 0.732,
      "grad_norm": 0.2948998212814331,
      "learning_rate": 7.561333333333332e-07,
      "logits/chosen": -3.183206558227539,
      "logits/rejected": -2.2914395332336426,
      "logps/chosen": -49.29283905029297,
      "logps/rejected": -101.11131286621094,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4091896414756775,
      "rewards/margins": 5.679176330566406,
      "rewards/rejected": -5.269987106323242,
      "step": 1830
    },
    {
      "epoch": 0.7324,
      "grad_norm": 10.61739444732666,
      "learning_rate": 7.559999999999999e-07,
      "logits/chosen": -2.874136209487915,
      "logits/rejected": -2.9786734580993652,
      "logps/chosen": -101.25102233886719,
      "logps/rejected": -78.32982635498047,
      "loss": 0.1396,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2574581205844879,
      "rewards/margins": 3.486024856567383,
      "rewards/rejected": -3.743483066558838,
      "step": 1831
    },
    {
      "epoch": 0.7328,
      "grad_norm": 0.020137999206781387,
      "learning_rate": 7.558666666666666e-07,
      "logits/chosen": -2.460886001586914,
      "logits/rejected": -1.6237432956695557,
      "logps/chosen": -143.72763061523438,
      "logps/rejected": -169.83062744140625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4054310321807861,
      "rewards/margins": 9.269292831420898,
      "rewards/rejected": -7.863861083984375,
      "step": 1832
    },
    {
      "epoch": 0.7332,
      "grad_norm": 1.6524715423583984,
      "learning_rate": 7.557333333333333e-07,
      "logits/chosen": -2.9334568977355957,
      "logits/rejected": -2.7920734882354736,
      "logps/chosen": -61.16865921020508,
      "logps/rejected": -120.82118225097656,
      "loss": 0.0273,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7860668301582336,
      "rewards/margins": 6.3438615798950195,
      "rewards/rejected": -5.55779504776001,
      "step": 1833
    },
    {
      "epoch": 0.7336,
      "grad_norm": 0.8895131349563599,
      "learning_rate": 7.556e-07,
      "logits/chosen": -2.7765913009643555,
      "logits/rejected": -2.1485705375671387,
      "logps/chosen": -80.93328857421875,
      "logps/rejected": -92.72442626953125,
      "loss": 0.0091,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2594037055969238,
      "rewards/margins": 5.969857692718506,
      "rewards/rejected": -4.710453987121582,
      "step": 1834
    },
    {
      "epoch": 0.734,
      "grad_norm": 0.059409964829683304,
      "learning_rate": 7.554666666666666e-07,
      "logits/chosen": -2.9203133583068848,
      "logits/rejected": -1.9457414150238037,
      "logps/chosen": -99.99456787109375,
      "logps/rejected": -139.9667205810547,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7824376821517944,
      "rewards/margins": 7.66810941696167,
      "rewards/rejected": -6.885671615600586,
      "step": 1835
    },
    {
      "epoch": 0.7344,
      "grad_norm": 0.16167116165161133,
      "learning_rate": 7.553333333333333e-07,
      "logits/chosen": -2.643054962158203,
      "logits/rejected": -1.9842748641967773,
      "logps/chosen": -66.86369323730469,
      "logps/rejected": -105.07015991210938,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0390517711639404,
      "rewards/margins": 6.538530349731445,
      "rewards/rejected": -5.499478340148926,
      "step": 1836
    },
    {
      "epoch": 0.7348,
      "grad_norm": 0.9235304594039917,
      "learning_rate": 7.552e-07,
      "logits/chosen": -3.1330018043518066,
      "logits/rejected": -2.573331594467163,
      "logps/chosen": -70.26101684570312,
      "logps/rejected": -105.82347106933594,
      "loss": 0.0094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11463432759046555,
      "rewards/margins": 5.253414630889893,
      "rewards/rejected": -5.13878059387207,
      "step": 1837
    },
    {
      "epoch": 0.7352,
      "grad_norm": 5.921721935272217,
      "learning_rate": 7.550666666666667e-07,
      "logits/chosen": -2.691404342651367,
      "logits/rejected": -2.106645107269287,
      "logps/chosen": -230.71902465820312,
      "logps/rejected": -148.70230102539062,
      "loss": 0.0357,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2405884265899658,
      "rewards/margins": 6.0114545822143555,
      "rewards/rejected": -7.252042770385742,
      "step": 1838
    },
    {
      "epoch": 0.7356,
      "grad_norm": 0.40548452734947205,
      "learning_rate": 7.549333333333333e-07,
      "logits/chosen": -3.168086528778076,
      "logits/rejected": -2.5337815284729004,
      "logps/chosen": -63.51359558105469,
      "logps/rejected": -95.03190612792969,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0401759147644043,
      "rewards/margins": 5.426499366760254,
      "rewards/rejected": -4.386323928833008,
      "step": 1839
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.011175205931067467,
      "learning_rate": 7.548e-07,
      "logits/chosen": -2.948763608932495,
      "logits/rejected": -2.1203858852386475,
      "logps/chosen": -82.96455383300781,
      "logps/rejected": -149.30453491210938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4325668811798096,
      "rewards/margins": 9.869058609008789,
      "rewards/rejected": -8.436491966247559,
      "step": 1840
    },
    {
      "epoch": 0.7364,
      "grad_norm": 0.8937183022499084,
      "learning_rate": 7.546666666666666e-07,
      "logits/chosen": -3.218600034713745,
      "logits/rejected": -2.9113712310791016,
      "logps/chosen": -83.50222778320312,
      "logps/rejected": -88.58551025390625,
      "loss": 0.0107,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4030950665473938,
      "rewards/margins": 4.6310834884643555,
      "rewards/rejected": -4.227988243103027,
      "step": 1841
    },
    {
      "epoch": 0.7368,
      "grad_norm": 4.273252487182617,
      "learning_rate": 7.545333333333332e-07,
      "logits/chosen": -2.7936148643493652,
      "logits/rejected": -2.002065420150757,
      "logps/chosen": -139.79052734375,
      "logps/rejected": -123.8928451538086,
      "loss": 0.0247,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3936221599578857,
      "rewards/margins": 5.2144646644592285,
      "rewards/rejected": -6.608087062835693,
      "step": 1842
    },
    {
      "epoch": 0.7372,
      "grad_norm": 2.6384294033050537,
      "learning_rate": 7.543999999999999e-07,
      "logits/chosen": -3.210024356842041,
      "logits/rejected": -2.6438894271850586,
      "logps/chosen": -107.07401275634766,
      "logps/rejected": -87.02105712890625,
      "loss": 0.0395,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1713319718837738,
      "rewards/margins": 3.225633144378662,
      "rewards/rejected": -3.3969650268554688,
      "step": 1843
    },
    {
      "epoch": 0.7376,
      "grad_norm": 4.428385257720947,
      "learning_rate": 7.542666666666666e-07,
      "logits/chosen": -3.056642770767212,
      "logits/rejected": -2.717146396636963,
      "logps/chosen": -36.795692443847656,
      "logps/rejected": -80.21980285644531,
      "loss": 0.0657,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5946453809738159,
      "rewards/margins": 4.101603984832764,
      "rewards/rejected": -3.506958484649658,
      "step": 1844
    },
    {
      "epoch": 0.738,
      "grad_norm": 0.1929531991481781,
      "learning_rate": 7.541333333333333e-07,
      "logits/chosen": -2.9423317909240723,
      "logits/rejected": -2.5250425338745117,
      "logps/chosen": -96.13336181640625,
      "logps/rejected": -116.80436706542969,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9471855163574219,
      "rewards/margins": 7.306948661804199,
      "rewards/rejected": -6.3597636222839355,
      "step": 1845
    },
    {
      "epoch": 0.7384,
      "grad_norm": 2.2012717723846436,
      "learning_rate": 7.54e-07,
      "logits/chosen": -2.614924430847168,
      "logits/rejected": -2.3291115760803223,
      "logps/chosen": -159.60748291015625,
      "logps/rejected": -109.6961441040039,
      "loss": 0.0192,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.019345462322235107,
      "rewards/margins": 4.006042957305908,
      "rewards/rejected": -4.025388717651367,
      "step": 1846
    },
    {
      "epoch": 0.7388,
      "grad_norm": 1.7308573722839355,
      "learning_rate": 7.538666666666667e-07,
      "logits/chosen": -2.8333983421325684,
      "logits/rejected": -2.7906575202941895,
      "logps/chosen": -134.17578125,
      "logps/rejected": -104.63714599609375,
      "loss": 0.0281,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3969871699810028,
      "rewards/margins": 3.5894317626953125,
      "rewards/rejected": -3.9864187240600586,
      "step": 1847
    },
    {
      "epoch": 0.7392,
      "grad_norm": 0.30825820565223694,
      "learning_rate": 7.537333333333333e-07,
      "logits/chosen": -2.8564677238464355,
      "logits/rejected": -2.134946346282959,
      "logps/chosen": -94.73332214355469,
      "logps/rejected": -192.26039123535156,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3890236020088196,
      "rewards/margins": 6.326190948486328,
      "rewards/rejected": -6.715214252471924,
      "step": 1848
    },
    {
      "epoch": 0.7396,
      "grad_norm": 0.3443380892276764,
      "learning_rate": 7.536e-07,
      "logits/chosen": -2.916623592376709,
      "logits/rejected": -2.5889720916748047,
      "logps/chosen": -93.60266876220703,
      "logps/rejected": -86.92977905273438,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1526705026626587,
      "rewards/margins": 5.439105033874512,
      "rewards/rejected": -4.286434173583984,
      "step": 1849
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.8471602201461792,
      "learning_rate": 7.534666666666666e-07,
      "logits/chosen": -2.9074957370758057,
      "logits/rejected": -2.376508951187134,
      "logps/chosen": -50.39126205444336,
      "logps/rejected": -86.38075256347656,
      "loss": 0.0082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5823484063148499,
      "rewards/margins": 5.009461879730225,
      "rewards/rejected": -4.4271135330200195,
      "step": 1850
    },
    {
      "epoch": 0.7404,
      "grad_norm": 1.1405515670776367,
      "learning_rate": 7.533333333333332e-07,
      "logits/chosen": -2.834656000137329,
      "logits/rejected": -2.4608840942382812,
      "logps/chosen": -110.02679443359375,
      "logps/rejected": -95.21878051757812,
      "loss": 0.0111,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020805001258850098,
      "rewards/margins": 5.082773208618164,
      "rewards/rejected": -5.061968803405762,
      "step": 1851
    },
    {
      "epoch": 0.7408,
      "grad_norm": 2.2057769298553467,
      "learning_rate": 7.531999999999999e-07,
      "logits/chosen": -2.891655921936035,
      "logits/rejected": -2.5535030364990234,
      "logps/chosen": -49.73473358154297,
      "logps/rejected": -111.63607788085938,
      "loss": 0.0286,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4545176029205322,
      "rewards/margins": 5.278557777404785,
      "rewards/rejected": -3.824040174484253,
      "step": 1852
    },
    {
      "epoch": 0.7412,
      "grad_norm": 5.1220927238464355,
      "learning_rate": 7.530666666666666e-07,
      "logits/chosen": -3.3232903480529785,
      "logits/rejected": -2.7736172676086426,
      "logps/chosen": -66.1978988647461,
      "logps/rejected": -94.85443115234375,
      "loss": 0.069,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06881104409694672,
      "rewards/margins": 4.409489154815674,
      "rewards/rejected": -4.3406782150268555,
      "step": 1853
    },
    {
      "epoch": 0.7416,
      "grad_norm": 0.1531115025281906,
      "learning_rate": 7.529333333333333e-07,
      "logits/chosen": -2.8519020080566406,
      "logits/rejected": -2.5928430557250977,
      "logps/chosen": -83.7188491821289,
      "logps/rejected": -148.6422576904297,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8357242345809937,
      "rewards/margins": 7.587271690368652,
      "rewards/rejected": -5.751547336578369,
      "step": 1854
    },
    {
      "epoch": 0.742,
      "grad_norm": 2.4611692428588867,
      "learning_rate": 7.528e-07,
      "logits/chosen": -2.635676383972168,
      "logits/rejected": -1.9662206172943115,
      "logps/chosen": -87.77745056152344,
      "logps/rejected": -122.22944641113281,
      "loss": 0.0288,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4949864149093628,
      "rewards/margins": 5.355183124542236,
      "rewards/rejected": -3.860196828842163,
      "step": 1855
    },
    {
      "epoch": 0.7424,
      "grad_norm": 1.2974332571029663,
      "learning_rate": 7.526666666666667e-07,
      "logits/chosen": -2.5196902751922607,
      "logits/rejected": -2.415947437286377,
      "logps/chosen": -124.30918884277344,
      "logps/rejected": -93.9066390991211,
      "loss": 0.0131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.789668321609497,
      "rewards/margins": 4.337706565856934,
      "rewards/rejected": -2.5480384826660156,
      "step": 1856
    },
    {
      "epoch": 0.7428,
      "grad_norm": 0.7726561427116394,
      "learning_rate": 7.525333333333334e-07,
      "logits/chosen": -2.537550449371338,
      "logits/rejected": -2.0650408267974854,
      "logps/chosen": -139.83853149414062,
      "logps/rejected": -98.76268768310547,
      "loss": 0.0103,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9539692401885986,
      "rewards/margins": 5.269086837768555,
      "rewards/rejected": -4.315117835998535,
      "step": 1857
    },
    {
      "epoch": 0.7432,
      "grad_norm": 0.9633349776268005,
      "learning_rate": 7.523999999999999e-07,
      "logits/chosen": -3.0890302658081055,
      "logits/rejected": -2.560023784637451,
      "logps/chosen": -82.84078979492188,
      "logps/rejected": -98.74198913574219,
      "loss": 0.0099,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7780373096466064,
      "rewards/margins": 7.070237159729004,
      "rewards/rejected": -5.292200088500977,
      "step": 1858
    },
    {
      "epoch": 0.7436,
      "grad_norm": 0.36311057209968567,
      "learning_rate": 7.522666666666666e-07,
      "logits/chosen": -2.5627193450927734,
      "logits/rejected": -1.804247260093689,
      "logps/chosen": -116.78820037841797,
      "logps/rejected": -165.13894653320312,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7189655900001526,
      "rewards/margins": 7.01596212387085,
      "rewards/rejected": -6.2969970703125,
      "step": 1859
    },
    {
      "epoch": 0.744,
      "grad_norm": 1.4575324058532715,
      "learning_rate": 7.521333333333333e-07,
      "logits/chosen": -3.0824027061462402,
      "logits/rejected": -2.6853249073028564,
      "logps/chosen": -63.1948356628418,
      "logps/rejected": -117.3743667602539,
      "loss": 0.016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015263751149177551,
      "rewards/margins": 6.0138936042785645,
      "rewards/rejected": -5.998630046844482,
      "step": 1860
    },
    {
      "epoch": 0.7444,
      "grad_norm": 0.3033011853694916,
      "learning_rate": 7.52e-07,
      "logits/chosen": -2.7748074531555176,
      "logits/rejected": -2.3591036796569824,
      "logps/chosen": -128.02920532226562,
      "logps/rejected": -157.4044189453125,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16959458589553833,
      "rewards/margins": 5.739356994628906,
      "rewards/rejected": -5.569762229919434,
      "step": 1861
    },
    {
      "epoch": 0.7448,
      "grad_norm": 18.769277572631836,
      "learning_rate": 7.518666666666666e-07,
      "logits/chosen": -3.0020744800567627,
      "logits/rejected": -2.706035852432251,
      "logps/chosen": -176.41152954101562,
      "logps/rejected": -80.84600830078125,
      "loss": 0.1961,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2496795952320099,
      "rewards/margins": 3.492671251296997,
      "rewards/rejected": -3.7423508167266846,
      "step": 1862
    },
    {
      "epoch": 0.7452,
      "grad_norm": 0.20659089088439941,
      "learning_rate": 7.517333333333333e-07,
      "logits/chosen": -2.622241735458374,
      "logits/rejected": -1.7214314937591553,
      "logps/chosen": -82.08536529541016,
      "logps/rejected": -131.92330932617188,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8937187194824219,
      "rewards/margins": 7.910422325134277,
      "rewards/rejected": -6.0167036056518555,
      "step": 1863
    },
    {
      "epoch": 0.7456,
      "grad_norm": 0.13339053094387054,
      "learning_rate": 7.516e-07,
      "logits/chosen": -2.786170482635498,
      "logits/rejected": -2.081730842590332,
      "logps/chosen": -148.14556884765625,
      "logps/rejected": -178.58653259277344,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0025619566440582275,
      "rewards/margins": 8.180727005004883,
      "rewards/rejected": -8.18328857421875,
      "step": 1864
    },
    {
      "epoch": 0.746,
      "grad_norm": 0.09570050984621048,
      "learning_rate": 7.514666666666666e-07,
      "logits/chosen": -2.6589112281799316,
      "logits/rejected": -1.7692654132843018,
      "logps/chosen": -91.77920532226562,
      "logps/rejected": -120.9240951538086,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.030644655227661,
      "rewards/margins": 8.341797828674316,
      "rewards/rejected": -6.311153411865234,
      "step": 1865
    },
    {
      "epoch": 0.7464,
      "grad_norm": 0.10458637028932571,
      "learning_rate": 7.513333333333333e-07,
      "logits/chosen": -2.586851119995117,
      "logits/rejected": -2.2286314964294434,
      "logps/chosen": -131.8043212890625,
      "logps/rejected": -130.2982940673828,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4940040111541748,
      "rewards/margins": 7.813146591186523,
      "rewards/rejected": -6.3191423416137695,
      "step": 1866
    },
    {
      "epoch": 0.7468,
      "grad_norm": 2.743386745452881,
      "learning_rate": 7.511999999999999e-07,
      "logits/chosen": -3.1820249557495117,
      "logits/rejected": -2.816901445388794,
      "logps/chosen": -50.6644287109375,
      "logps/rejected": -80.09794616699219,
      "loss": 0.0352,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.15743257105350494,
      "rewards/margins": 3.5535826683044434,
      "rewards/rejected": -3.711015224456787,
      "step": 1867
    },
    {
      "epoch": 0.7472,
      "grad_norm": 0.06714986264705658,
      "learning_rate": 7.510666666666666e-07,
      "logits/chosen": -2.547668933868408,
      "logits/rejected": -1.5602138042449951,
      "logps/chosen": -146.736572265625,
      "logps/rejected": -156.43527221679688,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5474113821983337,
      "rewards/margins": 7.632863998413086,
      "rewards/rejected": -7.085453033447266,
      "step": 1868
    },
    {
      "epoch": 0.7476,
      "grad_norm": 0.3072710931301117,
      "learning_rate": 7.509333333333333e-07,
      "logits/chosen": -2.670511245727539,
      "logits/rejected": -2.3577308654785156,
      "logps/chosen": -139.15896606445312,
      "logps/rejected": -120.1628646850586,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5530158877372742,
      "rewards/margins": 7.227471351623535,
      "rewards/rejected": -6.674455642700195,
      "step": 1869
    },
    {
      "epoch": 0.748,
      "grad_norm": 1.3462088108062744,
      "learning_rate": 7.508e-07,
      "logits/chosen": -2.751110553741455,
      "logits/rejected": -2.1965837478637695,
      "logps/chosen": -50.07783126831055,
      "logps/rejected": -151.14865112304688,
      "loss": 0.0158,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6237949132919312,
      "rewards/margins": 7.212227821350098,
      "rewards/rejected": -6.588432788848877,
      "step": 1870
    },
    {
      "epoch": 0.7484,
      "grad_norm": 3.6418964862823486,
      "learning_rate": 7.506666666666667e-07,
      "logits/chosen": -2.8729331493377686,
      "logits/rejected": -2.6180062294006348,
      "logps/chosen": -96.55648040771484,
      "logps/rejected": -171.63978576660156,
      "loss": 0.0413,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5696917176246643,
      "rewards/margins": 5.271603584289551,
      "rewards/rejected": -4.7019124031066895,
      "step": 1871
    },
    {
      "epoch": 0.7488,
      "grad_norm": 0.6217597723007202,
      "learning_rate": 7.505333333333334e-07,
      "logits/chosen": -3.161250352859497,
      "logits/rejected": -2.657252788543701,
      "logps/chosen": -46.374542236328125,
      "logps/rejected": -96.84213256835938,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9426849484443665,
      "rewards/margins": 5.935886859893799,
      "rewards/rejected": -4.993201732635498,
      "step": 1872
    },
    {
      "epoch": 0.7492,
      "grad_norm": 0.5897089838981628,
      "learning_rate": 7.503999999999999e-07,
      "logits/chosen": -2.5664103031158447,
      "logits/rejected": -2.0770039558410645,
      "logps/chosen": -212.67364501953125,
      "logps/rejected": -136.7318115234375,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9294326901435852,
      "rewards/margins": 5.985407829284668,
      "rewards/rejected": -6.9148406982421875,
      "step": 1873
    },
    {
      "epoch": 0.7496,
      "grad_norm": 1.0508497953414917,
      "learning_rate": 7.502666666666666e-07,
      "logits/chosen": -3.1010994911193848,
      "logits/rejected": -2.557114601135254,
      "logps/chosen": -95.67609405517578,
      "logps/rejected": -95.27849578857422,
      "loss": 0.0103,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1338355988264084,
      "rewards/margins": 4.602911949157715,
      "rewards/rejected": -4.469076156616211,
      "step": 1874
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.25634410977363586,
      "learning_rate": 7.501333333333333e-07,
      "logits/chosen": -2.5532078742980957,
      "logits/rejected": -2.117567539215088,
      "logps/chosen": -135.5276641845703,
      "logps/rejected": -114.12066650390625,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.460326075553894,
      "rewards/margins": 6.069252014160156,
      "rewards/rejected": -4.608925819396973,
      "step": 1875
    },
    {
      "epoch": 0.7504,
      "grad_norm": 1.9088064432144165,
      "learning_rate": 7.5e-07,
      "logits/chosen": -2.5688223838806152,
      "logits/rejected": -2.333883285522461,
      "logps/chosen": -151.13531494140625,
      "logps/rejected": -101.89705657958984,
      "loss": 0.0224,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.09874802827835083,
      "rewards/margins": 4.6743268966674805,
      "rewards/rejected": -4.773074626922607,
      "step": 1876
    },
    {
      "epoch": 0.7508,
      "grad_norm": 0.46097058057785034,
      "learning_rate": 7.498666666666666e-07,
      "logits/chosen": -2.902153491973877,
      "logits/rejected": -2.3566927909851074,
      "logps/chosen": -56.29429244995117,
      "logps/rejected": -105.84120178222656,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.821384072303772,
      "rewards/margins": 5.56062126159668,
      "rewards/rejected": -4.739237308502197,
      "step": 1877
    },
    {
      "epoch": 0.7512,
      "grad_norm": 24.065040588378906,
      "learning_rate": 7.497333333333333e-07,
      "logits/chosen": -2.6104865074157715,
      "logits/rejected": -2.159785270690918,
      "logps/chosen": -152.0432586669922,
      "logps/rejected": -126.56159973144531,
      "loss": 0.1518,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0687291622161865,
      "rewards/margins": 3.803318977355957,
      "rewards/rejected": -4.872048377990723,
      "step": 1878
    },
    {
      "epoch": 0.7516,
      "grad_norm": 12.812994003295898,
      "learning_rate": 7.496e-07,
      "logits/chosen": -2.7874410152435303,
      "logits/rejected": -2.3726017475128174,
      "logps/chosen": -96.53267669677734,
      "logps/rejected": -106.9016342163086,
      "loss": 0.1933,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7103271484375,
      "rewards/margins": 4.374176025390625,
      "rewards/rejected": -5.084503173828125,
      "step": 1879
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.4041425585746765,
      "learning_rate": 7.494666666666666e-07,
      "logits/chosen": -2.6552600860595703,
      "logits/rejected": -2.102271318435669,
      "logps/chosen": -106.89588928222656,
      "logps/rejected": -185.18817138671875,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.295785903930664,
      "rewards/margins": 6.557737350463867,
      "rewards/rejected": -5.261950969696045,
      "step": 1880
    },
    {
      "epoch": 0.7524,
      "grad_norm": 2.9255142211914062,
      "learning_rate": 7.493333333333333e-07,
      "logits/chosen": -2.692549705505371,
      "logits/rejected": -1.9432135820388794,
      "logps/chosen": -181.2106170654297,
      "logps/rejected": -106.13784790039062,
      "loss": 0.0261,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.1301381587982178,
      "rewards/margins": 3.70143461227417,
      "rewards/rejected": -5.831572532653809,
      "step": 1881
    },
    {
      "epoch": 0.7528,
      "grad_norm": 1.8631926774978638,
      "learning_rate": 7.492e-07,
      "logits/chosen": -3.0340638160705566,
      "logits/rejected": -2.722316265106201,
      "logps/chosen": -99.31431579589844,
      "logps/rejected": -81.90451049804688,
      "loss": 0.025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10876236110925674,
      "rewards/margins": 4.471866130828857,
      "rewards/rejected": -4.363103866577148,
      "step": 1882
    },
    {
      "epoch": 0.7532,
      "grad_norm": 0.2618046998977661,
      "learning_rate": 7.490666666666667e-07,
      "logits/chosen": -2.797969341278076,
      "logits/rejected": -2.4949965476989746,
      "logps/chosen": -94.22974395751953,
      "logps/rejected": -136.9768524169922,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.38217735290527344,
      "rewards/margins": 6.3642778396606445,
      "rewards/rejected": -6.746455192565918,
      "step": 1883
    },
    {
      "epoch": 0.7536,
      "grad_norm": 0.1804574877023697,
      "learning_rate": 7.489333333333333e-07,
      "logits/chosen": -2.8720922470092773,
      "logits/rejected": -1.9295310974121094,
      "logps/chosen": -109.91305541992188,
      "logps/rejected": -111.70584106445312,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4031959772109985,
      "rewards/margins": 6.93540096282959,
      "rewards/rejected": -5.532205581665039,
      "step": 1884
    },
    {
      "epoch": 0.754,
      "grad_norm": 0.4132138788700104,
      "learning_rate": 7.488e-07,
      "logits/chosen": -3.0581421852111816,
      "logits/rejected": -2.4040582180023193,
      "logps/chosen": -95.77359008789062,
      "logps/rejected": -84.86639404296875,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8093101978302002,
      "rewards/margins": 5.225956916809082,
      "rewards/rejected": -4.416646957397461,
      "step": 1885
    },
    {
      "epoch": 0.7544,
      "grad_norm": 3.207197427749634,
      "learning_rate": 7.486666666666666e-07,
      "logits/chosen": -2.8154234886169434,
      "logits/rejected": -2.438481330871582,
      "logps/chosen": -85.48831939697266,
      "logps/rejected": -95.86188507080078,
      "loss": 0.0327,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4352308511734009,
      "rewards/margins": 4.393221855163574,
      "rewards/rejected": -4.828453063964844,
      "step": 1886
    },
    {
      "epoch": 0.7548,
      "grad_norm": 0.48483994603157043,
      "learning_rate": 7.485333333333333e-07,
      "logits/chosen": -2.648552417755127,
      "logits/rejected": -1.9992316961288452,
      "logps/chosen": -102.36080932617188,
      "logps/rejected": -131.18218994140625,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8074241876602173,
      "rewards/margins": 5.852044105529785,
      "rewards/rejected": -5.044619560241699,
      "step": 1887
    },
    {
      "epoch": 0.7552,
      "grad_norm": 0.3632882535457611,
      "learning_rate": 7.483999999999999e-07,
      "logits/chosen": -3.3385777473449707,
      "logits/rejected": -2.4609503746032715,
      "logps/chosen": -66.07954406738281,
      "logps/rejected": -124.38941192626953,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.681113600730896,
      "rewards/margins": 7.174941062927246,
      "rewards/rejected": -6.493826866149902,
      "step": 1888
    },
    {
      "epoch": 0.7556,
      "grad_norm": 0.9294270873069763,
      "learning_rate": 7.482666666666666e-07,
      "logits/chosen": -2.9284164905548096,
      "logits/rejected": -2.430529832839966,
      "logps/chosen": -68.91055297851562,
      "logps/rejected": -96.57758331298828,
      "loss": 0.0128,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3410724699497223,
      "rewards/margins": 4.531031608581543,
      "rewards/rejected": -4.872104167938232,
      "step": 1889
    },
    {
      "epoch": 0.756,
      "grad_norm": 1.8516939878463745,
      "learning_rate": 7.481333333333333e-07,
      "logits/chosen": -2.980705499649048,
      "logits/rejected": -2.8198328018188477,
      "logps/chosen": -80.17784118652344,
      "logps/rejected": -104.79066467285156,
      "loss": 0.0245,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.32695409655570984,
      "rewards/margins": 4.794396877288818,
      "rewards/rejected": -5.1213507652282715,
      "step": 1890
    },
    {
      "epoch": 0.7564,
      "grad_norm": 3.443608283996582,
      "learning_rate": 7.48e-07,
      "logits/chosen": -2.8294260501861572,
      "logits/rejected": -2.359020709991455,
      "logps/chosen": -85.60481262207031,
      "logps/rejected": -115.7843017578125,
      "loss": 0.0484,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24096623063087463,
      "rewards/margins": 5.251184940338135,
      "rewards/rejected": -5.010218620300293,
      "step": 1891
    },
    {
      "epoch": 0.7568,
      "grad_norm": 0.7490553855895996,
      "learning_rate": 7.478666666666667e-07,
      "logits/chosen": -2.824617385864258,
      "logits/rejected": -1.9695284366607666,
      "logps/chosen": -117.2908935546875,
      "logps/rejected": -137.45494079589844,
      "loss": 0.0075,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8611236214637756,
      "rewards/margins": 7.320333957672119,
      "rewards/rejected": -6.459210395812988,
      "step": 1892
    },
    {
      "epoch": 0.7572,
      "grad_norm": 0.659023106098175,
      "learning_rate": 7.477333333333334e-07,
      "logits/chosen": -2.826949119567871,
      "logits/rejected": -2.004138231277466,
      "logps/chosen": -147.78863525390625,
      "logps/rejected": -146.28245544433594,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.49563562870025635,
      "rewards/margins": 6.454763412475586,
      "rewards/rejected": -6.950399398803711,
      "step": 1893
    },
    {
      "epoch": 0.7576,
      "grad_norm": 9.753691673278809,
      "learning_rate": 7.476e-07,
      "logits/chosen": -2.3477439880371094,
      "logits/rejected": -1.780118703842163,
      "logps/chosen": -133.18948364257812,
      "logps/rejected": -154.211181640625,
      "loss": 0.0667,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.425767183303833,
      "rewards/margins": 5.489024639129639,
      "rewards/rejected": -7.914792060852051,
      "step": 1894
    },
    {
      "epoch": 0.758,
      "grad_norm": 0.16400845348834991,
      "learning_rate": 7.474666666666665e-07,
      "logits/chosen": -2.857999324798584,
      "logits/rejected": -2.0695178508758545,
      "logps/chosen": -79.1055679321289,
      "logps/rejected": -137.34738159179688,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9029045104980469,
      "rewards/margins": 7.467432022094727,
      "rewards/rejected": -6.56452751159668,
      "step": 1895
    },
    {
      "epoch": 0.7584,
      "grad_norm": 0.9559773206710815,
      "learning_rate": 7.473333333333332e-07,
      "logits/chosen": -2.700714111328125,
      "logits/rejected": -2.4581809043884277,
      "logps/chosen": -99.01113891601562,
      "logps/rejected": -84.52175903320312,
      "loss": 0.0098,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8513927459716797,
      "rewards/margins": 4.876848220825195,
      "rewards/rejected": -4.025455474853516,
      "step": 1896
    },
    {
      "epoch": 0.7588,
      "grad_norm": 0.5051451325416565,
      "learning_rate": 7.471999999999999e-07,
      "logits/chosen": -2.832444429397583,
      "logits/rejected": -2.4815711975097656,
      "logps/chosen": -91.5927963256836,
      "logps/rejected": -98.06221008300781,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.26323664188385,
      "rewards/margins": 5.683039665222168,
      "rewards/rejected": -4.419802665710449,
      "step": 1897
    },
    {
      "epoch": 0.7592,
      "grad_norm": 1.4601467847824097,
      "learning_rate": 7.470666666666666e-07,
      "logits/chosen": -2.8087756633758545,
      "logits/rejected": -2.302692413330078,
      "logps/chosen": -106.26438903808594,
      "logps/rejected": -121.44857788085938,
      "loss": 0.0088,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3126544952392578,
      "rewards/margins": 6.163434028625488,
      "rewards/rejected": -5.850779056549072,
      "step": 1898
    },
    {
      "epoch": 0.7596,
      "grad_norm": 0.11047262698411942,
      "learning_rate": 7.469333333333333e-07,
      "logits/chosen": -2.6717634201049805,
      "logits/rejected": -2.2341670989990234,
      "logps/chosen": -154.04037475585938,
      "logps/rejected": -165.40338134765625,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5792785286903381,
      "rewards/margins": 6.990406513214111,
      "rewards/rejected": -7.569684982299805,
      "step": 1899
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.1959085911512375,
      "learning_rate": 7.468e-07,
      "logits/chosen": -2.717775344848633,
      "logits/rejected": -1.7799274921417236,
      "logps/chosen": -70.66439056396484,
      "logps/rejected": -156.24166870117188,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8539955615997314,
      "rewards/margins": 7.337569236755371,
      "rewards/rejected": -5.483573913574219,
      "step": 1900
    },
    {
      "epoch": 0.7604,
      "grad_norm": 1.989894986152649,
      "learning_rate": 7.466666666666667e-07,
      "logits/chosen": -3.0717310905456543,
      "logits/rejected": -2.6379241943359375,
      "logps/chosen": -73.05062866210938,
      "logps/rejected": -76.45820617675781,
      "loss": 0.0284,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2547954320907593,
      "rewards/margins": 3.5509305000305176,
      "rewards/rejected": -3.8057258129119873,
      "step": 1901
    },
    {
      "epoch": 0.7608,
      "grad_norm": 0.33624330163002014,
      "learning_rate": 7.465333333333334e-07,
      "logits/chosen": -2.848869800567627,
      "logits/rejected": -2.075829029083252,
      "logps/chosen": -76.73004150390625,
      "logps/rejected": -95.96345520019531,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.151129961013794,
      "rewards/margins": 6.118969917297363,
      "rewards/rejected": -4.967840194702148,
      "step": 1902
    },
    {
      "epoch": 0.7612,
      "grad_norm": 0.05332881584763527,
      "learning_rate": 7.464e-07,
      "logits/chosen": -2.623528480529785,
      "logits/rejected": -1.7182128429412842,
      "logps/chosen": -56.29869842529297,
      "logps/rejected": -155.6565704345703,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8894424438476562,
      "rewards/margins": 8.708341598510742,
      "rewards/rejected": -6.818898677825928,
      "step": 1903
    },
    {
      "epoch": 0.7616,
      "grad_norm": 3.542728900909424,
      "learning_rate": 7.462666666666667e-07,
      "logits/chosen": -2.9135422706604004,
      "logits/rejected": -2.80828857421875,
      "logps/chosen": -95.35003662109375,
      "logps/rejected": -97.42042541503906,
      "loss": 0.0666,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4559769034385681,
      "rewards/margins": 4.359847545623779,
      "rewards/rejected": -4.815824031829834,
      "step": 1904
    },
    {
      "epoch": 0.762,
      "grad_norm": 0.09397579729557037,
      "learning_rate": 7.461333333333332e-07,
      "logits/chosen": -2.7700655460357666,
      "logits/rejected": -1.862671136856079,
      "logps/chosen": -106.72413635253906,
      "logps/rejected": -151.5041961669922,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5738239288330078,
      "rewards/margins": 8.150642395019531,
      "rewards/rejected": -6.576818466186523,
      "step": 1905
    },
    {
      "epoch": 0.7624,
      "grad_norm": 1.9040261507034302,
      "learning_rate": 7.459999999999999e-07,
      "logits/chosen": -2.8701534271240234,
      "logits/rejected": -2.300487518310547,
      "logps/chosen": -76.75428771972656,
      "logps/rejected": -118.27362060546875,
      "loss": 0.0201,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4608457684516907,
      "rewards/margins": 5.844924449920654,
      "rewards/rejected": -6.305769920349121,
      "step": 1906
    },
    {
      "epoch": 0.7628,
      "grad_norm": 0.39440181851387024,
      "learning_rate": 7.458666666666666e-07,
      "logits/chosen": -2.930798292160034,
      "logits/rejected": -2.0745632648468018,
      "logps/chosen": -78.38971710205078,
      "logps/rejected": -170.2989501953125,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3437212705612183,
      "rewards/margins": 8.569175720214844,
      "rewards/rejected": -7.225454330444336,
      "step": 1907
    },
    {
      "epoch": 0.7632,
      "grad_norm": 1.8671499490737915,
      "learning_rate": 7.457333333333333e-07,
      "logits/chosen": -2.8276944160461426,
      "logits/rejected": -2.192845344543457,
      "logps/chosen": -58.810279846191406,
      "logps/rejected": -104.37777709960938,
      "loss": 0.0188,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3113987445831299,
      "rewards/margins": 4.9334564208984375,
      "rewards/rejected": -3.6220576763153076,
      "step": 1908
    },
    {
      "epoch": 0.7636,
      "grad_norm": 1.4234176874160767,
      "learning_rate": 7.456e-07,
      "logits/chosen": -2.8058407306671143,
      "logits/rejected": -2.46942400932312,
      "logps/chosen": -127.21360778808594,
      "logps/rejected": -101.96923828125,
      "loss": 0.0194,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.011816787533462048,
      "rewards/margins": 3.9401187896728516,
      "rewards/rejected": -3.928302049636841,
      "step": 1909
    },
    {
      "epoch": 0.764,
      "grad_norm": 2.9794130325317383,
      "learning_rate": 7.454666666666667e-07,
      "logits/chosen": -2.764324903488159,
      "logits/rejected": -2.168248176574707,
      "logps/chosen": -162.37681579589844,
      "logps/rejected": -148.60739135742188,
      "loss": 0.019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.46895983815193176,
      "rewards/margins": 6.05808162689209,
      "rewards/rejected": -6.527041435241699,
      "step": 1910
    },
    {
      "epoch": 0.7644,
      "grad_norm": 0.5245870351791382,
      "learning_rate": 7.453333333333333e-07,
      "logits/chosen": -2.861785888671875,
      "logits/rejected": -2.031193733215332,
      "logps/chosen": -121.61087799072266,
      "logps/rejected": -149.16224670410156,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5669807195663452,
      "rewards/margins": 6.434782981872559,
      "rewards/rejected": -8.001763343811035,
      "step": 1911
    },
    {
      "epoch": 0.7648,
      "grad_norm": 0.05735071375966072,
      "learning_rate": 7.452e-07,
      "logits/chosen": -2.7525830268859863,
      "logits/rejected": -2.2469260692596436,
      "logps/chosen": -95.11075592041016,
      "logps/rejected": -149.291015625,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7961117029190063,
      "rewards/margins": 7.994368076324463,
      "rewards/rejected": -7.198256492614746,
      "step": 1912
    },
    {
      "epoch": 0.7652,
      "grad_norm": 1.2253390550613403,
      "learning_rate": 7.450666666666667e-07,
      "logits/chosen": -2.8098373413085938,
      "logits/rejected": -2.2164466381073,
      "logps/chosen": -72.0433120727539,
      "logps/rejected": -151.96603393554688,
      "loss": 0.0169,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3646663725376129,
      "rewards/margins": 6.36395263671875,
      "rewards/rejected": -5.99928617477417,
      "step": 1913
    },
    {
      "epoch": 0.7656,
      "grad_norm": 0.38355010747909546,
      "learning_rate": 7.449333333333333e-07,
      "logits/chosen": -2.701878070831299,
      "logits/rejected": -2.03503155708313,
      "logps/chosen": -131.9685821533203,
      "logps/rejected": -126.54022979736328,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13052675127983093,
      "rewards/margins": 6.884469032287598,
      "rewards/rejected": -6.753942012786865,
      "step": 1914
    },
    {
      "epoch": 0.766,
      "grad_norm": 2.7848129272460938,
      "learning_rate": 7.447999999999999e-07,
      "logits/chosen": -2.7440268993377686,
      "logits/rejected": -2.1605019569396973,
      "logps/chosen": -151.24282836914062,
      "logps/rejected": -128.9976806640625,
      "loss": 0.0322,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0431429147720337,
      "rewards/margins": 4.886041641235352,
      "rewards/rejected": -5.929184436798096,
      "step": 1915
    },
    {
      "epoch": 0.7664,
      "grad_norm": 0.6789831519126892,
      "learning_rate": 7.446666666666666e-07,
      "logits/chosen": -2.8423914909362793,
      "logits/rejected": -2.093137264251709,
      "logps/chosen": -72.36943817138672,
      "logps/rejected": -123.85710906982422,
      "loss": 0.0071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3718931674957275,
      "rewards/margins": 5.9727277755737305,
      "rewards/rejected": -4.600834846496582,
      "step": 1916
    },
    {
      "epoch": 0.7668,
      "grad_norm": 0.037692077457904816,
      "learning_rate": 7.445333333333333e-07,
      "logits/chosen": -2.71484112739563,
      "logits/rejected": -2.0280890464782715,
      "logps/chosen": -110.38469696044922,
      "logps/rejected": -187.6990203857422,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0047744810581207275,
      "rewards/margins": 9.061355590820312,
      "rewards/rejected": -9.066129684448242,
      "step": 1917
    },
    {
      "epoch": 0.7672,
      "grad_norm": 2.4919331073760986,
      "learning_rate": 7.443999999999999e-07,
      "logits/chosen": -3.1742286682128906,
      "logits/rejected": -2.536378860473633,
      "logps/chosen": -99.38241577148438,
      "logps/rejected": -117.05905151367188,
      "loss": 0.0246,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6383670568466187,
      "rewards/margins": 4.857895851135254,
      "rewards/rejected": -5.496262550354004,
      "step": 1918
    },
    {
      "epoch": 0.7676,
      "grad_norm": 4.058415412902832,
      "learning_rate": 7.442666666666666e-07,
      "logits/chosen": -2.9207851886749268,
      "logits/rejected": -2.445256233215332,
      "logps/chosen": -111.53257751464844,
      "logps/rejected": -125.03822326660156,
      "loss": 0.0368,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5818376541137695,
      "rewards/margins": 4.5491132736206055,
      "rewards/rejected": -6.130950927734375,
      "step": 1919
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.09414157271385193,
      "learning_rate": 7.441333333333333e-07,
      "logits/chosen": -2.7234902381896973,
      "logits/rejected": -2.1526124477386475,
      "logps/chosen": -59.08933639526367,
      "logps/rejected": -143.7145538330078,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5157907605171204,
      "rewards/margins": 7.3603715896606445,
      "rewards/rejected": -6.84458065032959,
      "step": 1920
    },
    {
      "epoch": 0.7684,
      "grad_norm": 3.7730159759521484,
      "learning_rate": 7.44e-07,
      "logits/chosen": -2.9521570205688477,
      "logits/rejected": -2.479945659637451,
      "logps/chosen": -85.75965118408203,
      "logps/rejected": -87.94355773925781,
      "loss": 0.0257,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3374139666557312,
      "rewards/margins": 4.372457504272461,
      "rewards/rejected": -4.709871292114258,
      "step": 1921
    },
    {
      "epoch": 0.7688,
      "grad_norm": 0.2579449415206909,
      "learning_rate": 7.438666666666667e-07,
      "logits/chosen": -2.711768388748169,
      "logits/rejected": -1.9286422729492188,
      "logps/chosen": -137.0735321044922,
      "logps/rejected": -152.14146423339844,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.26915740966796875,
      "rewards/margins": 6.888055801391602,
      "rewards/rejected": -7.15721321105957,
      "step": 1922
    },
    {
      "epoch": 0.7692,
      "grad_norm": 2.309037208557129,
      "learning_rate": 7.437333333333334e-07,
      "logits/chosen": -2.864515781402588,
      "logits/rejected": -2.142822504043579,
      "logps/chosen": -126.17599487304688,
      "logps/rejected": -92.05796813964844,
      "loss": 0.0289,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.24197998642921448,
      "rewards/margins": 4.257230758666992,
      "rewards/rejected": -4.499210357666016,
      "step": 1923
    },
    {
      "epoch": 0.7696,
      "grad_norm": 0.962823748588562,
      "learning_rate": 7.436e-07,
      "logits/chosen": -3.218491554260254,
      "logits/rejected": -2.7200074195861816,
      "logps/chosen": -106.37538146972656,
      "logps/rejected": -122.25910186767578,
      "loss": 0.0092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10781975090503693,
      "rewards/margins": 4.939111709594727,
      "rewards/rejected": -4.831291675567627,
      "step": 1924
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.144287347793579,
      "learning_rate": 7.434666666666667e-07,
      "logits/chosen": -2.6281538009643555,
      "logits/rejected": -2.446242332458496,
      "logps/chosen": -126.45394897460938,
      "logps/rejected": -142.6824951171875,
      "loss": 0.0193,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3417510986328125,
      "rewards/margins": 6.715193271636963,
      "rewards/rejected": -7.056944370269775,
      "step": 1925
    },
    {
      "epoch": 0.7704,
      "grad_norm": 0.36055147647857666,
      "learning_rate": 7.433333333333332e-07,
      "logits/chosen": -2.999678611755371,
      "logits/rejected": -2.198509454727173,
      "logps/chosen": -73.47941589355469,
      "logps/rejected": -104.09940338134766,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7301217913627625,
      "rewards/margins": 5.673815727233887,
      "rewards/rejected": -4.943694114685059,
      "step": 1926
    },
    {
      "epoch": 0.7708,
      "grad_norm": 0.3345291018486023,
      "learning_rate": 7.431999999999999e-07,
      "logits/chosen": -2.972553253173828,
      "logits/rejected": -2.653346538543701,
      "logps/chosen": -80.95570373535156,
      "logps/rejected": -143.49745178222656,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5713769793510437,
      "rewards/margins": 6.504659652709961,
      "rewards/rejected": -7.07603645324707,
      "step": 1927
    },
    {
      "epoch": 0.7712,
      "grad_norm": 0.23362143337726593,
      "learning_rate": 7.430666666666666e-07,
      "logits/chosen": -2.9614081382751465,
      "logits/rejected": -2.658936023712158,
      "logps/chosen": -109.77488708496094,
      "logps/rejected": -135.65335083007812,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0020551681518554688,
      "rewards/margins": 6.156607627868652,
      "rewards/rejected": -6.154552459716797,
      "step": 1928
    },
    {
      "epoch": 0.7716,
      "grad_norm": 8.683048248291016,
      "learning_rate": 7.429333333333333e-07,
      "logits/chosen": -2.858549118041992,
      "logits/rejected": -2.713657855987549,
      "logps/chosen": -173.18951416015625,
      "logps/rejected": -102.32115936279297,
      "loss": 0.053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0584663152694702,
      "rewards/margins": 5.008903503417969,
      "rewards/rejected": -6.0673699378967285,
      "step": 1929
    },
    {
      "epoch": 0.772,
      "grad_norm": 1.9934905767440796,
      "learning_rate": 7.428e-07,
      "logits/chosen": -3.028202533721924,
      "logits/rejected": -2.686403274536133,
      "logps/chosen": -95.4560775756836,
      "logps/rejected": -99.75518798828125,
      "loss": 0.0194,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7832203507423401,
      "rewards/margins": 4.082541465759277,
      "rewards/rejected": -4.865761756896973,
      "step": 1930
    },
    {
      "epoch": 0.7724,
      "grad_norm": 0.08177298307418823,
      "learning_rate": 7.426666666666667e-07,
      "logits/chosen": -3.112318515777588,
      "logits/rejected": -2.440296173095703,
      "logps/chosen": -102.0202865600586,
      "logps/rejected": -152.78591918945312,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2238822877407074,
      "rewards/margins": 7.8544769287109375,
      "rewards/rejected": -7.6305952072143555,
      "step": 1931
    },
    {
      "epoch": 0.7728,
      "grad_norm": 7.7548089027404785,
      "learning_rate": 7.425333333333334e-07,
      "logits/chosen": -2.780709981918335,
      "logits/rejected": -2.7140955924987793,
      "logps/chosen": -104.99618530273438,
      "logps/rejected": -88.53484344482422,
      "loss": 0.1024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.001197099685669,
      "rewards/margins": 2.2727160453796387,
      "rewards/rejected": -4.273913383483887,
      "step": 1932
    },
    {
      "epoch": 0.7732,
      "grad_norm": 0.1252613216638565,
      "learning_rate": 7.423999999999999e-07,
      "logits/chosen": -2.5265727043151855,
      "logits/rejected": -1.6021034717559814,
      "logps/chosen": -160.9100341796875,
      "logps/rejected": -154.871826171875,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.26306915283203125,
      "rewards/margins": 7.753371238708496,
      "rewards/rejected": -7.490302085876465,
      "step": 1933
    },
    {
      "epoch": 0.7736,
      "grad_norm": 0.42820537090301514,
      "learning_rate": 7.422666666666666e-07,
      "logits/chosen": -2.986527681350708,
      "logits/rejected": -2.5789966583251953,
      "logps/chosen": -79.3419418334961,
      "logps/rejected": -132.8821258544922,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8416372537612915,
      "rewards/margins": 5.615220546722412,
      "rewards/rejected": -6.456857681274414,
      "step": 1934
    },
    {
      "epoch": 0.774,
      "grad_norm": 0.737997829914093,
      "learning_rate": 7.421333333333333e-07,
      "logits/chosen": -2.8892579078674316,
      "logits/rejected": -2.0158329010009766,
      "logps/chosen": -109.5111083984375,
      "logps/rejected": -94.81822204589844,
      "loss": 0.0067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1433231383562088,
      "rewards/margins": 5.009563446044922,
      "rewards/rejected": -4.86624002456665,
      "step": 1935
    },
    {
      "epoch": 0.7744,
      "grad_norm": 2.104412078857422,
      "learning_rate": 7.42e-07,
      "logits/chosen": -2.9092845916748047,
      "logits/rejected": -2.2976644039154053,
      "logps/chosen": -114.49571228027344,
      "logps/rejected": -100.6001968383789,
      "loss": 0.0197,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0376605987548828,
      "rewards/margins": 3.975792407989502,
      "rewards/rejected": -5.013453006744385,
      "step": 1936
    },
    {
      "epoch": 0.7748,
      "grad_norm": 0.5490756034851074,
      "learning_rate": 7.418666666666666e-07,
      "logits/chosen": -2.7988829612731934,
      "logits/rejected": -2.3179099559783936,
      "logps/chosen": -92.4013671875,
      "logps/rejected": -140.86988830566406,
      "loss": 0.0059,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2482471466064453,
      "rewards/margins": 6.425467491149902,
      "rewards/rejected": -6.673714637756348,
      "step": 1937
    },
    {
      "epoch": 0.7752,
      "grad_norm": 0.47238558530807495,
      "learning_rate": 7.417333333333333e-07,
      "logits/chosen": -3.0731215476989746,
      "logits/rejected": -2.1784911155700684,
      "logps/chosen": -122.86788177490234,
      "logps/rejected": -127.9803237915039,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1277015656232834,
      "rewards/margins": 6.36414098739624,
      "rewards/rejected": -6.491842269897461,
      "step": 1938
    },
    {
      "epoch": 0.7756,
      "grad_norm": 0.1464247852563858,
      "learning_rate": 7.416e-07,
      "logits/chosen": -3.122464418411255,
      "logits/rejected": -2.4105825424194336,
      "logps/chosen": -57.139259338378906,
      "logps/rejected": -107.89544677734375,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.155843734741211,
      "rewards/margins": 6.523954391479492,
      "rewards/rejected": -5.368110656738281,
      "step": 1939
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.7969639897346497,
      "learning_rate": 7.414666666666667e-07,
      "logits/chosen": -3.113313674926758,
      "logits/rejected": -2.470745325088501,
      "logps/chosen": -67.2762680053711,
      "logps/rejected": -126.98869323730469,
      "loss": 0.0083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.261190176010132,
      "rewards/margins": 7.17783260345459,
      "rewards/rejected": -4.916642189025879,
      "step": 1940
    },
    {
      "epoch": 0.7764,
      "grad_norm": 0.7983248233795166,
      "learning_rate": 7.413333333333333e-07,
      "logits/chosen": -3.0758562088012695,
      "logits/rejected": -2.5541467666625977,
      "logps/chosen": -98.42030334472656,
      "logps/rejected": -119.08008575439453,
      "loss": 0.0052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.20648612082004547,
      "rewards/margins": 6.184257507324219,
      "rewards/rejected": -6.390743732452393,
      "step": 1941
    },
    {
      "epoch": 0.7768,
      "grad_norm": 2.9024569988250732,
      "learning_rate": 7.411999999999999e-07,
      "logits/chosen": -3.2316057682037354,
      "logits/rejected": -2.5785961151123047,
      "logps/chosen": -110.57296752929688,
      "logps/rejected": -162.5009765625,
      "loss": 0.0206,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4591964483261108,
      "rewards/margins": 7.756379127502441,
      "rewards/rejected": -6.297183036804199,
      "step": 1942
    },
    {
      "epoch": 0.7772,
      "grad_norm": 8.320740699768066,
      "learning_rate": 7.410666666666666e-07,
      "logits/chosen": -2.550560474395752,
      "logits/rejected": -2.211569309234619,
      "logps/chosen": -143.147216796875,
      "logps/rejected": -78.16474151611328,
      "loss": 0.0551,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6692100763320923,
      "rewards/margins": 3.3405885696411133,
      "rewards/rejected": -4.009798526763916,
      "step": 1943
    },
    {
      "epoch": 0.7776,
      "grad_norm": 7.576396942138672,
      "learning_rate": 7.409333333333333e-07,
      "logits/chosen": -2.6455459594726562,
      "logits/rejected": -2.173680067062378,
      "logps/chosen": -144.60052490234375,
      "logps/rejected": -97.75352478027344,
      "loss": 0.0794,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.165869116783142,
      "rewards/margins": 2.8477253913879395,
      "rewards/rejected": -4.013594627380371,
      "step": 1944
    },
    {
      "epoch": 0.778,
      "grad_norm": 0.0608968548476696,
      "learning_rate": 7.408e-07,
      "logits/chosen": -2.9244251251220703,
      "logits/rejected": -2.157485246658325,
      "logps/chosen": -70.65767669677734,
      "logps/rejected": -120.20868682861328,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8315019607543945,
      "rewards/margins": 7.892910957336426,
      "rewards/rejected": -7.0614094734191895,
      "step": 1945
    },
    {
      "epoch": 0.7784,
      "grad_norm": 1.858343482017517,
      "learning_rate": 7.406666666666667e-07,
      "logits/chosen": -2.945925235748291,
      "logits/rejected": -2.476041316986084,
      "logps/chosen": -101.19570922851562,
      "logps/rejected": -97.152099609375,
      "loss": 0.0258,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2498959302902222,
      "rewards/margins": 3.9406065940856934,
      "rewards/rejected": -5.190502166748047,
      "step": 1946
    },
    {
      "epoch": 0.7788,
      "grad_norm": 0.1963796317577362,
      "learning_rate": 7.405333333333333e-07,
      "logits/chosen": -2.791459321975708,
      "logits/rejected": -2.1349239349365234,
      "logps/chosen": -137.31387329101562,
      "logps/rejected": -100.4708251953125,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1272780895233154,
      "rewards/margins": 6.68172550201416,
      "rewards/rejected": -5.554447174072266,
      "step": 1947
    },
    {
      "epoch": 0.7792,
      "grad_norm": 3.673015594482422,
      "learning_rate": 7.403999999999999e-07,
      "logits/chosen": -2.7533891201019287,
      "logits/rejected": -2.2856855392456055,
      "logps/chosen": -119.71637725830078,
      "logps/rejected": -128.14901733398438,
      "loss": 0.0423,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.12160375714302063,
      "rewards/margins": 6.540962219238281,
      "rewards/rejected": -6.6625657081604,
      "step": 1948
    },
    {
      "epoch": 0.7796,
      "grad_norm": 0.1446959227323532,
      "learning_rate": 7.402666666666666e-07,
      "logits/chosen": -3.2812013626098633,
      "logits/rejected": -2.6946158409118652,
      "logps/chosen": -54.01138687133789,
      "logps/rejected": -130.33114624023438,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2619169354438782,
      "rewards/margins": 7.116297245025635,
      "rewards/rejected": -6.854380130767822,
      "step": 1949
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.023602530360221863,
      "learning_rate": 7.401333333333333e-07,
      "logits/chosen": -2.540806293487549,
      "logits/rejected": -1.8613660335540771,
      "logps/chosen": -73.56944274902344,
      "logps/rejected": -155.46780395507812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.320786714553833,
      "rewards/margins": 9.220916748046875,
      "rewards/rejected": -7.900130271911621,
      "step": 1950
    },
    {
      "epoch": 0.7804,
      "grad_norm": 3.2760543823242188,
      "learning_rate": 7.4e-07,
      "logits/chosen": -2.912229299545288,
      "logits/rejected": -2.596010208129883,
      "logps/chosen": -111.34214782714844,
      "logps/rejected": -86.42816162109375,
      "loss": 0.0399,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0319637060165405,
      "rewards/margins": 3.308396816253662,
      "rewards/rejected": -4.340360641479492,
      "step": 1951
    },
    {
      "epoch": 0.7808,
      "grad_norm": 1.887679100036621,
      "learning_rate": 7.398666666666666e-07,
      "logits/chosen": -2.913851737976074,
      "logits/rejected": -2.2742366790771484,
      "logps/chosen": -79.4942626953125,
      "logps/rejected": -85.14891815185547,
      "loss": 0.0244,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7747993469238281,
      "rewards/margins": 4.83272123336792,
      "rewards/rejected": -4.057921886444092,
      "step": 1952
    },
    {
      "epoch": 0.7812,
      "grad_norm": 0.5202323794364929,
      "learning_rate": 7.397333333333333e-07,
      "logits/chosen": -2.8100733757019043,
      "logits/rejected": -2.1252360343933105,
      "logps/chosen": -99.19691467285156,
      "logps/rejected": -117.79205322265625,
      "loss": 0.0062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9893516302108765,
      "rewards/margins": 5.560822486877441,
      "rewards/rejected": -4.571470737457275,
      "step": 1953
    },
    {
      "epoch": 0.7816,
      "grad_norm": 5.185708999633789,
      "learning_rate": 7.396e-07,
      "logits/chosen": -2.9560017585754395,
      "logits/rejected": -2.8877859115600586,
      "logps/chosen": -95.69348907470703,
      "logps/rejected": -66.11959838867188,
      "loss": 0.0756,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5181423425674438,
      "rewards/margins": 2.5489258766174316,
      "rewards/rejected": -3.067068099975586,
      "step": 1954
    },
    {
      "epoch": 0.782,
      "grad_norm": 3.87165904045105,
      "learning_rate": 7.394666666666667e-07,
      "logits/chosen": -2.7863869667053223,
      "logits/rejected": -2.2719528675079346,
      "logps/chosen": -64.97618103027344,
      "logps/rejected": -134.39483642578125,
      "loss": 0.0417,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5854215621948242,
      "rewards/margins": 5.937705993652344,
      "rewards/rejected": -6.523128032684326,
      "step": 1955
    },
    {
      "epoch": 0.7824,
      "grad_norm": 1.9467195272445679,
      "learning_rate": 7.393333333333333e-07,
      "logits/chosen": -2.618176221847534,
      "logits/rejected": -2.0836832523345947,
      "logps/chosen": -177.1773223876953,
      "logps/rejected": -129.98193359375,
      "loss": 0.011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7902858257293701,
      "rewards/margins": 5.109009265899658,
      "rewards/rejected": -5.899295330047607,
      "step": 1956
    },
    {
      "epoch": 0.7828,
      "grad_norm": 8.312684059143066,
      "learning_rate": 7.392e-07,
      "logits/chosen": -2.995615243911743,
      "logits/rejected": -2.9830360412597656,
      "logps/chosen": -74.60955810546875,
      "logps/rejected": -81.94920349121094,
      "loss": 0.1468,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8724559545516968,
      "rewards/margins": 2.628561496734619,
      "rewards/rejected": -3.5010175704956055,
      "step": 1957
    },
    {
      "epoch": 0.7832,
      "grad_norm": 3.1912055015563965,
      "learning_rate": 7.390666666666666e-07,
      "logits/chosen": -2.984440803527832,
      "logits/rejected": -2.3089213371276855,
      "logps/chosen": -47.343502044677734,
      "logps/rejected": -87.84764099121094,
      "loss": 0.0418,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4778604507446289,
      "rewards/margins": 5.874056816101074,
      "rewards/rejected": -5.396196365356445,
      "step": 1958
    },
    {
      "epoch": 0.7836,
      "grad_norm": 0.21728602051734924,
      "learning_rate": 7.389333333333333e-07,
      "logits/chosen": -2.8606600761413574,
      "logits/rejected": -2.008373260498047,
      "logps/chosen": -124.54230499267578,
      "logps/rejected": -122.53517150878906,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6100037097930908,
      "rewards/margins": 7.247374534606934,
      "rewards/rejected": -6.637371063232422,
      "step": 1959
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.17223644256591797,
      "learning_rate": 7.388e-07,
      "logits/chosen": -3.005117416381836,
      "logits/rejected": -2.5162851810455322,
      "logps/chosen": -83.32908630371094,
      "logps/rejected": -162.27220153808594,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.860639214515686,
      "rewards/margins": 6.6838579177856445,
      "rewards/rejected": -7.544497013092041,
      "step": 1960
    },
    {
      "epoch": 0.7844,
      "grad_norm": 0.39678406715393066,
      "learning_rate": 7.386666666666666e-07,
      "logits/chosen": -3.075321674346924,
      "logits/rejected": -2.4963674545288086,
      "logps/chosen": -84.74853515625,
      "logps/rejected": -162.37637329101562,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08893108367919922,
      "rewards/margins": 8.152565956115723,
      "rewards/rejected": -8.241497039794922,
      "step": 1961
    },
    {
      "epoch": 0.7848,
      "grad_norm": 1.248579740524292,
      "learning_rate": 7.385333333333333e-07,
      "logits/chosen": -2.777773141860962,
      "logits/rejected": -2.394636869430542,
      "logps/chosen": -160.891357421875,
      "logps/rejected": -99.94047546386719,
      "loss": 0.0118,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7070019245147705,
      "rewards/margins": 4.440924644470215,
      "rewards/rejected": -5.1479268074035645,
      "step": 1962
    },
    {
      "epoch": 0.7852,
      "grad_norm": 0.23599563539028168,
      "learning_rate": 7.383999999999999e-07,
      "logits/chosen": -3.2469711303710938,
      "logits/rejected": -3.005943775177002,
      "logps/chosen": -94.56120300292969,
      "logps/rejected": -113.92379760742188,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.057046890258789,
      "rewards/margins": 6.177652359008789,
      "rewards/rejected": -5.12060546875,
      "step": 1963
    },
    {
      "epoch": 0.7856,
      "grad_norm": 0.46037185192108154,
      "learning_rate": 7.382666666666666e-07,
      "logits/chosen": -2.684548854827881,
      "logits/rejected": -2.1529393196105957,
      "logps/chosen": -102.27369689941406,
      "logps/rejected": -91.30599212646484,
      "loss": 0.0052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1652969121932983,
      "rewards/margins": 5.289200305938721,
      "rewards/rejected": -4.123903274536133,
      "step": 1964
    },
    {
      "epoch": 0.786,
      "grad_norm": 0.07356233149766922,
      "learning_rate": 7.381333333333333e-07,
      "logits/chosen": -2.7412333488464355,
      "logits/rejected": -1.7588649988174438,
      "logps/chosen": -57.556007385253906,
      "logps/rejected": -182.52459716796875,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3843359053134918,
      "rewards/margins": 9.6630277633667,
      "rewards/rejected": -9.278692245483398,
      "step": 1965
    },
    {
      "epoch": 0.7864,
      "grad_norm": 2.23249888420105,
      "learning_rate": 7.38e-07,
      "logits/chosen": -2.828780174255371,
      "logits/rejected": -2.2773890495300293,
      "logps/chosen": -123.6479263305664,
      "logps/rejected": -84.76229858398438,
      "loss": 0.0276,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8341836929321289,
      "rewards/margins": 3.9077517986297607,
      "rewards/rejected": -4.741935729980469,
      "step": 1966
    },
    {
      "epoch": 0.7868,
      "grad_norm": 0.15434877574443817,
      "learning_rate": 7.378666666666667e-07,
      "logits/chosen": -2.4894297122955322,
      "logits/rejected": -1.754077672958374,
      "logps/chosen": -79.48873138427734,
      "logps/rejected": -138.36367797851562,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7156015634536743,
      "rewards/margins": 6.993323802947998,
      "rewards/rejected": -6.277722358703613,
      "step": 1967
    },
    {
      "epoch": 0.7872,
      "grad_norm": 0.9428511261940002,
      "learning_rate": 7.377333333333333e-07,
      "logits/chosen": -2.9643375873565674,
      "logits/rejected": -2.493290901184082,
      "logps/chosen": -77.15909576416016,
      "logps/rejected": -89.81253051757812,
      "loss": 0.0118,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.228355050086975,
      "rewards/margins": 5.458372116088867,
      "rewards/rejected": -4.230017185211182,
      "step": 1968
    },
    {
      "epoch": 0.7876,
      "grad_norm": 0.4179547429084778,
      "learning_rate": 7.376e-07,
      "logits/chosen": -3.0480728149414062,
      "logits/rejected": -2.627026081085205,
      "logps/chosen": -74.69015502929688,
      "logps/rejected": -108.01591491699219,
      "loss": 0.0048,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.237100601196289,
      "rewards/margins": 6.153957843780518,
      "rewards/rejected": -4.9168572425842285,
      "step": 1969
    },
    {
      "epoch": 0.788,
      "grad_norm": 0.32651233673095703,
      "learning_rate": 7.374666666666667e-07,
      "logits/chosen": -3.129422187805176,
      "logits/rejected": -2.825192928314209,
      "logps/chosen": -65.59049987792969,
      "logps/rejected": -102.59208679199219,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9532566070556641,
      "rewards/margins": 6.304092884063721,
      "rewards/rejected": -5.350836277008057,
      "step": 1970
    },
    {
      "epoch": 0.7884,
      "grad_norm": 0.09482751041650772,
      "learning_rate": 7.373333333333332e-07,
      "logits/chosen": -2.7907004356384277,
      "logits/rejected": -2.383505344390869,
      "logps/chosen": -115.68132019042969,
      "logps/rejected": -101.79692840576172,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9278175234794617,
      "rewards/margins": 7.0187225341796875,
      "rewards/rejected": -6.090904712677002,
      "step": 1971
    },
    {
      "epoch": 0.7888,
      "grad_norm": 0.028906695544719696,
      "learning_rate": 7.371999999999999e-07,
      "logits/chosen": -2.5878710746765137,
      "logits/rejected": -1.6897087097167969,
      "logps/chosen": -101.62969970703125,
      "logps/rejected": -132.00753784179688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5543358325958252,
      "rewards/margins": 8.745293617248535,
      "rewards/rejected": -7.190958023071289,
      "step": 1972
    },
    {
      "epoch": 0.7892,
      "grad_norm": 2.038337469100952,
      "learning_rate": 7.370666666666666e-07,
      "logits/chosen": -3.120480537414551,
      "logits/rejected": -2.9323439598083496,
      "logps/chosen": -58.58856201171875,
      "logps/rejected": -79.82618713378906,
      "loss": 0.0324,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33174458146095276,
      "rewards/margins": 3.838956117630005,
      "rewards/rejected": -3.507211685180664,
      "step": 1973
    },
    {
      "epoch": 0.7896,
      "grad_norm": 2.767441749572754,
      "learning_rate": 7.369333333333333e-07,
      "logits/chosen": -2.882089853286743,
      "logits/rejected": -2.8464195728302,
      "logps/chosen": -130.41720581054688,
      "logps/rejected": -106.91048431396484,
      "loss": 0.0302,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06708794087171555,
      "rewards/margins": 5.258581161499023,
      "rewards/rejected": -5.191493034362793,
      "step": 1974
    },
    {
      "epoch": 0.79,
      "grad_norm": 7.087027072906494,
      "learning_rate": 7.368e-07,
      "logits/chosen": -2.825295925140381,
      "logits/rejected": -2.208909749984741,
      "logps/chosen": -99.86796569824219,
      "logps/rejected": -119.77067565917969,
      "loss": 0.0322,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4487873315811157,
      "rewards/margins": 3.7902708053588867,
      "rewards/rejected": -5.239058017730713,
      "step": 1975
    },
    {
      "epoch": 0.7904,
      "grad_norm": 5.250551223754883,
      "learning_rate": 7.366666666666667e-07,
      "logits/chosen": -3.1516618728637695,
      "logits/rejected": -3.0457208156585693,
      "logps/chosen": -68.463623046875,
      "logps/rejected": -68.91130065917969,
      "loss": 0.0899,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7681694030761719,
      "rewards/margins": 2.377878427505493,
      "rewards/rejected": -3.146047830581665,
      "step": 1976
    },
    {
      "epoch": 0.7908,
      "grad_norm": 0.7720400094985962,
      "learning_rate": 7.365333333333334e-07,
      "logits/chosen": -2.722097396850586,
      "logits/rejected": -2.1156158447265625,
      "logps/chosen": -162.48460388183594,
      "logps/rejected": -139.09274291992188,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.722419798374176,
      "rewards/margins": 5.50419807434082,
      "rewards/rejected": -6.226617813110352,
      "step": 1977
    },
    {
      "epoch": 0.7912,
      "grad_norm": 43.26327896118164,
      "learning_rate": 7.364000000000001e-07,
      "logits/chosen": -2.668941020965576,
      "logits/rejected": -2.3996949195861816,
      "logps/chosen": -120.02001953125,
      "logps/rejected": -142.60409545898438,
      "loss": 0.4935,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -3.5429489612579346,
      "rewards/margins": 4.252172470092773,
      "rewards/rejected": -7.795121192932129,
      "step": 1978
    },
    {
      "epoch": 0.7916,
      "grad_norm": 0.13392072916030884,
      "learning_rate": 7.362666666666666e-07,
      "logits/chosen": -2.7753634452819824,
      "logits/rejected": -2.1981592178344727,
      "logps/chosen": -200.06642150878906,
      "logps/rejected": -140.0050811767578,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5132736563682556,
      "rewards/margins": 6.794210433959961,
      "rewards/rejected": -6.280937194824219,
      "step": 1979
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.7413732409477234,
      "learning_rate": 7.361333333333332e-07,
      "logits/chosen": -3.183779716491699,
      "logits/rejected": -2.6863324642181396,
      "logps/chosen": -52.575748443603516,
      "logps/rejected": -95.5553970336914,
      "loss": 0.0084,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2545374035835266,
      "rewards/margins": 4.891244888305664,
      "rewards/rejected": -4.636707782745361,
      "step": 1980
    },
    {
      "epoch": 0.7924,
      "grad_norm": 3.3363454341888428,
      "learning_rate": 7.359999999999999e-07,
      "logits/chosen": -2.554611921310425,
      "logits/rejected": -2.33793568611145,
      "logps/chosen": -149.84498596191406,
      "logps/rejected": -125.12100219726562,
      "loss": 0.0282,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5755054354667664,
      "rewards/margins": 4.831169128417969,
      "rewards/rejected": -4.2556633949279785,
      "step": 1981
    },
    {
      "epoch": 0.7928,
      "grad_norm": 0.5025808811187744,
      "learning_rate": 7.358666666666666e-07,
      "logits/chosen": -3.2005786895751953,
      "logits/rejected": -2.7074646949768066,
      "logps/chosen": -81.95792388916016,
      "logps/rejected": -122.21815490722656,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.158606767654419,
      "rewards/margins": 5.418704986572266,
      "rewards/rejected": -6.577311992645264,
      "step": 1982
    },
    {
      "epoch": 0.7932,
      "grad_norm": 0.4614008963108063,
      "learning_rate": 7.357333333333333e-07,
      "logits/chosen": -2.6637494564056396,
      "logits/rejected": -1.7584953308105469,
      "logps/chosen": -137.1155548095703,
      "logps/rejected": -160.5370635986328,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.029603183269500732,
      "rewards/margins": 7.191132545471191,
      "rewards/rejected": -7.220735549926758,
      "step": 1983
    },
    {
      "epoch": 0.7936,
      "grad_norm": 1.6690177917480469,
      "learning_rate": 7.356e-07,
      "logits/chosen": -2.6845040321350098,
      "logits/rejected": -2.498950958251953,
      "logps/chosen": -114.34390258789062,
      "logps/rejected": -94.61161804199219,
      "loss": 0.0203,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6735162734985352,
      "rewards/margins": 4.690581321716309,
      "rewards/rejected": -4.017065048217773,
      "step": 1984
    },
    {
      "epoch": 0.794,
      "grad_norm": 0.7173536419868469,
      "learning_rate": 7.354666666666667e-07,
      "logits/chosen": -2.802633285522461,
      "logits/rejected": -2.014812707901001,
      "logps/chosen": -144.35284423828125,
      "logps/rejected": -105.64048767089844,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08386383950710297,
      "rewards/margins": 5.732914924621582,
      "rewards/rejected": -5.816778659820557,
      "step": 1985
    },
    {
      "epoch": 0.7944,
      "grad_norm": 3.243649959564209,
      "learning_rate": 7.353333333333333e-07,
      "logits/chosen": -2.997318744659424,
      "logits/rejected": -2.7241992950439453,
      "logps/chosen": -87.2152099609375,
      "logps/rejected": -76.33663177490234,
      "loss": 0.0316,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.06937713176012039,
      "rewards/margins": 3.486570358276367,
      "rewards/rejected": -3.5559475421905518,
      "step": 1986
    },
    {
      "epoch": 0.7948,
      "grad_norm": 0.09432040899991989,
      "learning_rate": 7.352e-07,
      "logits/chosen": -2.8753163814544678,
      "logits/rejected": -2.0811514854431152,
      "logps/chosen": -59.49180603027344,
      "logps/rejected": -121.57839965820312,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7216876745223999,
      "rewards/margins": 7.297271251678467,
      "rewards/rejected": -6.575583457946777,
      "step": 1987
    },
    {
      "epoch": 0.7952,
      "grad_norm": 2.52075457572937,
      "learning_rate": 7.350666666666667e-07,
      "logits/chosen": -2.983023166656494,
      "logits/rejected": -2.706118583679199,
      "logps/chosen": -70.4376220703125,
      "logps/rejected": -86.08394622802734,
      "loss": 0.0328,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4002678096294403,
      "rewards/margins": 4.408939361572266,
      "rewards/rejected": -4.008671760559082,
      "step": 1988
    },
    {
      "epoch": 0.7956,
      "grad_norm": 1.1713054180145264,
      "learning_rate": 7.349333333333332e-07,
      "logits/chosen": -3.1414504051208496,
      "logits/rejected": -2.766709566116333,
      "logps/chosen": -80.76313018798828,
      "logps/rejected": -103.19673919677734,
      "loss": 0.0148,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4838005006313324,
      "rewards/margins": 4.3562798500061035,
      "rewards/rejected": -4.840080261230469,
      "step": 1989
    },
    {
      "epoch": 0.796,
      "grad_norm": 6.033890247344971,
      "learning_rate": 7.347999999999999e-07,
      "logits/chosen": -2.889958381652832,
      "logits/rejected": -2.2969250679016113,
      "logps/chosen": -98.85065460205078,
      "logps/rejected": -122.77326965332031,
      "loss": 0.0493,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3373782634735107,
      "rewards/margins": 4.4966535568237305,
      "rewards/rejected": -5.83403205871582,
      "step": 1990
    },
    {
      "epoch": 0.7964,
      "grad_norm": 1.1268701553344727,
      "learning_rate": 7.346666666666666e-07,
      "logits/chosen": -2.6409449577331543,
      "logits/rejected": -2.0955159664154053,
      "logps/chosen": -109.97801208496094,
      "logps/rejected": -129.12030029296875,
      "loss": 0.0148,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8894279599189758,
      "rewards/margins": 6.2776665687561035,
      "rewards/rejected": -5.388238430023193,
      "step": 1991
    },
    {
      "epoch": 0.7968,
      "grad_norm": 0.10443998873233795,
      "learning_rate": 7.345333333333333e-07,
      "logits/chosen": -2.8575968742370605,
      "logits/rejected": -2.2442405223846436,
      "logps/chosen": -90.36438751220703,
      "logps/rejected": -132.7814178466797,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3813786506652832,
      "rewards/margins": 7.929141998291016,
      "rewards/rejected": -6.547763824462891,
      "step": 1992
    },
    {
      "epoch": 0.7972,
      "grad_norm": 0.3651483952999115,
      "learning_rate": 7.344e-07,
      "logits/chosen": -2.920010805130005,
      "logits/rejected": -2.6891062259674072,
      "logps/chosen": -120.29447174072266,
      "logps/rejected": -122.72047424316406,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.110266089439392,
      "rewards/margins": 5.829249382019043,
      "rewards/rejected": -6.939516067504883,
      "step": 1993
    },
    {
      "epoch": 0.7976,
      "grad_norm": 0.5349839925765991,
      "learning_rate": 7.342666666666666e-07,
      "logits/chosen": -2.9687387943267822,
      "logits/rejected": -2.4031319618225098,
      "logps/chosen": -131.21920776367188,
      "logps/rejected": -196.03977966308594,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5540965795516968,
      "rewards/margins": 10.267138481140137,
      "rewards/rejected": -9.713042259216309,
      "step": 1994
    },
    {
      "epoch": 0.798,
      "grad_norm": 84.07838439941406,
      "learning_rate": 7.341333333333333e-07,
      "logits/chosen": -2.3893637657165527,
      "logits/rejected": -2.130521774291992,
      "logps/chosen": -214.82891845703125,
      "logps/rejected": -208.3998260498047,
      "loss": 0.9336,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -3.4638216495513916,
      "rewards/margins": 4.503632545471191,
      "rewards/rejected": -7.967453956604004,
      "step": 1995
    },
    {
      "epoch": 0.7984,
      "grad_norm": 3.209073305130005,
      "learning_rate": 7.34e-07,
      "logits/chosen": -3.112558126449585,
      "logits/rejected": -2.522902488708496,
      "logps/chosen": -93.5709228515625,
      "logps/rejected": -118.38629913330078,
      "loss": 0.0279,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7752647399902344,
      "rewards/margins": 4.455408096313477,
      "rewards/rejected": -5.230672836303711,
      "step": 1996
    },
    {
      "epoch": 0.7988,
      "grad_norm": 2.3026492595672607,
      "learning_rate": 7.338666666666667e-07,
      "logits/chosen": -3.027191162109375,
      "logits/rejected": -2.9714958667755127,
      "logps/chosen": -119.33819580078125,
      "logps/rejected": -89.06558227539062,
      "loss": 0.0243,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7367454171180725,
      "rewards/margins": 3.713223457336426,
      "rewards/rejected": -2.976478099822998,
      "step": 1997
    },
    {
      "epoch": 0.7992,
      "grad_norm": 1.5475056171417236,
      "learning_rate": 7.337333333333334e-07,
      "logits/chosen": -3.0831985473632812,
      "logits/rejected": -2.6385927200317383,
      "logps/chosen": -71.66596984863281,
      "logps/rejected": -97.09867858886719,
      "loss": 0.0136,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5347858667373657,
      "rewards/margins": 5.345149993896484,
      "rewards/rejected": -4.81036376953125,
      "step": 1998
    },
    {
      "epoch": 0.7996,
      "grad_norm": 3.0395150184631348,
      "learning_rate": 7.336e-07,
      "logits/chosen": -2.878561019897461,
      "logits/rejected": -2.7032742500305176,
      "logps/chosen": -69.82856750488281,
      "logps/rejected": -69.85238647460938,
      "loss": 0.0341,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3145761489868164,
      "rewards/margins": 3.776712656021118,
      "rewards/rejected": -4.0912885665893555,
      "step": 1999
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.4038524627685547,
      "learning_rate": 7.334666666666666e-07,
      "logits/chosen": -2.9512100219726562,
      "logits/rejected": -2.233591318130493,
      "logps/chosen": -82.20758056640625,
      "logps/rejected": -117.6666488647461,
      "loss": 0.0318,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8490051031112671,
      "rewards/margins": 6.031644821166992,
      "rewards/rejected": -5.1826395988464355,
      "step": 2000
    },
    {
      "epoch": 0.8004,
      "grad_norm": 2.764410972595215,
      "learning_rate": 7.333333333333332e-07,
      "logits/chosen": -3.0338940620422363,
      "logits/rejected": -2.3968887329101562,
      "logps/chosen": -72.23030853271484,
      "logps/rejected": -92.90660858154297,
      "loss": 0.0312,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5566999912261963,
      "rewards/margins": 4.276490211486816,
      "rewards/rejected": -4.833190441131592,
      "step": 2001
    },
    {
      "epoch": 0.8008,
      "grad_norm": 0.3449881672859192,
      "learning_rate": 7.331999999999999e-07,
      "logits/chosen": -3.015291929244995,
      "logits/rejected": -2.5111355781555176,
      "logps/chosen": -62.6307373046875,
      "logps/rejected": -106.19007873535156,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4005873203277588,
      "rewards/margins": 7.052959442138672,
      "rewards/rejected": -5.652372360229492,
      "step": 2002
    },
    {
      "epoch": 0.8012,
      "grad_norm": 0.26621752977371216,
      "learning_rate": 7.330666666666666e-07,
      "logits/chosen": -2.580489158630371,
      "logits/rejected": -1.951317310333252,
      "logps/chosen": -117.17984008789062,
      "logps/rejected": -142.4436798095703,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3240489959716797,
      "rewards/margins": 6.371614456176758,
      "rewards/rejected": -6.047565460205078,
      "step": 2003
    },
    {
      "epoch": 0.8016,
      "grad_norm": 24.620960235595703,
      "learning_rate": 7.329333333333333e-07,
      "logits/chosen": -2.947766065597534,
      "logits/rejected": -3.0264077186584473,
      "logps/chosen": -119.71061706542969,
      "logps/rejected": -102.46569061279297,
      "loss": 0.198,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9273598194122314,
      "rewards/margins": 3.849357843399048,
      "rewards/rejected": -4.776717662811279,
      "step": 2004
    },
    {
      "epoch": 0.802,
      "grad_norm": 2.7060611248016357,
      "learning_rate": 7.328e-07,
      "logits/chosen": -3.225900173187256,
      "logits/rejected": -2.8009567260742188,
      "logps/chosen": -65.00064086914062,
      "logps/rejected": -87.5840835571289,
      "loss": 0.0375,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1869819164276123,
      "rewards/margins": 5.004654884338379,
      "rewards/rejected": -4.8176727294921875,
      "step": 2005
    },
    {
      "epoch": 0.8024,
      "grad_norm": 2.1920456886291504,
      "learning_rate": 7.326666666666667e-07,
      "logits/chosen": -2.9588029384613037,
      "logits/rejected": -2.1664602756500244,
      "logps/chosen": -100.90495300292969,
      "logps/rejected": -98.58296203613281,
      "loss": 0.0263,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27190741896629333,
      "rewards/margins": 4.672471046447754,
      "rewards/rejected": -4.4005632400512695,
      "step": 2006
    },
    {
      "epoch": 0.8028,
      "grad_norm": 0.04959601163864136,
      "learning_rate": 7.325333333333334e-07,
      "logits/chosen": -2.6209330558776855,
      "logits/rejected": -2.0044872760772705,
      "logps/chosen": -170.77882385253906,
      "logps/rejected": -246.88465881347656,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4470825493335724,
      "rewards/margins": 9.02553653717041,
      "rewards/rejected": -9.472618103027344,
      "step": 2007
    },
    {
      "epoch": 0.8032,
      "grad_norm": 0.19582296907901764,
      "learning_rate": 7.324e-07,
      "logits/chosen": -2.9208719730377197,
      "logits/rejected": -2.420842170715332,
      "logps/chosen": -122.0631332397461,
      "logps/rejected": -102.76248168945312,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.155126929283142,
      "rewards/margins": 6.091155052185059,
      "rewards/rejected": -4.936028480529785,
      "step": 2008
    },
    {
      "epoch": 0.8036,
      "grad_norm": 0.37141847610473633,
      "learning_rate": 7.322666666666666e-07,
      "logits/chosen": -2.9530158042907715,
      "logits/rejected": -2.4284021854400635,
      "logps/chosen": -91.0741958618164,
      "logps/rejected": -137.6484375,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25868263840675354,
      "rewards/margins": 6.493809700012207,
      "rewards/rejected": -6.235126972198486,
      "step": 2009
    },
    {
      "epoch": 0.804,
      "grad_norm": 0.1323363035917282,
      "learning_rate": 7.321333333333332e-07,
      "logits/chosen": -3.0683603286743164,
      "logits/rejected": -2.2256200313568115,
      "logps/chosen": -91.4837646484375,
      "logps/rejected": -120.10624694824219,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5066601037979126,
      "rewards/margins": 7.557558059692383,
      "rewards/rejected": -6.050897598266602,
      "step": 2010
    },
    {
      "epoch": 0.8044,
      "grad_norm": 0.05372081696987152,
      "learning_rate": 7.319999999999999e-07,
      "logits/chosen": -3.0490808486938477,
      "logits/rejected": -2.7587246894836426,
      "logps/chosen": -60.35835266113281,
      "logps/rejected": -145.667724609375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.028118327260017395,
      "rewards/margins": 7.8634796142578125,
      "rewards/rejected": -7.835361480712891,
      "step": 2011
    },
    {
      "epoch": 0.8048,
      "grad_norm": 1.952534556388855,
      "learning_rate": 7.318666666666666e-07,
      "logits/chosen": -2.826632022857666,
      "logits/rejected": -2.370941400527954,
      "logps/chosen": -128.8879852294922,
      "logps/rejected": -97.33341979980469,
      "loss": 0.0176,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.733996570110321,
      "rewards/margins": 5.091272354125977,
      "rewards/rejected": -4.35727596282959,
      "step": 2012
    },
    {
      "epoch": 0.8052,
      "grad_norm": 0.28522011637687683,
      "learning_rate": 7.317333333333333e-07,
      "logits/chosen": -2.779411792755127,
      "logits/rejected": -1.9814050197601318,
      "logps/chosen": -148.82708740234375,
      "logps/rejected": -137.75717163085938,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2409316897392273,
      "rewards/margins": 7.183794021606445,
      "rewards/rejected": -6.942862510681152,
      "step": 2013
    },
    {
      "epoch": 0.8056,
      "grad_norm": 0.36150485277175903,
      "learning_rate": 7.316e-07,
      "logits/chosen": -2.525460720062256,
      "logits/rejected": -1.8631625175476074,
      "logps/chosen": -139.72760009765625,
      "logps/rejected": -113.79585266113281,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.795056164264679,
      "rewards/margins": 5.834488868713379,
      "rewards/rejected": -5.039432525634766,
      "step": 2014
    },
    {
      "epoch": 0.806,
      "grad_norm": 0.9135578274726868,
      "learning_rate": 7.314666666666667e-07,
      "logits/chosen": -2.749535083770752,
      "logits/rejected": -2.307992696762085,
      "logps/chosen": -132.61019897460938,
      "logps/rejected": -112.33841705322266,
      "loss": 0.011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4368484616279602,
      "rewards/margins": 6.558915615081787,
      "rewards/rejected": -6.122067451477051,
      "step": 2015
    },
    {
      "epoch": 0.8064,
      "grad_norm": 1.0958456993103027,
      "learning_rate": 7.313333333333333e-07,
      "logits/chosen": -2.6886653900146484,
      "logits/rejected": -1.8593003749847412,
      "logps/chosen": -83.5648193359375,
      "logps/rejected": -178.2867431640625,
      "loss": 0.0129,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3193931579589844,
      "rewards/margins": 7.314121246337891,
      "rewards/rejected": -6.994728088378906,
      "step": 2016
    },
    {
      "epoch": 0.8068,
      "grad_norm": 0.15623880922794342,
      "learning_rate": 7.311999999999999e-07,
      "logits/chosen": -2.885928153991699,
      "logits/rejected": -2.441535234451294,
      "logps/chosen": -93.63517761230469,
      "logps/rejected": -128.9647674560547,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0798488855361938,
      "rewards/margins": 6.942626953125,
      "rewards/rejected": -5.862778186798096,
      "step": 2017
    },
    {
      "epoch": 0.8072,
      "grad_norm": 0.4484131932258606,
      "learning_rate": 7.310666666666666e-07,
      "logits/chosen": -3.105360507965088,
      "logits/rejected": -2.8258442878723145,
      "logps/chosen": -110.2344970703125,
      "logps/rejected": -113.27088928222656,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1958324909210205,
      "rewards/margins": 6.356771469116211,
      "rewards/rejected": -5.1609392166137695,
      "step": 2018
    },
    {
      "epoch": 0.8076,
      "grad_norm": 3.8442344665527344,
      "learning_rate": 7.309333333333333e-07,
      "logits/chosen": -3.0022311210632324,
      "logits/rejected": -2.9451301097869873,
      "logps/chosen": -150.5067901611328,
      "logps/rejected": -105.68263244628906,
      "loss": 0.0284,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1820030212402344,
      "rewards/margins": 3.966454267501831,
      "rewards/rejected": -5.1484575271606445,
      "step": 2019
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.06728511303663254,
      "learning_rate": 7.308e-07,
      "logits/chosen": -2.603668212890625,
      "logits/rejected": -1.688694715499878,
      "logps/chosen": -112.29811096191406,
      "logps/rejected": -142.4157257080078,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7625125646591187,
      "rewards/margins": 8.09023380279541,
      "rewards/rejected": -6.327721118927002,
      "step": 2020
    },
    {
      "epoch": 0.8084,
      "grad_norm": 2.538525342941284,
      "learning_rate": 7.306666666666666e-07,
      "logits/chosen": -2.999746799468994,
      "logits/rejected": -2.558422088623047,
      "logps/chosen": -56.173789978027344,
      "logps/rejected": -67.50447082519531,
      "loss": 0.037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08086374402046204,
      "rewards/margins": 3.5740556716918945,
      "rewards/rejected": -3.6549196243286133,
      "step": 2021
    },
    {
      "epoch": 0.8088,
      "grad_norm": 1.8103052377700806,
      "learning_rate": 7.305333333333333e-07,
      "logits/chosen": -2.7518444061279297,
      "logits/rejected": -2.360060930252075,
      "logps/chosen": -125.61605834960938,
      "logps/rejected": -163.158447265625,
      "loss": 0.0166,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3548794388771057,
      "rewards/margins": 4.1271653175354,
      "rewards/rejected": -4.482044696807861,
      "step": 2022
    },
    {
      "epoch": 0.8092,
      "grad_norm": 1.299083948135376,
      "learning_rate": 7.304e-07,
      "logits/chosen": -2.636582374572754,
      "logits/rejected": -2.0715014934539795,
      "logps/chosen": -160.4794921875,
      "logps/rejected": -172.57803344726562,
      "loss": 0.0111,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17593994736671448,
      "rewards/margins": 6.639918804168701,
      "rewards/rejected": -6.4639787673950195,
      "step": 2023
    },
    {
      "epoch": 0.8096,
      "grad_norm": 11.966994285583496,
      "learning_rate": 7.302666666666666e-07,
      "logits/chosen": -3.120150566101074,
      "logits/rejected": -2.8998258113861084,
      "logps/chosen": -86.54121398925781,
      "logps/rejected": -73.04568481445312,
      "loss": 0.1829,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5813579559326172,
      "rewards/margins": 2.305175304412842,
      "rewards/rejected": -3.886533260345459,
      "step": 2024
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.43583744764328003,
      "learning_rate": 7.301333333333333e-07,
      "logits/chosen": -2.7003352642059326,
      "logits/rejected": -2.156182289123535,
      "logps/chosen": -148.0019989013672,
      "logps/rejected": -117.44999694824219,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8335285186767578,
      "rewards/margins": 5.930190086364746,
      "rewards/rejected": -6.763718605041504,
      "step": 2025
    },
    {
      "epoch": 0.8104,
      "grad_norm": 3.3324086666107178,
      "learning_rate": 7.3e-07,
      "logits/chosen": -2.5884509086608887,
      "logits/rejected": -2.133084535598755,
      "logps/chosen": -147.30508422851562,
      "logps/rejected": -107.23987579345703,
      "loss": 0.0437,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.359567254781723,
      "rewards/margins": 4.575764179229736,
      "rewards/rejected": -4.935331344604492,
      "step": 2026
    },
    {
      "epoch": 0.8108,
      "grad_norm": 0.011996365152299404,
      "learning_rate": 7.298666666666666e-07,
      "logits/chosen": -2.960493564605713,
      "logits/rejected": -2.034804105758667,
      "logps/chosen": -83.1049575805664,
      "logps/rejected": -140.14773559570312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0706634521484375,
      "rewards/margins": 9.810464859008789,
      "rewards/rejected": -7.739800930023193,
      "step": 2027
    },
    {
      "epoch": 0.8112,
      "grad_norm": 1.3164690732955933,
      "learning_rate": 7.297333333333333e-07,
      "logits/chosen": -2.8374078273773193,
      "logits/rejected": -2.4593138694763184,
      "logps/chosen": -76.39448547363281,
      "logps/rejected": -59.921669006347656,
      "loss": 0.0153,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6639934778213501,
      "rewards/margins": 4.288772106170654,
      "rewards/rejected": -3.6247787475585938,
      "step": 2028
    },
    {
      "epoch": 0.8116,
      "grad_norm": 1.2524302005767822,
      "learning_rate": 7.296e-07,
      "logits/chosen": -3.2016115188598633,
      "logits/rejected": -2.5334057807922363,
      "logps/chosen": -71.28121185302734,
      "logps/rejected": -113.23037719726562,
      "loss": 0.0087,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1921402215957642,
      "rewards/margins": 6.2360615730285645,
      "rewards/rejected": -5.04392147064209,
      "step": 2029
    },
    {
      "epoch": 0.812,
      "grad_norm": 2.0396034717559814,
      "learning_rate": 7.294666666666667e-07,
      "logits/chosen": -3.153721809387207,
      "logits/rejected": -2.6851823329925537,
      "logps/chosen": -81.8834228515625,
      "logps/rejected": -97.69517517089844,
      "loss": 0.0285,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.15725785493850708,
      "rewards/margins": 4.388321876525879,
      "rewards/rejected": -4.54557991027832,
      "step": 2030
    },
    {
      "epoch": 0.8124,
      "grad_norm": 3.5070502758026123,
      "learning_rate": 7.293333333333332e-07,
      "logits/chosen": -2.622969150543213,
      "logits/rejected": -2.3036670684814453,
      "logps/chosen": -239.63597106933594,
      "logps/rejected": -127.37627410888672,
      "loss": 0.0195,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3785377740859985,
      "rewards/margins": 5.565846920013428,
      "rewards/rejected": -6.944384574890137,
      "step": 2031
    },
    {
      "epoch": 0.8128,
      "grad_norm": 0.41363757848739624,
      "learning_rate": 7.291999999999999e-07,
      "logits/chosen": -2.8209757804870605,
      "logits/rejected": -1.9527654647827148,
      "logps/chosen": -62.60686492919922,
      "logps/rejected": -133.46902465820312,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08733215183019638,
      "rewards/margins": 7.1343231201171875,
      "rewards/rejected": -7.221655368804932,
      "step": 2032
    },
    {
      "epoch": 0.8132,
      "grad_norm": 0.18577028810977936,
      "learning_rate": 7.290666666666666e-07,
      "logits/chosen": -3.08168888092041,
      "logits/rejected": -2.899219512939453,
      "logps/chosen": -76.89057922363281,
      "logps/rejected": -109.09355163574219,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1693633794784546,
      "rewards/margins": 6.965876579284668,
      "rewards/rejected": -5.796513557434082,
      "step": 2033
    },
    {
      "epoch": 0.8136,
      "grad_norm": 0.05605506896972656,
      "learning_rate": 7.289333333333333e-07,
      "logits/chosen": -2.5112833976745605,
      "logits/rejected": -1.5832939147949219,
      "logps/chosen": -175.21743774414062,
      "logps/rejected": -153.95370483398438,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4766579270362854,
      "rewards/margins": 7.875871181488037,
      "rewards/rejected": -7.399212837219238,
      "step": 2034
    },
    {
      "epoch": 0.814,
      "grad_norm": 0.03677350655198097,
      "learning_rate": 7.288e-07,
      "logits/chosen": -3.1273272037506104,
      "logits/rejected": -2.482172727584839,
      "logps/chosen": -90.19581604003906,
      "logps/rejected": -194.32919311523438,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09109802544116974,
      "rewards/margins": 9.033515930175781,
      "rewards/rejected": -8.942419052124023,
      "step": 2035
    },
    {
      "epoch": 0.8144,
      "grad_norm": 0.17134565114974976,
      "learning_rate": 7.286666666666666e-07,
      "logits/chosen": -2.8502817153930664,
      "logits/rejected": -2.365151882171631,
      "logps/chosen": -91.850830078125,
      "logps/rejected": -103.93757629394531,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6800525784492493,
      "rewards/margins": 7.002434730529785,
      "rewards/rejected": -6.32238245010376,
      "step": 2036
    },
    {
      "epoch": 0.8148,
      "grad_norm": 0.05777532979846001,
      "learning_rate": 7.285333333333333e-07,
      "logits/chosen": -2.524491786956787,
      "logits/rejected": -1.5008968114852905,
      "logps/chosen": -55.292991638183594,
      "logps/rejected": -152.88604736328125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0384693145751953,
      "rewards/margins": 10.090173721313477,
      "rewards/rejected": -8.051704406738281,
      "step": 2037
    },
    {
      "epoch": 0.8152,
      "grad_norm": 0.011684276163578033,
      "learning_rate": 7.284e-07,
      "logits/chosen": -2.592428684234619,
      "logits/rejected": -1.707640528678894,
      "logps/chosen": -166.21409606933594,
      "logps/rejected": -158.09681701660156,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1241569519042969,
      "rewards/margins": 10.276968002319336,
      "rewards/rejected": -9.152811050415039,
      "step": 2038
    },
    {
      "epoch": 0.8156,
      "grad_norm": 0.3902302086353302,
      "learning_rate": 7.282666666666666e-07,
      "logits/chosen": -2.5916671752929688,
      "logits/rejected": -2.138845920562744,
      "logps/chosen": -141.202392578125,
      "logps/rejected": -134.07138061523438,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7734527587890625,
      "rewards/margins": 6.144118309020996,
      "rewards/rejected": -5.370665550231934,
      "step": 2039
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.5452607274055481,
      "learning_rate": 7.281333333333333e-07,
      "logits/chosen": -2.8489186763763428,
      "logits/rejected": -2.1938061714172363,
      "logps/chosen": -92.79559326171875,
      "logps/rejected": -98.08086395263672,
      "loss": 0.006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.808762788772583,
      "rewards/margins": 5.120824337005615,
      "rewards/rejected": -4.312061786651611,
      "step": 2040
    },
    {
      "epoch": 0.8164,
      "grad_norm": 0.6323903799057007,
      "learning_rate": 7.28e-07,
      "logits/chosen": -2.764754056930542,
      "logits/rejected": -2.0244247913360596,
      "logps/chosen": -82.80570983886719,
      "logps/rejected": -135.9229278564453,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.552988052368164,
      "rewards/margins": 8.252556800842285,
      "rewards/rejected": -6.699569225311279,
      "step": 2041
    },
    {
      "epoch": 0.8168,
      "grad_norm": 1.1916686296463013,
      "learning_rate": 7.278666666666666e-07,
      "logits/chosen": -2.9284801483154297,
      "logits/rejected": -1.6401855945587158,
      "logps/chosen": -161.72247314453125,
      "logps/rejected": -140.7906494140625,
      "loss": 0.0107,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3731570839881897,
      "rewards/margins": 5.750905990600586,
      "rewards/rejected": -6.124063014984131,
      "step": 2042
    },
    {
      "epoch": 0.8172,
      "grad_norm": 0.31987279653549194,
      "learning_rate": 7.277333333333333e-07,
      "logits/chosen": -2.832797050476074,
      "logits/rejected": -2.418558359146118,
      "logps/chosen": -76.35615539550781,
      "logps/rejected": -128.8541717529297,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.15559086203575134,
      "rewards/margins": 7.5559844970703125,
      "rewards/rejected": -7.711575508117676,
      "step": 2043
    },
    {
      "epoch": 0.8176,
      "grad_norm": 0.9999167323112488,
      "learning_rate": 7.276e-07,
      "logits/chosen": -2.717729330062866,
      "logits/rejected": -2.225762367248535,
      "logps/chosen": -146.79278564453125,
      "logps/rejected": -101.09659576416016,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2966964840888977,
      "rewards/margins": 6.030076503753662,
      "rewards/rejected": -6.326773166656494,
      "step": 2044
    },
    {
      "epoch": 0.818,
      "grad_norm": 0.02431274577975273,
      "learning_rate": 7.274666666666667e-07,
      "logits/chosen": -2.5524206161499023,
      "logits/rejected": -1.9954187870025635,
      "logps/chosen": -116.67621612548828,
      "logps/rejected": -151.00146484375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2629448175430298,
      "rewards/margins": 9.134788513183594,
      "rewards/rejected": -7.871843338012695,
      "step": 2045
    },
    {
      "epoch": 0.8184,
      "grad_norm": 0.7924399971961975,
      "learning_rate": 7.273333333333333e-07,
      "logits/chosen": -2.961728572845459,
      "logits/rejected": -2.7728638648986816,
      "logps/chosen": -111.79975128173828,
      "logps/rejected": -224.84083557128906,
      "loss": 0.0055,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16321641206741333,
      "rewards/margins": 6.456491470336914,
      "rewards/rejected": -6.293274879455566,
      "step": 2046
    },
    {
      "epoch": 0.8188,
      "grad_norm": 0.3457300364971161,
      "learning_rate": 7.271999999999999e-07,
      "logits/chosen": -3.0647425651550293,
      "logits/rejected": -2.363430976867676,
      "logps/chosen": -78.79039001464844,
      "logps/rejected": -144.0309295654297,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.603642463684082,
      "rewards/margins": 6.7925825119018555,
      "rewards/rejected": -7.3962249755859375,
      "step": 2047
    },
    {
      "epoch": 0.8192,
      "grad_norm": 13.923995018005371,
      "learning_rate": 7.270666666666666e-07,
      "logits/chosen": -3.283815622329712,
      "logits/rejected": -2.7655935287475586,
      "logps/chosen": -153.4104766845703,
      "logps/rejected": -103.35692596435547,
      "loss": 0.1263,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6689293384552002,
      "rewards/margins": 2.1094863414764404,
      "rewards/rejected": -3.7784156799316406,
      "step": 2048
    },
    {
      "epoch": 0.8196,
      "grad_norm": 0.1450529545545578,
      "learning_rate": 7.269333333333333e-07,
      "logits/chosen": -2.7815704345703125,
      "logits/rejected": -2.2339720726013184,
      "logps/chosen": -54.73041915893555,
      "logps/rejected": -186.96083068847656,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41124534606933594,
      "rewards/margins": 7.291128158569336,
      "rewards/rejected": -6.879883289337158,
      "step": 2049
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.07792434096336365,
      "learning_rate": 7.268e-07,
      "logits/chosen": -2.4276034832000732,
      "logits/rejected": -1.4945778846740723,
      "logps/chosen": -96.48429870605469,
      "logps/rejected": -160.5858612060547,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5363998413085938,
      "rewards/margins": 7.596635818481445,
      "rewards/rejected": -7.060235977172852,
      "step": 2050
    },
    {
      "epoch": 0.8204,
      "grad_norm": 0.03041362203657627,
      "learning_rate": 7.266666666666667e-07,
      "logits/chosen": -2.579789161682129,
      "logits/rejected": -1.7382227182388306,
      "logps/chosen": -137.79043579101562,
      "logps/rejected": -194.60546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1566818356513977,
      "rewards/margins": 9.495280265808105,
      "rewards/rejected": -9.338598251342773,
      "step": 2051
    },
    {
      "epoch": 0.8208,
      "grad_norm": 0.0905645489692688,
      "learning_rate": 7.265333333333334e-07,
      "logits/chosen": -2.5519018173217773,
      "logits/rejected": -1.81787109375,
      "logps/chosen": -76.15338134765625,
      "logps/rejected": -176.50881958007812,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4554111361503601,
      "rewards/margins": 8.823680877685547,
      "rewards/rejected": -8.368269920349121,
      "step": 2052
    },
    {
      "epoch": 0.8212,
      "grad_norm": 4.599108695983887,
      "learning_rate": 7.264e-07,
      "logits/chosen": -2.7869186401367188,
      "logits/rejected": -2.615198850631714,
      "logps/chosen": -114.74658203125,
      "logps/rejected": -65.09121704101562,
      "loss": 0.0419,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.32967299222946167,
      "rewards/margins": 3.3740596771240234,
      "rewards/rejected": -3.703732967376709,
      "step": 2053
    },
    {
      "epoch": 0.8216,
      "grad_norm": 51.730350494384766,
      "learning_rate": 7.262666666666666e-07,
      "logits/chosen": -3.0855307579040527,
      "logits/rejected": -3.0969510078430176,
      "logps/chosen": -78.59982299804688,
      "logps/rejected": -80.9671401977539,
      "loss": 0.9337,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -2.5807902812957764,
      "rewards/margins": 1.7744301557540894,
      "rewards/rejected": -4.355220317840576,
      "step": 2054
    },
    {
      "epoch": 0.822,
      "grad_norm": 4.447189807891846,
      "learning_rate": 7.261333333333332e-07,
      "logits/chosen": -3.1334567070007324,
      "logits/rejected": -2.491231918334961,
      "logps/chosen": -106.43519592285156,
      "logps/rejected": -126.85006713867188,
      "loss": 0.0349,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5782558917999268,
      "rewards/margins": 6.905540466308594,
      "rewards/rejected": -7.4837965965271,
      "step": 2055
    },
    {
      "epoch": 0.8224,
      "grad_norm": 2.424196481704712,
      "learning_rate": 7.259999999999999e-07,
      "logits/chosen": -2.6657235622406006,
      "logits/rejected": -1.9093596935272217,
      "logps/chosen": -151.52407836914062,
      "logps/rejected": -112.95941925048828,
      "loss": 0.0254,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.229576587677002,
      "rewards/margins": 3.6684348583221436,
      "rewards/rejected": -5.898011684417725,
      "step": 2056
    },
    {
      "epoch": 0.8228,
      "grad_norm": 0.7195760011672974,
      "learning_rate": 7.258666666666666e-07,
      "logits/chosen": -2.5780017375946045,
      "logits/rejected": -1.9960343837738037,
      "logps/chosen": -95.48143768310547,
      "logps/rejected": -133.32363891601562,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3087596893310547,
      "rewards/margins": 8.355794906616211,
      "rewards/rejected": -7.047034740447998,
      "step": 2057
    },
    {
      "epoch": 0.8232,
      "grad_norm": 3.579258441925049,
      "learning_rate": 7.257333333333333e-07,
      "logits/chosen": -3.0096960067749023,
      "logits/rejected": -2.8607921600341797,
      "logps/chosen": -121.8807373046875,
      "logps/rejected": -92.24446105957031,
      "loss": 0.0459,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.523257851600647,
      "rewards/margins": 3.082304000854492,
      "rewards/rejected": -4.60556173324585,
      "step": 2058
    },
    {
      "epoch": 0.8236,
      "grad_norm": 3.3758609294891357,
      "learning_rate": 7.256e-07,
      "logits/chosen": -2.873166084289551,
      "logits/rejected": -2.175989866256714,
      "logps/chosen": -166.56787109375,
      "logps/rejected": -125.7389907836914,
      "loss": 0.0183,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9059524536132812,
      "rewards/margins": 5.146312713623047,
      "rewards/rejected": -6.052265167236328,
      "step": 2059
    },
    {
      "epoch": 0.824,
      "grad_norm": 1.098523736000061,
      "learning_rate": 7.254666666666667e-07,
      "logits/chosen": -2.967542886734009,
      "logits/rejected": -2.7237212657928467,
      "logps/chosen": -45.96799850463867,
      "logps/rejected": -109.7210693359375,
      "loss": 0.0102,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.026131823658943176,
      "rewards/margins": 4.6683855056762695,
      "rewards/rejected": -4.694517135620117,
      "step": 2060
    },
    {
      "epoch": 0.8244,
      "grad_norm": 0.26737749576568604,
      "learning_rate": 7.253333333333334e-07,
      "logits/chosen": -2.9184296131134033,
      "logits/rejected": -2.569319725036621,
      "logps/chosen": -104.67254638671875,
      "logps/rejected": -98.47169494628906,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7064841985702515,
      "rewards/margins": 6.26871919631958,
      "rewards/rejected": -5.562234878540039,
      "step": 2061
    },
    {
      "epoch": 0.8248,
      "grad_norm": 2.105086088180542,
      "learning_rate": 7.252e-07,
      "logits/chosen": -2.753784656524658,
      "logits/rejected": -2.1720497608184814,
      "logps/chosen": -170.98532104492188,
      "logps/rejected": -99.71955871582031,
      "loss": 0.0214,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4645836353302002,
      "rewards/margins": 3.8396410942077637,
      "rewards/rejected": -5.304224491119385,
      "step": 2062
    },
    {
      "epoch": 0.8252,
      "grad_norm": 0.726203441619873,
      "learning_rate": 7.250666666666666e-07,
      "logits/chosen": -2.791419506072998,
      "logits/rejected": -2.025186777114868,
      "logps/chosen": -129.27685546875,
      "logps/rejected": -105.4262466430664,
      "loss": 0.0068,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.04865950345993042,
      "rewards/margins": 5.307995796203613,
      "rewards/rejected": -5.356655597686768,
      "step": 2063
    },
    {
      "epoch": 0.8256,
      "grad_norm": 3.0451598167419434,
      "learning_rate": 7.249333333333332e-07,
      "logits/chosen": -2.7052595615386963,
      "logits/rejected": -2.01627254486084,
      "logps/chosen": -177.92794799804688,
      "logps/rejected": -169.82611083984375,
      "loss": 0.0171,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6237655282020569,
      "rewards/margins": 7.815737724304199,
      "rewards/rejected": -8.43950366973877,
      "step": 2064
    },
    {
      "epoch": 0.826,
      "grad_norm": 2.2410683631896973,
      "learning_rate": 7.247999999999999e-07,
      "logits/chosen": -2.847337484359741,
      "logits/rejected": -2.5433173179626465,
      "logps/chosen": -99.59452819824219,
      "logps/rejected": -141.99069213867188,
      "loss": 0.0259,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.13677063584327698,
      "rewards/margins": 6.661426544189453,
      "rewards/rejected": -6.798196792602539,
      "step": 2065
    },
    {
      "epoch": 0.8264,
      "grad_norm": 0.11882955580949783,
      "learning_rate": 7.246666666666666e-07,
      "logits/chosen": -2.8474483489990234,
      "logits/rejected": -2.2342612743377686,
      "logps/chosen": -110.90251922607422,
      "logps/rejected": -131.24440002441406,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04290771484375,
      "rewards/margins": 7.077888488769531,
      "rewards/rejected": -7.034980773925781,
      "step": 2066
    },
    {
      "epoch": 0.8268,
      "grad_norm": 2.4449753761291504,
      "learning_rate": 7.245333333333333e-07,
      "logits/chosen": -2.962766647338867,
      "logits/rejected": -2.203519821166992,
      "logps/chosen": -80.59010314941406,
      "logps/rejected": -99.5938720703125,
      "loss": 0.0241,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5648574829101562,
      "rewards/margins": 5.745514869689941,
      "rewards/rejected": -5.180657386779785,
      "step": 2067
    },
    {
      "epoch": 0.8272,
      "grad_norm": 0.7439227104187012,
      "learning_rate": 7.244e-07,
      "logits/chosen": -2.696776866912842,
      "logits/rejected": -2.148968458175659,
      "logps/chosen": -119.63893127441406,
      "logps/rejected": -185.63104248046875,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05361330509185791,
      "rewards/margins": 9.047399520874023,
      "rewards/rejected": -8.993786811828613,
      "step": 2068
    },
    {
      "epoch": 0.8276,
      "grad_norm": 1.9177019596099854,
      "learning_rate": 7.242666666666666e-07,
      "logits/chosen": -2.824172258377075,
      "logits/rejected": -2.3179898262023926,
      "logps/chosen": -61.82593536376953,
      "logps/rejected": -117.01913452148438,
      "loss": 0.0251,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1052650511264801,
      "rewards/margins": 5.618520736694336,
      "rewards/rejected": -5.513256072998047,
      "step": 2069
    },
    {
      "epoch": 0.828,
      "grad_norm": 1.30662202835083,
      "learning_rate": 7.241333333333333e-07,
      "logits/chosen": -2.905862808227539,
      "logits/rejected": -2.258882522583008,
      "logps/chosen": -53.83491516113281,
      "logps/rejected": -98.25091552734375,
      "loss": 0.0129,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5739231109619141,
      "rewards/margins": 5.299080848693848,
      "rewards/rejected": -4.725157737731934,
      "step": 2070
    },
    {
      "epoch": 0.8284,
      "grad_norm": 3.917165756225586,
      "learning_rate": 7.24e-07,
      "logits/chosen": -2.7030463218688965,
      "logits/rejected": -2.2096571922302246,
      "logps/chosen": -104.17237854003906,
      "logps/rejected": -101.57772827148438,
      "loss": 0.0315,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.1838245391845703,
      "rewards/margins": 4.247941970825195,
      "rewards/rejected": -6.431766510009766,
      "step": 2071
    },
    {
      "epoch": 0.8288,
      "grad_norm": 2.1372108459472656,
      "learning_rate": 7.238666666666667e-07,
      "logits/chosen": -2.324233293533325,
      "logits/rejected": -1.5990419387817383,
      "logps/chosen": -173.35516357421875,
      "logps/rejected": -150.7318115234375,
      "loss": 0.0097,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1379048824310303,
      "rewards/margins": 7.252668380737305,
      "rewards/rejected": -8.390573501586914,
      "step": 2072
    },
    {
      "epoch": 0.8292,
      "grad_norm": 1.9905601739883423,
      "learning_rate": 7.237333333333334e-07,
      "logits/chosen": -3.186497449874878,
      "logits/rejected": -2.589160203933716,
      "logps/chosen": -57.1060676574707,
      "logps/rejected": -68.80546569824219,
      "loss": 0.0245,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.06909789890050888,
      "rewards/margins": 3.7884297370910645,
      "rewards/rejected": -3.857527732849121,
      "step": 2073
    },
    {
      "epoch": 0.8296,
      "grad_norm": 1.165230631828308,
      "learning_rate": 7.235999999999999e-07,
      "logits/chosen": -2.8529467582702637,
      "logits/rejected": -2.2797250747680664,
      "logps/chosen": -131.4310302734375,
      "logps/rejected": -127.39497375488281,
      "loss": 0.0113,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07339553534984589,
      "rewards/margins": 7.2022857666015625,
      "rewards/rejected": -7.128890037536621,
      "step": 2074
    },
    {
      "epoch": 0.83,
      "grad_norm": 3.064138412475586,
      "learning_rate": 7.234666666666666e-07,
      "logits/chosen": -2.8500263690948486,
      "logits/rejected": -2.4128103256225586,
      "logps/chosen": -85.15343475341797,
      "logps/rejected": -119.49567413330078,
      "loss": 0.0477,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.713788628578186,
      "rewards/margins": 5.155756950378418,
      "rewards/rejected": -4.4419684410095215,
      "step": 2075
    },
    {
      "epoch": 0.8304,
      "grad_norm": 0.5552788376808167,
      "learning_rate": 7.233333333333333e-07,
      "logits/chosen": -2.7936348915100098,
      "logits/rejected": -2.2062125205993652,
      "logps/chosen": -110.73904418945312,
      "logps/rejected": -128.98472595214844,
      "loss": 0.0055,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1204441785812378,
      "rewards/margins": 6.058545112609863,
      "rewards/rejected": -4.938100814819336,
      "step": 2076
    },
    {
      "epoch": 0.8308,
      "grad_norm": 0.44933322072029114,
      "learning_rate": 7.231999999999999e-07,
      "logits/chosen": -3.2593936920166016,
      "logits/rejected": -2.7383179664611816,
      "logps/chosen": -82.93397521972656,
      "logps/rejected": -118.00778198242188,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.33542537689208984,
      "rewards/margins": 5.752928256988525,
      "rewards/rejected": -6.088353633880615,
      "step": 2077
    },
    {
      "epoch": 0.8312,
      "grad_norm": 0.02234281226992607,
      "learning_rate": 7.230666666666666e-07,
      "logits/chosen": -2.917780876159668,
      "logits/rejected": -2.90549898147583,
      "logps/chosen": -62.385746002197266,
      "logps/rejected": -137.4609832763672,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4138097763061523,
      "rewards/margins": 8.78549575805664,
      "rewards/rejected": -7.371685981750488,
      "step": 2078
    },
    {
      "epoch": 0.8316,
      "grad_norm": 0.13681846857070923,
      "learning_rate": 7.229333333333333e-07,
      "logits/chosen": -2.8877053260803223,
      "logits/rejected": -2.0446691513061523,
      "logps/chosen": -121.7264633178711,
      "logps/rejected": -141.57626342773438,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9638031721115112,
      "rewards/margins": 8.574663162231445,
      "rewards/rejected": -7.6108598709106445,
      "step": 2079
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.6423019170761108,
      "learning_rate": 7.228e-07,
      "logits/chosen": -3.2080371379852295,
      "logits/rejected": -2.8352441787719727,
      "logps/chosen": -58.45404052734375,
      "logps/rejected": -103.2958984375,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7707673907279968,
      "rewards/margins": 6.6167216300964355,
      "rewards/rejected": -5.845954418182373,
      "step": 2080
    },
    {
      "epoch": 0.8324,
      "grad_norm": 0.670764684677124,
      "learning_rate": 7.226666666666667e-07,
      "logits/chosen": -2.9409141540527344,
      "logits/rejected": -2.7843241691589355,
      "logps/chosen": -74.95005798339844,
      "logps/rejected": -88.03887939453125,
      "loss": 0.0082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39159926772117615,
      "rewards/margins": 4.880484580993652,
      "rewards/rejected": -4.488885402679443,
      "step": 2081
    },
    {
      "epoch": 0.8328,
      "grad_norm": 1.2777310609817505,
      "learning_rate": 7.225333333333334e-07,
      "logits/chosen": -2.7241744995117188,
      "logits/rejected": -2.498260021209717,
      "logps/chosen": -180.02003479003906,
      "logps/rejected": -220.9296875,
      "loss": 0.0114,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3149215579032898,
      "rewards/margins": 5.966281414031982,
      "rewards/rejected": -5.651359558105469,
      "step": 2082
    },
    {
      "epoch": 0.8332,
      "grad_norm": 0.8202728033065796,
      "learning_rate": 7.224e-07,
      "logits/chosen": -2.6256165504455566,
      "logits/rejected": -2.0045244693756104,
      "logps/chosen": -129.39962768554688,
      "logps/rejected": -214.93276977539062,
      "loss": 0.0082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8005294799804688,
      "rewards/margins": 4.9881367683410645,
      "rewards/rejected": -5.788666248321533,
      "step": 2083
    },
    {
      "epoch": 0.8336,
      "grad_norm": 0.6721991300582886,
      "learning_rate": 7.222666666666665e-07,
      "logits/chosen": -2.799434185028076,
      "logits/rejected": -2.153658866882324,
      "logps/chosen": -106.84413146972656,
      "logps/rejected": -158.981689453125,
      "loss": 0.005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22410660982131958,
      "rewards/margins": 6.701779842376709,
      "rewards/rejected": -6.477673530578613,
      "step": 2084
    },
    {
      "epoch": 0.834,
      "grad_norm": 0.3601728081703186,
      "learning_rate": 7.221333333333332e-07,
      "logits/chosen": -2.8953301906585693,
      "logits/rejected": -2.428739309310913,
      "logps/chosen": -73.63080596923828,
      "logps/rejected": -103.419921875,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6191909909248352,
      "rewards/margins": 5.717586994171143,
      "rewards/rejected": -5.098395824432373,
      "step": 2085
    },
    {
      "epoch": 0.8344,
      "grad_norm": 0.2752898335456848,
      "learning_rate": 7.219999999999999e-07,
      "logits/chosen": -2.943096160888672,
      "logits/rejected": -2.586142063140869,
      "logps/chosen": -86.9344482421875,
      "logps/rejected": -110.64073944091797,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6097095608711243,
      "rewards/margins": 6.450313568115234,
      "rewards/rejected": -5.840603828430176,
      "step": 2086
    },
    {
      "epoch": 0.8348,
      "grad_norm": 0.023248393088579178,
      "learning_rate": 7.218666666666666e-07,
      "logits/chosen": -2.5863447189331055,
      "logits/rejected": -1.8837777376174927,
      "logps/chosen": -63.852073669433594,
      "logps/rejected": -121.99845123291016,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7761123180389404,
      "rewards/margins": 8.910908699035645,
      "rewards/rejected": -7.134796142578125,
      "step": 2087
    },
    {
      "epoch": 0.8352,
      "grad_norm": 2.4423320293426514,
      "learning_rate": 7.217333333333333e-07,
      "logits/chosen": -2.758507251739502,
      "logits/rejected": -2.4480814933776855,
      "logps/chosen": -194.1116485595703,
      "logps/rejected": -109.48338317871094,
      "loss": 0.0205,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3559859991073608,
      "rewards/margins": 3.8980791568756104,
      "rewards/rejected": -5.25406551361084,
      "step": 2088
    },
    {
      "epoch": 0.8356,
      "grad_norm": 5.204074859619141,
      "learning_rate": 7.216e-07,
      "logits/chosen": -2.527007818222046,
      "logits/rejected": -2.3107810020446777,
      "logps/chosen": -120.93433380126953,
      "logps/rejected": -111.39366149902344,
      "loss": 0.0604,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04996947944164276,
      "rewards/margins": 5.164498329162598,
      "rewards/rejected": -5.114528656005859,
      "step": 2089
    },
    {
      "epoch": 0.836,
      "grad_norm": 2.7779510021209717,
      "learning_rate": 7.214666666666667e-07,
      "logits/chosen": -2.9548940658569336,
      "logits/rejected": -2.4881949424743652,
      "logps/chosen": -97.27238464355469,
      "logps/rejected": -69.81254577636719,
      "loss": 0.0281,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.37233051657676697,
      "rewards/margins": 4.026075839996338,
      "rewards/rejected": -4.398406505584717,
      "step": 2090
    },
    {
      "epoch": 0.8364,
      "grad_norm": 0.17980723083019257,
      "learning_rate": 7.213333333333334e-07,
      "logits/chosen": -3.3429207801818848,
      "logits/rejected": -2.4500608444213867,
      "logps/chosen": -41.9249267578125,
      "logps/rejected": -117.855224609375,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5929008722305298,
      "rewards/margins": 7.1766862869262695,
      "rewards/rejected": -6.583785057067871,
      "step": 2091
    },
    {
      "epoch": 0.8368,
      "grad_norm": 0.525924026966095,
      "learning_rate": 7.211999999999999e-07,
      "logits/chosen": -2.9830939769744873,
      "logits/rejected": -2.4640650749206543,
      "logps/chosen": -110.19253540039062,
      "logps/rejected": -104.9625244140625,
      "loss": 0.006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5672439932823181,
      "rewards/margins": 5.3184003829956055,
      "rewards/rejected": -4.751156806945801,
      "step": 2092
    },
    {
      "epoch": 0.8372,
      "grad_norm": 1.4545049667358398,
      "learning_rate": 7.210666666666666e-07,
      "logits/chosen": -3.219649314880371,
      "logits/rejected": -2.7241272926330566,
      "logps/chosen": -74.3526611328125,
      "logps/rejected": -80.37303161621094,
      "loss": 0.018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.044684600085020065,
      "rewards/margins": 4.310004234313965,
      "rewards/rejected": -4.35468864440918,
      "step": 2093
    },
    {
      "epoch": 0.8376,
      "grad_norm": 1.3394802808761597,
      "learning_rate": 7.209333333333333e-07,
      "logits/chosen": -2.9704010486602783,
      "logits/rejected": -2.3513636589050293,
      "logps/chosen": -74.53144073486328,
      "logps/rejected": -154.6815185546875,
      "loss": 0.0116,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9833465814590454,
      "rewards/margins": 7.745007514953613,
      "rewards/rejected": -6.761661052703857,
      "step": 2094
    },
    {
      "epoch": 0.838,
      "grad_norm": 0.09991279244422913,
      "learning_rate": 7.207999999999999e-07,
      "logits/chosen": -2.624452590942383,
      "logits/rejected": -1.8218319416046143,
      "logps/chosen": -121.69461059570312,
      "logps/rejected": -120.79212951660156,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6582109332084656,
      "rewards/margins": 7.048982620239258,
      "rewards/rejected": -6.390771865844727,
      "step": 2095
    },
    {
      "epoch": 0.8384,
      "grad_norm": 0.07115586847066879,
      "learning_rate": 7.206666666666666e-07,
      "logits/chosen": -2.8299055099487305,
      "logits/rejected": -1.9713505506515503,
      "logps/chosen": -84.79510498046875,
      "logps/rejected": -178.59356689453125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9374359846115112,
      "rewards/margins": 9.482940673828125,
      "rewards/rejected": -8.54550552368164,
      "step": 2096
    },
    {
      "epoch": 0.8388,
      "grad_norm": 0.47390982508659363,
      "learning_rate": 7.205333333333333e-07,
      "logits/chosen": -2.8996200561523438,
      "logits/rejected": -2.3157029151916504,
      "logps/chosen": -59.99237823486328,
      "logps/rejected": -162.7833709716797,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0055789947509765625,
      "rewards/margins": 6.9143595695495605,
      "rewards/rejected": -6.919938564300537,
      "step": 2097
    },
    {
      "epoch": 0.8392,
      "grad_norm": 4.405777454376221,
      "learning_rate": 7.204e-07,
      "logits/chosen": -2.7783570289611816,
      "logits/rejected": -2.3797097206115723,
      "logps/chosen": -95.97647094726562,
      "logps/rejected": -86.0191650390625,
      "loss": 0.0374,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16123390197753906,
      "rewards/margins": 4.534152030944824,
      "rewards/rejected": -4.372918128967285,
      "step": 2098
    },
    {
      "epoch": 0.8396,
      "grad_norm": 0.03754071146249771,
      "learning_rate": 7.202666666666667e-07,
      "logits/chosen": -2.577181339263916,
      "logits/rejected": -2.114149332046509,
      "logps/chosen": -112.33740234375,
      "logps/rejected": -130.83705139160156,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6954723596572876,
      "rewards/margins": 8.333548545837402,
      "rewards/rejected": -7.638076305389404,
      "step": 2099
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.1297757625579834,
      "learning_rate": 7.201333333333333e-07,
      "logits/chosen": -3.2493481636047363,
      "logits/rejected": -2.8488001823425293,
      "logps/chosen": -76.97540283203125,
      "logps/rejected": -78.40315246582031,
      "loss": 0.0196,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8111355304718018,
      "rewards/margins": 4.737341403961182,
      "rewards/rejected": -3.926205635070801,
      "step": 2100
    },
    {
      "epoch": 0.8404,
      "grad_norm": 2.5042707920074463,
      "learning_rate": 7.2e-07,
      "logits/chosen": -2.6599020957946777,
      "logits/rejected": -2.390256881713867,
      "logps/chosen": -91.02166748046875,
      "logps/rejected": -104.06170654296875,
      "loss": 0.0184,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0990859866142273,
      "rewards/margins": 4.945409774780273,
      "rewards/rejected": -5.044495582580566,
      "step": 2101
    },
    {
      "epoch": 0.8408,
      "grad_norm": 0.16525621712207794,
      "learning_rate": 7.198666666666666e-07,
      "logits/chosen": -3.1615922451019287,
      "logits/rejected": -2.248783826828003,
      "logps/chosen": -48.29744338989258,
      "logps/rejected": -116.21388244628906,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2357895374298096,
      "rewards/margins": 6.758147239685059,
      "rewards/rejected": -5.52235746383667,
      "step": 2102
    },
    {
      "epoch": 0.8412,
      "grad_norm": 0.12113376706838608,
      "learning_rate": 7.197333333333333e-07,
      "logits/chosen": -2.876232624053955,
      "logits/rejected": -2.106623888015747,
      "logps/chosen": -85.15478515625,
      "logps/rejected": -190.69573974609375,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0506747961044312,
      "rewards/margins": 7.447712421417236,
      "rewards/rejected": -6.397037506103516,
      "step": 2103
    },
    {
      "epoch": 0.8416,
      "grad_norm": 0.8283913135528564,
      "learning_rate": 7.196e-07,
      "logits/chosen": -3.178049087524414,
      "logits/rejected": -2.8925118446350098,
      "logps/chosen": -74.97254943847656,
      "logps/rejected": -107.49102783203125,
      "loss": 0.0079,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27172547578811646,
      "rewards/margins": 5.902999401092529,
      "rewards/rejected": -5.631274223327637,
      "step": 2104
    },
    {
      "epoch": 0.842,
      "grad_norm": 1.0378782749176025,
      "learning_rate": 7.194666666666667e-07,
      "logits/chosen": -2.980710983276367,
      "logits/rejected": -2.75136661529541,
      "logps/chosen": -111.22107696533203,
      "logps/rejected": -105.18630981445312,
      "loss": 0.0112,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7814565896987915,
      "rewards/margins": 4.483855247497559,
      "rewards/rejected": -5.2653117179870605,
      "step": 2105
    },
    {
      "epoch": 0.8424,
      "grad_norm": 0.4682213068008423,
      "learning_rate": 7.193333333333333e-07,
      "logits/chosen": -2.769000768661499,
      "logits/rejected": -2.262688159942627,
      "logps/chosen": -173.05902099609375,
      "logps/rejected": -106.55193328857422,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6186367869377136,
      "rewards/margins": 5.520350456237793,
      "rewards/rejected": -6.1389875411987305,
      "step": 2106
    },
    {
      "epoch": 0.8428,
      "grad_norm": 4.345461368560791,
      "learning_rate": 7.191999999999999e-07,
      "logits/chosen": -2.817014694213867,
      "logits/rejected": -2.5904250144958496,
      "logps/chosen": -88.0997543334961,
      "logps/rejected": -103.40380859375,
      "loss": 0.0649,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.240277960896492,
      "rewards/margins": 5.692931652069092,
      "rewards/rejected": -5.9332098960876465,
      "step": 2107
    },
    {
      "epoch": 0.8432,
      "grad_norm": 1.8367983102798462,
      "learning_rate": 7.190666666666666e-07,
      "logits/chosen": -3.0824384689331055,
      "logits/rejected": -2.901111602783203,
      "logps/chosen": -57.57536697387695,
      "logps/rejected": -61.612457275390625,
      "loss": 0.0282,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.023014456033706665,
      "rewards/margins": 3.66347599029541,
      "rewards/rejected": -3.6404614448547363,
      "step": 2108
    },
    {
      "epoch": 0.8436,
      "grad_norm": 2.896759510040283,
      "learning_rate": 7.189333333333333e-07,
      "logits/chosen": -2.436403512954712,
      "logits/rejected": -1.6890480518341064,
      "logps/chosen": -207.74179077148438,
      "logps/rejected": -142.77362060546875,
      "loss": 0.0151,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0090491771697998,
      "rewards/margins": 4.575101852416992,
      "rewards/rejected": -5.584151268005371,
      "step": 2109
    },
    {
      "epoch": 0.844,
      "grad_norm": 1.3232309818267822,
      "learning_rate": 7.188e-07,
      "logits/chosen": -3.274566650390625,
      "logits/rejected": -2.7504029273986816,
      "logps/chosen": -51.76750183105469,
      "logps/rejected": -75.16999816894531,
      "loss": 0.0181,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.14680518209934235,
      "rewards/margins": 4.11420202255249,
      "rewards/rejected": -4.261007308959961,
      "step": 2110
    },
    {
      "epoch": 0.8444,
      "grad_norm": 1.6369116306304932,
      "learning_rate": 7.186666666666667e-07,
      "logits/chosen": -3.333310127258301,
      "logits/rejected": -3.062096357345581,
      "logps/chosen": -55.464149475097656,
      "logps/rejected": -78.06604766845703,
      "loss": 0.0154,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3326154947280884,
      "rewards/margins": 4.353359699249268,
      "rewards/rejected": -4.020744323730469,
      "step": 2111
    },
    {
      "epoch": 0.8448,
      "grad_norm": 0.3343753516674042,
      "learning_rate": 7.185333333333333e-07,
      "logits/chosen": -2.8006129264831543,
      "logits/rejected": -2.2648448944091797,
      "logps/chosen": -118.46566772460938,
      "logps/rejected": -112.06588745117188,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.24527132511138916,
      "rewards/margins": 5.823269844055176,
      "rewards/rejected": -6.068541049957275,
      "step": 2112
    },
    {
      "epoch": 0.8452,
      "grad_norm": 4.651269912719727,
      "learning_rate": 7.184e-07,
      "logits/chosen": -2.9016599655151367,
      "logits/rejected": -2.825356960296631,
      "logps/chosen": -105.46669006347656,
      "logps/rejected": -101.64533233642578,
      "loss": 0.0367,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.17394790053367615,
      "rewards/margins": 4.951308727264404,
      "rewards/rejected": -5.125256538391113,
      "step": 2113
    },
    {
      "epoch": 0.8456,
      "grad_norm": 0.06472635269165039,
      "learning_rate": 7.182666666666667e-07,
      "logits/chosen": -3.220475912094116,
      "logits/rejected": -2.4001963138580322,
      "logps/chosen": -59.20874786376953,
      "logps/rejected": -146.02590942382812,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5978884100914001,
      "rewards/margins": 9.79219913482666,
      "rewards/rejected": -9.194310188293457,
      "step": 2114
    },
    {
      "epoch": 0.846,
      "grad_norm": 2.7848455905914307,
      "learning_rate": 7.181333333333333e-07,
      "logits/chosen": -2.6987271308898926,
      "logits/rejected": -2.0748276710510254,
      "logps/chosen": -101.36834716796875,
      "logps/rejected": -117.4584732055664,
      "loss": 0.0424,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.400020033121109,
      "rewards/margins": 5.595355033874512,
      "rewards/rejected": -5.1953349113464355,
      "step": 2115
    },
    {
      "epoch": 0.8464,
      "grad_norm": 1.8058158159255981,
      "learning_rate": 7.179999999999999e-07,
      "logits/chosen": -3.0576019287109375,
      "logits/rejected": -2.7308735847473145,
      "logps/chosen": -28.884552001953125,
      "logps/rejected": -98.70277404785156,
      "loss": 0.0199,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.018540292978286743,
      "rewards/margins": 5.305821418762207,
      "rewards/rejected": -5.324361801147461,
      "step": 2116
    },
    {
      "epoch": 0.8468,
      "grad_norm": 19.022695541381836,
      "learning_rate": 7.178666666666666e-07,
      "logits/chosen": -2.652945041656494,
      "logits/rejected": -2.3256421089172363,
      "logps/chosen": -161.2882537841797,
      "logps/rejected": -139.19189453125,
      "loss": 0.1085,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.341686487197876,
      "rewards/margins": 4.602730751037598,
      "rewards/rejected": -7.944417476654053,
      "step": 2117
    },
    {
      "epoch": 0.8472,
      "grad_norm": 0.7341424226760864,
      "learning_rate": 7.177333333333333e-07,
      "logits/chosen": -2.792915105819702,
      "logits/rejected": -2.022439479827881,
      "logps/chosen": -75.973876953125,
      "logps/rejected": -106.0240478515625,
      "loss": 0.0097,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09274263679981232,
      "rewards/margins": 5.834285736083984,
      "rewards/rejected": -5.741543292999268,
      "step": 2118
    },
    {
      "epoch": 0.8476,
      "grad_norm": 0.041736818850040436,
      "learning_rate": 7.176e-07,
      "logits/chosen": -2.6777749061584473,
      "logits/rejected": -2.098257303237915,
      "logps/chosen": -102.27851867675781,
      "logps/rejected": -181.22828674316406,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6343124508857727,
      "rewards/margins": 8.30389404296875,
      "rewards/rejected": -7.669581413269043,
      "step": 2119
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.1491004079580307,
      "learning_rate": 7.174666666666667e-07,
      "logits/chosen": -2.9239096641540527,
      "logits/rejected": -2.0040290355682373,
      "logps/chosen": -73.53518676757812,
      "logps/rejected": -119.82054138183594,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019975662231445312,
      "rewards/margins": 6.575205326080322,
      "rewards/rejected": -6.555229663848877,
      "step": 2120
    },
    {
      "epoch": 0.8484,
      "grad_norm": 0.05085095018148422,
      "learning_rate": 7.173333333333333e-07,
      "logits/chosen": -2.6631786823272705,
      "logits/rejected": -2.0221633911132812,
      "logps/chosen": -117.5867919921875,
      "logps/rejected": -172.7698211669922,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1886790990829468,
      "rewards/margins": 8.819425582885742,
      "rewards/rejected": -7.630745887756348,
      "step": 2121
    },
    {
      "epoch": 0.8488,
      "grad_norm": 0.08085347712039948,
      "learning_rate": 7.171999999999999e-07,
      "logits/chosen": -2.9163742065429688,
      "logits/rejected": -2.1356263160705566,
      "logps/chosen": -66.95758819580078,
      "logps/rejected": -125.04438781738281,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5517851114273071,
      "rewards/margins": 8.109947204589844,
      "rewards/rejected": -6.558161735534668,
      "step": 2122
    },
    {
      "epoch": 0.8492,
      "grad_norm": 1.7680140733718872,
      "learning_rate": 7.170666666666666e-07,
      "logits/chosen": -2.9520952701568604,
      "logits/rejected": -3.0933964252471924,
      "logps/chosen": -97.28257751464844,
      "logps/rejected": -79.65836334228516,
      "loss": 0.0277,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.35818517208099365,
      "rewards/margins": 3.6398489475250244,
      "rewards/rejected": -3.9980340003967285,
      "step": 2123
    },
    {
      "epoch": 0.8496,
      "grad_norm": 0.30165955424308777,
      "learning_rate": 7.169333333333333e-07,
      "logits/chosen": -2.7261605262756348,
      "logits/rejected": -2.1680188179016113,
      "logps/chosen": -91.47126770019531,
      "logps/rejected": -111.35856628417969,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0830574035644531,
      "rewards/margins": 6.0560407638549805,
      "rewards/rejected": -4.972983360290527,
      "step": 2124
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.7543702721595764,
      "learning_rate": 7.168e-07,
      "logits/chosen": -2.815871238708496,
      "logits/rejected": -2.1426453590393066,
      "logps/chosen": -133.2039794921875,
      "logps/rejected": -132.83856201171875,
      "loss": 0.0072,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5575748682022095,
      "rewards/margins": 7.121788024902344,
      "rewards/rejected": -6.564213275909424,
      "step": 2125
    },
    {
      "epoch": 0.8504,
      "grad_norm": 0.14501157402992249,
      "learning_rate": 7.166666666666667e-07,
      "logits/chosen": -2.7520525455474854,
      "logits/rejected": -2.084731340408325,
      "logps/chosen": -119.17393493652344,
      "logps/rejected": -110.27132415771484,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5828739404678345,
      "rewards/margins": 7.368673801422119,
      "rewards/rejected": -5.785799980163574,
      "step": 2126
    },
    {
      "epoch": 0.8508,
      "grad_norm": 3.948899507522583,
      "learning_rate": 7.165333333333333e-07,
      "logits/chosen": -2.862393379211426,
      "logits/rejected": -2.4486942291259766,
      "logps/chosen": -97.98185729980469,
      "logps/rejected": -199.18405151367188,
      "loss": 0.0482,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1986324787139893,
      "rewards/margins": 3.172791004180908,
      "rewards/rejected": -4.371423244476318,
      "step": 2127
    },
    {
      "epoch": 0.8512,
      "grad_norm": 1.1225061416625977,
      "learning_rate": 7.164e-07,
      "logits/chosen": -2.8077964782714844,
      "logits/rejected": -2.281618356704712,
      "logps/chosen": -117.43621826171875,
      "logps/rejected": -249.4725799560547,
      "loss": 0.0131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8620179891586304,
      "rewards/margins": 5.639162063598633,
      "rewards/rejected": -4.777143955230713,
      "step": 2128
    },
    {
      "epoch": 0.8516,
      "grad_norm": 5.7964372634887695,
      "learning_rate": 7.162666666666667e-07,
      "logits/chosen": -3.024308204650879,
      "logits/rejected": -2.678654670715332,
      "logps/chosen": -78.01024627685547,
      "logps/rejected": -79.63938903808594,
      "loss": 0.0728,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.18925990164279938,
      "rewards/margins": 3.8852174282073975,
      "rewards/rejected": -4.074477195739746,
      "step": 2129
    },
    {
      "epoch": 0.852,
      "grad_norm": 0.33123910427093506,
      "learning_rate": 7.161333333333332e-07,
      "logits/chosen": -2.746802806854248,
      "logits/rejected": -2.0962305068969727,
      "logps/chosen": -50.87693786621094,
      "logps/rejected": -119.7776870727539,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0154575109481812,
      "rewards/margins": 7.007674217224121,
      "rewards/rejected": -5.99221658706665,
      "step": 2130
    },
    {
      "epoch": 0.8524,
      "grad_norm": 0.4647917151451111,
      "learning_rate": 7.159999999999999e-07,
      "logits/chosen": -2.771588087081909,
      "logits/rejected": -1.7217234373092651,
      "logps/chosen": -102.94869995117188,
      "logps/rejected": -177.37246704101562,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0724352598190308,
      "rewards/margins": 9.334708213806152,
      "rewards/rejected": -8.262272834777832,
      "step": 2131
    },
    {
      "epoch": 0.8528,
      "grad_norm": 2.981283187866211,
      "learning_rate": 7.158666666666666e-07,
      "logits/chosen": -3.1129157543182373,
      "logits/rejected": -2.6188254356384277,
      "logps/chosen": -48.277156829833984,
      "logps/rejected": -71.46495056152344,
      "loss": 0.0421,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23906366527080536,
      "rewards/margins": 4.292304039001465,
      "rewards/rejected": -4.053239822387695,
      "step": 2132
    },
    {
      "epoch": 0.8532,
      "grad_norm": 7.37447452545166,
      "learning_rate": 7.157333333333333e-07,
      "logits/chosen": -3.1284828186035156,
      "logits/rejected": -2.6591124534606934,
      "logps/chosen": -74.67279815673828,
      "logps/rejected": -107.32579040527344,
      "loss": 0.0967,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.204346776008606,
      "rewards/margins": 4.848095417022705,
      "rewards/rejected": -6.05244255065918,
      "step": 2133
    },
    {
      "epoch": 0.8536,
      "grad_norm": 0.5392460227012634,
      "learning_rate": 7.156e-07,
      "logits/chosen": -2.839064121246338,
      "logits/rejected": -2.1861929893493652,
      "logps/chosen": -75.162109375,
      "logps/rejected": -142.6923370361328,
      "loss": 0.0045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4785901308059692,
      "rewards/margins": 9.512280464172363,
      "rewards/rejected": -8.033690452575684,
      "step": 2134
    },
    {
      "epoch": 0.854,
      "grad_norm": 1.1045525074005127,
      "learning_rate": 7.154666666666667e-07,
      "logits/chosen": -2.8821754455566406,
      "logits/rejected": -2.4372522830963135,
      "logps/chosen": -71.77609252929688,
      "logps/rejected": -170.39822387695312,
      "loss": 0.012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0303730964660645,
      "rewards/margins": 6.114744663238525,
      "rewards/rejected": -5.084372043609619,
      "step": 2135
    },
    {
      "epoch": 0.8544,
      "grad_norm": 2.2807533740997314,
      "learning_rate": 7.153333333333334e-07,
      "logits/chosen": -3.0058796405792236,
      "logits/rejected": -3.0879294872283936,
      "logps/chosen": -62.88050842285156,
      "logps/rejected": -83.39924621582031,
      "loss": 0.0302,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0054759979248046875,
      "rewards/margins": 3.4872989654541016,
      "rewards/rejected": -3.4927749633789062,
      "step": 2136
    },
    {
      "epoch": 0.8548,
      "grad_norm": 21.43122100830078,
      "learning_rate": 7.151999999999999e-07,
      "logits/chosen": -2.8260905742645264,
      "logits/rejected": -2.574193000793457,
      "logps/chosen": -148.77920532226562,
      "logps/rejected": -122.99022674560547,
      "loss": 0.1199,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.801032781600952,
      "rewards/margins": 2.7349131107330322,
      "rewards/rejected": -5.535945892333984,
      "step": 2137
    },
    {
      "epoch": 0.8552,
      "grad_norm": 2.8600692749023438,
      "learning_rate": 7.150666666666666e-07,
      "logits/chosen": -2.730937957763672,
      "logits/rejected": -2.2293856143951416,
      "logps/chosen": -131.9915008544922,
      "logps/rejected": -139.31216430664062,
      "loss": 0.021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6195752620697021,
      "rewards/margins": 6.9615325927734375,
      "rewards/rejected": -5.341957092285156,
      "step": 2138
    },
    {
      "epoch": 0.8556,
      "grad_norm": 0.04162104055285454,
      "learning_rate": 7.149333333333333e-07,
      "logits/chosen": -3.012481451034546,
      "logits/rejected": -2.419823169708252,
      "logps/chosen": -59.34619903564453,
      "logps/rejected": -124.90960693359375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6971979141235352,
      "rewards/margins": 7.961421012878418,
      "rewards/rejected": -7.264223575592041,
      "step": 2139
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.035853441804647446,
      "learning_rate": 7.147999999999999e-07,
      "logits/chosen": -3.2058465480804443,
      "logits/rejected": -2.264594793319702,
      "logps/chosen": -76.303955078125,
      "logps/rejected": -144.55894470214844,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2577098608016968,
      "rewards/margins": 9.211288452148438,
      "rewards/rejected": -7.953577995300293,
      "step": 2140
    },
    {
      "epoch": 0.8564,
      "grad_norm": 0.6112643480300903,
      "learning_rate": 7.146666666666666e-07,
      "logits/chosen": -3.0034992694854736,
      "logits/rejected": -2.508208990097046,
      "logps/chosen": -113.93882751464844,
      "logps/rejected": -111.15939331054688,
      "loss": 0.0061,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6315956115722656,
      "rewards/margins": 5.169877052307129,
      "rewards/rejected": -5.8014726638793945,
      "step": 2141
    },
    {
      "epoch": 0.8568,
      "grad_norm": 1.1320044994354248,
      "learning_rate": 7.145333333333333e-07,
      "logits/chosen": -2.3316898345947266,
      "logits/rejected": -1.471218466758728,
      "logps/chosen": -204.88172912597656,
      "logps/rejected": -165.6307373046875,
      "loss": 0.0065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9835792779922485,
      "rewards/margins": 5.146056175231934,
      "rewards/rejected": -7.129634857177734,
      "step": 2142
    },
    {
      "epoch": 0.8572,
      "grad_norm": 0.33868607878685,
      "learning_rate": 7.144e-07,
      "logits/chosen": -2.9115495681762695,
      "logits/rejected": -2.076148509979248,
      "logps/chosen": -82.78304290771484,
      "logps/rejected": -139.07742309570312,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7028011083602905,
      "rewards/margins": 8.84007453918457,
      "rewards/rejected": -8.137273788452148,
      "step": 2143
    },
    {
      "epoch": 0.8576,
      "grad_norm": 0.7725503444671631,
      "learning_rate": 7.142666666666667e-07,
      "logits/chosen": -2.8196282386779785,
      "logits/rejected": -2.1852216720581055,
      "logps/chosen": -167.01824951171875,
      "logps/rejected": -185.3406982421875,
      "loss": 0.0063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0023338794708252,
      "rewards/margins": 6.1214518547058105,
      "rewards/rejected": -7.123785972595215,
      "step": 2144
    },
    {
      "epoch": 0.858,
      "grad_norm": 0.5569837093353271,
      "learning_rate": 7.141333333333333e-07,
      "logits/chosen": -3.309643268585205,
      "logits/rejected": -2.9624111652374268,
      "logps/chosen": -63.388328552246094,
      "logps/rejected": -107.7757339477539,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7668561935424805,
      "rewards/margins": 5.6836442947387695,
      "rewards/rejected": -6.45050048828125,
      "step": 2145
    },
    {
      "epoch": 0.8584,
      "grad_norm": 11.964147567749023,
      "learning_rate": 7.14e-07,
      "logits/chosen": -2.758765697479248,
      "logits/rejected": -2.36411190032959,
      "logps/chosen": -94.73472595214844,
      "logps/rejected": -83.12873840332031,
      "loss": 0.1911,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015850067138671875,
      "rewards/margins": 4.670657634735107,
      "rewards/rejected": -4.654808044433594,
      "step": 2146
    },
    {
      "epoch": 0.8588,
      "grad_norm": 0.5446395874023438,
      "learning_rate": 7.138666666666667e-07,
      "logits/chosen": -2.726040840148926,
      "logits/rejected": -2.1216840744018555,
      "logps/chosen": -101.30908203125,
      "logps/rejected": -132.47171020507812,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8835827112197876,
      "rewards/margins": 7.915419578552246,
      "rewards/rejected": -7.03183650970459,
      "step": 2147
    },
    {
      "epoch": 0.8592,
      "grad_norm": 0.09498389065265656,
      "learning_rate": 7.137333333333333e-07,
      "logits/chosen": -3.047393798828125,
      "logits/rejected": -2.1759986877441406,
      "logps/chosen": -93.8592758178711,
      "logps/rejected": -134.6202392578125,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7519641518592834,
      "rewards/margins": 8.122931480407715,
      "rewards/rejected": -7.370967388153076,
      "step": 2148
    },
    {
      "epoch": 0.8596,
      "grad_norm": 0.13089297711849213,
      "learning_rate": 7.135999999999999e-07,
      "logits/chosen": -2.724734306335449,
      "logits/rejected": -2.1827642917633057,
      "logps/chosen": -98.29103088378906,
      "logps/rejected": -129.39149475097656,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3705596923828125,
      "rewards/margins": 6.7589569091796875,
      "rewards/rejected": -7.1295166015625,
      "step": 2149
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6186590194702148,
      "learning_rate": 7.134666666666666e-07,
      "logits/chosen": -3.0536179542541504,
      "logits/rejected": -2.8597493171691895,
      "logps/chosen": -78.51289367675781,
      "logps/rejected": -129.01394653320312,
      "loss": 0.0065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.046133995056152344,
      "rewards/margins": 5.1168212890625,
      "rewards/rejected": -5.162955284118652,
      "step": 2150
    },
    {
      "epoch": 0.8604,
      "grad_norm": 0.3378836512565613,
      "learning_rate": 7.133333333333333e-07,
      "logits/chosen": -3.2104928493499756,
      "logits/rejected": -2.6209983825683594,
      "logps/chosen": -67.42203521728516,
      "logps/rejected": -101.50682067871094,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2926349639892578,
      "rewards/margins": 5.770840644836426,
      "rewards/rejected": -5.478205680847168,
      "step": 2151
    },
    {
      "epoch": 0.8608,
      "grad_norm": 0.6182756423950195,
      "learning_rate": 7.131999999999999e-07,
      "logits/chosen": -2.93292236328125,
      "logits/rejected": -2.5915732383728027,
      "logps/chosen": -69.023681640625,
      "logps/rejected": -89.05180358886719,
      "loss": 0.0067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.37271690368652344,
      "rewards/margins": 5.137264251708984,
      "rewards/rejected": -4.764547348022461,
      "step": 2152
    },
    {
      "epoch": 0.8612,
      "grad_norm": 1.5294305086135864,
      "learning_rate": 7.130666666666666e-07,
      "logits/chosen": -2.8365955352783203,
      "logits/rejected": -2.446986436843872,
      "logps/chosen": -90.03468322753906,
      "logps/rejected": -149.56689453125,
      "loss": 0.0145,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2978740334510803,
      "rewards/margins": 6.100305557250977,
      "rewards/rejected": -5.802431583404541,
      "step": 2153
    },
    {
      "epoch": 0.8616,
      "grad_norm": 0.24455061554908752,
      "learning_rate": 7.129333333333333e-07,
      "logits/chosen": -2.9729080200195312,
      "logits/rejected": -2.6269514560699463,
      "logps/chosen": -118.99889373779297,
      "logps/rejected": -107.1826171875,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.096581220626831,
      "rewards/margins": 6.414506912231445,
      "rewards/rejected": -5.317925453186035,
      "step": 2154
    },
    {
      "epoch": 0.862,
      "grad_norm": 0.15938717126846313,
      "learning_rate": 7.128e-07,
      "logits/chosen": -2.7643027305603027,
      "logits/rejected": -1.9143321514129639,
      "logps/chosen": -86.46926879882812,
      "logps/rejected": -137.96766662597656,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1272876262664795,
      "rewards/margins": 7.914643287658691,
      "rewards/rejected": -6.787355422973633,
      "step": 2155
    },
    {
      "epoch": 0.8624,
      "grad_norm": 0.7759724259376526,
      "learning_rate": 7.126666666666667e-07,
      "logits/chosen": -2.973393440246582,
      "logits/rejected": -2.5120620727539062,
      "logps/chosen": -97.08673095703125,
      "logps/rejected": -125.52561950683594,
      "loss": 0.007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.28009453415870667,
      "rewards/margins": 5.414576530456543,
      "rewards/rejected": -5.694670677185059,
      "step": 2156
    },
    {
      "epoch": 0.8628,
      "grad_norm": 7.531761169433594,
      "learning_rate": 7.125333333333334e-07,
      "logits/chosen": -2.2427072525024414,
      "logits/rejected": -1.6205804347991943,
      "logps/chosen": -209.6142578125,
      "logps/rejected": -196.939208984375,
      "loss": 0.0397,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.817080020904541,
      "rewards/margins": 4.864432334899902,
      "rewards/rejected": -6.681511878967285,
      "step": 2157
    },
    {
      "epoch": 0.8632,
      "grad_norm": 0.1449039876461029,
      "learning_rate": 7.124e-07,
      "logits/chosen": -3.1506240367889404,
      "logits/rejected": -2.553757667541504,
      "logps/chosen": -92.73953247070312,
      "logps/rejected": -118.35057067871094,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7562679052352905,
      "rewards/margins": 6.862020492553711,
      "rewards/rejected": -6.105751991271973,
      "step": 2158
    },
    {
      "epoch": 0.8636,
      "grad_norm": 0.14795129001140594,
      "learning_rate": 7.122666666666666e-07,
      "logits/chosen": -2.8417086601257324,
      "logits/rejected": -2.7449846267700195,
      "logps/chosen": -77.86653137207031,
      "logps/rejected": -106.21062469482422,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6208595633506775,
      "rewards/margins": 6.529623985290527,
      "rewards/rejected": -5.908764839172363,
      "step": 2159
    },
    {
      "epoch": 0.864,
      "grad_norm": 1.792284369468689,
      "learning_rate": 7.121333333333332e-07,
      "logits/chosen": -3.0095510482788086,
      "logits/rejected": -2.572575569152832,
      "logps/chosen": -105.46513366699219,
      "logps/rejected": -109.97323608398438,
      "loss": 0.015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8082931637763977,
      "rewards/margins": 5.968061447143555,
      "rewards/rejected": -6.776354789733887,
      "step": 2160
    },
    {
      "epoch": 0.8644,
      "grad_norm": 1.066406011581421,
      "learning_rate": 7.119999999999999e-07,
      "logits/chosen": -2.6649155616760254,
      "logits/rejected": -1.9682384729385376,
      "logps/chosen": -133.63645935058594,
      "logps/rejected": -145.33547973632812,
      "loss": 0.0078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7641860842704773,
      "rewards/margins": 5.931049346923828,
      "rewards/rejected": -6.695235252380371,
      "step": 2161
    },
    {
      "epoch": 0.8648,
      "grad_norm": 0.1666109561920166,
      "learning_rate": 7.118666666666666e-07,
      "logits/chosen": -2.795525550842285,
      "logits/rejected": -2.344015598297119,
      "logps/chosen": -88.70291900634766,
      "logps/rejected": -129.72030639648438,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5639150738716125,
      "rewards/margins": 7.012005805969238,
      "rewards/rejected": -6.448090553283691,
      "step": 2162
    },
    {
      "epoch": 0.8652,
      "grad_norm": 2.913592576980591,
      "learning_rate": 7.117333333333333e-07,
      "logits/chosen": -2.899679183959961,
      "logits/rejected": -2.7509264945983887,
      "logps/chosen": -101.92866516113281,
      "logps/rejected": -123.92390441894531,
      "loss": 0.0253,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9204632043838501,
      "rewards/margins": 5.270397186279297,
      "rewards/rejected": -6.190860748291016,
      "step": 2163
    },
    {
      "epoch": 0.8656,
      "grad_norm": 0.1149846613407135,
      "learning_rate": 7.116e-07,
      "logits/chosen": -2.642570734024048,
      "logits/rejected": -2.14775013923645,
      "logps/chosen": -121.73851776123047,
      "logps/rejected": -233.85604858398438,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.020975887775421143,
      "rewards/margins": 9.292109489440918,
      "rewards/rejected": -9.313085556030273,
      "step": 2164
    },
    {
      "epoch": 0.866,
      "grad_norm": 0.005203936714679003,
      "learning_rate": 7.114666666666667e-07,
      "logits/chosen": -2.741558313369751,
      "logits/rejected": -1.9423792362213135,
      "logps/chosen": -83.37047576904297,
      "logps/rejected": -157.0996856689453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.400303840637207,
      "rewards/margins": 10.732542991638184,
      "rewards/rejected": -9.332239151000977,
      "step": 2165
    },
    {
      "epoch": 0.8664,
      "grad_norm": 5.256752967834473,
      "learning_rate": 7.113333333333334e-07,
      "logits/chosen": -2.6790246963500977,
      "logits/rejected": -2.5158841609954834,
      "logps/chosen": -122.95042419433594,
      "logps/rejected": -81.32254028320312,
      "loss": 0.062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3761551082134247,
      "rewards/margins": 2.9190468788146973,
      "rewards/rejected": -3.2952022552490234,
      "step": 2166
    },
    {
      "epoch": 0.8668,
      "grad_norm": 0.03311591222882271,
      "learning_rate": 7.112000000000001e-07,
      "logits/chosen": -3.138667583465576,
      "logits/rejected": -2.4971957206726074,
      "logps/chosen": -65.80754089355469,
      "logps/rejected": -180.50697326660156,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17473027110099792,
      "rewards/margins": 8.582286834716797,
      "rewards/rejected": -8.40755558013916,
      "step": 2167
    },
    {
      "epoch": 0.8672,
      "grad_norm": 4.295504570007324,
      "learning_rate": 7.110666666666665e-07,
      "logits/chosen": -3.0117154121398926,
      "logits/rejected": -2.49328351020813,
      "logps/chosen": -79.62195587158203,
      "logps/rejected": -115.3305892944336,
      "loss": 0.0376,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25230997800827026,
      "rewards/margins": 7.128424167633057,
      "rewards/rejected": -6.876114368438721,
      "step": 2168
    },
    {
      "epoch": 0.8676,
      "grad_norm": 0.03174032270908356,
      "learning_rate": 7.109333333333332e-07,
      "logits/chosen": -2.4224343299865723,
      "logits/rejected": -1.6730406284332275,
      "logps/chosen": -107.92593383789062,
      "logps/rejected": -173.4091796875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1485798358917236,
      "rewards/margins": 10.914892196655273,
      "rewards/rejected": -9.766311645507812,
      "step": 2169
    },
    {
      "epoch": 0.868,
      "grad_norm": 0.17516422271728516,
      "learning_rate": 7.107999999999999e-07,
      "logits/chosen": -3.063732624053955,
      "logits/rejected": -2.3240578174591064,
      "logps/chosen": -92.63331604003906,
      "logps/rejected": -186.25192260742188,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2159988284111023,
      "rewards/margins": 6.820722579956055,
      "rewards/rejected": -7.036721229553223,
      "step": 2170
    },
    {
      "epoch": 0.8684,
      "grad_norm": 1.9507423639297485,
      "learning_rate": 7.106666666666666e-07,
      "logits/chosen": -2.872096061706543,
      "logits/rejected": -2.6172211170196533,
      "logps/chosen": -104.95059967041016,
      "logps/rejected": -123.98027801513672,
      "loss": 0.0144,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08996086567640305,
      "rewards/margins": 6.3592848777771,
      "rewards/rejected": -6.449245452880859,
      "step": 2171
    },
    {
      "epoch": 0.8688,
      "grad_norm": 5.118702411651611,
      "learning_rate": 7.105333333333333e-07,
      "logits/chosen": -3.2198688983917236,
      "logits/rejected": -3.006204128265381,
      "logps/chosen": -64.5464096069336,
      "logps/rejected": -79.98982238769531,
      "loss": 0.0712,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09230613708496094,
      "rewards/margins": 4.984776496887207,
      "rewards/rejected": -4.892470359802246,
      "step": 2172
    },
    {
      "epoch": 0.8692,
      "grad_norm": 0.10516038537025452,
      "learning_rate": 7.104e-07,
      "logits/chosen": -3.0463294982910156,
      "logits/rejected": -2.3543200492858887,
      "logps/chosen": -68.67322540283203,
      "logps/rejected": -131.04405212402344,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1691370010375977,
      "rewards/margins": 8.856328010559082,
      "rewards/rejected": -6.687191009521484,
      "step": 2173
    },
    {
      "epoch": 0.8696,
      "grad_norm": 84.57337951660156,
      "learning_rate": 7.102666666666667e-07,
      "logits/chosen": -2.524916410446167,
      "logits/rejected": -2.2004687786102295,
      "logps/chosen": -135.065673828125,
      "logps/rejected": -106.38011932373047,
      "loss": 3.5021,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -4.642367839813232,
      "rewards/margins": 0.5772593021392822,
      "rewards/rejected": -5.219627380371094,
      "step": 2174
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.7746126651763916,
      "learning_rate": 7.101333333333333e-07,
      "logits/chosen": -3.088010311126709,
      "logits/rejected": -2.68526554107666,
      "logps/chosen": -71.93860626220703,
      "logps/rejected": -79.48228454589844,
      "loss": 0.0391,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7529277801513672,
      "rewards/margins": 4.588661193847656,
      "rewards/rejected": -3.835732936859131,
      "step": 2175
    },
    {
      "epoch": 0.8704,
      "grad_norm": 5.8435959815979,
      "learning_rate": 7.1e-07,
      "logits/chosen": -2.6588234901428223,
      "logits/rejected": -2.1778972148895264,
      "logps/chosen": -105.75505828857422,
      "logps/rejected": -105.21273040771484,
      "loss": 0.0562,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6095710396766663,
      "rewards/margins": 5.8167290687561035,
      "rewards/rejected": -5.207158088684082,
      "step": 2176
    },
    {
      "epoch": 0.8708,
      "grad_norm": 0.01354204211384058,
      "learning_rate": 7.098666666666666e-07,
      "logits/chosen": -2.2575454711914062,
      "logits/rejected": -1.618041753768921,
      "logps/chosen": -249.21246337890625,
      "logps/rejected": -219.35768127441406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5289887189865112,
      "rewards/margins": 9.430645942687988,
      "rewards/rejected": -8.901657104492188,
      "step": 2177
    },
    {
      "epoch": 0.8712,
      "grad_norm": 0.05723024532198906,
      "learning_rate": 7.097333333333333e-07,
      "logits/chosen": -2.758016347885132,
      "logits/rejected": -1.833611011505127,
      "logps/chosen": -168.92977905273438,
      "logps/rejected": -172.12603759765625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4644172787666321,
      "rewards/margins": 9.380488395690918,
      "rewards/rejected": -8.916070938110352,
      "step": 2178
    },
    {
      "epoch": 0.8716,
      "grad_norm": 1.1547409296035767,
      "learning_rate": 7.096e-07,
      "logits/chosen": -2.7041945457458496,
      "logits/rejected": -2.171666145324707,
      "logps/chosen": -122.44873046875,
      "logps/rejected": -135.07818603515625,
      "loss": 0.0095,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31297722458839417,
      "rewards/margins": 6.40972375869751,
      "rewards/rejected": -6.096746444702148,
      "step": 2179
    },
    {
      "epoch": 0.872,
      "grad_norm": 4.838324069976807,
      "learning_rate": 7.094666666666666e-07,
      "logits/chosen": -2.7476792335510254,
      "logits/rejected": -2.376831531524658,
      "logps/chosen": -173.5928497314453,
      "logps/rejected": -144.2179718017578,
      "loss": 0.0382,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.594018578529358,
      "rewards/margins": 5.262081623077393,
      "rewards/rejected": -6.856100082397461,
      "step": 2180
    },
    {
      "epoch": 0.8724,
      "grad_norm": 1.7124805450439453,
      "learning_rate": 7.093333333333333e-07,
      "logits/chosen": -2.6947836875915527,
      "logits/rejected": -1.9047603607177734,
      "logps/chosen": -156.16490173339844,
      "logps/rejected": -180.44903564453125,
      "loss": 0.0094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.3452751636505127,
      "rewards/margins": 8.357002258300781,
      "rewards/rejected": -10.702277183532715,
      "step": 2181
    },
    {
      "epoch": 0.8728,
      "grad_norm": 0.5119317770004272,
      "learning_rate": 7.092e-07,
      "logits/chosen": -3.0689611434936523,
      "logits/rejected": -2.767772674560547,
      "logps/chosen": -66.77395629882812,
      "logps/rejected": -85.78166198730469,
      "loss": 0.0061,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.584994912147522,
      "rewards/margins": 5.330158233642578,
      "rewards/rejected": -4.7451629638671875,
      "step": 2182
    },
    {
      "epoch": 0.8732,
      "grad_norm": 0.035039957612752914,
      "learning_rate": 7.090666666666666e-07,
      "logits/chosen": -3.1926560401916504,
      "logits/rejected": -2.4651358127593994,
      "logps/chosen": -46.24571228027344,
      "logps/rejected": -166.94007873535156,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7764116525650024,
      "rewards/margins": 9.168937683105469,
      "rewards/rejected": -8.392526626586914,
      "step": 2183
    },
    {
      "epoch": 0.8736,
      "grad_norm": 0.6806619763374329,
      "learning_rate": 7.089333333333333e-07,
      "logits/chosen": -2.785008430480957,
      "logits/rejected": -2.183804988861084,
      "logps/chosen": -96.85882568359375,
      "logps/rejected": -190.59579467773438,
      "loss": 0.0068,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6084892749786377,
      "rewards/margins": 9.940465927124023,
      "rewards/rejected": -9.331975936889648,
      "step": 2184
    },
    {
      "epoch": 0.874,
      "grad_norm": 1.5019491910934448,
      "learning_rate": 7.088e-07,
      "logits/chosen": -2.8593931198120117,
      "logits/rejected": -2.464232921600342,
      "logps/chosen": -99.59551239013672,
      "logps/rejected": -106.31515502929688,
      "loss": 0.013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10976371169090271,
      "rewards/margins": 5.376093864440918,
      "rewards/rejected": -5.4858574867248535,
      "step": 2185
    },
    {
      "epoch": 0.8744,
      "grad_norm": 0.04598267748951912,
      "learning_rate": 7.086666666666667e-07,
      "logits/chosen": -3.129456043243408,
      "logits/rejected": -2.480717182159424,
      "logps/chosen": -54.13548278808594,
      "logps/rejected": -142.29388427734375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9231010675430298,
      "rewards/margins": 9.011917114257812,
      "rewards/rejected": -8.088815689086914,
      "step": 2186
    },
    {
      "epoch": 0.8748,
      "grad_norm": 1.8847118616104126,
      "learning_rate": 7.085333333333333e-07,
      "logits/chosen": -2.811697006225586,
      "logits/rejected": -2.345278739929199,
      "logps/chosen": -160.49996948242188,
      "logps/rejected": -103.19454956054688,
      "loss": 0.02,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9797424674034119,
      "rewards/margins": 4.318891525268555,
      "rewards/rejected": -5.2986345291137695,
      "step": 2187
    },
    {
      "epoch": 0.8752,
      "grad_norm": 2.443584680557251,
      "learning_rate": 7.084e-07,
      "logits/chosen": -3.0846283435821533,
      "logits/rejected": -2.9554643630981445,
      "logps/chosen": -86.62277221679688,
      "logps/rejected": -81.65345764160156,
      "loss": 0.0304,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.13158416748046875,
      "rewards/margins": 4.545973777770996,
      "rewards/rejected": -4.677557945251465,
      "step": 2188
    },
    {
      "epoch": 0.8756,
      "grad_norm": 1.2815725803375244,
      "learning_rate": 7.082666666666667e-07,
      "logits/chosen": -2.943009853363037,
      "logits/rejected": -2.366513729095459,
      "logps/chosen": -98.37860870361328,
      "logps/rejected": -123.24626922607422,
      "loss": 0.0131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4438132345676422,
      "rewards/margins": 7.122354030609131,
      "rewards/rejected": -6.6785407066345215,
      "step": 2189
    },
    {
      "epoch": 0.876,
      "grad_norm": 1.7026818990707397,
      "learning_rate": 7.081333333333332e-07,
      "logits/chosen": -3.0581815242767334,
      "logits/rejected": -2.7703399658203125,
      "logps/chosen": -75.63235473632812,
      "logps/rejected": -80.66557312011719,
      "loss": 0.0172,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13950157165527344,
      "rewards/margins": 4.463983058929443,
      "rewards/rejected": -4.32448148727417,
      "step": 2190
    },
    {
      "epoch": 0.8764,
      "grad_norm": 22.444252014160156,
      "learning_rate": 7.079999999999999e-07,
      "logits/chosen": -2.7960100173950195,
      "logits/rejected": -2.448777198791504,
      "logps/chosen": -158.47036743164062,
      "logps/rejected": -125.70246124267578,
      "loss": 0.1118,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6295541524887085,
      "rewards/margins": 5.307524681091309,
      "rewards/rejected": -6.937079429626465,
      "step": 2191
    },
    {
      "epoch": 0.8768,
      "grad_norm": 0.5917840003967285,
      "learning_rate": 7.078666666666666e-07,
      "logits/chosen": -2.4807214736938477,
      "logits/rejected": -1.7130481004714966,
      "logps/chosen": -81.62316131591797,
      "logps/rejected": -114.48656463623047,
      "loss": 0.0056,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4391666352748871,
      "rewards/margins": 6.981222629547119,
      "rewards/rejected": -6.542056083679199,
      "step": 2192
    },
    {
      "epoch": 0.8772,
      "grad_norm": 6.916147232055664,
      "learning_rate": 7.077333333333333e-07,
      "logits/chosen": -2.9178054332733154,
      "logits/rejected": -2.6462242603302,
      "logps/chosen": -97.35574340820312,
      "logps/rejected": -91.97261047363281,
      "loss": 0.0643,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6455976963043213,
      "rewards/margins": 3.179682731628418,
      "rewards/rejected": -4.82528018951416,
      "step": 2193
    },
    {
      "epoch": 0.8776,
      "grad_norm": 0.21827150881290436,
      "learning_rate": 7.076e-07,
      "logits/chosen": -3.0141069889068604,
      "logits/rejected": -2.296175479888916,
      "logps/chosen": -88.1559066772461,
      "logps/rejected": -214.71983337402344,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.11243055760860443,
      "rewards/margins": 9.826886177062988,
      "rewards/rejected": -9.939316749572754,
      "step": 2194
    },
    {
      "epoch": 0.878,
      "grad_norm": 1.3736344575881958,
      "learning_rate": 7.074666666666667e-07,
      "logits/chosen": -2.6333236694335938,
      "logits/rejected": -1.973144292831421,
      "logps/chosen": -174.19125366210938,
      "logps/rejected": -126.43302917480469,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6283783912658691,
      "rewards/margins": 5.037790298461914,
      "rewards/rejected": -6.666168689727783,
      "step": 2195
    },
    {
      "epoch": 0.8784,
      "grad_norm": 0.3029094636440277,
      "learning_rate": 7.073333333333333e-07,
      "logits/chosen": -2.755333423614502,
      "logits/rejected": -2.156771183013916,
      "logps/chosen": -120.62785339355469,
      "logps/rejected": -170.8023681640625,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0760889053344727,
      "rewards/margins": 7.388486385345459,
      "rewards/rejected": -9.464574813842773,
      "step": 2196
    },
    {
      "epoch": 0.8788,
      "grad_norm": 0.11575224250555038,
      "learning_rate": 7.072e-07,
      "logits/chosen": -2.808415412902832,
      "logits/rejected": -2.4805994033813477,
      "logps/chosen": -128.92604064941406,
      "logps/rejected": -128.76718139648438,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5374076962471008,
      "rewards/margins": 7.64277458190918,
      "rewards/rejected": -8.180182456970215,
      "step": 2197
    },
    {
      "epoch": 0.8792,
      "grad_norm": 1.6535199880599976,
      "learning_rate": 7.070666666666666e-07,
      "logits/chosen": -2.815908432006836,
      "logits/rejected": -2.231414794921875,
      "logps/chosen": -64.13980865478516,
      "logps/rejected": -123.27593231201172,
      "loss": 0.0204,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1773134469985962,
      "rewards/margins": 6.605712890625,
      "rewards/rejected": -6.428400039672852,
      "step": 2198
    },
    {
      "epoch": 0.8796,
      "grad_norm": 2.9318370819091797,
      "learning_rate": 7.069333333333333e-07,
      "logits/chosen": -3.0020089149475098,
      "logits/rejected": -2.9166836738586426,
      "logps/chosen": -96.23648834228516,
      "logps/rejected": -76.40907287597656,
      "loss": 0.0252,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1917923092842102,
      "rewards/margins": 4.211611747741699,
      "rewards/rejected": -4.019819736480713,
      "step": 2199
    },
    {
      "epoch": 0.88,
      "grad_norm": 11.464723587036133,
      "learning_rate": 7.068e-07,
      "logits/chosen": -3.0064809322357178,
      "logits/rejected": -2.627749443054199,
      "logps/chosen": -124.6370849609375,
      "logps/rejected": -104.40614318847656,
      "loss": 0.0708,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.615622341632843,
      "rewards/margins": 4.541714668273926,
      "rewards/rejected": -5.157336711883545,
      "step": 2200
    },
    {
      "epoch": 0.8804,
      "grad_norm": 0.06568146497011185,
      "learning_rate": 7.066666666666666e-07,
      "logits/chosen": -2.444509983062744,
      "logits/rejected": -1.7047178745269775,
      "logps/chosen": -133.21286010742188,
      "logps/rejected": -156.19688415527344,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2766616344451904,
      "rewards/margins": 8.396517753601074,
      "rewards/rejected": -7.119855880737305,
      "step": 2201
    },
    {
      "epoch": 0.8808,
      "grad_norm": 1.5933870077133179,
      "learning_rate": 7.065333333333333e-07,
      "logits/chosen": -2.863894462585449,
      "logits/rejected": -3.0476431846618652,
      "logps/chosen": -83.85517883300781,
      "logps/rejected": -88.02682495117188,
      "loss": 0.0229,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.13350677490234375,
      "rewards/margins": 4.401233673095703,
      "rewards/rejected": -4.534740447998047,
      "step": 2202
    },
    {
      "epoch": 0.8812,
      "grad_norm": 0.4607694149017334,
      "learning_rate": 7.064e-07,
      "logits/chosen": -2.9612221717834473,
      "logits/rejected": -2.4797258377075195,
      "logps/chosen": -108.04185485839844,
      "logps/rejected": -143.9411163330078,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7948811054229736,
      "rewards/margins": 6.665456771850586,
      "rewards/rejected": -7.4603376388549805,
      "step": 2203
    },
    {
      "epoch": 0.8816,
      "grad_norm": 1.366549015045166,
      "learning_rate": 7.062666666666667e-07,
      "logits/chosen": -3.029311180114746,
      "logits/rejected": -2.822044610977173,
      "logps/chosen": -103.6549301147461,
      "logps/rejected": -89.66453552246094,
      "loss": 0.0164,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.41313135623931885,
      "rewards/margins": 4.321781158447266,
      "rewards/rejected": -4.734912395477295,
      "step": 2204
    },
    {
      "epoch": 0.882,
      "grad_norm": 0.7858019471168518,
      "learning_rate": 7.061333333333332e-07,
      "logits/chosen": -2.790822982788086,
      "logits/rejected": -1.9822760820388794,
      "logps/chosen": -169.33203125,
      "logps/rejected": -124.61470031738281,
      "loss": 0.007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4071045219898224,
      "rewards/margins": 6.04721212387085,
      "rewards/rejected": -6.45431661605835,
      "step": 2205
    },
    {
      "epoch": 0.8824,
      "grad_norm": 3.1926310062408447,
      "learning_rate": 7.059999999999999e-07,
      "logits/chosen": -3.1992058753967285,
      "logits/rejected": -2.7800092697143555,
      "logps/chosen": -98.15975952148438,
      "logps/rejected": -91.19554138183594,
      "loss": 0.0251,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.599686861038208,
      "rewards/margins": 4.174320697784424,
      "rewards/rejected": -4.774007797241211,
      "step": 2206
    },
    {
      "epoch": 0.8828,
      "grad_norm": 0.2522628605365753,
      "learning_rate": 7.058666666666666e-07,
      "logits/chosen": -2.893686056137085,
      "logits/rejected": -2.4707958698272705,
      "logps/chosen": -97.89210510253906,
      "logps/rejected": -126.8001708984375,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5624850988388062,
      "rewards/margins": 7.788846015930176,
      "rewards/rejected": -7.226360321044922,
      "step": 2207
    },
    {
      "epoch": 0.8832,
      "grad_norm": 61.18447494506836,
      "learning_rate": 7.057333333333333e-07,
      "logits/chosen": -2.723464250564575,
      "logits/rejected": -2.408539056777954,
      "logps/chosen": -180.58535766601562,
      "logps/rejected": -102.49958038330078,
      "loss": 0.6487,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -1.7231833934783936,
      "rewards/margins": 3.4512040615081787,
      "rewards/rejected": -5.174387454986572,
      "step": 2208
    },
    {
      "epoch": 0.8836,
      "grad_norm": 0.205758199095726,
      "learning_rate": 7.056e-07,
      "logits/chosen": -2.7200489044189453,
      "logits/rejected": -2.1683590412139893,
      "logps/chosen": -187.21987915039062,
      "logps/rejected": -193.58685302734375,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2527519166469574,
      "rewards/margins": 7.08515739440918,
      "rewards/rejected": -7.337909698486328,
      "step": 2209
    },
    {
      "epoch": 0.884,
      "grad_norm": 0.25296300649642944,
      "learning_rate": 7.054666666666667e-07,
      "logits/chosen": -2.978318214416504,
      "logits/rejected": -2.1040923595428467,
      "logps/chosen": -98.22637176513672,
      "logps/rejected": -129.2830047607422,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.905247151851654,
      "rewards/margins": 7.479257583618164,
      "rewards/rejected": -6.574010848999023,
      "step": 2210
    },
    {
      "epoch": 0.8844,
      "grad_norm": 0.3411557376384735,
      "learning_rate": 7.053333333333333e-07,
      "logits/chosen": -2.8390626907348633,
      "logits/rejected": -2.2139737606048584,
      "logps/chosen": -146.0443572998047,
      "logps/rejected": -123.00454711914062,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.19003257155418396,
      "rewards/margins": 6.970344543457031,
      "rewards/rejected": -7.160377502441406,
      "step": 2211
    },
    {
      "epoch": 0.8848,
      "grad_norm": 0.19643595814704895,
      "learning_rate": 7.052e-07,
      "logits/chosen": -3.0148096084594727,
      "logits/rejected": -2.4150235652923584,
      "logps/chosen": -80.17033386230469,
      "logps/rejected": -177.88739013671875,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.26933616399765015,
      "rewards/margins": 9.048827171325684,
      "rewards/rejected": -9.31816291809082,
      "step": 2212
    },
    {
      "epoch": 0.8852,
      "grad_norm": 1.8488250970840454,
      "learning_rate": 7.050666666666666e-07,
      "logits/chosen": -2.806117534637451,
      "logits/rejected": -2.3246634006500244,
      "logps/chosen": -104.70120239257812,
      "logps/rejected": -145.11715698242188,
      "loss": 0.0213,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4643977880477905,
      "rewards/margins": 7.017093181610107,
      "rewards/rejected": -5.552695274353027,
      "step": 2213
    },
    {
      "epoch": 0.8856,
      "grad_norm": 0.8697666525840759,
      "learning_rate": 7.049333333333333e-07,
      "logits/chosen": -2.8407115936279297,
      "logits/rejected": -2.8385252952575684,
      "logps/chosen": -87.11831665039062,
      "logps/rejected": -90.9012451171875,
      "loss": 0.0105,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.46509018540382385,
      "rewards/margins": 4.563929557800293,
      "rewards/rejected": -4.09883975982666,
      "step": 2214
    },
    {
      "epoch": 0.886,
      "grad_norm": 0.27335530519485474,
      "learning_rate": 7.047999999999999e-07,
      "logits/chosen": -3.146996259689331,
      "logits/rejected": -2.6158227920532227,
      "logps/chosen": -72.03543090820312,
      "logps/rejected": -94.54751586914062,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2940467894077301,
      "rewards/margins": 5.734305381774902,
      "rewards/rejected": -5.440258979797363,
      "step": 2215
    },
    {
      "epoch": 0.8864,
      "grad_norm": 0.30067044496536255,
      "learning_rate": 7.046666666666666e-07,
      "logits/chosen": -3.1909334659576416,
      "logits/rejected": -2.5096795558929443,
      "logps/chosen": -90.4801025390625,
      "logps/rejected": -115.8038330078125,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5919143557548523,
      "rewards/margins": 5.819093704223633,
      "rewards/rejected": -6.411007881164551,
      "step": 2216
    },
    {
      "epoch": 0.8868,
      "grad_norm": 9.387276649475098,
      "learning_rate": 7.045333333333333e-07,
      "logits/chosen": -2.7899694442749023,
      "logits/rejected": -2.5688352584838867,
      "logps/chosen": -75.97216796875,
      "logps/rejected": -123.54742431640625,
      "loss": 0.0883,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4938061237335205,
      "rewards/margins": 5.6432719230651855,
      "rewards/rejected": -6.137078285217285,
      "step": 2217
    },
    {
      "epoch": 0.8872,
      "grad_norm": 0.253861665725708,
      "learning_rate": 7.044e-07,
      "logits/chosen": -2.9236040115356445,
      "logits/rejected": -2.3076300621032715,
      "logps/chosen": -73.48735809326172,
      "logps/rejected": -95.26759338378906,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6786690950393677,
      "rewards/margins": 6.2982563972473145,
      "rewards/rejected": -5.619587421417236,
      "step": 2218
    },
    {
      "epoch": 0.8876,
      "grad_norm": 0.21955449879169464,
      "learning_rate": 7.042666666666667e-07,
      "logits/chosen": -3.3608944416046143,
      "logits/rejected": -2.508378267288208,
      "logps/chosen": -50.76964569091797,
      "logps/rejected": -145.67730712890625,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3212427496910095,
      "rewards/margins": 8.177740097045898,
      "rewards/rejected": -8.498983383178711,
      "step": 2219
    },
    {
      "epoch": 0.888,
      "grad_norm": 4.509812355041504,
      "learning_rate": 7.041333333333334e-07,
      "logits/chosen": -2.6976962089538574,
      "logits/rejected": -2.4780325889587402,
      "logps/chosen": -86.51444244384766,
      "logps/rejected": -90.87324523925781,
      "loss": 0.0475,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0060946941375732,
      "rewards/margins": 3.6260807514190674,
      "rewards/rejected": -4.632175445556641,
      "step": 2220
    },
    {
      "epoch": 0.8884,
      "grad_norm": 0.239800363779068,
      "learning_rate": 7.04e-07,
      "logits/chosen": -2.8325986862182617,
      "logits/rejected": -2.151540756225586,
      "logps/chosen": -132.67041015625,
      "logps/rejected": -182.35800170898438,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.26838457584381104,
      "rewards/margins": 6.90850830078125,
      "rewards/rejected": -7.176892280578613,
      "step": 2221
    },
    {
      "epoch": 0.8888,
      "grad_norm": 0.5344347953796387,
      "learning_rate": 7.038666666666666e-07,
      "logits/chosen": -3.053253650665283,
      "logits/rejected": -2.465862274169922,
      "logps/chosen": -116.46186828613281,
      "logps/rejected": -113.29934692382812,
      "loss": 0.0049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9868740439414978,
      "rewards/margins": 5.313478469848633,
      "rewards/rejected": -6.300352096557617,
      "step": 2222
    },
    {
      "epoch": 0.8892,
      "grad_norm": 1.6778326034545898,
      "learning_rate": 7.037333333333333e-07,
      "logits/chosen": -2.6218833923339844,
      "logits/rejected": -2.152606725692749,
      "logps/chosen": -107.32414245605469,
      "logps/rejected": -94.50541687011719,
      "loss": 0.03,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.027469642460346222,
      "rewards/margins": 5.35860013961792,
      "rewards/rejected": -5.386069297790527,
      "step": 2223
    },
    {
      "epoch": 0.8896,
      "grad_norm": 0.03309807553887367,
      "learning_rate": 7.035999999999999e-07,
      "logits/chosen": -3.114254951477051,
      "logits/rejected": -2.4876937866210938,
      "logps/chosen": -108.94645690917969,
      "logps/rejected": -141.11660766601562,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7710292935371399,
      "rewards/margins": 8.167017936706543,
      "rewards/rejected": -8.938047409057617,
      "step": 2224
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.12265662848949432,
      "learning_rate": 7.034666666666666e-07,
      "logits/chosen": -2.7638349533081055,
      "logits/rejected": -2.21929669380188,
      "logps/chosen": -70.27224731445312,
      "logps/rejected": -116.74856567382812,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.043710708618164,
      "rewards/margins": 7.411959648132324,
      "rewards/rejected": -6.368249416351318,
      "step": 2225
    },
    {
      "epoch": 0.8904,
      "grad_norm": 0.7436694502830505,
      "learning_rate": 7.033333333333333e-07,
      "logits/chosen": -3.0918755531311035,
      "logits/rejected": -2.6027309894561768,
      "logps/chosen": -69.19216918945312,
      "logps/rejected": -125.76507568359375,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.23090973496437073,
      "rewards/margins": 6.655324459075928,
      "rewards/rejected": -6.886234283447266,
      "step": 2226
    },
    {
      "epoch": 0.8908,
      "grad_norm": 0.13870586454868317,
      "learning_rate": 7.032e-07,
      "logits/chosen": -3.00398588180542,
      "logits/rejected": -2.315211772918701,
      "logps/chosen": -77.4301528930664,
      "logps/rejected": -112.89717102050781,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3711121082305908,
      "rewards/margins": 7.387506008148193,
      "rewards/rejected": -6.016393661499023,
      "step": 2227
    },
    {
      "epoch": 0.8912,
      "grad_norm": 14.908795356750488,
      "learning_rate": 7.030666666666666e-07,
      "logits/chosen": -3.022233009338379,
      "logits/rejected": -3.04278564453125,
      "logps/chosen": -84.64275360107422,
      "logps/rejected": -61.5450325012207,
      "loss": 0.1132,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.128610610961914,
      "rewards/margins": 2.2721335887908936,
      "rewards/rejected": -3.4007441997528076,
      "step": 2228
    },
    {
      "epoch": 0.8916,
      "grad_norm": 0.03095705807209015,
      "learning_rate": 7.029333333333333e-07,
      "logits/chosen": -3.2226147651672363,
      "logits/rejected": -2.783703327178955,
      "logps/chosen": -62.008636474609375,
      "logps/rejected": -144.1473388671875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3977058529853821,
      "rewards/margins": 8.664925575256348,
      "rewards/rejected": -8.267219543457031,
      "step": 2229
    },
    {
      "epoch": 0.892,
      "grad_norm": 13.108429908752441,
      "learning_rate": 7.028e-07,
      "logits/chosen": -2.5654008388519287,
      "logits/rejected": -2.1326961517333984,
      "logps/chosen": -195.51498413085938,
      "logps/rejected": -118.29507446289062,
      "loss": 0.0781,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.328634262084961,
      "rewards/margins": 3.2313218116760254,
      "rewards/rejected": -5.559956073760986,
      "step": 2230
    },
    {
      "epoch": 0.8924,
      "grad_norm": 2.159423589706421,
      "learning_rate": 7.026666666666667e-07,
      "logits/chosen": -3.0781240463256836,
      "logits/rejected": -2.6764681339263916,
      "logps/chosen": -104.47737121582031,
      "logps/rejected": -88.15494537353516,
      "loss": 0.0196,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7298858761787415,
      "rewards/margins": 5.4723711013793945,
      "rewards/rejected": -4.742485523223877,
      "step": 2231
    },
    {
      "epoch": 0.8928,
      "grad_norm": 1.8797876834869385,
      "learning_rate": 7.025333333333334e-07,
      "logits/chosen": -3.3465137481689453,
      "logits/rejected": -3.1958560943603516,
      "logps/chosen": -47.79142761230469,
      "logps/rejected": -73.9050521850586,
      "loss": 0.0309,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35225313901901245,
      "rewards/margins": 4.69087553024292,
      "rewards/rejected": -4.338622093200684,
      "step": 2232
    },
    {
      "epoch": 0.8932,
      "grad_norm": 0.6130538582801819,
      "learning_rate": 7.024e-07,
      "logits/chosen": -2.564174175262451,
      "logits/rejected": -1.9701042175292969,
      "logps/chosen": -169.59097290039062,
      "logps/rejected": -127.88673400878906,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.11034467816352844,
      "rewards/margins": 6.711748123168945,
      "rewards/rejected": -6.8220930099487305,
      "step": 2233
    },
    {
      "epoch": 0.8936,
      "grad_norm": 0.01588938571512699,
      "learning_rate": 7.022666666666666e-07,
      "logits/chosen": -2.8232626914978027,
      "logits/rejected": -2.291968822479248,
      "logps/chosen": -63.49176025390625,
      "logps/rejected": -179.16485595703125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.121058702468872,
      "rewards/margins": 9.766488075256348,
      "rewards/rejected": -7.645429611206055,
      "step": 2234
    },
    {
      "epoch": 0.894,
      "grad_norm": 1.171765923500061,
      "learning_rate": 7.021333333333333e-07,
      "logits/chosen": -2.930156707763672,
      "logits/rejected": -2.4533514976501465,
      "logps/chosen": -89.53253936767578,
      "logps/rejected": -125.1666030883789,
      "loss": 0.0085,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.26982423663139343,
      "rewards/margins": 6.754650115966797,
      "rewards/rejected": -6.48482608795166,
      "step": 2235
    },
    {
      "epoch": 0.8944,
      "grad_norm": 0.09177613258361816,
      "learning_rate": 7.019999999999999e-07,
      "logits/chosen": -2.6718692779541016,
      "logits/rejected": -2.264055013656616,
      "logps/chosen": -82.04330444335938,
      "logps/rejected": -132.04725646972656,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.556170642375946,
      "rewards/margins": 7.9913105964660645,
      "rewards/rejected": -7.4351396560668945,
      "step": 2236
    },
    {
      "epoch": 0.8948,
      "grad_norm": 0.2113734483718872,
      "learning_rate": 7.018666666666666e-07,
      "logits/chosen": -2.886972427368164,
      "logits/rejected": -1.950256586074829,
      "logps/chosen": -84.43004608154297,
      "logps/rejected": -125.04740142822266,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8868663907051086,
      "rewards/margins": 7.036252975463867,
      "rewards/rejected": -6.149386405944824,
      "step": 2237
    },
    {
      "epoch": 0.8952,
      "grad_norm": 0.01669292338192463,
      "learning_rate": 7.017333333333333e-07,
      "logits/chosen": -2.908379077911377,
      "logits/rejected": -2.135441780090332,
      "logps/chosen": -85.48958587646484,
      "logps/rejected": -145.96282958984375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6366972923278809,
      "rewards/margins": 9.44394302368164,
      "rewards/rejected": -7.807246208190918,
      "step": 2238
    },
    {
      "epoch": 0.8956,
      "grad_norm": 2.265108585357666,
      "learning_rate": 7.016e-07,
      "logits/chosen": -2.9421586990356445,
      "logits/rejected": -2.8646979331970215,
      "logps/chosen": -125.11781311035156,
      "logps/rejected": -115.45940399169922,
      "loss": 0.021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.824030339717865,
      "rewards/margins": 4.2429680824279785,
      "rewards/rejected": -5.066998481750488,
      "step": 2239
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.03853359445929527,
      "learning_rate": 7.014666666666667e-07,
      "logits/chosen": -2.7982897758483887,
      "logits/rejected": -2.0036683082580566,
      "logps/chosen": -104.79757690429688,
      "logps/rejected": -135.7769317626953,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.711106538772583,
      "rewards/margins": 7.962554931640625,
      "rewards/rejected": -7.251448154449463,
      "step": 2240
    },
    {
      "epoch": 0.8964,
      "grad_norm": 0.03466082736849785,
      "learning_rate": 7.013333333333334e-07,
      "logits/chosen": -3.1779398918151855,
      "logits/rejected": -2.4312591552734375,
      "logps/chosen": -63.948028564453125,
      "logps/rejected": -161.6912384033203,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2537037134170532,
      "rewards/margins": 9.991326332092285,
      "rewards/rejected": -8.73762321472168,
      "step": 2241
    },
    {
      "epoch": 0.8968,
      "grad_norm": 1.3319673538208008,
      "learning_rate": 7.012000000000001e-07,
      "logits/chosen": -3.2072079181671143,
      "logits/rejected": -2.9223098754882812,
      "logps/chosen": -54.48993682861328,
      "logps/rejected": -88.18283081054688,
      "loss": 0.0127,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.310756117105484,
      "rewards/margins": 4.365654945373535,
      "rewards/rejected": -4.6764116287231445,
      "step": 2242
    },
    {
      "epoch": 0.8972,
      "grad_norm": 0.04798751696944237,
      "learning_rate": 7.010666666666665e-07,
      "logits/chosen": -2.907013177871704,
      "logits/rejected": -2.1551272869110107,
      "logps/chosen": -89.69989013671875,
      "logps/rejected": -133.70277404785156,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1354671716690063,
      "rewards/margins": 8.804941177368164,
      "rewards/rejected": -7.669473648071289,
      "step": 2243
    },
    {
      "epoch": 0.8976,
      "grad_norm": 0.7108441591262817,
      "learning_rate": 7.009333333333332e-07,
      "logits/chosen": -3.3393373489379883,
      "logits/rejected": -3.181213855743408,
      "logps/chosen": -49.604469299316406,
      "logps/rejected": -82.7264404296875,
      "loss": 0.0085,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6546601057052612,
      "rewards/margins": 5.385449409484863,
      "rewards/rejected": -4.7307891845703125,
      "step": 2244
    },
    {
      "epoch": 0.898,
      "grad_norm": 0.1326889991760254,
      "learning_rate": 7.007999999999999e-07,
      "logits/chosen": -2.7012243270874023,
      "logits/rejected": -2.1109299659729004,
      "logps/chosen": -86.939453125,
      "logps/rejected": -105.14602661132812,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3902645409107208,
      "rewards/margins": 6.611496925354004,
      "rewards/rejected": -6.2212324142456055,
      "step": 2245
    },
    {
      "epoch": 0.8984,
      "grad_norm": 0.40539589524269104,
      "learning_rate": 7.006666666666666e-07,
      "logits/chosen": -2.529754877090454,
      "logits/rejected": -2.0568935871124268,
      "logps/chosen": -138.21780395507812,
      "logps/rejected": -170.6254119873047,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21355514228343964,
      "rewards/margins": 6.591804027557373,
      "rewards/rejected": -6.378248691558838,
      "step": 2246
    },
    {
      "epoch": 0.8988,
      "grad_norm": 1.4507601261138916,
      "learning_rate": 7.005333333333333e-07,
      "logits/chosen": -2.8661627769470215,
      "logits/rejected": -2.3430352210998535,
      "logps/chosen": -156.08108520507812,
      "logps/rejected": -144.50254821777344,
      "loss": 0.0099,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7519515752792358,
      "rewards/margins": 7.606080055236816,
      "rewards/rejected": -6.854128837585449,
      "step": 2247
    },
    {
      "epoch": 0.8992,
      "grad_norm": 5.737883567810059,
      "learning_rate": 7.004e-07,
      "logits/chosen": -3.0927553176879883,
      "logits/rejected": -3.0195517539978027,
      "logps/chosen": -87.8504638671875,
      "logps/rejected": -111.58032989501953,
      "loss": 0.079,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.37410929799079895,
      "rewards/margins": 5.106070041656494,
      "rewards/rejected": -5.480179309844971,
      "step": 2248
    },
    {
      "epoch": 0.8996,
      "grad_norm": 0.06967821717262268,
      "learning_rate": 7.002666666666667e-07,
      "logits/chosen": -3.1104540824890137,
      "logits/rejected": -2.6158604621887207,
      "logps/chosen": -54.590057373046875,
      "logps/rejected": -141.66114807128906,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6625998020172119,
      "rewards/margins": 8.57384204864502,
      "rewards/rejected": -7.911242485046387,
      "step": 2249
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.35959360003471375,
      "learning_rate": 7.001333333333334e-07,
      "logits/chosen": -2.8655056953430176,
      "logits/rejected": -2.2081379890441895,
      "logps/chosen": -87.61351013183594,
      "logps/rejected": -163.0220184326172,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21517068147659302,
      "rewards/margins": 7.384577751159668,
      "rewards/rejected": -7.169406890869141,
      "step": 2250
    },
    {
      "epoch": 0.9004,
      "grad_norm": 0.02556878887116909,
      "learning_rate": 7e-07,
      "logits/chosen": -2.6959071159362793,
      "logits/rejected": -1.8750770092010498,
      "logps/chosen": -68.39463806152344,
      "logps/rejected": -170.78758239746094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7657352685928345,
      "rewards/margins": 8.931486129760742,
      "rewards/rejected": -9.697221755981445,
      "step": 2251
    },
    {
      "epoch": 0.9008,
      "grad_norm": 0.32241687178611755,
      "learning_rate": 6.998666666666666e-07,
      "logits/chosen": -3.0298666954040527,
      "logits/rejected": -2.754422187805176,
      "logps/chosen": -87.96321105957031,
      "logps/rejected": -109.63534545898438,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08777731657028198,
      "rewards/margins": 5.7549848556518555,
      "rewards/rejected": -5.842761993408203,
      "step": 2252
    },
    {
      "epoch": 0.9012,
      "grad_norm": 22.13275718688965,
      "learning_rate": 6.997333333333332e-07,
      "logits/chosen": -2.734508991241455,
      "logits/rejected": -2.442201852798462,
      "logps/chosen": -148.12625122070312,
      "logps/rejected": -126.00425720214844,
      "loss": 0.327,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.835955023765564,
      "rewards/margins": 4.474882125854492,
      "rewards/rejected": -6.310837268829346,
      "step": 2253
    },
    {
      "epoch": 0.9016,
      "grad_norm": 27.122283935546875,
      "learning_rate": 6.995999999999999e-07,
      "logits/chosen": -2.3505349159240723,
      "logits/rejected": -1.8440444469451904,
      "logps/chosen": -189.67340087890625,
      "logps/rejected": -243.38482666015625,
      "loss": 0.1693,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.1142659187316895,
      "rewards/margins": 3.969766616821289,
      "rewards/rejected": -7.0840325355529785,
      "step": 2254
    },
    {
      "epoch": 0.902,
      "grad_norm": 0.033324938267469406,
      "learning_rate": 6.994666666666666e-07,
      "logits/chosen": -2.618400812149048,
      "logits/rejected": -1.6805139780044556,
      "logps/chosen": -129.68150329589844,
      "logps/rejected": -177.10488891601562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4885692596435547,
      "rewards/margins": 10.148463249206543,
      "rewards/rejected": -9.659893989562988,
      "step": 2255
    },
    {
      "epoch": 0.9024,
      "grad_norm": 2.283106803894043,
      "learning_rate": 6.993333333333333e-07,
      "logits/chosen": -2.368400812149048,
      "logits/rejected": -1.7483149766921997,
      "logps/chosen": -183.714111328125,
      "logps/rejected": -138.93605041503906,
      "loss": 0.0128,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.012816667556762695,
      "rewards/margins": 6.857048034667969,
      "rewards/rejected": -6.844231128692627,
      "step": 2256
    },
    {
      "epoch": 0.9028,
      "grad_norm": 0.34175992012023926,
      "learning_rate": 6.992e-07,
      "logits/chosen": -2.6463510990142822,
      "logits/rejected": -2.4408202171325684,
      "logps/chosen": -159.254638671875,
      "logps/rejected": -137.86746215820312,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3442741632461548,
      "rewards/margins": 5.732929229736328,
      "rewards/rejected": -7.077203750610352,
      "step": 2257
    },
    {
      "epoch": 0.9032,
      "grad_norm": 2.0231618881225586,
      "learning_rate": 6.990666666666666e-07,
      "logits/chosen": -2.984388828277588,
      "logits/rejected": -2.554936170578003,
      "logps/chosen": -119.38995361328125,
      "logps/rejected": -106.9548110961914,
      "loss": 0.023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3000030517578125,
      "rewards/margins": 3.9455690383911133,
      "rewards/rejected": -5.245572090148926,
      "step": 2258
    },
    {
      "epoch": 0.9036,
      "grad_norm": 0.14513061940670013,
      "learning_rate": 6.989333333333333e-07,
      "logits/chosen": -2.9818081855773926,
      "logits/rejected": -2.065969705581665,
      "logps/chosen": -76.1277847290039,
      "logps/rejected": -174.71075439453125,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7743370532989502,
      "rewards/margins": 9.743119239807129,
      "rewards/rejected": -8.968782424926758,
      "step": 2259
    },
    {
      "epoch": 0.904,
      "grad_norm": 2.236193895339966,
      "learning_rate": 6.988e-07,
      "logits/chosen": -2.8514647483825684,
      "logits/rejected": -2.4252405166625977,
      "logps/chosen": -96.8175277709961,
      "logps/rejected": -135.08096313476562,
      "loss": 0.0193,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8155227899551392,
      "rewards/margins": 9.236678123474121,
      "rewards/rejected": -8.421154975891113,
      "step": 2260
    },
    {
      "epoch": 0.9044,
      "grad_norm": 10.781413078308105,
      "learning_rate": 6.986666666666667e-07,
      "logits/chosen": -3.0192689895629883,
      "logits/rejected": -2.8598170280456543,
      "logps/chosen": -143.79718017578125,
      "logps/rejected": -107.2706527709961,
      "loss": 0.0966,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.858712673187256,
      "rewards/margins": 2.3369929790496826,
      "rewards/rejected": -6.195705413818359,
      "step": 2261
    },
    {
      "epoch": 0.9048,
      "grad_norm": 1.0288528203964233,
      "learning_rate": 6.985333333333333e-07,
      "logits/chosen": -2.751708984375,
      "logits/rejected": -2.2798054218292236,
      "logps/chosen": -91.79056549072266,
      "logps/rejected": -100.7762222290039,
      "loss": 0.0093,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1108384132385254,
      "rewards/margins": 6.193041801452637,
      "rewards/rejected": -5.082203388214111,
      "step": 2262
    },
    {
      "epoch": 0.9052,
      "grad_norm": 0.5401114821434021,
      "learning_rate": 6.984e-07,
      "logits/chosen": -3.023552417755127,
      "logits/rejected": -2.5830259323120117,
      "logps/chosen": -87.0666732788086,
      "logps/rejected": -108.68045043945312,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2387646436691284,
      "rewards/margins": 6.171133041381836,
      "rewards/rejected": -4.932368278503418,
      "step": 2263
    },
    {
      "epoch": 0.9056,
      "grad_norm": 0.13897289335727692,
      "learning_rate": 6.982666666666666e-07,
      "logits/chosen": -3.0854127407073975,
      "logits/rejected": -2.8329579830169678,
      "logps/chosen": -72.51958465576172,
      "logps/rejected": -109.4148178100586,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17469902336597443,
      "rewards/margins": 7.2161054611206055,
      "rewards/rejected": -7.041406631469727,
      "step": 2264
    },
    {
      "epoch": 0.906,
      "grad_norm": 0.022517306730151176,
      "learning_rate": 6.981333333333333e-07,
      "logits/chosen": -2.907233476638794,
      "logits/rejected": -2.253894329071045,
      "logps/chosen": -66.09559631347656,
      "logps/rejected": -174.09771728515625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6470177173614502,
      "rewards/margins": 9.747016906738281,
      "rewards/rejected": -9.099998474121094,
      "step": 2265
    },
    {
      "epoch": 0.9064,
      "grad_norm": 3.73409104347229,
      "learning_rate": 6.979999999999999e-07,
      "logits/chosen": -3.559079170227051,
      "logits/rejected": -3.280233860015869,
      "logps/chosen": -50.801658630371094,
      "logps/rejected": -68.66241455078125,
      "loss": 0.0519,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0364227294921875,
      "rewards/margins": 3.362255573272705,
      "rewards/rejected": -3.3986783027648926,
      "step": 2266
    },
    {
      "epoch": 0.9068,
      "grad_norm": 0.28568193316459656,
      "learning_rate": 6.978666666666666e-07,
      "logits/chosen": -3.0556674003601074,
      "logits/rejected": -2.92500638961792,
      "logps/chosen": -84.7337646484375,
      "logps/rejected": -110.90582275390625,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.44026339054107666,
      "rewards/margins": 5.935120582580566,
      "rewards/rejected": -6.375384330749512,
      "step": 2267
    },
    {
      "epoch": 0.9072,
      "grad_norm": 1.1850767135620117,
      "learning_rate": 6.977333333333333e-07,
      "logits/chosen": -2.5072855949401855,
      "logits/rejected": -1.960867166519165,
      "logps/chosen": -122.17770385742188,
      "logps/rejected": -107.39729309082031,
      "loss": 0.007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9815578460693359,
      "rewards/margins": 7.041548728942871,
      "rewards/rejected": -6.059990406036377,
      "step": 2268
    },
    {
      "epoch": 0.9076,
      "grad_norm": 0.025085922330617905,
      "learning_rate": 6.976e-07,
      "logits/chosen": -3.031195640563965,
      "logits/rejected": -2.2974185943603516,
      "logps/chosen": -61.417354583740234,
      "logps/rejected": -151.3837432861328,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4180063009262085,
      "rewards/margins": 8.745978355407715,
      "rewards/rejected": -7.327972412109375,
      "step": 2269
    },
    {
      "epoch": 0.908,
      "grad_norm": 4.972086429595947,
      "learning_rate": 6.974666666666667e-07,
      "logits/chosen": -2.8681397438049316,
      "logits/rejected": -2.7166173458099365,
      "logps/chosen": -79.02618408203125,
      "logps/rejected": -99.39468383789062,
      "loss": 0.0492,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4814181327819824,
      "rewards/margins": 4.149918556213379,
      "rewards/rejected": -5.631336688995361,
      "step": 2270
    },
    {
      "epoch": 0.9084,
      "grad_norm": 0.13634933531284332,
      "learning_rate": 6.973333333333333e-07,
      "logits/chosen": -2.627377986907959,
      "logits/rejected": -1.9664514064788818,
      "logps/chosen": -104.55892944335938,
      "logps/rejected": -166.6271209716797,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9106159210205078,
      "rewards/margins": 7.892359733581543,
      "rewards/rejected": -6.981743812561035,
      "step": 2271
    },
    {
      "epoch": 0.9088,
      "grad_norm": 1.7736632823944092,
      "learning_rate": 6.972e-07,
      "logits/chosen": -2.4047656059265137,
      "logits/rejected": -1.9214091300964355,
      "logps/chosen": -158.19769287109375,
      "logps/rejected": -183.809326171875,
      "loss": 0.0104,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7999213933944702,
      "rewards/margins": 6.196855545043945,
      "rewards/rejected": -5.3969340324401855,
      "step": 2272
    },
    {
      "epoch": 0.9092,
      "grad_norm": 0.013972192071378231,
      "learning_rate": 6.970666666666666e-07,
      "logits/chosen": -2.771007537841797,
      "logits/rejected": -2.126652717590332,
      "logps/chosen": -65.65544128417969,
      "logps/rejected": -166.9766082763672,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9486956000328064,
      "rewards/margins": 10.083658218383789,
      "rewards/rejected": -9.13496208190918,
      "step": 2273
    },
    {
      "epoch": 0.9096,
      "grad_norm": 30.84052085876465,
      "learning_rate": 6.969333333333332e-07,
      "logits/chosen": -2.389974594116211,
      "logits/rejected": -1.9088311195373535,
      "logps/chosen": -162.2490692138672,
      "logps/rejected": -128.177001953125,
      "loss": 0.5297,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -5.162351608276367,
      "rewards/margins": 1.6896365880966187,
      "rewards/rejected": -6.851988315582275,
      "step": 2274
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.49174419045448303,
      "learning_rate": 6.967999999999999e-07,
      "logits/chosen": -2.8535218238830566,
      "logits/rejected": -2.176119089126587,
      "logps/chosen": -59.42770767211914,
      "logps/rejected": -125.97528839111328,
      "loss": 0.0049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.971256673336029,
      "rewards/margins": 8.44819450378418,
      "rewards/rejected": -7.476937294006348,
      "step": 2275
    },
    {
      "epoch": 0.9104,
      "grad_norm": 0.02797701209783554,
      "learning_rate": 6.966666666666666e-07,
      "logits/chosen": -2.6319351196289062,
      "logits/rejected": -1.550558090209961,
      "logps/chosen": -129.84336853027344,
      "logps/rejected": -121.15721893310547,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5318740606307983,
      "rewards/margins": 8.56468391418457,
      "rewards/rejected": -7.032810211181641,
      "step": 2276
    },
    {
      "epoch": 0.9108,
      "grad_norm": 2.1053500175476074,
      "learning_rate": 6.965333333333333e-07,
      "logits/chosen": -2.7418134212493896,
      "logits/rejected": -2.154409885406494,
      "logps/chosen": -206.91549682617188,
      "logps/rejected": -155.9113311767578,
      "loss": 0.0113,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.48790442943573,
      "rewards/margins": 5.583333969116211,
      "rewards/rejected": -7.071238040924072,
      "step": 2277
    },
    {
      "epoch": 0.9112,
      "grad_norm": 0.14909972250461578,
      "learning_rate": 6.964e-07,
      "logits/chosen": -2.5850467681884766,
      "logits/rejected": -1.7512524127960205,
      "logps/chosen": -148.42713928222656,
      "logps/rejected": -138.01351928710938,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2685646116733551,
      "rewards/margins": 7.7663679122924805,
      "rewards/rejected": -7.497803688049316,
      "step": 2278
    },
    {
      "epoch": 0.9116,
      "grad_norm": 35.15734100341797,
      "learning_rate": 6.962666666666667e-07,
      "logits/chosen": -2.7817862033843994,
      "logits/rejected": -2.572244882583618,
      "logps/chosen": -197.87667846679688,
      "logps/rejected": -117.31732177734375,
      "loss": 0.3258,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3954994678497314,
      "rewards/margins": 4.478207588195801,
      "rewards/rejected": -5.873706817626953,
      "step": 2279
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.5065604448318481,
      "learning_rate": 6.961333333333334e-07,
      "logits/chosen": -3.1281909942626953,
      "logits/rejected": -2.672739028930664,
      "logps/chosen": -56.74517059326172,
      "logps/rejected": -130.56719970703125,
      "loss": 0.0063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.30187320709228516,
      "rewards/margins": 7.528470993041992,
      "rewards/rejected": -7.226597785949707,
      "step": 2280
    },
    {
      "epoch": 0.9124,
      "grad_norm": 46.09796142578125,
      "learning_rate": 6.959999999999999e-07,
      "logits/chosen": -2.236814022064209,
      "logits/rejected": -1.4339773654937744,
      "logps/chosen": -170.265869140625,
      "logps/rejected": -147.87448120117188,
      "loss": 0.1964,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.4004478454589844,
      "rewards/margins": 5.3448405265808105,
      "rewards/rejected": -7.745288372039795,
      "step": 2281
    },
    {
      "epoch": 0.9128,
      "grad_norm": 0.018569903448224068,
      "learning_rate": 6.958666666666666e-07,
      "logits/chosen": -2.7193260192871094,
      "logits/rejected": -1.6935639381408691,
      "logps/chosen": -91.61123657226562,
      "logps/rejected": -165.7325897216797,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7832374572753906,
      "rewards/margins": 9.342350959777832,
      "rewards/rejected": -8.559113502502441,
      "step": 2282
    },
    {
      "epoch": 0.9132,
      "grad_norm": 0.06876565515995026,
      "learning_rate": 6.957333333333333e-07,
      "logits/chosen": -2.621675968170166,
      "logits/rejected": -2.0851035118103027,
      "logps/chosen": -171.93296813964844,
      "logps/rejected": -133.36068725585938,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5160709023475647,
      "rewards/margins": 7.566446304321289,
      "rewards/rejected": -8.082517623901367,
      "step": 2283
    },
    {
      "epoch": 0.9136,
      "grad_norm": 0.12087764590978622,
      "learning_rate": 6.956e-07,
      "logits/chosen": -2.993661403656006,
      "logits/rejected": -2.658146381378174,
      "logps/chosen": -76.16889953613281,
      "logps/rejected": -115.08245849609375,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20306435227394104,
      "rewards/margins": 7.280691146850586,
      "rewards/rejected": -7.077626705169678,
      "step": 2284
    },
    {
      "epoch": 0.914,
      "grad_norm": 1.4781125783920288,
      "learning_rate": 6.954666666666666e-07,
      "logits/chosen": -2.975447654724121,
      "logits/rejected": -2.418105363845825,
      "logps/chosen": -112.2957763671875,
      "logps/rejected": -148.17715454101562,
      "loss": 0.012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.40860557556152344,
      "rewards/margins": 8.001142501831055,
      "rewards/rejected": -8.409748077392578,
      "step": 2285
    },
    {
      "epoch": 0.9144,
      "grad_norm": 1.146196961402893,
      "learning_rate": 6.953333333333333e-07,
      "logits/chosen": -2.598048448562622,
      "logits/rejected": -2.198482036590576,
      "logps/chosen": -160.58387756347656,
      "logps/rejected": -117.5911865234375,
      "loss": 0.0088,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7465789318084717,
      "rewards/margins": 4.778792381286621,
      "rewards/rejected": -6.525371074676514,
      "step": 2286
    },
    {
      "epoch": 0.9148,
      "grad_norm": 0.3015464246273041,
      "learning_rate": 6.952e-07,
      "logits/chosen": -2.666038990020752,
      "logits/rejected": -1.9815912246704102,
      "logps/chosen": -69.80988311767578,
      "logps/rejected": -131.65060424804688,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2870733141899109,
      "rewards/margins": 5.9126482009887695,
      "rewards/rejected": -5.625575065612793,
      "step": 2287
    },
    {
      "epoch": 0.9152,
      "grad_norm": 0.29880133271217346,
      "learning_rate": 6.950666666666667e-07,
      "logits/chosen": -3.3557348251342773,
      "logits/rejected": -2.497201442718506,
      "logps/chosen": -69.40861511230469,
      "logps/rejected": -128.53074645996094,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5814693570137024,
      "rewards/margins": 7.500215530395508,
      "rewards/rejected": -6.918745994567871,
      "step": 2288
    },
    {
      "epoch": 0.9156,
      "grad_norm": 3.11177134513855,
      "learning_rate": 6.949333333333333e-07,
      "logits/chosen": -2.7737088203430176,
      "logits/rejected": -2.4767768383026123,
      "logps/chosen": -88.9154052734375,
      "logps/rejected": -199.59500122070312,
      "loss": 0.0257,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.21969914436340332,
      "rewards/margins": 7.868859767913818,
      "rewards/rejected": -8.0885591506958,
      "step": 2289
    },
    {
      "epoch": 0.916,
      "grad_norm": 0.4810667634010315,
      "learning_rate": 6.947999999999999e-07,
      "logits/chosen": -2.874403476715088,
      "logits/rejected": -2.169222354888916,
      "logps/chosen": -100.54749298095703,
      "logps/rejected": -123.65620422363281,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.244993805885315,
      "rewards/margins": 6.5091094970703125,
      "rewards/rejected": -7.754103660583496,
      "step": 2290
    },
    {
      "epoch": 0.9164,
      "grad_norm": 0.12675270438194275,
      "learning_rate": 6.946666666666666e-07,
      "logits/chosen": -3.1259613037109375,
      "logits/rejected": -2.387359142303467,
      "logps/chosen": -63.71467590332031,
      "logps/rejected": -126.85604095458984,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.045011043548584,
      "rewards/margins": 7.91267204284668,
      "rewards/rejected": -6.867660999298096,
      "step": 2291
    },
    {
      "epoch": 0.9168,
      "grad_norm": 2.7854979038238525,
      "learning_rate": 6.945333333333333e-07,
      "logits/chosen": -2.67995023727417,
      "logits/rejected": -2.0186400413513184,
      "logps/chosen": -175.7584991455078,
      "logps/rejected": -118.73719787597656,
      "loss": 0.0182,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6680969595909119,
      "rewards/margins": 5.9483323097229,
      "rewards/rejected": -6.616429328918457,
      "step": 2292
    },
    {
      "epoch": 0.9172,
      "grad_norm": 0.5250537395477295,
      "learning_rate": 6.944e-07,
      "logits/chosen": -2.6618754863739014,
      "logits/rejected": -2.6178183555603027,
      "logps/chosen": -54.395137786865234,
      "logps/rejected": -109.1358642578125,
      "loss": 0.005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5009613037109375,
      "rewards/margins": 6.350517272949219,
      "rewards/rejected": -5.849555969238281,
      "step": 2293
    },
    {
      "epoch": 0.9176,
      "grad_norm": 0.09122035652399063,
      "learning_rate": 6.942666666666667e-07,
      "logits/chosen": -2.660548686981201,
      "logits/rejected": -2.094290018081665,
      "logps/chosen": -55.274192810058594,
      "logps/rejected": -122.63219451904297,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9788545966148376,
      "rewards/margins": 7.976800441741943,
      "rewards/rejected": -6.997945785522461,
      "step": 2294
    },
    {
      "epoch": 0.918,
      "grad_norm": 0.05652187392115593,
      "learning_rate": 6.941333333333334e-07,
      "logits/chosen": -3.0805139541625977,
      "logits/rejected": -2.4845592975616455,
      "logps/chosen": -62.347137451171875,
      "logps/rejected": -152.06710815429688,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7941223382949829,
      "rewards/margins": 8.04220962524414,
      "rewards/rejected": -8.836332321166992,
      "step": 2295
    },
    {
      "epoch": 0.9184,
      "grad_norm": 0.9650566577911377,
      "learning_rate": 6.939999999999999e-07,
      "logits/chosen": -3.102201461791992,
      "logits/rejected": -2.6121182441711426,
      "logps/chosen": -54.51325988769531,
      "logps/rejected": -108.99540710449219,
      "loss": 0.0086,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6048109531402588,
      "rewards/margins": 6.136756420135498,
      "rewards/rejected": -5.53194522857666,
      "step": 2296
    },
    {
      "epoch": 0.9188,
      "grad_norm": 5.832446098327637,
      "learning_rate": 6.938666666666666e-07,
      "logits/chosen": -2.6506800651550293,
      "logits/rejected": -2.3221514225006104,
      "logps/chosen": -130.75001525878906,
      "logps/rejected": -92.79829406738281,
      "loss": 0.0566,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9428707361221313,
      "rewards/margins": 3.9867935180664062,
      "rewards/rejected": -4.929664134979248,
      "step": 2297
    },
    {
      "epoch": 0.9192,
      "grad_norm": 0.1809650957584381,
      "learning_rate": 6.937333333333333e-07,
      "logits/chosen": -2.646162986755371,
      "logits/rejected": -2.3515632152557373,
      "logps/chosen": -116.9769058227539,
      "logps/rejected": -157.0989990234375,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6775192618370056,
      "rewards/margins": 8.802148818969727,
      "rewards/rejected": -9.479668617248535,
      "step": 2298
    },
    {
      "epoch": 0.9196,
      "grad_norm": 2.4386942386627197,
      "learning_rate": 6.935999999999999e-07,
      "logits/chosen": -2.887126922607422,
      "logits/rejected": -2.3674254417419434,
      "logps/chosen": -73.91755676269531,
      "logps/rejected": -125.24687957763672,
      "loss": 0.0211,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8889931440353394,
      "rewards/margins": 5.100859642028809,
      "rewards/rejected": -4.21186637878418,
      "step": 2299
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.07020865380764008,
      "learning_rate": 6.934666666666666e-07,
      "logits/chosen": -2.3749022483825684,
      "logits/rejected": -1.5635685920715332,
      "logps/chosen": -66.01925659179688,
      "logps/rejected": -150.3193817138672,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9009189605712891,
      "rewards/margins": 8.623268127441406,
      "rewards/rejected": -7.722349643707275,
      "step": 2300
    },
    {
      "epoch": 0.9204,
      "grad_norm": 0.10222738981246948,
      "learning_rate": 6.933333333333333e-07,
      "logits/chosen": -3.1041460037231445,
      "logits/rejected": -2.909337043762207,
      "logps/chosen": -76.57880401611328,
      "logps/rejected": -114.5830078125,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6459009647369385,
      "rewards/margins": 7.590928077697754,
      "rewards/rejected": -6.9450273513793945,
      "step": 2301
    },
    {
      "epoch": 0.9208,
      "grad_norm": 0.22382862865924835,
      "learning_rate": 6.932e-07,
      "logits/chosen": -2.8242573738098145,
      "logits/rejected": -2.4214234352111816,
      "logps/chosen": -55.88644790649414,
      "logps/rejected": -117.45011901855469,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7343765497207642,
      "rewards/margins": 7.202052116394043,
      "rewards/rejected": -6.467676162719727,
      "step": 2302
    },
    {
      "epoch": 0.9212,
      "grad_norm": 0.32099780440330505,
      "learning_rate": 6.930666666666667e-07,
      "logits/chosen": -2.9703588485717773,
      "logits/rejected": -2.5113677978515625,
      "logps/chosen": -93.66983032226562,
      "logps/rejected": -126.4827880859375,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8030624389648438,
      "rewards/margins": 8.412919044494629,
      "rewards/rejected": -7.609856128692627,
      "step": 2303
    },
    {
      "epoch": 0.9216,
      "grad_norm": 0.019202006980776787,
      "learning_rate": 6.929333333333333e-07,
      "logits/chosen": -2.7325544357299805,
      "logits/rejected": -2.3101649284362793,
      "logps/chosen": -100.93126678466797,
      "logps/rejected": -159.98333740234375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8385351896286011,
      "rewards/margins": 9.143965721130371,
      "rewards/rejected": -8.30543041229248,
      "step": 2304
    },
    {
      "epoch": 0.922,
      "grad_norm": 0.08882167935371399,
      "learning_rate": 6.928e-07,
      "logits/chosen": -2.7871060371398926,
      "logits/rejected": -2.3861944675445557,
      "logps/chosen": -94.70849609375,
      "logps/rejected": -176.19781494140625,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2099098265171051,
      "rewards/margins": 7.436007976531982,
      "rewards/rejected": -7.22609806060791,
      "step": 2305
    },
    {
      "epoch": 0.9224,
      "grad_norm": 0.018909970298409462,
      "learning_rate": 6.926666666666666e-07,
      "logits/chosen": -2.9246678352355957,
      "logits/rejected": -2.171198844909668,
      "logps/chosen": -81.34487915039062,
      "logps/rejected": -132.63046264648438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6725852489471436,
      "rewards/margins": 9.321307182312012,
      "rewards/rejected": -7.648721694946289,
      "step": 2306
    },
    {
      "epoch": 0.9228,
      "grad_norm": 0.0014279637252911925,
      "learning_rate": 6.925333333333333e-07,
      "logits/chosen": -2.826122283935547,
      "logits/rejected": -2.110830307006836,
      "logps/chosen": -77.03092956542969,
      "logps/rejected": -197.77577209472656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3116111755371094,
      "rewards/margins": 12.002021789550781,
      "rewards/rejected": -10.690410614013672,
      "step": 2307
    },
    {
      "epoch": 0.9232,
      "grad_norm": 0.07143227010965347,
      "learning_rate": 6.924e-07,
      "logits/chosen": -3.075557231903076,
      "logits/rejected": -2.3720221519470215,
      "logps/chosen": -50.87462615966797,
      "logps/rejected": -116.30094909667969,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0951002836227417,
      "rewards/margins": 7.900599002838135,
      "rewards/rejected": -6.805499076843262,
      "step": 2308
    },
    {
      "epoch": 0.9236,
      "grad_norm": 0.3834092617034912,
      "learning_rate": 6.922666666666666e-07,
      "logits/chosen": -2.811434268951416,
      "logits/rejected": -2.30727481842041,
      "logps/chosen": -86.05915832519531,
      "logps/rejected": -127.60089111328125,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5920189023017883,
      "rewards/margins": 6.857583999633789,
      "rewards/rejected": -7.449603080749512,
      "step": 2309
    },
    {
      "epoch": 0.924,
      "grad_norm": 0.6823912858963013,
      "learning_rate": 6.921333333333333e-07,
      "logits/chosen": -2.6912779808044434,
      "logits/rejected": -2.14572811126709,
      "logps/chosen": -110.87250518798828,
      "logps/rejected": -181.70065307617188,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.14921236038208,
      "rewards/margins": 7.632179260253906,
      "rewards/rejected": -10.781391143798828,
      "step": 2310
    },
    {
      "epoch": 0.9244,
      "grad_norm": 0.049148235470056534,
      "learning_rate": 6.919999999999999e-07,
      "logits/chosen": -2.878004550933838,
      "logits/rejected": -2.200270891189575,
      "logps/chosen": -71.07180786132812,
      "logps/rejected": -141.14364624023438,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0592705011367798,
      "rewards/margins": 8.80891227722168,
      "rewards/rejected": -7.749641418457031,
      "step": 2311
    },
    {
      "epoch": 0.9248,
      "grad_norm": 0.2840900719165802,
      "learning_rate": 6.918666666666666e-07,
      "logits/chosen": -2.783803939819336,
      "logits/rejected": -2.066190242767334,
      "logps/chosen": -128.468017578125,
      "logps/rejected": -117.90438842773438,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2846755981445312,
      "rewards/margins": 6.814043998718262,
      "rewards/rejected": -5.529367923736572,
      "step": 2312
    },
    {
      "epoch": 0.9252,
      "grad_norm": 0.0016579916700720787,
      "learning_rate": 6.917333333333333e-07,
      "logits/chosen": -2.8391146659851074,
      "logits/rejected": -2.2627248764038086,
      "logps/chosen": -102.18171691894531,
      "logps/rejected": -190.7393798828125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.901691198348999,
      "rewards/margins": 11.668767929077148,
      "rewards/rejected": -9.76707649230957,
      "step": 2313
    },
    {
      "epoch": 0.9256,
      "grad_norm": 0.9361520409584045,
      "learning_rate": 6.916e-07,
      "logits/chosen": -3.282890558242798,
      "logits/rejected": -2.8275461196899414,
      "logps/chosen": -85.25299072265625,
      "logps/rejected": -91.81559753417969,
      "loss": 0.0115,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5419772863388062,
      "rewards/margins": 4.493453025817871,
      "rewards/rejected": -5.035429954528809,
      "step": 2314
    },
    {
      "epoch": 0.926,
      "grad_norm": 1.5539897680282593,
      "learning_rate": 6.914666666666667e-07,
      "logits/chosen": -3.442183017730713,
      "logits/rejected": -3.4646177291870117,
      "logps/chosen": -70.72728729248047,
      "logps/rejected": -66.31011962890625,
      "loss": 0.0201,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08891983330249786,
      "rewards/margins": 3.989307165145874,
      "rewards/rejected": -4.0782270431518555,
      "step": 2315
    },
    {
      "epoch": 0.9264,
      "grad_norm": 1.722241997718811,
      "learning_rate": 6.913333333333334e-07,
      "logits/chosen": -3.2667951583862305,
      "logits/rejected": -3.2354135513305664,
      "logps/chosen": -89.45388793945312,
      "logps/rejected": -92.02525329589844,
      "loss": 0.0196,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7379270792007446,
      "rewards/margins": 4.438106536865234,
      "rewards/rejected": -5.1760334968566895,
      "step": 2316
    },
    {
      "epoch": 0.9268,
      "grad_norm": 0.4263593554496765,
      "learning_rate": 6.912e-07,
      "logits/chosen": -2.694662570953369,
      "logits/rejected": -2.208923816680908,
      "logps/chosen": -128.25567626953125,
      "logps/rejected": -133.3743896484375,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1597187519073486,
      "rewards/margins": 6.569977283477783,
      "rewards/rejected": -4.4102582931518555,
      "step": 2317
    },
    {
      "epoch": 0.9272,
      "grad_norm": 0.04249115660786629,
      "learning_rate": 6.910666666666666e-07,
      "logits/chosen": -2.927419900894165,
      "logits/rejected": -2.326864719390869,
      "logps/chosen": -66.97745513916016,
      "logps/rejected": -165.5396728515625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05582618713378906,
      "rewards/margins": 9.209966659545898,
      "rewards/rejected": -9.15414047241211,
      "step": 2318
    },
    {
      "epoch": 0.9276,
      "grad_norm": 0.15918509662151337,
      "learning_rate": 6.909333333333332e-07,
      "logits/chosen": -3.033202648162842,
      "logits/rejected": -2.2819132804870605,
      "logps/chosen": -57.5630989074707,
      "logps/rejected": -127.96730041503906,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6032455563545227,
      "rewards/margins": 6.856933116912842,
      "rewards/rejected": -7.460178852081299,
      "step": 2319
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.2988032400608063,
      "learning_rate": 6.907999999999999e-07,
      "logits/chosen": -2.8043596744537354,
      "logits/rejected": -1.9815006256103516,
      "logps/chosen": -100.31108093261719,
      "logps/rejected": -132.42555236816406,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3320762515068054,
      "rewards/margins": 7.878623008728027,
      "rewards/rejected": -7.546546936035156,
      "step": 2320
    },
    {
      "epoch": 0.9284,
      "grad_norm": 0.17059724032878876,
      "learning_rate": 6.906666666666666e-07,
      "logits/chosen": -2.8028416633605957,
      "logits/rejected": -2.4285776615142822,
      "logps/chosen": -104.84619140625,
      "logps/rejected": -125.12252807617188,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5216903686523438,
      "rewards/margins": 7.259692668914795,
      "rewards/rejected": -6.738002300262451,
      "step": 2321
    },
    {
      "epoch": 0.9288,
      "grad_norm": 0.14368084073066711,
      "learning_rate": 6.905333333333333e-07,
      "logits/chosen": -2.7557408809661865,
      "logits/rejected": -2.1088969707489014,
      "logps/chosen": -106.2982177734375,
      "logps/rejected": -129.88397216796875,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4493164122104645,
      "rewards/margins": 6.739897727966309,
      "rewards/rejected": -6.290581703186035,
      "step": 2322
    },
    {
      "epoch": 0.9292,
      "grad_norm": 0.11679024994373322,
      "learning_rate": 6.904e-07,
      "logits/chosen": -2.6974878311157227,
      "logits/rejected": -2.275116443634033,
      "logps/chosen": -79.00804138183594,
      "logps/rejected": -136.7126922607422,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16224995255470276,
      "rewards/margins": 7.14619779586792,
      "rewards/rejected": -6.98394775390625,
      "step": 2323
    },
    {
      "epoch": 0.9296,
      "grad_norm": 0.02541622519493103,
      "learning_rate": 6.902666666666667e-07,
      "logits/chosen": -2.6453843116760254,
      "logits/rejected": -1.8650062084197998,
      "logps/chosen": -115.70488739013672,
      "logps/rejected": -142.1774139404297,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5717605352401733,
      "rewards/margins": 9.680373191833496,
      "rewards/rejected": -8.108613014221191,
      "step": 2324
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.2599800825119019,
      "learning_rate": 6.901333333333334e-07,
      "logits/chosen": -3.079566240310669,
      "logits/rejected": -2.901320457458496,
      "logps/chosen": -55.239315032958984,
      "logps/rejected": -76.5513916015625,
      "loss": 0.0145,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.599966824054718,
      "rewards/margins": 4.5780720710754395,
      "rewards/rejected": -3.978105306625366,
      "step": 2325
    },
    {
      "epoch": 0.9304,
      "grad_norm": 0.008643749170005322,
      "learning_rate": 6.9e-07,
      "logits/chosen": -2.9978342056274414,
      "logits/rejected": -2.233633041381836,
      "logps/chosen": -75.66007995605469,
      "logps/rejected": -148.20660400390625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2734673023223877,
      "rewards/margins": 10.279333114624023,
      "rewards/rejected": -8.005866050720215,
      "step": 2326
    },
    {
      "epoch": 0.9308,
      "grad_norm": 0.597796618938446,
      "learning_rate": 6.898666666666665e-07,
      "logits/chosen": -2.871919631958008,
      "logits/rejected": -2.2048628330230713,
      "logps/chosen": -172.63412475585938,
      "logps/rejected": -149.35263061523438,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.821163535118103,
      "rewards/margins": 7.265111923217773,
      "rewards/rejected": -8.086275100708008,
      "step": 2327
    },
    {
      "epoch": 0.9312,
      "grad_norm": 3.5781636238098145,
      "learning_rate": 6.897333333333332e-07,
      "logits/chosen": -3.0707952976226807,
      "logits/rejected": -2.8237686157226562,
      "logps/chosen": -98.15769958496094,
      "logps/rejected": -67.98611450195312,
      "loss": 0.0366,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1772586852312088,
      "rewards/margins": 3.4285922050476074,
      "rewards/rejected": -3.251333236694336,
      "step": 2328
    },
    {
      "epoch": 0.9316,
      "grad_norm": 2.06817626953125,
      "learning_rate": 6.895999999999999e-07,
      "logits/chosen": -3.259713649749756,
      "logits/rejected": -2.8217673301696777,
      "logps/chosen": -73.63580322265625,
      "logps/rejected": -151.9599609375,
      "loss": 0.0212,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0383622646331787,
      "rewards/margins": 7.589702606201172,
      "rewards/rejected": -8.62806510925293,
      "step": 2329
    },
    {
      "epoch": 0.932,
      "grad_norm": 2.286832332611084,
      "learning_rate": 6.894666666666666e-07,
      "logits/chosen": -2.856541395187378,
      "logits/rejected": -2.83314847946167,
      "logps/chosen": -79.39966583251953,
      "logps/rejected": -77.56336212158203,
      "loss": 0.0226,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3668479919433594,
      "rewards/margins": 4.796586990356445,
      "rewards/rejected": -3.429739236831665,
      "step": 2330
    },
    {
      "epoch": 0.9324,
      "grad_norm": 3.2771389484405518,
      "learning_rate": 6.893333333333333e-07,
      "logits/chosen": -2.4600632190704346,
      "logits/rejected": -2.2058234214782715,
      "logps/chosen": -174.0565185546875,
      "logps/rejected": -135.0458526611328,
      "loss": 0.0277,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.955819845199585,
      "rewards/margins": 3.577336311340332,
      "rewards/rejected": -5.533156394958496,
      "step": 2331
    },
    {
      "epoch": 0.9328,
      "grad_norm": 0.25157874822616577,
      "learning_rate": 6.892e-07,
      "logits/chosen": -3.0114316940307617,
      "logits/rejected": -2.5835471153259277,
      "logps/chosen": -108.52840423583984,
      "logps/rejected": -165.04031372070312,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6968231201171875,
      "rewards/margins": 8.706117630004883,
      "rewards/rejected": -9.40294075012207,
      "step": 2332
    },
    {
      "epoch": 0.9332,
      "grad_norm": 2.813526153564453,
      "learning_rate": 6.890666666666667e-07,
      "logits/chosen": -2.8502306938171387,
      "logits/rejected": -2.530613660812378,
      "logps/chosen": -91.44050598144531,
      "logps/rejected": -85.02655029296875,
      "loss": 0.0282,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.19125118851661682,
      "rewards/margins": 4.949504375457764,
      "rewards/rejected": -5.140755653381348,
      "step": 2333
    },
    {
      "epoch": 0.9336,
      "grad_norm": 0.6209916472434998,
      "learning_rate": 6.889333333333333e-07,
      "logits/chosen": -2.8560678958892822,
      "logits/rejected": -2.2241978645324707,
      "logps/chosen": -74.74400329589844,
      "logps/rejected": -122.27779388427734,
      "loss": 0.0063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09071503579616547,
      "rewards/margins": 5.697824478149414,
      "rewards/rejected": -5.607109069824219,
      "step": 2334
    },
    {
      "epoch": 0.934,
      "grad_norm": 0.10028934478759766,
      "learning_rate": 6.888e-07,
      "logits/chosen": -2.446542739868164,
      "logits/rejected": -1.7291884422302246,
      "logps/chosen": -134.44578552246094,
      "logps/rejected": -218.8925018310547,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.165032982826233,
      "rewards/margins": 7.680359840393066,
      "rewards/rejected": -6.515326499938965,
      "step": 2335
    },
    {
      "epoch": 0.9344,
      "grad_norm": 0.028788449242711067,
      "learning_rate": 6.886666666666667e-07,
      "logits/chosen": -2.713045597076416,
      "logits/rejected": -2.0452046394348145,
      "logps/chosen": -116.3006591796875,
      "logps/rejected": -180.33697509765625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02410164475440979,
      "rewards/margins": 8.816732406616211,
      "rewards/rejected": -8.792630195617676,
      "step": 2336
    },
    {
      "epoch": 0.9348,
      "grad_norm": 0.007557657081633806,
      "learning_rate": 6.885333333333333e-07,
      "logits/chosen": -2.776853322982788,
      "logits/rejected": -2.0164365768432617,
      "logps/chosen": -112.34353637695312,
      "logps/rejected": -181.60665893554688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6709667444229126,
      "rewards/margins": 10.394793510437012,
      "rewards/rejected": -9.723827362060547,
      "step": 2337
    },
    {
      "epoch": 0.9352,
      "grad_norm": 0.04058929905295372,
      "learning_rate": 6.883999999999999e-07,
      "logits/chosen": -2.8347301483154297,
      "logits/rejected": -2.0033016204833984,
      "logps/chosen": -94.33639526367188,
      "logps/rejected": -148.23236083984375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7362602353096008,
      "rewards/margins": 9.065183639526367,
      "rewards/rejected": -8.328923225402832,
      "step": 2338
    },
    {
      "epoch": 0.9356,
      "grad_norm": 0.2666988968849182,
      "learning_rate": 6.882666666666666e-07,
      "logits/chosen": -3.050601005554199,
      "logits/rejected": -2.6289005279541016,
      "logps/chosen": -76.22792053222656,
      "logps/rejected": -114.19535827636719,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2760326564311981,
      "rewards/margins": 6.088484764099121,
      "rewards/rejected": -5.81245231628418,
      "step": 2339
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.8248170018196106,
      "learning_rate": 6.881333333333333e-07,
      "logits/chosen": -3.1974754333496094,
      "logits/rejected": -2.6421914100646973,
      "logps/chosen": -53.65339660644531,
      "logps/rejected": -89.9584732055664,
      "loss": 0.0099,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.321297287940979,
      "rewards/margins": 4.858095169067383,
      "rewards/rejected": -4.536797523498535,
      "step": 2340
    },
    {
      "epoch": 0.9364,
      "grad_norm": 0.06877046823501587,
      "learning_rate": 6.879999999999999e-07,
      "logits/chosen": -3.293245792388916,
      "logits/rejected": -2.4379165172576904,
      "logps/chosen": -62.82893371582031,
      "logps/rejected": -134.36517333984375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06091422587633133,
      "rewards/margins": 7.638004302978516,
      "rewards/rejected": -7.577089786529541,
      "step": 2341
    },
    {
      "epoch": 0.9368,
      "grad_norm": 1.0889240503311157,
      "learning_rate": 6.878666666666666e-07,
      "logits/chosen": -3.0780293941497803,
      "logits/rejected": -2.4811973571777344,
      "logps/chosen": -70.65252685546875,
      "logps/rejected": -101.85472106933594,
      "loss": 0.0106,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0018547028303146362,
      "rewards/margins": 5.685248851776123,
      "rewards/rejected": -5.683394432067871,
      "step": 2342
    },
    {
      "epoch": 0.9372,
      "grad_norm": 2.0502536296844482,
      "learning_rate": 6.877333333333333e-07,
      "logits/chosen": -2.972426414489746,
      "logits/rejected": -2.5419530868530273,
      "logps/chosen": -76.01823425292969,
      "logps/rejected": -121.94952392578125,
      "loss": 0.018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.06162413954734802,
      "rewards/margins": 6.499229431152344,
      "rewards/rejected": -6.560853958129883,
      "step": 2343
    },
    {
      "epoch": 0.9376,
      "grad_norm": 0.6799104809761047,
      "learning_rate": 6.876e-07,
      "logits/chosen": -3.075596809387207,
      "logits/rejected": -2.9123542308807373,
      "logps/chosen": -89.30706787109375,
      "logps/rejected": -83.46919250488281,
      "loss": 0.0072,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6929386258125305,
      "rewards/margins": 4.932233810424805,
      "rewards/rejected": -4.23929500579834,
      "step": 2344
    },
    {
      "epoch": 0.938,
      "grad_norm": 1.7451870441436768,
      "learning_rate": 6.874666666666667e-07,
      "logits/chosen": -3.2308311462402344,
      "logits/rejected": -2.6534829139709473,
      "logps/chosen": -81.8941650390625,
      "logps/rejected": -112.12730407714844,
      "loss": 0.0116,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.283087968826294,
      "rewards/margins": 5.393765449523926,
      "rewards/rejected": -6.676853179931641,
      "step": 2345
    },
    {
      "epoch": 0.9384,
      "grad_norm": 0.47113457322120667,
      "learning_rate": 6.873333333333334e-07,
      "logits/chosen": -3.0414910316467285,
      "logits/rejected": -2.2952921390533447,
      "logps/chosen": -90.40455627441406,
      "logps/rejected": -104.97727966308594,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.266296625137329,
      "rewards/margins": 7.015109062194824,
      "rewards/rejected": -5.748812675476074,
      "step": 2346
    },
    {
      "epoch": 0.9388,
      "grad_norm": 0.21166515350341797,
      "learning_rate": 6.872e-07,
      "logits/chosen": -2.7475838661193848,
      "logits/rejected": -2.0606191158294678,
      "logps/chosen": -135.94656372070312,
      "logps/rejected": -118.52619934082031,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.569653332233429,
      "rewards/margins": 6.077176570892334,
      "rewards/rejected": -6.646829605102539,
      "step": 2347
    },
    {
      "epoch": 0.9392,
      "grad_norm": 11.695137977600098,
      "learning_rate": 6.870666666666667e-07,
      "logits/chosen": -2.9063010215759277,
      "logits/rejected": -2.723674774169922,
      "logps/chosen": -130.60386657714844,
      "logps/rejected": -114.65695190429688,
      "loss": 0.0857,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.1289615631103516,
      "rewards/margins": 3.7587170600891113,
      "rewards/rejected": -5.887678623199463,
      "step": 2348
    },
    {
      "epoch": 0.9396,
      "grad_norm": 1.890223741531372,
      "learning_rate": 6.869333333333332e-07,
      "logits/chosen": -2.7502355575561523,
      "logits/rejected": -2.8424596786499023,
      "logps/chosen": -64.93077087402344,
      "logps/rejected": -143.87013244628906,
      "loss": 0.0126,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.30616146326065063,
      "rewards/margins": 6.620940685272217,
      "rewards/rejected": -6.927102088928223,
      "step": 2349
    },
    {
      "epoch": 0.94,
      "grad_norm": 4.684335708618164,
      "learning_rate": 6.867999999999999e-07,
      "logits/chosen": -3.078181743621826,
      "logits/rejected": -3.0656044483184814,
      "logps/chosen": -87.46696472167969,
      "logps/rejected": -78.6007308959961,
      "loss": 0.0579,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.07919922471046448,
      "rewards/margins": 4.022650718688965,
      "rewards/rejected": -4.101849555969238,
      "step": 2350
    },
    {
      "epoch": 0.9404,
      "grad_norm": 1.5947452783584595,
      "learning_rate": 6.866666666666666e-07,
      "logits/chosen": -2.610659599304199,
      "logits/rejected": -2.122377395629883,
      "logps/chosen": -143.30899047851562,
      "logps/rejected": -117.22225952148438,
      "loss": 0.0136,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6588940024375916,
      "rewards/margins": 6.464585781097412,
      "rewards/rejected": -5.805691719055176,
      "step": 2351
    },
    {
      "epoch": 0.9408,
      "grad_norm": 1.0499314069747925,
      "learning_rate": 6.865333333333333e-07,
      "logits/chosen": -3.1530275344848633,
      "logits/rejected": -2.6655569076538086,
      "logps/chosen": -116.23580169677734,
      "logps/rejected": -117.94853210449219,
      "loss": 0.0082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07734222710132599,
      "rewards/margins": 5.865992546081543,
      "rewards/rejected": -5.7886505126953125,
      "step": 2352
    },
    {
      "epoch": 0.9412,
      "grad_norm": 1.079278588294983,
      "learning_rate": 6.864e-07,
      "logits/chosen": -3.01483154296875,
      "logits/rejected": -2.438150644302368,
      "logps/chosen": -64.31874084472656,
      "logps/rejected": -92.1711196899414,
      "loss": 0.0161,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.505472183227539,
      "rewards/margins": 6.233674049377441,
      "rewards/rejected": -4.7282023429870605,
      "step": 2353
    },
    {
      "epoch": 0.9416,
      "grad_norm": 0.5880475640296936,
      "learning_rate": 6.862666666666667e-07,
      "logits/chosen": -3.1078929901123047,
      "logits/rejected": -2.828543186187744,
      "logps/chosen": -91.84115600585938,
      "logps/rejected": -109.12623596191406,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.06937123090028763,
      "rewards/margins": 5.992475509643555,
      "rewards/rejected": -6.061846733093262,
      "step": 2354
    },
    {
      "epoch": 0.942,
      "grad_norm": 0.056352414190769196,
      "learning_rate": 6.861333333333334e-07,
      "logits/chosen": -2.6444365978240967,
      "logits/rejected": -1.8551127910614014,
      "logps/chosen": -109.34410858154297,
      "logps/rejected": -166.59149169921875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4979400634765625,
      "rewards/margins": 8.59846019744873,
      "rewards/rejected": -9.096400260925293,
      "step": 2355
    },
    {
      "epoch": 0.9424,
      "grad_norm": 0.03963223472237587,
      "learning_rate": 6.86e-07,
      "logits/chosen": -2.932386875152588,
      "logits/rejected": -2.170041084289551,
      "logps/chosen": -110.73051452636719,
      "logps/rejected": -181.31890869140625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4658359885215759,
      "rewards/margins": 10.816428184509277,
      "rewards/rejected": -10.350591659545898,
      "step": 2356
    },
    {
      "epoch": 0.9428,
      "grad_norm": 0.03645952790975571,
      "learning_rate": 6.858666666666666e-07,
      "logits/chosen": -3.011136054992676,
      "logits/rejected": -2.3925533294677734,
      "logps/chosen": -49.28907775878906,
      "logps/rejected": -173.0676727294922,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2858266830444336,
      "rewards/margins": 10.374524116516113,
      "rewards/rejected": -10.08869743347168,
      "step": 2357
    },
    {
      "epoch": 0.9432,
      "grad_norm": 0.13555940985679626,
      "learning_rate": 6.857333333333333e-07,
      "logits/chosen": -2.9842305183410645,
      "logits/rejected": -2.247217893600464,
      "logps/chosen": -103.58940887451172,
      "logps/rejected": -139.41455078125,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.031154252588748932,
      "rewards/margins": 8.06039810180664,
      "rewards/rejected": -8.029244422912598,
      "step": 2358
    },
    {
      "epoch": 0.9436,
      "grad_norm": 63.95296859741211,
      "learning_rate": 6.855999999999999e-07,
      "logits/chosen": -2.9071335792541504,
      "logits/rejected": -2.722456216812134,
      "logps/chosen": -81.73350524902344,
      "logps/rejected": -100.60350036621094,
      "loss": 1.2768,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -3.8299601078033447,
      "rewards/margins": 1.3769638538360596,
      "rewards/rejected": -5.206923961639404,
      "step": 2359
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.0647006705403328,
      "learning_rate": 6.854666666666666e-07,
      "logits/chosen": -2.9225149154663086,
      "logits/rejected": -2.4601988792419434,
      "logps/chosen": -140.4776611328125,
      "logps/rejected": -151.38333129882812,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.155664086341858,
      "rewards/margins": 7.8772077560424805,
      "rewards/rejected": -9.03287124633789,
      "step": 2360
    },
    {
      "epoch": 0.9444,
      "grad_norm": 0.08055813610553741,
      "learning_rate": 6.853333333333333e-07,
      "logits/chosen": -2.8417234420776367,
      "logits/rejected": -2.162959337234497,
      "logps/chosen": -80.62274169921875,
      "logps/rejected": -212.7862548828125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6359791159629822,
      "rewards/margins": 10.894466400146484,
      "rewards/rejected": -10.2584867477417,
      "step": 2361
    },
    {
      "epoch": 0.9448,
      "grad_norm": 1.514373779296875,
      "learning_rate": 6.852e-07,
      "logits/chosen": -3.1601309776306152,
      "logits/rejected": -2.7677552700042725,
      "logps/chosen": -105.73240661621094,
      "logps/rejected": -93.702392578125,
      "loss": 0.0159,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.15740814805030823,
      "rewards/margins": 4.7293901443481445,
      "rewards/rejected": -4.886797904968262,
      "step": 2362
    },
    {
      "epoch": 0.9452,
      "grad_norm": 0.05954454466700554,
      "learning_rate": 6.850666666666667e-07,
      "logits/chosen": -2.6376633644104004,
      "logits/rejected": -1.6845018863677979,
      "logps/chosen": -60.25726318359375,
      "logps/rejected": -144.630126953125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7409271001815796,
      "rewards/margins": 9.965557098388672,
      "rewards/rejected": -9.224630355834961,
      "step": 2363
    },
    {
      "epoch": 0.9456,
      "grad_norm": 0.4149104356765747,
      "learning_rate": 6.849333333333333e-07,
      "logits/chosen": -3.084152936935425,
      "logits/rejected": -2.432155132293701,
      "logps/chosen": -108.79556274414062,
      "logps/rejected": -155.7051239013672,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6200512647628784,
      "rewards/margins": 7.795564651489258,
      "rewards/rejected": -9.415616035461426,
      "step": 2364
    },
    {
      "epoch": 0.946,
      "grad_norm": 0.48304086923599243,
      "learning_rate": 6.847999999999999e-07,
      "logits/chosen": -2.9279446601867676,
      "logits/rejected": -2.3789479732513428,
      "logps/chosen": -75.8376235961914,
      "logps/rejected": -130.93734741210938,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5367622375488281,
      "rewards/margins": 8.684321403503418,
      "rewards/rejected": -8.14755916595459,
      "step": 2365
    },
    {
      "epoch": 0.9464,
      "grad_norm": 1.0651459693908691,
      "learning_rate": 6.846666666666666e-07,
      "logits/chosen": -2.982480049133301,
      "logits/rejected": -2.3739659786224365,
      "logps/chosen": -74.03175354003906,
      "logps/rejected": -100.49689483642578,
      "loss": 0.0093,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13012811541557312,
      "rewards/margins": 5.058046340942383,
      "rewards/rejected": -4.927917957305908,
      "step": 2366
    },
    {
      "epoch": 0.9468,
      "grad_norm": 0.0862874686717987,
      "learning_rate": 6.845333333333333e-07,
      "logits/chosen": -2.9335203170776367,
      "logits/rejected": -2.398099184036255,
      "logps/chosen": -99.55844116210938,
      "logps/rejected": -125.14942932128906,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.008673664182424545,
      "rewards/margins": 8.077775955200195,
      "rewards/rejected": -8.06910228729248,
      "step": 2367
    },
    {
      "epoch": 0.9472,
      "grad_norm": 0.6321432590484619,
      "learning_rate": 6.844e-07,
      "logits/chosen": -2.689713478088379,
      "logits/rejected": -2.319082021713257,
      "logps/chosen": -160.022705078125,
      "logps/rejected": -99.9803237915039,
      "loss": 0.0064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.41742444038391113,
      "rewards/margins": 5.162207126617432,
      "rewards/rejected": -5.579631805419922,
      "step": 2368
    },
    {
      "epoch": 0.9476,
      "grad_norm": 0.20135392248630524,
      "learning_rate": 6.842666666666667e-07,
      "logits/chosen": -2.9647722244262695,
      "logits/rejected": -2.3305773735046387,
      "logps/chosen": -105.00225830078125,
      "logps/rejected": -146.77059936523438,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8656650185585022,
      "rewards/margins": 9.152048110961914,
      "rewards/rejected": -8.286383628845215,
      "step": 2369
    },
    {
      "epoch": 0.948,
      "grad_norm": 0.06141040846705437,
      "learning_rate": 6.841333333333333e-07,
      "logits/chosen": -2.9232895374298096,
      "logits/rejected": -2.3641343116760254,
      "logps/chosen": -106.77030944824219,
      "logps/rejected": -140.18531799316406,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.038119882345199585,
      "rewards/margins": 8.4425048828125,
      "rewards/rejected": -8.404385566711426,
      "step": 2370
    },
    {
      "epoch": 0.9484,
      "grad_norm": 3.952126979827881,
      "learning_rate": 6.84e-07,
      "logits/chosen": -2.906200885772705,
      "logits/rejected": -2.372056484222412,
      "logps/chosen": -213.4661865234375,
      "logps/rejected": -179.2802734375,
      "loss": 0.0177,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2670029401779175,
      "rewards/margins": 5.6990580558776855,
      "rewards/rejected": -6.966061115264893,
      "step": 2371
    },
    {
      "epoch": 0.9488,
      "grad_norm": 0.9735977649688721,
      "learning_rate": 6.838666666666666e-07,
      "logits/chosen": -3.149695873260498,
      "logits/rejected": -2.680544376373291,
      "logps/chosen": -85.68052673339844,
      "logps/rejected": -118.38971710205078,
      "loss": 0.0095,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.742285966873169,
      "rewards/margins": 4.744978904724121,
      "rewards/rejected": -6.487265110015869,
      "step": 2372
    },
    {
      "epoch": 0.9492,
      "grad_norm": 0.050674859434366226,
      "learning_rate": 6.837333333333333e-07,
      "logits/chosen": -2.598912239074707,
      "logits/rejected": -1.9277633428573608,
      "logps/chosen": -116.72779846191406,
      "logps/rejected": -125.93644714355469,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5910571813583374,
      "rewards/margins": 8.225525856018066,
      "rewards/rejected": -7.6344685554504395,
      "step": 2373
    },
    {
      "epoch": 0.9496,
      "grad_norm": 0.8367711305618286,
      "learning_rate": 6.836e-07,
      "logits/chosen": -2.9802567958831787,
      "logits/rejected": -2.1734399795532227,
      "logps/chosen": -90.71719360351562,
      "logps/rejected": -109.33192443847656,
      "loss": 0.0081,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5602021813392639,
      "rewards/margins": 6.289268493652344,
      "rewards/rejected": -5.729066848754883,
      "step": 2374
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.89208722114563,
      "learning_rate": 6.834666666666666e-07,
      "logits/chosen": -2.8027477264404297,
      "logits/rejected": -2.3301572799682617,
      "logps/chosen": -145.74351501464844,
      "logps/rejected": -140.3123321533203,
      "loss": 0.0217,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3542335629463196,
      "rewards/margins": 7.499378681182861,
      "rewards/rejected": -7.853611946105957,
      "step": 2375
    },
    {
      "epoch": 0.9504,
      "grad_norm": 0.028468722477555275,
      "learning_rate": 6.833333333333333e-07,
      "logits/chosen": -2.823495864868164,
      "logits/rejected": -1.9535107612609863,
      "logps/chosen": -118.31336975097656,
      "logps/rejected": -168.84603881835938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7703083157539368,
      "rewards/margins": 9.789690971374512,
      "rewards/rejected": -9.01938247680664,
      "step": 2376
    },
    {
      "epoch": 0.9508,
      "grad_norm": 0.1223735436797142,
      "learning_rate": 6.832e-07,
      "logits/chosen": -2.690915822982788,
      "logits/rejected": -2.083031177520752,
      "logps/chosen": -155.46652221679688,
      "logps/rejected": -147.40191650390625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.032363295555114746,
      "rewards/margins": 7.849008560180664,
      "rewards/rejected": -7.816644668579102,
      "step": 2377
    },
    {
      "epoch": 0.9512,
      "grad_norm": 62.526771545410156,
      "learning_rate": 6.830666666666667e-07,
      "logits/chosen": -2.3822922706604004,
      "logits/rejected": -2.1681907176971436,
      "logps/chosen": -187.6741943359375,
      "logps/rejected": -92.27094268798828,
      "loss": 0.3854,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -3.977217435836792,
      "rewards/margins": 1.7300721406936646,
      "rewards/rejected": -5.707289695739746,
      "step": 2378
    },
    {
      "epoch": 0.9516,
      "grad_norm": 0.12017592042684555,
      "learning_rate": 6.829333333333333e-07,
      "logits/chosen": -3.0288515090942383,
      "logits/rejected": -2.61708664894104,
      "logps/chosen": -69.46199035644531,
      "logps/rejected": -129.57589721679688,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6362373232841492,
      "rewards/margins": 7.305492401123047,
      "rewards/rejected": -6.669255256652832,
      "step": 2379
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.5763167142868042,
      "learning_rate": 6.827999999999999e-07,
      "logits/chosen": -2.7092370986938477,
      "logits/rejected": -2.40342378616333,
      "logps/chosen": -234.84523010253906,
      "logps/rejected": -149.3460693359375,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.880085825920105,
      "rewards/margins": 5.652603626251221,
      "rewards/rejected": -7.532689094543457,
      "step": 2380
    },
    {
      "epoch": 0.9524,
      "grad_norm": 3.0140957832336426,
      "learning_rate": 6.826666666666666e-07,
      "logits/chosen": -3.0051422119140625,
      "logits/rejected": -2.701115608215332,
      "logps/chosen": -82.87089538574219,
      "logps/rejected": -70.86767578125,
      "loss": 0.0334,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.039398565888404846,
      "rewards/margins": 3.3975930213928223,
      "rewards/rejected": -3.4369916915893555,
      "step": 2381
    },
    {
      "epoch": 0.9528,
      "grad_norm": 0.1425725668668747,
      "learning_rate": 6.825333333333333e-07,
      "logits/chosen": -3.258692979812622,
      "logits/rejected": -2.6879167556762695,
      "logps/chosen": -36.94462966918945,
      "logps/rejected": -125.70375061035156,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2857602834701538,
      "rewards/margins": 9.308757781982422,
      "rewards/rejected": -8.022997856140137,
      "step": 2382
    },
    {
      "epoch": 0.9532,
      "grad_norm": 0.019474735483527184,
      "learning_rate": 6.824e-07,
      "logits/chosen": -2.974325656890869,
      "logits/rejected": -2.2289552688598633,
      "logps/chosen": -64.91659545898438,
      "logps/rejected": -149.06890869140625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8705606460571289,
      "rewards/margins": 9.349367141723633,
      "rewards/rejected": -8.478805541992188,
      "step": 2383
    },
    {
      "epoch": 0.9536,
      "grad_norm": 7.484555721282959,
      "learning_rate": 6.822666666666666e-07,
      "logits/chosen": -3.05733585357666,
      "logits/rejected": -2.8287086486816406,
      "logps/chosen": -69.72589874267578,
      "logps/rejected": -61.59659194946289,
      "loss": 0.1131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8134664297103882,
      "rewards/margins": 2.5265889167785645,
      "rewards/rejected": -3.340055227279663,
      "step": 2384
    },
    {
      "epoch": 0.954,
      "grad_norm": 0.005824683699756861,
      "learning_rate": 6.821333333333333e-07,
      "logits/chosen": -2.518892765045166,
      "logits/rejected": -1.8362826108932495,
      "logps/chosen": -174.880126953125,
      "logps/rejected": -226.52798461914062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4617042541503906,
      "rewards/margins": 11.246232986450195,
      "rewards/rejected": -9.784528732299805,
      "step": 2385
    },
    {
      "epoch": 0.9544,
      "grad_norm": 0.5607801079750061,
      "learning_rate": 6.82e-07,
      "logits/chosen": -2.7402184009552,
      "logits/rejected": -2.1567018032073975,
      "logps/chosen": -111.48348999023438,
      "logps/rejected": -150.6319580078125,
      "loss": 0.0055,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.29121479392051697,
      "rewards/margins": 6.925380706787109,
      "rewards/rejected": -6.6341657638549805,
      "step": 2386
    },
    {
      "epoch": 0.9548,
      "grad_norm": 0.0013789191143587232,
      "learning_rate": 6.818666666666666e-07,
      "logits/chosen": -2.692265033721924,
      "logits/rejected": -1.9620411396026611,
      "logps/chosen": -102.29536437988281,
      "logps/rejected": -233.08193969726562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1229310035705566,
      "rewards/margins": 12.662601470947266,
      "rewards/rejected": -10.539670944213867,
      "step": 2387
    },
    {
      "epoch": 0.9552,
      "grad_norm": 9.065903663635254,
      "learning_rate": 6.817333333333333e-07,
      "logits/chosen": -2.594879150390625,
      "logits/rejected": -2.214259624481201,
      "logps/chosen": -138.50416564941406,
      "logps/rejected": -114.7020263671875,
      "loss": 0.0702,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5192577838897705,
      "rewards/margins": 5.90758752822876,
      "rewards/rejected": -6.426845550537109,
      "step": 2388
    },
    {
      "epoch": 0.9556,
      "grad_norm": 0.01088711153715849,
      "learning_rate": 6.816e-07,
      "logits/chosen": -2.738555669784546,
      "logits/rejected": -1.9726011753082275,
      "logps/chosen": -193.08087158203125,
      "logps/rejected": -200.87359619140625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3533272743225098,
      "rewards/margins": 9.903890609741211,
      "rewards/rejected": -11.257218360900879,
      "step": 2389
    },
    {
      "epoch": 0.956,
      "grad_norm": 0.2876991927623749,
      "learning_rate": 6.814666666666667e-07,
      "logits/chosen": -2.930548667907715,
      "logits/rejected": -2.335710287094116,
      "logps/chosen": -121.10609436035156,
      "logps/rejected": -182.43174743652344,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7243118286132812,
      "rewards/margins": 7.3372602462768555,
      "rewards/rejected": -8.061572074890137,
      "step": 2390
    },
    {
      "epoch": 0.9564,
      "grad_norm": 0.017528563737869263,
      "learning_rate": 6.813333333333333e-07,
      "logits/chosen": -2.861006259918213,
      "logits/rejected": -2.1086442470550537,
      "logps/chosen": -62.63442611694336,
      "logps/rejected": -167.3992919921875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10961342602968216,
      "rewards/margins": 9.231271743774414,
      "rewards/rejected": -9.121658325195312,
      "step": 2391
    },
    {
      "epoch": 0.9568,
      "grad_norm": 0.4573095440864563,
      "learning_rate": 6.812e-07,
      "logits/chosen": -3.154724359512329,
      "logits/rejected": -2.6557579040527344,
      "logps/chosen": -102.3486328125,
      "logps/rejected": -149.87460327148438,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8834018707275391,
      "rewards/margins": 6.788216590881348,
      "rewards/rejected": -7.671618461608887,
      "step": 2392
    },
    {
      "epoch": 0.9572,
      "grad_norm": 0.46022555232048035,
      "learning_rate": 6.810666666666667e-07,
      "logits/chosen": -2.8516621589660645,
      "logits/rejected": -2.316483497619629,
      "logps/chosen": -152.0968780517578,
      "logps/rejected": -126.25662994384766,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9174435138702393,
      "rewards/margins": 6.8250579833984375,
      "rewards/rejected": -7.742501258850098,
      "step": 2393
    },
    {
      "epoch": 0.9576,
      "grad_norm": 2.411602258682251,
      "learning_rate": 6.809333333333332e-07,
      "logits/chosen": -2.965491771697998,
      "logits/rejected": -2.6035046577453613,
      "logps/chosen": -119.07550048828125,
      "logps/rejected": -117.73478698730469,
      "loss": 0.0254,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4922535419464111,
      "rewards/margins": 5.141861915588379,
      "rewards/rejected": -6.634115695953369,
      "step": 2394
    },
    {
      "epoch": 0.958,
      "grad_norm": 0.35713401436805725,
      "learning_rate": 6.807999999999999e-07,
      "logits/chosen": -2.506704330444336,
      "logits/rejected": -1.7511457204818726,
      "logps/chosen": -111.28021240234375,
      "logps/rejected": -120.66110229492188,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6164894104003906,
      "rewards/margins": 6.034152030944824,
      "rewards/rejected": -5.417662620544434,
      "step": 2395
    },
    {
      "epoch": 0.9584,
      "grad_norm": 1.6208503246307373,
      "learning_rate": 6.806666666666666e-07,
      "logits/chosen": -2.78584623336792,
      "logits/rejected": -2.3841753005981445,
      "logps/chosen": -50.46931076049805,
      "logps/rejected": -110.739501953125,
      "loss": 0.0157,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5817278027534485,
      "rewards/margins": 4.1496171951293945,
      "rewards/rejected": -4.731345176696777,
      "step": 2396
    },
    {
      "epoch": 0.9588,
      "grad_norm": 171.8470001220703,
      "learning_rate": 6.805333333333333e-07,
      "logits/chosen": -2.4927892684936523,
      "logits/rejected": -2.2165234088897705,
      "logps/chosen": -346.8841247558594,
      "logps/rejected": -148.44403076171875,
      "loss": 1.1366,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -4.895742893218994,
      "rewards/margins": 3.0711803436279297,
      "rewards/rejected": -7.966923713684082,
      "step": 2397
    },
    {
      "epoch": 0.9592,
      "grad_norm": 0.6829119920730591,
      "learning_rate": 6.804e-07,
      "logits/chosen": -3.1942691802978516,
      "logits/rejected": -2.721536874771118,
      "logps/chosen": -80.43460845947266,
      "logps/rejected": -108.54524230957031,
      "loss": 0.005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4732086658477783,
      "rewards/margins": 6.513683795928955,
      "rewards/rejected": -6.040475368499756,
      "step": 2398
    },
    {
      "epoch": 0.9596,
      "grad_norm": 3.2115204334259033,
      "learning_rate": 6.802666666666667e-07,
      "logits/chosen": -3.0287342071533203,
      "logits/rejected": -2.7581069469451904,
      "logps/chosen": -143.25253295898438,
      "logps/rejected": -114.63542175292969,
      "loss": 0.0273,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0364052057266235,
      "rewards/margins": 5.152367115020752,
      "rewards/rejected": -6.188772201538086,
      "step": 2399
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.003629399696364999,
      "learning_rate": 6.801333333333334e-07,
      "logits/chosen": -2.720167875289917,
      "logits/rejected": -1.7237422466278076,
      "logps/chosen": -91.25900268554688,
      "logps/rejected": -150.32566833496094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.890730381011963,
      "rewards/margins": 10.945691108703613,
      "rewards/rejected": -9.054960250854492,
      "step": 2400
    },
    {
      "epoch": 0.9604,
      "grad_norm": 9.629170417785645,
      "learning_rate": 6.800000000000001e-07,
      "logits/chosen": -2.988065719604492,
      "logits/rejected": -2.42177677154541,
      "logps/chosen": -124.92718505859375,
      "logps/rejected": -109.186279296875,
      "loss": 0.0899,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7364368438720703,
      "rewards/margins": 4.79764461517334,
      "rewards/rejected": -5.53408145904541,
      "step": 2401
    },
    {
      "epoch": 0.9608,
      "grad_norm": 21.87975311279297,
      "learning_rate": 6.798666666666666e-07,
      "logits/chosen": -2.483293056488037,
      "logits/rejected": -1.8034251928329468,
      "logps/chosen": -154.5802001953125,
      "logps/rejected": -126.93509674072266,
      "loss": 0.103,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.272054672241211,
      "rewards/margins": 5.544271945953369,
      "rewards/rejected": -7.81632661819458,
      "step": 2402
    },
    {
      "epoch": 0.9612,
      "grad_norm": 0.04837647080421448,
      "learning_rate": 6.797333333333332e-07,
      "logits/chosen": -2.526455879211426,
      "logits/rejected": -1.7601866722106934,
      "logps/chosen": -146.86785888671875,
      "logps/rejected": -146.28225708007812,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4712947607040405,
      "rewards/margins": 8.10661792755127,
      "rewards/rejected": -8.577913284301758,
      "step": 2403
    },
    {
      "epoch": 0.9616,
      "grad_norm": 54.3375358581543,
      "learning_rate": 6.795999999999999e-07,
      "logits/chosen": -3.2606801986694336,
      "logits/rejected": -3.4665427207946777,
      "logps/chosen": -96.74031066894531,
      "logps/rejected": -60.65448760986328,
      "loss": 0.4329,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4828546047210693,
      "rewards/margins": 0.8330417275428772,
      "rewards/rejected": -2.315896511077881,
      "step": 2404
    },
    {
      "epoch": 0.962,
      "grad_norm": 0.03986659646034241,
      "learning_rate": 6.794666666666666e-07,
      "logits/chosen": -2.7153615951538086,
      "logits/rejected": -2.453704833984375,
      "logps/chosen": -64.97618103027344,
      "logps/rejected": -142.49871826171875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5903749465942383,
      "rewards/margins": 9.959421157836914,
      "rewards/rejected": -8.369047164916992,
      "step": 2405
    },
    {
      "epoch": 0.9624,
      "grad_norm": 0.5279046297073364,
      "learning_rate": 6.793333333333333e-07,
      "logits/chosen": -3.1552677154541016,
      "logits/rejected": -2.8025729656219482,
      "logps/chosen": -107.73539733886719,
      "logps/rejected": -113.61395263671875,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1919170469045639,
      "rewards/margins": 5.996041297912598,
      "rewards/rejected": -5.80412483215332,
      "step": 2406
    },
    {
      "epoch": 0.9628,
      "grad_norm": 9.648760795593262,
      "learning_rate": 6.792e-07,
      "logits/chosen": -2.6480863094329834,
      "logits/rejected": -2.209287643432617,
      "logps/chosen": -190.64700317382812,
      "logps/rejected": -178.3245849609375,
      "loss": 0.0713,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.3085122108459473,
      "rewards/margins": 2.6599998474121094,
      "rewards/rejected": -5.968512058258057,
      "step": 2407
    },
    {
      "epoch": 0.9632,
      "grad_norm": 0.03105715475976467,
      "learning_rate": 6.790666666666667e-07,
      "logits/chosen": -3.131160259246826,
      "logits/rejected": -2.529632091522217,
      "logps/chosen": -68.61335754394531,
      "logps/rejected": -131.53985595703125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4309188723564148,
      "rewards/margins": 8.480876922607422,
      "rewards/rejected": -8.049958229064941,
      "step": 2408
    },
    {
      "epoch": 0.9636,
      "grad_norm": 1.5116488933563232,
      "learning_rate": 6.789333333333334e-07,
      "logits/chosen": -3.0383219718933105,
      "logits/rejected": -2.7785754203796387,
      "logps/chosen": -64.93560791015625,
      "logps/rejected": -118.01765441894531,
      "loss": 0.0125,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09256857633590698,
      "rewards/margins": 4.663134574890137,
      "rewards/rejected": -4.570566177368164,
      "step": 2409
    },
    {
      "epoch": 0.964,
      "grad_norm": 0.00744278309866786,
      "learning_rate": 6.788e-07,
      "logits/chosen": -2.7929415702819824,
      "logits/rejected": -1.9581542015075684,
      "logps/chosen": -116.79658508300781,
      "logps/rejected": -150.81875610351562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1273564100265503,
      "rewards/margins": 10.391801834106445,
      "rewards/rejected": -9.264445304870605,
      "step": 2410
    },
    {
      "epoch": 0.9644,
      "grad_norm": 0.023166589438915253,
      "learning_rate": 6.786666666666667e-07,
      "logits/chosen": -2.817636728286743,
      "logits/rejected": -2.4311413764953613,
      "logps/chosen": -71.7509994506836,
      "logps/rejected": -153.06040954589844,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2364394664764404,
      "rewards/margins": 9.465875625610352,
      "rewards/rejected": -8.229436874389648,
      "step": 2411
    },
    {
      "epoch": 0.9648,
      "grad_norm": 1.6928876638412476,
      "learning_rate": 6.785333333333332e-07,
      "logits/chosen": -2.7916107177734375,
      "logits/rejected": -2.3908231258392334,
      "logps/chosen": -72.109130859375,
      "logps/rejected": -82.85212707519531,
      "loss": 0.0203,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3417610228061676,
      "rewards/margins": 4.317429065704346,
      "rewards/rejected": -3.975667953491211,
      "step": 2412
    },
    {
      "epoch": 0.9652,
      "grad_norm": 1.1384882926940918,
      "learning_rate": 6.783999999999999e-07,
      "logits/chosen": -2.836398124694824,
      "logits/rejected": -2.2212719917297363,
      "logps/chosen": -87.66768646240234,
      "logps/rejected": -106.73614501953125,
      "loss": 0.0116,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.26066702604293823,
      "rewards/margins": 5.809426784515381,
      "rewards/rejected": -5.548759460449219,
      "step": 2413
    },
    {
      "epoch": 0.9656,
      "grad_norm": 0.2894631028175354,
      "learning_rate": 6.782666666666666e-07,
      "logits/chosen": -3.1292035579681396,
      "logits/rejected": -2.5433857440948486,
      "logps/chosen": -65.86381530761719,
      "logps/rejected": -114.5821762084961,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8601215481758118,
      "rewards/margins": 7.866280555725098,
      "rewards/rejected": -7.006158828735352,
      "step": 2414
    },
    {
      "epoch": 0.966,
      "grad_norm": 0.07957793027162552,
      "learning_rate": 6.781333333333333e-07,
      "logits/chosen": -2.5491464138031006,
      "logits/rejected": -2.1627132892608643,
      "logps/chosen": -142.67945861816406,
      "logps/rejected": -170.2886962890625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7664386630058289,
      "rewards/margins": 8.044042587280273,
      "rewards/rejected": -8.810481071472168,
      "step": 2415
    },
    {
      "epoch": 0.9664,
      "grad_norm": 1.6788084506988525,
      "learning_rate": 6.78e-07,
      "logits/chosen": -2.717268228530884,
      "logits/rejected": -2.195518970489502,
      "logps/chosen": -101.37503051757812,
      "logps/rejected": -102.01372528076172,
      "loss": 0.0104,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3872818350791931,
      "rewards/margins": 5.117536544799805,
      "rewards/rejected": -5.504818439483643,
      "step": 2416
    },
    {
      "epoch": 0.9668,
      "grad_norm": 1.4137866497039795,
      "learning_rate": 6.778666666666666e-07,
      "logits/chosen": -2.936652183532715,
      "logits/rejected": -2.2117226123809814,
      "logps/chosen": -103.73312377929688,
      "logps/rejected": -161.32919311523438,
      "loss": 0.013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6821498870849609,
      "rewards/margins": 9.103046417236328,
      "rewards/rejected": -8.420896530151367,
      "step": 2417
    },
    {
      "epoch": 0.9672,
      "grad_norm": 0.10796623677015305,
      "learning_rate": 6.777333333333333e-07,
      "logits/chosen": -2.6858811378479004,
      "logits/rejected": -2.381471872329712,
      "logps/chosen": -103.75631713867188,
      "logps/rejected": -222.1002197265625,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.35553133487701416,
      "rewards/margins": 8.162141799926758,
      "rewards/rejected": -8.51767349243164,
      "step": 2418
    },
    {
      "epoch": 0.9676,
      "grad_norm": 0.24508433043956757,
      "learning_rate": 6.776e-07,
      "logits/chosen": -2.345892906188965,
      "logits/rejected": -1.8980375528335571,
      "logps/chosen": -205.52659606933594,
      "logps/rejected": -152.22422790527344,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4083518981933594,
      "rewards/margins": 7.796003341674805,
      "rewards/rejected": -8.204355239868164,
      "step": 2419
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.06321224570274353,
      "learning_rate": 6.774666666666667e-07,
      "logits/chosen": -2.73311710357666,
      "logits/rejected": -1.686453104019165,
      "logps/chosen": -84.41279602050781,
      "logps/rejected": -254.24459838867188,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4307835102081299,
      "rewards/margins": 9.977723121643066,
      "rewards/rejected": -8.546939849853516,
      "step": 2420
    },
    {
      "epoch": 0.9684,
      "grad_norm": 1.089471697807312,
      "learning_rate": 6.773333333333334e-07,
      "logits/chosen": -3.1959149837493896,
      "logits/rejected": -3.1736698150634766,
      "logps/chosen": -51.65007781982422,
      "logps/rejected": -93.83502197265625,
      "loss": 0.0105,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3723708987236023,
      "rewards/margins": 4.9560699462890625,
      "rewards/rejected": -4.5836992263793945,
      "step": 2421
    },
    {
      "epoch": 0.9688,
      "grad_norm": 28.073305130004883,
      "learning_rate": 6.772e-07,
      "logits/chosen": -2.7015204429626465,
      "logits/rejected": -2.1570701599121094,
      "logps/chosen": -155.17401123046875,
      "logps/rejected": -187.92367553710938,
      "loss": 0.2239,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0389915704727173,
      "rewards/margins": 5.816596508026123,
      "rewards/rejected": -6.855588436126709,
      "step": 2422
    },
    {
      "epoch": 0.9692,
      "grad_norm": 0.5782335996627808,
      "learning_rate": 6.770666666666666e-07,
      "logits/chosen": -3.221560478210449,
      "logits/rejected": -2.7327334880828857,
      "logps/chosen": -54.72434997558594,
      "logps/rejected": -94.54087829589844,
      "loss": 0.0056,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3162998557090759,
      "rewards/margins": 5.8738298416137695,
      "rewards/rejected": -5.557530403137207,
      "step": 2423
    },
    {
      "epoch": 0.9696,
      "grad_norm": 0.26514166593551636,
      "learning_rate": 6.769333333333333e-07,
      "logits/chosen": -2.746243953704834,
      "logits/rejected": -1.9227474927902222,
      "logps/chosen": -91.62217712402344,
      "logps/rejected": -147.03659057617188,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.46860599517822266,
      "rewards/margins": 7.230305194854736,
      "rewards/rejected": -7.698911190032959,
      "step": 2424
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6744874715805054,
      "learning_rate": 6.767999999999999e-07,
      "logits/chosen": -3.1346991062164307,
      "logits/rejected": -2.8352670669555664,
      "logps/chosen": -88.60941314697266,
      "logps/rejected": -104.42312622070312,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.29079359769821167,
      "rewards/margins": 5.50372314453125,
      "rewards/rejected": -5.794516563415527,
      "step": 2425
    },
    {
      "epoch": 0.9704,
      "grad_norm": 2.3787569999694824,
      "learning_rate": 6.766666666666666e-07,
      "logits/chosen": -3.1438393592834473,
      "logits/rejected": -2.7920279502868652,
      "logps/chosen": -58.41138458251953,
      "logps/rejected": -80.14543914794922,
      "loss": 0.0286,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6297200918197632,
      "rewards/margins": 4.269935131072998,
      "rewards/rejected": -3.6402149200439453,
      "step": 2426
    },
    {
      "epoch": 0.9708,
      "grad_norm": 0.6172745823860168,
      "learning_rate": 6.765333333333333e-07,
      "logits/chosen": -2.984272003173828,
      "logits/rejected": -2.5833277702331543,
      "logps/chosen": -54.41876220703125,
      "logps/rejected": -102.00347900390625,
      "loss": 0.0055,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08148173987865448,
      "rewards/margins": 5.922885894775391,
      "rewards/rejected": -5.841403961181641,
      "step": 2427
    },
    {
      "epoch": 0.9712,
      "grad_norm": 2.101400375366211,
      "learning_rate": 6.764e-07,
      "logits/chosen": -2.9670963287353516,
      "logits/rejected": -2.228933811187744,
      "logps/chosen": -71.29800415039062,
      "logps/rejected": -129.5928192138672,
      "loss": 0.02,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019889261573553085,
      "rewards/margins": 7.140017509460449,
      "rewards/rejected": -7.120128631591797,
      "step": 2428
    },
    {
      "epoch": 0.9716,
      "grad_norm": 0.004874042700976133,
      "learning_rate": 6.762666666666667e-07,
      "logits/chosen": -2.5452778339385986,
      "logits/rejected": -1.6392478942871094,
      "logps/chosen": -77.64007568359375,
      "logps/rejected": -233.62966918945312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6160893440246582,
      "rewards/margins": 11.317482948303223,
      "rewards/rejected": -9.701393127441406,
      "step": 2429
    },
    {
      "epoch": 0.972,
      "grad_norm": 0.02111276425421238,
      "learning_rate": 6.761333333333334e-07,
      "logits/chosen": -2.6452438831329346,
      "logits/rejected": -2.2189908027648926,
      "logps/chosen": -97.32386779785156,
      "logps/rejected": -201.8293914794922,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.223088502883911,
      "rewards/margins": 10.835517883300781,
      "rewards/rejected": -8.61242961883545,
      "step": 2430
    },
    {
      "epoch": 0.9724,
      "grad_norm": 2.366724967956543,
      "learning_rate": 6.76e-07,
      "logits/chosen": -3.1318130493164062,
      "logits/rejected": -2.591806173324585,
      "logps/chosen": -94.33118438720703,
      "logps/rejected": -108.39175415039062,
      "loss": 0.018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10852204263210297,
      "rewards/margins": 4.492979049682617,
      "rewards/rejected": -4.601500988006592,
      "step": 2431
    },
    {
      "epoch": 0.9728,
      "grad_norm": 0.1461624652147293,
      "learning_rate": 6.758666666666666e-07,
      "logits/chosen": -2.9727439880371094,
      "logits/rejected": -2.513246536254883,
      "logps/chosen": -77.75462341308594,
      "logps/rejected": -152.05926513671875,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03323821723461151,
      "rewards/margins": 8.777005195617676,
      "rewards/rejected": -8.743766784667969,
      "step": 2432
    },
    {
      "epoch": 0.9732,
      "grad_norm": 1.569814682006836,
      "learning_rate": 6.757333333333332e-07,
      "logits/chosen": -2.8730010986328125,
      "logits/rejected": -2.8522377014160156,
      "logps/chosen": -133.30438232421875,
      "logps/rejected": -107.88646697998047,
      "loss": 0.0114,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3968498706817627,
      "rewards/margins": 7.889193058013916,
      "rewards/rejected": -6.492343425750732,
      "step": 2433
    },
    {
      "epoch": 0.9736,
      "grad_norm": 0.35068896412849426,
      "learning_rate": 6.755999999999999e-07,
      "logits/chosen": -2.6627936363220215,
      "logits/rejected": -2.3691649436950684,
      "logps/chosen": -110.70220947265625,
      "logps/rejected": -130.27008056640625,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9042472839355469,
      "rewards/margins": 7.433466911315918,
      "rewards/rejected": -6.529219627380371,
      "step": 2434
    },
    {
      "epoch": 0.974,
      "grad_norm": 0.12701267004013062,
      "learning_rate": 6.754666666666666e-07,
      "logits/chosen": -2.9719936847686768,
      "logits/rejected": -2.720428466796875,
      "logps/chosen": -60.31709671020508,
      "logps/rejected": -130.5092315673828,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.322653591632843,
      "rewards/margins": 7.761099338531494,
      "rewards/rejected": -7.438445568084717,
      "step": 2435
    },
    {
      "epoch": 0.9744,
      "grad_norm": 0.06502877175807953,
      "learning_rate": 6.753333333333333e-07,
      "logits/chosen": -2.802283525466919,
      "logits/rejected": -2.201152801513672,
      "logps/chosen": -88.03243255615234,
      "logps/rejected": -155.46121215820312,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0037304162979126,
      "rewards/margins": 9.165936470031738,
      "rewards/rejected": -8.162205696105957,
      "step": 2436
    },
    {
      "epoch": 0.9748,
      "grad_norm": 0.19366000592708588,
      "learning_rate": 6.752e-07,
      "logits/chosen": -3.024764060974121,
      "logits/rejected": -2.5275535583496094,
      "logps/chosen": -85.02056884765625,
      "logps/rejected": -120.98118591308594,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6958560943603516,
      "rewards/margins": 7.401677131652832,
      "rewards/rejected": -5.7058210372924805,
      "step": 2437
    },
    {
      "epoch": 0.9752,
      "grad_norm": 0.9554215669631958,
      "learning_rate": 6.750666666666667e-07,
      "logits/chosen": -3.040825366973877,
      "logits/rejected": -2.973273754119873,
      "logps/chosen": -90.14424133300781,
      "logps/rejected": -50.72472381591797,
      "loss": 0.012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.360743761062622,
      "rewards/margins": 4.420082092285156,
      "rewards/rejected": -3.059338331222534,
      "step": 2438
    },
    {
      "epoch": 0.9756,
      "grad_norm": 0.4649011790752411,
      "learning_rate": 6.749333333333334e-07,
      "logits/chosen": -3.1921420097351074,
      "logits/rejected": -2.534236431121826,
      "logps/chosen": -51.810890197753906,
      "logps/rejected": -99.85562133789062,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22201499342918396,
      "rewards/margins": 5.611966609954834,
      "rewards/rejected": -5.389951705932617,
      "step": 2439
    },
    {
      "epoch": 0.976,
      "grad_norm": 1.545890212059021,
      "learning_rate": 6.747999999999999e-07,
      "logits/chosen": -2.63510799407959,
      "logits/rejected": -2.2407212257385254,
      "logps/chosen": -245.1607666015625,
      "logps/rejected": -134.42166137695312,
      "loss": 0.0093,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0322768688201904,
      "rewards/margins": 5.516736030578613,
      "rewards/rejected": -6.549013137817383,
      "step": 2440
    },
    {
      "epoch": 0.9764,
      "grad_norm": 0.5072392225265503,
      "learning_rate": 6.746666666666666e-07,
      "logits/chosen": -3.2375330924987793,
      "logits/rejected": -2.4896240234375,
      "logps/chosen": -78.09941101074219,
      "logps/rejected": -154.44955444335938,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11923521757125854,
      "rewards/margins": 8.21592903137207,
      "rewards/rejected": -8.096693992614746,
      "step": 2441
    },
    {
      "epoch": 0.9768,
      "grad_norm": 1.4427374601364136,
      "learning_rate": 6.745333333333333e-07,
      "logits/chosen": -2.8171043395996094,
      "logits/rejected": -2.0725929737091064,
      "logps/chosen": -84.90367126464844,
      "logps/rejected": -117.80421447753906,
      "loss": 0.0127,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7329815030097961,
      "rewards/margins": 6.498454570770264,
      "rewards/rejected": -5.765472888946533,
      "step": 2442
    },
    {
      "epoch": 0.9772,
      "grad_norm": 0.016546815633773804,
      "learning_rate": 6.744e-07,
      "logits/chosen": -2.9162070751190186,
      "logits/rejected": -2.2051732540130615,
      "logps/chosen": -96.95630645751953,
      "logps/rejected": -158.75045776367188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34177225828170776,
      "rewards/margins": 9.074983596801758,
      "rewards/rejected": -8.733210563659668,
      "step": 2443
    },
    {
      "epoch": 0.9776,
      "grad_norm": 0.25089526176452637,
      "learning_rate": 6.742666666666666e-07,
      "logits/chosen": -3.0778675079345703,
      "logits/rejected": -2.685764789581299,
      "logps/chosen": -75.78971862792969,
      "logps/rejected": -92.80915069580078,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5272911190986633,
      "rewards/margins": 5.753894805908203,
      "rewards/rejected": -5.2266035079956055,
      "step": 2444
    },
    {
      "epoch": 0.978,
      "grad_norm": 5.774224281311035,
      "learning_rate": 6.741333333333333e-07,
      "logits/chosen": -3.0635573863983154,
      "logits/rejected": -2.9928736686706543,
      "logps/chosen": -40.44751739501953,
      "logps/rejected": -55.59176254272461,
      "loss": 0.0962,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2795860171318054,
      "rewards/margins": 2.425042152404785,
      "rewards/rejected": -2.7046279907226562,
      "step": 2445
    },
    {
      "epoch": 0.9784,
      "grad_norm": 0.45342114567756653,
      "learning_rate": 6.74e-07,
      "logits/chosen": -3.2666635513305664,
      "logits/rejected": -2.6551804542541504,
      "logps/chosen": -88.66079711914062,
      "logps/rejected": -163.82656860351562,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5679180026054382,
      "rewards/margins": 7.877535820007324,
      "rewards/rejected": -8.445453643798828,
      "step": 2446
    },
    {
      "epoch": 0.9788,
      "grad_norm": 63.06974792480469,
      "learning_rate": 6.738666666666666e-07,
      "logits/chosen": -2.7830042839050293,
      "logits/rejected": -2.4439761638641357,
      "logps/chosen": -166.38546752929688,
      "logps/rejected": -107.57594299316406,
      "loss": 0.3176,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.976195812225342,
      "rewards/margins": 3.6020963191986084,
      "rewards/rejected": -6.578291893005371,
      "step": 2447
    },
    {
      "epoch": 0.9792,
      "grad_norm": 0.5192564725875854,
      "learning_rate": 6.737333333333333e-07,
      "logits/chosen": -2.5260274410247803,
      "logits/rejected": -2.144749164581299,
      "logps/chosen": -114.00840759277344,
      "logps/rejected": -161.8540496826172,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.177399754524231,
      "rewards/margins": 6.694555759429932,
      "rewards/rejected": -7.871955394744873,
      "step": 2448
    },
    {
      "epoch": 0.9796,
      "grad_norm": 24.250425338745117,
      "learning_rate": 6.736e-07,
      "logits/chosen": -2.1204092502593994,
      "logits/rejected": -1.7370634078979492,
      "logps/chosen": -211.55227661132812,
      "logps/rejected": -129.17669677734375,
      "loss": 0.1513,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.265096187591553,
      "rewards/margins": 2.5215110778808594,
      "rewards/rejected": -6.78660774230957,
      "step": 2449
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.017106134444475174,
      "learning_rate": 6.734666666666666e-07,
      "logits/chosen": -3.2366089820861816,
      "logits/rejected": -2.7212181091308594,
      "logps/chosen": -46.9117431640625,
      "logps/rejected": -150.04188537597656,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8061920404434204,
      "rewards/margins": 9.334108352661133,
      "rewards/rejected": -8.52791690826416,
      "step": 2450
    },
    {
      "epoch": 0.9804,
      "grad_norm": 2.329056978225708,
      "learning_rate": 6.733333333333333e-07,
      "logits/chosen": -3.2624659538269043,
      "logits/rejected": -3.058034896850586,
      "logps/chosen": -72.8353271484375,
      "logps/rejected": -119.82264709472656,
      "loss": 0.0183,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2377905249595642,
      "rewards/margins": 4.352165699005127,
      "rewards/rejected": -4.589956283569336,
      "step": 2451
    },
    {
      "epoch": 0.9808,
      "grad_norm": 0.15788349509239197,
      "learning_rate": 6.732e-07,
      "logits/chosen": -3.0636816024780273,
      "logits/rejected": -2.634781837463379,
      "logps/chosen": -67.13298797607422,
      "logps/rejected": -113.85829162597656,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4077646732330322,
      "rewards/margins": 7.29409646987915,
      "rewards/rejected": -6.886331558227539,
      "step": 2452
    },
    {
      "epoch": 0.9812,
      "grad_norm": 0.027159731835126877,
      "learning_rate": 6.730666666666667e-07,
      "logits/chosen": -2.8700361251831055,
      "logits/rejected": -2.4458365440368652,
      "logps/chosen": -107.18714904785156,
      "logps/rejected": -142.60614013671875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5108966827392578,
      "rewards/margins": 8.925174713134766,
      "rewards/rejected": -7.41427755355835,
      "step": 2453
    },
    {
      "epoch": 0.9816,
      "grad_norm": 0.025441166013479233,
      "learning_rate": 6.729333333333334e-07,
      "logits/chosen": -2.5573506355285645,
      "logits/rejected": -1.6195590496063232,
      "logps/chosen": -127.5331802368164,
      "logps/rejected": -151.57733154296875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.41123199462890625,
      "rewards/margins": 8.942537307739258,
      "rewards/rejected": -9.353769302368164,
      "step": 2454
    },
    {
      "epoch": 0.982,
      "grad_norm": 1.0654566287994385,
      "learning_rate": 6.727999999999999e-07,
      "logits/chosen": -3.0562078952789307,
      "logits/rejected": -2.8868064880371094,
      "logps/chosen": -65.65171813964844,
      "logps/rejected": -81.78948974609375,
      "loss": 0.0134,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6392654776573181,
      "rewards/margins": 4.317623138427734,
      "rewards/rejected": -4.956888675689697,
      "step": 2455
    },
    {
      "epoch": 0.9824,
      "grad_norm": 2.898106336593628,
      "learning_rate": 6.726666666666666e-07,
      "logits/chosen": -3.149965524673462,
      "logits/rejected": -2.948824405670166,
      "logps/chosen": -36.798519134521484,
      "logps/rejected": -71.98435974121094,
      "loss": 0.041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2212169170379639,
      "rewards/margins": 4.726817607879639,
      "rewards/rejected": -3.505600690841675,
      "step": 2456
    },
    {
      "epoch": 0.9828,
      "grad_norm": 0.01837809383869171,
      "learning_rate": 6.725333333333333e-07,
      "logits/chosen": -2.9553465843200684,
      "logits/rejected": -2.225677490234375,
      "logps/chosen": -104.71377563476562,
      "logps/rejected": -159.92910766601562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14957886934280396,
      "rewards/margins": 9.304343223571777,
      "rewards/rejected": -9.154764175415039,
      "step": 2457
    },
    {
      "epoch": 0.9832,
      "grad_norm": 0.05070103704929352,
      "learning_rate": 6.724e-07,
      "logits/chosen": -2.8843557834625244,
      "logits/rejected": -2.240108013153076,
      "logps/chosen": -79.20958709716797,
      "logps/rejected": -135.9949188232422,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9960685968399048,
      "rewards/margins": 9.03751277923584,
      "rewards/rejected": -8.041443824768066,
      "step": 2458
    },
    {
      "epoch": 0.9836,
      "grad_norm": 0.058840926736593246,
      "learning_rate": 6.722666666666666e-07,
      "logits/chosen": -2.745793342590332,
      "logits/rejected": -2.313333034515381,
      "logps/chosen": -84.66643524169922,
      "logps/rejected": -168.35562133789062,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2844269871711731,
      "rewards/margins": 8.882360458374023,
      "rewards/rejected": -8.597932815551758,
      "step": 2459
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.08207874745130539,
      "learning_rate": 6.721333333333333e-07,
      "logits/chosen": -2.8457398414611816,
      "logits/rejected": -2.3322064876556396,
      "logps/chosen": -134.91966247558594,
      "logps/rejected": -152.71348571777344,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5220470428466797,
      "rewards/margins": 8.44268798828125,
      "rewards/rejected": -7.920640468597412,
      "step": 2460
    },
    {
      "epoch": 0.9844,
      "grad_norm": 4.608255386352539,
      "learning_rate": 6.72e-07,
      "logits/chosen": -2.789684295654297,
      "logits/rejected": -2.421794891357422,
      "logps/chosen": -106.79902648925781,
      "logps/rejected": -103.67716979980469,
      "loss": 0.0593,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5057613253593445,
      "rewards/margins": 4.967113494873047,
      "rewards/rejected": -5.472875118255615,
      "step": 2461
    },
    {
      "epoch": 0.9848,
      "grad_norm": 57.20367431640625,
      "learning_rate": 6.718666666666666e-07,
      "logits/chosen": -3.0700290203094482,
      "logits/rejected": -3.0824437141418457,
      "logps/chosen": -138.7913818359375,
      "logps/rejected": -70.77317810058594,
      "loss": 0.6768,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -3.0132484436035156,
      "rewards/margins": 1.282233715057373,
      "rewards/rejected": -4.295482158660889,
      "step": 2462
    },
    {
      "epoch": 0.9852,
      "grad_norm": 0.04458877071738243,
      "learning_rate": 6.717333333333333e-07,
      "logits/chosen": -3.0097148418426514,
      "logits/rejected": -2.523127555847168,
      "logps/chosen": -75.46367645263672,
      "logps/rejected": -141.65567016601562,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.05731469392776489,
      "rewards/margins": 9.166086196899414,
      "rewards/rejected": -9.223400115966797,
      "step": 2463
    },
    {
      "epoch": 0.9856,
      "grad_norm": 13.77206039428711,
      "learning_rate": 6.716e-07,
      "logits/chosen": -2.9805421829223633,
      "logits/rejected": -2.5770082473754883,
      "logps/chosen": -157.06546020507812,
      "logps/rejected": -152.2917938232422,
      "loss": 0.0652,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4564487338066101,
      "rewards/margins": 7.876903533935547,
      "rewards/rejected": -7.420454502105713,
      "step": 2464
    },
    {
      "epoch": 0.986,
      "grad_norm": 10.328567504882812,
      "learning_rate": 6.714666666666666e-07,
      "logits/chosen": -2.5445523262023926,
      "logits/rejected": -2.0346293449401855,
      "logps/chosen": -187.3505859375,
      "logps/rejected": -163.56582641601562,
      "loss": 0.0634,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.386199474334717,
      "rewards/margins": 6.814549446105957,
      "rewards/rejected": -9.200749397277832,
      "step": 2465
    },
    {
      "epoch": 0.9864,
      "grad_norm": 2.193046808242798,
      "learning_rate": 6.713333333333333e-07,
      "logits/chosen": -3.18949818611145,
      "logits/rejected": -2.625199794769287,
      "logps/chosen": -51.08399963378906,
      "logps/rejected": -78.27583312988281,
      "loss": 0.0275,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2631843686103821,
      "rewards/margins": 3.7029519081115723,
      "rewards/rejected": -3.439767360687256,
      "step": 2466
    },
    {
      "epoch": 0.9868,
      "grad_norm": 5.740192413330078,
      "learning_rate": 6.712e-07,
      "logits/chosen": -3.0002827644348145,
      "logits/rejected": -2.6357407569885254,
      "logps/chosen": -87.14383697509766,
      "logps/rejected": -132.26828002929688,
      "loss": 0.0536,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3961297869682312,
      "rewards/margins": 6.427844524383545,
      "rewards/rejected": -6.823974132537842,
      "step": 2467
    },
    {
      "epoch": 0.9872,
      "grad_norm": 0.0367991179227829,
      "learning_rate": 6.710666666666667e-07,
      "logits/chosen": -3.0481410026550293,
      "logits/rejected": -2.603621482849121,
      "logps/chosen": -73.04344177246094,
      "logps/rejected": -132.1221923828125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7941153049468994,
      "rewards/margins": 9.23420238494873,
      "rewards/rejected": -8.44008731842041,
      "step": 2468
    },
    {
      "epoch": 0.9876,
      "grad_norm": 0.4811215102672577,
      "learning_rate": 6.709333333333333e-07,
      "logits/chosen": -3.0338807106018066,
      "logits/rejected": -2.5727787017822266,
      "logps/chosen": -83.66093444824219,
      "logps/rejected": -105.89927673339844,
      "loss": 0.0055,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.029840081930160522,
      "rewards/margins": 5.433564186096191,
      "rewards/rejected": -5.463404655456543,
      "step": 2469
    },
    {
      "epoch": 0.988,
      "grad_norm": 0.24203209578990936,
      "learning_rate": 6.707999999999999e-07,
      "logits/chosen": -2.7716212272644043,
      "logits/rejected": -1.9714428186416626,
      "logps/chosen": -137.65463256835938,
      "logps/rejected": -136.61691284179688,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9591373205184937,
      "rewards/margins": 6.632843971252441,
      "rewards/rejected": -7.591981410980225,
      "step": 2470
    },
    {
      "epoch": 0.9884,
      "grad_norm": 1.0444319248199463,
      "learning_rate": 6.706666666666666e-07,
      "logits/chosen": -2.803109645843506,
      "logits/rejected": -2.0893962383270264,
      "logps/chosen": -98.56122589111328,
      "logps/rejected": -104.35790252685547,
      "loss": 0.009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.053168535232544,
      "rewards/margins": 7.030692100524902,
      "rewards/rejected": -5.9775238037109375,
      "step": 2471
    },
    {
      "epoch": 0.9888,
      "grad_norm": 19.296123504638672,
      "learning_rate": 6.705333333333333e-07,
      "logits/chosen": -2.907181978225708,
      "logits/rejected": -2.4853944778442383,
      "logps/chosen": -129.17984008789062,
      "logps/rejected": -91.00053405761719,
      "loss": 0.1277,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8714637756347656,
      "rewards/margins": 3.4910435676574707,
      "rewards/rejected": -5.362507343292236,
      "step": 2472
    },
    {
      "epoch": 0.9892,
      "grad_norm": 1.9377639293670654,
      "learning_rate": 6.704e-07,
      "logits/chosen": -2.717365264892578,
      "logits/rejected": -2.0638391971588135,
      "logps/chosen": -190.819580078125,
      "logps/rejected": -141.28271484375,
      "loss": 0.0124,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0067100524902344,
      "rewards/margins": 6.492128372192383,
      "rewards/rejected": -8.498838424682617,
      "step": 2473
    },
    {
      "epoch": 0.9896,
      "grad_norm": 0.30835476517677307,
      "learning_rate": 6.702666666666667e-07,
      "logits/chosen": -2.818936347961426,
      "logits/rejected": -2.206139087677002,
      "logps/chosen": -68.57377624511719,
      "logps/rejected": -127.06537628173828,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6194758415222168,
      "rewards/margins": 6.552814483642578,
      "rewards/rejected": -4.9333391189575195,
      "step": 2474
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.034354209899902344,
      "learning_rate": 6.701333333333334e-07,
      "logits/chosen": -3.0304620265960693,
      "logits/rejected": -2.3944220542907715,
      "logps/chosen": -66.9024658203125,
      "logps/rejected": -167.37042236328125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4167587459087372,
      "rewards/margins": 8.907119750976562,
      "rewards/rejected": -8.490360260009766,
      "step": 2475
    },
    {
      "epoch": 0.9904,
      "grad_norm": 0.02190837822854519,
      "learning_rate": 6.7e-07,
      "logits/chosen": -2.9463467597961426,
      "logits/rejected": -2.25637149810791,
      "logps/chosen": -75.89741516113281,
      "logps/rejected": -166.0440673828125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4080100953578949,
      "rewards/margins": 10.08781623840332,
      "rewards/rejected": -9.679805755615234,
      "step": 2476
    },
    {
      "epoch": 0.9908,
      "grad_norm": 0.3747400641441345,
      "learning_rate": 6.698666666666667e-07,
      "logits/chosen": -2.695399522781372,
      "logits/rejected": -2.1278176307678223,
      "logps/chosen": -241.447021484375,
      "logps/rejected": -185.29827880859375,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.455701470375061,
      "rewards/margins": 8.141167640686035,
      "rewards/rejected": -9.596869468688965,
      "step": 2477
    },
    {
      "epoch": 0.9912,
      "grad_norm": 6.6580986976623535,
      "learning_rate": 6.697333333333332e-07,
      "logits/chosen": -3.0717735290527344,
      "logits/rejected": -2.8396999835968018,
      "logps/chosen": -61.36063766479492,
      "logps/rejected": -125.0940170288086,
      "loss": 0.0617,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.07901594042778015,
      "rewards/margins": 6.257699489593506,
      "rewards/rejected": -6.3367156982421875,
      "step": 2478
    },
    {
      "epoch": 0.9916,
      "grad_norm": 1.6538017988204956,
      "learning_rate": 6.695999999999999e-07,
      "logits/chosen": -3.0494632720947266,
      "logits/rejected": -2.723519802093506,
      "logps/chosen": -118.55303955078125,
      "logps/rejected": -107.96878051757812,
      "loss": 0.012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1647762060165405,
      "rewards/margins": 4.963781356811523,
      "rewards/rejected": -6.1285576820373535,
      "step": 2479
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.29779261350631714,
      "learning_rate": 6.694666666666666e-07,
      "logits/chosen": -2.7559146881103516,
      "logits/rejected": -2.183701992034912,
      "logps/chosen": -95.45498657226562,
      "logps/rejected": -124.65923309326172,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20542603731155396,
      "rewards/margins": 6.815676689147949,
      "rewards/rejected": -6.610250473022461,
      "step": 2480
    },
    {
      "epoch": 0.9924,
      "grad_norm": 0.01958114467561245,
      "learning_rate": 6.693333333333333e-07,
      "logits/chosen": -2.9695496559143066,
      "logits/rejected": -2.510396957397461,
      "logps/chosen": -50.237525939941406,
      "logps/rejected": -148.71319580078125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2937700152397156,
      "rewards/margins": 9.393980026245117,
      "rewards/rejected": -9.687749862670898,
      "step": 2481
    },
    {
      "epoch": 0.9928,
      "grad_norm": 0.18847551941871643,
      "learning_rate": 6.692e-07,
      "logits/chosen": -2.9869256019592285,
      "logits/rejected": -2.704476833343506,
      "logps/chosen": -96.03385925292969,
      "logps/rejected": -112.92948150634766,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03194122388958931,
      "rewards/margins": 6.683990478515625,
      "rewards/rejected": -6.6520490646362305,
      "step": 2482
    },
    {
      "epoch": 0.9932,
      "grad_norm": 0.0008993696537800133,
      "learning_rate": 6.690666666666667e-07,
      "logits/chosen": -2.7807459831237793,
      "logits/rejected": -2.0099971294403076,
      "logps/chosen": -137.99993896484375,
      "logps/rejected": -179.78057861328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1091846227645874,
      "rewards/margins": 12.371222496032715,
      "rewards/rejected": -12.26203727722168,
      "step": 2483
    },
    {
      "epoch": 0.9936,
      "grad_norm": 0.9533900022506714,
      "learning_rate": 6.689333333333334e-07,
      "logits/chosen": -2.401103973388672,
      "logits/rejected": -1.569345474243164,
      "logps/chosen": -178.72305297851562,
      "logps/rejected": -179.95169067382812,
      "loss": 0.0057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.1812446117401123,
      "rewards/margins": 6.713138580322266,
      "rewards/rejected": -8.89438247680664,
      "step": 2484
    },
    {
      "epoch": 0.994,
      "grad_norm": 0.8024351596832275,
      "learning_rate": 6.688e-07,
      "logits/chosen": -3.0608205795288086,
      "logits/rejected": -2.7673985958099365,
      "logps/chosen": -51.28858184814453,
      "logps/rejected": -68.90809631347656,
      "loss": 0.0096,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9173567295074463,
      "rewards/margins": 4.675563812255859,
      "rewards/rejected": -3.758206844329834,
      "step": 2485
    },
    {
      "epoch": 0.9944,
      "grad_norm": 0.01970294676721096,
      "learning_rate": 6.686666666666666e-07,
      "logits/chosen": -2.4779155254364014,
      "logits/rejected": -2.0615594387054443,
      "logps/chosen": -122.810546875,
      "logps/rejected": -211.66537475585938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3174346685409546,
      "rewards/margins": 9.771543502807617,
      "rewards/rejected": -8.454109191894531,
      "step": 2486
    },
    {
      "epoch": 0.9948,
      "grad_norm": 0.015277614817023277,
      "learning_rate": 6.685333333333332e-07,
      "logits/chosen": -2.8966288566589355,
      "logits/rejected": -2.143920421600342,
      "logps/chosen": -84.96675109863281,
      "logps/rejected": -139.74551391601562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6441184878349304,
      "rewards/margins": 9.121273040771484,
      "rewards/rejected": -8.477154731750488,
      "step": 2487
    },
    {
      "epoch": 0.9952,
      "grad_norm": 31.346885681152344,
      "learning_rate": 6.683999999999999e-07,
      "logits/chosen": -3.1876847743988037,
      "logits/rejected": -2.7700865268707275,
      "logps/chosen": -86.38523864746094,
      "logps/rejected": -88.33131408691406,
      "loss": 0.3084,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0199546813964844,
      "rewards/margins": 3.089759111404419,
      "rewards/rejected": -5.109713554382324,
      "step": 2488
    },
    {
      "epoch": 0.9956,
      "grad_norm": 1.4936628341674805,
      "learning_rate": 6.682666666666666e-07,
      "logits/chosen": -2.7142152786254883,
      "logits/rejected": -2.2873363494873047,
      "logps/chosen": -118.23260498046875,
      "logps/rejected": -118.16313171386719,
      "loss": 0.018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8039840459823608,
      "rewards/margins": 5.255448341369629,
      "rewards/rejected": -6.059432506561279,
      "step": 2489
    },
    {
      "epoch": 0.996,
      "grad_norm": 0.6822136640548706,
      "learning_rate": 6.681333333333333e-07,
      "logits/chosen": -2.8497118949890137,
      "logits/rejected": -2.1766371726989746,
      "logps/chosen": -112.09562683105469,
      "logps/rejected": -102.97135925292969,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3957977294921875,
      "rewards/margins": 4.992922782897949,
      "rewards/rejected": -5.388720512390137,
      "step": 2490
    },
    {
      "epoch": 0.9964,
      "grad_norm": 0.9390755295753479,
      "learning_rate": 6.68e-07,
      "logits/chosen": -2.7971878051757812,
      "logits/rejected": -2.3956809043884277,
      "logps/chosen": -163.73773193359375,
      "logps/rejected": -142.06350708007812,
      "loss": 0.0072,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6585792899131775,
      "rewards/margins": 5.801530838012695,
      "rewards/rejected": -6.460109710693359,
      "step": 2491
    },
    {
      "epoch": 0.9968,
      "grad_norm": 0.19486171007156372,
      "learning_rate": 6.678666666666667e-07,
      "logits/chosen": -2.5955517292022705,
      "logits/rejected": -2.191197395324707,
      "logps/chosen": -163.29803466796875,
      "logps/rejected": -176.57398986816406,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02777862548828125,
      "rewards/margins": 7.180664539337158,
      "rewards/rejected": -7.152885437011719,
      "step": 2492
    },
    {
      "epoch": 0.9972,
      "grad_norm": 0.18487143516540527,
      "learning_rate": 6.677333333333333e-07,
      "logits/chosen": -2.4712255001068115,
      "logits/rejected": -1.7407214641571045,
      "logps/chosen": -153.3712921142578,
      "logps/rejected": -171.00405883789062,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1095802783966064,
      "rewards/margins": 8.70044231414795,
      "rewards/rejected": -9.810022354125977,
      "step": 2493
    },
    {
      "epoch": 0.9976,
      "grad_norm": 8.33945083618164,
      "learning_rate": 6.676e-07,
      "logits/chosen": -2.813854217529297,
      "logits/rejected": -2.272768974304199,
      "logps/chosen": -202.57395935058594,
      "logps/rejected": -131.10655212402344,
      "loss": 0.0424,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7108533382415771,
      "rewards/margins": 4.917686462402344,
      "rewards/rejected": -6.6285400390625,
      "step": 2494
    },
    {
      "epoch": 0.998,
      "grad_norm": 0.4042450189590454,
      "learning_rate": 6.674666666666667e-07,
      "logits/chosen": -2.8839616775512695,
      "logits/rejected": -2.385422706604004,
      "logps/chosen": -122.20431518554688,
      "logps/rejected": -122.32429504394531,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1057857275009155,
      "rewards/margins": 5.550073146820068,
      "rewards/rejected": -6.655858993530273,
      "step": 2495
    },
    {
      "epoch": 0.9984,
      "grad_norm": 0.10198445618152618,
      "learning_rate": 6.673333333333334e-07,
      "logits/chosen": -2.740945816040039,
      "logits/rejected": -2.40826416015625,
      "logps/chosen": -157.51492309570312,
      "logps/rejected": -190.0127716064453,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.37520867586135864,
      "rewards/margins": 8.007515907287598,
      "rewards/rejected": -8.38272476196289,
      "step": 2496
    },
    {
      "epoch": 0.9988,
      "grad_norm": 0.13027609884738922,
      "learning_rate": 6.671999999999999e-07,
      "logits/chosen": -3.115072011947632,
      "logits/rejected": -2.4167368412017822,
      "logps/chosen": -63.77710723876953,
      "logps/rejected": -117.7887191772461,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9295581579208374,
      "rewards/margins": 7.295096397399902,
      "rewards/rejected": -6.365538120269775,
      "step": 2497
    },
    {
      "epoch": 0.9992,
      "grad_norm": 0.3640064597129822,
      "learning_rate": 6.670666666666666e-07,
      "logits/chosen": -3.1443119049072266,
      "logits/rejected": -2.8651418685913086,
      "logps/chosen": -74.43743896484375,
      "logps/rejected": -87.06353759765625,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.734177827835083,
      "rewards/margins": 5.651455402374268,
      "rewards/rejected": -4.9172773361206055,
      "step": 2498
    },
    {
      "epoch": 0.9996,
      "grad_norm": 0.005812645889818668,
      "learning_rate": 6.669333333333333e-07,
      "logits/chosen": -2.650289535522461,
      "logits/rejected": -1.6955316066741943,
      "logps/chosen": -77.03892517089844,
      "logps/rejected": -164.6295166015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4671132564544678,
      "rewards/margins": 10.750429153442383,
      "rewards/rejected": -9.283316612243652,
      "step": 2499
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.12391777336597443,
      "learning_rate": 6.667999999999999e-07,
      "logits/chosen": -2.846979856491089,
      "logits/rejected": -2.42501163482666,
      "logps/chosen": -101.81942749023438,
      "logps/rejected": -140.20333862304688,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.16652564704418182,
      "rewards/margins": 7.522564888000488,
      "rewards/rejected": -7.689090251922607,
      "step": 2500
    },
    {
      "epoch": 1.0004,
      "grad_norm": 0.004964118357747793,
      "learning_rate": 6.666666666666666e-07,
      "logits/chosen": -2.7152793407440186,
      "logits/rejected": -1.7469245195388794,
      "logps/chosen": -116.67509460449219,
      "logps/rejected": -195.31582641601562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.240041732788086,
      "rewards/margins": 11.443733215332031,
      "rewards/rejected": -9.203691482543945,
      "step": 2501
    },
    {
      "epoch": 1.0008,
      "grad_norm": 0.16467146575450897,
      "learning_rate": 6.665333333333333e-07,
      "logits/chosen": -2.8078696727752686,
      "logits/rejected": -2.5378332138061523,
      "logps/chosen": -128.3787841796875,
      "logps/rejected": -118.45475006103516,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.04361361265182495,
      "rewards/margins": 7.080387115478516,
      "rewards/rejected": -7.124000549316406,
      "step": 2502
    },
    {
      "epoch": 1.0012,
      "grad_norm": 1.2495769262313843,
      "learning_rate": 6.664e-07,
      "logits/chosen": -2.708470106124878,
      "logits/rejected": -2.0268754959106445,
      "logps/chosen": -121.30807495117188,
      "logps/rejected": -140.40277099609375,
      "loss": 0.0109,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7496978640556335,
      "rewards/margins": 7.157144546508789,
      "rewards/rejected": -7.906842231750488,
      "step": 2503
    },
    {
      "epoch": 1.0016,
      "grad_norm": 0.012416246347129345,
      "learning_rate": 6.662666666666667e-07,
      "logits/chosen": -2.902709484100342,
      "logits/rejected": -2.3406624794006348,
      "logps/chosen": -73.82220458984375,
      "logps/rejected": -176.5546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6030079126358032,
      "rewards/margins": 10.204011917114258,
      "rewards/rejected": -8.601003646850586,
      "step": 2504
    },
    {
      "epoch": 1.002,
      "grad_norm": 0.41394057869911194,
      "learning_rate": 6.661333333333334e-07,
      "logits/chosen": -2.85897159576416,
      "logits/rejected": -2.2449097633361816,
      "logps/chosen": -132.37600708007812,
      "logps/rejected": -151.4373779296875,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4792362153530121,
      "rewards/margins": 8.310882568359375,
      "rewards/rejected": -7.831645965576172,
      "step": 2505
    },
    {
      "epoch": 1.0024,
      "grad_norm": 0.1284068524837494,
      "learning_rate": 6.66e-07,
      "logits/chosen": -2.8511550426483154,
      "logits/rejected": -2.0412344932556152,
      "logps/chosen": -85.92390441894531,
      "logps/rejected": -158.86512756347656,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3045421838760376,
      "rewards/margins": 9.657768249511719,
      "rewards/rejected": -8.353225708007812,
      "step": 2506
    },
    {
      "epoch": 1.0028,
      "grad_norm": 0.002263301284983754,
      "learning_rate": 6.658666666666666e-07,
      "logits/chosen": -2.7065820693969727,
      "logits/rejected": -1.571115255355835,
      "logps/chosen": -109.07678985595703,
      "logps/rejected": -152.04466247558594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.112062931060791,
      "rewards/margins": 11.485557556152344,
      "rewards/rejected": -9.373494148254395,
      "step": 2507
    },
    {
      "epoch": 1.0032,
      "grad_norm": 9.826797485351562,
      "learning_rate": 6.657333333333332e-07,
      "logits/chosen": -2.4301228523254395,
      "logits/rejected": -1.7064902782440186,
      "logps/chosen": -175.9247283935547,
      "logps/rejected": -155.73928833007812,
      "loss": 0.0352,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4469891786575317,
      "rewards/margins": 6.851805686950684,
      "rewards/rejected": -8.298794746398926,
      "step": 2508
    },
    {
      "epoch": 1.0036,
      "grad_norm": 4.12261438369751,
      "learning_rate": 6.655999999999999e-07,
      "logits/chosen": -2.6586341857910156,
      "logits/rejected": -2.2144558429718018,
      "logps/chosen": -162.8453826904297,
      "logps/rejected": -110.06642150878906,
      "loss": 0.0304,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.3054556846618652,
      "rewards/margins": 3.6155121326446533,
      "rewards/rejected": -5.920968055725098,
      "step": 2509
    },
    {
      "epoch": 1.004,
      "grad_norm": 0.46775105595588684,
      "learning_rate": 6.654666666666666e-07,
      "logits/chosen": -3.0222010612487793,
      "logits/rejected": -2.7272610664367676,
      "logps/chosen": -85.06622314453125,
      "logps/rejected": -116.21371459960938,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3009762167930603,
      "rewards/margins": 6.968969345092773,
      "rewards/rejected": -7.26994514465332,
      "step": 2510
    },
    {
      "epoch": 1.0044,
      "grad_norm": 1.3251475095748901,
      "learning_rate": 6.653333333333333e-07,
      "logits/chosen": -2.9063472747802734,
      "logits/rejected": -2.8939449787139893,
      "logps/chosen": -53.5490837097168,
      "logps/rejected": -119.08334350585938,
      "loss": 0.0065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06223487854003906,
      "rewards/margins": 6.1401753425598145,
      "rewards/rejected": -6.077940464019775,
      "step": 2511
    },
    {
      "epoch": 1.0048,
      "grad_norm": 4.476918697357178,
      "learning_rate": 6.652e-07,
      "logits/chosen": -3.1705660820007324,
      "logits/rejected": -2.462765693664551,
      "logps/chosen": -75.36051940917969,
      "logps/rejected": -106.42271423339844,
      "loss": 0.0316,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35765552520751953,
      "rewards/margins": 6.612521648406982,
      "rewards/rejected": -6.254866123199463,
      "step": 2512
    },
    {
      "epoch": 1.0052,
      "grad_norm": 0.3525015711784363,
      "learning_rate": 6.650666666666667e-07,
      "logits/chosen": -2.5887610912323,
      "logits/rejected": -2.3799591064453125,
      "logps/chosen": -144.03982543945312,
      "logps/rejected": -176.95492553710938,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8750236630439758,
      "rewards/margins": 6.5875091552734375,
      "rewards/rejected": -5.712485313415527,
      "step": 2513
    },
    {
      "epoch": 1.0056,
      "grad_norm": 0.4759749472141266,
      "learning_rate": 6.649333333333334e-07,
      "logits/chosen": -2.4500865936279297,
      "logits/rejected": -1.8741211891174316,
      "logps/chosen": -131.74765014648438,
      "logps/rejected": -183.34817504882812,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.048570990562439,
      "rewards/margins": 7.359285354614258,
      "rewards/rejected": -8.407855987548828,
      "step": 2514
    },
    {
      "epoch": 1.006,
      "grad_norm": 0.01101138535887003,
      "learning_rate": 6.647999999999999e-07,
      "logits/chosen": -2.520082473754883,
      "logits/rejected": -1.6307299137115479,
      "logps/chosen": -90.43743896484375,
      "logps/rejected": -197.99114990234375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.224726438522339,
      "rewards/margins": 10.604293823242188,
      "rewards/rejected": -8.37956714630127,
      "step": 2515
    },
    {
      "epoch": 1.0064,
      "grad_norm": 1.4457015991210938,
      "learning_rate": 6.646666666666666e-07,
      "logits/chosen": -2.989107847213745,
      "logits/rejected": -2.481433868408203,
      "logps/chosen": -49.66299819946289,
      "logps/rejected": -135.3104248046875,
      "loss": 0.0141,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1567692756652832,
      "rewards/margins": 5.916705131530762,
      "rewards/rejected": -7.073474407196045,
      "step": 2516
    },
    {
      "epoch": 1.0068,
      "grad_norm": 2.4044501781463623,
      "learning_rate": 6.645333333333332e-07,
      "logits/chosen": -3.225951671600342,
      "logits/rejected": -2.962658405303955,
      "logps/chosen": -76.06021118164062,
      "logps/rejected": -82.38225555419922,
      "loss": 0.0239,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08526113629341125,
      "rewards/margins": 4.5317277908325195,
      "rewards/rejected": -4.6169891357421875,
      "step": 2517
    },
    {
      "epoch": 1.0072,
      "grad_norm": 1.3934096097946167,
      "learning_rate": 6.643999999999999e-07,
      "logits/chosen": -3.1092987060546875,
      "logits/rejected": -2.608229160308838,
      "logps/chosen": -79.3861312866211,
      "logps/rejected": -117.70840454101562,
      "loss": 0.0154,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1511865854263306,
      "rewards/margins": 8.388053894042969,
      "rewards/rejected": -7.236867427825928,
      "step": 2518
    },
    {
      "epoch": 1.0076,
      "grad_norm": 0.7965179085731506,
      "learning_rate": 6.642666666666666e-07,
      "logits/chosen": -2.8797287940979004,
      "logits/rejected": -2.5863709449768066,
      "logps/chosen": -81.87361145019531,
      "logps/rejected": -85.21780395507812,
      "loss": 0.0052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.550590991973877,
      "rewards/margins": 5.8816728591918945,
      "rewards/rejected": -4.331082344055176,
      "step": 2519
    },
    {
      "epoch": 1.008,
      "grad_norm": 0.559989869594574,
      "learning_rate": 6.641333333333333e-07,
      "logits/chosen": -2.8388495445251465,
      "logits/rejected": -2.3870904445648193,
      "logps/chosen": -74.39311981201172,
      "logps/rejected": -141.33233642578125,
      "loss": 0.0051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3944253921508789,
      "rewards/margins": 8.010891914367676,
      "rewards/rejected": -7.616466522216797,
      "step": 2520
    },
    {
      "epoch": 1.0084,
      "grad_norm": 0.8148866295814514,
      "learning_rate": 6.64e-07,
      "logits/chosen": -2.6536154747009277,
      "logits/rejected": -2.124070882797241,
      "logps/chosen": -126.38634490966797,
      "logps/rejected": -139.33229064941406,
      "loss": 0.0079,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7116373777389526,
      "rewards/margins": 5.0666913986206055,
      "rewards/rejected": -6.778328895568848,
      "step": 2521
    },
    {
      "epoch": 1.0088,
      "grad_norm": 0.07404962182044983,
      "learning_rate": 6.638666666666667e-07,
      "logits/chosen": -2.771688461303711,
      "logits/rejected": -2.5074586868286133,
      "logps/chosen": -111.23792266845703,
      "logps/rejected": -167.02719116210938,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0422821044921875,
      "rewards/margins": 9.64262866973877,
      "rewards/rejected": -9.684910774230957,
      "step": 2522
    },
    {
      "epoch": 1.0092,
      "grad_norm": 0.40978318452835083,
      "learning_rate": 6.637333333333333e-07,
      "logits/chosen": -3.210644245147705,
      "logits/rejected": -2.8240513801574707,
      "logps/chosen": -89.17672729492188,
      "logps/rejected": -129.24197387695312,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17697982490062714,
      "rewards/margins": 6.427977561950684,
      "rewards/rejected": -6.250997543334961,
      "step": 2523
    },
    {
      "epoch": 1.0096,
      "grad_norm": 36.00741958618164,
      "learning_rate": 6.636e-07,
      "logits/chosen": -2.85400390625,
      "logits/rejected": -2.767277240753174,
      "logps/chosen": -170.0731201171875,
      "logps/rejected": -121.59934997558594,
      "loss": 0.1632,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.0835063457489014,
      "rewards/margins": 3.7618961334228516,
      "rewards/rejected": -6.845402717590332,
      "step": 2524
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.3262467384338379,
      "learning_rate": 6.634666666666666e-07,
      "logits/chosen": -2.9483726024627686,
      "logits/rejected": -2.3140783309936523,
      "logps/chosen": -92.56608581542969,
      "logps/rejected": -137.30503845214844,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.740020751953125,
      "rewards/margins": 8.677085876464844,
      "rewards/rejected": -6.937065124511719,
      "step": 2525
    },
    {
      "epoch": 1.0104,
      "grad_norm": 0.692197859287262,
      "learning_rate": 6.633333333333333e-07,
      "logits/chosen": -3.0819878578186035,
      "logits/rejected": -2.963353157043457,
      "logps/chosen": -61.22182846069336,
      "logps/rejected": -105.44650268554688,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6590908169746399,
      "rewards/margins": 5.892548084259033,
      "rewards/rejected": -5.233457565307617,
      "step": 2526
    },
    {
      "epoch": 1.0108,
      "grad_norm": 0.023857511579990387,
      "learning_rate": 6.632e-07,
      "logits/chosen": -2.596360683441162,
      "logits/rejected": -1.7229278087615967,
      "logps/chosen": -106.44239044189453,
      "logps/rejected": -148.18722534179688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9018896222114563,
      "rewards/margins": 9.43542194366455,
      "rewards/rejected": -8.53353214263916,
      "step": 2527
    },
    {
      "epoch": 1.0112,
      "grad_norm": 0.13535529375076294,
      "learning_rate": 6.630666666666666e-07,
      "logits/chosen": -2.566715955734253,
      "logits/rejected": -2.1233773231506348,
      "logps/chosen": -95.6473617553711,
      "logps/rejected": -140.70074462890625,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8421401977539062,
      "rewards/margins": 8.3780517578125,
      "rewards/rejected": -5.535911560058594,
      "step": 2528
    },
    {
      "epoch": 1.0116,
      "grad_norm": 1.4951401948928833,
      "learning_rate": 6.629333333333333e-07,
      "logits/chosen": -2.98534893989563,
      "logits/rejected": -2.857055187225342,
      "logps/chosen": -87.85647583007812,
      "logps/rejected": -107.39183044433594,
      "loss": 0.024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.13916780054569244,
      "rewards/margins": 5.896578788757324,
      "rewards/rejected": -6.0357465744018555,
      "step": 2529
    },
    {
      "epoch": 1.012,
      "grad_norm": 4.291316509246826,
      "learning_rate": 6.627999999999999e-07,
      "logits/chosen": -2.7180590629577637,
      "logits/rejected": -2.1206166744232178,
      "logps/chosen": -108.93766784667969,
      "logps/rejected": -172.6192626953125,
      "loss": 0.0254,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6932228207588196,
      "rewards/margins": 6.45072078704834,
      "rewards/rejected": -7.143943786621094,
      "step": 2530
    },
    {
      "epoch": 1.0124,
      "grad_norm": 0.05419014021754265,
      "learning_rate": 6.626666666666666e-07,
      "logits/chosen": -3.0465073585510254,
      "logits/rejected": -2.2034897804260254,
      "logps/chosen": -69.80322265625,
      "logps/rejected": -168.64492797851562,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3386526107788086,
      "rewards/margins": 9.441438674926758,
      "rewards/rejected": -9.10278606414795,
      "step": 2531
    },
    {
      "epoch": 1.0128,
      "grad_norm": 0.05891402065753937,
      "learning_rate": 6.625333333333333e-07,
      "logits/chosen": -2.65419864654541,
      "logits/rejected": -1.9744982719421387,
      "logps/chosen": -115.4062728881836,
      "logps/rejected": -144.56399536132812,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2872717082500458,
      "rewards/margins": 7.966538429260254,
      "rewards/rejected": -8.253809928894043,
      "step": 2532
    },
    {
      "epoch": 1.0132,
      "grad_norm": 0.0056356447748839855,
      "learning_rate": 6.624e-07,
      "logits/chosen": -3.043447732925415,
      "logits/rejected": -2.3635146617889404,
      "logps/chosen": -92.02825927734375,
      "logps/rejected": -203.54483032226562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.13918724656105042,
      "rewards/margins": 11.615630149841309,
      "rewards/rejected": -11.754817962646484,
      "step": 2533
    },
    {
      "epoch": 1.0136,
      "grad_norm": 1.0105488300323486,
      "learning_rate": 6.622666666666666e-07,
      "logits/chosen": -2.8327205181121826,
      "logits/rejected": -2.451612949371338,
      "logps/chosen": -61.16315460205078,
      "logps/rejected": -106.68231201171875,
      "loss": 0.0115,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4242099523544312,
      "rewards/margins": 6.186766147613525,
      "rewards/rejected": -4.762556076049805,
      "step": 2534
    },
    {
      "epoch": 1.014,
      "grad_norm": 0.9926928877830505,
      "learning_rate": 6.621333333333333e-07,
      "logits/chosen": -2.9837708473205566,
      "logits/rejected": -2.205423593521118,
      "logps/chosen": -81.88430786132812,
      "logps/rejected": -102.61442565917969,
      "loss": 0.0081,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1525254249572754,
      "rewards/margins": 6.492424488067627,
      "rewards/rejected": -5.339899063110352,
      "step": 2535
    },
    {
      "epoch": 1.0144,
      "grad_norm": 1.1407119035720825,
      "learning_rate": 6.62e-07,
      "logits/chosen": -3.0594820976257324,
      "logits/rejected": -2.771609306335449,
      "logps/chosen": -64.52706146240234,
      "logps/rejected": -55.047096252441406,
      "loss": 0.0178,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.305781602859497,
      "rewards/margins": 4.020605087280273,
      "rewards/rejected": -2.7148232460021973,
      "step": 2536
    },
    {
      "epoch": 1.0148,
      "grad_norm": 0.015176961198449135,
      "learning_rate": 6.618666666666667e-07,
      "logits/chosen": -2.511176109313965,
      "logits/rejected": -1.5773074626922607,
      "logps/chosen": -94.32640075683594,
      "logps/rejected": -155.9378662109375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.057651996612549,
      "rewards/margins": 9.57296371459961,
      "rewards/rejected": -7.515312194824219,
      "step": 2537
    },
    {
      "epoch": 1.0152,
      "grad_norm": 1.802219033241272,
      "learning_rate": 6.617333333333333e-07,
      "logits/chosen": -3.307166576385498,
      "logits/rejected": -3.0220842361450195,
      "logps/chosen": -64.26473999023438,
      "logps/rejected": -86.91841125488281,
      "loss": 0.0131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9985458850860596,
      "rewards/margins": 5.3448028564453125,
      "rewards/rejected": -4.346257209777832,
      "step": 2538
    },
    {
      "epoch": 1.0156,
      "grad_norm": 1.1539034843444824,
      "learning_rate": 6.615999999999999e-07,
      "logits/chosen": -3.0844407081604004,
      "logits/rejected": -2.771170139312744,
      "logps/chosen": -101.24461364746094,
      "logps/rejected": -105.45306396484375,
      "loss": 0.0122,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5222355127334595,
      "rewards/margins": 4.664369583129883,
      "rewards/rejected": -5.186604976654053,
      "step": 2539
    },
    {
      "epoch": 1.016,
      "grad_norm": 0.876925528049469,
      "learning_rate": 6.614666666666666e-07,
      "logits/chosen": -2.8682479858398438,
      "logits/rejected": -2.6505885124206543,
      "logps/chosen": -93.88716888427734,
      "logps/rejected": -100.86637878417969,
      "loss": 0.0073,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.43924543261528015,
      "rewards/margins": 4.933333873748779,
      "rewards/rejected": -5.372579574584961,
      "step": 2540
    },
    {
      "epoch": 1.0164,
      "grad_norm": 0.004472041968256235,
      "learning_rate": 6.613333333333333e-07,
      "logits/chosen": -2.513665199279785,
      "logits/rejected": -1.5831849575042725,
      "logps/chosen": -64.67790985107422,
      "logps/rejected": -237.4849853515625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4868465662002563,
      "rewards/margins": 12.042865753173828,
      "rewards/rejected": -10.556018829345703,
      "step": 2541
    },
    {
      "epoch": 1.0168,
      "grad_norm": 0.9417684078216553,
      "learning_rate": 6.612e-07,
      "logits/chosen": -2.5757665634155273,
      "logits/rejected": -2.1635894775390625,
      "logps/chosen": -117.8509521484375,
      "logps/rejected": -136.599365234375,
      "loss": 0.0064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6301639080047607,
      "rewards/margins": 6.256948471069336,
      "rewards/rejected": -7.887112617492676,
      "step": 2542
    },
    {
      "epoch": 1.0172,
      "grad_norm": 1.0004481077194214,
      "learning_rate": 6.610666666666667e-07,
      "logits/chosen": -2.8569960594177246,
      "logits/rejected": -2.366787910461426,
      "logps/chosen": -127.4105224609375,
      "logps/rejected": -87.22125244140625,
      "loss": 0.0108,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1352546215057373,
      "rewards/margins": 5.944507122039795,
      "rewards/rejected": -4.809252738952637,
      "step": 2543
    },
    {
      "epoch": 1.0176,
      "grad_norm": 0.018243689090013504,
      "learning_rate": 6.609333333333333e-07,
      "logits/chosen": -2.762338161468506,
      "logits/rejected": -1.9418723583221436,
      "logps/chosen": -214.40753173828125,
      "logps/rejected": -201.5807342529297,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2883931398391724,
      "rewards/margins": 12.579065322875977,
      "rewards/rejected": -13.86745834350586,
      "step": 2544
    },
    {
      "epoch": 1.018,
      "grad_norm": 0.013833186589181423,
      "learning_rate": 6.608e-07,
      "logits/chosen": -3.102450132369995,
      "logits/rejected": -2.3059802055358887,
      "logps/chosen": -71.19554901123047,
      "logps/rejected": -168.12765502929688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9156501889228821,
      "rewards/margins": 10.048145294189453,
      "rewards/rejected": -9.13249397277832,
      "step": 2545
    },
    {
      "epoch": 1.0184,
      "grad_norm": 10.375765800476074,
      "learning_rate": 6.606666666666666e-07,
      "logits/chosen": -3.0636234283447266,
      "logits/rejected": -3.052906036376953,
      "logps/chosen": -104.93975067138672,
      "logps/rejected": -74.34910583496094,
      "loss": 0.0974,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2418116331100464,
      "rewards/margins": 2.682036876678467,
      "rewards/rejected": -3.9238486289978027,
      "step": 2546
    },
    {
      "epoch": 1.0188,
      "grad_norm": 1.802854299545288,
      "learning_rate": 6.605333333333333e-07,
      "logits/chosen": -2.8472094535827637,
      "logits/rejected": -2.2401270866394043,
      "logps/chosen": -102.86874389648438,
      "logps/rejected": -107.86502075195312,
      "loss": 0.0142,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1041929721832275,
      "rewards/margins": 5.384552478790283,
      "rewards/rejected": -6.488745212554932,
      "step": 2547
    },
    {
      "epoch": 1.0192,
      "grad_norm": 0.1524440199136734,
      "learning_rate": 6.604e-07,
      "logits/chosen": -2.9523959159851074,
      "logits/rejected": -2.5273213386535645,
      "logps/chosen": -69.40835571289062,
      "logps/rejected": -115.77318572998047,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3817462921142578,
      "rewards/margins": 6.96055793762207,
      "rewards/rejected": -6.5788116455078125,
      "step": 2548
    },
    {
      "epoch": 1.0196,
      "grad_norm": 13.544917106628418,
      "learning_rate": 6.602666666666666e-07,
      "logits/chosen": -2.4004065990448,
      "logits/rejected": -2.14441180229187,
      "logps/chosen": -88.52613830566406,
      "logps/rejected": -99.02129364013672,
      "loss": 0.0986,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.092742443084717,
      "rewards/margins": 3.098708152770996,
      "rewards/rejected": -5.191450595855713,
      "step": 2549
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.46313637495040894,
      "learning_rate": 6.601333333333333e-07,
      "logits/chosen": -3.1786742210388184,
      "logits/rejected": -2.7989273071289062,
      "logps/chosen": -42.71139907836914,
      "logps/rejected": -113.53787994384766,
      "loss": 0.0057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7456250190734863,
      "rewards/margins": 7.966206073760986,
      "rewards/rejected": -6.2205810546875,
      "step": 2550
    },
    {
      "epoch": 1.0204,
      "grad_norm": 0.14643557369709015,
      "learning_rate": 6.6e-07,
      "logits/chosen": -3.1476879119873047,
      "logits/rejected": -2.680861473083496,
      "logps/chosen": -57.88787078857422,
      "logps/rejected": -95.40800476074219,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.040317177772522,
      "rewards/margins": 6.5112152099609375,
      "rewards/rejected": -5.470898151397705,
      "step": 2551
    },
    {
      "epoch": 1.0208,
      "grad_norm": 0.009278999641537666,
      "learning_rate": 6.598666666666667e-07,
      "logits/chosen": -2.9934115409851074,
      "logits/rejected": -2.4245150089263916,
      "logps/chosen": -95.60447692871094,
      "logps/rejected": -185.76043701171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6572495102882385,
      "rewards/margins": 11.311793327331543,
      "rewards/rejected": -10.65454387664795,
      "step": 2552
    },
    {
      "epoch": 1.0212,
      "grad_norm": 3.0538108348846436,
      "learning_rate": 6.597333333333332e-07,
      "logits/chosen": -2.6984376907348633,
      "logits/rejected": -2.3587021827697754,
      "logps/chosen": -89.45266723632812,
      "logps/rejected": -178.3188934326172,
      "loss": 0.0237,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.908969521522522,
      "rewards/margins": 8.197894096374512,
      "rewards/rejected": -7.288924694061279,
      "step": 2553
    },
    {
      "epoch": 1.0216,
      "grad_norm": 7.884392738342285,
      "learning_rate": 6.595999999999999e-07,
      "logits/chosen": -2.256199598312378,
      "logits/rejected": -1.975693941116333,
      "logps/chosen": -118.34030151367188,
      "logps/rejected": -100.26848602294922,
      "loss": 0.0421,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.386191964149475,
      "rewards/margins": 3.7912182807922363,
      "rewards/rejected": -5.177410125732422,
      "step": 2554
    },
    {
      "epoch": 1.022,
      "grad_norm": 0.016210278496146202,
      "learning_rate": 6.594666666666666e-07,
      "logits/chosen": -2.5180506706237793,
      "logits/rejected": -1.6336417198181152,
      "logps/chosen": -141.60304260253906,
      "logps/rejected": -167.10992431640625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2702816128730774,
      "rewards/margins": 9.325448989868164,
      "rewards/rejected": -9.595730781555176,
      "step": 2555
    },
    {
      "epoch": 1.0224,
      "grad_norm": 1.7748558521270752,
      "learning_rate": 6.593333333333333e-07,
      "logits/chosen": -3.1535279750823975,
      "logits/rejected": -2.651427745819092,
      "logps/chosen": -75.90951538085938,
      "logps/rejected": -76.19989013671875,
      "loss": 0.0156,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.686527669429779,
      "rewards/margins": 5.560089111328125,
      "rewards/rejected": -4.873561382293701,
      "step": 2556
    },
    {
      "epoch": 1.0228,
      "grad_norm": 0.7308534383773804,
      "learning_rate": 6.592e-07,
      "logits/chosen": -2.795347213745117,
      "logits/rejected": -2.134934902191162,
      "logps/chosen": -133.27908325195312,
      "logps/rejected": -129.83238220214844,
      "loss": 0.006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.010989785194396973,
      "rewards/margins": 6.845582485198975,
      "rewards/rejected": -6.856572151184082,
      "step": 2557
    },
    {
      "epoch": 1.0232,
      "grad_norm": 0.18663522601127625,
      "learning_rate": 6.590666666666667e-07,
      "logits/chosen": -3.033107280731201,
      "logits/rejected": -2.50278377532959,
      "logps/chosen": -105.49837493896484,
      "logps/rejected": -110.20252990722656,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.303165078163147,
      "rewards/margins": 6.717638969421387,
      "rewards/rejected": -7.020804405212402,
      "step": 2558
    },
    {
      "epoch": 1.0236,
      "grad_norm": 39.35213851928711,
      "learning_rate": 6.589333333333334e-07,
      "logits/chosen": -3.068920612335205,
      "logits/rejected": -2.6872217655181885,
      "logps/chosen": -119.64852142333984,
      "logps/rejected": -95.68680572509766,
      "loss": 0.4151,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.4861255884170532,
      "rewards/margins": 4.694120407104492,
      "rewards/rejected": -5.180246353149414,
      "step": 2559
    },
    {
      "epoch": 1.024,
      "grad_norm": 1.6363290548324585,
      "learning_rate": 6.588e-07,
      "logits/chosen": -3.372311592102051,
      "logits/rejected": -3.108555316925049,
      "logps/chosen": -61.778839111328125,
      "logps/rejected": -100.06982421875,
      "loss": 0.0239,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1148061752319336,
      "rewards/margins": 6.149736404418945,
      "rewards/rejected": -6.03493070602417,
      "step": 2560
    },
    {
      "epoch": 1.0244,
      "grad_norm": 0.12247861921787262,
      "learning_rate": 6.586666666666666e-07,
      "logits/chosen": -2.9657492637634277,
      "logits/rejected": -2.881462574005127,
      "logps/chosen": -69.91215515136719,
      "logps/rejected": -127.54147338867188,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.12132826447486877,
      "rewards/margins": 8.619087219238281,
      "rewards/rejected": -8.740415573120117,
      "step": 2561
    },
    {
      "epoch": 1.0248,
      "grad_norm": 0.4634232521057129,
      "learning_rate": 6.585333333333332e-07,
      "logits/chosen": -3.219907760620117,
      "logits/rejected": -2.7872138023376465,
      "logps/chosen": -61.41838455200195,
      "logps/rejected": -113.68502807617188,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4357764720916748,
      "rewards/margins": 6.967135429382324,
      "rewards/rejected": -7.402912139892578,
      "step": 2562
    },
    {
      "epoch": 1.0252,
      "grad_norm": 0.10054976493120193,
      "learning_rate": 6.583999999999999e-07,
      "logits/chosen": -2.912444591522217,
      "logits/rejected": -2.0238795280456543,
      "logps/chosen": -107.78907775878906,
      "logps/rejected": -119.98953247070312,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17831401526927948,
      "rewards/margins": 7.17941951751709,
      "rewards/rejected": -7.001105308532715,
      "step": 2563
    },
    {
      "epoch": 1.0256,
      "grad_norm": 0.07213940471410751,
      "learning_rate": 6.582666666666666e-07,
      "logits/chosen": -2.5207831859588623,
      "logits/rejected": -1.7612121105194092,
      "logps/chosen": -142.6609344482422,
      "logps/rejected": -185.19781494140625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.05443382263183594,
      "rewards/margins": 9.28807544708252,
      "rewards/rejected": -9.342509269714355,
      "step": 2564
    },
    {
      "epoch": 1.026,
      "grad_norm": 0.15750327706336975,
      "learning_rate": 6.581333333333333e-07,
      "logits/chosen": -2.7342567443847656,
      "logits/rejected": -1.8128259181976318,
      "logps/chosen": -86.92547607421875,
      "logps/rejected": -144.82009887695312,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0694652572274208,
      "rewards/margins": 8.548198699951172,
      "rewards/rejected": -8.617663383483887,
      "step": 2565
    },
    {
      "epoch": 1.0264,
      "grad_norm": 0.2114667296409607,
      "learning_rate": 6.58e-07,
      "logits/chosen": -3.1552672386169434,
      "logits/rejected": -2.6181986331939697,
      "logps/chosen": -86.85284423828125,
      "logps/rejected": -158.89085388183594,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.46269112825393677,
      "rewards/margins": 8.36622428894043,
      "rewards/rejected": -7.903532981872559,
      "step": 2566
    },
    {
      "epoch": 1.0268,
      "grad_norm": 0.648973286151886,
      "learning_rate": 6.578666666666667e-07,
      "logits/chosen": -2.999335527420044,
      "logits/rejected": -2.6043319702148438,
      "logps/chosen": -42.86266326904297,
      "logps/rejected": -90.00212097167969,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4993141293525696,
      "rewards/margins": 5.454107284545898,
      "rewards/rejected": -4.9547929763793945,
      "step": 2567
    },
    {
      "epoch": 1.0272,
      "grad_norm": 0.007713787257671356,
      "learning_rate": 6.577333333333333e-07,
      "logits/chosen": -3.0459957122802734,
      "logits/rejected": -2.4029531478881836,
      "logps/chosen": -57.31169128417969,
      "logps/rejected": -193.33486938476562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0474529266357422,
      "rewards/margins": 10.418521881103516,
      "rewards/rejected": -9.371068954467773,
      "step": 2568
    },
    {
      "epoch": 1.0276,
      "grad_norm": 4.529933929443359,
      "learning_rate": 6.576e-07,
      "logits/chosen": -3.052994966506958,
      "logits/rejected": -2.723236560821533,
      "logps/chosen": -68.117431640625,
      "logps/rejected": -92.107666015625,
      "loss": 0.0426,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10963267087936401,
      "rewards/margins": 4.65966796875,
      "rewards/rejected": -4.769300937652588,
      "step": 2569
    },
    {
      "epoch": 1.028,
      "grad_norm": 0.05581206455826759,
      "learning_rate": 6.574666666666667e-07,
      "logits/chosen": -2.887261390686035,
      "logits/rejected": -2.1966357231140137,
      "logps/chosen": -193.69371032714844,
      "logps/rejected": -145.734619140625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16790561378002167,
      "rewards/margins": 8.522087097167969,
      "rewards/rejected": -8.354181289672852,
      "step": 2570
    },
    {
      "epoch": 1.0284,
      "grad_norm": 0.07611143589019775,
      "learning_rate": 6.573333333333333e-07,
      "logits/chosen": -2.8264546394348145,
      "logits/rejected": -2.168722629547119,
      "logps/chosen": -83.62095642089844,
      "logps/rejected": -120.02279663085938,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6966792941093445,
      "rewards/margins": 7.4296722412109375,
      "rewards/rejected": -6.732993125915527,
      "step": 2571
    },
    {
      "epoch": 1.0288,
      "grad_norm": 0.16611739993095398,
      "learning_rate": 6.571999999999999e-07,
      "logits/chosen": -2.627185821533203,
      "logits/rejected": -2.236837387084961,
      "logps/chosen": -168.5300750732422,
      "logps/rejected": -136.81903076171875,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7810043692588806,
      "rewards/margins": 9.134031295776367,
      "rewards/rejected": -9.91503620147705,
      "step": 2572
    },
    {
      "epoch": 1.0292,
      "grad_norm": 0.21819539368152618,
      "learning_rate": 6.570666666666666e-07,
      "logits/chosen": -3.0584850311279297,
      "logits/rejected": -2.5476627349853516,
      "logps/chosen": -110.05694580078125,
      "logps/rejected": -171.1713409423828,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2105979919433594,
      "rewards/margins": 8.056842803955078,
      "rewards/rejected": -9.267440795898438,
      "step": 2573
    },
    {
      "epoch": 1.0296,
      "grad_norm": 0.22369852662086487,
      "learning_rate": 6.569333333333333e-07,
      "logits/chosen": -3.1583752632141113,
      "logits/rejected": -2.142580509185791,
      "logps/chosen": -64.05143737792969,
      "logps/rejected": -160.60662841796875,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1815357208251953,
      "rewards/margins": 9.719888687133789,
      "rewards/rejected": -8.538352966308594,
      "step": 2574
    },
    {
      "epoch": 1.03,
      "grad_norm": 4.216785430908203,
      "learning_rate": 6.568e-07,
      "logits/chosen": -2.844025135040283,
      "logits/rejected": -3.0108275413513184,
      "logps/chosen": -101.47486877441406,
      "logps/rejected": -102.30245208740234,
      "loss": 0.0386,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026914596557617188,
      "rewards/margins": 5.245580673217773,
      "rewards/rejected": -5.2186665534973145,
      "step": 2575
    },
    {
      "epoch": 1.0304,
      "grad_norm": 3.073829174041748,
      "learning_rate": 6.566666666666666e-07,
      "logits/chosen": -2.557209014892578,
      "logits/rejected": -1.6835216283798218,
      "logps/chosen": -136.31597900390625,
      "logps/rejected": -123.23553466796875,
      "loss": 0.0168,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.22248375415802,
      "rewards/margins": 5.435216903686523,
      "rewards/rejected": -6.657700538635254,
      "step": 2576
    },
    {
      "epoch": 1.0308,
      "grad_norm": 0.03137379139661789,
      "learning_rate": 6.565333333333333e-07,
      "logits/chosen": -2.5545263290405273,
      "logits/rejected": -1.8599269390106201,
      "logps/chosen": -169.7503204345703,
      "logps/rejected": -240.01187133789062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1398574709892273,
      "rewards/margins": 9.655961990356445,
      "rewards/rejected": -9.795818328857422,
      "step": 2577
    },
    {
      "epoch": 1.0312,
      "grad_norm": 0.14126068353652954,
      "learning_rate": 6.564e-07,
      "logits/chosen": -2.861161708831787,
      "logits/rejected": -2.081397533416748,
      "logps/chosen": -122.30056762695312,
      "logps/rejected": -197.38095092773438,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.17414474487304688,
      "rewards/margins": 11.094504356384277,
      "rewards/rejected": -11.268649101257324,
      "step": 2578
    },
    {
      "epoch": 1.0316,
      "grad_norm": 0.035799212753772736,
      "learning_rate": 6.562666666666667e-07,
      "logits/chosen": -2.583326816558838,
      "logits/rejected": -1.6125462055206299,
      "logps/chosen": -190.2342071533203,
      "logps/rejected": -154.946533203125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.846173107624054,
      "rewards/margins": 8.412385940551758,
      "rewards/rejected": -9.25855827331543,
      "step": 2579
    },
    {
      "epoch": 1.032,
      "grad_norm": 1.9956830739974976,
      "learning_rate": 6.561333333333334e-07,
      "logits/chosen": -3.1189749240875244,
      "logits/rejected": -2.9845075607299805,
      "logps/chosen": -81.52753448486328,
      "logps/rejected": -119.15789031982422,
      "loss": 0.017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5643821358680725,
      "rewards/margins": 5.630876541137695,
      "rewards/rejected": -6.195259094238281,
      "step": 2580
    },
    {
      "epoch": 1.0324,
      "grad_norm": 12.024121284484863,
      "learning_rate": 6.56e-07,
      "logits/chosen": -2.949612617492676,
      "logits/rejected": -2.6473965644836426,
      "logps/chosen": -150.56466674804688,
      "logps/rejected": -93.1973876953125,
      "loss": 0.0728,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5056984424591064,
      "rewards/margins": 4.211076736450195,
      "rewards/rejected": -5.716774940490723,
      "step": 2581
    },
    {
      "epoch": 1.0328,
      "grad_norm": 1.8782655000686646,
      "learning_rate": 6.558666666666666e-07,
      "logits/chosen": -3.0790767669677734,
      "logits/rejected": -2.5811638832092285,
      "logps/chosen": -117.39020538330078,
      "logps/rejected": -152.19760131835938,
      "loss": 0.0167,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9688321948051453,
      "rewards/margins": 8.249224662780762,
      "rewards/rejected": -9.218056678771973,
      "step": 2582
    },
    {
      "epoch": 1.0332,
      "grad_norm": 0.03126322850584984,
      "learning_rate": 6.557333333333332e-07,
      "logits/chosen": -2.6484427452087402,
      "logits/rejected": -2.095885992050171,
      "logps/chosen": -99.20782470703125,
      "logps/rejected": -143.97088623046875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7649872303009033,
      "rewards/margins": 9.57636833190918,
      "rewards/rejected": -7.811380863189697,
      "step": 2583
    },
    {
      "epoch": 1.0336,
      "grad_norm": 2.834662437438965,
      "learning_rate": 6.555999999999999e-07,
      "logits/chosen": -2.9807627201080322,
      "logits/rejected": -2.6323659420013428,
      "logps/chosen": -90.5788803100586,
      "logps/rejected": -106.70121002197266,
      "loss": 0.02,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5919586420059204,
      "rewards/margins": 6.841052532196045,
      "rewards/rejected": -6.249094009399414,
      "step": 2584
    },
    {
      "epoch": 1.034,
      "grad_norm": 0.07965417951345444,
      "learning_rate": 6.554666666666666e-07,
      "logits/chosen": -2.849613904953003,
      "logits/rejected": -1.8574190139770508,
      "logps/chosen": -126.3304443359375,
      "logps/rejected": -160.15513610839844,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07861156761646271,
      "rewards/margins": 9.835302352905273,
      "rewards/rejected": -9.756690979003906,
      "step": 2585
    },
    {
      "epoch": 1.0344,
      "grad_norm": 0.0806526243686676,
      "learning_rate": 6.553333333333333e-07,
      "logits/chosen": -2.570341110229492,
      "logits/rejected": -1.6366424560546875,
      "logps/chosen": -147.36257934570312,
      "logps/rejected": -193.24700927734375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1843078136444092,
      "rewards/margins": 9.253582000732422,
      "rewards/rejected": -10.437889099121094,
      "step": 2586
    },
    {
      "epoch": 1.0348,
      "grad_norm": 0.5738528966903687,
      "learning_rate": 6.552e-07,
      "logits/chosen": -2.9948105812072754,
      "logits/rejected": -2.6093900203704834,
      "logps/chosen": -72.14085388183594,
      "logps/rejected": -149.23638916015625,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3628738224506378,
      "rewards/margins": 7.329549312591553,
      "rewards/rejected": -6.966675758361816,
      "step": 2587
    },
    {
      "epoch": 1.0352,
      "grad_norm": 0.006583001464605331,
      "learning_rate": 6.550666666666667e-07,
      "logits/chosen": -2.7983970642089844,
      "logits/rejected": -1.959733009338379,
      "logps/chosen": -122.95565795898438,
      "logps/rejected": -178.1615447998047,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.46412888169288635,
      "rewards/margins": 10.518665313720703,
      "rewards/rejected": -10.054536819458008,
      "step": 2588
    },
    {
      "epoch": 1.0356,
      "grad_norm": 11.48468017578125,
      "learning_rate": 6.549333333333334e-07,
      "logits/chosen": -3.0623977184295654,
      "logits/rejected": -2.6007585525512695,
      "logps/chosen": -128.48471069335938,
      "logps/rejected": -92.79771423339844,
      "loss": 0.0707,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4711300134658813,
      "rewards/margins": 4.2689104080200195,
      "rewards/rejected": -5.740040302276611,
      "step": 2589
    },
    {
      "epoch": 1.036,
      "grad_norm": 2.1843185424804688,
      "learning_rate": 6.548000000000001e-07,
      "logits/chosen": -2.979304313659668,
      "logits/rejected": -2.745234489440918,
      "logps/chosen": -111.75589752197266,
      "logps/rejected": -81.4244384765625,
      "loss": 0.025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2817268371582031,
      "rewards/margins": 3.7289280891418457,
      "rewards/rejected": -4.010654926300049,
      "step": 2590
    },
    {
      "epoch": 1.0364,
      "grad_norm": 0.222712904214859,
      "learning_rate": 6.546666666666665e-07,
      "logits/chosen": -3.103860855102539,
      "logits/rejected": -2.6567559242248535,
      "logps/chosen": -83.05021667480469,
      "logps/rejected": -122.0294418334961,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7955803275108337,
      "rewards/margins": 6.826902866363525,
      "rewards/rejected": -6.031322479248047,
      "step": 2591
    },
    {
      "epoch": 1.0368,
      "grad_norm": 0.49305978417396545,
      "learning_rate": 6.545333333333332e-07,
      "logits/chosen": -2.4401350021362305,
      "logits/rejected": -1.8611518144607544,
      "logps/chosen": -112.31135559082031,
      "logps/rejected": -111.82112121582031,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03867644816637039,
      "rewards/margins": 6.198456287384033,
      "rewards/rejected": -6.1597795486450195,
      "step": 2592
    },
    {
      "epoch": 1.0372,
      "grad_norm": 2.8811917304992676,
      "learning_rate": 6.543999999999999e-07,
      "logits/chosen": -2.8854846954345703,
      "logits/rejected": -2.2723073959350586,
      "logps/chosen": -113.67872619628906,
      "logps/rejected": -117.74200439453125,
      "loss": 0.0224,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8244854211807251,
      "rewards/margins": 7.11402702331543,
      "rewards/rejected": -6.289541244506836,
      "step": 2593
    },
    {
      "epoch": 1.0376,
      "grad_norm": 0.6346287131309509,
      "learning_rate": 6.542666666666666e-07,
      "logits/chosen": -2.588236093521118,
      "logits/rejected": -2.3109850883483887,
      "logps/chosen": -118.32423400878906,
      "logps/rejected": -154.88717651367188,
      "loss": 0.0048,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.43845796585083,
      "rewards/margins": 5.329553604125977,
      "rewards/rejected": -6.768011569976807,
      "step": 2594
    },
    {
      "epoch": 1.038,
      "grad_norm": 0.008971045725047588,
      "learning_rate": 6.541333333333333e-07,
      "logits/chosen": -2.628854990005493,
      "logits/rejected": -1.985440731048584,
      "logps/chosen": -103.78598022460938,
      "logps/rejected": -159.04037475585938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2167587280273438,
      "rewards/margins": 10.272435188293457,
      "rewards/rejected": -9.055676460266113,
      "step": 2595
    },
    {
      "epoch": 1.0384,
      "grad_norm": 0.03417140990495682,
      "learning_rate": 6.54e-07,
      "logits/chosen": -2.6918716430664062,
      "logits/rejected": -2.0682718753814697,
      "logps/chosen": -126.07971954345703,
      "logps/rejected": -139.74703979492188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8348121643066406,
      "rewards/margins": 9.569963455200195,
      "rewards/rejected": -8.735151290893555,
      "step": 2596
    },
    {
      "epoch": 1.0388,
      "grad_norm": 0.004470981657505035,
      "learning_rate": 6.538666666666667e-07,
      "logits/chosen": -2.9819986820220947,
      "logits/rejected": -2.467245101928711,
      "logps/chosen": -120.84484100341797,
      "logps/rejected": -200.64773559570312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.41467761993408203,
      "rewards/margins": 11.234416007995605,
      "rewards/rejected": -11.649093627929688,
      "step": 2597
    },
    {
      "epoch": 1.0392,
      "grad_norm": 0.07580201327800751,
      "learning_rate": 6.537333333333334e-07,
      "logits/chosen": -2.753955364227295,
      "logits/rejected": -2.0507261753082275,
      "logps/chosen": -173.1586151123047,
      "logps/rejected": -204.10914611816406,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1300945281982422,
      "rewards/margins": 9.214740753173828,
      "rewards/rejected": -9.34483528137207,
      "step": 2598
    },
    {
      "epoch": 1.0396,
      "grad_norm": 0.4104076027870178,
      "learning_rate": 6.536e-07,
      "logits/chosen": -3.1387012004852295,
      "logits/rejected": -2.801274299621582,
      "logps/chosen": -42.408851623535156,
      "logps/rejected": -76.71775817871094,
      "loss": 0.005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3379106521606445,
      "rewards/margins": 5.50806999206543,
      "rewards/rejected": -4.170159339904785,
      "step": 2599
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.9382445216178894,
      "learning_rate": 6.534666666666666e-07,
      "logits/chosen": -2.667426109313965,
      "logits/rejected": -2.2619447708129883,
      "logps/chosen": -145.09568786621094,
      "logps/rejected": -203.37144470214844,
      "loss": 0.0081,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35920676589012146,
      "rewards/margins": 9.120132446289062,
      "rewards/rejected": -8.760926246643066,
      "step": 2600
    },
    {
      "epoch": 1.0404,
      "grad_norm": 0.22779518365859985,
      "learning_rate": 6.533333333333333e-07,
      "logits/chosen": -3.1533875465393066,
      "logits/rejected": -2.888443946838379,
      "logps/chosen": -49.878944396972656,
      "logps/rejected": -104.44610595703125,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24124431610107422,
      "rewards/margins": 6.01680326461792,
      "rewards/rejected": -5.775558948516846,
      "step": 2601
    },
    {
      "epoch": 1.0408,
      "grad_norm": 1.808144450187683,
      "learning_rate": 6.531999999999999e-07,
      "logits/chosen": -2.973546028137207,
      "logits/rejected": -2.749107837677002,
      "logps/chosen": -147.01165771484375,
      "logps/rejected": -146.2382049560547,
      "loss": 0.0157,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8623119592666626,
      "rewards/margins": 6.081117630004883,
      "rewards/rejected": -6.943429946899414,
      "step": 2602
    },
    {
      "epoch": 1.0412,
      "grad_norm": 2.560744524002075,
      "learning_rate": 6.530666666666666e-07,
      "logits/chosen": -3.0612220764160156,
      "logits/rejected": -2.7935948371887207,
      "logps/chosen": -94.9083023071289,
      "logps/rejected": -87.03706359863281,
      "loss": 0.0241,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.23702356219291687,
      "rewards/margins": 4.553306579589844,
      "rewards/rejected": -4.790329933166504,
      "step": 2603
    },
    {
      "epoch": 1.0416,
      "grad_norm": 107.45381164550781,
      "learning_rate": 6.529333333333333e-07,
      "logits/chosen": -2.958585262298584,
      "logits/rejected": -2.662386894226074,
      "logps/chosen": -177.5149688720703,
      "logps/rejected": -90.44524383544922,
      "loss": 2.0879,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -4.058037757873535,
      "rewards/margins": 1.308300256729126,
      "rewards/rejected": -5.366337776184082,
      "step": 2604
    },
    {
      "epoch": 1.042,
      "grad_norm": 39.77241897583008,
      "learning_rate": 6.528e-07,
      "logits/chosen": -2.4778876304626465,
      "logits/rejected": -2.0876286029815674,
      "logps/chosen": -177.7525634765625,
      "logps/rejected": -141.74923706054688,
      "loss": 0.1517,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.5403614044189453,
      "rewards/margins": 3.3969063758850098,
      "rewards/rejected": -5.937267780303955,
      "step": 2605
    },
    {
      "epoch": 1.0424,
      "grad_norm": 11.981433868408203,
      "learning_rate": 6.526666666666666e-07,
      "logits/chosen": -2.4576172828674316,
      "logits/rejected": -1.8176430463790894,
      "logps/chosen": -171.7132568359375,
      "logps/rejected": -158.744873046875,
      "loss": 0.0794,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.482086181640625,
      "rewards/margins": 7.097894668579102,
      "rewards/rejected": -8.579980850219727,
      "step": 2606
    },
    {
      "epoch": 1.0428,
      "grad_norm": 0.07868588715791702,
      "learning_rate": 6.525333333333333e-07,
      "logits/chosen": -2.949984312057495,
      "logits/rejected": -2.592857837677002,
      "logps/chosen": -144.04298400878906,
      "logps/rejected": -144.30506896972656,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5802990198135376,
      "rewards/margins": 8.871313095092773,
      "rewards/rejected": -9.45161247253418,
      "step": 2607
    },
    {
      "epoch": 1.0432,
      "grad_norm": 0.28752991557121277,
      "learning_rate": 6.524e-07,
      "logits/chosen": -3.115610361099243,
      "logits/rejected": -2.4539589881896973,
      "logps/chosen": -87.9755630493164,
      "logps/rejected": -117.10670471191406,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7423810958862305,
      "rewards/margins": 6.928450584411621,
      "rewards/rejected": -6.186069488525391,
      "step": 2608
    },
    {
      "epoch": 1.0436,
      "grad_norm": 0.20459270477294922,
      "learning_rate": 6.522666666666667e-07,
      "logits/chosen": -2.744499683380127,
      "logits/rejected": -2.234851360321045,
      "logps/chosen": -66.66155242919922,
      "logps/rejected": -125.55071258544922,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7005352973937988,
      "rewards/margins": 9.163186073303223,
      "rewards/rejected": -7.462650299072266,
      "step": 2609
    },
    {
      "epoch": 1.044,
      "grad_norm": 0.14729876816272736,
      "learning_rate": 6.521333333333333e-07,
      "logits/chosen": -3.0647358894348145,
      "logits/rejected": -2.672877311706543,
      "logps/chosen": -69.56315612792969,
      "logps/rejected": -154.87539672851562,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5419605374336243,
      "rewards/margins": 7.341846942901611,
      "rewards/rejected": -7.883807182312012,
      "step": 2610
    },
    {
      "epoch": 1.0444,
      "grad_norm": 0.02273082546889782,
      "learning_rate": 6.52e-07,
      "logits/chosen": -3.038217544555664,
      "logits/rejected": -2.4386582374572754,
      "logps/chosen": -92.30814361572266,
      "logps/rejected": -172.3698272705078,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39158058166503906,
      "rewards/margins": 10.187271118164062,
      "rewards/rejected": -9.795690536499023,
      "step": 2611
    },
    {
      "epoch": 1.0448,
      "grad_norm": 2.3019986152648926,
      "learning_rate": 6.518666666666667e-07,
      "logits/chosen": -2.8572325706481934,
      "logits/rejected": -2.258861541748047,
      "logps/chosen": -120.64656829833984,
      "logps/rejected": -87.64720153808594,
      "loss": 0.0187,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7698454856872559,
      "rewards/margins": 6.509360313415527,
      "rewards/rejected": -4.73951530456543,
      "step": 2612
    },
    {
      "epoch": 1.0452,
      "grad_norm": 14.643969535827637,
      "learning_rate": 6.517333333333333e-07,
      "logits/chosen": -2.884857654571533,
      "logits/rejected": -2.2952868938446045,
      "logps/chosen": -110.49734497070312,
      "logps/rejected": -101.46487426757812,
      "loss": 0.1155,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6087493896484375,
      "rewards/margins": 4.97243595123291,
      "rewards/rejected": -4.363686561584473,
      "step": 2613
    },
    {
      "epoch": 1.0456,
      "grad_norm": 2.9173214435577393,
      "learning_rate": 6.515999999999999e-07,
      "logits/chosen": -2.7312209606170654,
      "logits/rejected": -2.224015235900879,
      "logps/chosen": -118.61045837402344,
      "logps/rejected": -146.65213012695312,
      "loss": 0.0248,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4237705171108246,
      "rewards/margins": 7.843518257141113,
      "rewards/rejected": -8.267288208007812,
      "step": 2614
    },
    {
      "epoch": 1.046,
      "grad_norm": 0.2531723380088806,
      "learning_rate": 6.514666666666666e-07,
      "logits/chosen": -3.203111171722412,
      "logits/rejected": -2.678158760070801,
      "logps/chosen": -78.741455078125,
      "logps/rejected": -112.62403106689453,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.356008917093277,
      "rewards/margins": 6.654101371765137,
      "rewards/rejected": -7.010109901428223,
      "step": 2615
    },
    {
      "epoch": 1.0464,
      "grad_norm": 0.08977589756250381,
      "learning_rate": 6.513333333333333e-07,
      "logits/chosen": -2.7347140312194824,
      "logits/rejected": -2.150447130203247,
      "logps/chosen": -46.1140022277832,
      "logps/rejected": -111.07282257080078,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2708234786987305,
      "rewards/margins": 8.139328002929688,
      "rewards/rejected": -6.868504047393799,
      "step": 2616
    },
    {
      "epoch": 1.0468,
      "grad_norm": 0.08599378913640976,
      "learning_rate": 6.512e-07,
      "logits/chosen": -2.864980697631836,
      "logits/rejected": -2.1625187397003174,
      "logps/chosen": -81.47959899902344,
      "logps/rejected": -166.80007934570312,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.13469316065311432,
      "rewards/margins": 8.760753631591797,
      "rewards/rejected": -8.89544677734375,
      "step": 2617
    },
    {
      "epoch": 1.0472,
      "grad_norm": 1.7148853540420532,
      "learning_rate": 6.510666666666667e-07,
      "logits/chosen": -2.7162418365478516,
      "logits/rejected": -2.4494519233703613,
      "logps/chosen": -117.19139099121094,
      "logps/rejected": -110.2054443359375,
      "loss": 0.0071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7441128492355347,
      "rewards/margins": 5.3075947761535645,
      "rewards/rejected": -4.563482284545898,
      "step": 2618
    },
    {
      "epoch": 1.0476,
      "grad_norm": 0.5574259161949158,
      "learning_rate": 6.509333333333333e-07,
      "logits/chosen": -3.3970088958740234,
      "logits/rejected": -2.94386887550354,
      "logps/chosen": -54.55107116699219,
      "logps/rejected": -106.60002899169922,
      "loss": 0.0045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14658641815185547,
      "rewards/margins": 6.913339614868164,
      "rewards/rejected": -6.766753196716309,
      "step": 2619
    },
    {
      "epoch": 1.048,
      "grad_norm": 0.16214171051979065,
      "learning_rate": 6.508e-07,
      "logits/chosen": -2.6830453872680664,
      "logits/rejected": -2.228600025177002,
      "logps/chosen": -151.72398376464844,
      "logps/rejected": -186.88937377929688,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.273442029953003,
      "rewards/margins": 7.70561408996582,
      "rewards/rejected": -9.979055404663086,
      "step": 2620
    },
    {
      "epoch": 1.0484,
      "grad_norm": 1.8563894033432007,
      "learning_rate": 6.506666666666666e-07,
      "logits/chosen": -2.3125715255737305,
      "logits/rejected": -1.729048490524292,
      "logps/chosen": -169.58856201171875,
      "logps/rejected": -144.96107482910156,
      "loss": 0.0111,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.460428476333618,
      "rewards/margins": 5.811137676239014,
      "rewards/rejected": -8.271566390991211,
      "step": 2621
    },
    {
      "epoch": 1.0488,
      "grad_norm": 0.9082900881767273,
      "learning_rate": 6.505333333333333e-07,
      "logits/chosen": -2.777052402496338,
      "logits/rejected": -2.530583381652832,
      "logps/chosen": -77.61883544921875,
      "logps/rejected": -105.7208251953125,
      "loss": 0.0073,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7402164340019226,
      "rewards/margins": 6.085663318634033,
      "rewards/rejected": -5.345446586608887,
      "step": 2622
    },
    {
      "epoch": 1.0492,
      "grad_norm": 0.3679552674293518,
      "learning_rate": 6.504e-07,
      "logits/chosen": -3.1930432319641113,
      "logits/rejected": -2.6946802139282227,
      "logps/chosen": -76.857666015625,
      "logps/rejected": -170.77684020996094,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5681889057159424,
      "rewards/margins": 9.179012298583984,
      "rewards/rejected": -9.747201919555664,
      "step": 2623
    },
    {
      "epoch": 1.0496,
      "grad_norm": 0.9587273597717285,
      "learning_rate": 6.502666666666666e-07,
      "logits/chosen": -3.080078125,
      "logits/rejected": -2.6505236625671387,
      "logps/chosen": -63.259918212890625,
      "logps/rejected": -76.10057067871094,
      "loss": 0.0082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0781698226928711,
      "rewards/margins": 4.804046154022217,
      "rewards/rejected": -4.725876331329346,
      "step": 2624
    },
    {
      "epoch": 1.05,
      "grad_norm": 35.43238067626953,
      "learning_rate": 6.501333333333333e-07,
      "logits/chosen": -2.218287706375122,
      "logits/rejected": -1.5265467166900635,
      "logps/chosen": -175.8006134033203,
      "logps/rejected": -143.26358032226562,
      "loss": 0.1313,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0986850261688232,
      "rewards/margins": 4.362289905548096,
      "rewards/rejected": -6.46097469329834,
      "step": 2625
    },
    {
      "epoch": 1.0504,
      "grad_norm": 0.07949992269277573,
      "learning_rate": 6.5e-07,
      "logits/chosen": -2.7047834396362305,
      "logits/rejected": -2.0221400260925293,
      "logps/chosen": -108.04489135742188,
      "logps/rejected": -216.1248016357422,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2328286170959473,
      "rewards/margins": 7.94050931930542,
      "rewards/rejected": -6.707680702209473,
      "step": 2626
    },
    {
      "epoch": 1.0508,
      "grad_norm": 0.1849195659160614,
      "learning_rate": 6.498666666666667e-07,
      "logits/chosen": -2.9049768447875977,
      "logits/rejected": -2.4792380332946777,
      "logps/chosen": -85.87417602539062,
      "logps/rejected": -138.31234741210938,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3627612888813019,
      "rewards/margins": 7.853176116943359,
      "rewards/rejected": -8.215937614440918,
      "step": 2627
    },
    {
      "epoch": 1.0512,
      "grad_norm": 1.250014066696167,
      "learning_rate": 6.497333333333334e-07,
      "logits/chosen": -2.3457818031311035,
      "logits/rejected": -1.7685909271240234,
      "logps/chosen": -232.44119262695312,
      "logps/rejected": -169.76730346679688,
      "loss": 0.0065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.6356942653656006,
      "rewards/margins": 7.648745536804199,
      "rewards/rejected": -10.284440040588379,
      "step": 2628
    },
    {
      "epoch": 1.0516,
      "grad_norm": 4.710402011871338,
      "learning_rate": 6.495999999999999e-07,
      "logits/chosen": -3.1916353702545166,
      "logits/rejected": -3.0543317794799805,
      "logps/chosen": -65.99345397949219,
      "logps/rejected": -61.950740814208984,
      "loss": 0.0591,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3937239646911621,
      "rewards/margins": 2.7999002933502197,
      "rewards/rejected": -3.193624258041382,
      "step": 2629
    },
    {
      "epoch": 1.052,
      "grad_norm": 0.01790112443268299,
      "learning_rate": 6.494666666666666e-07,
      "logits/chosen": -2.874364137649536,
      "logits/rejected": -2.217108726501465,
      "logps/chosen": -75.79301452636719,
      "logps/rejected": -154.98297119140625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2388052940368652,
      "rewards/margins": 9.693836212158203,
      "rewards/rejected": -8.45503044128418,
      "step": 2630
    },
    {
      "epoch": 1.0524,
      "grad_norm": 0.5395565629005432,
      "learning_rate": 6.493333333333333e-07,
      "logits/chosen": -3.024848461151123,
      "logits/rejected": -2.886322021484375,
      "logps/chosen": -106.88912200927734,
      "logps/rejected": -131.2903594970703,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.847638726234436,
      "rewards/margins": 6.092110633850098,
      "rewards/rejected": -7.939749240875244,
      "step": 2631
    },
    {
      "epoch": 1.0528,
      "grad_norm": 0.6946032643318176,
      "learning_rate": 6.492e-07,
      "logits/chosen": -2.9028468132019043,
      "logits/rejected": -2.2902069091796875,
      "logps/chosen": -117.55643463134766,
      "logps/rejected": -112.41299438476562,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7438459396362305,
      "rewards/margins": 5.76546573638916,
      "rewards/rejected": -6.509311676025391,
      "step": 2632
    },
    {
      "epoch": 1.0532,
      "grad_norm": 1.4712451696395874,
      "learning_rate": 6.490666666666667e-07,
      "logits/chosen": -3.179934501647949,
      "logits/rejected": -2.9409656524658203,
      "logps/chosen": -35.87603759765625,
      "logps/rejected": -77.93614196777344,
      "loss": 0.014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1704425811767578,
      "rewards/margins": 4.259160041809082,
      "rewards/rejected": -4.088717460632324,
      "step": 2633
    },
    {
      "epoch": 1.0536,
      "grad_norm": 0.9214702844619751,
      "learning_rate": 6.489333333333333e-07,
      "logits/chosen": -3.036414623260498,
      "logits/rejected": -2.738640785217285,
      "logps/chosen": -112.31478881835938,
      "logps/rejected": -95.51193237304688,
      "loss": 0.0099,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.031357184052467346,
      "rewards/margins": 4.830053329467773,
      "rewards/rejected": -4.861410140991211,
      "step": 2634
    },
    {
      "epoch": 1.054,
      "grad_norm": 0.06288544833660126,
      "learning_rate": 6.488e-07,
      "logits/chosen": -2.926034927368164,
      "logits/rejected": -1.9871690273284912,
      "logps/chosen": -89.06671905517578,
      "logps/rejected": -123.0623779296875,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.340735673904419,
      "rewards/margins": 7.878429889678955,
      "rewards/rejected": -6.537693977355957,
      "step": 2635
    },
    {
      "epoch": 1.0544,
      "grad_norm": 0.39721059799194336,
      "learning_rate": 6.486666666666666e-07,
      "logits/chosen": -2.835198402404785,
      "logits/rejected": -2.4010891914367676,
      "logps/chosen": -56.04340744018555,
      "logps/rejected": -97.90658569335938,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10048083961009979,
      "rewards/margins": 6.226757049560547,
      "rewards/rejected": -6.126276016235352,
      "step": 2636
    },
    {
      "epoch": 1.0548,
      "grad_norm": 0.04786958172917366,
      "learning_rate": 6.485333333333333e-07,
      "logits/chosen": -2.8812007904052734,
      "logits/rejected": -2.3288633823394775,
      "logps/chosen": -151.54266357421875,
      "logps/rejected": -142.3519287109375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1646286249160767,
      "rewards/margins": 8.087080001831055,
      "rewards/rejected": -9.251708984375,
      "step": 2637
    },
    {
      "epoch": 1.0552,
      "grad_norm": 0.1427992582321167,
      "learning_rate": 6.483999999999999e-07,
      "logits/chosen": -3.071735382080078,
      "logits/rejected": -2.4452457427978516,
      "logps/chosen": -56.593849182128906,
      "logps/rejected": -123.65115356445312,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.647254228591919,
      "rewards/margins": 7.275556564331055,
      "rewards/rejected": -6.628302574157715,
      "step": 2638
    },
    {
      "epoch": 1.0556,
      "grad_norm": 0.16008491814136505,
      "learning_rate": 6.482666666666666e-07,
      "logits/chosen": -3.186150074005127,
      "logits/rejected": -2.660224199295044,
      "logps/chosen": -83.14309692382812,
      "logps/rejected": -126.11943054199219,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.26141417026519775,
      "rewards/margins": 7.530025482177734,
      "rewards/rejected": -7.791440010070801,
      "step": 2639
    },
    {
      "epoch": 1.056,
      "grad_norm": 41.385196685791016,
      "learning_rate": 6.481333333333333e-07,
      "logits/chosen": -3.012301445007324,
      "logits/rejected": -2.968221664428711,
      "logps/chosen": -163.90536499023438,
      "logps/rejected": -77.36846160888672,
      "loss": 0.4714,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.3071794509887695,
      "rewards/margins": 0.5971730947494507,
      "rewards/rejected": -3.9043524265289307,
      "step": 2640
    },
    {
      "epoch": 1.0564,
      "grad_norm": 0.00782173965126276,
      "learning_rate": 6.48e-07,
      "logits/chosen": -2.729576826095581,
      "logits/rejected": -2.1519052982330322,
      "logps/chosen": -151.27276611328125,
      "logps/rejected": -180.83773803710938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7964088916778564,
      "rewards/margins": 10.43188190460205,
      "rewards/rejected": -9.635473251342773,
      "step": 2641
    },
    {
      "epoch": 1.0568,
      "grad_norm": 0.04387228563427925,
      "learning_rate": 6.478666666666667e-07,
      "logits/chosen": -3.1054182052612305,
      "logits/rejected": -2.8167247772216797,
      "logps/chosen": -55.463172912597656,
      "logps/rejected": -134.47900390625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2312639355659485,
      "rewards/margins": 8.506209373474121,
      "rewards/rejected": -8.737473487854004,
      "step": 2642
    },
    {
      "epoch": 1.0572,
      "grad_norm": 0.17475557327270508,
      "learning_rate": 6.477333333333334e-07,
      "logits/chosen": -2.8581812381744385,
      "logits/rejected": -2.457728147506714,
      "logps/chosen": -118.43926239013672,
      "logps/rejected": -143.12722778320312,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3029128909111023,
      "rewards/margins": 9.188400268554688,
      "rewards/rejected": -8.88548755645752,
      "step": 2643
    },
    {
      "epoch": 1.0576,
      "grad_norm": 0.08781273663043976,
      "learning_rate": 6.476e-07,
      "logits/chosen": -3.193962812423706,
      "logits/rejected": -2.6379506587982178,
      "logps/chosen": -57.49942398071289,
      "logps/rejected": -132.4279022216797,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45199528336524963,
      "rewards/margins": 8.54513931274414,
      "rewards/rejected": -8.093144416809082,
      "step": 2644
    },
    {
      "epoch": 1.058,
      "grad_norm": 0.38024190068244934,
      "learning_rate": 6.474666666666666e-07,
      "logits/chosen": -2.5334525108337402,
      "logits/rejected": -1.8867311477661133,
      "logps/chosen": -139.59579467773438,
      "logps/rejected": -137.58425903320312,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.00687253475189209,
      "rewards/margins": 7.14437198638916,
      "rewards/rejected": -7.151244640350342,
      "step": 2645
    },
    {
      "epoch": 1.0584,
      "grad_norm": 0.00634155236184597,
      "learning_rate": 6.473333333333333e-07,
      "logits/chosen": -2.625896453857422,
      "logits/rejected": -2.0520076751708984,
      "logps/chosen": -61.86285400390625,
      "logps/rejected": -204.56814575195312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1549644470214844,
      "rewards/margins": 11.058895111083984,
      "rewards/rejected": -8.9039306640625,
      "step": 2646
    },
    {
      "epoch": 1.0588,
      "grad_norm": 9.633663177490234,
      "learning_rate": 6.471999999999999e-07,
      "logits/chosen": -3.0291967391967773,
      "logits/rejected": -3.301164388656616,
      "logps/chosen": -87.46755981445312,
      "logps/rejected": -83.84005737304688,
      "loss": 0.1164,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4552406668663025,
      "rewards/margins": 4.30379056930542,
      "rewards/rejected": -4.759031295776367,
      "step": 2647
    },
    {
      "epoch": 1.0592,
      "grad_norm": 0.12357216328382492,
      "learning_rate": 6.470666666666666e-07,
      "logits/chosen": -3.05855393409729,
      "logits/rejected": -2.4714324474334717,
      "logps/chosen": -76.070556640625,
      "logps/rejected": -120.30537414550781,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3881450593471527,
      "rewards/margins": 6.967419624328613,
      "rewards/rejected": -6.579275131225586,
      "step": 2648
    },
    {
      "epoch": 1.0596,
      "grad_norm": 0.7339301705360413,
      "learning_rate": 6.469333333333333e-07,
      "logits/chosen": -2.5463473796844482,
      "logits/rejected": -2.289860963821411,
      "logps/chosen": -190.33331298828125,
      "logps/rejected": -121.97650146484375,
      "loss": 0.0059,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6999802589416504,
      "rewards/margins": 5.13974666595459,
      "rewards/rejected": -6.83972692489624,
      "step": 2649
    },
    {
      "epoch": 1.06,
      "grad_norm": 4.013940334320068,
      "learning_rate": 6.468e-07,
      "logits/chosen": -3.1353542804718018,
      "logits/rejected": -3.141866683959961,
      "logps/chosen": -73.14591979980469,
      "logps/rejected": -60.32387161254883,
      "loss": 0.0387,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5542110204696655,
      "rewards/margins": 3.8067843914031982,
      "rewards/rejected": -3.2525734901428223,
      "step": 2650
    },
    {
      "epoch": 1.0604,
      "grad_norm": 10.795740127563477,
      "learning_rate": 6.466666666666666e-07,
      "logits/chosen": -2.804889678955078,
      "logits/rejected": -2.596001148223877,
      "logps/chosen": -186.2681884765625,
      "logps/rejected": -132.3462371826172,
      "loss": 0.0621,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.930804431438446,
      "rewards/margins": 5.010314464569092,
      "rewards/rejected": -5.941119194030762,
      "step": 2651
    },
    {
      "epoch": 1.0608,
      "grad_norm": 0.07473565638065338,
      "learning_rate": 6.465333333333333e-07,
      "logits/chosen": -2.5745065212249756,
      "logits/rejected": -2.073894500732422,
      "logps/chosen": -114.44520568847656,
      "logps/rejected": -135.874267578125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6317436695098877,
      "rewards/margins": 7.763399124145508,
      "rewards/rejected": -7.131655693054199,
      "step": 2652
    },
    {
      "epoch": 1.0612,
      "grad_norm": 0.00032960038515739143,
      "learning_rate": 6.464e-07,
      "logits/chosen": -2.9138731956481934,
      "logits/rejected": -2.301575183868408,
      "logps/chosen": -61.542701721191406,
      "logps/rejected": -216.41592407226562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5295910835266113,
      "rewards/margins": 13.63949203491211,
      "rewards/rejected": -12.10990047454834,
      "step": 2653
    },
    {
      "epoch": 1.0616,
      "grad_norm": 0.08715873211622238,
      "learning_rate": 6.462666666666667e-07,
      "logits/chosen": -2.733816623687744,
      "logits/rejected": -1.9785301685333252,
      "logps/chosen": -130.63552856445312,
      "logps/rejected": -137.0925750732422,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6247059106826782,
      "rewards/margins": 8.99625015258789,
      "rewards/rejected": -8.371543884277344,
      "step": 2654
    },
    {
      "epoch": 1.062,
      "grad_norm": 0.15135324001312256,
      "learning_rate": 6.461333333333333e-07,
      "logits/chosen": -2.791433811187744,
      "logits/rejected": -2.5785772800445557,
      "logps/chosen": -77.31755828857422,
      "logps/rejected": -142.45718383789062,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9609262943267822,
      "rewards/margins": 6.937239646911621,
      "rewards/rejected": -7.898165702819824,
      "step": 2655
    },
    {
      "epoch": 1.0624,
      "grad_norm": 0.6577452421188354,
      "learning_rate": 6.46e-07,
      "logits/chosen": -3.041677951812744,
      "logits/rejected": -2.504861831665039,
      "logps/chosen": -54.0894660949707,
      "logps/rejected": -102.44692993164062,
      "loss": 0.0065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9774649143218994,
      "rewards/margins": 7.029223442077637,
      "rewards/rejected": -6.051758289337158,
      "step": 2656
    },
    {
      "epoch": 1.0628,
      "grad_norm": 1.357691764831543,
      "learning_rate": 6.458666666666666e-07,
      "logits/chosen": -3.3366329669952393,
      "logits/rejected": -2.741363048553467,
      "logps/chosen": -46.88612365722656,
      "logps/rejected": -98.2353515625,
      "loss": 0.0161,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5419643521308899,
      "rewards/margins": 5.820516586303711,
      "rewards/rejected": -5.278552055358887,
      "step": 2657
    },
    {
      "epoch": 1.0632,
      "grad_norm": 0.5777422785758972,
      "learning_rate": 6.457333333333333e-07,
      "logits/chosen": -2.84348726272583,
      "logits/rejected": -2.1840667724609375,
      "logps/chosen": -88.77943420410156,
      "logps/rejected": -112.32286834716797,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.15441209077835083,
      "rewards/margins": 6.213010787963867,
      "rewards/rejected": -6.367423057556152,
      "step": 2658
    },
    {
      "epoch": 1.0636,
      "grad_norm": 1.562646746635437,
      "learning_rate": 6.455999999999999e-07,
      "logits/chosen": -3.125159740447998,
      "logits/rejected": -2.84381103515625,
      "logps/chosen": -66.1313247680664,
      "logps/rejected": -76.92465209960938,
      "loss": 0.0189,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3183639347553253,
      "rewards/margins": 4.192071914672852,
      "rewards/rejected": -4.510436058044434,
      "step": 2659
    },
    {
      "epoch": 1.064,
      "grad_norm": 0.15722906589508057,
      "learning_rate": 6.454666666666666e-07,
      "logits/chosen": -2.6441493034362793,
      "logits/rejected": -1.8588330745697021,
      "logps/chosen": -63.73344039916992,
      "logps/rejected": -187.13601684570312,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.48074644804000854,
      "rewards/margins": 7.959152698516846,
      "rewards/rejected": -7.4784064292907715,
      "step": 2660
    },
    {
      "epoch": 1.0644,
      "grad_norm": 0.5364122986793518,
      "learning_rate": 6.453333333333333e-07,
      "logits/chosen": -2.6620500087738037,
      "logits/rejected": -2.141587257385254,
      "logps/chosen": -114.98800659179688,
      "logps/rejected": -117.403564453125,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.052439115941524506,
      "rewards/margins": 6.055351257324219,
      "rewards/rejected": -6.107789993286133,
      "step": 2661
    },
    {
      "epoch": 1.0648,
      "grad_norm": 0.019242506474256516,
      "learning_rate": 6.452e-07,
      "logits/chosen": -2.7655131816864014,
      "logits/rejected": -2.134531259536743,
      "logps/chosen": -143.91885375976562,
      "logps/rejected": -180.6260528564453,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.33271104097366333,
      "rewards/margins": 9.360776901245117,
      "rewards/rejected": -9.693487167358398,
      "step": 2662
    },
    {
      "epoch": 1.0652,
      "grad_norm": 0.003125009825453162,
      "learning_rate": 6.450666666666667e-07,
      "logits/chosen": -2.9632151126861572,
      "logits/rejected": -2.467881441116333,
      "logps/chosen": -92.2813720703125,
      "logps/rejected": -253.49661254882812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9275975227355957,
      "rewards/margins": 12.262960433959961,
      "rewards/rejected": -10.335362434387207,
      "step": 2663
    },
    {
      "epoch": 1.0656,
      "grad_norm": 2.543767213821411,
      "learning_rate": 6.449333333333334e-07,
      "logits/chosen": -2.908973217010498,
      "logits/rejected": -2.3549087047576904,
      "logps/chosen": -112.30110168457031,
      "logps/rejected": -116.03948974609375,
      "loss": 0.0173,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6405968070030212,
      "rewards/margins": 5.0770487785339355,
      "rewards/rejected": -5.717645645141602,
      "step": 2664
    },
    {
      "epoch": 1.066,
      "grad_norm": 0.031389977782964706,
      "learning_rate": 6.448000000000001e-07,
      "logits/chosen": -3.090017795562744,
      "logits/rejected": -2.534919261932373,
      "logps/chosen": -95.34739685058594,
      "logps/rejected": -137.00938415527344,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31949615478515625,
      "rewards/margins": 8.35171127319336,
      "rewards/rejected": -8.032215118408203,
      "step": 2665
    },
    {
      "epoch": 1.0664,
      "grad_norm": 0.018647782504558563,
      "learning_rate": 6.446666666666666e-07,
      "logits/chosen": -2.5818700790405273,
      "logits/rejected": -1.5945255756378174,
      "logps/chosen": -144.29861450195312,
      "logps/rejected": -226.60177612304688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9879982471466064,
      "rewards/margins": 10.486202239990234,
      "rewards/rejected": -9.49820327758789,
      "step": 2666
    },
    {
      "epoch": 1.0668,
      "grad_norm": 0.35404452681541443,
      "learning_rate": 6.445333333333332e-07,
      "logits/chosen": -2.7075932025909424,
      "logits/rejected": -2.4812285900115967,
      "logps/chosen": -122.40003204345703,
      "logps/rejected": -127.32402038574219,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2472686767578125,
      "rewards/margins": 5.955717086791992,
      "rewards/rejected": -5.70844841003418,
      "step": 2667
    },
    {
      "epoch": 1.0672,
      "grad_norm": 0.46048420667648315,
      "learning_rate": 6.443999999999999e-07,
      "logits/chosen": -2.799015522003174,
      "logits/rejected": -2.450471878051758,
      "logps/chosen": -114.86121368408203,
      "logps/rejected": -118.34526062011719,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.49794843792915344,
      "rewards/margins": 6.323712348937988,
      "rewards/rejected": -5.825763702392578,
      "step": 2668
    },
    {
      "epoch": 1.0676,
      "grad_norm": 0.21443626284599304,
      "learning_rate": 6.442666666666666e-07,
      "logits/chosen": -3.0726394653320312,
      "logits/rejected": -2.4628524780273438,
      "logps/chosen": -71.71232604980469,
      "logps/rejected": -132.37779235839844,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020293429493904114,
      "rewards/margins": 7.2774271965026855,
      "rewards/rejected": -7.257133960723877,
      "step": 2669
    },
    {
      "epoch": 1.068,
      "grad_norm": 2.160428047180176,
      "learning_rate": 6.441333333333333e-07,
      "logits/chosen": -3.127511978149414,
      "logits/rejected": -2.8038992881774902,
      "logps/chosen": -69.05535888671875,
      "logps/rejected": -136.58082580566406,
      "loss": 0.0178,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.510723888874054,
      "rewards/margins": 7.519530296325684,
      "rewards/rejected": -8.030254364013672,
      "step": 2670
    },
    {
      "epoch": 1.0684,
      "grad_norm": 0.9366631507873535,
      "learning_rate": 6.44e-07,
      "logits/chosen": -3.2177834510803223,
      "logits/rejected": -2.548703670501709,
      "logps/chosen": -92.45166015625,
      "logps/rejected": -100.43692779541016,
      "loss": 0.0078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07369938492774963,
      "rewards/margins": 5.862005233764648,
      "rewards/rejected": -5.788305759429932,
      "step": 2671
    },
    {
      "epoch": 1.0688,
      "grad_norm": 0.0823802649974823,
      "learning_rate": 6.438666666666667e-07,
      "logits/chosen": -3.0319883823394775,
      "logits/rejected": -2.469330072402954,
      "logps/chosen": -84.76481628417969,
      "logps/rejected": -125.06475067138672,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4678688049316406,
      "rewards/margins": 8.601221084594727,
      "rewards/rejected": -8.133352279663086,
      "step": 2672
    },
    {
      "epoch": 1.0692,
      "grad_norm": 0.04303618147969246,
      "learning_rate": 6.437333333333334e-07,
      "logits/chosen": -3.110076904296875,
      "logits/rejected": -2.809621810913086,
      "logps/chosen": -136.723876953125,
      "logps/rejected": -178.1851806640625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.26166534423828125,
      "rewards/margins": 10.484978675842285,
      "rewards/rejected": -10.746644020080566,
      "step": 2673
    },
    {
      "epoch": 1.0695999999999999,
      "grad_norm": 0.37017878890037537,
      "learning_rate": 6.436e-07,
      "logits/chosen": -2.9583446979522705,
      "logits/rejected": -2.8017916679382324,
      "logps/chosen": -119.60601043701172,
      "logps/rejected": -109.46565246582031,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.42466244101524353,
      "rewards/margins": 6.105367660522461,
      "rewards/rejected": -6.530030250549316,
      "step": 2674
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.1642310470342636,
      "learning_rate": 6.434666666666666e-07,
      "logits/chosen": -2.887866973876953,
      "logits/rejected": -2.106605052947998,
      "logps/chosen": -72.23147583007812,
      "logps/rejected": -146.3130645751953,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7897176742553711,
      "rewards/margins": 9.113972663879395,
      "rewards/rejected": -8.324254989624023,
      "step": 2675
    },
    {
      "epoch": 1.0704,
      "grad_norm": 0.4863646626472473,
      "learning_rate": 6.433333333333332e-07,
      "logits/chosen": -2.949228048324585,
      "logits/rejected": -2.560124397277832,
      "logps/chosen": -97.57440948486328,
      "logps/rejected": -163.272705078125,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17312052845954895,
      "rewards/margins": 8.990826606750488,
      "rewards/rejected": -8.817706108093262,
      "step": 2676
    },
    {
      "epoch": 1.0708,
      "grad_norm": 1.3608720302581787,
      "learning_rate": 6.431999999999999e-07,
      "logits/chosen": -3.0170488357543945,
      "logits/rejected": -2.5992722511291504,
      "logps/chosen": -119.28334045410156,
      "logps/rejected": -99.63322448730469,
      "loss": 0.0128,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2816734313964844,
      "rewards/margins": 4.535183906555176,
      "rewards/rejected": -5.81685733795166,
      "step": 2677
    },
    {
      "epoch": 1.0712,
      "grad_norm": 0.01660901866853237,
      "learning_rate": 6.430666666666666e-07,
      "logits/chosen": -2.8492255210876465,
      "logits/rejected": -2.118264675140381,
      "logps/chosen": -102.52149963378906,
      "logps/rejected": -142.85916137695312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08637657761573792,
      "rewards/margins": 9.428718566894531,
      "rewards/rejected": -9.515094757080078,
      "step": 2678
    },
    {
      "epoch": 1.0716,
      "grad_norm": 0.3210712969303131,
      "learning_rate": 6.429333333333333e-07,
      "logits/chosen": -3.150120735168457,
      "logits/rejected": -2.7716593742370605,
      "logps/chosen": -84.60944366455078,
      "logps/rejected": -91.92498779296875,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.249418020248413,
      "rewards/margins": 6.097312927246094,
      "rewards/rejected": -4.84789514541626,
      "step": 2679
    },
    {
      "epoch": 1.072,
      "grad_norm": 0.22070114314556122,
      "learning_rate": 6.428e-07,
      "logits/chosen": -2.553938150405884,
      "logits/rejected": -1.95200514793396,
      "logps/chosen": -166.99221801757812,
      "logps/rejected": -153.9618377685547,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.28485107421875,
      "rewards/margins": 8.032829284667969,
      "rewards/rejected": -7.747979164123535,
      "step": 2680
    },
    {
      "epoch": 1.0724,
      "grad_norm": 0.920329749584198,
      "learning_rate": 6.426666666666667e-07,
      "logits/chosen": -2.8014392852783203,
      "logits/rejected": -2.0619125366210938,
      "logps/chosen": -62.919700622558594,
      "logps/rejected": -174.42996215820312,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.32017117738723755,
      "rewards/margins": 5.466648101806641,
      "rewards/rejected": -5.7868194580078125,
      "step": 2681
    },
    {
      "epoch": 1.0728,
      "grad_norm": 0.807403028011322,
      "learning_rate": 6.425333333333333e-07,
      "logits/chosen": -3.0718438625335693,
      "logits/rejected": -2.841555595397949,
      "logps/chosen": -70.82371520996094,
      "logps/rejected": -112.31892395019531,
      "loss": 0.0071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3686237335205078,
      "rewards/margins": 5.101607322692871,
      "rewards/rejected": -5.470231056213379,
      "step": 2682
    },
    {
      "epoch": 1.0732,
      "grad_norm": 0.7059917449951172,
      "learning_rate": 6.424e-07,
      "logits/chosen": -2.721607208251953,
      "logits/rejected": -2.2959964275360107,
      "logps/chosen": -65.65502166748047,
      "logps/rejected": -111.46479034423828,
      "loss": 0.007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3194376230239868,
      "rewards/margins": 5.581427574157715,
      "rewards/rejected": -5.90086555480957,
      "step": 2683
    },
    {
      "epoch": 1.0735999999999999,
      "grad_norm": 0.06694009900093079,
      "learning_rate": 6.422666666666667e-07,
      "logits/chosen": -2.8429508209228516,
      "logits/rejected": -2.248453378677368,
      "logps/chosen": -143.12301635742188,
      "logps/rejected": -147.29733276367188,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8763694763183594,
      "rewards/margins": 7.680129528045654,
      "rewards/rejected": -8.556499481201172,
      "step": 2684
    },
    {
      "epoch": 1.074,
      "grad_norm": 0.1813451200723648,
      "learning_rate": 6.421333333333333e-07,
      "logits/chosen": -2.983515739440918,
      "logits/rejected": -2.50565767288208,
      "logps/chosen": -127.27264404296875,
      "logps/rejected": -160.3243408203125,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.68105548620224,
      "rewards/margins": 6.755348205566406,
      "rewards/rejected": -7.436403274536133,
      "step": 2685
    },
    {
      "epoch": 1.0744,
      "grad_norm": 3.0875813961029053,
      "learning_rate": 6.42e-07,
      "logits/chosen": -2.775465965270996,
      "logits/rejected": -2.454094171524048,
      "logps/chosen": -112.87837219238281,
      "logps/rejected": -112.93022155761719,
      "loss": 0.0247,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7822262048721313,
      "rewards/margins": 6.104427337646484,
      "rewards/rejected": -6.886653423309326,
      "step": 2686
    },
    {
      "epoch": 1.0748,
      "grad_norm": 0.48696231842041016,
      "learning_rate": 6.418666666666666e-07,
      "logits/chosen": -2.8566672801971436,
      "logits/rejected": -2.5689735412597656,
      "logps/chosen": -116.00495910644531,
      "logps/rejected": -135.4150390625,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5444748401641846,
      "rewards/margins": 7.26420259475708,
      "rewards/rejected": -7.808677673339844,
      "step": 2687
    },
    {
      "epoch": 1.0752,
      "grad_norm": 1.0883817672729492,
      "learning_rate": 6.417333333333333e-07,
      "logits/chosen": -3.2121100425720215,
      "logits/rejected": -3.0639350414276123,
      "logps/chosen": -60.687679290771484,
      "logps/rejected": -98.32599639892578,
      "loss": 0.0095,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8533264398574829,
      "rewards/margins": 6.439157009124756,
      "rewards/rejected": -5.5858306884765625,
      "step": 2688
    },
    {
      "epoch": 1.0756000000000001,
      "grad_norm": 0.18153494596481323,
      "learning_rate": 6.415999999999999e-07,
      "logits/chosen": -2.691359043121338,
      "logits/rejected": -2.0804107189178467,
      "logps/chosen": -141.34054565429688,
      "logps/rejected": -135.14102172851562,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1125054359436035,
      "rewards/margins": 7.171630859375,
      "rewards/rejected": -8.284135818481445,
      "step": 2689
    },
    {
      "epoch": 1.076,
      "grad_norm": 1.465066909790039,
      "learning_rate": 6.414666666666666e-07,
      "logits/chosen": -3.0271239280700684,
      "logits/rejected": -2.9586801528930664,
      "logps/chosen": -79.12724304199219,
      "logps/rejected": -99.43942260742188,
      "loss": 0.0105,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1582658737897873,
      "rewards/margins": 4.900022506713867,
      "rewards/rejected": -4.741756439208984,
      "step": 2690
    },
    {
      "epoch": 1.0764,
      "grad_norm": 0.0581204816699028,
      "learning_rate": 6.413333333333333e-07,
      "logits/chosen": -2.819643974304199,
      "logits/rejected": -2.1610910892486572,
      "logps/chosen": -95.72532653808594,
      "logps/rejected": -160.5546417236328,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1950855255126953,
      "rewards/margins": 10.668217658996582,
      "rewards/rejected": -9.473132133483887,
      "step": 2691
    },
    {
      "epoch": 1.0768,
      "grad_norm": 0.8220977783203125,
      "learning_rate": 6.412e-07,
      "logits/chosen": -3.0024609565734863,
      "logits/rejected": -2.490199565887451,
      "logps/chosen": -60.733924865722656,
      "logps/rejected": -144.67953491210938,
      "loss": 0.0061,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.672619342803955,
      "rewards/margins": 8.897270202636719,
      "rewards/rejected": -7.224650859832764,
      "step": 2692
    },
    {
      "epoch": 1.0772,
      "grad_norm": 0.0367901548743248,
      "learning_rate": 6.410666666666667e-07,
      "logits/chosen": -2.7189688682556152,
      "logits/rejected": -2.275256872177124,
      "logps/chosen": -102.98641967773438,
      "logps/rejected": -144.25534057617188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8874042630195618,
      "rewards/margins": 8.536160469055176,
      "rewards/rejected": -7.64875602722168,
      "step": 2693
    },
    {
      "epoch": 1.0776,
      "grad_norm": 0.7342601418495178,
      "learning_rate": 6.409333333333333e-07,
      "logits/chosen": -2.9639954566955566,
      "logits/rejected": -2.686194896697998,
      "logps/chosen": -119.74376678466797,
      "logps/rejected": -122.01783752441406,
      "loss": 0.0057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5148155689239502,
      "rewards/margins": 8.289657592773438,
      "rewards/rejected": -7.774842262268066,
      "step": 2694
    },
    {
      "epoch": 1.078,
      "grad_norm": 8.174064636230469,
      "learning_rate": 6.408e-07,
      "logits/chosen": -3.072634220123291,
      "logits/rejected": -2.765900135040283,
      "logps/chosen": -162.23565673828125,
      "logps/rejected": -156.17674255371094,
      "loss": 0.0523,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.523436069488525,
      "rewards/margins": 3.9510653018951416,
      "rewards/rejected": -8.474501609802246,
      "step": 2695
    },
    {
      "epoch": 1.0784,
      "grad_norm": 0.10112141072750092,
      "learning_rate": 6.406666666666667e-07,
      "logits/chosen": -2.901308536529541,
      "logits/rejected": -2.1231799125671387,
      "logps/chosen": -75.21243286132812,
      "logps/rejected": -234.4527587890625,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7747360467910767,
      "rewards/margins": 8.741689682006836,
      "rewards/rejected": -7.966953754425049,
      "step": 2696
    },
    {
      "epoch": 1.0788,
      "grad_norm": 0.27578601241111755,
      "learning_rate": 6.405333333333332e-07,
      "logits/chosen": -3.058840751647949,
      "logits/rejected": -2.753835916519165,
      "logps/chosen": -67.41313171386719,
      "logps/rejected": -160.115234375,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.185052290558815,
      "rewards/margins": 8.816573143005371,
      "rewards/rejected": -8.631521224975586,
      "step": 2697
    },
    {
      "epoch": 1.0792,
      "grad_norm": 2.369171142578125,
      "learning_rate": 6.403999999999999e-07,
      "logits/chosen": -3.0875625610351562,
      "logits/rejected": -2.761059522628784,
      "logps/chosen": -139.29986572265625,
      "logps/rejected": -102.40028381347656,
      "loss": 0.017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5316773056983948,
      "rewards/margins": 4.898499011993408,
      "rewards/rejected": -5.430176258087158,
      "step": 2698
    },
    {
      "epoch": 1.0796000000000001,
      "grad_norm": 223.78579711914062,
      "learning_rate": 6.402666666666666e-07,
      "logits/chosen": -2.2977898120880127,
      "logits/rejected": -1.8394159078598022,
      "logps/chosen": -235.48516845703125,
      "logps/rejected": -211.72906494140625,
      "loss": 3.4715,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -5.799627780914307,
      "rewards/margins": 1.8334288597106934,
      "rewards/rejected": -7.633056640625,
      "step": 2699
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.07135888189077377,
      "learning_rate": 6.401333333333333e-07,
      "logits/chosen": -2.780141830444336,
      "logits/rejected": -1.8741583824157715,
      "logps/chosen": -77.4920654296875,
      "logps/rejected": -140.03225708007812,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20773354172706604,
      "rewards/margins": 8.68957233428955,
      "rewards/rejected": -8.481839179992676,
      "step": 2700
    },
    {
      "epoch": 1.0804,
      "grad_norm": 1.6390066146850586,
      "learning_rate": 6.4e-07,
      "logits/chosen": -2.541472911834717,
      "logits/rejected": -2.216261625289917,
      "logps/chosen": -235.88302612304688,
      "logps/rejected": -98.93916320800781,
      "loss": 0.0133,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1595494747161865,
      "rewards/margins": 4.3228631019592285,
      "rewards/rejected": -5.482412338256836,
      "step": 2701
    },
    {
      "epoch": 1.0808,
      "grad_norm": 6.749667644500732,
      "learning_rate": 6.398666666666667e-07,
      "logits/chosen": -2.8533577919006348,
      "logits/rejected": -2.773439645767212,
      "logps/chosen": -91.78887939453125,
      "logps/rejected": -85.77735900878906,
      "loss": 0.0499,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8434724807739258,
      "rewards/margins": 3.1664414405822754,
      "rewards/rejected": -4.009913921356201,
      "step": 2702
    },
    {
      "epoch": 1.0812,
      "grad_norm": 1.8013503551483154,
      "learning_rate": 6.397333333333334e-07,
      "logits/chosen": -2.481724262237549,
      "logits/rejected": -2.5578360557556152,
      "logps/chosen": -187.37351989746094,
      "logps/rejected": -122.87971496582031,
      "loss": 0.014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5361797213554382,
      "rewards/margins": 4.263157844543457,
      "rewards/rejected": -4.799337387084961,
      "step": 2703
    },
    {
      "epoch": 1.0816,
      "grad_norm": 1.0801430940628052,
      "learning_rate": 6.395999999999999e-07,
      "logits/chosen": -3.1111159324645996,
      "logits/rejected": -2.8325231075286865,
      "logps/chosen": -55.797210693359375,
      "logps/rejected": -104.2424545288086,
      "loss": 0.0092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7364017367362976,
      "rewards/margins": 7.603906154632568,
      "rewards/rejected": -6.867504596710205,
      "step": 2704
    },
    {
      "epoch": 1.082,
      "grad_norm": 0.11438218504190445,
      "learning_rate": 6.394666666666666e-07,
      "logits/chosen": -2.8024818897247314,
      "logits/rejected": -2.18471360206604,
      "logps/chosen": -105.56607055664062,
      "logps/rejected": -130.30906677246094,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7981777191162109,
      "rewards/margins": 8.349327087402344,
      "rewards/rejected": -7.551148891448975,
      "step": 2705
    },
    {
      "epoch": 1.0824,
      "grad_norm": 0.0030254912562668324,
      "learning_rate": 6.393333333333333e-07,
      "logits/chosen": -3.043105125427246,
      "logits/rejected": -1.9962434768676758,
      "logps/chosen": -84.71094512939453,
      "logps/rejected": -164.820068359375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9889011383056641,
      "rewards/margins": 11.199540138244629,
      "rewards/rejected": -10.210638999938965,
      "step": 2706
    },
    {
      "epoch": 1.0828,
      "grad_norm": 1.1551318168640137,
      "learning_rate": 6.392e-07,
      "logits/chosen": -2.9358468055725098,
      "logits/rejected": -2.7238974571228027,
      "logps/chosen": -99.41432189941406,
      "logps/rejected": -89.47793579101562,
      "loss": 0.0116,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1071979999542236,
      "rewards/margins": 4.452665328979492,
      "rewards/rejected": -5.559863090515137,
      "step": 2707
    },
    {
      "epoch": 1.0832,
      "grad_norm": 0.31171301007270813,
      "learning_rate": 6.390666666666666e-07,
      "logits/chosen": -2.6599531173706055,
      "logits/rejected": -2.3728525638580322,
      "logps/chosen": -105.1975326538086,
      "logps/rejected": -110.53460693359375,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3431595265865326,
      "rewards/margins": 6.924715995788574,
      "rewards/rejected": -6.58155632019043,
      "step": 2708
    },
    {
      "epoch": 1.0836,
      "grad_norm": 1.7841334342956543,
      "learning_rate": 6.389333333333333e-07,
      "logits/chosen": -2.9496917724609375,
      "logits/rejected": -2.8707308769226074,
      "logps/chosen": -68.93256378173828,
      "logps/rejected": -74.96058654785156,
      "loss": 0.0213,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14581450819969177,
      "rewards/margins": 4.535119533538818,
      "rewards/rejected": -4.389305114746094,
      "step": 2709
    },
    {
      "epoch": 1.084,
      "grad_norm": 0.012991220690310001,
      "learning_rate": 6.388e-07,
      "logits/chosen": -2.626030921936035,
      "logits/rejected": -2.1064047813415527,
      "logps/chosen": -54.76982879638672,
      "logps/rejected": -138.593017578125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.540156126022339,
      "rewards/margins": 10.006536483764648,
      "rewards/rejected": -7.4663801193237305,
      "step": 2710
    },
    {
      "epoch": 1.0844,
      "grad_norm": 0.6272297501564026,
      "learning_rate": 6.386666666666667e-07,
      "logits/chosen": -2.5704965591430664,
      "logits/rejected": -1.8800930976867676,
      "logps/chosen": -133.93447875976562,
      "logps/rejected": -146.22097778320312,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9239159226417542,
      "rewards/margins": 5.957376480102539,
      "rewards/rejected": -6.881292343139648,
      "step": 2711
    },
    {
      "epoch": 1.0848,
      "grad_norm": 0.007731258403509855,
      "learning_rate": 6.385333333333333e-07,
      "logits/chosen": -2.7562155723571777,
      "logits/rejected": -2.290811777114868,
      "logps/chosen": -98.33903503417969,
      "logps/rejected": -258.38671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.061627984046936035,
      "rewards/margins": 11.507634162902832,
      "rewards/rejected": -11.446006774902344,
      "step": 2712
    },
    {
      "epoch": 1.0852,
      "grad_norm": 0.002618069527670741,
      "learning_rate": 6.383999999999999e-07,
      "logits/chosen": -2.3969790935516357,
      "logits/rejected": -1.9992494583129883,
      "logps/chosen": -81.49822235107422,
      "logps/rejected": -228.19784545898438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5632126331329346,
      "rewards/margins": 11.914615631103516,
      "rewards/rejected": -12.477828025817871,
      "step": 2713
    },
    {
      "epoch": 1.0856,
      "grad_norm": 0.6466229557991028,
      "learning_rate": 6.382666666666666e-07,
      "logits/chosen": -2.4484429359436035,
      "logits/rejected": -1.9990153312683105,
      "logps/chosen": -160.4413604736328,
      "logps/rejected": -126.97752380371094,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2688239812850952,
      "rewards/margins": 6.096386909484863,
      "rewards/rejected": -5.8275628089904785,
      "step": 2714
    },
    {
      "epoch": 1.086,
      "grad_norm": 0.2877533733844757,
      "learning_rate": 6.381333333333333e-07,
      "logits/chosen": -2.5561118125915527,
      "logits/rejected": -2.5156729221343994,
      "logps/chosen": -225.7303009033203,
      "logps/rejected": -164.51821899414062,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.302896499633789,
      "rewards/margins": 6.847641944885254,
      "rewards/rejected": -8.150538444519043,
      "step": 2715
    },
    {
      "epoch": 1.0864,
      "grad_norm": 0.10201314091682434,
      "learning_rate": 6.38e-07,
      "logits/chosen": -2.8717143535614014,
      "logits/rejected": -2.494959831237793,
      "logps/chosen": -72.3442611694336,
      "logps/rejected": -259.9164123535156,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.141060709953308,
      "rewards/margins": 8.237466812133789,
      "rewards/rejected": -7.096405982971191,
      "step": 2716
    },
    {
      "epoch": 1.0868,
      "grad_norm": 0.2602132558822632,
      "learning_rate": 6.378666666666667e-07,
      "logits/chosen": -2.8482046127319336,
      "logits/rejected": -2.421168804168701,
      "logps/chosen": -81.41957092285156,
      "logps/rejected": -125.56764221191406,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9428787231445312,
      "rewards/margins": 6.692783355712891,
      "rewards/rejected": -5.749904632568359,
      "step": 2717
    },
    {
      "epoch": 1.0872,
      "grad_norm": 5.262721538543701,
      "learning_rate": 6.377333333333334e-07,
      "logits/chosen": -2.931701421737671,
      "logits/rejected": -2.4828038215637207,
      "logps/chosen": -70.41703796386719,
      "logps/rejected": -111.6122817993164,
      "loss": 0.0454,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6680893301963806,
      "rewards/margins": 4.997273921966553,
      "rewards/rejected": -5.665363311767578,
      "step": 2718
    },
    {
      "epoch": 1.0876,
      "grad_norm": 0.8709376454353333,
      "learning_rate": 6.375999999999999e-07,
      "logits/chosen": -3.0125465393066406,
      "logits/rejected": -2.584444046020508,
      "logps/chosen": -73.51309967041016,
      "logps/rejected": -95.85000610351562,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27305373549461365,
      "rewards/margins": 5.9789018630981445,
      "rewards/rejected": -5.705848217010498,
      "step": 2719
    },
    {
      "epoch": 1.088,
      "grad_norm": 0.02761230804026127,
      "learning_rate": 6.374666666666666e-07,
      "logits/chosen": -2.8133153915405273,
      "logits/rejected": -2.009793996810913,
      "logps/chosen": -80.61095428466797,
      "logps/rejected": -122.57261657714844,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.746577501296997,
      "rewards/margins": 8.799356460571289,
      "rewards/rejected": -7.052779197692871,
      "step": 2720
    },
    {
      "epoch": 1.0884,
      "grad_norm": 0.1524147391319275,
      "learning_rate": 6.373333333333333e-07,
      "logits/chosen": -3.242713451385498,
      "logits/rejected": -2.786207914352417,
      "logps/chosen": -74.92088317871094,
      "logps/rejected": -148.39112854003906,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22902491688728333,
      "rewards/margins": 7.636105537414551,
      "rewards/rejected": -7.40708065032959,
      "step": 2721
    },
    {
      "epoch": 1.0888,
      "grad_norm": 0.20167438685894012,
      "learning_rate": 6.371999999999999e-07,
      "logits/chosen": -2.7015671730041504,
      "logits/rejected": -1.8900151252746582,
      "logps/chosen": -100.91925048828125,
      "logps/rejected": -146.4304656982422,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.951658308506012,
      "rewards/margins": 10.210893630981445,
      "rewards/rejected": -9.259235382080078,
      "step": 2722
    },
    {
      "epoch": 1.0892,
      "grad_norm": 0.20393472909927368,
      "learning_rate": 6.370666666666666e-07,
      "logits/chosen": -3.2070016860961914,
      "logits/rejected": -2.8370556831359863,
      "logps/chosen": -114.60714721679688,
      "logps/rejected": -141.59222412109375,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0513836145401,
      "rewards/margins": 7.7149152755737305,
      "rewards/rejected": -6.663531303405762,
      "step": 2723
    },
    {
      "epoch": 1.0896,
      "grad_norm": 55.586360931396484,
      "learning_rate": 6.369333333333333e-07,
      "logits/chosen": -2.5108344554901123,
      "logits/rejected": -2.245375633239746,
      "logps/chosen": -212.15260314941406,
      "logps/rejected": -197.17405700683594,
      "loss": 0.2496,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.4838037490844727,
      "rewards/margins": 5.098608016967773,
      "rewards/rejected": -8.582411766052246,
      "step": 2724
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.13565705716609955,
      "learning_rate": 6.368e-07,
      "logits/chosen": -3.3148419857025146,
      "logits/rejected": -2.4535160064697266,
      "logps/chosen": -74.46908569335938,
      "logps/rejected": -147.15086364746094,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5552652478218079,
      "rewards/margins": 8.416155815124512,
      "rewards/rejected": -7.860890865325928,
      "step": 2725
    },
    {
      "epoch": 1.0904,
      "grad_norm": 2.2555012702941895,
      "learning_rate": 6.366666666666667e-07,
      "logits/chosen": -2.904204845428467,
      "logits/rejected": -2.7932932376861572,
      "logps/chosen": -80.83149719238281,
      "logps/rejected": -78.94248962402344,
      "loss": 0.0271,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13716010749340057,
      "rewards/margins": 3.959573984146118,
      "rewards/rejected": -3.822413921356201,
      "step": 2726
    },
    {
      "epoch": 1.0908,
      "grad_norm": 0.34129828214645386,
      "learning_rate": 6.365333333333333e-07,
      "logits/chosen": -2.488569974899292,
      "logits/rejected": -1.841016173362732,
      "logps/chosen": -169.06739807128906,
      "logps/rejected": -190.35069274902344,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.1485061645507812,
      "rewards/margins": 7.933438301086426,
      "rewards/rejected": -10.08194351196289,
      "step": 2727
    },
    {
      "epoch": 1.0912,
      "grad_norm": 61.953983306884766,
      "learning_rate": 6.364e-07,
      "logits/chosen": -3.1015071868896484,
      "logits/rejected": -3.0787553787231445,
      "logps/chosen": -183.97903442382812,
      "logps/rejected": -102.33514404296875,
      "loss": 0.2972,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.9443559646606445,
      "rewards/margins": 2.0136313438415527,
      "rewards/rejected": -5.957987308502197,
      "step": 2728
    },
    {
      "epoch": 1.0916,
      "grad_norm": 3.5244569778442383,
      "learning_rate": 6.362666666666666e-07,
      "logits/chosen": -3.001209020614624,
      "logits/rejected": -2.8560595512390137,
      "logps/chosen": -104.0746841430664,
      "logps/rejected": -68.29443359375,
      "loss": 0.0249,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24494916200637817,
      "rewards/margins": 3.9581997394561768,
      "rewards/rejected": -3.7132503986358643,
      "step": 2729
    },
    {
      "epoch": 1.092,
      "grad_norm": 0.31456348299980164,
      "learning_rate": 6.361333333333333e-07,
      "logits/chosen": -2.7781546115875244,
      "logits/rejected": -2.2911016941070557,
      "logps/chosen": -128.19715881347656,
      "logps/rejected": -136.7157745361328,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.203137993812561,
      "rewards/margins": 6.780389785766602,
      "rewards/rejected": -7.983528137207031,
      "step": 2730
    },
    {
      "epoch": 1.0924,
      "grad_norm": 0.04934150353074074,
      "learning_rate": 6.36e-07,
      "logits/chosen": -3.231046676635742,
      "logits/rejected": -2.592592239379883,
      "logps/chosen": -56.065452575683594,
      "logps/rejected": -115.33497619628906,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6647729873657227,
      "rewards/margins": 8.206438064575195,
      "rewards/rejected": -7.541666030883789,
      "step": 2731
    },
    {
      "epoch": 1.0928,
      "grad_norm": 0.10715302079916,
      "learning_rate": 6.358666666666666e-07,
      "logits/chosen": -2.7945544719696045,
      "logits/rejected": -2.095360040664673,
      "logps/chosen": -153.89234924316406,
      "logps/rejected": -173.05726623535156,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7021713256835938,
      "rewards/margins": 10.619694709777832,
      "rewards/rejected": -9.917523384094238,
      "step": 2732
    },
    {
      "epoch": 1.0932,
      "grad_norm": 0.007314423564821482,
      "learning_rate": 6.357333333333333e-07,
      "logits/chosen": -2.733098268508911,
      "logits/rejected": -2.1998770236968994,
      "logps/chosen": -160.56158447265625,
      "logps/rejected": -174.23922729492188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6093250513076782,
      "rewards/margins": 10.310346603393555,
      "rewards/rejected": -9.701021194458008,
      "step": 2733
    },
    {
      "epoch": 1.0936,
      "grad_norm": 0.049773093312978745,
      "learning_rate": 6.356e-07,
      "logits/chosen": -2.9863903522491455,
      "logits/rejected": -2.39107084274292,
      "logps/chosen": -105.72917175292969,
      "logps/rejected": -145.670654296875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.26692312955856323,
      "rewards/margins": 8.578691482543945,
      "rewards/rejected": -8.84561538696289,
      "step": 2734
    },
    {
      "epoch": 1.094,
      "grad_norm": 0.35399720072746277,
      "learning_rate": 6.354666666666666e-07,
      "logits/chosen": -2.7379424571990967,
      "logits/rejected": -2.260812759399414,
      "logps/chosen": -157.38668823242188,
      "logps/rejected": -125.8495101928711,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4694393575191498,
      "rewards/margins": 6.853391647338867,
      "rewards/rejected": -7.322831153869629,
      "step": 2735
    },
    {
      "epoch": 1.0944,
      "grad_norm": 5.259395599365234,
      "learning_rate": 6.353333333333333e-07,
      "logits/chosen": -2.5392370223999023,
      "logits/rejected": -2.211275339126587,
      "logps/chosen": -73.71420288085938,
      "logps/rejected": -102.60623168945312,
      "loss": 0.0776,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5958340167999268,
      "rewards/margins": 7.137637615203857,
      "rewards/rejected": -5.541803359985352,
      "step": 2736
    },
    {
      "epoch": 1.0948,
      "grad_norm": 1.2256593704223633,
      "learning_rate": 6.352e-07,
      "logits/chosen": -2.687925338745117,
      "logits/rejected": -2.3082685470581055,
      "logps/chosen": -213.91854858398438,
      "logps/rejected": -186.45921325683594,
      "loss": 0.0074,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.644767165184021,
      "rewards/margins": 6.853288650512695,
      "rewards/rejected": -8.498056411743164,
      "step": 2737
    },
    {
      "epoch": 1.0952,
      "grad_norm": 0.6730408668518066,
      "learning_rate": 6.350666666666667e-07,
      "logits/chosen": -3.1141860485076904,
      "logits/rejected": -2.5632715225219727,
      "logps/chosen": -78.98002624511719,
      "logps/rejected": -142.57095336914062,
      "loss": 0.0048,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1602363884449005,
      "rewards/margins": 8.17236328125,
      "rewards/rejected": -8.332599639892578,
      "step": 2738
    },
    {
      "epoch": 1.0956,
      "grad_norm": 2.9048969745635986,
      "learning_rate": 6.349333333333334e-07,
      "logits/chosen": -2.9416491985321045,
      "logits/rejected": -2.374556064605713,
      "logps/chosen": -100.13292694091797,
      "logps/rejected": -132.41815185546875,
      "loss": 0.0339,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7462805509567261,
      "rewards/margins": 7.0375776290893555,
      "rewards/rejected": -6.29129695892334,
      "step": 2739
    },
    {
      "epoch": 1.096,
      "grad_norm": 0.022886987775564194,
      "learning_rate": 6.348e-07,
      "logits/chosen": -2.9901905059814453,
      "logits/rejected": -2.7887182235717773,
      "logps/chosen": -62.781089782714844,
      "logps/rejected": -176.37478637695312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0319918394088745,
      "rewards/margins": 11.261330604553223,
      "rewards/rejected": -10.229339599609375,
      "step": 2740
    },
    {
      "epoch": 1.0964,
      "grad_norm": 4.190915584564209,
      "learning_rate": 6.346666666666666e-07,
      "logits/chosen": -2.796820640563965,
      "logits/rejected": -2.4471492767333984,
      "logps/chosen": -164.28106689453125,
      "logps/rejected": -116.58743286132812,
      "loss": 0.0333,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.660881996154785,
      "rewards/margins": 3.6269989013671875,
      "rewards/rejected": -6.287880897521973,
      "step": 2741
    },
    {
      "epoch": 1.0968,
      "grad_norm": 0.034779880195856094,
      "learning_rate": 6.345333333333332e-07,
      "logits/chosen": -2.5304088592529297,
      "logits/rejected": -1.8731813430786133,
      "logps/chosen": -107.81735229492188,
      "logps/rejected": -158.82546997070312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.294010877609253,
      "rewards/margins": 10.124431610107422,
      "rewards/rejected": -8.83042049407959,
      "step": 2742
    },
    {
      "epoch": 1.0972,
      "grad_norm": 1.5661189556121826,
      "learning_rate": 6.343999999999999e-07,
      "logits/chosen": -3.1181864738464355,
      "logits/rejected": -2.912830114364624,
      "logps/chosen": -69.56454467773438,
      "logps/rejected": -69.295654296875,
      "loss": 0.0168,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1890113353729248,
      "rewards/margins": 4.855002403259277,
      "rewards/rejected": -3.6659908294677734,
      "step": 2743
    },
    {
      "epoch": 1.0976,
      "grad_norm": 1.3534750938415527,
      "learning_rate": 6.342666666666666e-07,
      "logits/chosen": -3.1671335697174072,
      "logits/rejected": -2.9627327919006348,
      "logps/chosen": -54.13108825683594,
      "logps/rejected": -74.89768981933594,
      "loss": 0.0104,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.011683657765388489,
      "rewards/margins": 4.8935651779174805,
      "rewards/rejected": -4.8818817138671875,
      "step": 2744
    },
    {
      "epoch": 1.098,
      "grad_norm": 0.10061044245958328,
      "learning_rate": 6.341333333333333e-07,
      "logits/chosen": -2.8734729290008545,
      "logits/rejected": -2.4583330154418945,
      "logps/chosen": -112.05048370361328,
      "logps/rejected": -143.13177490234375,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4804569482803345,
      "rewards/margins": 7.779752731323242,
      "rewards/rejected": -8.260210037231445,
      "step": 2745
    },
    {
      "epoch": 1.0984,
      "grad_norm": 0.43282550573349,
      "learning_rate": 6.34e-07,
      "logits/chosen": -2.951834201812744,
      "logits/rejected": -2.5105180740356445,
      "logps/chosen": -56.629295349121094,
      "logps/rejected": -191.92428588867188,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7353113889694214,
      "rewards/margins": 9.112420082092285,
      "rewards/rejected": -8.37710952758789,
      "step": 2746
    },
    {
      "epoch": 1.0988,
      "grad_norm": 0.9681830406188965,
      "learning_rate": 6.338666666666667e-07,
      "logits/chosen": -2.992410182952881,
      "logits/rejected": -2.6396021842956543,
      "logps/chosen": -172.3373565673828,
      "logps/rejected": -148.2478790283203,
      "loss": 0.0055,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0330287218093872,
      "rewards/margins": 5.658159255981445,
      "rewards/rejected": -6.691187858581543,
      "step": 2747
    },
    {
      "epoch": 1.0992,
      "grad_norm": 0.01077527366578579,
      "learning_rate": 6.337333333333334e-07,
      "logits/chosen": -3.1250391006469727,
      "logits/rejected": -2.6475882530212402,
      "logps/chosen": -72.59588623046875,
      "logps/rejected": -147.1903076171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2990387678146362,
      "rewards/margins": 10.51616096496582,
      "rewards/rejected": -9.217122077941895,
      "step": 2748
    },
    {
      "epoch": 1.0996,
      "grad_norm": 0.3951965272426605,
      "learning_rate": 6.336000000000001e-07,
      "logits/chosen": -2.748436450958252,
      "logits/rejected": -2.4243240356445312,
      "logps/chosen": -112.58470916748047,
      "logps/rejected": -130.81649780273438,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3357732892036438,
      "rewards/margins": 7.445499420166016,
      "rewards/rejected": -7.7812724113464355,
      "step": 2749
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.9182719588279724,
      "learning_rate": 6.334666666666665e-07,
      "logits/chosen": -2.8242273330688477,
      "logits/rejected": -2.092015504837036,
      "logps/chosen": -113.64783477783203,
      "logps/rejected": -169.176513671875,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0151073932647705,
      "rewards/margins": 5.780145645141602,
      "rewards/rejected": -6.795252799987793,
      "step": 2750
    },
    {
      "epoch": 1.1004,
      "grad_norm": 6.471296310424805,
      "learning_rate": 6.333333333333332e-07,
      "logits/chosen": -2.854799747467041,
      "logits/rejected": -2.9082655906677246,
      "logps/chosen": -115.02168273925781,
      "logps/rejected": -80.47824096679688,
      "loss": 0.0835,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0403661727905273,
      "rewards/margins": 2.6704440116882324,
      "rewards/rejected": -4.71081018447876,
      "step": 2751
    },
    {
      "epoch": 1.1008,
      "grad_norm": 2.669677734375,
      "learning_rate": 6.331999999999999e-07,
      "logits/chosen": -2.958550214767456,
      "logits/rejected": -2.8469290733337402,
      "logps/chosen": -71.85005950927734,
      "logps/rejected": -80.19390106201172,
      "loss": 0.0397,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.905947744846344,
      "rewards/margins": 3.358062267303467,
      "rewards/rejected": -4.264009952545166,
      "step": 2752
    },
    {
      "epoch": 1.1012,
      "grad_norm": 0.5342466235160828,
      "learning_rate": 6.330666666666666e-07,
      "logits/chosen": -3.253126621246338,
      "logits/rejected": -2.9962942600250244,
      "logps/chosen": -61.21071243286133,
      "logps/rejected": -103.46549987792969,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8315876126289368,
      "rewards/margins": 7.057458877563477,
      "rewards/rejected": -6.225871562957764,
      "step": 2753
    },
    {
      "epoch": 1.1016,
      "grad_norm": 0.2832894027233124,
      "learning_rate": 6.329333333333333e-07,
      "logits/chosen": -2.6555213928222656,
      "logits/rejected": -1.8345472812652588,
      "logps/chosen": -201.32659912109375,
      "logps/rejected": -180.30398559570312,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8120087385177612,
      "rewards/margins": 6.16257381439209,
      "rewards/rejected": -7.974582672119141,
      "step": 2754
    },
    {
      "epoch": 1.102,
      "grad_norm": 0.003977036569267511,
      "learning_rate": 6.328e-07,
      "logits/chosen": -2.417102813720703,
      "logits/rejected": -1.52833092212677,
      "logps/chosen": -127.17037963867188,
      "logps/rejected": -192.81854248046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.21733969449996948,
      "rewards/margins": 11.29963493347168,
      "rewards/rejected": -11.516974449157715,
      "step": 2755
    },
    {
      "epoch": 1.1024,
      "grad_norm": 0.16712412238121033,
      "learning_rate": 6.326666666666667e-07,
      "logits/chosen": -2.669447422027588,
      "logits/rejected": -2.227663993835449,
      "logps/chosen": -111.58938598632812,
      "logps/rejected": -161.6558380126953,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3863983154296875,
      "rewards/margins": 9.416869163513184,
      "rewards/rejected": -10.803267478942871,
      "step": 2756
    },
    {
      "epoch": 1.1028,
      "grad_norm": 0.014716566540300846,
      "learning_rate": 6.325333333333333e-07,
      "logits/chosen": -2.784119129180908,
      "logits/rejected": -2.1191201210021973,
      "logps/chosen": -126.00096130371094,
      "logps/rejected": -166.46961975097656,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8575004935264587,
      "rewards/margins": 9.873335838317871,
      "rewards/rejected": -9.01583480834961,
      "step": 2757
    },
    {
      "epoch": 1.1032,
      "grad_norm": 0.002277946099638939,
      "learning_rate": 6.324e-07,
      "logits/chosen": -3.117844581604004,
      "logits/rejected": -2.54603910446167,
      "logps/chosen": -78.42755126953125,
      "logps/rejected": -180.65460205078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1628624051809311,
      "rewards/margins": 11.477724075317383,
      "rewards/rejected": -11.640585899353027,
      "step": 2758
    },
    {
      "epoch": 1.1036,
      "grad_norm": 0.020676400512456894,
      "learning_rate": 6.322666666666667e-07,
      "logits/chosen": -2.955955982208252,
      "logits/rejected": -2.266808271408081,
      "logps/chosen": -109.50102233886719,
      "logps/rejected": -155.6034393310547,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6101746559143066,
      "rewards/margins": 9.941085815429688,
      "rewards/rejected": -8.330910682678223,
      "step": 2759
    },
    {
      "epoch": 1.104,
      "grad_norm": 0.11592905968427658,
      "learning_rate": 6.321333333333332e-07,
      "logits/chosen": -3.1500766277313232,
      "logits/rejected": -2.8488593101501465,
      "logps/chosen": -43.68876647949219,
      "logps/rejected": -110.60157775878906,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4158340394496918,
      "rewards/margins": 7.027801513671875,
      "rewards/rejected": -6.611967086791992,
      "step": 2760
    },
    {
      "epoch": 1.1044,
      "grad_norm": 5.713132858276367,
      "learning_rate": 6.319999999999999e-07,
      "logits/chosen": -2.788318634033203,
      "logits/rejected": -2.391345977783203,
      "logps/chosen": -153.61082458496094,
      "logps/rejected": -115.94868469238281,
      "loss": 0.0537,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.3082141876220703,
      "rewards/margins": 4.303060531616211,
      "rewards/rejected": -6.611274719238281,
      "step": 2761
    },
    {
      "epoch": 1.1048,
      "grad_norm": 3.673642635345459,
      "learning_rate": 6.318666666666666e-07,
      "logits/chosen": -2.90993595123291,
      "logits/rejected": -2.7855381965637207,
      "logps/chosen": -101.10264587402344,
      "logps/rejected": -88.28394317626953,
      "loss": 0.0316,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.415060043334961,
      "rewards/margins": 3.7005865573883057,
      "rewards/rejected": -5.1156463623046875,
      "step": 2762
    },
    {
      "epoch": 1.1052,
      "grad_norm": 0.018854113295674324,
      "learning_rate": 6.317333333333333e-07,
      "logits/chosen": -2.6940855979919434,
      "logits/rejected": -2.2433388233184814,
      "logps/chosen": -117.4647445678711,
      "logps/rejected": -213.035400390625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.921515703201294,
      "rewards/margins": 9.236111640930176,
      "rewards/rejected": -8.314596176147461,
      "step": 2763
    },
    {
      "epoch": 1.1056,
      "grad_norm": 0.011909750290215015,
      "learning_rate": 6.316e-07,
      "logits/chosen": -2.751410484313965,
      "logits/rejected": -2.2017998695373535,
      "logps/chosen": -72.37044525146484,
      "logps/rejected": -206.75894165039062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3350120782852173,
      "rewards/margins": 11.421489715576172,
      "rewards/rejected": -10.086477279663086,
      "step": 2764
    },
    {
      "epoch": 1.106,
      "grad_norm": 0.5590713024139404,
      "learning_rate": 6.314666666666666e-07,
      "logits/chosen": -2.7444069385528564,
      "logits/rejected": -2.6237874031066895,
      "logps/chosen": -166.56549072265625,
      "logps/rejected": -132.38223266601562,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2850854396820068,
      "rewards/margins": 5.774476051330566,
      "rewards/rejected": -7.059561729431152,
      "step": 2765
    },
    {
      "epoch": 1.1064,
      "grad_norm": 0.04193877428770065,
      "learning_rate": 6.313333333333333e-07,
      "logits/chosen": -2.869379997253418,
      "logits/rejected": -2.1152377128601074,
      "logps/chosen": -125.4527587890625,
      "logps/rejected": -266.70672607421875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0581936836242676,
      "rewards/margins": 10.577901840209961,
      "rewards/rejected": -11.63609504699707,
      "step": 2766
    },
    {
      "epoch": 1.1068,
      "grad_norm": 8.702080726623535,
      "learning_rate": 6.312e-07,
      "logits/chosen": -2.5840654373168945,
      "logits/rejected": -2.3571083545684814,
      "logps/chosen": -153.2828369140625,
      "logps/rejected": -135.276123046875,
      "loss": 0.0563,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9329009652137756,
      "rewards/margins": 5.321307182312012,
      "rewards/rejected": -6.254208564758301,
      "step": 2767
    },
    {
      "epoch": 1.1072,
      "grad_norm": 0.4359045922756195,
      "learning_rate": 6.310666666666667e-07,
      "logits/chosen": -2.963278293609619,
      "logits/rejected": -2.1885690689086914,
      "logps/chosen": -78.83055877685547,
      "logps/rejected": -124.28372955322266,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2533470392227173,
      "rewards/margins": 7.366082191467285,
      "rewards/rejected": -6.112735271453857,
      "step": 2768
    },
    {
      "epoch": 1.1076,
      "grad_norm": 1.858075737953186,
      "learning_rate": 6.309333333333333e-07,
      "logits/chosen": -3.1215100288391113,
      "logits/rejected": -2.9956462383270264,
      "logps/chosen": -83.60452270507812,
      "logps/rejected": -92.7543716430664,
      "loss": 0.0139,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6589046716690063,
      "rewards/margins": 4.270664215087891,
      "rewards/rejected": -4.929568767547607,
      "step": 2769
    },
    {
      "epoch": 1.108,
      "grad_norm": 1.1971362829208374,
      "learning_rate": 6.308e-07,
      "logits/chosen": -2.789207696914673,
      "logits/rejected": -2.648059606552124,
      "logps/chosen": -121.13887023925781,
      "logps/rejected": -142.78126525878906,
      "loss": 0.0094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8559118509292603,
      "rewards/margins": 6.526615619659424,
      "rewards/rejected": -8.382527351379395,
      "step": 2770
    },
    {
      "epoch": 1.1084,
      "grad_norm": 0.21002261340618134,
      "learning_rate": 6.306666666666666e-07,
      "logits/chosen": -2.651747941970825,
      "logits/rejected": -2.7247490882873535,
      "logps/chosen": -91.6817855834961,
      "logps/rejected": -110.19752502441406,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7490932941436768,
      "rewards/margins": 6.666695594787598,
      "rewards/rejected": -5.917602062225342,
      "step": 2771
    },
    {
      "epoch": 1.1088,
      "grad_norm": 0.04130325838923454,
      "learning_rate": 6.305333333333332e-07,
      "logits/chosen": -2.7343239784240723,
      "logits/rejected": -2.234739303588867,
      "logps/chosen": -121.57039642333984,
      "logps/rejected": -173.24456787109375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.038703203201294,
      "rewards/margins": 9.564534187316895,
      "rewards/rejected": -10.60323715209961,
      "step": 2772
    },
    {
      "epoch": 1.1092,
      "grad_norm": 0.27557098865509033,
      "learning_rate": 6.303999999999999e-07,
      "logits/chosen": -3.149724006652832,
      "logits/rejected": -2.6097350120544434,
      "logps/chosen": -67.66937255859375,
      "logps/rejected": -118.34478759765625,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6960300207138062,
      "rewards/margins": 6.944141387939453,
      "rewards/rejected": -6.248110771179199,
      "step": 2773
    },
    {
      "epoch": 1.1096,
      "grad_norm": 0.05866716057062149,
      "learning_rate": 6.302666666666666e-07,
      "logits/chosen": -2.9084136486053467,
      "logits/rejected": -2.3211050033569336,
      "logps/chosen": -103.10466003417969,
      "logps/rejected": -147.0640411376953,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5735205411911011,
      "rewards/margins": 7.99073600769043,
      "rewards/rejected": -7.417215347290039,
      "step": 2774
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.2994784712791443,
      "learning_rate": 6.301333333333333e-07,
      "logits/chosen": -2.9894375801086426,
      "logits/rejected": -2.782766819000244,
      "logps/chosen": -49.82634735107422,
      "logps/rejected": -127.3183364868164,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8176863789558411,
      "rewards/margins": 6.173805236816406,
      "rewards/rejected": -6.991491794586182,
      "step": 2775
    },
    {
      "epoch": 1.1104,
      "grad_norm": 0.04316217824816704,
      "learning_rate": 6.3e-07,
      "logits/chosen": -3.0043787956237793,
      "logits/rejected": -2.2239551544189453,
      "logps/chosen": -89.10523223876953,
      "logps/rejected": -146.66488647460938,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7847335934638977,
      "rewards/margins": 8.248889923095703,
      "rewards/rejected": -7.464156150817871,
      "step": 2776
    },
    {
      "epoch": 1.1108,
      "grad_norm": 0.008122631348669529,
      "learning_rate": 6.298666666666667e-07,
      "logits/chosen": -2.6368837356567383,
      "logits/rejected": -1.6501307487487793,
      "logps/chosen": -146.794677734375,
      "logps/rejected": -171.4517364501953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34837108850479126,
      "rewards/margins": 10.103370666503906,
      "rewards/rejected": -9.754999160766602,
      "step": 2777
    },
    {
      "epoch": 1.1112,
      "grad_norm": 1.4301925897598267,
      "learning_rate": 6.297333333333334e-07,
      "logits/chosen": -2.855917453765869,
      "logits/rejected": -2.4119577407836914,
      "logps/chosen": -93.15690612792969,
      "logps/rejected": -143.6094970703125,
      "loss": 0.0089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8954188823699951,
      "rewards/margins": 7.2317986488342285,
      "rewards/rejected": -8.127218246459961,
      "step": 2778
    },
    {
      "epoch": 1.1116,
      "grad_norm": 0.00444252323359251,
      "learning_rate": 6.296e-07,
      "logits/chosen": -2.614290714263916,
      "logits/rejected": -1.4569151401519775,
      "logps/chosen": -106.75492095947266,
      "logps/rejected": -160.05902099609375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.577493667602539,
      "rewards/margins": 11.4014892578125,
      "rewards/rejected": -8.823995590209961,
      "step": 2779
    },
    {
      "epoch": 1.112,
      "grad_norm": 0.6206770539283752,
      "learning_rate": 6.294666666666666e-07,
      "logits/chosen": -2.8373351097106934,
      "logits/rejected": -2.2275936603546143,
      "logps/chosen": -76.90966796875,
      "logps/rejected": -133.66143798828125,
      "loss": 0.0056,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6997547149658203,
      "rewards/margins": 9.683452606201172,
      "rewards/rejected": -8.983697891235352,
      "step": 2780
    },
    {
      "epoch": 1.1124,
      "grad_norm": 0.052030399441719055,
      "learning_rate": 6.293333333333333e-07,
      "logits/chosen": -2.668168067932129,
      "logits/rejected": -1.6413767337799072,
      "logps/chosen": -137.2804718017578,
      "logps/rejected": -175.28921508789062,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7138668298721313,
      "rewards/margins": 10.927665710449219,
      "rewards/rejected": -10.213799476623535,
      "step": 2781
    },
    {
      "epoch": 1.1128,
      "grad_norm": 0.0021791746839880943,
      "learning_rate": 6.291999999999999e-07,
      "logits/chosen": -2.612274646759033,
      "logits/rejected": -1.5139679908752441,
      "logps/chosen": -127.34754943847656,
      "logps/rejected": -159.73866271972656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2125751972198486,
      "rewards/margins": 11.690739631652832,
      "rewards/rejected": -9.478164672851562,
      "step": 2782
    },
    {
      "epoch": 1.1132,
      "grad_norm": 0.09679144620895386,
      "learning_rate": 6.290666666666666e-07,
      "logits/chosen": -2.56441593170166,
      "logits/rejected": -2.3184924125671387,
      "logps/chosen": -62.86508560180664,
      "logps/rejected": -178.56497192382812,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5366573333740234,
      "rewards/margins": 11.823372840881348,
      "rewards/rejected": -11.286715507507324,
      "step": 2783
    },
    {
      "epoch": 1.1136,
      "grad_norm": 0.28026798367500305,
      "learning_rate": 6.289333333333333e-07,
      "logits/chosen": -3.0482664108276367,
      "logits/rejected": -2.6644721031188965,
      "logps/chosen": -53.30866622924805,
      "logps/rejected": -89.50360107421875,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7919673919677734,
      "rewards/margins": 6.107579231262207,
      "rewards/rejected": -5.315611839294434,
      "step": 2784
    },
    {
      "epoch": 1.114,
      "grad_norm": 0.022848596796393394,
      "learning_rate": 6.288e-07,
      "logits/chosen": -2.8856215476989746,
      "logits/rejected": -1.9650321006774902,
      "logps/chosen": -80.73297119140625,
      "logps/rejected": -166.40676879882812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0083242654800415,
      "rewards/margins": 10.02877426147461,
      "rewards/rejected": -9.020450592041016,
      "step": 2785
    },
    {
      "epoch": 1.1144,
      "grad_norm": 0.025879105553030968,
      "learning_rate": 6.286666666666667e-07,
      "logits/chosen": -2.824972152709961,
      "logits/rejected": -2.4280571937561035,
      "logps/chosen": -109.7743911743164,
      "logps/rejected": -166.16748046875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2784183621406555,
      "rewards/margins": 9.612337112426758,
      "rewards/rejected": -9.333918571472168,
      "step": 2786
    },
    {
      "epoch": 1.1148,
      "grad_norm": 0.07583834230899811,
      "learning_rate": 6.285333333333334e-07,
      "logits/chosen": -3.042598247528076,
      "logits/rejected": -2.510876417160034,
      "logps/chosen": -54.791358947753906,
      "logps/rejected": -151.84146118164062,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5652172565460205,
      "rewards/margins": 8.96091079711914,
      "rewards/rejected": -9.526127815246582,
      "step": 2787
    },
    {
      "epoch": 1.1152,
      "grad_norm": 1.2222213745117188,
      "learning_rate": 6.283999999999999e-07,
      "logits/chosen": -3.1433987617492676,
      "logits/rejected": -2.7578368186950684,
      "logps/chosen": -68.31495666503906,
      "logps/rejected": -93.22418212890625,
      "loss": 0.0132,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.04421880841255188,
      "rewards/margins": 6.054224967956543,
      "rewards/rejected": -6.098443984985352,
      "step": 2788
    },
    {
      "epoch": 1.1156,
      "grad_norm": 15.412181854248047,
      "learning_rate": 6.282666666666666e-07,
      "logits/chosen": -3.0017166137695312,
      "logits/rejected": -2.514244556427002,
      "logps/chosen": -73.54228210449219,
      "logps/rejected": -69.65706634521484,
      "loss": 0.1274,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.461447536945343,
      "rewards/margins": 3.905627965927124,
      "rewards/rejected": -4.367075443267822,
      "step": 2789
    },
    {
      "epoch": 1.116,
      "grad_norm": 0.34053871035575867,
      "learning_rate": 6.281333333333333e-07,
      "logits/chosen": -2.7695109844207764,
      "logits/rejected": -2.4003043174743652,
      "logps/chosen": -92.17347717285156,
      "logps/rejected": -180.93959045410156,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.20664158463478088,
      "rewards/margins": 6.541129112243652,
      "rewards/rejected": -6.747770309448242,
      "step": 2790
    },
    {
      "epoch": 1.1164,
      "grad_norm": 1.8212904930114746,
      "learning_rate": 6.28e-07,
      "logits/chosen": -2.8273000717163086,
      "logits/rejected": -2.40976881980896,
      "logps/chosen": -159.3219451904297,
      "logps/rejected": -87.67033386230469,
      "loss": 0.0172,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8512386083602905,
      "rewards/margins": 4.249085426330566,
      "rewards/rejected": -5.1003241539001465,
      "step": 2791
    },
    {
      "epoch": 1.1168,
      "grad_norm": 0.016337864100933075,
      "learning_rate": 6.278666666666667e-07,
      "logits/chosen": -3.249105215072632,
      "logits/rejected": -2.568147659301758,
      "logps/chosen": -92.78749084472656,
      "logps/rejected": -172.1907958984375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1585443615913391,
      "rewards/margins": 10.124940872192383,
      "rewards/rejected": -10.28348445892334,
      "step": 2792
    },
    {
      "epoch": 1.1172,
      "grad_norm": 13.870325088500977,
      "learning_rate": 6.277333333333333e-07,
      "logits/chosen": -3.191697597503662,
      "logits/rejected": -3.191641092300415,
      "logps/chosen": -69.93598937988281,
      "logps/rejected": -58.69996643066406,
      "loss": 0.1458,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.317125916481018,
      "rewards/margins": 1.9061686992645264,
      "rewards/rejected": -3.223294734954834,
      "step": 2793
    },
    {
      "epoch": 1.1176,
      "grad_norm": 4.356360912322998,
      "learning_rate": 6.276e-07,
      "logits/chosen": -2.6151187419891357,
      "logits/rejected": -2.181065559387207,
      "logps/chosen": -124.83493041992188,
      "logps/rejected": -197.82955932617188,
      "loss": 0.0273,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.951714515686035,
      "rewards/margins": 6.221371173858643,
      "rewards/rejected": -9.17308521270752,
      "step": 2794
    },
    {
      "epoch": 1.1179999999999999,
      "grad_norm": 0.03965437784790993,
      "learning_rate": 6.274666666666666e-07,
      "logits/chosen": -2.971747398376465,
      "logits/rejected": -2.551546573638916,
      "logps/chosen": -82.71985626220703,
      "logps/rejected": -193.55914306640625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8933704495429993,
      "rewards/margins": 11.038915634155273,
      "rewards/rejected": -11.932286262512207,
      "step": 2795
    },
    {
      "epoch": 1.1184,
      "grad_norm": 0.03362544998526573,
      "learning_rate": 6.273333333333333e-07,
      "logits/chosen": -2.7887773513793945,
      "logits/rejected": -2.3888044357299805,
      "logps/chosen": -70.35621643066406,
      "logps/rejected": -149.14215087890625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5294452905654907,
      "rewards/margins": 8.567670822143555,
      "rewards/rejected": -7.038226127624512,
      "step": 2796
    },
    {
      "epoch": 1.1188,
      "grad_norm": 0.09342072904109955,
      "learning_rate": 6.271999999999999e-07,
      "logits/chosen": -3.268608570098877,
      "logits/rejected": -2.421557903289795,
      "logps/chosen": -70.40129089355469,
      "logps/rejected": -184.16444396972656,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6552841067314148,
      "rewards/margins": 10.400530815124512,
      "rewards/rejected": -11.055814743041992,
      "step": 2797
    },
    {
      "epoch": 1.1192,
      "grad_norm": 0.0008224403718486428,
      "learning_rate": 6.270666666666666e-07,
      "logits/chosen": -2.910940647125244,
      "logits/rejected": -1.972726583480835,
      "logps/chosen": -77.69129943847656,
      "logps/rejected": -178.01397705078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2648836374282837,
      "rewards/margins": 13.010438919067383,
      "rewards/rejected": -11.74555492401123,
      "step": 2798
    },
    {
      "epoch": 1.1196,
      "grad_norm": 2.511305570602417,
      "learning_rate": 6.269333333333333e-07,
      "logits/chosen": -2.7337846755981445,
      "logits/rejected": -2.1407580375671387,
      "logps/chosen": -142.33447265625,
      "logps/rejected": -120.94248962402344,
      "loss": 0.0154,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6652733087539673,
      "rewards/margins": 6.407388687133789,
      "rewards/rejected": -7.072661399841309,
      "step": 2799
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.019895052537322044,
      "learning_rate": 6.268e-07,
      "logits/chosen": -2.668882369995117,
      "logits/rejected": -1.842911720275879,
      "logps/chosen": -84.74465942382812,
      "logps/rejected": -176.0142059326172,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1698179244995117,
      "rewards/margins": 10.0316162109375,
      "rewards/rejected": -7.861798286437988,
      "step": 2800
    },
    {
      "epoch": 1.1204,
      "grad_norm": 0.42941808700561523,
      "learning_rate": 6.266666666666667e-07,
      "logits/chosen": -2.7827308177948,
      "logits/rejected": -1.7861311435699463,
      "logps/chosen": -141.4122314453125,
      "logps/rejected": -129.87051391601562,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2388298213481903,
      "rewards/margins": 6.679375648498535,
      "rewards/rejected": -6.440546035766602,
      "step": 2801
    },
    {
      "epoch": 1.1208,
      "grad_norm": 0.45790770649909973,
      "learning_rate": 6.265333333333334e-07,
      "logits/chosen": -3.2042698860168457,
      "logits/rejected": -2.6636383533477783,
      "logps/chosen": -47.188507080078125,
      "logps/rejected": -145.01206970214844,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04412451386451721,
      "rewards/margins": 9.311899185180664,
      "rewards/rejected": -9.26777458190918,
      "step": 2802
    },
    {
      "epoch": 1.1212,
      "grad_norm": 0.0016662303823977709,
      "learning_rate": 6.263999999999999e-07,
      "logits/chosen": -2.6052331924438477,
      "logits/rejected": -1.6441047191619873,
      "logps/chosen": -93.53137969970703,
      "logps/rejected": -170.7121124267578,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.708038330078125,
      "rewards/margins": 11.999943733215332,
      "rewards/rejected": -10.291905403137207,
      "step": 2803
    },
    {
      "epoch": 1.1216,
      "grad_norm": 0.6894188523292542,
      "learning_rate": 6.262666666666666e-07,
      "logits/chosen": -2.74760103225708,
      "logits/rejected": -1.825842022895813,
      "logps/chosen": -103.54598999023438,
      "logps/rejected": -152.81912231445312,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3794898986816406,
      "rewards/margins": 6.143130302429199,
      "rewards/rejected": -5.763640403747559,
      "step": 2804
    },
    {
      "epoch": 1.1219999999999999,
      "grad_norm": 0.0024228710681200027,
      "learning_rate": 6.261333333333333e-07,
      "logits/chosen": -2.8893280029296875,
      "logits/rejected": -2.039222002029419,
      "logps/chosen": -75.53684997558594,
      "logps/rejected": -166.05941772460938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3886200189590454,
      "rewards/margins": 11.726892471313477,
      "rewards/rejected": -10.338272094726562,
      "step": 2805
    },
    {
      "epoch": 1.1224,
      "grad_norm": 0.01641802117228508,
      "learning_rate": 6.26e-07,
      "logits/chosen": -2.772465229034424,
      "logits/rejected": -2.2477340698242188,
      "logps/chosen": -83.21333312988281,
      "logps/rejected": -256.4393310546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7316337823867798,
      "rewards/margins": 12.274595260620117,
      "rewards/rejected": -10.542962074279785,
      "step": 2806
    },
    {
      "epoch": 1.1228,
      "grad_norm": 0.0480671264231205,
      "learning_rate": 6.258666666666666e-07,
      "logits/chosen": -3.166701555252075,
      "logits/rejected": -2.581965208053589,
      "logps/chosen": -68.12660217285156,
      "logps/rejected": -129.74708557128906,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9554910659790039,
      "rewards/margins": 8.443422317504883,
      "rewards/rejected": -7.487931251525879,
      "step": 2807
    },
    {
      "epoch": 1.1232,
      "grad_norm": 0.08640232682228088,
      "learning_rate": 6.257333333333333e-07,
      "logits/chosen": -2.7863144874572754,
      "logits/rejected": -2.4316768646240234,
      "logps/chosen": -104.58688354492188,
      "logps/rejected": -128.91629028320312,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0919567346572876,
      "rewards/margins": 9.067012786865234,
      "rewards/rejected": -7.975055694580078,
      "step": 2808
    },
    {
      "epoch": 1.1236,
      "grad_norm": 0.5087758898735046,
      "learning_rate": 6.256e-07,
      "logits/chosen": -3.1659159660339355,
      "logits/rejected": -2.876537799835205,
      "logps/chosen": -67.31430053710938,
      "logps/rejected": -98.17024993896484,
      "loss": 0.0045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8636623620986938,
      "rewards/margins": 5.973383903503418,
      "rewards/rejected": -5.109721660614014,
      "step": 2809
    },
    {
      "epoch": 1.124,
      "grad_norm": 2.1736135482788086,
      "learning_rate": 6.254666666666666e-07,
      "logits/chosen": -2.6628355979919434,
      "logits/rejected": -2.4049856662750244,
      "logps/chosen": -94.71707916259766,
      "logps/rejected": -160.1142578125,
      "loss": 0.0141,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6403717994689941,
      "rewards/margins": 6.967650413513184,
      "rewards/rejected": -5.3272786140441895,
      "step": 2810
    },
    {
      "epoch": 1.1244,
      "grad_norm": 13.926725387573242,
      "learning_rate": 6.253333333333333e-07,
      "logits/chosen": -3.0700173377990723,
      "logits/rejected": -2.773346185684204,
      "logps/chosen": -65.259765625,
      "logps/rejected": -84.0576400756836,
      "loss": 0.1813,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6799567937850952,
      "rewards/margins": 4.711837291717529,
      "rewards/rejected": -5.391793727874756,
      "step": 2811
    },
    {
      "epoch": 1.1248,
      "grad_norm": 0.018101563677191734,
      "learning_rate": 6.252e-07,
      "logits/chosen": -2.7193446159362793,
      "logits/rejected": -2.2388551235198975,
      "logps/chosen": -133.62881469726562,
      "logps/rejected": -153.37521362304688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4902427196502686,
      "rewards/margins": 9.314787864685059,
      "rewards/rejected": -7.824545383453369,
      "step": 2812
    },
    {
      "epoch": 1.1252,
      "grad_norm": 0.13926683366298676,
      "learning_rate": 6.250666666666667e-07,
      "logits/chosen": -3.144958972930908,
      "logits/rejected": -2.6717324256896973,
      "logps/chosen": -70.8427734375,
      "logps/rejected": -146.17596435546875,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6370651125907898,
      "rewards/margins": 8.503509521484375,
      "rewards/rejected": -9.140575408935547,
      "step": 2813
    },
    {
      "epoch": 1.1256,
      "grad_norm": 10.688759803771973,
      "learning_rate": 6.249333333333333e-07,
      "logits/chosen": -2.9215595722198486,
      "logits/rejected": -2.495767831802368,
      "logps/chosen": -139.3864288330078,
      "logps/rejected": -111.7193603515625,
      "loss": 0.0977,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.350972294807434,
      "rewards/margins": 4.53179931640625,
      "rewards/rejected": -5.8827714920043945,
      "step": 2814
    },
    {
      "epoch": 1.126,
      "grad_norm": 0.7972551584243774,
      "learning_rate": 6.248e-07,
      "logits/chosen": -2.6920652389526367,
      "logits/rejected": -2.349438190460205,
      "logps/chosen": -149.83956909179688,
      "logps/rejected": -88.70923614501953,
      "loss": 0.0078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.009038567543029785,
      "rewards/margins": 5.0293731689453125,
      "rewards/rejected": -5.038412094116211,
      "step": 2815
    },
    {
      "epoch": 1.1264,
      "grad_norm": 0.0170261412858963,
      "learning_rate": 6.246666666666667e-07,
      "logits/chosen": -3.360466480255127,
      "logits/rejected": -2.5220634937286377,
      "logps/chosen": -47.678138732910156,
      "logps/rejected": -167.4368896484375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9896473288536072,
      "rewards/margins": 10.657790184020996,
      "rewards/rejected": -9.668143272399902,
      "step": 2816
    },
    {
      "epoch": 1.1268,
      "grad_norm": 1.1734999418258667,
      "learning_rate": 6.245333333333333e-07,
      "logits/chosen": -2.752202033996582,
      "logits/rejected": -2.307813882827759,
      "logps/chosen": -128.3617401123047,
      "logps/rejected": -130.82516479492188,
      "loss": 0.0069,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.29617154598236084,
      "rewards/margins": 5.282588958740234,
      "rewards/rejected": -5.578760623931885,
      "step": 2817
    },
    {
      "epoch": 1.1272,
      "grad_norm": 0.09927405416965485,
      "learning_rate": 6.243999999999999e-07,
      "logits/chosen": -3.051393985748291,
      "logits/rejected": -2.590320587158203,
      "logps/chosen": -70.5041732788086,
      "logps/rejected": -118.46908569335938,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08344686031341553,
      "rewards/margins": 7.449676036834717,
      "rewards/rejected": -7.533123016357422,
      "step": 2818
    },
    {
      "epoch": 1.1276,
      "grad_norm": 0.726247251033783,
      "learning_rate": 6.242666666666666e-07,
      "logits/chosen": -2.943507671356201,
      "logits/rejected": -2.4808902740478516,
      "logps/chosen": -94.47259521484375,
      "logps/rejected": -142.76992797851562,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.007382780313491821,
      "rewards/margins": 8.319104194641113,
      "rewards/rejected": -8.32648754119873,
      "step": 2819
    },
    {
      "epoch": 1.1280000000000001,
      "grad_norm": 0.07233032584190369,
      "learning_rate": 6.241333333333333e-07,
      "logits/chosen": -2.9841387271881104,
      "logits/rejected": -2.271994113922119,
      "logps/chosen": -53.5640869140625,
      "logps/rejected": -133.5914306640625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6798410415649414,
      "rewards/margins": 8.719619750976562,
      "rewards/rejected": -8.039778709411621,
      "step": 2820
    },
    {
      "epoch": 1.1284,
      "grad_norm": 0.963786244392395,
      "learning_rate": 6.24e-07,
      "logits/chosen": -2.951720714569092,
      "logits/rejected": -2.444575071334839,
      "logps/chosen": -68.28126525878906,
      "logps/rejected": -135.8660125732422,
      "loss": 0.0089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1949041485786438,
      "rewards/margins": 7.9912919998168945,
      "rewards/rejected": -7.796387672424316,
      "step": 2821
    },
    {
      "epoch": 1.1288,
      "grad_norm": 0.5161589980125427,
      "learning_rate": 6.238666666666667e-07,
      "logits/chosen": -2.776606559753418,
      "logits/rejected": -2.0925445556640625,
      "logps/chosen": -174.77407836914062,
      "logps/rejected": -122.42096710205078,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4037902355194092,
      "rewards/margins": 6.058035373687744,
      "rewards/rejected": -7.461825370788574,
      "step": 2822
    },
    {
      "epoch": 1.1292,
      "grad_norm": 0.18483585119247437,
      "learning_rate": 6.237333333333334e-07,
      "logits/chosen": -2.8517136573791504,
      "logits/rejected": -1.9926915168762207,
      "logps/chosen": -120.93313598632812,
      "logps/rejected": -157.31370544433594,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0134434700012207,
      "rewards/margins": 7.299114227294922,
      "rewards/rejected": -9.312557220458984,
      "step": 2823
    },
    {
      "epoch": 1.1296,
      "grad_norm": 0.20983615517616272,
      "learning_rate": 6.236e-07,
      "logits/chosen": -2.7874553203582764,
      "logits/rejected": -2.5273756980895996,
      "logps/chosen": -193.29754638671875,
      "logps/rejected": -167.04307556152344,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3277558088302612,
      "rewards/margins": 8.700611114501953,
      "rewards/rejected": -10.028366088867188,
      "step": 2824
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.028878850862383842,
      "learning_rate": 6.234666666666666e-07,
      "logits/chosen": -3.3906123638153076,
      "logits/rejected": -2.8586349487304688,
      "logps/chosen": -63.84398651123047,
      "logps/rejected": -121.78014373779297,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8230041861534119,
      "rewards/margins": 8.703425407409668,
      "rewards/rejected": -7.8804216384887695,
      "step": 2825
    },
    {
      "epoch": 1.1304,
      "grad_norm": 0.003224460408091545,
      "learning_rate": 6.233333333333332e-07,
      "logits/chosen": -3.218564510345459,
      "logits/rejected": -2.3937759399414062,
      "logps/chosen": -68.06507873535156,
      "logps/rejected": -173.13116455078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4603704512119293,
      "rewards/margins": 11.178369522094727,
      "rewards/rejected": -10.717998504638672,
      "step": 2826
    },
    {
      "epoch": 1.1308,
      "grad_norm": 0.033629003912210464,
      "learning_rate": 6.231999999999999e-07,
      "logits/chosen": -3.0070371627807617,
      "logits/rejected": -1.9951858520507812,
      "logps/chosen": -102.66317749023438,
      "logps/rejected": -160.37594604492188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9607052206993103,
      "rewards/margins": 10.677419662475586,
      "rewards/rejected": -9.716714859008789,
      "step": 2827
    },
    {
      "epoch": 1.1312,
      "grad_norm": 0.49261540174484253,
      "learning_rate": 6.230666666666666e-07,
      "logits/chosen": -3.0236167907714844,
      "logits/rejected": -2.51005482673645,
      "logps/chosen": -77.63270568847656,
      "logps/rejected": -106.28814697265625,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9091713428497314,
      "rewards/margins": 6.5507402420043945,
      "rewards/rejected": -5.641569137573242,
      "step": 2828
    },
    {
      "epoch": 1.1316,
      "grad_norm": 0.02064289152622223,
      "learning_rate": 6.229333333333333e-07,
      "logits/chosen": -3.030003786087036,
      "logits/rejected": -2.3811140060424805,
      "logps/chosen": -95.82412719726562,
      "logps/rejected": -159.05421447753906,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24576416611671448,
      "rewards/margins": 9.427974700927734,
      "rewards/rejected": -9.182210922241211,
      "step": 2829
    },
    {
      "epoch": 1.1320000000000001,
      "grad_norm": 0.049566663801670074,
      "learning_rate": 6.228e-07,
      "logits/chosen": -2.6495633125305176,
      "logits/rejected": -2.0292985439300537,
      "logps/chosen": -111.89122009277344,
      "logps/rejected": -164.2703857421875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5126010775566101,
      "rewards/margins": 7.998281002044678,
      "rewards/rejected": -8.510881423950195,
      "step": 2830
    },
    {
      "epoch": 1.1324,
      "grad_norm": 1.7083696126937866,
      "learning_rate": 6.226666666666667e-07,
      "logits/chosen": -2.79058837890625,
      "logits/rejected": -2.254408121109009,
      "logps/chosen": -119.43391418457031,
      "logps/rejected": -132.46226501464844,
      "loss": 0.0153,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23198586702346802,
      "rewards/margins": 8.015268325805664,
      "rewards/rejected": -7.78328275680542,
      "step": 2831
    },
    {
      "epoch": 1.1328,
      "grad_norm": 11.13947582244873,
      "learning_rate": 6.225333333333334e-07,
      "logits/chosen": -3.0748209953308105,
      "logits/rejected": -3.029337167739868,
      "logps/chosen": -150.413818359375,
      "logps/rejected": -103.1613540649414,
      "loss": 0.0646,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.7366058826446533,
      "rewards/margins": 2.9847066402435303,
      "rewards/rejected": -5.721312522888184,
      "step": 2832
    },
    {
      "epoch": 1.1332,
      "grad_norm": 2.2082345485687256,
      "learning_rate": 6.224e-07,
      "logits/chosen": -3.193925619125366,
      "logits/rejected": -2.7549962997436523,
      "logps/chosen": -69.455810546875,
      "logps/rejected": -127.09072875976562,
      "loss": 0.0221,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.620513916015625,
      "rewards/margins": 6.417605400085449,
      "rewards/rejected": -7.038119316101074,
      "step": 2833
    },
    {
      "epoch": 1.1336,
      "grad_norm": 0.17842644453048706,
      "learning_rate": 6.222666666666667e-07,
      "logits/chosen": -2.925581455230713,
      "logits/rejected": -2.52297306060791,
      "logps/chosen": -94.7501449584961,
      "logps/rejected": -225.75967407226562,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5852928161621094,
      "rewards/margins": 12.131702423095703,
      "rewards/rejected": -12.716995239257812,
      "step": 2834
    },
    {
      "epoch": 1.134,
      "grad_norm": 5.513444900512695,
      "learning_rate": 6.221333333333332e-07,
      "logits/chosen": -3.207246780395508,
      "logits/rejected": -2.926617383956909,
      "logps/chosen": -100.06776428222656,
      "logps/rejected": -95.77534484863281,
      "loss": 0.0366,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4935017228126526,
      "rewards/margins": 5.396295547485352,
      "rewards/rejected": -5.889797210693359,
      "step": 2835
    },
    {
      "epoch": 1.1344,
      "grad_norm": 0.39874541759490967,
      "learning_rate": 6.219999999999999e-07,
      "logits/chosen": -2.9937477111816406,
      "logits/rejected": -2.666764974594116,
      "logps/chosen": -71.41180419921875,
      "logps/rejected": -145.4342498779297,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.29919683933258057,
      "rewards/margins": 9.60336685180664,
      "rewards/rejected": -9.304170608520508,
      "step": 2836
    },
    {
      "epoch": 1.1348,
      "grad_norm": 0.009698665700852871,
      "learning_rate": 6.218666666666666e-07,
      "logits/chosen": -2.7542572021484375,
      "logits/rejected": -2.4644365310668945,
      "logps/chosen": -90.69070434570312,
      "logps/rejected": -217.05174255371094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39629554748535156,
      "rewards/margins": 10.42922592163086,
      "rewards/rejected": -10.032930374145508,
      "step": 2837
    },
    {
      "epoch": 1.1352,
      "grad_norm": 0.10254042595624924,
      "learning_rate": 6.217333333333333e-07,
      "logits/chosen": -3.114274024963379,
      "logits/rejected": -2.508669853210449,
      "logps/chosen": -95.45867919921875,
      "logps/rejected": -121.28572082519531,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6124778985977173,
      "rewards/margins": 8.65777587890625,
      "rewards/rejected": -7.045297622680664,
      "step": 2838
    },
    {
      "epoch": 1.1356,
      "grad_norm": 0.8948453664779663,
      "learning_rate": 6.216e-07,
      "logits/chosen": -3.0420145988464355,
      "logits/rejected": -2.2790493965148926,
      "logps/chosen": -104.45516967773438,
      "logps/rejected": -122.06490325927734,
      "loss": 0.0045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6538662314414978,
      "rewards/margins": 6.669939041137695,
      "rewards/rejected": -7.32380485534668,
      "step": 2839
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 0.44328609108924866,
      "learning_rate": 6.214666666666666e-07,
      "logits/chosen": -2.9965548515319824,
      "logits/rejected": -2.470644950866699,
      "logps/chosen": -110.01758575439453,
      "logps/rejected": -142.37863159179688,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.18826982378959656,
      "rewards/margins": 8.942888259887695,
      "rewards/rejected": -9.131158828735352,
      "step": 2840
    },
    {
      "epoch": 1.1364,
      "grad_norm": 0.021964818239212036,
      "learning_rate": 6.213333333333333e-07,
      "logits/chosen": -2.454451084136963,
      "logits/rejected": -1.5842533111572266,
      "logps/chosen": -79.53006744384766,
      "logps/rejected": -179.4779052734375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0639381408691406,
      "rewards/margins": 9.524850845336914,
      "rewards/rejected": -8.46091365814209,
      "step": 2841
    },
    {
      "epoch": 1.1368,
      "grad_norm": 0.14013215899467468,
      "learning_rate": 6.212e-07,
      "logits/chosen": -2.9279332160949707,
      "logits/rejected": -2.658499002456665,
      "logps/chosen": -79.75233459472656,
      "logps/rejected": -166.60475158691406,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09610748291015625,
      "rewards/margins": 11.337288856506348,
      "rewards/rejected": -11.241181373596191,
      "step": 2842
    },
    {
      "epoch": 1.1372,
      "grad_norm": 0.3462972342967987,
      "learning_rate": 6.210666666666667e-07,
      "logits/chosen": -2.7323033809661865,
      "logits/rejected": -2.1860790252685547,
      "logps/chosen": -119.99114990234375,
      "logps/rejected": -168.53977966308594,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4280269742012024,
      "rewards/margins": 10.600349426269531,
      "rewards/rejected": -10.172322273254395,
      "step": 2843
    },
    {
      "epoch": 1.1376,
      "grad_norm": 0.08191729336977005,
      "learning_rate": 6.209333333333334e-07,
      "logits/chosen": -3.186056613922119,
      "logits/rejected": -2.6099395751953125,
      "logps/chosen": -90.2688980102539,
      "logps/rejected": -126.27706909179688,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5176852941513062,
      "rewards/margins": 7.45095157623291,
      "rewards/rejected": -6.9332661628723145,
      "step": 2844
    },
    {
      "epoch": 1.138,
      "grad_norm": 0.4664822518825531,
      "learning_rate": 6.208e-07,
      "logits/chosen": -2.666759490966797,
      "logits/rejected": -2.111140251159668,
      "logps/chosen": -137.0575714111328,
      "logps/rejected": -128.6201171875,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.5200350284576416,
      "rewards/margins": 5.59443473815918,
      "rewards/rejected": -8.114469528198242,
      "step": 2845
    },
    {
      "epoch": 1.1384,
      "grad_norm": 0.020844431594014168,
      "learning_rate": 6.206666666666666e-07,
      "logits/chosen": -3.02911114692688,
      "logits/rejected": -2.380187511444092,
      "logps/chosen": -38.818992614746094,
      "logps/rejected": -131.07888793945312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.298965334892273,
      "rewards/margins": 9.132317543029785,
      "rewards/rejected": -7.833352565765381,
      "step": 2846
    },
    {
      "epoch": 1.1388,
      "grad_norm": 0.026809029281139374,
      "learning_rate": 6.205333333333333e-07,
      "logits/chosen": -2.706488609313965,
      "logits/rejected": -2.5547306537628174,
      "logps/chosen": -120.18024444580078,
      "logps/rejected": -145.16383361816406,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.26068079471588135,
      "rewards/margins": 8.75424861907959,
      "rewards/rejected": -9.014928817749023,
      "step": 2847
    },
    {
      "epoch": 1.1392,
      "grad_norm": 0.005867139436304569,
      "learning_rate": 6.203999999999999e-07,
      "logits/chosen": -2.929673910140991,
      "logits/rejected": -2.181596517562866,
      "logps/chosen": -57.59593200683594,
      "logps/rejected": -166.76234436035156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6413111686706543,
      "rewards/margins": 10.982364654541016,
      "rewards/rejected": -9.34105396270752,
      "step": 2848
    },
    {
      "epoch": 1.1396,
      "grad_norm": 0.24356919527053833,
      "learning_rate": 6.202666666666666e-07,
      "logits/chosen": -2.983017921447754,
      "logits/rejected": -2.4614217281341553,
      "logps/chosen": -40.62529373168945,
      "logps/rejected": -95.08733367919922,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10164375603199005,
      "rewards/margins": 6.36609411239624,
      "rewards/rejected": -6.467737674713135,
      "step": 2849
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 75.49372863769531,
      "learning_rate": 6.201333333333333e-07,
      "logits/chosen": -2.9895715713500977,
      "logits/rejected": -2.555797576904297,
      "logps/chosen": -104.91151428222656,
      "logps/rejected": -121.7259521484375,
      "loss": 1.3018,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -4.6545209884643555,
      "rewards/margins": 2.2228660583496094,
      "rewards/rejected": -6.877387046813965,
      "step": 2850
    },
    {
      "epoch": 1.1404,
      "grad_norm": 0.09325341880321503,
      "learning_rate": 6.2e-07,
      "logits/chosen": -2.6339995861053467,
      "logits/rejected": -2.164811849594116,
      "logps/chosen": -100.33580780029297,
      "logps/rejected": -126.50634765625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7622730135917664,
      "rewards/margins": 8.984787940979004,
      "rewards/rejected": -8.222515106201172,
      "step": 2851
    },
    {
      "epoch": 1.1408,
      "grad_norm": 0.03670894727110863,
      "learning_rate": 6.198666666666667e-07,
      "logits/chosen": -2.8531250953674316,
      "logits/rejected": -2.297441005706787,
      "logps/chosen": -123.645263671875,
      "logps/rejected": -169.20645141601562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2972544729709625,
      "rewards/margins": 8.962408065795898,
      "rewards/rejected": -9.259662628173828,
      "step": 2852
    },
    {
      "epoch": 1.1412,
      "grad_norm": 0.18138054013252258,
      "learning_rate": 6.197333333333334e-07,
      "logits/chosen": -3.08774995803833,
      "logits/rejected": -2.931506633758545,
      "logps/chosen": -108.33111572265625,
      "logps/rejected": -118.88771057128906,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3300548493862152,
      "rewards/margins": 7.411428451538086,
      "rewards/rejected": -7.741482734680176,
      "step": 2853
    },
    {
      "epoch": 1.1416,
      "grad_norm": 0.4248574376106262,
      "learning_rate": 6.196e-07,
      "logits/chosen": -2.7611427307128906,
      "logits/rejected": -2.136054754257202,
      "logps/chosen": -121.6718521118164,
      "logps/rejected": -123.29238891601562,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.206761360168457,
      "rewards/margins": 7.611807346343994,
      "rewards/rejected": -8.81856918334961,
      "step": 2854
    },
    {
      "epoch": 1.142,
      "grad_norm": 0.039768073707818985,
      "learning_rate": 6.194666666666667e-07,
      "logits/chosen": -2.407247543334961,
      "logits/rejected": -2.177255392074585,
      "logps/chosen": -117.42338562011719,
      "logps/rejected": -127.8939208984375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6850932836532593,
      "rewards/margins": 7.838465213775635,
      "rewards/rejected": -7.153371810913086,
      "step": 2855
    },
    {
      "epoch": 1.1424,
      "grad_norm": 1.1687270402908325,
      "learning_rate": 6.193333333333332e-07,
      "logits/chosen": -3.1594533920288086,
      "logits/rejected": -3.112382173538208,
      "logps/chosen": -70.88707733154297,
      "logps/rejected": -116.27055358886719,
      "loss": 0.0065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0695416927337646,
      "rewards/margins": 5.424175262451172,
      "rewards/rejected": -6.493717193603516,
      "step": 2856
    },
    {
      "epoch": 1.1428,
      "grad_norm": 0.32257652282714844,
      "learning_rate": 6.191999999999999e-07,
      "logits/chosen": -2.538654088973999,
      "logits/rejected": -2.2612464427948,
      "logps/chosen": -133.35118103027344,
      "logps/rejected": -144.97073364257812,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6649742126464844,
      "rewards/margins": 7.768482208251953,
      "rewards/rejected": -8.433456420898438,
      "step": 2857
    },
    {
      "epoch": 1.1432,
      "grad_norm": 1.1735762357711792,
      "learning_rate": 6.190666666666666e-07,
      "logits/chosen": -2.894195079803467,
      "logits/rejected": -2.234616279602051,
      "logps/chosen": -70.52801513671875,
      "logps/rejected": -118.87152099609375,
      "loss": 0.0095,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2730642259120941,
      "rewards/margins": 6.227158546447754,
      "rewards/rejected": -5.954094886779785,
      "step": 2858
    },
    {
      "epoch": 1.1436,
      "grad_norm": 0.004524144809693098,
      "learning_rate": 6.189333333333333e-07,
      "logits/chosen": -2.8261098861694336,
      "logits/rejected": -1.9739036560058594,
      "logps/chosen": -120.74382019042969,
      "logps/rejected": -186.9519500732422,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4966797828674316,
      "rewards/margins": 12.24725341796875,
      "rewards/rejected": -10.750574111938477,
      "step": 2859
    },
    {
      "epoch": 1.144,
      "grad_norm": 0.041733890771865845,
      "learning_rate": 6.188e-07,
      "logits/chosen": -2.571826934814453,
      "logits/rejected": -1.6642892360687256,
      "logps/chosen": -75.34400939941406,
      "logps/rejected": -173.07763671875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8281265497207642,
      "rewards/margins": 11.032020568847656,
      "rewards/rejected": -9.203893661499023,
      "step": 2860
    },
    {
      "epoch": 1.1444,
      "grad_norm": 2.50640869140625,
      "learning_rate": 6.186666666666667e-07,
      "logits/chosen": -3.147300958633423,
      "logits/rejected": -2.679013729095459,
      "logps/chosen": -76.47928619384766,
      "logps/rejected": -69.20500183105469,
      "loss": 0.0214,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7630581855773926,
      "rewards/margins": 4.116601943969727,
      "rewards/rejected": -3.353543996810913,
      "step": 2861
    },
    {
      "epoch": 1.1448,
      "grad_norm": 0.007558205630630255,
      "learning_rate": 6.185333333333334e-07,
      "logits/chosen": -2.7349483966827393,
      "logits/rejected": -2.1787843704223633,
      "logps/chosen": -75.28237915039062,
      "logps/rejected": -195.75575256347656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3020331859588623,
      "rewards/margins": 12.827645301818848,
      "rewards/rejected": -11.525611877441406,
      "step": 2862
    },
    {
      "epoch": 1.1452,
      "grad_norm": 0.05592982843518257,
      "learning_rate": 6.183999999999999e-07,
      "logits/chosen": -2.4748339653015137,
      "logits/rejected": -1.455472469329834,
      "logps/chosen": -73.091552734375,
      "logps/rejected": -160.42831420898438,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3929126262664795,
      "rewards/margins": 8.3251953125,
      "rewards/rejected": -6.932282447814941,
      "step": 2863
    },
    {
      "epoch": 1.1456,
      "grad_norm": 0.004685212392359972,
      "learning_rate": 6.182666666666666e-07,
      "logits/chosen": -2.53083872795105,
      "logits/rejected": -1.586517095565796,
      "logps/chosen": -157.17343139648438,
      "logps/rejected": -177.59286499023438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0694656372070312,
      "rewards/margins": 11.016853332519531,
      "rewards/rejected": -9.9473876953125,
      "step": 2864
    },
    {
      "epoch": 1.146,
      "grad_norm": 0.05077090486884117,
      "learning_rate": 6.181333333333333e-07,
      "logits/chosen": -2.2736496925354004,
      "logits/rejected": -1.5233538150787354,
      "logps/chosen": -101.23983001708984,
      "logps/rejected": -160.17564392089844,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4117721319198608,
      "rewards/margins": 10.184548377990723,
      "rewards/rejected": -8.772775650024414,
      "step": 2865
    },
    {
      "epoch": 1.1464,
      "grad_norm": 0.013957559131085873,
      "learning_rate": 6.18e-07,
      "logits/chosen": -3.210691452026367,
      "logits/rejected": -2.5392749309539795,
      "logps/chosen": -45.27002716064453,
      "logps/rejected": -155.14212036132812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6247182488441467,
      "rewards/margins": 11.370285034179688,
      "rewards/rejected": -10.745567321777344,
      "step": 2866
    },
    {
      "epoch": 1.1468,
      "grad_norm": 0.5467954874038696,
      "learning_rate": 6.178666666666666e-07,
      "logits/chosen": -2.8575518131256104,
      "logits/rejected": -2.3464255332946777,
      "logps/chosen": -112.11187744140625,
      "logps/rejected": -148.89430236816406,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4836505651473999,
      "rewards/margins": 8.605502128601074,
      "rewards/rejected": -8.121851921081543,
      "step": 2867
    },
    {
      "epoch": 1.1472,
      "grad_norm": 0.49389103055000305,
      "learning_rate": 6.177333333333333e-07,
      "logits/chosen": -2.727271556854248,
      "logits/rejected": -2.495356559753418,
      "logps/chosen": -112.42510223388672,
      "logps/rejected": -110.13903045654297,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27756062150001526,
      "rewards/margins": 5.800796031951904,
      "rewards/rejected": -5.523235321044922,
      "step": 2868
    },
    {
      "epoch": 1.1476,
      "grad_norm": 0.030989672988653183,
      "learning_rate": 6.176e-07,
      "logits/chosen": -3.0506906509399414,
      "logits/rejected": -2.1006689071655273,
      "logps/chosen": -62.692989349365234,
      "logps/rejected": -190.203369140625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23822709918022156,
      "rewards/margins": 10.712103843688965,
      "rewards/rejected": -10.473876953125,
      "step": 2869
    },
    {
      "epoch": 1.148,
      "grad_norm": 0.19516366720199585,
      "learning_rate": 6.174666666666667e-07,
      "logits/chosen": -2.9336295127868652,
      "logits/rejected": -2.512133836746216,
      "logps/chosen": -80.57117462158203,
      "logps/rejected": -105.62216186523438,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8086513876914978,
      "rewards/margins": 6.660470008850098,
      "rewards/rejected": -5.851819038391113,
      "step": 2870
    },
    {
      "epoch": 1.1484,
      "grad_norm": 0.07824430614709854,
      "learning_rate": 6.173333333333333e-07,
      "logits/chosen": -2.9205949306488037,
      "logits/rejected": -2.501160144805908,
      "logps/chosen": -75.33073425292969,
      "logps/rejected": -184.9508056640625,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.202050805091858,
      "rewards/margins": 12.299654960632324,
      "rewards/rejected": -11.097604751586914,
      "step": 2871
    },
    {
      "epoch": 1.1488,
      "grad_norm": 0.3084084689617157,
      "learning_rate": 6.172e-07,
      "logits/chosen": -2.600527048110962,
      "logits/rejected": -1.9330099821090698,
      "logps/chosen": -109.22897338867188,
      "logps/rejected": -151.28436279296875,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5217961072921753,
      "rewards/margins": 9.156962394714355,
      "rewards/rejected": -9.67875862121582,
      "step": 2872
    },
    {
      "epoch": 1.1492,
      "grad_norm": 0.0060663833282887936,
      "learning_rate": 6.170666666666666e-07,
      "logits/chosen": -3.183858871459961,
      "logits/rejected": -2.32136869430542,
      "logps/chosen": -62.644874572753906,
      "logps/rejected": -205.8000030517578,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0380113422870636,
      "rewards/margins": 11.374162673950195,
      "rewards/rejected": -11.336151123046875,
      "step": 2873
    },
    {
      "epoch": 1.1496,
      "grad_norm": 0.0017370921559631824,
      "learning_rate": 6.169333333333333e-07,
      "logits/chosen": -2.7241568565368652,
      "logits/rejected": -1.4762316942214966,
      "logps/chosen": -57.2242317199707,
      "logps/rejected": -216.34722900390625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8688812255859375,
      "rewards/margins": 13.347110748291016,
      "rewards/rejected": -12.478229522705078,
      "step": 2874
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.1398254930973053,
      "learning_rate": 6.168e-07,
      "logits/chosen": -2.874594211578369,
      "logits/rejected": -2.091308116912842,
      "logps/chosen": -111.52499389648438,
      "logps/rejected": -129.66015625,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5035243630409241,
      "rewards/margins": 7.310081481933594,
      "rewards/rejected": -6.806557655334473,
      "step": 2875
    },
    {
      "epoch": 1.1504,
      "grad_norm": 0.081901416182518,
      "learning_rate": 6.166666666666667e-07,
      "logits/chosen": -2.9377951622009277,
      "logits/rejected": -2.580627202987671,
      "logps/chosen": -57.58160400390625,
      "logps/rejected": -161.24566650390625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5389522314071655,
      "rewards/margins": 8.592989921569824,
      "rewards/rejected": -8.054037094116211,
      "step": 2876
    },
    {
      "epoch": 1.1508,
      "grad_norm": 0.3457593023777008,
      "learning_rate": 6.165333333333333e-07,
      "logits/chosen": -2.9070382118225098,
      "logits/rejected": -2.702249765396118,
      "logps/chosen": -82.53929901123047,
      "logps/rejected": -118.38481140136719,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1780289113521576,
      "rewards/margins": 7.278931140899658,
      "rewards/rejected": -7.100902080535889,
      "step": 2877
    },
    {
      "epoch": 1.1512,
      "grad_norm": 0.005964532494544983,
      "learning_rate": 6.163999999999999e-07,
      "logits/chosen": -3.008770227432251,
      "logits/rejected": -2.2721974849700928,
      "logps/chosen": -146.54840087890625,
      "logps/rejected": -191.7816162109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6521709561347961,
      "rewards/margins": 10.656364440917969,
      "rewards/rejected": -10.004193305969238,
      "step": 2878
    },
    {
      "epoch": 1.1516,
      "grad_norm": 0.035872507840394974,
      "learning_rate": 6.162666666666666e-07,
      "logits/chosen": -3.056929588317871,
      "logits/rejected": -2.4074840545654297,
      "logps/chosen": -51.437583923339844,
      "logps/rejected": -126.46061706542969,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7044447064399719,
      "rewards/margins": 8.555475234985352,
      "rewards/rejected": -7.851031303405762,
      "step": 2879
    },
    {
      "epoch": 1.152,
      "grad_norm": 0.007713066413998604,
      "learning_rate": 6.161333333333333e-07,
      "logits/chosen": -2.8619065284729004,
      "logits/rejected": -2.272977352142334,
      "logps/chosen": -115.71366882324219,
      "logps/rejected": -173.53257751464844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8331884741783142,
      "rewards/margins": 11.125875473022461,
      "rewards/rejected": -10.292686462402344,
      "step": 2880
    },
    {
      "epoch": 1.1524,
      "grad_norm": 1.2783082723617554,
      "learning_rate": 6.16e-07,
      "logits/chosen": -2.9044108390808105,
      "logits/rejected": -2.727494716644287,
      "logps/chosen": -104.6677017211914,
      "logps/rejected": -129.0133056640625,
      "loss": 0.0086,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0874847173690796,
      "rewards/margins": 8.719106674194336,
      "rewards/rejected": -7.631622314453125,
      "step": 2881
    },
    {
      "epoch": 1.1528,
      "grad_norm": 0.003995055798441172,
      "learning_rate": 6.158666666666666e-07,
      "logits/chosen": -2.9459729194641113,
      "logits/rejected": -2.0942201614379883,
      "logps/chosen": -95.00353240966797,
      "logps/rejected": -207.5172119140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1734592914581299,
      "rewards/margins": 13.283632278442383,
      "rewards/rejected": -12.110173225402832,
      "step": 2882
    },
    {
      "epoch": 1.1532,
      "grad_norm": 0.0021810783073306084,
      "learning_rate": 6.157333333333333e-07,
      "logits/chosen": -2.5879225730895996,
      "logits/rejected": -1.8262466192245483,
      "logps/chosen": -128.30459594726562,
      "logps/rejected": -201.70455932617188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8008224964141846,
      "rewards/margins": 12.397640228271484,
      "rewards/rejected": -11.596817016601562,
      "step": 2883
    },
    {
      "epoch": 1.1536,
      "grad_norm": 0.054700978100299835,
      "learning_rate": 6.156e-07,
      "logits/chosen": -2.9721992015838623,
      "logits/rejected": -2.6177539825439453,
      "logps/chosen": -76.46945190429688,
      "logps/rejected": -138.19158935546875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5358296036720276,
      "rewards/margins": 9.111345291137695,
      "rewards/rejected": -9.647174835205078,
      "step": 2884
    },
    {
      "epoch": 1.154,
      "grad_norm": 1.7890678644180298,
      "learning_rate": 6.154666666666667e-07,
      "logits/chosen": -2.8516035079956055,
      "logits/rejected": -2.5721259117126465,
      "logps/chosen": -108.93656921386719,
      "logps/rejected": -84.48175048828125,
      "loss": 0.0141,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6793929934501648,
      "rewards/margins": 4.496450424194336,
      "rewards/rejected": -5.175843715667725,
      "step": 2885
    },
    {
      "epoch": 1.1544,
      "grad_norm": 0.9046018123626709,
      "learning_rate": 6.153333333333333e-07,
      "logits/chosen": -2.935112953186035,
      "logits/rejected": -2.5519347190856934,
      "logps/chosen": -51.397430419921875,
      "logps/rejected": -123.515869140625,
      "loss": 0.0094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5591335296630859,
      "rewards/margins": 7.151559829711914,
      "rewards/rejected": -7.710693359375,
      "step": 2886
    },
    {
      "epoch": 1.1548,
      "grad_norm": 0.006462687626481056,
      "learning_rate": 6.152e-07,
      "logits/chosen": -3.149078130722046,
      "logits/rejected": -2.2900567054748535,
      "logps/chosen": -70.92086029052734,
      "logps/rejected": -188.20970153808594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2513703107833862,
      "rewards/margins": 11.936147689819336,
      "rewards/rejected": -10.684778213500977,
      "step": 2887
    },
    {
      "epoch": 1.1552,
      "grad_norm": 0.12044641375541687,
      "learning_rate": 6.150666666666666e-07,
      "logits/chosen": -2.5346953868865967,
      "logits/rejected": -1.8210430145263672,
      "logps/chosen": -145.65780639648438,
      "logps/rejected": -194.12057495117188,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5146664381027222,
      "rewards/margins": 10.037727355957031,
      "rewards/rejected": -10.552392959594727,
      "step": 2888
    },
    {
      "epoch": 1.1556,
      "grad_norm": 0.0013163122348487377,
      "learning_rate": 6.149333333333333e-07,
      "logits/chosen": -2.6612071990966797,
      "logits/rejected": -1.8639111518859863,
      "logps/chosen": -138.0279998779297,
      "logps/rejected": -208.09884643554688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1377582550048828,
      "rewards/margins": 12.288810729980469,
      "rewards/rejected": -12.426568984985352,
      "step": 2889
    },
    {
      "epoch": 1.156,
      "grad_norm": 0.003328337101265788,
      "learning_rate": 6.148e-07,
      "logits/chosen": -3.0691065788269043,
      "logits/rejected": -2.766756534576416,
      "logps/chosen": -62.744049072265625,
      "logps/rejected": -179.3311004638672,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7756572961807251,
      "rewards/margins": 11.071062088012695,
      "rewards/rejected": -10.295404434204102,
      "step": 2890
    },
    {
      "epoch": 1.1564,
      "grad_norm": 2.238612413406372,
      "learning_rate": 6.146666666666667e-07,
      "logits/chosen": -2.998885154724121,
      "logits/rejected": -2.646135091781616,
      "logps/chosen": -88.81568145751953,
      "logps/rejected": -108.11456298828125,
      "loss": 0.0156,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.420174241065979,
      "rewards/margins": 5.281716346740723,
      "rewards/rejected": -4.861542224884033,
      "step": 2891
    },
    {
      "epoch": 1.1568,
      "grad_norm": 0.16196322441101074,
      "learning_rate": 6.145333333333333e-07,
      "logits/chosen": -2.807666778564453,
      "logits/rejected": -2.2477755546569824,
      "logps/chosen": -69.9095458984375,
      "logps/rejected": -136.7598876953125,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0467735528945923,
      "rewards/margins": 10.26059627532959,
      "rewards/rejected": -9.213823318481445,
      "step": 2892
    },
    {
      "epoch": 1.1572,
      "grad_norm": 0.0027279951609671116,
      "learning_rate": 6.143999999999999e-07,
      "logits/chosen": -2.922006607055664,
      "logits/rejected": -2.037060022354126,
      "logps/chosen": -116.72578430175781,
      "logps/rejected": -198.9199981689453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06767349690198898,
      "rewards/margins": 11.67159652709961,
      "rewards/rejected": -11.603923797607422,
      "step": 2893
    },
    {
      "epoch": 1.1576,
      "grad_norm": 2.2881031036376953,
      "learning_rate": 6.142666666666666e-07,
      "logits/chosen": -2.789687156677246,
      "logits/rejected": -2.293186902999878,
      "logps/chosen": -122.68890380859375,
      "logps/rejected": -128.50401306152344,
      "loss": 0.0154,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5747727155685425,
      "rewards/margins": 7.5615386962890625,
      "rewards/rejected": -9.136311531066895,
      "step": 2894
    },
    {
      "epoch": 1.158,
      "grad_norm": 0.0019422098994255066,
      "learning_rate": 6.141333333333333e-07,
      "logits/chosen": -2.6968884468078613,
      "logits/rejected": -1.6784929037094116,
      "logps/chosen": -132.61570739746094,
      "logps/rejected": -180.21893310546875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5152363777160645,
      "rewards/margins": 13.921908378601074,
      "rewards/rejected": -11.406671524047852,
      "step": 2895
    },
    {
      "epoch": 1.1584,
      "grad_norm": 0.061816997826099396,
      "learning_rate": 6.14e-07,
      "logits/chosen": -2.830524444580078,
      "logits/rejected": -2.3002817630767822,
      "logps/chosen": -109.27623748779297,
      "logps/rejected": -156.09085083007812,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1119537353515625,
      "rewards/margins": 7.800093650817871,
      "rewards/rejected": -7.912047386169434,
      "step": 2896
    },
    {
      "epoch": 1.1588,
      "grad_norm": 1.3991360664367676,
      "learning_rate": 6.138666666666667e-07,
      "logits/chosen": -3.349745750427246,
      "logits/rejected": -3.144385814666748,
      "logps/chosen": -57.8936882019043,
      "logps/rejected": -128.78079223632812,
      "loss": 0.0099,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6925075054168701,
      "rewards/margins": 7.205671310424805,
      "rewards/rejected": -7.898179054260254,
      "step": 2897
    },
    {
      "epoch": 1.1592,
      "grad_norm": 8.680542945861816,
      "learning_rate": 6.137333333333333e-07,
      "logits/chosen": -3.064098834991455,
      "logits/rejected": -2.6790690422058105,
      "logps/chosen": -106.61398315429688,
      "logps/rejected": -78.32942199707031,
      "loss": 0.0754,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6796112060546875,
      "rewards/margins": 3.0616307258605957,
      "rewards/rejected": -3.741241931915283,
      "step": 2898
    },
    {
      "epoch": 1.1596,
      "grad_norm": 18.42223358154297,
      "learning_rate": 6.136e-07,
      "logits/chosen": -2.8483972549438477,
      "logits/rejected": -2.7493369579315186,
      "logps/chosen": -143.64466857910156,
      "logps/rejected": -139.28753662109375,
      "loss": 0.1084,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.5418879985809326,
      "rewards/margins": 5.8940958976745605,
      "rewards/rejected": -8.435983657836914,
      "step": 2899
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.005802711937576532,
      "learning_rate": 6.134666666666667e-07,
      "logits/chosen": -2.772618055343628,
      "logits/rejected": -2.0084471702575684,
      "logps/chosen": -70.8863525390625,
      "logps/rejected": -185.46200561523438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.24590644240379333,
      "rewards/margins": 10.780733108520508,
      "rewards/rejected": -11.026638984680176,
      "step": 2900
    },
    {
      "epoch": 1.1604,
      "grad_norm": 0.09546318650245667,
      "learning_rate": 6.133333333333332e-07,
      "logits/chosen": -2.7870936393737793,
      "logits/rejected": -1.9146754741668701,
      "logps/chosen": -100.10676574707031,
      "logps/rejected": -141.41099548339844,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10847246646881104,
      "rewards/margins": 7.370290756225586,
      "rewards/rejected": -7.478763103485107,
      "step": 2901
    },
    {
      "epoch": 1.1608,
      "grad_norm": 0.7949087023735046,
      "learning_rate": 6.131999999999999e-07,
      "logits/chosen": -2.8866469860076904,
      "logits/rejected": -2.0760574340820312,
      "logps/chosen": -76.63085174560547,
      "logps/rejected": -129.94403076171875,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.772726833820343,
      "rewards/margins": 8.284893035888672,
      "rewards/rejected": -7.5121660232543945,
      "step": 2902
    },
    {
      "epoch": 1.1612,
      "grad_norm": 107.24775695800781,
      "learning_rate": 6.130666666666666e-07,
      "logits/chosen": -2.7278504371643066,
      "logits/rejected": -2.7553694248199463,
      "logps/chosen": -190.46652221679688,
      "logps/rejected": -92.05854034423828,
      "loss": 0.9059,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -3.8402247428894043,
      "rewards/margins": 0.02786886692047119,
      "rewards/rejected": -3.868093490600586,
      "step": 2903
    },
    {
      "epoch": 1.1616,
      "grad_norm": 0.14676152169704437,
      "learning_rate": 6.129333333333333e-07,
      "logits/chosen": -3.105032444000244,
      "logits/rejected": -2.5508289337158203,
      "logps/chosen": -65.34736633300781,
      "logps/rejected": -122.73844909667969,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5019235610961914,
      "rewards/margins": 7.79667854309082,
      "rewards/rejected": -7.294754981994629,
      "step": 2904
    },
    {
      "epoch": 1.162,
      "grad_norm": 0.40894681215286255,
      "learning_rate": 6.128e-07,
      "logits/chosen": -2.9727203845977783,
      "logits/rejected": -2.8159079551696777,
      "logps/chosen": -59.436195373535156,
      "logps/rejected": -116.30685424804688,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8930419683456421,
      "rewards/margins": 7.279978275299072,
      "rewards/rejected": -8.173020362854004,
      "step": 2905
    },
    {
      "epoch": 1.1623999999999999,
      "grad_norm": 0.018588658422231674,
      "learning_rate": 6.126666666666667e-07,
      "logits/chosen": -2.7124109268188477,
      "logits/rejected": -2.499246835708618,
      "logps/chosen": -166.232421875,
      "logps/rejected": -175.13565063476562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9603477716445923,
      "rewards/margins": 9.445279121398926,
      "rewards/rejected": -10.40562629699707,
      "step": 2906
    },
    {
      "epoch": 1.1628,
      "grad_norm": 3.115453004837036,
      "learning_rate": 6.125333333333334e-07,
      "logits/chosen": -2.607529640197754,
      "logits/rejected": -2.437183141708374,
      "logps/chosen": -126.9489974975586,
      "logps/rejected": -119.99858093261719,
      "loss": 0.0137,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4318393468856812,
      "rewards/margins": 5.206309795379639,
      "rewards/rejected": -6.638149261474609,
      "step": 2907
    },
    {
      "epoch": 1.1632,
      "grad_norm": 0.04840277507901192,
      "learning_rate": 6.124000000000001e-07,
      "logits/chosen": -2.8318748474121094,
      "logits/rejected": -2.116197109222412,
      "logps/chosen": -79.23580169677734,
      "logps/rejected": -146.90252685546875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0593159198760986,
      "rewards/margins": 9.260797500610352,
      "rewards/rejected": -8.201481819152832,
      "step": 2908
    },
    {
      "epoch": 1.1636,
      "grad_norm": 4.160308361053467,
      "learning_rate": 6.122666666666666e-07,
      "logits/chosen": -3.0993990898132324,
      "logits/rejected": -2.9625766277313232,
      "logps/chosen": -97.54994201660156,
      "logps/rejected": -56.01276397705078,
      "loss": 0.0331,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0094724893569946,
      "rewards/margins": 3.859515428543091,
      "rewards/rejected": -2.8500428199768066,
      "step": 2909
    },
    {
      "epoch": 1.164,
      "grad_norm": 0.4754965007305145,
      "learning_rate": 6.121333333333332e-07,
      "logits/chosen": -2.6606860160827637,
      "logits/rejected": -2.1407127380371094,
      "logps/chosen": -75.97030639648438,
      "logps/rejected": -131.02218627929688,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09604716300964355,
      "rewards/margins": 7.901425361633301,
      "rewards/rejected": -7.8053789138793945,
      "step": 2910
    },
    {
      "epoch": 1.1644,
      "grad_norm": 32.69775390625,
      "learning_rate": 6.119999999999999e-07,
      "logits/chosen": -2.7338576316833496,
      "logits/rejected": -1.9901965856552124,
      "logps/chosen": -140.09896850585938,
      "logps/rejected": -131.6029052734375,
      "loss": 0.182,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7943267822265625,
      "rewards/margins": 5.820257186889648,
      "rewards/rejected": -6.614584445953369,
      "step": 2911
    },
    {
      "epoch": 1.1648,
      "grad_norm": 1.3299294710159302,
      "learning_rate": 6.118666666666666e-07,
      "logits/chosen": -3.109589099884033,
      "logits/rejected": -2.9315624237060547,
      "logps/chosen": -86.87857055664062,
      "logps/rejected": -115.84480285644531,
      "loss": 0.0134,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.787060558795929,
      "rewards/margins": 7.272759437561035,
      "rewards/rejected": -6.485698699951172,
      "step": 2912
    },
    {
      "epoch": 1.1652,
      "grad_norm": 0.010428088717162609,
      "learning_rate": 6.117333333333333e-07,
      "logits/chosen": -2.728567600250244,
      "logits/rejected": -1.8802037239074707,
      "logps/chosen": -158.83432006835938,
      "logps/rejected": -175.12701416015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9063476324081421,
      "rewards/margins": 10.186838150024414,
      "rewards/rejected": -11.093186378479004,
      "step": 2913
    },
    {
      "epoch": 1.1656,
      "grad_norm": 24.649555206298828,
      "learning_rate": 6.116e-07,
      "logits/chosen": -2.84177827835083,
      "logits/rejected": -2.982161045074463,
      "logps/chosen": -186.564208984375,
      "logps/rejected": -90.57728576660156,
      "loss": 0.1727,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5184303522109985,
      "rewards/margins": 3.6731033325195312,
      "rewards/rejected": -5.19153356552124,
      "step": 2914
    },
    {
      "epoch": 1.166,
      "grad_norm": 1.0920275449752808,
      "learning_rate": 6.114666666666667e-07,
      "logits/chosen": -2.8673057556152344,
      "logits/rejected": -2.755690097808838,
      "logps/chosen": -88.53772735595703,
      "logps/rejected": -90.91930389404297,
      "loss": 0.0109,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7308441400527954,
      "rewards/margins": 4.579122543334961,
      "rewards/rejected": -5.309966087341309,
      "step": 2915
    },
    {
      "epoch": 1.1663999999999999,
      "grad_norm": 0.022180983796715736,
      "learning_rate": 6.113333333333333e-07,
      "logits/chosen": -2.829148769378662,
      "logits/rejected": -2.1495461463928223,
      "logps/chosen": -139.30628967285156,
      "logps/rejected": -152.26815795898438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8193621039390564,
      "rewards/margins": 9.769644737243652,
      "rewards/rejected": -8.95028305053711,
      "step": 2916
    },
    {
      "epoch": 1.1668,
      "grad_norm": 0.06770146638154984,
      "learning_rate": 6.112e-07,
      "logits/chosen": -3.0215983390808105,
      "logits/rejected": -2.6009254455566406,
      "logps/chosen": -77.90168762207031,
      "logps/rejected": -148.18777465820312,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.34693145751953125,
      "rewards/margins": 7.859476089477539,
      "rewards/rejected": -8.20640754699707,
      "step": 2917
    },
    {
      "epoch": 1.1672,
      "grad_norm": 0.36681029200553894,
      "learning_rate": 6.110666666666667e-07,
      "logits/chosen": -3.212801456451416,
      "logits/rejected": -2.467515230178833,
      "logps/chosen": -74.19427490234375,
      "logps/rejected": -112.22319793701172,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8920333981513977,
      "rewards/margins": 6.67352294921875,
      "rewards/rejected": -7.565556526184082,
      "step": 2918
    },
    {
      "epoch": 1.1676,
      "grad_norm": 1.6229983568191528,
      "learning_rate": 6.109333333333334e-07,
      "logits/chosen": -2.9056396484375,
      "logits/rejected": -3.1298999786376953,
      "logps/chosen": -90.13018798828125,
      "logps/rejected": -96.45005798339844,
      "loss": 0.0184,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0731605589389801,
      "rewards/margins": 6.572021961212158,
      "rewards/rejected": -6.6451826095581055,
      "step": 2919
    },
    {
      "epoch": 1.168,
      "grad_norm": 0.11180632561445236,
      "learning_rate": 6.107999999999999e-07,
      "logits/chosen": -2.5418238639831543,
      "logits/rejected": -1.7544548511505127,
      "logps/chosen": -144.20346069335938,
      "logps/rejected": -140.76141357421875,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3346710205078125,
      "rewards/margins": 7.813080310821533,
      "rewards/rejected": -9.147750854492188,
      "step": 2920
    },
    {
      "epoch": 1.1684,
      "grad_norm": 0.6213987469673157,
      "learning_rate": 6.106666666666666e-07,
      "logits/chosen": -3.216188430786133,
      "logits/rejected": -2.8245484828948975,
      "logps/chosen": -116.03578186035156,
      "logps/rejected": -119.62116241455078,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0009143948554992676,
      "rewards/margins": 7.546449184417725,
      "rewards/rejected": -7.545535087585449,
      "step": 2921
    },
    {
      "epoch": 1.1688,
      "grad_norm": 0.05829630792140961,
      "learning_rate": 6.105333333333333e-07,
      "logits/chosen": -2.407073974609375,
      "logits/rejected": -1.835481882095337,
      "logps/chosen": -141.58489990234375,
      "logps/rejected": -195.27755737304688,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.126900553703308,
      "rewards/margins": 11.478130340576172,
      "rewards/rejected": -10.35123062133789,
      "step": 2922
    },
    {
      "epoch": 1.1692,
      "grad_norm": 0.187739297747612,
      "learning_rate": 6.104e-07,
      "logits/chosen": -2.9968061447143555,
      "logits/rejected": -2.694836378097534,
      "logps/chosen": -33.333717346191406,
      "logps/rejected": -122.57162475585938,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9935585260391235,
      "rewards/margins": 7.309096336364746,
      "rewards/rejected": -6.315537452697754,
      "step": 2923
    },
    {
      "epoch": 1.1696,
      "grad_norm": 0.19842597842216492,
      "learning_rate": 6.102666666666666e-07,
      "logits/chosen": -2.6471376419067383,
      "logits/rejected": -2.1218929290771484,
      "logps/chosen": -123.98272705078125,
      "logps/rejected": -158.01773071289062,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9013705253601074,
      "rewards/margins": 6.487039566040039,
      "rewards/rejected": -8.388410568237305,
      "step": 2924
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.07389383018016815,
      "learning_rate": 6.101333333333333e-07,
      "logits/chosen": -2.5780506134033203,
      "logits/rejected": -1.842339277267456,
      "logps/chosen": -118.73020935058594,
      "logps/rejected": -150.89793395996094,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2532764673233032,
      "rewards/margins": 8.33495044708252,
      "rewards/rejected": -8.081673622131348,
      "step": 2925
    },
    {
      "epoch": 1.1703999999999999,
      "grad_norm": 0.08810918033123016,
      "learning_rate": 6.1e-07,
      "logits/chosen": -2.723660707473755,
      "logits/rejected": -1.880878210067749,
      "logps/chosen": -87.39797973632812,
      "logps/rejected": -155.458740234375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0966339111328125,
      "rewards/margins": 9.597976684570312,
      "rewards/rejected": -9.5013427734375,
      "step": 2926
    },
    {
      "epoch": 1.1708,
      "grad_norm": 3.2137978076934814,
      "learning_rate": 6.098666666666667e-07,
      "logits/chosen": -2.1801834106445312,
      "logits/rejected": -1.610445261001587,
      "logps/chosen": -250.16070556640625,
      "logps/rejected": -191.2808380126953,
      "loss": 0.0183,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6139709949493408,
      "rewards/margins": 6.292695999145508,
      "rewards/rejected": -7.906667232513428,
      "step": 2927
    },
    {
      "epoch": 1.1712,
      "grad_norm": 0.012434604577720165,
      "learning_rate": 6.097333333333334e-07,
      "logits/chosen": -2.640535831451416,
      "logits/rejected": -2.1227805614471436,
      "logps/chosen": -157.97457885742188,
      "logps/rejected": -213.1720733642578,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.1409804821014404,
      "rewards/margins": 9.96737289428711,
      "rewards/rejected": -12.108353614807129,
      "step": 2928
    },
    {
      "epoch": 1.1716,
      "grad_norm": 10.721916198730469,
      "learning_rate": 6.096e-07,
      "logits/chosen": -3.2240753173828125,
      "logits/rejected": -3.140437126159668,
      "logps/chosen": -84.37081909179688,
      "logps/rejected": -93.8082504272461,
      "loss": 0.0949,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5876872539520264,
      "rewards/margins": 6.213616371154785,
      "rewards/rejected": -5.62592887878418,
      "step": 2929
    },
    {
      "epoch": 1.172,
      "grad_norm": 0.22885078191757202,
      "learning_rate": 6.094666666666666e-07,
      "logits/chosen": -2.4576807022094727,
      "logits/rejected": -1.956382393836975,
      "logps/chosen": -162.12060546875,
      "logps/rejected": -197.89425659179688,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12939989566802979,
      "rewards/margins": 6.847272872924805,
      "rewards/rejected": -6.7178730964660645,
      "step": 2930
    },
    {
      "epoch": 1.1724,
      "grad_norm": 0.0073290071450173855,
      "learning_rate": 6.093333333333332e-07,
      "logits/chosen": -2.6886000633239746,
      "logits/rejected": -1.7904267311096191,
      "logps/chosen": -82.04656219482422,
      "logps/rejected": -176.81283569335938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.522076368331909,
      "rewards/margins": 12.440032958984375,
      "rewards/rejected": -9.917957305908203,
      "step": 2931
    },
    {
      "epoch": 1.1728,
      "grad_norm": 0.003418321255594492,
      "learning_rate": 6.091999999999999e-07,
      "logits/chosen": -3.0069241523742676,
      "logits/rejected": -2.299900531768799,
      "logps/chosen": -75.9678726196289,
      "logps/rejected": -222.5365753173828,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.362031102180481,
      "rewards/margins": 11.941730499267578,
      "rewards/rejected": -13.30376148223877,
      "step": 2932
    },
    {
      "epoch": 1.1732,
      "grad_norm": 0.01394735649228096,
      "learning_rate": 6.090666666666666e-07,
      "logits/chosen": -3.062588691711426,
      "logits/rejected": -2.3182754516601562,
      "logps/chosen": -78.53010559082031,
      "logps/rejected": -130.97354125976562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0866096019744873,
      "rewards/margins": 9.529708862304688,
      "rewards/rejected": -8.443099021911621,
      "step": 2933
    },
    {
      "epoch": 1.1736,
      "grad_norm": 3.556018114089966,
      "learning_rate": 6.089333333333333e-07,
      "logits/chosen": -2.844529628753662,
      "logits/rejected": -2.64500093460083,
      "logps/chosen": -70.79579162597656,
      "logps/rejected": -105.29722595214844,
      "loss": 0.02,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.37949371337890625,
      "rewards/margins": 4.811567306518555,
      "rewards/rejected": -4.432073593139648,
      "step": 2934
    },
    {
      "epoch": 1.174,
      "grad_norm": 0.03381124511361122,
      "learning_rate": 6.088e-07,
      "logits/chosen": -3.050990104675293,
      "logits/rejected": -2.7247395515441895,
      "logps/chosen": -125.00970458984375,
      "logps/rejected": -198.83335876464844,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.39296719431877136,
      "rewards/margins": 8.799766540527344,
      "rewards/rejected": -9.192733764648438,
      "step": 2935
    },
    {
      "epoch": 1.1743999999999999,
      "grad_norm": 0.18134921789169312,
      "learning_rate": 6.086666666666667e-07,
      "logits/chosen": -3.450564384460449,
      "logits/rejected": -3.1691651344299316,
      "logps/chosen": -57.128662109375,
      "logps/rejected": -118.34286499023438,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6971441507339478,
      "rewards/margins": 7.545570373535156,
      "rewards/rejected": -6.848426818847656,
      "step": 2936
    },
    {
      "epoch": 1.1748,
      "grad_norm": 0.396305114030838,
      "learning_rate": 6.085333333333334e-07,
      "logits/chosen": -2.9414660930633545,
      "logits/rejected": -2.06203556060791,
      "logps/chosen": -79.67268371582031,
      "logps/rejected": -108.84182739257812,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9753715991973877,
      "rewards/margins": 7.601600646972656,
      "rewards/rejected": -5.626229286193848,
      "step": 2937
    },
    {
      "epoch": 1.1752,
      "grad_norm": 0.9015027284622192,
      "learning_rate": 6.084000000000001e-07,
      "logits/chosen": -2.906827449798584,
      "logits/rejected": -2.2783055305480957,
      "logps/chosen": -110.74346160888672,
      "logps/rejected": -151.26712036132812,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7552112340927124,
      "rewards/margins": 9.433980941772461,
      "rewards/rejected": -8.6787691116333,
      "step": 2938
    },
    {
      "epoch": 1.1756,
      "grad_norm": 1.1989288330078125,
      "learning_rate": 6.082666666666666e-07,
      "logits/chosen": -2.8987674713134766,
      "logits/rejected": -2.9976658821105957,
      "logps/chosen": -73.91853332519531,
      "logps/rejected": -129.79635620117188,
      "loss": 0.0073,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6318104267120361,
      "rewards/margins": 5.65993595123291,
      "rewards/rejected": -7.291746139526367,
      "step": 2939
    },
    {
      "epoch": 1.176,
      "grad_norm": 0.0031994387973099947,
      "learning_rate": 6.081333333333332e-07,
      "logits/chosen": -2.543703556060791,
      "logits/rejected": -1.5833725929260254,
      "logps/chosen": -107.39547729492188,
      "logps/rejected": -180.72930908203125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5651655197143555,
      "rewards/margins": 11.698274612426758,
      "rewards/rejected": -11.133109092712402,
      "step": 2940
    },
    {
      "epoch": 1.1764000000000001,
      "grad_norm": 0.18399544060230255,
      "learning_rate": 6.079999999999999e-07,
      "logits/chosen": -2.7978029251098633,
      "logits/rejected": -2.211268424987793,
      "logps/chosen": -101.00601196289062,
      "logps/rejected": -154.98947143554688,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19723129272460938,
      "rewards/margins": 9.582830429077148,
      "rewards/rejected": -9.385599136352539,
      "step": 2941
    },
    {
      "epoch": 1.1768,
      "grad_norm": 0.0056878915056586266,
      "learning_rate": 6.078666666666666e-07,
      "logits/chosen": -2.829052209854126,
      "logits/rejected": -2.1127514839172363,
      "logps/chosen": -156.9854736328125,
      "logps/rejected": -222.02496337890625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.411261796951294,
      "rewards/margins": 11.038333892822266,
      "rewards/rejected": -12.449596405029297,
      "step": 2942
    },
    {
      "epoch": 1.1772,
      "grad_norm": 0.35132113099098206,
      "learning_rate": 6.077333333333333e-07,
      "logits/chosen": -3.1802759170532227,
      "logits/rejected": -2.66343355178833,
      "logps/chosen": -55.99028015136719,
      "logps/rejected": -95.24597930908203,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.09816628694534302,
      "rewards/margins": 5.595428466796875,
      "rewards/rejected": -5.693594932556152,
      "step": 2943
    },
    {
      "epoch": 1.1776,
      "grad_norm": 0.010479087941348553,
      "learning_rate": 6.076e-07,
      "logits/chosen": -2.782411575317383,
      "logits/rejected": -2.5066962242126465,
      "logps/chosen": -121.78325653076172,
      "logps/rejected": -151.8245849609375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2962465286254883,
      "rewards/margins": 9.929443359375,
      "rewards/rejected": -10.225689888000488,
      "step": 2944
    },
    {
      "epoch": 1.178,
      "grad_norm": 0.028462925925850868,
      "learning_rate": 6.074666666666667e-07,
      "logits/chosen": -2.8073067665100098,
      "logits/rejected": -2.209803581237793,
      "logps/chosen": -134.751953125,
      "logps/rejected": -141.45831298828125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6716408133506775,
      "rewards/margins": 8.789073944091797,
      "rewards/rejected": -8.117433547973633,
      "step": 2945
    },
    {
      "epoch": 1.1784,
      "grad_norm": 0.06130623444914818,
      "learning_rate": 6.073333333333333e-07,
      "logits/chosen": -2.8129096031188965,
      "logits/rejected": -2.1912221908569336,
      "logps/chosen": -73.22251892089844,
      "logps/rejected": -120.989990234375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5210906863212585,
      "rewards/margins": 7.982064247131348,
      "rewards/rejected": -7.460973739624023,
      "step": 2946
    },
    {
      "epoch": 1.1788,
      "grad_norm": 0.6291252374649048,
      "learning_rate": 6.072e-07,
      "logits/chosen": -2.770667552947998,
      "logits/rejected": -1.9101202487945557,
      "logps/chosen": -164.97268676757812,
      "logps/rejected": -152.51638793945312,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.845380425453186,
      "rewards/margins": 8.626302719116211,
      "rewards/rejected": -9.47168254852295,
      "step": 2947
    },
    {
      "epoch": 1.1792,
      "grad_norm": 0.3616061806678772,
      "learning_rate": 6.070666666666666e-07,
      "logits/chosen": -3.102285861968994,
      "logits/rejected": -2.628251075744629,
      "logps/chosen": -111.63374328613281,
      "logps/rejected": -146.47421264648438,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.02206951379776001,
      "rewards/margins": 9.08370590209961,
      "rewards/rejected": -9.105775833129883,
      "step": 2948
    },
    {
      "epoch": 1.1796,
      "grad_norm": 102.7119140625,
      "learning_rate": 6.069333333333333e-07,
      "logits/chosen": -2.5509033203125,
      "logits/rejected": -2.4398012161254883,
      "logps/chosen": -243.7693634033203,
      "logps/rejected": -115.30689239501953,
      "loss": 1.5035,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -5.331794738769531,
      "rewards/margins": -1.0513672828674316,
      "rewards/rejected": -4.280427932739258,
      "step": 2949
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.03459378331899643,
      "learning_rate": 6.068e-07,
      "logits/chosen": -2.929473876953125,
      "logits/rejected": -2.282136917114258,
      "logps/chosen": -40.63654708862305,
      "logps/rejected": -178.6249237060547,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6189301013946533,
      "rewards/margins": 10.533323287963867,
      "rewards/rejected": -8.914392471313477,
      "step": 2950
    },
    {
      "epoch": 1.1804000000000001,
      "grad_norm": 0.0562390573322773,
      "learning_rate": 6.066666666666666e-07,
      "logits/chosen": -2.6251943111419678,
      "logits/rejected": -2.3494739532470703,
      "logps/chosen": -117.90715026855469,
      "logps/rejected": -168.78842163085938,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.46597564220428467,
      "rewards/margins": 10.230926513671875,
      "rewards/rejected": -10.696901321411133,
      "step": 2951
    },
    {
      "epoch": 1.1808,
      "grad_norm": 0.1522437036037445,
      "learning_rate": 6.065333333333333e-07,
      "logits/chosen": -2.8489837646484375,
      "logits/rejected": -2.387848377227783,
      "logps/chosen": -115.23880004882812,
      "logps/rejected": -141.4550018310547,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5528492331504822,
      "rewards/margins": 7.995999336242676,
      "rewards/rejected": -7.443150043487549,
      "step": 2952
    },
    {
      "epoch": 1.1812,
      "grad_norm": 0.13442829251289368,
      "learning_rate": 6.064e-07,
      "logits/chosen": -3.2011234760284424,
      "logits/rejected": -2.6619315147399902,
      "logps/chosen": -54.69151306152344,
      "logps/rejected": -119.18156433105469,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05122852697968483,
      "rewards/margins": 6.990516662597656,
      "rewards/rejected": -6.939288139343262,
      "step": 2953
    },
    {
      "epoch": 1.1816,
      "grad_norm": 3.5330581665039062,
      "learning_rate": 6.062666666666666e-07,
      "logits/chosen": -2.782125949859619,
      "logits/rejected": -2.1892929077148438,
      "logps/chosen": -86.87649536132812,
      "logps/rejected": -140.62896728515625,
      "loss": 0.0342,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.45449909567832947,
      "rewards/margins": 7.121798038482666,
      "rewards/rejected": -7.576297283172607,
      "step": 2954
    },
    {
      "epoch": 1.182,
      "grad_norm": 0.26135602593421936,
      "learning_rate": 6.061333333333333e-07,
      "logits/chosen": -3.2041091918945312,
      "logits/rejected": -2.596583604812622,
      "logps/chosen": -62.631324768066406,
      "logps/rejected": -99.60543823242188,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.365928292274475,
      "rewards/margins": 7.4172587394714355,
      "rewards/rejected": -6.05133056640625,
      "step": 2955
    },
    {
      "epoch": 1.1824,
      "grad_norm": 0.0026838432531803846,
      "learning_rate": 6.06e-07,
      "logits/chosen": -2.8221499919891357,
      "logits/rejected": -2.142294406890869,
      "logps/chosen": -92.74309539794922,
      "logps/rejected": -147.03514099121094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.902806043624878,
      "rewards/margins": 11.519390106201172,
      "rewards/rejected": -9.616582870483398,
      "step": 2956
    },
    {
      "epoch": 1.1828,
      "grad_norm": 0.35882535576820374,
      "learning_rate": 6.058666666666666e-07,
      "logits/chosen": -2.9263687133789062,
      "logits/rejected": -2.565595865249634,
      "logps/chosen": -106.84660339355469,
      "logps/rejected": -201.13156127929688,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.01101837307214737,
      "rewards/margins": 7.696307182312012,
      "rewards/rejected": -7.707324981689453,
      "step": 2957
    },
    {
      "epoch": 1.1832,
      "grad_norm": 0.3388369679450989,
      "learning_rate": 6.057333333333333e-07,
      "logits/chosen": -2.9225759506225586,
      "logits/rejected": -2.2787089347839355,
      "logps/chosen": -75.46925354003906,
      "logps/rejected": -106.20328521728516,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7011457681655884,
      "rewards/margins": 8.401742935180664,
      "rewards/rejected": -6.700596809387207,
      "step": 2958
    },
    {
      "epoch": 1.1836,
      "grad_norm": 2.5758721828460693,
      "learning_rate": 6.056e-07,
      "logits/chosen": -3.102466344833374,
      "logits/rejected": -3.162977695465088,
      "logps/chosen": -75.65157318115234,
      "logps/rejected": -95.21857452392578,
      "loss": 0.0268,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.480778455734253,
      "rewards/margins": 4.000521659851074,
      "rewards/rejected": -5.481299877166748,
      "step": 2959
    },
    {
      "epoch": 1.184,
      "grad_norm": 5.326289176940918,
      "learning_rate": 6.054666666666667e-07,
      "logits/chosen": -2.1662983894348145,
      "logits/rejected": -1.6931843757629395,
      "logps/chosen": -186.79342651367188,
      "logps/rejected": -130.89488220214844,
      "loss": 0.0313,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.2115142345428467,
      "rewards/margins": 5.083431243896484,
      "rewards/rejected": -8.294944763183594,
      "step": 2960
    },
    {
      "epoch": 1.1844000000000001,
      "grad_norm": 0.032880447804927826,
      "learning_rate": 6.053333333333332e-07,
      "logits/chosen": -2.5350184440612793,
      "logits/rejected": -1.9096063375473022,
      "logps/chosen": -150.68734741210938,
      "logps/rejected": -218.94500732421875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8565651178359985,
      "rewards/margins": 10.478395462036133,
      "rewards/rejected": -11.3349609375,
      "step": 2961
    },
    {
      "epoch": 1.1848,
      "grad_norm": 0.09777870029211044,
      "learning_rate": 6.051999999999999e-07,
      "logits/chosen": -2.8544700145721436,
      "logits/rejected": -1.8848782777786255,
      "logps/chosen": -91.93878173828125,
      "logps/rejected": -162.83673095703125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2898488938808441,
      "rewards/margins": 9.27149486541748,
      "rewards/rejected": -9.561344146728516,
      "step": 2962
    },
    {
      "epoch": 1.1852,
      "grad_norm": 0.04774002358317375,
      "learning_rate": 6.050666666666666e-07,
      "logits/chosen": -2.683831214904785,
      "logits/rejected": -1.9593515396118164,
      "logps/chosen": -117.16278839111328,
      "logps/rejected": -188.53384399414062,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10812035202980042,
      "rewards/margins": 10.071231842041016,
      "rewards/rejected": -10.179351806640625,
      "step": 2963
    },
    {
      "epoch": 1.1856,
      "grad_norm": 0.024892795830965042,
      "learning_rate": 6.049333333333333e-07,
      "logits/chosen": -2.528325319290161,
      "logits/rejected": -1.5547211170196533,
      "logps/chosen": -120.54431915283203,
      "logps/rejected": -179.04757690429688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6327335238456726,
      "rewards/margins": 10.591789245605469,
      "rewards/rejected": -9.959054946899414,
      "step": 2964
    },
    {
      "epoch": 1.186,
      "grad_norm": 0.0013187522999942303,
      "learning_rate": 6.048e-07,
      "logits/chosen": -2.8900468349456787,
      "logits/rejected": -2.231093168258667,
      "logps/chosen": -91.60624694824219,
      "logps/rejected": -174.99557495117188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9820938110351562,
      "rewards/margins": 12.078454971313477,
      "rewards/rejected": -11.09636116027832,
      "step": 2965
    },
    {
      "epoch": 1.1864,
      "grad_norm": 108.91460418701172,
      "learning_rate": 6.046666666666667e-07,
      "logits/chosen": -2.547708034515381,
      "logits/rejected": -2.548708915710449,
      "logps/chosen": -318.40032958984375,
      "logps/rejected": -152.74420166015625,
      "loss": 0.5771,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -8.289019584655762,
      "rewards/margins": 1.1547574996948242,
      "rewards/rejected": -9.443777084350586,
      "step": 2966
    },
    {
      "epoch": 1.1868,
      "grad_norm": 0.006615776568651199,
      "learning_rate": 6.045333333333333e-07,
      "logits/chosen": -2.5851755142211914,
      "logits/rejected": -1.8787373304367065,
      "logps/chosen": -87.19743347167969,
      "logps/rejected": -137.17721557617188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0336551666259766,
      "rewards/margins": 10.334822654724121,
      "rewards/rejected": -9.301167488098145,
      "step": 2967
    },
    {
      "epoch": 1.1872,
      "grad_norm": 5.373056411743164,
      "learning_rate": 6.044e-07,
      "logits/chosen": -2.929903507232666,
      "logits/rejected": -2.719644069671631,
      "logps/chosen": -128.33041381835938,
      "logps/rejected": -99.74859619140625,
      "loss": 0.0366,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2812182903289795,
      "rewards/margins": 4.587047576904297,
      "rewards/rejected": -4.8682661056518555,
      "step": 2968
    },
    {
      "epoch": 1.1876,
      "grad_norm": 0.005684772040694952,
      "learning_rate": 6.042666666666666e-07,
      "logits/chosen": -2.7944111824035645,
      "logits/rejected": -1.7817131280899048,
      "logps/chosen": -72.93464660644531,
      "logps/rejected": -224.6433868408203,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8447292447090149,
      "rewards/margins": 12.206464767456055,
      "rewards/rejected": -11.361734390258789,
      "step": 2969
    },
    {
      "epoch": 1.188,
      "grad_norm": 0.01156576070934534,
      "learning_rate": 6.041333333333333e-07,
      "logits/chosen": -2.753742218017578,
      "logits/rejected": -2.0304512977600098,
      "logps/chosen": -97.96904754638672,
      "logps/rejected": -162.03948974609375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6604437232017517,
      "rewards/margins": 9.82735824584961,
      "rewards/rejected": -9.166914939880371,
      "step": 2970
    },
    {
      "epoch": 1.1884000000000001,
      "grad_norm": 0.7347707748413086,
      "learning_rate": 6.04e-07,
      "logits/chosen": -2.4277939796447754,
      "logits/rejected": -2.0714471340179443,
      "logps/chosen": -152.21533203125,
      "logps/rejected": -120.98088836669922,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8213348388671875,
      "rewards/margins": 5.760445594787598,
      "rewards/rejected": -6.581780433654785,
      "step": 2971
    },
    {
      "epoch": 1.1888,
      "grad_norm": 1.1395078897476196,
      "learning_rate": 6.038666666666666e-07,
      "logits/chosen": -3.190842628479004,
      "logits/rejected": -2.634298324584961,
      "logps/chosen": -60.10959243774414,
      "logps/rejected": -145.00677490234375,
      "loss": 0.0093,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1027948260307312,
      "rewards/margins": 8.292452812194824,
      "rewards/rejected": -8.395247459411621,
      "step": 2972
    },
    {
      "epoch": 1.1892,
      "grad_norm": 0.13157300651073456,
      "learning_rate": 6.037333333333333e-07,
      "logits/chosen": -2.483952522277832,
      "logits/rejected": -1.9419341087341309,
      "logps/chosen": -185.46798706054688,
      "logps/rejected": -159.41978454589844,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6369224786758423,
      "rewards/margins": 8.063340187072754,
      "rewards/rejected": -8.700263023376465,
      "step": 2973
    },
    {
      "epoch": 1.1896,
      "grad_norm": 0.5435788035392761,
      "learning_rate": 6.036e-07,
      "logits/chosen": -2.5645081996917725,
      "logits/rejected": -2.082650661468506,
      "logps/chosen": -249.60287475585938,
      "logps/rejected": -137.06869506835938,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5768547058105469,
      "rewards/margins": 5.780904769897461,
      "rewards/rejected": -7.357759475708008,
      "step": 2974
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.0016174216289073229,
      "learning_rate": 6.034666666666667e-07,
      "logits/chosen": -2.6251537799835205,
      "logits/rejected": -1.7327078580856323,
      "logps/chosen": -47.557289123535156,
      "logps/rejected": -180.9004364013672,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8436920642852783,
      "rewards/margins": 12.14579963684082,
      "rewards/rejected": -11.302106857299805,
      "step": 2975
    },
    {
      "epoch": 1.1904,
      "grad_norm": 0.038265857845544815,
      "learning_rate": 6.033333333333333e-07,
      "logits/chosen": -2.9237494468688965,
      "logits/rejected": -2.058372735977173,
      "logps/chosen": -80.50013732910156,
      "logps/rejected": -109.03269958496094,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7131286859512329,
      "rewards/margins": 7.799160957336426,
      "rewards/rejected": -7.086032867431641,
      "step": 2976
    },
    {
      "epoch": 1.1908,
      "grad_norm": 0.23520831763744354,
      "learning_rate": 6.031999999999999e-07,
      "logits/chosen": -2.4851179122924805,
      "logits/rejected": -1.7942394018173218,
      "logps/chosen": -164.43067932128906,
      "logps/rejected": -163.6983642578125,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4413429498672485,
      "rewards/margins": 8.053842544555664,
      "rewards/rejected": -9.495184898376465,
      "step": 2977
    },
    {
      "epoch": 1.1912,
      "grad_norm": 0.8255900144577026,
      "learning_rate": 6.030666666666666e-07,
      "logits/chosen": -3.068661689758301,
      "logits/rejected": -2.5851073265075684,
      "logps/chosen": -96.55215454101562,
      "logps/rejected": -114.68344116210938,
      "loss": 0.0091,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09275970607995987,
      "rewards/margins": 7.247723579406738,
      "rewards/rejected": -7.154963493347168,
      "step": 2978
    },
    {
      "epoch": 1.1916,
      "grad_norm": 2.049576997756958,
      "learning_rate": 6.029333333333333e-07,
      "logits/chosen": -2.66978120803833,
      "logits/rejected": -2.2035279273986816,
      "logps/chosen": -95.21083068847656,
      "logps/rejected": -130.49600219726562,
      "loss": 0.0249,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.40244722366333,
      "rewards/margins": 6.591716766357422,
      "rewards/rejected": -7.994163513183594,
      "step": 2979
    },
    {
      "epoch": 1.192,
      "grad_norm": 0.009832224808633327,
      "learning_rate": 6.028e-07,
      "logits/chosen": -2.722856283187866,
      "logits/rejected": -2.332538604736328,
      "logps/chosen": -78.12262725830078,
      "logps/rejected": -196.45379638671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2368175983428955,
      "rewards/margins": 10.042573928833008,
      "rewards/rejected": -8.805756568908691,
      "step": 2980
    },
    {
      "epoch": 1.1924,
      "grad_norm": 0.02226252667605877,
      "learning_rate": 6.026666666666667e-07,
      "logits/chosen": -2.5357563495635986,
      "logits/rejected": -2.1251091957092285,
      "logps/chosen": -199.13771057128906,
      "logps/rejected": -232.62452697753906,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.032406806945801,
      "rewards/margins": 9.065820693969727,
      "rewards/rejected": -13.098227500915527,
      "step": 2981
    },
    {
      "epoch": 1.1928,
      "grad_norm": 0.0118349464610219,
      "learning_rate": 6.025333333333334e-07,
      "logits/chosen": -2.7754011154174805,
      "logits/rejected": -2.2253875732421875,
      "logps/chosen": -50.61492919921875,
      "logps/rejected": -185.3726806640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3658462762832642,
      "rewards/margins": 10.309873580932617,
      "rewards/rejected": -8.9440279006958,
      "step": 2982
    },
    {
      "epoch": 1.1932,
      "grad_norm": 0.047035012394189835,
      "learning_rate": 6.024e-07,
      "logits/chosen": -2.8476524353027344,
      "logits/rejected": -2.374202251434326,
      "logps/chosen": -63.85321044921875,
      "logps/rejected": -163.6447296142578,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2349649667739868,
      "rewards/margins": 9.443023681640625,
      "rewards/rejected": -8.208059310913086,
      "step": 2983
    },
    {
      "epoch": 1.1936,
      "grad_norm": 0.7684289813041687,
      "learning_rate": 6.022666666666666e-07,
      "logits/chosen": -2.826211452484131,
      "logits/rejected": -2.463629722595215,
      "logps/chosen": -117.3641586303711,
      "logps/rejected": -133.78182983398438,
      "loss": 0.0086,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4350520968437195,
      "rewards/margins": 7.646511554718018,
      "rewards/rejected": -8.081563949584961,
      "step": 2984
    },
    {
      "epoch": 1.194,
      "grad_norm": 0.15654397010803223,
      "learning_rate": 6.021333333333332e-07,
      "logits/chosen": -3.0575926303863525,
      "logits/rejected": -2.313715934753418,
      "logps/chosen": -106.990234375,
      "logps/rejected": -114.75921630859375,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6284893155097961,
      "rewards/margins": 6.752631664276123,
      "rewards/rejected": -6.124142646789551,
      "step": 2985
    },
    {
      "epoch": 1.1944,
      "grad_norm": 0.1719432771205902,
      "learning_rate": 6.019999999999999e-07,
      "logits/chosen": -2.759319305419922,
      "logits/rejected": -1.913062572479248,
      "logps/chosen": -105.3992919921875,
      "logps/rejected": -156.87454223632812,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14269834756851196,
      "rewards/margins": 9.673639297485352,
      "rewards/rejected": -9.530941009521484,
      "step": 2986
    },
    {
      "epoch": 1.1948,
      "grad_norm": 1.0093642473220825,
      "learning_rate": 6.018666666666666e-07,
      "logits/chosen": -2.9046874046325684,
      "logits/rejected": -2.1707763671875,
      "logps/chosen": -103.205810546875,
      "logps/rejected": -136.879638671875,
      "loss": 0.0062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8115299940109253,
      "rewards/margins": 8.741050720214844,
      "rewards/rejected": -7.929520606994629,
      "step": 2987
    },
    {
      "epoch": 1.1952,
      "grad_norm": 0.10273988544940948,
      "learning_rate": 6.017333333333333e-07,
      "logits/chosen": -2.9004743099212646,
      "logits/rejected": -2.125471353530884,
      "logps/chosen": -101.62289428710938,
      "logps/rejected": -147.5808563232422,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8459092974662781,
      "rewards/margins": 8.305143356323242,
      "rewards/rejected": -7.459234237670898,
      "step": 2988
    },
    {
      "epoch": 1.1956,
      "grad_norm": 0.005603841971606016,
      "learning_rate": 6.016e-07,
      "logits/chosen": -2.562547206878662,
      "logits/rejected": -1.7298369407653809,
      "logps/chosen": -95.55799865722656,
      "logps/rejected": -206.97024536132812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3228885531425476,
      "rewards/margins": 11.108333587646484,
      "rewards/rejected": -10.785445213317871,
      "step": 2989
    },
    {
      "epoch": 1.196,
      "grad_norm": 0.00830832589417696,
      "learning_rate": 6.014666666666667e-07,
      "logits/chosen": -2.7245140075683594,
      "logits/rejected": -1.9634654521942139,
      "logps/chosen": -77.72407531738281,
      "logps/rejected": -192.7156524658203,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.49854776263237,
      "rewards/margins": 11.584301948547363,
      "rewards/rejected": -12.082849502563477,
      "step": 2990
    },
    {
      "epoch": 1.1964,
      "grad_norm": 0.023013269528746605,
      "learning_rate": 6.013333333333334e-07,
      "logits/chosen": -3.0950117111206055,
      "logits/rejected": -2.335139751434326,
      "logps/chosen": -61.357879638671875,
      "logps/rejected": -144.50680541992188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45649453997612,
      "rewards/margins": 10.303167343139648,
      "rewards/rejected": -9.846673011779785,
      "step": 2991
    },
    {
      "epoch": 1.1968,
      "grad_norm": 1.443858027458191,
      "learning_rate": 6.012e-07,
      "logits/chosen": -2.9269561767578125,
      "logits/rejected": -2.252112865447998,
      "logps/chosen": -108.88628387451172,
      "logps/rejected": -110.92845916748047,
      "loss": 0.0088,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1393272876739502,
      "rewards/margins": 8.614872932434082,
      "rewards/rejected": -7.475545883178711,
      "step": 2992
    },
    {
      "epoch": 1.1972,
      "grad_norm": 0.03914043307304382,
      "learning_rate": 6.010666666666666e-07,
      "logits/chosen": -3.1899447441101074,
      "logits/rejected": -2.4384994506835938,
      "logps/chosen": -61.89614486694336,
      "logps/rejected": -164.70162963867188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5683687329292297,
      "rewards/margins": 9.602641105651855,
      "rewards/rejected": -9.034272193908691,
      "step": 2993
    },
    {
      "epoch": 1.1976,
      "grad_norm": 0.10470525175333023,
      "learning_rate": 6.009333333333333e-07,
      "logits/chosen": -2.52042818069458,
      "logits/rejected": -2.1484193801879883,
      "logps/chosen": -129.632080078125,
      "logps/rejected": -146.499267578125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5255650281906128,
      "rewards/margins": 7.566432952880859,
      "rewards/rejected": -9.091998100280762,
      "step": 2994
    },
    {
      "epoch": 1.198,
      "grad_norm": 1.064139723777771,
      "learning_rate": 6.007999999999999e-07,
      "logits/chosen": -2.715888500213623,
      "logits/rejected": -2.0830609798431396,
      "logps/chosen": -130.44967651367188,
      "logps/rejected": -103.57965850830078,
      "loss": 0.0093,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1691856384277344,
      "rewards/margins": 5.463043212890625,
      "rewards/rejected": -6.632228851318359,
      "step": 2995
    },
    {
      "epoch": 1.1984,
      "grad_norm": 0.03467269986867905,
      "learning_rate": 6.006666666666666e-07,
      "logits/chosen": -2.7687323093414307,
      "logits/rejected": -1.9852442741394043,
      "logps/chosen": -127.09215545654297,
      "logps/rejected": -199.03941345214844,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2268695831298828,
      "rewards/margins": 8.511724472045898,
      "rewards/rejected": -8.738594055175781,
      "step": 2996
    },
    {
      "epoch": 1.1988,
      "grad_norm": 0.11970525979995728,
      "learning_rate": 6.005333333333333e-07,
      "logits/chosen": -2.6207456588745117,
      "logits/rejected": -2.2768139839172363,
      "logps/chosen": -120.11148834228516,
      "logps/rejected": -144.7099609375,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9685951471328735,
      "rewards/margins": 8.55610466003418,
      "rewards/rejected": -7.587510108947754,
      "step": 2997
    },
    {
      "epoch": 1.1992,
      "grad_norm": 0.09423942863941193,
      "learning_rate": 6.004e-07,
      "logits/chosen": -2.8246822357177734,
      "logits/rejected": -2.3637733459472656,
      "logps/chosen": -103.78299713134766,
      "logps/rejected": -190.00289916992188,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1449474096298218,
      "rewards/margins": 8.327771186828613,
      "rewards/rejected": -7.182823181152344,
      "step": 2998
    },
    {
      "epoch": 1.1996,
      "grad_norm": 0.0484481044113636,
      "learning_rate": 6.002666666666666e-07,
      "logits/chosen": -3.253066062927246,
      "logits/rejected": -2.450347423553467,
      "logps/chosen": -48.80809783935547,
      "logps/rejected": -137.0819549560547,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7315269708633423,
      "rewards/margins": 8.724896430969238,
      "rewards/rejected": -7.993370056152344,
      "step": 2999
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.631075382232666,
      "learning_rate": 6.001333333333333e-07,
      "logits/chosen": -2.7868940830230713,
      "logits/rejected": -2.4474728107452393,
      "logps/chosen": -91.37921142578125,
      "logps/rejected": -147.38250732421875,
      "loss": 0.0138,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019464682787656784,
      "rewards/margins": 6.121271133422852,
      "rewards/rejected": -6.101806640625,
      "step": 3000
    },
    {
      "epoch": 1.2004,
      "grad_norm": 5.9870734214782715,
      "learning_rate": 6e-07,
      "logits/chosen": -2.6238861083984375,
      "logits/rejected": -2.1343793869018555,
      "logps/chosen": -159.3928680419922,
      "logps/rejected": -163.3321990966797,
      "loss": 0.0378,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.0318198204040527,
      "rewards/margins": 5.88612174987793,
      "rewards/rejected": -8.91794204711914,
      "step": 3001
    },
    {
      "epoch": 1.2008,
      "grad_norm": 0.07711124420166016,
      "learning_rate": 5.998666666666667e-07,
      "logits/chosen": -2.5942530632019043,
      "logits/rejected": -1.517056941986084,
      "logps/chosen": -202.31968688964844,
      "logps/rejected": -163.74066162109375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.17664335668087006,
      "rewards/margins": 8.305822372436523,
      "rewards/rejected": -8.482465744018555,
      "step": 3002
    },
    {
      "epoch": 1.2012,
      "grad_norm": 0.05565935745835304,
      "learning_rate": 5.997333333333334e-07,
      "logits/chosen": -3.052443027496338,
      "logits/rejected": -2.5518898963928223,
      "logps/chosen": -115.43699645996094,
      "logps/rejected": -144.44435119628906,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.589847207069397,
      "rewards/margins": 9.668856620788574,
      "rewards/rejected": -9.079009056091309,
      "step": 3003
    },
    {
      "epoch": 1.2016,
      "grad_norm": 0.2784235179424286,
      "learning_rate": 5.995999999999999e-07,
      "logits/chosen": -2.733198642730713,
      "logits/rejected": -2.2452926635742188,
      "logps/chosen": -118.16664123535156,
      "logps/rejected": -152.33367919921875,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7516646981239319,
      "rewards/margins": 7.339932441711426,
      "rewards/rejected": -8.091596603393555,
      "step": 3004
    },
    {
      "epoch": 1.202,
      "grad_norm": 0.003318067407235503,
      "learning_rate": 5.994666666666666e-07,
      "logits/chosen": -2.854548931121826,
      "logits/rejected": -2.2074878215789795,
      "logps/chosen": -96.08766174316406,
      "logps/rejected": -177.89700317382812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6333611011505127,
      "rewards/margins": 11.602495193481445,
      "rewards/rejected": -9.969133377075195,
      "step": 3005
    },
    {
      "epoch": 1.2024,
      "grad_norm": 1.6190534830093384,
      "learning_rate": 5.993333333333333e-07,
      "logits/chosen": -3.0653839111328125,
      "logits/rejected": -2.5484399795532227,
      "logps/chosen": -103.13964080810547,
      "logps/rejected": -135.18405151367188,
      "loss": 0.0117,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.4868226051330566,
      "rewards/margins": 5.907896995544434,
      "rewards/rejected": -8.394720077514648,
      "step": 3006
    },
    {
      "epoch": 1.2028,
      "grad_norm": 0.0025853165425360203,
      "learning_rate": 5.991999999999999e-07,
      "logits/chosen": -2.7019028663635254,
      "logits/rejected": -2.1196320056915283,
      "logps/chosen": -180.613037109375,
      "logps/rejected": -287.067138671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0240936279296875,
      "rewards/margins": 12.719328880310059,
      "rewards/rejected": -13.743422508239746,
      "step": 3007
    },
    {
      "epoch": 1.2032,
      "grad_norm": 63.635841369628906,
      "learning_rate": 5.990666666666666e-07,
      "logits/chosen": -2.3248722553253174,
      "logits/rejected": -1.8717515468597412,
      "logps/chosen": -171.90359497070312,
      "logps/rejected": -181.89036560058594,
      "loss": 0.2904,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.878899335861206,
      "rewards/margins": 7.164881229400635,
      "rewards/rejected": -11.043780326843262,
      "step": 3008
    },
    {
      "epoch": 1.2036,
      "grad_norm": 1.159687876701355,
      "learning_rate": 5.989333333333333e-07,
      "logits/chosen": -2.7033722400665283,
      "logits/rejected": -2.3015408515930176,
      "logps/chosen": -95.98772430419922,
      "logps/rejected": -137.8490753173828,
      "loss": 0.0109,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10780659317970276,
      "rewards/margins": 8.833166122436523,
      "rewards/rejected": -8.725359916687012,
      "step": 3009
    },
    {
      "epoch": 1.204,
      "grad_norm": 0.05740390345454216,
      "learning_rate": 5.988e-07,
      "logits/chosen": -2.9658164978027344,
      "logits/rejected": -2.36348295211792,
      "logps/chosen": -85.72557830810547,
      "logps/rejected": -142.0269775390625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38080137968063354,
      "rewards/margins": 9.003036499023438,
      "rewards/rejected": -8.622234344482422,
      "step": 3010
    },
    {
      "epoch": 1.2044,
      "grad_norm": 0.1993129700422287,
      "learning_rate": 5.986666666666667e-07,
      "logits/chosen": -3.175539016723633,
      "logits/rejected": -2.6869964599609375,
      "logps/chosen": -58.75201416015625,
      "logps/rejected": -113.9134521484375,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4999802112579346,
      "rewards/margins": 8.025266647338867,
      "rewards/rejected": -6.525286674499512,
      "step": 3011
    },
    {
      "epoch": 1.2048,
      "grad_norm": 60.8609733581543,
      "learning_rate": 5.985333333333334e-07,
      "logits/chosen": -2.678424835205078,
      "logits/rejected": -1.9331276416778564,
      "logps/chosen": -204.98655700683594,
      "logps/rejected": -133.48672485351562,
      "loss": 0.2003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.152975082397461,
      "rewards/margins": 4.001158237457275,
      "rewards/rejected": -8.154132843017578,
      "step": 3012
    },
    {
      "epoch": 1.2052,
      "grad_norm": 0.027239704504609108,
      "learning_rate": 5.984000000000001e-07,
      "logits/chosen": -3.096007823944092,
      "logits/rejected": -2.3091630935668945,
      "logps/chosen": -65.04011535644531,
      "logps/rejected": -143.55198669433594,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9418119788169861,
      "rewards/margins": 9.68692684173584,
      "rewards/rejected": -8.745115280151367,
      "step": 3013
    },
    {
      "epoch": 1.2056,
      "grad_norm": 0.008539073169231415,
      "learning_rate": 5.982666666666665e-07,
      "logits/chosen": -2.838642120361328,
      "logits/rejected": -2.466329574584961,
      "logps/chosen": -99.75753021240234,
      "logps/rejected": -199.81594848632812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5817863941192627,
      "rewards/margins": 11.779888153076172,
      "rewards/rejected": -10.198101997375488,
      "step": 3014
    },
    {
      "epoch": 1.206,
      "grad_norm": 0.000615783385001123,
      "learning_rate": 5.981333333333332e-07,
      "logits/chosen": -2.538106918334961,
      "logits/rejected": -1.8150436878204346,
      "logps/chosen": -97.32377624511719,
      "logps/rejected": -212.73121643066406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0364575386047363,
      "rewards/margins": 13.007190704345703,
      "rewards/rejected": -10.970733642578125,
      "step": 3015
    },
    {
      "epoch": 1.2064,
      "grad_norm": 0.27742165327072144,
      "learning_rate": 5.979999999999999e-07,
      "logits/chosen": -3.237901449203491,
      "logits/rejected": -2.768585205078125,
      "logps/chosen": -57.99907684326172,
      "logps/rejected": -91.97889709472656,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9276092648506165,
      "rewards/margins": 6.160301685333252,
      "rewards/rejected": -5.232692718505859,
      "step": 3016
    },
    {
      "epoch": 1.2068,
      "grad_norm": 0.22958983480930328,
      "learning_rate": 5.978666666666666e-07,
      "logits/chosen": -2.9499592781066895,
      "logits/rejected": -2.344914436340332,
      "logps/chosen": -65.87562561035156,
      "logps/rejected": -135.6997833251953,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3283289074897766,
      "rewards/margins": 7.492310523986816,
      "rewards/rejected": -7.820639610290527,
      "step": 3017
    },
    {
      "epoch": 1.2072,
      "grad_norm": 0.12462601065635681,
      "learning_rate": 5.977333333333333e-07,
      "logits/chosen": -2.7633373737335205,
      "logits/rejected": -2.232072591781616,
      "logps/chosen": -116.78549194335938,
      "logps/rejected": -192.5382843017578,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9957783222198486,
      "rewards/margins": 8.056439399719238,
      "rewards/rejected": -9.052217483520508,
      "step": 3018
    },
    {
      "epoch": 1.2076,
      "grad_norm": 0.012406612746417522,
      "learning_rate": 5.976e-07,
      "logits/chosen": -3.2079076766967773,
      "logits/rejected": -2.690786361694336,
      "logps/chosen": -51.64627456665039,
      "logps/rejected": -155.77993774414062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2608883380889893,
      "rewards/margins": 10.116570472717285,
      "rewards/rejected": -8.855682373046875,
      "step": 3019
    },
    {
      "epoch": 1.208,
      "grad_norm": 5.729250431060791,
      "learning_rate": 5.974666666666667e-07,
      "logits/chosen": -2.9659783840179443,
      "logits/rejected": -2.7921371459960938,
      "logps/chosen": -94.24649047851562,
      "logps/rejected": -96.27000427246094,
      "loss": 0.0386,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4885423183441162,
      "rewards/margins": 4.536201477050781,
      "rewards/rejected": -6.024744033813477,
      "step": 3020
    },
    {
      "epoch": 1.2084,
      "grad_norm": 0.3491339087486267,
      "learning_rate": 5.973333333333334e-07,
      "logits/chosen": -3.039850950241089,
      "logits/rejected": -2.583621025085449,
      "logps/chosen": -74.73528289794922,
      "logps/rejected": -123.39007568359375,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8318981528282166,
      "rewards/margins": 7.154306888580322,
      "rewards/rejected": -7.986205101013184,
      "step": 3021
    },
    {
      "epoch": 1.2088,
      "grad_norm": 0.14785628020763397,
      "learning_rate": 5.972e-07,
      "logits/chosen": -2.7634501457214355,
      "logits/rejected": -2.3839640617370605,
      "logps/chosen": -141.83859252929688,
      "logps/rejected": -135.8804931640625,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9024299383163452,
      "rewards/margins": 6.7996721267700195,
      "rewards/rejected": -7.702101707458496,
      "step": 3022
    },
    {
      "epoch": 1.2092,
      "grad_norm": 0.0006452585803344846,
      "learning_rate": 5.970666666666666e-07,
      "logits/chosen": -2.7382633686065674,
      "logits/rejected": -1.923496961593628,
      "logps/chosen": -78.98318481445312,
      "logps/rejected": -203.80543518066406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.408104658126831,
      "rewards/margins": 13.625261306762695,
      "rewards/rejected": -12.217156410217285,
      "step": 3023
    },
    {
      "epoch": 1.2096,
      "grad_norm": 0.2068842351436615,
      "learning_rate": 5.969333333333333e-07,
      "logits/chosen": -2.8379039764404297,
      "logits/rejected": -2.6932034492492676,
      "logps/chosen": -82.3952407836914,
      "logps/rejected": -116.172119140625,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10745009779930115,
      "rewards/margins": 6.924770355224609,
      "rewards/rejected": -6.817319869995117,
      "step": 3024
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.6528525352478027,
      "learning_rate": 5.967999999999999e-07,
      "logits/chosen": -2.8028345108032227,
      "logits/rejected": -2.629624605178833,
      "logps/chosen": -94.44784545898438,
      "logps/rejected": -128.83218383789062,
      "loss": 0.0131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9727069735527039,
      "rewards/margins": 7.037792682647705,
      "rewards/rejected": -8.010499954223633,
      "step": 3025
    },
    {
      "epoch": 1.2104,
      "grad_norm": 0.08418956398963928,
      "learning_rate": 5.966666666666666e-07,
      "logits/chosen": -2.6148715019226074,
      "logits/rejected": -2.0330886840820312,
      "logps/chosen": -107.94068145751953,
      "logps/rejected": -136.08517456054688,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6805351376533508,
      "rewards/margins": 8.09364128112793,
      "rewards/rejected": -8.774177551269531,
      "step": 3026
    },
    {
      "epoch": 1.2107999999999999,
      "grad_norm": 0.015336333774030209,
      "learning_rate": 5.965333333333333e-07,
      "logits/chosen": -2.8053016662597656,
      "logits/rejected": -2.1665120124816895,
      "logps/chosen": -72.32684326171875,
      "logps/rejected": -142.00717163085938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.744755506515503,
      "rewards/margins": 9.20856761932373,
      "rewards/rejected": -7.463811874389648,
      "step": 3027
    },
    {
      "epoch": 1.2112,
      "grad_norm": 0.38237228989601135,
      "learning_rate": 5.964e-07,
      "logits/chosen": -2.3606061935424805,
      "logits/rejected": -1.703138828277588,
      "logps/chosen": -179.0970458984375,
      "logps/rejected": -183.0244140625,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.691760301589966,
      "rewards/margins": 6.30747127532959,
      "rewards/rejected": -9.999231338500977,
      "step": 3028
    },
    {
      "epoch": 1.2116,
      "grad_norm": 6.256494045257568,
      "learning_rate": 5.962666666666666e-07,
      "logits/chosen": -2.4916017055511475,
      "logits/rejected": -1.8220895528793335,
      "logps/chosen": -180.88983154296875,
      "logps/rejected": -149.87210083007812,
      "loss": 0.0289,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.4055733680725098,
      "rewards/margins": 5.7843546867370605,
      "rewards/rejected": -8.18992805480957,
      "step": 3029
    },
    {
      "epoch": 1.212,
      "grad_norm": 2.447531223297119,
      "learning_rate": 5.961333333333333e-07,
      "logits/chosen": -2.8266987800598145,
      "logits/rejected": -2.4047961235046387,
      "logps/chosen": -100.24375915527344,
      "logps/rejected": -168.36843872070312,
      "loss": 0.0204,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2515072226524353,
      "rewards/margins": 9.149930000305176,
      "rewards/rejected": -9.401437759399414,
      "step": 3030
    },
    {
      "epoch": 1.2124,
      "grad_norm": 0.4977656900882721,
      "learning_rate": 5.96e-07,
      "logits/chosen": -2.9050662517547607,
      "logits/rejected": -2.353334426879883,
      "logps/chosen": -106.34185791015625,
      "logps/rejected": -187.56011962890625,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8569997549057007,
      "rewards/margins": 10.339016914367676,
      "rewards/rejected": -11.196016311645508,
      "step": 3031
    },
    {
      "epoch": 1.2128,
      "grad_norm": 1.6803361177444458,
      "learning_rate": 5.958666666666666e-07,
      "logits/chosen": -3.363844394683838,
      "logits/rejected": -2.928281307220459,
      "logps/chosen": -45.991798400878906,
      "logps/rejected": -94.11207580566406,
      "loss": 0.0169,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.06126232445240021,
      "rewards/margins": 4.784343242645264,
      "rewards/rejected": -4.845605850219727,
      "step": 3032
    },
    {
      "epoch": 1.2132,
      "grad_norm": 0.007550693582743406,
      "learning_rate": 5.957333333333333e-07,
      "logits/chosen": -2.4823997020721436,
      "logits/rejected": -1.7253518104553223,
      "logps/chosen": -240.64242553710938,
      "logps/rejected": -216.04815673828125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07238537073135376,
      "rewards/margins": 12.141782760620117,
      "rewards/rejected": -12.069397926330566,
      "step": 3033
    },
    {
      "epoch": 1.2136,
      "grad_norm": 0.0660354420542717,
      "learning_rate": 5.956e-07,
      "logits/chosen": -3.1633777618408203,
      "logits/rejected": -2.615036725997925,
      "logps/chosen": -56.56974792480469,
      "logps/rejected": -125.42432403564453,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1412791013717651,
      "rewards/margins": 9.454239845275879,
      "rewards/rejected": -8.312960624694824,
      "step": 3034
    },
    {
      "epoch": 1.214,
      "grad_norm": 0.8133895993232727,
      "learning_rate": 5.954666666666667e-07,
      "logits/chosen": -3.261469841003418,
      "logits/rejected": -2.8727967739105225,
      "logps/chosen": -52.670413970947266,
      "logps/rejected": -83.35429382324219,
      "loss": 0.0083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.24583682417869568,
      "rewards/margins": 4.791152000427246,
      "rewards/rejected": -5.036989212036133,
      "step": 3035
    },
    {
      "epoch": 1.2144,
      "grad_norm": 1.0776532888412476,
      "learning_rate": 5.953333333333333e-07,
      "logits/chosen": -2.752580165863037,
      "logits/rejected": -2.561577081680298,
      "logps/chosen": -110.74244689941406,
      "logps/rejected": -90.71536254882812,
      "loss": 0.0105,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12419739365577698,
      "rewards/margins": 5.094439506530762,
      "rewards/rejected": -4.970242023468018,
      "step": 3036
    },
    {
      "epoch": 1.2147999999999999,
      "grad_norm": 0.04747910425066948,
      "learning_rate": 5.951999999999999e-07,
      "logits/chosen": -3.1397957801818848,
      "logits/rejected": -2.5127711296081543,
      "logps/chosen": -51.48358154296875,
      "logps/rejected": -127.8501205444336,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7452396154403687,
      "rewards/margins": 9.876127243041992,
      "rewards/rejected": -8.130887031555176,
      "step": 3037
    },
    {
      "epoch": 1.2152,
      "grad_norm": 0.006133577320724726,
      "learning_rate": 5.950666666666666e-07,
      "logits/chosen": -2.8137221336364746,
      "logits/rejected": -1.9992575645446777,
      "logps/chosen": -82.2738037109375,
      "logps/rejected": -140.42735290527344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0030962228775024,
      "rewards/margins": 10.224174499511719,
      "rewards/rejected": -9.221077919006348,
      "step": 3038
    },
    {
      "epoch": 1.2156,
      "grad_norm": 2.473112106323242,
      "learning_rate": 5.949333333333333e-07,
      "logits/chosen": -2.7766313552856445,
      "logits/rejected": -2.4281516075134277,
      "logps/chosen": -110.77710723876953,
      "logps/rejected": -118.07366943359375,
      "loss": 0.0216,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.651178240776062,
      "rewards/margins": 5.111698150634766,
      "rewards/rejected": -6.762876510620117,
      "step": 3039
    },
    {
      "epoch": 1.216,
      "grad_norm": 1.857494831085205,
      "learning_rate": 5.948e-07,
      "logits/chosen": -2.756751775741577,
      "logits/rejected": -2.6588022708892822,
      "logps/chosen": -124.13758850097656,
      "logps/rejected": -127.48236846923828,
      "loss": 0.0169,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.7944016456604004,
      "rewards/margins": 4.072440147399902,
      "rewards/rejected": -6.866842269897461,
      "step": 3040
    },
    {
      "epoch": 1.2164,
      "grad_norm": 0.3244209587574005,
      "learning_rate": 5.946666666666667e-07,
      "logits/chosen": -3.108941078186035,
      "logits/rejected": -2.8561902046203613,
      "logps/chosen": -94.44010162353516,
      "logps/rejected": -120.70843505859375,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3974401652812958,
      "rewards/margins": 7.900069236755371,
      "rewards/rejected": -7.502628326416016,
      "step": 3041
    },
    {
      "epoch": 1.2168,
      "grad_norm": 1.4506932497024536,
      "learning_rate": 5.945333333333333e-07,
      "logits/chosen": -3.010493278503418,
      "logits/rejected": -3.1368751525878906,
      "logps/chosen": -93.76722717285156,
      "logps/rejected": -98.69505310058594,
      "loss": 0.0125,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5495277643203735,
      "rewards/margins": 5.446481704711914,
      "rewards/rejected": -5.996009349822998,
      "step": 3042
    },
    {
      "epoch": 1.2172,
      "grad_norm": 3.7689361572265625,
      "learning_rate": 5.944e-07,
      "logits/chosen": -2.797408103942871,
      "logits/rejected": -2.156261444091797,
      "logps/chosen": -75.69952392578125,
      "logps/rejected": -127.46177673339844,
      "loss": 0.0382,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.34682807326316833,
      "rewards/margins": 7.072967529296875,
      "rewards/rejected": -7.419795513153076,
      "step": 3043
    },
    {
      "epoch": 1.2176,
      "grad_norm": 1.9326138496398926,
      "learning_rate": 5.942666666666667e-07,
      "logits/chosen": -2.8614635467529297,
      "logits/rejected": -2.5974392890930176,
      "logps/chosen": -102.44520568847656,
      "logps/rejected": -110.03932189941406,
      "loss": 0.021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7124996781349182,
      "rewards/margins": 6.189046859741211,
      "rewards/rejected": -5.4765472412109375,
      "step": 3044
    },
    {
      "epoch": 1.218,
      "grad_norm": 0.6953473091125488,
      "learning_rate": 5.941333333333333e-07,
      "logits/chosen": -3.0698442459106445,
      "logits/rejected": -2.6529159545898438,
      "logps/chosen": -63.58986282348633,
      "logps/rejected": -104.56629943847656,
      "loss": 0.0055,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.236745685338974,
      "rewards/margins": 6.422382831573486,
      "rewards/rejected": -6.659128189086914,
      "step": 3045
    },
    {
      "epoch": 1.2184,
      "grad_norm": 0.0026979625690728426,
      "learning_rate": 5.939999999999999e-07,
      "logits/chosen": -2.6619369983673096,
      "logits/rejected": -1.780035138130188,
      "logps/chosen": -91.15670776367188,
      "logps/rejected": -184.88694763183594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1311954259872437,
      "rewards/margins": 11.730009078979492,
      "rewards/rejected": -10.598814010620117,
      "step": 3046
    },
    {
      "epoch": 1.2187999999999999,
      "grad_norm": 0.39838123321533203,
      "learning_rate": 5.938666666666666e-07,
      "logits/chosen": -3.1289525032043457,
      "logits/rejected": -2.555644989013672,
      "logps/chosen": -103.32588195800781,
      "logps/rejected": -121.85208129882812,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2172969579696655,
      "rewards/margins": 5.7298736572265625,
      "rewards/rejected": -6.947170257568359,
      "step": 3047
    },
    {
      "epoch": 1.2192,
      "grad_norm": 0.04737711325287819,
      "learning_rate": 5.937333333333333e-07,
      "logits/chosen": -2.723282814025879,
      "logits/rejected": -1.942735195159912,
      "logps/chosen": -90.07826232910156,
      "logps/rejected": -140.7534942626953,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.011880874633789062,
      "rewards/margins": 8.249436378479004,
      "rewards/rejected": -8.261317253112793,
      "step": 3048
    },
    {
      "epoch": 1.2196,
      "grad_norm": 0.020475240424275398,
      "learning_rate": 5.936e-07,
      "logits/chosen": -3.1995654106140137,
      "logits/rejected": -2.695187568664551,
      "logps/chosen": -58.60615921020508,
      "logps/rejected": -161.86117553710938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2026905119419098,
      "rewards/margins": 9.606114387512207,
      "rewards/rejected": -9.808805465698242,
      "step": 3049
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.01354260928928852,
      "learning_rate": 5.934666666666667e-07,
      "logits/chosen": -2.7981815338134766,
      "logits/rejected": -2.361103057861328,
      "logps/chosen": -122.11992645263672,
      "logps/rejected": -210.26597595214844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0359033346176147,
      "rewards/margins": 11.36788558959961,
      "rewards/rejected": -12.403789520263672,
      "step": 3050
    },
    {
      "epoch": 1.2204,
      "grad_norm": 1.0649858713150024,
      "learning_rate": 5.933333333333334e-07,
      "logits/chosen": -3.0682263374328613,
      "logits/rejected": -2.698343515396118,
      "logps/chosen": -62.78460693359375,
      "logps/rejected": -115.51905822753906,
      "loss": 0.0074,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6873675584793091,
      "rewards/margins": 6.699456691741943,
      "rewards/rejected": -6.012088775634766,
      "step": 3051
    },
    {
      "epoch": 1.2208,
      "grad_norm": 0.008414855226874352,
      "learning_rate": 5.931999999999999e-07,
      "logits/chosen": -2.754967212677002,
      "logits/rejected": -2.2714757919311523,
      "logps/chosen": -158.85281372070312,
      "logps/rejected": -151.95794677734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4894065856933594,
      "rewards/margins": 10.029818534851074,
      "rewards/rejected": -9.540411949157715,
      "step": 3052
    },
    {
      "epoch": 1.2212,
      "grad_norm": 0.5263964533805847,
      "learning_rate": 5.930666666666666e-07,
      "logits/chosen": -2.7914488315582275,
      "logits/rejected": -2.3589282035827637,
      "logps/chosen": -70.0631103515625,
      "logps/rejected": -136.46218872070312,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.047753930091858,
      "rewards/margins": 9.520751953125,
      "rewards/rejected": -8.472997665405273,
      "step": 3053
    },
    {
      "epoch": 1.2216,
      "grad_norm": 1.6218229532241821,
      "learning_rate": 5.929333333333333e-07,
      "logits/chosen": -2.7369489669799805,
      "logits/rejected": -2.2055060863494873,
      "logps/chosen": -129.81716918945312,
      "logps/rejected": -148.25274658203125,
      "loss": 0.0128,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.42529380321502686,
      "rewards/margins": 9.169768333435059,
      "rewards/rejected": -9.595062255859375,
      "step": 3054
    },
    {
      "epoch": 1.222,
      "grad_norm": 6.471554279327393,
      "learning_rate": 5.928e-07,
      "logits/chosen": -2.805299758911133,
      "logits/rejected": -2.192512273788452,
      "logps/chosen": -158.00059509277344,
      "logps/rejected": -212.45089721679688,
      "loss": 0.03,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1005983352661133,
      "rewards/margins": 9.887554168701172,
      "rewards/rejected": -10.988153457641602,
      "step": 3055
    },
    {
      "epoch": 1.2224,
      "grad_norm": 0.02605440840125084,
      "learning_rate": 5.926666666666667e-07,
      "logits/chosen": -2.548818588256836,
      "logits/rejected": -2.3271098136901855,
      "logps/chosen": -120.97418975830078,
      "logps/rejected": -180.13150024414062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7633446455001831,
      "rewards/margins": 10.38520622253418,
      "rewards/rejected": -9.621862411499023,
      "step": 3056
    },
    {
      "epoch": 1.2227999999999999,
      "grad_norm": 0.029055297374725342,
      "learning_rate": 5.925333333333333e-07,
      "logits/chosen": -2.986191749572754,
      "logits/rejected": -2.7312045097351074,
      "logps/chosen": -68.82029724121094,
      "logps/rejected": -103.98419189453125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9993822574615479,
      "rewards/margins": 8.309927940368652,
      "rewards/rejected": -6.310545921325684,
      "step": 3057
    },
    {
      "epoch": 1.2232,
      "grad_norm": 0.18875497579574585,
      "learning_rate": 5.924e-07,
      "logits/chosen": -3.066620349884033,
      "logits/rejected": -2.6781578063964844,
      "logps/chosen": -101.22233581542969,
      "logps/rejected": -204.8773193359375,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25236475467681885,
      "rewards/margins": 10.232284545898438,
      "rewards/rejected": -9.97991943359375,
      "step": 3058
    },
    {
      "epoch": 1.2236,
      "grad_norm": 0.0007021085475571454,
      "learning_rate": 5.922666666666667e-07,
      "logits/chosen": -2.635873794555664,
      "logits/rejected": -1.7366176843643188,
      "logps/chosen": -78.38927459716797,
      "logps/rejected": -232.76585388183594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2189688682556152,
      "rewards/margins": 13.91620922088623,
      "rewards/rejected": -11.697240829467773,
      "step": 3059
    },
    {
      "epoch": 1.224,
      "grad_norm": 0.3425986170768738,
      "learning_rate": 5.921333333333333e-07,
      "logits/chosen": -2.693838119506836,
      "logits/rejected": -2.544935703277588,
      "logps/chosen": -169.1522216796875,
      "logps/rejected": -152.8032989501953,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.536638617515564,
      "rewards/margins": 8.458203315734863,
      "rewards/rejected": -8.994842529296875,
      "step": 3060
    },
    {
      "epoch": 1.2244,
      "grad_norm": 0.3175315260887146,
      "learning_rate": 5.919999999999999e-07,
      "logits/chosen": -2.641815185546875,
      "logits/rejected": -1.8498635292053223,
      "logps/chosen": -109.39315795898438,
      "logps/rejected": -138.94566345214844,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6624196767807007,
      "rewards/margins": 6.774631977081299,
      "rewards/rejected": -8.437051773071289,
      "step": 3061
    },
    {
      "epoch": 1.2248,
      "grad_norm": 17.43246078491211,
      "learning_rate": 5.918666666666666e-07,
      "logits/chosen": -2.9920973777770996,
      "logits/rejected": -2.92462158203125,
      "logps/chosen": -88.08604431152344,
      "logps/rejected": -103.6488037109375,
      "loss": 0.1557,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.260152816772461,
      "rewards/margins": 4.946033954620361,
      "rewards/rejected": -6.2061872482299805,
      "step": 3062
    },
    {
      "epoch": 1.2252,
      "grad_norm": 0.08556867390871048,
      "learning_rate": 5.917333333333333e-07,
      "logits/chosen": -2.8934764862060547,
      "logits/rejected": -2.247184991836548,
      "logps/chosen": -66.6209716796875,
      "logps/rejected": -169.68215942382812,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3489353358745575,
      "rewards/margins": 7.4141435623168945,
      "rewards/rejected": -7.065208435058594,
      "step": 3063
    },
    {
      "epoch": 1.2256,
      "grad_norm": 0.0030960245057940483,
      "learning_rate": 5.916e-07,
      "logits/chosen": -2.8436059951782227,
      "logits/rejected": -2.5325567722320557,
      "logps/chosen": -93.11857604980469,
      "logps/rejected": -183.1677703857422,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0563114881515503,
      "rewards/margins": 11.595560073852539,
      "rewards/rejected": -10.5392484664917,
      "step": 3064
    },
    {
      "epoch": 1.226,
      "grad_norm": 0.09585052728652954,
      "learning_rate": 5.914666666666667e-07,
      "logits/chosen": -3.104201555252075,
      "logits/rejected": -2.8212552070617676,
      "logps/chosen": -63.79855728149414,
      "logps/rejected": -120.29275512695312,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7461361289024353,
      "rewards/margins": 7.469606399536133,
      "rewards/rejected": -8.215742111206055,
      "step": 3065
    },
    {
      "epoch": 1.2264,
      "grad_norm": 0.011677578091621399,
      "learning_rate": 5.913333333333334e-07,
      "logits/chosen": -2.842623710632324,
      "logits/rejected": -2.2201972007751465,
      "logps/chosen": -96.57124328613281,
      "logps/rejected": -227.11282348632812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6149471402168274,
      "rewards/margins": 12.49817943572998,
      "rewards/rejected": -11.883232116699219,
      "step": 3066
    },
    {
      "epoch": 1.2268,
      "grad_norm": 1.0056594610214233,
      "learning_rate": 5.911999999999999e-07,
      "logits/chosen": -3.1022298336029053,
      "logits/rejected": -2.684401512145996,
      "logps/chosen": -70.13069152832031,
      "logps/rejected": -129.19705200195312,
      "loss": 0.0074,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2897750735282898,
      "rewards/margins": 7.913145065307617,
      "rewards/rejected": -7.623370170593262,
      "step": 3067
    },
    {
      "epoch": 1.2272,
      "grad_norm": 3.9212725162506104,
      "learning_rate": 5.910666666666666e-07,
      "logits/chosen": -2.9382245540618896,
      "logits/rejected": -2.2997074127197266,
      "logps/chosen": -155.6146240234375,
      "logps/rejected": -142.82122802734375,
      "loss": 0.0177,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3630397319793701,
      "rewards/margins": 5.842735290527344,
      "rewards/rejected": -7.205775260925293,
      "step": 3068
    },
    {
      "epoch": 1.2276,
      "grad_norm": 0.010440482757985592,
      "learning_rate": 5.909333333333333e-07,
      "logits/chosen": -3.211411952972412,
      "logits/rejected": -2.6325676441192627,
      "logps/chosen": -51.289520263671875,
      "logps/rejected": -168.28768920898438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.030559159815311432,
      "rewards/margins": 10.271369934082031,
      "rewards/rejected": -10.301929473876953,
      "step": 3069
    },
    {
      "epoch": 1.228,
      "grad_norm": 0.0013008886016905308,
      "learning_rate": 5.907999999999999e-07,
      "logits/chosen": -2.743417739868164,
      "logits/rejected": -2.307612419128418,
      "logps/chosen": -131.25045776367188,
      "logps/rejected": -203.89419555664062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.213334858417511,
      "rewards/margins": 12.047691345214844,
      "rewards/rejected": -11.834356307983398,
      "step": 3070
    },
    {
      "epoch": 1.2284,
      "grad_norm": 3.0501084327697754,
      "learning_rate": 5.906666666666666e-07,
      "logits/chosen": -2.4032700061798096,
      "logits/rejected": -1.9214370250701904,
      "logps/chosen": -142.3007049560547,
      "logps/rejected": -114.28620147705078,
      "loss": 0.0262,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3451240658760071,
      "rewards/margins": 5.915385723114014,
      "rewards/rejected": -5.570261478424072,
      "step": 3071
    },
    {
      "epoch": 1.2288000000000001,
      "grad_norm": 1.1736162900924683,
      "learning_rate": 5.905333333333333e-07,
      "logits/chosen": -3.070125102996826,
      "logits/rejected": -2.769036293029785,
      "logps/chosen": -81.30012512207031,
      "logps/rejected": -98.31986236572266,
      "loss": 0.0111,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7184129953384399,
      "rewards/margins": 4.497655868530273,
      "rewards/rejected": -5.216068744659424,
      "step": 3072
    },
    {
      "epoch": 1.2292,
      "grad_norm": 0.004105588421225548,
      "learning_rate": 5.904e-07,
      "logits/chosen": -2.5954465866088867,
      "logits/rejected": -1.7394990921020508,
      "logps/chosen": -98.82357788085938,
      "logps/rejected": -164.12698364257812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.960150122642517,
      "rewards/margins": 11.728513717651367,
      "rewards/rejected": -9.768362998962402,
      "step": 3073
    },
    {
      "epoch": 1.2296,
      "grad_norm": 0.25533413887023926,
      "learning_rate": 5.902666666666667e-07,
      "logits/chosen": -2.7953341007232666,
      "logits/rejected": -2.822019338607788,
      "logps/chosen": -125.03681182861328,
      "logps/rejected": -126.6522216796875,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6498361825942993,
      "rewards/margins": 6.292505264282227,
      "rewards/rejected": -7.942341327667236,
      "step": 3074
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.0026137791574001312,
      "learning_rate": 5.901333333333333e-07,
      "logits/chosen": -2.5341389179229736,
      "logits/rejected": -1.3859752416610718,
      "logps/chosen": -94.23399353027344,
      "logps/rejected": -199.95635986328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4189269542694092,
      "rewards/margins": 11.947561264038086,
      "rewards/rejected": -10.528633117675781,
      "step": 3075
    },
    {
      "epoch": 1.2304,
      "grad_norm": 0.007358128670603037,
      "learning_rate": 5.9e-07,
      "logits/chosen": -2.7269883155822754,
      "logits/rejected": -2.2405648231506348,
      "logps/chosen": -118.508056640625,
      "logps/rejected": -215.26901245117188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0147137641906738,
      "rewards/margins": 12.51046371459961,
      "rewards/rejected": -13.525177001953125,
      "step": 3076
    },
    {
      "epoch": 1.2308,
      "grad_norm": 0.011886445805430412,
      "learning_rate": 5.898666666666667e-07,
      "logits/chosen": -2.654283046722412,
      "logits/rejected": -1.8878130912780762,
      "logps/chosen": -99.41519165039062,
      "logps/rejected": -223.03749084472656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2813396453857422,
      "rewards/margins": 11.32916259765625,
      "rewards/rejected": -10.047822952270508,
      "step": 3077
    },
    {
      "epoch": 1.2312,
      "grad_norm": 0.14444005489349365,
      "learning_rate": 5.897333333333333e-07,
      "logits/chosen": -2.7481822967529297,
      "logits/rejected": -2.2800474166870117,
      "logps/chosen": -101.1240234375,
      "logps/rejected": -151.33001708984375,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4961986541748047,
      "rewards/margins": 9.635173797607422,
      "rewards/rejected": -8.138975143432617,
      "step": 3078
    },
    {
      "epoch": 1.2316,
      "grad_norm": 1.9796663522720337,
      "learning_rate": 5.896e-07,
      "logits/chosen": -3.0180530548095703,
      "logits/rejected": -2.769130229949951,
      "logps/chosen": -103.43606567382812,
      "logps/rejected": -108.06031799316406,
      "loss": 0.0132,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9731561541557312,
      "rewards/margins": 5.087730407714844,
      "rewards/rejected": -6.060886859893799,
      "step": 3079
    },
    {
      "epoch": 1.232,
      "grad_norm": 0.02150556445121765,
      "learning_rate": 5.894666666666666e-07,
      "logits/chosen": -3.053758144378662,
      "logits/rejected": -2.5329580307006836,
      "logps/chosen": -104.56553649902344,
      "logps/rejected": -196.24069213867188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10660172253847122,
      "rewards/margins": 10.266895294189453,
      "rewards/rejected": -10.160293579101562,
      "step": 3080
    },
    {
      "epoch": 1.2324,
      "grad_norm": 0.7241409420967102,
      "learning_rate": 5.893333333333333e-07,
      "logits/chosen": -3.220717430114746,
      "logits/rejected": -3.083014726638794,
      "logps/chosen": -52.066436767578125,
      "logps/rejected": -80.88945007324219,
      "loss": 0.0099,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7347219586372375,
      "rewards/margins": 5.337176322937012,
      "rewards/rejected": -4.60245418548584,
      "step": 3081
    },
    {
      "epoch": 1.2328000000000001,
      "grad_norm": 0.031923457980155945,
      "learning_rate": 5.891999999999999e-07,
      "logits/chosen": -2.8313910961151123,
      "logits/rejected": -2.153088092803955,
      "logps/chosen": -110.88349914550781,
      "logps/rejected": -156.94229125976562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40522539615631104,
      "rewards/margins": 9.923328399658203,
      "rewards/rejected": -9.51810359954834,
      "step": 3082
    },
    {
      "epoch": 1.2332,
      "grad_norm": 4.7277398109436035,
      "learning_rate": 5.890666666666666e-07,
      "logits/chosen": -2.913431406021118,
      "logits/rejected": -2.3440229892730713,
      "logps/chosen": -61.43242645263672,
      "logps/rejected": -124.44493103027344,
      "loss": 0.0449,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05463029444217682,
      "rewards/margins": 7.096129417419434,
      "rewards/rejected": -7.041499137878418,
      "step": 3083
    },
    {
      "epoch": 1.2336,
      "grad_norm": 0.003999939188361168,
      "learning_rate": 5.889333333333333e-07,
      "logits/chosen": -2.622199535369873,
      "logits/rejected": -1.6680032014846802,
      "logps/chosen": -122.50473022460938,
      "logps/rejected": -187.2404022216797,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0616848468780518,
      "rewards/margins": 12.651311874389648,
      "rewards/rejected": -11.58962631225586,
      "step": 3084
    },
    {
      "epoch": 1.234,
      "grad_norm": 0.004446382634341717,
      "learning_rate": 5.888e-07,
      "logits/chosen": -2.841742992401123,
      "logits/rejected": -2.1231601238250732,
      "logps/chosen": -87.31214904785156,
      "logps/rejected": -174.76168823242188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45022544264793396,
      "rewards/margins": 10.759481430053711,
      "rewards/rejected": -10.309255599975586,
      "step": 3085
    },
    {
      "epoch": 1.2344,
      "grad_norm": 0.32945722341537476,
      "learning_rate": 5.886666666666667e-07,
      "logits/chosen": -2.71755313873291,
      "logits/rejected": -2.4233851432800293,
      "logps/chosen": -152.45355224609375,
      "logps/rejected": -187.55552673339844,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.5966994762420654,
      "rewards/margins": 7.788876533508301,
      "rewards/rejected": -10.385576248168945,
      "step": 3086
    },
    {
      "epoch": 1.2348,
      "grad_norm": 0.0007118365610949695,
      "learning_rate": 5.885333333333334e-07,
      "logits/chosen": -2.4948530197143555,
      "logits/rejected": -1.8865916728973389,
      "logps/chosen": -104.51346588134766,
      "logps/rejected": -202.16107177734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.096221923828125,
      "rewards/margins": 12.985660552978516,
      "rewards/rejected": -10.88943862915039,
      "step": 3087
    },
    {
      "epoch": 1.2352,
      "grad_norm": 0.002289234194904566,
      "learning_rate": 5.884000000000001e-07,
      "logits/chosen": -2.7925190925598145,
      "logits/rejected": -2.140477418899536,
      "logps/chosen": -93.292724609375,
      "logps/rejected": -176.0604248046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3207430839538574,
      "rewards/margins": 11.583337783813477,
      "rewards/rejected": -9.262594223022461,
      "step": 3088
    },
    {
      "epoch": 1.2356,
      "grad_norm": 0.007068410515785217,
      "learning_rate": 5.882666666666666e-07,
      "logits/chosen": -3.1529393196105957,
      "logits/rejected": -2.5459656715393066,
      "logps/chosen": -67.13160705566406,
      "logps/rejected": -163.31570434570312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8057870864868164,
      "rewards/margins": 10.479991912841797,
      "rewards/rejected": -9.674205780029297,
      "step": 3089
    },
    {
      "epoch": 1.236,
      "grad_norm": 0.17776493728160858,
      "learning_rate": 5.881333333333332e-07,
      "logits/chosen": -2.8456692695617676,
      "logits/rejected": -2.36614990234375,
      "logps/chosen": -86.47459411621094,
      "logps/rejected": -141.4388427734375,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.07867011427879333,
      "rewards/margins": 8.584552764892578,
      "rewards/rejected": -8.663223266601562,
      "step": 3090
    },
    {
      "epoch": 1.2364,
      "grad_norm": 1.4551678895950317,
      "learning_rate": 5.879999999999999e-07,
      "logits/chosen": -2.78361177444458,
      "logits/rejected": -2.449252128601074,
      "logps/chosen": -151.6856689453125,
      "logps/rejected": -136.1945037841797,
      "loss": 0.0118,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3785862326622009,
      "rewards/margins": 6.496220588684082,
      "rewards/rejected": -6.1176347732543945,
      "step": 3091
    },
    {
      "epoch": 1.2368000000000001,
      "grad_norm": 0.19095154106616974,
      "learning_rate": 5.878666666666666e-07,
      "logits/chosen": -2.754309892654419,
      "logits/rejected": -2.618441104888916,
      "logps/chosen": -109.56376647949219,
      "logps/rejected": -124.02998352050781,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7322080731391907,
      "rewards/margins": 7.670573711395264,
      "rewards/rejected": -6.938365459442139,
      "step": 3092
    },
    {
      "epoch": 1.2372,
      "grad_norm": 0.2734483778476715,
      "learning_rate": 5.877333333333333e-07,
      "logits/chosen": -3.0372419357299805,
      "logits/rejected": -2.5327796936035156,
      "logps/chosen": -93.10124206542969,
      "logps/rejected": -117.17713928222656,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.19597530364990234,
      "rewards/margins": 6.858736991882324,
      "rewards/rejected": -7.054712295532227,
      "step": 3093
    },
    {
      "epoch": 1.2376,
      "grad_norm": 0.08641092479228973,
      "learning_rate": 5.876e-07,
      "logits/chosen": -2.763498306274414,
      "logits/rejected": -2.2773470878601074,
      "logps/chosen": -75.84812927246094,
      "logps/rejected": -171.5481719970703,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.038841724395752,
      "rewards/margins": 11.863188743591309,
      "rewards/rejected": -10.824346542358398,
      "step": 3094
    },
    {
      "epoch": 1.238,
      "grad_norm": 0.011520693078637123,
      "learning_rate": 5.874666666666667e-07,
      "logits/chosen": -3.083439826965332,
      "logits/rejected": -2.5993120670318604,
      "logps/chosen": -84.99080657958984,
      "logps/rejected": -180.05642700195312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.22344720363616943,
      "rewards/margins": 11.718074798583984,
      "rewards/rejected": -11.941521644592285,
      "step": 3095
    },
    {
      "epoch": 1.2384,
      "grad_norm": 1.1017646789550781,
      "learning_rate": 5.873333333333334e-07,
      "logits/chosen": -2.5613515377044678,
      "logits/rejected": -2.407309055328369,
      "logps/chosen": -156.14796447753906,
      "logps/rejected": -137.16802978515625,
      "loss": 0.0072,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9052085876464844,
      "rewards/margins": 5.989963531494141,
      "rewards/rejected": -7.895172119140625,
      "step": 3096
    },
    {
      "epoch": 1.2388,
      "grad_norm": 0.10522682964801788,
      "learning_rate": 5.872000000000001e-07,
      "logits/chosen": -2.9354867935180664,
      "logits/rejected": -2.51718807220459,
      "logps/chosen": -77.3910903930664,
      "logps/rejected": -114.06950378417969,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5424900054931641,
      "rewards/margins": 7.483329772949219,
      "rewards/rejected": -6.940840244293213,
      "step": 3097
    },
    {
      "epoch": 1.2392,
      "grad_norm": 0.0036306160036474466,
      "learning_rate": 5.870666666666666e-07,
      "logits/chosen": -3.082995891571045,
      "logits/rejected": -2.5305254459381104,
      "logps/chosen": -80.2147216796875,
      "logps/rejected": -192.12368774414062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.27780038118362427,
      "rewards/margins": 11.523838996887207,
      "rewards/rejected": -11.801639556884766,
      "step": 3098
    },
    {
      "epoch": 1.2396,
      "grad_norm": 0.019079014658927917,
      "learning_rate": 5.869333333333332e-07,
      "logits/chosen": -2.918158531188965,
      "logits/rejected": -2.5630252361297607,
      "logps/chosen": -95.87721252441406,
      "logps/rejected": -157.9198760986328,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.612436830997467,
      "rewards/margins": 9.390905380249023,
      "rewards/rejected": -10.003341674804688,
      "step": 3099
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.10524149239063263,
      "learning_rate": 5.867999999999999e-07,
      "logits/chosen": -2.972813129425049,
      "logits/rejected": -2.7848875522613525,
      "logps/chosen": -57.055870056152344,
      "logps/rejected": -114.33279418945312,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3178709149360657,
      "rewards/margins": 7.0267133712768555,
      "rewards/rejected": -6.7088422775268555,
      "step": 3100
    },
    {
      "epoch": 1.2404,
      "grad_norm": 2.055842161178589,
      "learning_rate": 5.866666666666666e-07,
      "logits/chosen": -3.117129325866699,
      "logits/rejected": -2.8569812774658203,
      "logps/chosen": -70.79974365234375,
      "logps/rejected": -105.44886016845703,
      "loss": 0.0187,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19481775164604187,
      "rewards/margins": 6.517895698547363,
      "rewards/rejected": -6.323078155517578,
      "step": 3101
    },
    {
      "epoch": 1.2408,
      "grad_norm": 5.340358257293701,
      "learning_rate": 5.865333333333333e-07,
      "logits/chosen": -3.1639440059661865,
      "logits/rejected": -3.093240976333618,
      "logps/chosen": -75.85591125488281,
      "logps/rejected": -90.81431579589844,
      "loss": 0.0542,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1450363397598267,
      "rewards/margins": 4.132519245147705,
      "rewards/rejected": -5.277555465698242,
      "step": 3102
    },
    {
      "epoch": 1.2412,
      "grad_norm": 20.886367797851562,
      "learning_rate": 5.864e-07,
      "logits/chosen": -2.9247920513153076,
      "logits/rejected": -2.6053788661956787,
      "logps/chosen": -88.02552032470703,
      "logps/rejected": -78.9075927734375,
      "loss": 0.1274,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7820457816123962,
      "rewards/margins": 4.631769180297852,
      "rewards/rejected": -5.413815021514893,
      "step": 3103
    },
    {
      "epoch": 1.2416,
      "grad_norm": 0.004175272770226002,
      "learning_rate": 5.862666666666667e-07,
      "logits/chosen": -2.832038164138794,
      "logits/rejected": -2.289918899536133,
      "logps/chosen": -110.68011474609375,
      "logps/rejected": -146.05838012695312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4049408435821533,
      "rewards/margins": 11.71682357788086,
      "rewards/rejected": -10.311882972717285,
      "step": 3104
    },
    {
      "epoch": 1.242,
      "grad_norm": 1.6142165660858154,
      "learning_rate": 5.861333333333333e-07,
      "logits/chosen": -3.046684741973877,
      "logits/rejected": -2.7821903228759766,
      "logps/chosen": -97.57254791259766,
      "logps/rejected": -93.6915054321289,
      "loss": 0.0172,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6480906009674072,
      "rewards/margins": 4.8439483642578125,
      "rewards/rejected": -5.492039203643799,
      "step": 3105
    },
    {
      "epoch": 1.2424,
      "grad_norm": 0.33558106422424316,
      "learning_rate": 5.86e-07,
      "logits/chosen": -2.9896838665008545,
      "logits/rejected": -2.570969581604004,
      "logps/chosen": -105.11328125,
      "logps/rejected": -164.773193359375,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3204818665981293,
      "rewards/margins": 9.820932388305664,
      "rewards/rejected": -10.141413688659668,
      "step": 3106
    },
    {
      "epoch": 1.2428,
      "grad_norm": 0.5970044732093811,
      "learning_rate": 5.858666666666667e-07,
      "logits/chosen": -2.977950096130371,
      "logits/rejected": -2.463359832763672,
      "logps/chosen": -48.90411376953125,
      "logps/rejected": -124.20896911621094,
      "loss": 0.0045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.637358546257019,
      "rewards/margins": 8.760082244873047,
      "rewards/rejected": -7.1227240562438965,
      "step": 3107
    },
    {
      "epoch": 1.2432,
      "grad_norm": 0.3162289261817932,
      "learning_rate": 5.857333333333333e-07,
      "logits/chosen": -2.921769618988037,
      "logits/rejected": -2.8190054893493652,
      "logps/chosen": -68.1949234008789,
      "logps/rejected": -101.64022827148438,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5706695318222046,
      "rewards/margins": 6.0861663818359375,
      "rewards/rejected": -5.515496730804443,
      "step": 3108
    },
    {
      "epoch": 1.2436,
      "grad_norm": 4.704076290130615,
      "learning_rate": 5.856e-07,
      "logits/chosen": -3.0127267837524414,
      "logits/rejected": -2.857295036315918,
      "logps/chosen": -120.06552124023438,
      "logps/rejected": -81.03114318847656,
      "loss": 0.0352,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4630969762802124,
      "rewards/margins": 4.232527732849121,
      "rewards/rejected": -4.695624351501465,
      "step": 3109
    },
    {
      "epoch": 1.244,
      "grad_norm": 0.0053811767138540745,
      "learning_rate": 5.854666666666666e-07,
      "logits/chosen": -2.9875617027282715,
      "logits/rejected": -2.2902374267578125,
      "logps/chosen": -66.76287841796875,
      "logps/rejected": -146.72781372070312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5195965766906738,
      "rewards/margins": 10.717564582824707,
      "rewards/rejected": -9.197967529296875,
      "step": 3110
    },
    {
      "epoch": 1.2444,
      "grad_norm": 0.03641125559806824,
      "learning_rate": 5.853333333333333e-07,
      "logits/chosen": -3.065255641937256,
      "logits/rejected": -2.5986664295196533,
      "logps/chosen": -54.51711654663086,
      "logps/rejected": -160.89845275878906,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05423279106616974,
      "rewards/margins": 8.944040298461914,
      "rewards/rejected": -8.88980770111084,
      "step": 3111
    },
    {
      "epoch": 1.2448,
      "grad_norm": 0.019344143569469452,
      "learning_rate": 5.852e-07,
      "logits/chosen": -2.542901039123535,
      "logits/rejected": -1.9143600463867188,
      "logps/chosen": -73.28707885742188,
      "logps/rejected": -142.5972900390625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4609909057617188,
      "rewards/margins": 9.480674743652344,
      "rewards/rejected": -8.019683837890625,
      "step": 3112
    },
    {
      "epoch": 1.2452,
      "grad_norm": 0.9183192253112793,
      "learning_rate": 5.850666666666666e-07,
      "logits/chosen": -2.840501546859741,
      "logits/rejected": -2.6394951343536377,
      "logps/chosen": -110.06040954589844,
      "logps/rejected": -116.09463500976562,
      "loss": 0.0075,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0476438999176025,
      "rewards/margins": 5.036557197570801,
      "rewards/rejected": -7.084200859069824,
      "step": 3113
    },
    {
      "epoch": 1.2456,
      "grad_norm": 1.1129487752914429,
      "learning_rate": 5.849333333333333e-07,
      "logits/chosen": -2.673891067504883,
      "logits/rejected": -2.2499539852142334,
      "logps/chosen": -189.29273986816406,
      "logps/rejected": -144.11456298828125,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4538428783416748,
      "rewards/margins": 7.3980326652526855,
      "rewards/rejected": -8.851875305175781,
      "step": 3114
    },
    {
      "epoch": 1.246,
      "grad_norm": 0.031942613422870636,
      "learning_rate": 5.848e-07,
      "logits/chosen": -2.886903762817383,
      "logits/rejected": -2.478355884552002,
      "logps/chosen": -110.31700134277344,
      "logps/rejected": -158.1383819580078,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0996029376983643,
      "rewards/margins": 9.565656661987305,
      "rewards/rejected": -10.66525936126709,
      "step": 3115
    },
    {
      "epoch": 1.2464,
      "grad_norm": 0.013869126327335835,
      "learning_rate": 5.846666666666667e-07,
      "logits/chosen": -3.0359630584716797,
      "logits/rejected": -2.4208970069885254,
      "logps/chosen": -119.46255493164062,
      "logps/rejected": -155.07408142089844,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.753872275352478,
      "rewards/margins": 9.508837699890137,
      "rewards/rejected": -8.754964828491211,
      "step": 3116
    },
    {
      "epoch": 1.2468,
      "grad_norm": 0.01426752656698227,
      "learning_rate": 5.845333333333333e-07,
      "logits/chosen": -2.988252639770508,
      "logits/rejected": -2.5977258682250977,
      "logps/chosen": -58.09516143798828,
      "logps/rejected": -154.04701232910156,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22778376936912537,
      "rewards/margins": 9.387706756591797,
      "rewards/rejected": -9.159923553466797,
      "step": 3117
    },
    {
      "epoch": 1.2472,
      "grad_norm": 8.087831497192383,
      "learning_rate": 5.844e-07,
      "logits/chosen": -3.2561333179473877,
      "logits/rejected": -2.8196463584899902,
      "logps/chosen": -60.02532196044922,
      "logps/rejected": -125.6957778930664,
      "loss": 0.087,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.34012851119041443,
      "rewards/margins": 7.8458709716796875,
      "rewards/rejected": -8.185999870300293,
      "step": 3118
    },
    {
      "epoch": 1.2476,
      "grad_norm": 0.0977846309542656,
      "learning_rate": 5.842666666666667e-07,
      "logits/chosen": -2.5662426948547363,
      "logits/rejected": -1.6627721786499023,
      "logps/chosen": -151.79537963867188,
      "logps/rejected": -148.6932373046875,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9050579071044922,
      "rewards/margins": 8.691681861877441,
      "rewards/rejected": -9.596739768981934,
      "step": 3119
    },
    {
      "epoch": 1.248,
      "grad_norm": 0.1895730197429657,
      "learning_rate": 5.841333333333332e-07,
      "logits/chosen": -3.1854970455169678,
      "logits/rejected": -2.7713232040405273,
      "logps/chosen": -100.01449584960938,
      "logps/rejected": -123.07684326171875,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8992336988449097,
      "rewards/margins": 6.695857048034668,
      "rewards/rejected": -7.595090866088867,
      "step": 3120
    },
    {
      "epoch": 1.2484,
      "grad_norm": 10.683969497680664,
      "learning_rate": 5.839999999999999e-07,
      "logits/chosen": -2.9186108112335205,
      "logits/rejected": -2.4219112396240234,
      "logps/chosen": -112.47314453125,
      "logps/rejected": -91.01429748535156,
      "loss": 0.0582,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1879119873046875,
      "rewards/margins": 4.845883369445801,
      "rewards/rejected": -5.033795356750488,
      "step": 3121
    },
    {
      "epoch": 1.2488,
      "grad_norm": 0.0039882599376142025,
      "learning_rate": 5.838666666666666e-07,
      "logits/chosen": -3.0323307514190674,
      "logits/rejected": -2.299686908721924,
      "logps/chosen": -83.0325927734375,
      "logps/rejected": -194.46823120117188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08779394626617432,
      "rewards/margins": 11.64055061340332,
      "rewards/rejected": -11.72834587097168,
      "step": 3122
    },
    {
      "epoch": 1.2492,
      "grad_norm": 0.032470621168613434,
      "learning_rate": 5.837333333333333e-07,
      "logits/chosen": -2.8499703407287598,
      "logits/rejected": -2.438476324081421,
      "logps/chosen": -89.74819946289062,
      "logps/rejected": -130.93405151367188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.864605188369751,
      "rewards/margins": 8.656792640686035,
      "rewards/rejected": -7.792187690734863,
      "step": 3123
    },
    {
      "epoch": 1.2496,
      "grad_norm": 0.013203969225287437,
      "learning_rate": 5.836e-07,
      "logits/chosen": -2.4820797443389893,
      "logits/rejected": -1.9290900230407715,
      "logps/chosen": -107.50811767578125,
      "logps/rejected": -164.38572692871094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3453254699707031,
      "rewards/margins": 11.214333534240723,
      "rewards/rejected": -9.86900806427002,
      "step": 3124
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.021222788840532303,
      "learning_rate": 5.834666666666667e-07,
      "logits/chosen": -2.901728630065918,
      "logits/rejected": -2.2183780670166016,
      "logps/chosen": -63.050148010253906,
      "logps/rejected": -141.8748779296875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0054051876068115,
      "rewards/margins": 10.203269958496094,
      "rewards/rejected": -9.197864532470703,
      "step": 3125
    },
    {
      "epoch": 1.2504,
      "grad_norm": 5.519677639007568,
      "learning_rate": 5.833333333333334e-07,
      "logits/chosen": -3.020843982696533,
      "logits/rejected": -2.591428279876709,
      "logps/chosen": -125.12715148925781,
      "logps/rejected": -104.22828674316406,
      "loss": 0.0263,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9317752122879028,
      "rewards/margins": 5.177471160888672,
      "rewards/rejected": -7.109246253967285,
      "step": 3126
    },
    {
      "epoch": 1.2508,
      "grad_norm": 0.7037357687950134,
      "learning_rate": 5.832e-07,
      "logits/chosen": -3.167665481567383,
      "logits/rejected": -2.586636781692505,
      "logps/chosen": -68.83214569091797,
      "logps/rejected": -94.17019653320312,
      "loss": 0.0089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5438600778579712,
      "rewards/margins": 4.9679718017578125,
      "rewards/rejected": -5.511832237243652,
      "step": 3127
    },
    {
      "epoch": 1.2511999999999999,
      "grad_norm": 0.1442328840494156,
      "learning_rate": 5.830666666666666e-07,
      "logits/chosen": -2.700838327407837,
      "logits/rejected": -2.1989243030548096,
      "logps/chosen": -104.93359375,
      "logps/rejected": -129.04248046875,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6308853626251221,
      "rewards/margins": 8.854761123657227,
      "rewards/rejected": -8.223875999450684,
      "step": 3128
    },
    {
      "epoch": 1.2516,
      "grad_norm": 0.005026247818022966,
      "learning_rate": 5.829333333333333e-07,
      "logits/chosen": -2.7743287086486816,
      "logits/rejected": -1.9351816177368164,
      "logps/chosen": -73.83857727050781,
      "logps/rejected": -174.73202514648438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5230317115783691,
      "rewards/margins": 11.47720718383789,
      "rewards/rejected": -9.95417594909668,
      "step": 3129
    },
    {
      "epoch": 1.252,
      "grad_norm": 0.02330518327653408,
      "learning_rate": 5.828e-07,
      "logits/chosen": -2.6221227645874023,
      "logits/rejected": -2.1932976245880127,
      "logps/chosen": -56.495216369628906,
      "logps/rejected": -232.31671142578125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.312203973531723,
      "rewards/margins": 14.165990829467773,
      "rewards/rejected": -13.85378646850586,
      "step": 3130
    },
    {
      "epoch": 1.2524,
      "grad_norm": 0.09104232490062714,
      "learning_rate": 5.826666666666666e-07,
      "logits/chosen": -2.982787609100342,
      "logits/rejected": -2.2167184352874756,
      "logps/chosen": -111.40779113769531,
      "logps/rejected": -148.68087768554688,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.798317015171051,
      "rewards/margins": 10.696557998657227,
      "rewards/rejected": -9.89824104309082,
      "step": 3131
    },
    {
      "epoch": 1.2528000000000001,
      "grad_norm": 0.05636581778526306,
      "learning_rate": 5.825333333333333e-07,
      "logits/chosen": -2.8951239585876465,
      "logits/rejected": -2.3029251098632812,
      "logps/chosen": -123.09855651855469,
      "logps/rejected": -208.53602600097656,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1723294258117676,
      "rewards/margins": 12.565591812133789,
      "rewards/rejected": -11.393261909484863,
      "step": 3132
    },
    {
      "epoch": 1.2532,
      "grad_norm": 0.17880003154277802,
      "learning_rate": 5.824e-07,
      "logits/chosen": -2.9341113567352295,
      "logits/rejected": -2.5759260654449463,
      "logps/chosen": -64.37952423095703,
      "logps/rejected": -134.9443359375,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2044174671173096,
      "rewards/margins": 9.13442325592041,
      "rewards/rejected": -7.9300055503845215,
      "step": 3133
    },
    {
      "epoch": 1.2536,
      "grad_norm": 0.016251452267169952,
      "learning_rate": 5.822666666666667e-07,
      "logits/chosen": -2.7296652793884277,
      "logits/rejected": -2.2400498390197754,
      "logps/chosen": -131.9801483154297,
      "logps/rejected": -150.56793212890625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6247367858886719,
      "rewards/margins": 8.979917526245117,
      "rewards/rejected": -9.604655265808105,
      "step": 3134
    },
    {
      "epoch": 1.254,
      "grad_norm": 0.008585608564317226,
      "learning_rate": 5.821333333333333e-07,
      "logits/chosen": -2.5405683517456055,
      "logits/rejected": -1.7652382850646973,
      "logps/chosen": -152.06561279296875,
      "logps/rejected": -198.4309844970703,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35359421372413635,
      "rewards/margins": 10.560544967651367,
      "rewards/rejected": -10.206950187683105,
      "step": 3135
    },
    {
      "epoch": 1.2544,
      "grad_norm": 3.505593776702881,
      "learning_rate": 5.819999999999999e-07,
      "logits/chosen": -3.1632802486419678,
      "logits/rejected": -3.2406387329101562,
      "logps/chosen": -51.16376495361328,
      "logps/rejected": -100.31745910644531,
      "loss": 0.0359,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.36648234724998474,
      "rewards/margins": 5.2439866065979,
      "rewards/rejected": -5.610468864440918,
      "step": 3136
    },
    {
      "epoch": 1.2548,
      "grad_norm": 0.4026261270046234,
      "learning_rate": 5.818666666666666e-07,
      "logits/chosen": -2.9893157482147217,
      "logits/rejected": -2.6618614196777344,
      "logps/chosen": -121.49456024169922,
      "logps/rejected": -87.04644012451172,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5470428466796875,
      "rewards/margins": 5.610299110412598,
      "rewards/rejected": -5.06325626373291,
      "step": 3137
    },
    {
      "epoch": 1.2551999999999999,
      "grad_norm": 0.23836453258991241,
      "learning_rate": 5.817333333333333e-07,
      "logits/chosen": -2.8968329429626465,
      "logits/rejected": -3.0113916397094727,
      "logps/chosen": -103.8495101928711,
      "logps/rejected": -131.60174560546875,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4599544405937195,
      "rewards/margins": 6.476499557495117,
      "rewards/rejected": -6.9364542961120605,
      "step": 3138
    },
    {
      "epoch": 1.2556,
      "grad_norm": 0.16785775125026703,
      "learning_rate": 5.816e-07,
      "logits/chosen": -3.172274589538574,
      "logits/rejected": -2.678178310394287,
      "logps/chosen": -79.32428741455078,
      "logps/rejected": -113.99014282226562,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5500442981719971,
      "rewards/margins": 7.627986907958984,
      "rewards/rejected": -7.077942848205566,
      "step": 3139
    },
    {
      "epoch": 1.256,
      "grad_norm": 3.931093692779541,
      "learning_rate": 5.814666666666667e-07,
      "logits/chosen": -2.8048834800720215,
      "logits/rejected": -2.875819683074951,
      "logps/chosen": -87.64051818847656,
      "logps/rejected": -102.918212890625,
      "loss": 0.0336,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4700694978237152,
      "rewards/margins": 5.490725040435791,
      "rewards/rejected": -5.020655632019043,
      "step": 3140
    },
    {
      "epoch": 1.2564,
      "grad_norm": 0.07385366410017014,
      "learning_rate": 5.813333333333334e-07,
      "logits/chosen": -2.6456878185272217,
      "logits/rejected": -2.1624274253845215,
      "logps/chosen": -82.59759521484375,
      "logps/rejected": -136.973388671875,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5703861117362976,
      "rewards/margins": 8.281806945800781,
      "rewards/rejected": -7.711421012878418,
      "step": 3141
    },
    {
      "epoch": 1.2568,
      "grad_norm": 0.19519087672233582,
      "learning_rate": 5.812e-07,
      "logits/chosen": -2.840013265609741,
      "logits/rejected": -2.7394649982452393,
      "logps/chosen": -101.54594421386719,
      "logps/rejected": -133.28607177734375,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5176429748535156,
      "rewards/margins": 9.076494216918945,
      "rewards/rejected": -8.55885124206543,
      "step": 3142
    },
    {
      "epoch": 1.2572,
      "grad_norm": 0.00917370431125164,
      "learning_rate": 5.810666666666666e-07,
      "logits/chosen": -2.8151793479919434,
      "logits/rejected": -2.02565860748291,
      "logps/chosen": -152.70608520507812,
      "logps/rejected": -222.50767517089844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7875670790672302,
      "rewards/margins": 12.290903091430664,
      "rewards/rejected": -13.078470230102539,
      "step": 3143
    },
    {
      "epoch": 1.2576,
      "grad_norm": 0.17071262001991272,
      "learning_rate": 5.809333333333333e-07,
      "logits/chosen": -2.577737331390381,
      "logits/rejected": -2.2694168090820312,
      "logps/chosen": -134.7713623046875,
      "logps/rejected": -180.25872802734375,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0391998291015625,
      "rewards/margins": 10.703044891357422,
      "rewards/rejected": -10.66384506225586,
      "step": 3144
    },
    {
      "epoch": 1.258,
      "grad_norm": 0.005094773601740599,
      "learning_rate": 5.807999999999999e-07,
      "logits/chosen": -2.9483470916748047,
      "logits/rejected": -2.2937495708465576,
      "logps/chosen": -87.76693725585938,
      "logps/rejected": -166.7486572265625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.435805082321167,
      "rewards/margins": 11.205171585083008,
      "rewards/rejected": -10.769367218017578,
      "step": 3145
    },
    {
      "epoch": 1.2584,
      "grad_norm": 0.04396940395236015,
      "learning_rate": 5.806666666666666e-07,
      "logits/chosen": -2.8424997329711914,
      "logits/rejected": -2.292499542236328,
      "logps/chosen": -170.17066955566406,
      "logps/rejected": -178.161376953125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0039384365081787,
      "rewards/margins": 9.409799575805664,
      "rewards/rejected": -11.413738250732422,
      "step": 3146
    },
    {
      "epoch": 1.2588,
      "grad_norm": 0.0725158229470253,
      "learning_rate": 5.805333333333333e-07,
      "logits/chosen": -3.0258421897888184,
      "logits/rejected": -2.3824501037597656,
      "logps/chosen": -59.529022216796875,
      "logps/rejected": -156.4716339111328,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4206686019897461,
      "rewards/margins": 11.090469360351562,
      "rewards/rejected": -10.6697998046875,
      "step": 3147
    },
    {
      "epoch": 1.2591999999999999,
      "grad_norm": 19.787872314453125,
      "learning_rate": 5.804e-07,
      "logits/chosen": -2.9949445724487305,
      "logits/rejected": -2.6811060905456543,
      "logps/chosen": -129.64840698242188,
      "logps/rejected": -96.47132873535156,
      "loss": 0.1006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6881047487258911,
      "rewards/margins": 3.728330612182617,
      "rewards/rejected": -5.416435241699219,
      "step": 3148
    },
    {
      "epoch": 1.2596,
      "grad_norm": 0.0706741064786911,
      "learning_rate": 5.802666666666667e-07,
      "logits/chosen": -2.708231210708618,
      "logits/rejected": -2.232217311859131,
      "logps/chosen": -112.97571563720703,
      "logps/rejected": -141.20867919921875,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.40076521039009094,
      "rewards/margins": 8.386651992797852,
      "rewards/rejected": -8.787416458129883,
      "step": 3149
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.9364785552024841,
      "learning_rate": 5.801333333333333e-07,
      "logits/chosen": -2.910365104675293,
      "logits/rejected": -2.8214242458343506,
      "logps/chosen": -97.13983917236328,
      "logps/rejected": -118.484619140625,
      "loss": 0.0049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.41553956270217896,
      "rewards/margins": 7.068922996520996,
      "rewards/rejected": -7.484462738037109,
      "step": 3150
    },
    {
      "epoch": 1.2604,
      "grad_norm": 2.9067742824554443,
      "learning_rate": 5.8e-07,
      "logits/chosen": -2.6552605628967285,
      "logits/rejected": -2.04740571975708,
      "logps/chosen": -173.73495483398438,
      "logps/rejected": -170.86624145507812,
      "loss": 0.0112,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5967568159103394,
      "rewards/margins": 9.20701789855957,
      "rewards/rejected": -10.803775787353516,
      "step": 3151
    },
    {
      "epoch": 1.2608,
      "grad_norm": 0.07295215874910355,
      "learning_rate": 5.798666666666666e-07,
      "logits/chosen": -2.7812013626098633,
      "logits/rejected": -2.0512516498565674,
      "logps/chosen": -123.05924987792969,
      "logps/rejected": -138.130615234375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.786785900592804,
      "rewards/margins": 7.5239715576171875,
      "rewards/rejected": -8.31075668334961,
      "step": 3152
    },
    {
      "epoch": 1.2612,
      "grad_norm": 0.009988833218812943,
      "learning_rate": 5.797333333333333e-07,
      "logits/chosen": -2.8640031814575195,
      "logits/rejected": -2.2242913246154785,
      "logps/chosen": -96.18852996826172,
      "logps/rejected": -169.24142456054688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3042318522930145,
      "rewards/margins": 9.779637336730957,
      "rewards/rejected": -9.4754056930542,
      "step": 3153
    },
    {
      "epoch": 1.2616,
      "grad_norm": 17.886329650878906,
      "learning_rate": 5.796e-07,
      "logits/chosen": -3.1901559829711914,
      "logits/rejected": -2.994074821472168,
      "logps/chosen": -81.10636901855469,
      "logps/rejected": -132.79229736328125,
      "loss": 0.1458,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.674486517906189,
      "rewards/margins": 6.51269006729126,
      "rewards/rejected": -7.187176704406738,
      "step": 3154
    },
    {
      "epoch": 1.262,
      "grad_norm": 0.010396183468401432,
      "learning_rate": 5.794666666666666e-07,
      "logits/chosen": -2.6918222904205322,
      "logits/rejected": -2.013744831085205,
      "logps/chosen": -66.57759857177734,
      "logps/rejected": -189.80897521972656,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.607251763343811,
      "rewards/margins": 11.789361953735352,
      "rewards/rejected": -11.182109832763672,
      "step": 3155
    },
    {
      "epoch": 1.2624,
      "grad_norm": 2.19385027885437,
      "learning_rate": 5.793333333333333e-07,
      "logits/chosen": -2.686927318572998,
      "logits/rejected": -2.1939644813537598,
      "logps/chosen": -150.22964477539062,
      "logps/rejected": -152.03627014160156,
      "loss": 0.0092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.29858136177063,
      "rewards/margins": 6.592551231384277,
      "rewards/rejected": -8.891132354736328,
      "step": 3156
    },
    {
      "epoch": 1.2628,
      "grad_norm": 0.017527809366583824,
      "learning_rate": 5.792e-07,
      "logits/chosen": -2.8544225692749023,
      "logits/rejected": -2.2870845794677734,
      "logps/chosen": -86.17462158203125,
      "logps/rejected": -182.52597045898438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8492725491523743,
      "rewards/margins": 11.139888763427734,
      "rewards/rejected": -10.290616035461426,
      "step": 3157
    },
    {
      "epoch": 1.2631999999999999,
      "grad_norm": 0.010381973348557949,
      "learning_rate": 5.790666666666666e-07,
      "logits/chosen": -2.5110130310058594,
      "logits/rejected": -2.34556245803833,
      "logps/chosen": -63.963157653808594,
      "logps/rejected": -174.36972045898438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2944544553756714,
      "rewards/margins": 10.056133270263672,
      "rewards/rejected": -8.761678695678711,
      "step": 3158
    },
    {
      "epoch": 1.2636,
      "grad_norm": 0.06290122121572495,
      "learning_rate": 5.789333333333333e-07,
      "logits/chosen": -2.2798843383789062,
      "logits/rejected": -1.493611454963684,
      "logps/chosen": -168.83612060546875,
      "logps/rejected": -177.06912231445312,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0755982398986816,
      "rewards/margins": 8.042116165161133,
      "rewards/rejected": -10.117713928222656,
      "step": 3159
    },
    {
      "epoch": 1.264,
      "grad_norm": 0.21661211550235748,
      "learning_rate": 5.788e-07,
      "logits/chosen": -3.1624791622161865,
      "logits/rejected": -2.721035957336426,
      "logps/chosen": -50.8759765625,
      "logps/rejected": -133.181396484375,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6772161722183228,
      "rewards/margins": 8.688465118408203,
      "rewards/rejected": -8.011249542236328,
      "step": 3160
    },
    {
      "epoch": 1.2644,
      "grad_norm": 37.741798400878906,
      "learning_rate": 5.786666666666667e-07,
      "logits/chosen": -2.250091552734375,
      "logits/rejected": -1.4785053730010986,
      "logps/chosen": -239.78433227539062,
      "logps/rejected": -237.81161499023438,
      "loss": 0.1613,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.159210681915283,
      "rewards/margins": 8.524334907531738,
      "rewards/rejected": -11.68354606628418,
      "step": 3161
    },
    {
      "epoch": 1.2648,
      "grad_norm": 69.78218841552734,
      "learning_rate": 5.785333333333334e-07,
      "logits/chosen": -2.185997486114502,
      "logits/rejected": -1.8965448141098022,
      "logps/chosen": -178.9490203857422,
      "logps/rejected": -225.59584045410156,
      "loss": 0.6643,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -3.6605353355407715,
      "rewards/margins": 6.139892578125,
      "rewards/rejected": -9.80042839050293,
      "step": 3162
    },
    {
      "epoch": 1.2652,
      "grad_norm": 0.19236886501312256,
      "learning_rate": 5.784e-07,
      "logits/chosen": -2.9436826705932617,
      "logits/rejected": -2.8665611743927,
      "logps/chosen": -58.46636962890625,
      "logps/rejected": -108.59172058105469,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32285135984420776,
      "rewards/margins": 7.392468452453613,
      "rewards/rejected": -7.06961727142334,
      "step": 3163
    },
    {
      "epoch": 1.2656,
      "grad_norm": 0.013891873881220818,
      "learning_rate": 5.782666666666666e-07,
      "logits/chosen": -3.077221393585205,
      "logits/rejected": -2.509026527404785,
      "logps/chosen": -76.67242431640625,
      "logps/rejected": -184.91099548339844,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4125751554965973,
      "rewards/margins": 9.650703430175781,
      "rewards/rejected": -9.238127708435059,
      "step": 3164
    },
    {
      "epoch": 1.266,
      "grad_norm": 0.015953557565808296,
      "learning_rate": 5.781333333333333e-07,
      "logits/chosen": -2.9400272369384766,
      "logits/rejected": -2.6497397422790527,
      "logps/chosen": -99.37017059326172,
      "logps/rejected": -159.24093627929688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4040794372558594,
      "rewards/margins": 9.369245529174805,
      "rewards/rejected": -7.965167045593262,
      "step": 3165
    },
    {
      "epoch": 1.2664,
      "grad_norm": 1.5378512144088745,
      "learning_rate": 5.779999999999999e-07,
      "logits/chosen": -2.800489902496338,
      "logits/rejected": -2.5327818393707275,
      "logps/chosen": -57.623435974121094,
      "logps/rejected": -133.53985595703125,
      "loss": 0.0109,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7361294031143188,
      "rewards/margins": 8.606422424316406,
      "rewards/rejected": -7.870293140411377,
      "step": 3166
    },
    {
      "epoch": 1.2668,
      "grad_norm": 0.0014138155383989215,
      "learning_rate": 5.778666666666666e-07,
      "logits/chosen": -2.555147886276245,
      "logits/rejected": -2.1100687980651855,
      "logps/chosen": -124.91954040527344,
      "logps/rejected": -255.05709838867188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1574214696884155,
      "rewards/margins": 12.374944686889648,
      "rewards/rejected": -11.217523574829102,
      "step": 3167
    },
    {
      "epoch": 1.2671999999999999,
      "grad_norm": 0.02307034283876419,
      "learning_rate": 5.777333333333333e-07,
      "logits/chosen": -3.013373851776123,
      "logits/rejected": -2.497603416442871,
      "logps/chosen": -147.57110595703125,
      "logps/rejected": -186.71670532226562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.9994537830352783,
      "rewards/margins": 9.082290649414062,
      "rewards/rejected": -12.081744194030762,
      "step": 3168
    },
    {
      "epoch": 1.2676,
      "grad_norm": 4.721923351287842,
      "learning_rate": 5.776e-07,
      "logits/chosen": -2.700965404510498,
      "logits/rejected": -2.5038390159606934,
      "logps/chosen": -98.23491668701172,
      "logps/rejected": -220.0373077392578,
      "loss": 0.0346,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6496463418006897,
      "rewards/margins": 5.9528093338012695,
      "rewards/rejected": -6.602455139160156,
      "step": 3169
    },
    {
      "epoch": 1.268,
      "grad_norm": 0.0016605141572654247,
      "learning_rate": 5.774666666666667e-07,
      "logits/chosen": -2.747101306915283,
      "logits/rejected": -1.823843002319336,
      "logps/chosen": -126.92768096923828,
      "logps/rejected": -188.48336791992188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.125382661819458,
      "rewards/margins": 12.19347858428955,
      "rewards/rejected": -11.068096160888672,
      "step": 3170
    },
    {
      "epoch": 1.2684,
      "grad_norm": 0.018505442887544632,
      "learning_rate": 5.773333333333334e-07,
      "logits/chosen": -2.755016803741455,
      "logits/rejected": -1.8618483543395996,
      "logps/chosen": -101.08515930175781,
      "logps/rejected": -178.7662811279297,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0160598754882812,
      "rewards/margins": 11.55263900756836,
      "rewards/rejected": -10.536579132080078,
      "step": 3171
    },
    {
      "epoch": 1.2688,
      "grad_norm": 0.24534597992897034,
      "learning_rate": 5.772000000000001e-07,
      "logits/chosen": -2.8843841552734375,
      "logits/rejected": -2.27949595451355,
      "logps/chosen": -152.5157470703125,
      "logps/rejected": -141.1570587158203,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8656219244003296,
      "rewards/margins": 8.566560745239258,
      "rewards/rejected": -9.432182312011719,
      "step": 3172
    },
    {
      "epoch": 1.2692,
      "grad_norm": 0.12707552313804626,
      "learning_rate": 5.770666666666665e-07,
      "logits/chosen": -2.823073387145996,
      "logits/rejected": -2.046771287918091,
      "logps/chosen": -121.81838989257812,
      "logps/rejected": -153.10569763183594,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3763572573661804,
      "rewards/margins": 8.310161590576172,
      "rewards/rejected": -8.686518669128418,
      "step": 3173
    },
    {
      "epoch": 1.2696,
      "grad_norm": 7.499619007110596,
      "learning_rate": 5.769333333333332e-07,
      "logits/chosen": -3.304539680480957,
      "logits/rejected": -2.972224712371826,
      "logps/chosen": -65.20697784423828,
      "logps/rejected": -96.1283950805664,
      "loss": 0.0531,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5052425861358643,
      "rewards/margins": 4.419581413269043,
      "rewards/rejected": -4.924823760986328,
      "step": 3174
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.419281929731369,
      "learning_rate": 5.767999999999999e-07,
      "logits/chosen": -3.005636215209961,
      "logits/rejected": -2.7631850242614746,
      "logps/chosen": -100.58817291259766,
      "logps/rejected": -143.3909912109375,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24620133638381958,
      "rewards/margins": 8.508124351501465,
      "rewards/rejected": -8.261923789978027,
      "step": 3175
    },
    {
      "epoch": 1.2704,
      "grad_norm": 1.151970386505127,
      "learning_rate": 5.766666666666666e-07,
      "logits/chosen": -2.998023748397827,
      "logits/rejected": -2.6400375366210938,
      "logps/chosen": -79.35648345947266,
      "logps/rejected": -98.87686157226562,
      "loss": 0.0087,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1098875105381012,
      "rewards/margins": 5.627569198608398,
      "rewards/rejected": -5.737456798553467,
      "step": 3176
    },
    {
      "epoch": 1.2708,
      "grad_norm": 0.4324249029159546,
      "learning_rate": 5.765333333333333e-07,
      "logits/chosen": -2.4558639526367188,
      "logits/rejected": -1.3954074382781982,
      "logps/chosen": -202.73333740234375,
      "logps/rejected": -192.4766387939453,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.3906166553497314,
      "rewards/margins": 7.844677925109863,
      "rewards/rejected": -11.235294342041016,
      "step": 3177
    },
    {
      "epoch": 1.2711999999999999,
      "grad_norm": 0.015612425282597542,
      "learning_rate": 5.764e-07,
      "logits/chosen": -2.649061679840088,
      "logits/rejected": -2.0922014713287354,
      "logps/chosen": -131.0901336669922,
      "logps/rejected": -147.22525024414062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33864670991897583,
      "rewards/margins": 9.109591484069824,
      "rewards/rejected": -8.770944595336914,
      "step": 3178
    },
    {
      "epoch": 1.2716,
      "grad_norm": 0.028538405895233154,
      "learning_rate": 5.762666666666667e-07,
      "logits/chosen": -2.987238883972168,
      "logits/rejected": -2.618025302886963,
      "logps/chosen": -102.24365234375,
      "logps/rejected": -159.79000854492188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.020602822303771973,
      "rewards/margins": 8.94384479522705,
      "rewards/rejected": -8.964447021484375,
      "step": 3179
    },
    {
      "epoch": 1.272,
      "grad_norm": 5.519293785095215,
      "learning_rate": 5.761333333333334e-07,
      "logits/chosen": -2.724031448364258,
      "logits/rejected": -2.397859811782837,
      "logps/chosen": -167.4970703125,
      "logps/rejected": -125.01466369628906,
      "loss": 0.0239,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.6329431533813477,
      "rewards/margins": 4.621820449829102,
      "rewards/rejected": -7.254763603210449,
      "step": 3180
    },
    {
      "epoch": 1.2724,
      "grad_norm": 0.1911831796169281,
      "learning_rate": 5.76e-07,
      "logits/chosen": -3.1995584964752197,
      "logits/rejected": -2.8850655555725098,
      "logps/chosen": -72.84829711914062,
      "logps/rejected": -109.92176818847656,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6563224792480469,
      "rewards/margins": 6.575220108032227,
      "rewards/rejected": -7.231542587280273,
      "step": 3181
    },
    {
      "epoch": 1.2728,
      "grad_norm": 1.2152127027511597,
      "learning_rate": 5.758666666666667e-07,
      "logits/chosen": -2.556627035140991,
      "logits/rejected": -2.0971322059631348,
      "logps/chosen": -155.82565307617188,
      "logps/rejected": -157.22930908203125,
      "loss": 0.0069,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.364453911781311,
      "rewards/margins": 5.953940391540527,
      "rewards/rejected": -7.318394184112549,
      "step": 3182
    },
    {
      "epoch": 1.2732,
      "grad_norm": 1.1651952266693115,
      "learning_rate": 5.757333333333332e-07,
      "logits/chosen": -3.006075143814087,
      "logits/rejected": -2.479656457901001,
      "logps/chosen": -83.67139434814453,
      "logps/rejected": -132.30392456054688,
      "loss": 0.0102,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.13252297043800354,
      "rewards/margins": 8.90510368347168,
      "rewards/rejected": -9.037626266479492,
      "step": 3183
    },
    {
      "epoch": 1.2736,
      "grad_norm": 0.35562339425086975,
      "learning_rate": 5.755999999999999e-07,
      "logits/chosen": -2.9448413848876953,
      "logits/rejected": -2.562830924987793,
      "logps/chosen": -78.42701721191406,
      "logps/rejected": -96.52934265136719,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4265672564506531,
      "rewards/margins": 6.5475897789001465,
      "rewards/rejected": -6.1210222244262695,
      "step": 3184
    },
    {
      "epoch": 1.274,
      "grad_norm": 0.7464268803596497,
      "learning_rate": 5.754666666666666e-07,
      "logits/chosen": -2.6335039138793945,
      "logits/rejected": -2.3694162368774414,
      "logps/chosen": -230.70848083496094,
      "logps/rejected": -126.85888671875,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.35975950956344604,
      "rewards/margins": 6.934688091278076,
      "rewards/rejected": -7.294447898864746,
      "step": 3185
    },
    {
      "epoch": 1.2744,
      "grad_norm": 0.06479845941066742,
      "learning_rate": 5.753333333333333e-07,
      "logits/chosen": -2.69551420211792,
      "logits/rejected": -1.9876561164855957,
      "logps/chosen": -129.33096313476562,
      "logps/rejected": -156.29261779785156,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4320831298828125,
      "rewards/margins": 10.097576141357422,
      "rewards/rejected": -9.66549301147461,
      "step": 3186
    },
    {
      "epoch": 1.2748,
      "grad_norm": 0.03159279748797417,
      "learning_rate": 5.752e-07,
      "logits/chosen": -2.6510555744171143,
      "logits/rejected": -1.9539897441864014,
      "logps/chosen": -144.90298461914062,
      "logps/rejected": -222.34762573242188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.956451416015625,
      "rewards/margins": 11.074012756347656,
      "rewards/rejected": -12.030464172363281,
      "step": 3187
    },
    {
      "epoch": 1.2752,
      "grad_norm": 0.002193641848862171,
      "learning_rate": 5.750666666666666e-07,
      "logits/chosen": -2.6405129432678223,
      "logits/rejected": -2.183377504348755,
      "logps/chosen": -162.54830932617188,
      "logps/rejected": -254.6311798095703,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.039374545216560364,
      "rewards/margins": 11.727777481079102,
      "rewards/rejected": -11.68840217590332,
      "step": 3188
    },
    {
      "epoch": 1.2756,
      "grad_norm": 0.06754329800605774,
      "learning_rate": 5.749333333333333e-07,
      "logits/chosen": -2.8352179527282715,
      "logits/rejected": -2.406660556793213,
      "logps/chosen": -93.44070434570312,
      "logps/rejected": -135.55819702148438,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7586787939071655,
      "rewards/margins": 8.521867752075195,
      "rewards/rejected": -7.763188362121582,
      "step": 3189
    },
    {
      "epoch": 1.276,
      "grad_norm": 0.03790650516748428,
      "learning_rate": 5.748e-07,
      "logits/chosen": -2.710124969482422,
      "logits/rejected": -2.234103202819824,
      "logps/chosen": -151.95298767089844,
      "logps/rejected": -131.0366668701172,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.293212890625,
      "rewards/margins": 8.31336784362793,
      "rewards/rejected": -8.60658073425293,
      "step": 3190
    },
    {
      "epoch": 1.2764,
      "grad_norm": 0.10586802661418915,
      "learning_rate": 5.746666666666667e-07,
      "logits/chosen": -2.922024726867676,
      "logits/rejected": -2.787748336791992,
      "logps/chosen": -84.69422912597656,
      "logps/rejected": -104.64684295654297,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.097846269607544,
      "rewards/margins": 7.114107131958008,
      "rewards/rejected": -6.016261100769043,
      "step": 3191
    },
    {
      "epoch": 1.2768,
      "grad_norm": 0.009473505429923534,
      "learning_rate": 5.745333333333333e-07,
      "logits/chosen": -2.5819621086120605,
      "logits/rejected": -2.1898446083068848,
      "logps/chosen": -151.82974243164062,
      "logps/rejected": -222.36788940429688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7005149126052856,
      "rewards/margins": 10.22691822052002,
      "rewards/rejected": -10.927433013916016,
      "step": 3192
    },
    {
      "epoch": 1.2772000000000001,
      "grad_norm": 0.18023553490638733,
      "learning_rate": 5.744e-07,
      "logits/chosen": -2.9740190505981445,
      "logits/rejected": -2.779125213623047,
      "logps/chosen": -98.2551040649414,
      "logps/rejected": -147.65487670898438,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6367034912109375,
      "rewards/margins": 8.827611923217773,
      "rewards/rejected": -8.190908432006836,
      "step": 3193
    },
    {
      "epoch": 1.2776,
      "grad_norm": 4.763692378997803,
      "learning_rate": 5.742666666666666e-07,
      "logits/chosen": -3.004084587097168,
      "logits/rejected": -2.7869696617126465,
      "logps/chosen": -128.6685028076172,
      "logps/rejected": -98.08943176269531,
      "loss": 0.0275,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.061976671218872,
      "rewards/margins": 5.089689254760742,
      "rewards/rejected": -6.151665687561035,
      "step": 3194
    },
    {
      "epoch": 1.278,
      "grad_norm": 1.908525824546814,
      "learning_rate": 5.741333333333333e-07,
      "logits/chosen": -2.714108467102051,
      "logits/rejected": -2.30627179145813,
      "logps/chosen": -90.25635528564453,
      "logps/rejected": -122.96853637695312,
      "loss": 0.0116,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6254154443740845,
      "rewards/margins": 6.421843528747559,
      "rewards/rejected": -5.7964277267456055,
      "step": 3195
    },
    {
      "epoch": 1.2784,
      "grad_norm": 7.88183069229126,
      "learning_rate": 5.739999999999999e-07,
      "logits/chosen": -3.0688209533691406,
      "logits/rejected": -2.610804796218872,
      "logps/chosen": -75.54397583007812,
      "logps/rejected": -114.6509017944336,
      "loss": 0.1174,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6201827526092529,
      "rewards/margins": 5.078810214996338,
      "rewards/rejected": -5.698992729187012,
      "step": 3196
    },
    {
      "epoch": 1.2788,
      "grad_norm": 0.004089376889169216,
      "learning_rate": 5.738666666666666e-07,
      "logits/chosen": -2.5070371627807617,
      "logits/rejected": -1.8134233951568604,
      "logps/chosen": -136.8778533935547,
      "logps/rejected": -197.29876708984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5765037536621094,
      "rewards/margins": 11.275461196899414,
      "rewards/rejected": -10.698957443237305,
      "step": 3197
    },
    {
      "epoch": 1.2792,
      "grad_norm": 0.009457290172576904,
      "learning_rate": 5.737333333333333e-07,
      "logits/chosen": -2.3728318214416504,
      "logits/rejected": -1.877159833908081,
      "logps/chosen": -87.36778259277344,
      "logps/rejected": -178.09820556640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4353184700012207,
      "rewards/margins": 10.48655891418457,
      "rewards/rejected": -9.051240921020508,
      "step": 3198
    },
    {
      "epoch": 1.2796,
      "grad_norm": 0.2511734664440155,
      "learning_rate": 5.736e-07,
      "logits/chosen": -3.2302980422973633,
      "logits/rejected": -2.958894729614258,
      "logps/chosen": -67.47892761230469,
      "logps/rejected": -102.01802825927734,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.24894103407859802,
      "rewards/margins": 6.33566951751709,
      "rewards/rejected": -6.584610462188721,
      "step": 3199
    },
    {
      "epoch": 1.28,
      "grad_norm": 5.464959621429443,
      "learning_rate": 5.734666666666667e-07,
      "logits/chosen": -3.2267067432403564,
      "logits/rejected": -2.6555802822113037,
      "logps/chosen": -75.66327667236328,
      "logps/rejected": -124.35452270507812,
      "loss": 0.0442,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7345958948135376,
      "rewards/margins": 6.809325695037842,
      "rewards/rejected": -7.54392147064209,
      "step": 3200
    },
    {
      "epoch": 1.2804,
      "grad_norm": 5.636075496673584,
      "learning_rate": 5.733333333333334e-07,
      "logits/chosen": -2.6601266860961914,
      "logits/rejected": -2.035722494125366,
      "logps/chosen": -153.0830841064453,
      "logps/rejected": -110.12408447265625,
      "loss": 0.0428,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13612326979637146,
      "rewards/margins": 5.964305877685547,
      "rewards/rejected": -5.828182220458984,
      "step": 3201
    },
    {
      "epoch": 1.2808,
      "grad_norm": 1.933250904083252,
      "learning_rate": 5.732e-07,
      "logits/chosen": -2.4807682037353516,
      "logits/rejected": -1.8725738525390625,
      "logps/chosen": -128.1563262939453,
      "logps/rejected": -93.28314208984375,
      "loss": 0.0153,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4229645729064941,
      "rewards/margins": 5.0372090339660645,
      "rewards/rejected": -6.460173606872559,
      "step": 3202
    },
    {
      "epoch": 1.2812000000000001,
      "grad_norm": 0.18017181754112244,
      "learning_rate": 5.730666666666666e-07,
      "logits/chosen": -2.9879631996154785,
      "logits/rejected": -2.894876480102539,
      "logps/chosen": -94.88689422607422,
      "logps/rejected": -88.00248718261719,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1745777130126953,
      "rewards/margins": 6.718290328979492,
      "rewards/rejected": -5.543712615966797,
      "step": 3203
    },
    {
      "epoch": 1.2816,
      "grad_norm": 3.891104221343994,
      "learning_rate": 5.729333333333332e-07,
      "logits/chosen": -2.7227234840393066,
      "logits/rejected": -2.2616586685180664,
      "logps/chosen": -111.03163146972656,
      "logps/rejected": -155.15286254882812,
      "loss": 0.0161,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9293828010559082,
      "rewards/margins": 5.439923286437988,
      "rewards/rejected": -7.369306564331055,
      "step": 3204
    },
    {
      "epoch": 1.282,
      "grad_norm": 3.8616409301757812,
      "learning_rate": 5.727999999999999e-07,
      "logits/chosen": -2.5286169052124023,
      "logits/rejected": -2.2693934440612793,
      "logps/chosen": -198.88833618164062,
      "logps/rejected": -135.96514892578125,
      "loss": 0.0211,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.059093475341797,
      "rewards/margins": 7.188669681549072,
      "rewards/rejected": -9.247762680053711,
      "step": 3205
    },
    {
      "epoch": 1.2824,
      "grad_norm": 1.907701015472412,
      "learning_rate": 5.726666666666666e-07,
      "logits/chosen": -2.957460403442383,
      "logits/rejected": -2.5927538871765137,
      "logps/chosen": -90.45439147949219,
      "logps/rejected": -106.7430191040039,
      "loss": 0.0205,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4586830139160156,
      "rewards/margins": 6.695641994476318,
      "rewards/rejected": -6.236958980560303,
      "step": 3206
    },
    {
      "epoch": 1.2828,
      "grad_norm": 0.11117561161518097,
      "learning_rate": 5.725333333333333e-07,
      "logits/chosen": -2.611489772796631,
      "logits/rejected": -1.983217716217041,
      "logps/chosen": -182.64413452148438,
      "logps/rejected": -174.92262268066406,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6331745386123657,
      "rewards/margins": 8.574604988098145,
      "rewards/rejected": -10.207778930664062,
      "step": 3207
    },
    {
      "epoch": 1.2832,
      "grad_norm": 0.020130174234509468,
      "learning_rate": 5.724e-07,
      "logits/chosen": -2.5370893478393555,
      "logits/rejected": -2.134232521057129,
      "logps/chosen": -91.29737854003906,
      "logps/rejected": -168.1282958984375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2422375679016113,
      "rewards/margins": 10.699592590332031,
      "rewards/rejected": -8.457355499267578,
      "step": 3208
    },
    {
      "epoch": 1.2836,
      "grad_norm": 3.255803346633911,
      "learning_rate": 5.722666666666667e-07,
      "logits/chosen": -2.3557541370391846,
      "logits/rejected": -1.577643632888794,
      "logps/chosen": -199.6167755126953,
      "logps/rejected": -214.55535888671875,
      "loss": 0.0127,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.3698365688323975,
      "rewards/margins": 9.648394584655762,
      "rewards/rejected": -12.018230438232422,
      "step": 3209
    },
    {
      "epoch": 1.284,
      "grad_norm": 1.2396728992462158,
      "learning_rate": 5.721333333333334e-07,
      "logits/chosen": -2.886317491531372,
      "logits/rejected": -2.2660393714904785,
      "logps/chosen": -84.4618911743164,
      "logps/rejected": -124.75250244140625,
      "loss": 0.0094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1258724331855774,
      "rewards/margins": 7.8069682121276855,
      "rewards/rejected": -7.681096076965332,
      "step": 3210
    },
    {
      "epoch": 1.2844,
      "grad_norm": 0.9850562214851379,
      "learning_rate": 5.719999999999999e-07,
      "logits/chosen": -2.8066158294677734,
      "logits/rejected": -2.8908426761627197,
      "logps/chosen": -79.37368774414062,
      "logps/rejected": -90.38026428222656,
      "loss": 0.0111,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17236460745334625,
      "rewards/margins": 5.095922470092773,
      "rewards/rejected": -4.923558235168457,
      "step": 3211
    },
    {
      "epoch": 1.2848,
      "grad_norm": 0.12013062834739685,
      "learning_rate": 5.718666666666666e-07,
      "logits/chosen": -2.8156769275665283,
      "logits/rejected": -2.2386302947998047,
      "logps/chosen": -107.74360656738281,
      "logps/rejected": -113.32675170898438,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11256256699562073,
      "rewards/margins": 7.071805953979492,
      "rewards/rejected": -6.959243297576904,
      "step": 3212
    },
    {
      "epoch": 1.2852000000000001,
      "grad_norm": 0.5209134817123413,
      "learning_rate": 5.717333333333333e-07,
      "logits/chosen": -2.7858753204345703,
      "logits/rejected": -2.4250636100769043,
      "logps/chosen": -115.23009490966797,
      "logps/rejected": -145.70352172851562,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3225746154785156,
      "rewards/margins": 7.149528503417969,
      "rewards/rejected": -8.472103118896484,
      "step": 3213
    },
    {
      "epoch": 1.2856,
      "grad_norm": 2.179840087890625,
      "learning_rate": 5.716e-07,
      "logits/chosen": -3.0674586296081543,
      "logits/rejected": -2.9094595909118652,
      "logps/chosen": -84.79739379882812,
      "logps/rejected": -77.41891479492188,
      "loss": 0.0184,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.147956132888794,
      "rewards/margins": 4.639657974243164,
      "rewards/rejected": -3.491701602935791,
      "step": 3214
    },
    {
      "epoch": 1.286,
      "grad_norm": 0.9066629409790039,
      "learning_rate": 5.714666666666666e-07,
      "logits/chosen": -3.1535444259643555,
      "logits/rejected": -2.705878734588623,
      "logps/chosen": -79.60623168945312,
      "logps/rejected": -125.66096496582031,
      "loss": 0.0045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9454342126846313,
      "rewards/margins": 6.758337020874023,
      "rewards/rejected": -7.703770637512207,
      "step": 3215
    },
    {
      "epoch": 1.2864,
      "grad_norm": 0.013453997671604156,
      "learning_rate": 5.713333333333333e-07,
      "logits/chosen": -2.805314064025879,
      "logits/rejected": -2.020359992980957,
      "logps/chosen": -28.720691680908203,
      "logps/rejected": -143.78048706054688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6703648567199707,
      "rewards/margins": 10.711723327636719,
      "rewards/rejected": -9.041358947753906,
      "step": 3216
    },
    {
      "epoch": 1.2868,
      "grad_norm": 0.947175920009613,
      "learning_rate": 5.712e-07,
      "logits/chosen": -2.58372163772583,
      "logits/rejected": -2.2992215156555176,
      "logps/chosen": -235.32400512695312,
      "logps/rejected": -137.56692504882812,
      "loss": 0.005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5426830053329468,
      "rewards/margins": 5.717992305755615,
      "rewards/rejected": -7.260675430297852,
      "step": 3217
    },
    {
      "epoch": 1.2872,
      "grad_norm": 11.665569305419922,
      "learning_rate": 5.710666666666666e-07,
      "logits/chosen": -2.770703077316284,
      "logits/rejected": -2.7497127056121826,
      "logps/chosen": -151.10667419433594,
      "logps/rejected": -78.07989501953125,
      "loss": 0.0829,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6141464710235596,
      "rewards/margins": 3.162921905517578,
      "rewards/rejected": -4.777068138122559,
      "step": 3218
    },
    {
      "epoch": 1.2876,
      "grad_norm": 0.0009138968889601529,
      "learning_rate": 5.709333333333333e-07,
      "logits/chosen": -2.609377861022949,
      "logits/rejected": -1.8554494380950928,
      "logps/chosen": -67.9551773071289,
      "logps/rejected": -251.50177001953125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8539888858795166,
      "rewards/margins": 14.985612869262695,
      "rewards/rejected": -13.131624221801758,
      "step": 3219
    },
    {
      "epoch": 1.288,
      "grad_norm": 0.8225058317184448,
      "learning_rate": 5.707999999999999e-07,
      "logits/chosen": -3.0613067150115967,
      "logits/rejected": -2.7434349060058594,
      "logps/chosen": -58.567596435546875,
      "logps/rejected": -112.48348999023438,
      "loss": 0.0051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4922887980937958,
      "rewards/margins": 7.905447959899902,
      "rewards/rejected": -7.413159370422363,
      "step": 3220
    },
    {
      "epoch": 1.2884,
      "grad_norm": 52.329742431640625,
      "learning_rate": 5.706666666666666e-07,
      "logits/chosen": -2.7229576110839844,
      "logits/rejected": -2.3300423622131348,
      "logps/chosen": -247.8318328857422,
      "logps/rejected": -177.62319946289062,
      "loss": 0.3862,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -5.216763496398926,
      "rewards/margins": 3.651683807373047,
      "rewards/rejected": -8.868447303771973,
      "step": 3221
    },
    {
      "epoch": 1.2888,
      "grad_norm": 0.4874643385410309,
      "learning_rate": 5.705333333333333e-07,
      "logits/chosen": -2.5687289237976074,
      "logits/rejected": -2.079636812210083,
      "logps/chosen": -107.85774993896484,
      "logps/rejected": -198.3822021484375,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.624501645565033,
      "rewards/margins": 8.40217113494873,
      "rewards/rejected": -9.02667236328125,
      "step": 3222
    },
    {
      "epoch": 1.2892000000000001,
      "grad_norm": 0.5239470601081848,
      "learning_rate": 5.704e-07,
      "logits/chosen": -3.137730121612549,
      "logits/rejected": -2.774517059326172,
      "logps/chosen": -97.06388854980469,
      "logps/rejected": -106.88299560546875,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33729591965675354,
      "rewards/margins": 6.67720890045166,
      "rewards/rejected": -6.339913368225098,
      "step": 3223
    },
    {
      "epoch": 1.2896,
      "grad_norm": 0.27784982323646545,
      "learning_rate": 5.702666666666667e-07,
      "logits/chosen": -2.6741485595703125,
      "logits/rejected": -2.4073500633239746,
      "logps/chosen": -149.9857940673828,
      "logps/rejected": -118.65599060058594,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.393499732017517,
      "rewards/margins": 8.17924976348877,
      "rewards/rejected": -6.785750389099121,
      "step": 3224
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.08345009386539459,
      "learning_rate": 5.701333333333334e-07,
      "logits/chosen": -2.991563081741333,
      "logits/rejected": -2.464200973510742,
      "logps/chosen": -78.58741760253906,
      "logps/rejected": -162.0994415283203,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9688051342964172,
      "rewards/margins": 8.85462760925293,
      "rewards/rejected": -9.823432922363281,
      "step": 3225
    },
    {
      "epoch": 1.2904,
      "grad_norm": 0.040543071925640106,
      "learning_rate": 5.699999999999999e-07,
      "logits/chosen": -3.120116710662842,
      "logits/rejected": -2.5496511459350586,
      "logps/chosen": -45.21791076660156,
      "logps/rejected": -118.36949157714844,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1273689270019531,
      "rewards/margins": 8.53361701965332,
      "rewards/rejected": -7.406248092651367,
      "step": 3226
    },
    {
      "epoch": 1.2908,
      "grad_norm": 0.13101144134998322,
      "learning_rate": 5.698666666666666e-07,
      "logits/chosen": -2.532952070236206,
      "logits/rejected": -1.8157020807266235,
      "logps/chosen": -190.63430786132812,
      "logps/rejected": -167.47195434570312,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0657150745391846,
      "rewards/margins": 7.4182538986206055,
      "rewards/rejected": -8.483968734741211,
      "step": 3227
    },
    {
      "epoch": 1.2912,
      "grad_norm": 0.00458620535209775,
      "learning_rate": 5.697333333333333e-07,
      "logits/chosen": -2.8035457134246826,
      "logits/rejected": -1.9219738245010376,
      "logps/chosen": -79.85539245605469,
      "logps/rejected": -198.09323120117188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7101856470108032,
      "rewards/margins": 12.583454132080078,
      "rewards/rejected": -13.29364013671875,
      "step": 3228
    },
    {
      "epoch": 1.2916,
      "grad_norm": 0.0018769646994769573,
      "learning_rate": 5.696e-07,
      "logits/chosen": -2.627016305923462,
      "logits/rejected": -2.089607000350952,
      "logps/chosen": -112.4192886352539,
      "logps/rejected": -265.775634765625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9556472897529602,
      "rewards/margins": 15.412418365478516,
      "rewards/rejected": -14.456771850585938,
      "step": 3229
    },
    {
      "epoch": 1.292,
      "grad_norm": 0.34212762117385864,
      "learning_rate": 5.694666666666666e-07,
      "logits/chosen": -2.5880134105682373,
      "logits/rejected": -2.353803873062134,
      "logps/chosen": -66.81500244140625,
      "logps/rejected": -150.4090576171875,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.022141456604003906,
      "rewards/margins": 8.708446502685547,
      "rewards/rejected": -8.686305046081543,
      "step": 3230
    },
    {
      "epoch": 1.2924,
      "grad_norm": 0.016272934153676033,
      "learning_rate": 5.693333333333333e-07,
      "logits/chosen": -3.271505832672119,
      "logits/rejected": -2.5531232357025146,
      "logps/chosen": -61.37775421142578,
      "logps/rejected": -159.7638397216797,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2207893133163452,
      "rewards/margins": 11.492770195007324,
      "rewards/rejected": -10.271981239318848,
      "step": 3231
    },
    {
      "epoch": 1.2928,
      "grad_norm": 0.15794624388217926,
      "learning_rate": 5.692e-07,
      "logits/chosen": -2.629487991333008,
      "logits/rejected": -2.072796583175659,
      "logps/chosen": -101.06320190429688,
      "logps/rejected": -129.28582763671875,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.18084965646266937,
      "rewards/margins": 8.03985595703125,
      "rewards/rejected": -8.22070598602295,
      "step": 3232
    },
    {
      "epoch": 1.2932000000000001,
      "grad_norm": 0.5591390132904053,
      "learning_rate": 5.690666666666667e-07,
      "logits/chosen": -2.3588476181030273,
      "logits/rejected": -2.0443153381347656,
      "logps/chosen": -230.95774841308594,
      "logps/rejected": -177.026611328125,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.152787685394287,
      "rewards/margins": 6.8208394050598145,
      "rewards/rejected": -9.973627090454102,
      "step": 3233
    },
    {
      "epoch": 1.2936,
      "grad_norm": 0.006470825988799334,
      "learning_rate": 5.689333333333333e-07,
      "logits/chosen": -2.3252792358398438,
      "logits/rejected": -1.5533297061920166,
      "logps/chosen": -165.0842742919922,
      "logps/rejected": -211.0037384033203,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31106263399124146,
      "rewards/margins": 11.408834457397461,
      "rewards/rejected": -11.097770690917969,
      "step": 3234
    },
    {
      "epoch": 1.294,
      "grad_norm": 11.416861534118652,
      "learning_rate": 5.688e-07,
      "logits/chosen": -2.880326271057129,
      "logits/rejected": -2.744079113006592,
      "logps/chosen": -172.23245239257812,
      "logps/rejected": -108.92965698242188,
      "loss": 0.0489,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.46253588795661926,
      "rewards/margins": 3.1939592361450195,
      "rewards/rejected": -3.6564950942993164,
      "step": 3235
    },
    {
      "epoch": 1.2944,
      "grad_norm": 0.012293701060116291,
      "learning_rate": 5.686666666666667e-07,
      "logits/chosen": -2.2553529739379883,
      "logits/rejected": -1.5751726627349854,
      "logps/chosen": -211.95205688476562,
      "logps/rejected": -246.9935302734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7895827889442444,
      "rewards/margins": 10.973800659179688,
      "rewards/rejected": -11.763382911682129,
      "step": 3236
    },
    {
      "epoch": 1.2948,
      "grad_norm": 0.0010364281479269266,
      "learning_rate": 5.685333333333333e-07,
      "logits/chosen": -2.5691819190979004,
      "logits/rejected": -1.7360029220581055,
      "logps/chosen": -93.21115112304688,
      "logps/rejected": -220.50595092773438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18207283318042755,
      "rewards/margins": 14.038787841796875,
      "rewards/rejected": -13.85671615600586,
      "step": 3237
    },
    {
      "epoch": 1.2952,
      "grad_norm": 2.2629642486572266,
      "learning_rate": 5.684e-07,
      "logits/chosen": -2.821354866027832,
      "logits/rejected": -2.385017156600952,
      "logps/chosen": -101.87788391113281,
      "logps/rejected": -121.19129943847656,
      "loss": 0.0144,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8982036113739014,
      "rewards/margins": 6.998635768890381,
      "rewards/rejected": -6.100432395935059,
      "step": 3238
    },
    {
      "epoch": 1.2955999999999999,
      "grad_norm": 0.025918642058968544,
      "learning_rate": 5.682666666666666e-07,
      "logits/chosen": -2.632412910461426,
      "logits/rejected": -2.0174989700317383,
      "logps/chosen": -171.1163330078125,
      "logps/rejected": -200.2877655029297,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.046141505241394,
      "rewards/margins": 10.464006423950195,
      "rewards/rejected": -11.510147094726562,
      "step": 3239
    },
    {
      "epoch": 1.296,
      "grad_norm": 0.043050628155469894,
      "learning_rate": 5.681333333333333e-07,
      "logits/chosen": -2.748760223388672,
      "logits/rejected": -2.2733395099639893,
      "logps/chosen": -105.20243835449219,
      "logps/rejected": -133.9905242919922,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7288776636123657,
      "rewards/margins": 8.495488166809082,
      "rewards/rejected": -9.224365234375,
      "step": 3240
    },
    {
      "epoch": 1.2964,
      "grad_norm": 0.7721706628799438,
      "learning_rate": 5.679999999999999e-07,
      "logits/chosen": -2.9845707416534424,
      "logits/rejected": -2.8488855361938477,
      "logps/chosen": -84.28450775146484,
      "logps/rejected": -97.85888671875,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.004210662096738815,
      "rewards/margins": 5.436619281768799,
      "rewards/rejected": -5.440829753875732,
      "step": 3241
    },
    {
      "epoch": 1.2968,
      "grad_norm": 0.0715545266866684,
      "learning_rate": 5.678666666666666e-07,
      "logits/chosen": -3.263812303543091,
      "logits/rejected": -2.8534326553344727,
      "logps/chosen": -66.0033950805664,
      "logps/rejected": -108.78630065917969,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6756284832954407,
      "rewards/margins": 7.56590461730957,
      "rewards/rejected": -6.890275955200195,
      "step": 3242
    },
    {
      "epoch": 1.2972000000000001,
      "grad_norm": 0.31547898054122925,
      "learning_rate": 5.677333333333333e-07,
      "logits/chosen": -3.1886773109436035,
      "logits/rejected": -2.6852526664733887,
      "logps/chosen": -53.93423080444336,
      "logps/rejected": -137.70242309570312,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5012539029121399,
      "rewards/margins": 8.780023574829102,
      "rewards/rejected": -8.278770446777344,
      "step": 3243
    },
    {
      "epoch": 1.2976,
      "grad_norm": 0.007598712109029293,
      "learning_rate": 5.676e-07,
      "logits/chosen": -2.5467517375946045,
      "logits/rejected": -1.8854777812957764,
      "logps/chosen": -91.1258544921875,
      "logps/rejected": -156.47608947753906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3267624378204346,
      "rewards/margins": 11.104637145996094,
      "rewards/rejected": -9.777874946594238,
      "step": 3244
    },
    {
      "epoch": 1.298,
      "grad_norm": 0.9364087581634521,
      "learning_rate": 5.674666666666667e-07,
      "logits/chosen": -2.877983570098877,
      "logits/rejected": -2.4275550842285156,
      "logps/chosen": -89.96583557128906,
      "logps/rejected": -151.57859802246094,
      "loss": 0.0068,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7883914709091187,
      "rewards/margins": 9.436639785766602,
      "rewards/rejected": -8.648248672485352,
      "step": 3245
    },
    {
      "epoch": 1.2984,
      "grad_norm": 0.25827595591545105,
      "learning_rate": 5.673333333333334e-07,
      "logits/chosen": -2.5913491249084473,
      "logits/rejected": -2.1599855422973633,
      "logps/chosen": -155.41647338867188,
      "logps/rejected": -173.0558319091797,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5090755224227905,
      "rewards/margins": 8.386603355407715,
      "rewards/rejected": -7.877527236938477,
      "step": 3246
    },
    {
      "epoch": 1.2988,
      "grad_norm": 59.58027648925781,
      "learning_rate": 5.672e-07,
      "logits/chosen": -2.872159481048584,
      "logits/rejected": -2.609790086746216,
      "logps/chosen": -140.19271850585938,
      "logps/rejected": -122.37822723388672,
      "loss": 0.4717,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -3.0782272815704346,
      "rewards/margins": 4.9551682472229,
      "rewards/rejected": -8.033395767211914,
      "step": 3247
    },
    {
      "epoch": 1.2992,
      "grad_norm": 1.4176511764526367,
      "learning_rate": 5.670666666666667e-07,
      "logits/chosen": -2.987462043762207,
      "logits/rejected": -3.0205307006835938,
      "logps/chosen": -117.50991821289062,
      "logps/rejected": -110.33792114257812,
      "loss": 0.0099,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5528709888458252,
      "rewards/margins": 4.63869571685791,
      "rewards/rejected": -6.191566467285156,
      "step": 3248
    },
    {
      "epoch": 1.2995999999999999,
      "grad_norm": 0.16791632771492004,
      "learning_rate": 5.669333333333332e-07,
      "logits/chosen": -2.779853105545044,
      "logits/rejected": -2.2952358722686768,
      "logps/chosen": -121.00334930419922,
      "logps/rejected": -246.31723022460938,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3260452151298523,
      "rewards/margins": 8.98411750793457,
      "rewards/rejected": -8.658071517944336,
      "step": 3249
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.1509472131729126,
      "learning_rate": 5.667999999999999e-07,
      "logits/chosen": -2.5876827239990234,
      "logits/rejected": -2.1413488388061523,
      "logps/chosen": -72.74319458007812,
      "logps/rejected": -156.9911651611328,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.12564793229103088,
      "rewards/margins": 8.19294261932373,
      "rewards/rejected": -8.318591117858887,
      "step": 3250
    },
    {
      "epoch": 1.3004,
      "grad_norm": 0.11987560987472534,
      "learning_rate": 5.666666666666666e-07,
      "logits/chosen": -2.7874035835266113,
      "logits/rejected": -1.9681628942489624,
      "logps/chosen": -108.06086730957031,
      "logps/rejected": -154.17031860351562,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.25709420442581177,
      "rewards/margins": 9.64444351196289,
      "rewards/rejected": -9.901538848876953,
      "step": 3251
    },
    {
      "epoch": 1.3008,
      "grad_norm": 0.1821703165769577,
      "learning_rate": 5.665333333333333e-07,
      "logits/chosen": -2.8633198738098145,
      "logits/rejected": -2.3754003047943115,
      "logps/chosen": -54.991397857666016,
      "logps/rejected": -129.5911102294922,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0398353636264801,
      "rewards/margins": 7.574883937835693,
      "rewards/rejected": -7.614719390869141,
      "step": 3252
    },
    {
      "epoch": 1.3012000000000001,
      "grad_norm": 0.3656543493270874,
      "learning_rate": 5.664e-07,
      "logits/chosen": -3.0805115699768066,
      "logits/rejected": -2.741436004638672,
      "logps/chosen": -100.11048889160156,
      "logps/rejected": -140.7788543701172,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03507041931152344,
      "rewards/margins": 7.09669303894043,
      "rewards/rejected": -7.061622619628906,
      "step": 3253
    },
    {
      "epoch": 1.3016,
      "grad_norm": 220.7569580078125,
      "learning_rate": 5.662666666666667e-07,
      "logits/chosen": -2.403735399246216,
      "logits/rejected": -2.377152442932129,
      "logps/chosen": -190.56484985351562,
      "logps/rejected": -142.38580322265625,
      "loss": 0.9187,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -4.633515357971191,
      "rewards/margins": 3.4082329273223877,
      "rewards/rejected": -8.041748046875,
      "step": 3254
    },
    {
      "epoch": 1.302,
      "grad_norm": 0.00038961757672950625,
      "learning_rate": 5.661333333333334e-07,
      "logits/chosen": -2.943087100982666,
      "logits/rejected": -2.0628347396850586,
      "logps/chosen": -61.24660110473633,
      "logps/rejected": -216.4632110595703,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0846118927001953,
      "rewards/margins": 15.66253662109375,
      "rewards/rejected": -14.577924728393555,
      "step": 3255
    },
    {
      "epoch": 1.3024,
      "grad_norm": 0.015655215829610825,
      "learning_rate": 5.66e-07,
      "logits/chosen": -2.7051315307617188,
      "logits/rejected": -2.207871437072754,
      "logps/chosen": -162.8792266845703,
      "logps/rejected": -139.46981811523438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.298174262046814,
      "rewards/margins": 9.561393737792969,
      "rewards/rejected": -8.263219833374023,
      "step": 3256
    },
    {
      "epoch": 1.3028,
      "grad_norm": 0.31158193945884705,
      "learning_rate": 5.658666666666667e-07,
      "logits/chosen": -2.4634907245635986,
      "logits/rejected": -2.3508734703063965,
      "logps/chosen": -122.30364990234375,
      "logps/rejected": -113.41290283203125,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5859134197235107,
      "rewards/margins": 6.131772041320801,
      "rewards/rejected": -5.545858383178711,
      "step": 3257
    },
    {
      "epoch": 1.3032,
      "grad_norm": 0.07155144214630127,
      "learning_rate": 5.657333333333332e-07,
      "logits/chosen": -2.6061341762542725,
      "logits/rejected": -1.7818760871887207,
      "logps/chosen": -39.055259704589844,
      "logps/rejected": -146.9809112548828,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5311453938484192,
      "rewards/margins": 7.70211124420166,
      "rewards/rejected": -7.170965671539307,
      "step": 3258
    },
    {
      "epoch": 1.3035999999999999,
      "grad_norm": 0.00012130394316045567,
      "learning_rate": 5.655999999999999e-07,
      "logits/chosen": -2.5525460243225098,
      "logits/rejected": -1.7219078540802002,
      "logps/chosen": -63.050689697265625,
      "logps/rejected": -222.1529083251953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5401127338409424,
      "rewards/margins": 15.333551406860352,
      "rewards/rejected": -13.793439865112305,
      "step": 3259
    },
    {
      "epoch": 1.304,
      "grad_norm": 0.8364986181259155,
      "learning_rate": 5.654666666666666e-07,
      "logits/chosen": -2.759739398956299,
      "logits/rejected": -2.414684772491455,
      "logps/chosen": -107.56686401367188,
      "logps/rejected": -215.21682739257812,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0775291919708252,
      "rewards/margins": 5.923480033874512,
      "rewards/rejected": -7.001009464263916,
      "step": 3260
    },
    {
      "epoch": 1.3044,
      "grad_norm": 0.14226140081882477,
      "learning_rate": 5.653333333333333e-07,
      "logits/chosen": -2.390752077102661,
      "logits/rejected": -1.528209924697876,
      "logps/chosen": -180.65277099609375,
      "logps/rejected": -138.0552978515625,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.46030351519584656,
      "rewards/margins": 7.379434585571289,
      "rewards/rejected": -7.839738368988037,
      "step": 3261
    },
    {
      "epoch": 1.3048,
      "grad_norm": 3.9879648685455322,
      "learning_rate": 5.652e-07,
      "logits/chosen": -2.5261237621307373,
      "logits/rejected": -2.2826309204101562,
      "logps/chosen": -200.34959411621094,
      "logps/rejected": -176.91705322265625,
      "loss": 0.0161,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.7784342765808105,
      "rewards/margins": 5.442121982574463,
      "rewards/rejected": -8.220556259155273,
      "step": 3262
    },
    {
      "epoch": 1.3052000000000001,
      "grad_norm": 0.25308123230934143,
      "learning_rate": 5.650666666666667e-07,
      "logits/chosen": -3.1914920806884766,
      "logits/rejected": -2.8032424449920654,
      "logps/chosen": -51.34552764892578,
      "logps/rejected": -116.43670654296875,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3227181434631348,
      "rewards/margins": 8.416214942932129,
      "rewards/rejected": -7.093496322631836,
      "step": 3263
    },
    {
      "epoch": 1.3056,
      "grad_norm": 0.0025753353256732225,
      "learning_rate": 5.649333333333333e-07,
      "logits/chosen": -2.7299752235412598,
      "logits/rejected": -1.9682645797729492,
      "logps/chosen": -137.88046264648438,
      "logps/rejected": -195.94082641601562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.053744126111269,
      "rewards/margins": 12.889402389526367,
      "rewards/rejected": -12.835658073425293,
      "step": 3264
    },
    {
      "epoch": 1.306,
      "grad_norm": 0.050060562789440155,
      "learning_rate": 5.648e-07,
      "logits/chosen": -2.798449993133545,
      "logits/rejected": -2.032470226287842,
      "logps/chosen": -113.7314453125,
      "logps/rejected": -227.724609375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2718769311904907,
      "rewards/margins": 10.535334587097168,
      "rewards/rejected": -11.807211875915527,
      "step": 3265
    },
    {
      "epoch": 1.3064,
      "grad_norm": 0.03341960906982422,
      "learning_rate": 5.646666666666667e-07,
      "logits/chosen": -2.9589614868164062,
      "logits/rejected": -2.679547071456909,
      "logps/chosen": -113.38496398925781,
      "logps/rejected": -136.36642456054688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07530251145362854,
      "rewards/margins": 8.736785888671875,
      "rewards/rejected": -8.661482810974121,
      "step": 3266
    },
    {
      "epoch": 1.3068,
      "grad_norm": 0.004240675829350948,
      "learning_rate": 5.645333333333333e-07,
      "logits/chosen": -2.60903263092041,
      "logits/rejected": -2.116271495819092,
      "logps/chosen": -72.80264282226562,
      "logps/rejected": -173.47488403320312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.704127550125122,
      "rewards/margins": 11.160743713378906,
      "rewards/rejected": -9.456615447998047,
      "step": 3267
    },
    {
      "epoch": 1.3072,
      "grad_norm": 0.00959707796573639,
      "learning_rate": 5.643999999999999e-07,
      "logits/chosen": -2.8576982021331787,
      "logits/rejected": -2.1624624729156494,
      "logps/chosen": -114.64801788330078,
      "logps/rejected": -158.80589294433594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.15273743867874146,
      "rewards/margins": 11.378175735473633,
      "rewards/rejected": -11.530913352966309,
      "step": 3268
    },
    {
      "epoch": 1.3075999999999999,
      "grad_norm": 0.3466692864894867,
      "learning_rate": 5.642666666666666e-07,
      "logits/chosen": -2.361705780029297,
      "logits/rejected": -1.6179077625274658,
      "logps/chosen": -147.94686889648438,
      "logps/rejected": -208.85987854003906,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4050480127334595,
      "rewards/margins": 8.676668167114258,
      "rewards/rejected": -7.27161979675293,
      "step": 3269
    },
    {
      "epoch": 1.308,
      "grad_norm": 0.0014355388702824712,
      "learning_rate": 5.641333333333333e-07,
      "logits/chosen": -2.7299013137817383,
      "logits/rejected": -1.9735422134399414,
      "logps/chosen": -184.7411346435547,
      "logps/rejected": -199.099365234375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11631965637207031,
      "rewards/margins": 12.243447303771973,
      "rewards/rejected": -12.127127647399902,
      "step": 3270
    },
    {
      "epoch": 1.3084,
      "grad_norm": 0.001353548956103623,
      "learning_rate": 5.639999999999999e-07,
      "logits/chosen": -2.4561257362365723,
      "logits/rejected": -1.8141984939575195,
      "logps/chosen": -123.70307922363281,
      "logps/rejected": -156.78494262695312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.415217638015747,
      "rewards/margins": 11.763538360595703,
      "rewards/rejected": -10.348320960998535,
      "step": 3271
    },
    {
      "epoch": 1.3088,
      "grad_norm": 0.0029592777136713266,
      "learning_rate": 5.638666666666666e-07,
      "logits/chosen": -2.566370964050293,
      "logits/rejected": -1.8021923303604126,
      "logps/chosen": -51.5621337890625,
      "logps/rejected": -170.35275268554688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3920774459838867,
      "rewards/margins": 12.228496551513672,
      "rewards/rejected": -9.836419105529785,
      "step": 3272
    },
    {
      "epoch": 1.3092,
      "grad_norm": 0.04925835505127907,
      "learning_rate": 5.637333333333333e-07,
      "logits/chosen": -2.5266835689544678,
      "logits/rejected": -1.5173733234405518,
      "logps/chosen": -176.96282958984375,
      "logps/rejected": -150.74468994140625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.20859679579734802,
      "rewards/margins": 8.7911376953125,
      "rewards/rejected": -8.999734878540039,
      "step": 3273
    },
    {
      "epoch": 1.3096,
      "grad_norm": 0.1835051327943802,
      "learning_rate": 5.636e-07,
      "logits/chosen": -3.173672676086426,
      "logits/rejected": -2.871772050857544,
      "logps/chosen": -50.14122009277344,
      "logps/rejected": -107.96099853515625,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.015875428915023804,
      "rewards/margins": 6.502938270568848,
      "rewards/rejected": -6.5188140869140625,
      "step": 3274
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.1033582016825676,
      "learning_rate": 5.634666666666667e-07,
      "logits/chosen": -2.6063482761383057,
      "logits/rejected": -1.990420937538147,
      "logps/chosen": -64.93992614746094,
      "logps/rejected": -216.1708526611328,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2558225393295288,
      "rewards/margins": 12.365442276000977,
      "rewards/rejected": -12.109619140625,
      "step": 3275
    },
    {
      "epoch": 1.3104,
      "grad_norm": 0.040626902133226395,
      "learning_rate": 5.633333333333334e-07,
      "logits/chosen": -3.2844882011413574,
      "logits/rejected": -2.6693477630615234,
      "logps/chosen": -61.688140869140625,
      "logps/rejected": -157.8997802734375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7785495519638062,
      "rewards/margins": 11.803707122802734,
      "rewards/rejected": -11.025157928466797,
      "step": 3276
    },
    {
      "epoch": 1.3108,
      "grad_norm": 0.03382178395986557,
      "learning_rate": 5.632e-07,
      "logits/chosen": -2.2030560970306396,
      "logits/rejected": -1.9201693534851074,
      "logps/chosen": -145.17996215820312,
      "logps/rejected": -164.41122436523438,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4602249264717102,
      "rewards/margins": 8.801362991333008,
      "rewards/rejected": -9.261588096618652,
      "step": 3277
    },
    {
      "epoch": 1.3112,
      "grad_norm": 0.0021809693425893784,
      "learning_rate": 5.630666666666667e-07,
      "logits/chosen": -2.609557628631592,
      "logits/rejected": -1.716344952583313,
      "logps/chosen": -92.38811492919922,
      "logps/rejected": -185.02322387695312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6721340417861938,
      "rewards/margins": 13.410767555236816,
      "rewards/rejected": -11.738633155822754,
      "step": 3278
    },
    {
      "epoch": 1.3115999999999999,
      "grad_norm": 1.4611951112747192,
      "learning_rate": 5.629333333333332e-07,
      "logits/chosen": -2.6373982429504395,
      "logits/rejected": -1.9471266269683838,
      "logps/chosen": -110.4928970336914,
      "logps/rejected": -119.26473999023438,
      "loss": 0.0107,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9403610229492188,
      "rewards/margins": 6.921645641326904,
      "rewards/rejected": -7.862006664276123,
      "step": 3279
    },
    {
      "epoch": 1.312,
      "grad_norm": 23.80489730834961,
      "learning_rate": 5.627999999999999e-07,
      "logits/chosen": -2.7003936767578125,
      "logits/rejected": -2.617326498031616,
      "logps/chosen": -132.9728240966797,
      "logps/rejected": -92.0345458984375,
      "loss": 0.1402,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.3626041412353516,
      "rewards/margins": 3.09544038772583,
      "rewards/rejected": -5.458044528961182,
      "step": 3280
    },
    {
      "epoch": 1.3124,
      "grad_norm": 0.0022612796165049076,
      "learning_rate": 5.626666666666666e-07,
      "logits/chosen": -2.38179874420166,
      "logits/rejected": -1.8453481197357178,
      "logps/chosen": -149.1124725341797,
      "logps/rejected": -247.04698181152344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0931648313999176,
      "rewards/margins": 12.897417068481445,
      "rewards/rejected": -12.804252624511719,
      "step": 3281
    },
    {
      "epoch": 1.3128,
      "grad_norm": 0.20149379968643188,
      "learning_rate": 5.625333333333333e-07,
      "logits/chosen": -3.143460273742676,
      "logits/rejected": -2.6517698764801025,
      "logps/chosen": -76.76224517822266,
      "logps/rejected": -108.99650573730469,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.598881721496582,
      "rewards/margins": 7.1824049949646,
      "rewards/rejected": -6.583522796630859,
      "step": 3282
    },
    {
      "epoch": 1.3132,
      "grad_norm": 7.941336631774902,
      "learning_rate": 5.624e-07,
      "logits/chosen": -2.9311373233795166,
      "logits/rejected": -2.979185104370117,
      "logps/chosen": -131.00343322753906,
      "logps/rejected": -75.32398223876953,
      "loss": 0.0655,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8802067041397095,
      "rewards/margins": 3.26206636428833,
      "rewards/rejected": -4.14227294921875,
      "step": 3283
    },
    {
      "epoch": 1.3136,
      "grad_norm": 0.777759850025177,
      "learning_rate": 5.622666666666667e-07,
      "logits/chosen": -2.761387348175049,
      "logits/rejected": -2.4266397953033447,
      "logps/chosen": -138.56964111328125,
      "logps/rejected": -177.81723022460938,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8889047503471375,
      "rewards/margins": 6.916998863220215,
      "rewards/rejected": -7.805903434753418,
      "step": 3284
    },
    {
      "epoch": 1.314,
      "grad_norm": 0.2154412865638733,
      "learning_rate": 5.621333333333334e-07,
      "logits/chosen": -3.1023635864257812,
      "logits/rejected": -2.4757490158081055,
      "logps/chosen": -77.9441909790039,
      "logps/rejected": -121.00336456298828,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05794599652290344,
      "rewards/margins": 6.567112922668457,
      "rewards/rejected": -6.509166717529297,
      "step": 3285
    },
    {
      "epoch": 1.3144,
      "grad_norm": 0.019881827756762505,
      "learning_rate": 5.620000000000001e-07,
      "logits/chosen": -2.4206833839416504,
      "logits/rejected": -1.8184106349945068,
      "logps/chosen": -234.77459716796875,
      "logps/rejected": -191.65603637695312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7594231367111206,
      "rewards/margins": 9.947267532348633,
      "rewards/rejected": -11.706690788269043,
      "step": 3286
    },
    {
      "epoch": 1.3148,
      "grad_norm": 0.05480710044503212,
      "learning_rate": 5.618666666666666e-07,
      "logits/chosen": -2.7776589393615723,
      "logits/rejected": -2.054452657699585,
      "logps/chosen": -43.792701721191406,
      "logps/rejected": -146.3719482421875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3345208168029785,
      "rewards/margins": 10.480973243713379,
      "rewards/rejected": -9.146452903747559,
      "step": 3287
    },
    {
      "epoch": 1.3152,
      "grad_norm": 0.07555324584245682,
      "learning_rate": 5.617333333333333e-07,
      "logits/chosen": -3.065390110015869,
      "logits/rejected": -2.4039173126220703,
      "logps/chosen": -89.95083618164062,
      "logps/rejected": -138.02838134765625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5685898065567017,
      "rewards/margins": 8.066925048828125,
      "rewards/rejected": -7.498335838317871,
      "step": 3288
    },
    {
      "epoch": 1.3155999999999999,
      "grad_norm": 38.992530822753906,
      "learning_rate": 5.615999999999999e-07,
      "logits/chosen": -2.7891898155212402,
      "logits/rejected": -2.0282742977142334,
      "logps/chosen": -118.43434143066406,
      "logps/rejected": -114.15972900390625,
      "loss": 0.2566,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7421356439590454,
      "rewards/margins": 5.6990203857421875,
      "rewards/rejected": -4.956884860992432,
      "step": 3289
    },
    {
      "epoch": 1.316,
      "grad_norm": 0.0021782866679131985,
      "learning_rate": 5.614666666666666e-07,
      "logits/chosen": -2.754882335662842,
      "logits/rejected": -1.9557690620422363,
      "logps/chosen": -94.76615142822266,
      "logps/rejected": -198.54258728027344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5566730499267578,
      "rewards/margins": 11.670251846313477,
      "rewards/rejected": -11.113578796386719,
      "step": 3290
    },
    {
      "epoch": 1.3164,
      "grad_norm": 0.2868497669696808,
      "learning_rate": 5.613333333333333e-07,
      "logits/chosen": -2.9957494735717773,
      "logits/rejected": -2.6398510932922363,
      "logps/chosen": -92.82537841796875,
      "logps/rejected": -118.60684204101562,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1954116821289062,
      "rewards/margins": 9.569287300109863,
      "rewards/rejected": -7.373875617980957,
      "step": 3291
    },
    {
      "epoch": 1.3168,
      "grad_norm": 0.14637652039527893,
      "learning_rate": 5.612e-07,
      "logits/chosen": -2.718414783477783,
      "logits/rejected": -2.580326557159424,
      "logps/chosen": -87.27314758300781,
      "logps/rejected": -173.5554656982422,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.202280879020691,
      "rewards/margins": 9.77017593383789,
      "rewards/rejected": -8.56789493560791,
      "step": 3292
    },
    {
      "epoch": 1.3172,
      "grad_norm": 1.548690915107727,
      "learning_rate": 5.610666666666667e-07,
      "logits/chosen": -3.077725887298584,
      "logits/rejected": -2.4607744216918945,
      "logps/chosen": -61.30974197387695,
      "logps/rejected": -117.21539306640625,
      "loss": 0.0131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.26101458072662354,
      "rewards/margins": 6.701085090637207,
      "rewards/rejected": -6.962100028991699,
      "step": 3293
    },
    {
      "epoch": 1.3176,
      "grad_norm": 0.5690876245498657,
      "learning_rate": 5.609333333333333e-07,
      "logits/chosen": -2.600821018218994,
      "logits/rejected": -2.5887279510498047,
      "logps/chosen": -75.0631332397461,
      "logps/rejected": -107.16694641113281,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.23995590209960938,
      "rewards/margins": 6.321916580200195,
      "rewards/rejected": -6.561872482299805,
      "step": 3294
    },
    {
      "epoch": 1.318,
      "grad_norm": 0.00956955086439848,
      "learning_rate": 5.608e-07,
      "logits/chosen": -3.1509413719177246,
      "logits/rejected": -2.4707040786743164,
      "logps/chosen": -88.5888671875,
      "logps/rejected": -162.97412109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0995193719863892,
      "rewards/margins": 11.497133255004883,
      "rewards/rejected": -10.397614479064941,
      "step": 3295
    },
    {
      "epoch": 1.3184,
      "grad_norm": 0.10400275141000748,
      "learning_rate": 5.606666666666666e-07,
      "logits/chosen": -2.541306972503662,
      "logits/rejected": -1.7657921314239502,
      "logps/chosen": -227.3146209716797,
      "logps/rejected": -143.53602600097656,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.388218641281128,
      "rewards/margins": 7.663687705993652,
      "rewards/rejected": -9.05190658569336,
      "step": 3296
    },
    {
      "epoch": 1.3188,
      "grad_norm": 0.006159696262329817,
      "learning_rate": 5.605333333333333e-07,
      "logits/chosen": -2.40860652923584,
      "logits/rejected": -1.4556162357330322,
      "logps/chosen": -175.83273315429688,
      "logps/rejected": -181.66836547851562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0853241682052612,
      "rewards/margins": 10.64493179321289,
      "rewards/rejected": -9.559608459472656,
      "step": 3297
    },
    {
      "epoch": 1.3192,
      "grad_norm": 0.30231910943984985,
      "learning_rate": 5.604e-07,
      "logits/chosen": -2.7216053009033203,
      "logits/rejected": -2.236232280731201,
      "logps/chosen": -172.7632598876953,
      "logps/rejected": -137.98114013671875,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15134122967720032,
      "rewards/margins": 8.831989288330078,
      "rewards/rejected": -8.680648803710938,
      "step": 3298
    },
    {
      "epoch": 1.3195999999999999,
      "grad_norm": 0.0031867665238678455,
      "learning_rate": 5.602666666666667e-07,
      "logits/chosen": -2.630134105682373,
      "logits/rejected": -1.5827311277389526,
      "logps/chosen": -120.53045654296875,
      "logps/rejected": -198.5823974609375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.482848882675171,
      "rewards/margins": 13.183099746704102,
      "rewards/rejected": -11.700250625610352,
      "step": 3299
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.07419935613870621,
      "learning_rate": 5.601333333333333e-07,
      "logits/chosen": -2.662414789199829,
      "logits/rejected": -2.247997522354126,
      "logps/chosen": -87.0706558227539,
      "logps/rejected": -149.29049682617188,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2908679246902466,
      "rewards/margins": 9.310569763183594,
      "rewards/rejected": -9.60143756866455,
      "step": 3300
    },
    {
      "epoch": 1.3204,
      "grad_norm": 0.030793340876698494,
      "learning_rate": 5.6e-07,
      "logits/chosen": -2.997278928756714,
      "logits/rejected": -2.430663824081421,
      "logps/chosen": -123.21143341064453,
      "logps/rejected": -166.67645263671875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.15336114168167114,
      "rewards/margins": 9.916584014892578,
      "rewards/rejected": -10.069945335388184,
      "step": 3301
    },
    {
      "epoch": 1.3208,
      "grad_norm": 0.0035986267030239105,
      "learning_rate": 5.598666666666666e-07,
      "logits/chosen": -2.7598166465759277,
      "logits/rejected": -1.8014838695526123,
      "logps/chosen": -93.73779296875,
      "logps/rejected": -182.0681915283203,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2564098834991455,
      "rewards/margins": 11.977872848510742,
      "rewards/rejected": -10.72146224975586,
      "step": 3302
    },
    {
      "epoch": 1.3212,
      "grad_norm": 1.8000833988189697,
      "learning_rate": 5.597333333333333e-07,
      "logits/chosen": -2.5494771003723145,
      "logits/rejected": -1.869781494140625,
      "logps/chosen": -178.00436401367188,
      "logps/rejected": -172.30459594726562,
      "loss": 0.0079,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6728198528289795,
      "rewards/margins": 6.481163024902344,
      "rewards/rejected": -8.153983116149902,
      "step": 3303
    },
    {
      "epoch": 1.3216,
      "grad_norm": 1.4702075719833374,
      "learning_rate": 5.596e-07,
      "logits/chosen": -2.8688464164733887,
      "logits/rejected": -2.442054033279419,
      "logps/chosen": -58.71245193481445,
      "logps/rejected": -142.24520874023438,
      "loss": 0.0105,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0842965841293335,
      "rewards/margins": 7.7924604415893555,
      "rewards/rejected": -7.876757621765137,
      "step": 3304
    },
    {
      "epoch": 1.322,
      "grad_norm": 0.31832507252693176,
      "learning_rate": 5.594666666666666e-07,
      "logits/chosen": -3.1903915405273438,
      "logits/rejected": -2.9456229209899902,
      "logps/chosen": -79.07511901855469,
      "logps/rejected": -94.70713806152344,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08884487301111221,
      "rewards/margins": 6.219587326049805,
      "rewards/rejected": -6.130742073059082,
      "step": 3305
    },
    {
      "epoch": 1.3224,
      "grad_norm": 0.05469256639480591,
      "learning_rate": 5.593333333333333e-07,
      "logits/chosen": -3.1061978340148926,
      "logits/rejected": -2.8278708457946777,
      "logps/chosen": -61.808448791503906,
      "logps/rejected": -130.88665771484375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.008993148803710938,
      "rewards/margins": 7.955353736877441,
      "rewards/rejected": -7.9463605880737305,
      "step": 3306
    },
    {
      "epoch": 1.3228,
      "grad_norm": 0.792855978012085,
      "learning_rate": 5.592e-07,
      "logits/chosen": -2.9553940296173096,
      "logits/rejected": -2.663875102996826,
      "logps/chosen": -87.46269226074219,
      "logps/rejected": -142.08978271484375,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2211609035730362,
      "rewards/margins": 8.874814987182617,
      "rewards/rejected": -9.095974922180176,
      "step": 3307
    },
    {
      "epoch": 1.3232,
      "grad_norm": 0.6896833181381226,
      "learning_rate": 5.590666666666667e-07,
      "logits/chosen": -2.938467264175415,
      "logits/rejected": -2.6190989017486572,
      "logps/chosen": -97.8218994140625,
      "logps/rejected": -103.53915405273438,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9547222256660461,
      "rewards/margins": 6.206608295440674,
      "rewards/rejected": -5.251886367797852,
      "step": 3308
    },
    {
      "epoch": 1.3235999999999999,
      "grad_norm": 0.023636214435100555,
      "learning_rate": 5.589333333333333e-07,
      "logits/chosen": -2.8006861209869385,
      "logits/rejected": -2.3009612560272217,
      "logps/chosen": -106.66279602050781,
      "logps/rejected": -193.15658569335938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6337311267852783,
      "rewards/margins": 10.680727005004883,
      "rewards/rejected": -9.046996116638184,
      "step": 3309
    },
    {
      "epoch": 1.324,
      "grad_norm": 4.468459606170654,
      "learning_rate": 5.588e-07,
      "logits/chosen": -3.2750179767608643,
      "logits/rejected": -2.864163637161255,
      "logps/chosen": -41.58802032470703,
      "logps/rejected": -75.20946502685547,
      "loss": 0.0608,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3085882067680359,
      "rewards/margins": 5.151195049285889,
      "rewards/rejected": -4.842606544494629,
      "step": 3310
    },
    {
      "epoch": 1.3244,
      "grad_norm": 0.011268427595496178,
      "learning_rate": 5.586666666666666e-07,
      "logits/chosen": -2.3923707008361816,
      "logits/rejected": -1.4718607664108276,
      "logps/chosen": -75.62510681152344,
      "logps/rejected": -155.7015380859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3193886280059814,
      "rewards/margins": 10.578317642211914,
      "rewards/rejected": -9.258928298950195,
      "step": 3311
    },
    {
      "epoch": 1.3248,
      "grad_norm": 0.08675534278154373,
      "learning_rate": 5.585333333333333e-07,
      "logits/chosen": -2.945859909057617,
      "logits/rejected": -2.4950342178344727,
      "logps/chosen": -48.41105651855469,
      "logps/rejected": -146.05503845214844,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.675869345664978,
      "rewards/margins": 10.197422981262207,
      "rewards/rejected": -9.521553993225098,
      "step": 3312
    },
    {
      "epoch": 1.3252,
      "grad_norm": 0.22903695702552795,
      "learning_rate": 5.584e-07,
      "logits/chosen": -3.1805155277252197,
      "logits/rejected": -2.760439395904541,
      "logps/chosen": -67.24437713623047,
      "logps/rejected": -127.31717681884766,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.06899094581604,
      "rewards/margins": 6.523340225219727,
      "rewards/rejected": -7.5923309326171875,
      "step": 3313
    },
    {
      "epoch": 1.3256000000000001,
      "grad_norm": 0.37267011404037476,
      "learning_rate": 5.582666666666667e-07,
      "logits/chosen": -2.6521759033203125,
      "logits/rejected": -2.188718795776367,
      "logps/chosen": -150.43417358398438,
      "logps/rejected": -161.97203063964844,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.06830672919750214,
      "rewards/margins": 8.596395492553711,
      "rewards/rejected": -8.664702415466309,
      "step": 3314
    },
    {
      "epoch": 1.326,
      "grad_norm": 0.16780808568000793,
      "learning_rate": 5.581333333333333e-07,
      "logits/chosen": -2.6071581840515137,
      "logits/rejected": -2.121316432952881,
      "logps/chosen": -96.82058715820312,
      "logps/rejected": -119.58877563476562,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6671440601348877,
      "rewards/margins": 7.1184468269348145,
      "rewards/rejected": -5.451302528381348,
      "step": 3315
    },
    {
      "epoch": 1.3264,
      "grad_norm": 0.2369810938835144,
      "learning_rate": 5.58e-07,
      "logits/chosen": -2.7247605323791504,
      "logits/rejected": -2.184828281402588,
      "logps/chosen": -107.03810119628906,
      "logps/rejected": -137.00205993652344,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7944542169570923,
      "rewards/margins": 8.169547080993652,
      "rewards/rejected": -7.37509298324585,
      "step": 3316
    },
    {
      "epoch": 1.3268,
      "grad_norm": 4.113683700561523,
      "learning_rate": 5.578666666666666e-07,
      "logits/chosen": -2.9485116004943848,
      "logits/rejected": -2.673142433166504,
      "logps/chosen": -90.71157836914062,
      "logps/rejected": -85.35017395019531,
      "loss": 0.038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.22331926226615906,
      "rewards/margins": 3.2648911476135254,
      "rewards/rejected": -3.4882102012634277,
      "step": 3317
    },
    {
      "epoch": 1.3272,
      "grad_norm": 0.6480937004089355,
      "learning_rate": 5.577333333333333e-07,
      "logits/chosen": -2.706594944000244,
      "logits/rejected": -2.221747398376465,
      "logps/chosen": -88.36389923095703,
      "logps/rejected": -145.7603759765625,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0652261972427368,
      "rewards/margins": 6.8598151206970215,
      "rewards/rejected": -7.925041198730469,
      "step": 3318
    },
    {
      "epoch": 1.3276,
      "grad_norm": 0.001944997115060687,
      "learning_rate": 5.576e-07,
      "logits/chosen": -2.4348669052124023,
      "logits/rejected": -1.8077821731567383,
      "logps/chosen": -196.16073608398438,
      "logps/rejected": -194.01231384277344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.407515048980713,
      "rewards/margins": 11.799275398254395,
      "rewards/rejected": -13.206790924072266,
      "step": 3319
    },
    {
      "epoch": 1.328,
      "grad_norm": 0.059171661734580994,
      "learning_rate": 5.574666666666667e-07,
      "logits/chosen": -2.2550456523895264,
      "logits/rejected": -1.628459095954895,
      "logps/chosen": -178.7645721435547,
      "logps/rejected": -194.82357788085938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2154266834259033,
      "rewards/margins": 9.039360046386719,
      "rewards/rejected": -10.254786491394043,
      "step": 3320
    },
    {
      "epoch": 1.3284,
      "grad_norm": 8.739221572875977,
      "learning_rate": 5.573333333333333e-07,
      "logits/chosen": -3.010976791381836,
      "logits/rejected": -2.700498342514038,
      "logps/chosen": -74.90802001953125,
      "logps/rejected": -86.12101745605469,
      "loss": 0.078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7161678671836853,
      "rewards/margins": 4.005867004394531,
      "rewards/rejected": -4.722034931182861,
      "step": 3321
    },
    {
      "epoch": 1.3288,
      "grad_norm": 0.003685993840917945,
      "learning_rate": 5.572e-07,
      "logits/chosen": -2.5772063732147217,
      "logits/rejected": -2.028214454650879,
      "logps/chosen": -142.05938720703125,
      "logps/rejected": -176.7172393798828,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18781816959381104,
      "rewards/margins": 11.813316345214844,
      "rewards/rejected": -11.62549877166748,
      "step": 3322
    },
    {
      "epoch": 1.3292,
      "grad_norm": 0.0030831987969577312,
      "learning_rate": 5.570666666666667e-07,
      "logits/chosen": -2.753718376159668,
      "logits/rejected": -1.9834873676300049,
      "logps/chosen": -113.44466400146484,
      "logps/rejected": -180.89810180664062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0301669836044312,
      "rewards/margins": 12.972978591918945,
      "rewards/rejected": -11.942811965942383,
      "step": 3323
    },
    {
      "epoch": 1.3296000000000001,
      "grad_norm": 0.2503930926322937,
      "learning_rate": 5.569333333333332e-07,
      "logits/chosen": -3.0074620246887207,
      "logits/rejected": -2.720726251602173,
      "logps/chosen": -108.46527099609375,
      "logps/rejected": -162.32652282714844,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7127799987792969,
      "rewards/margins": 8.445723533630371,
      "rewards/rejected": -9.158502578735352,
      "step": 3324
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.023969357833266258,
      "learning_rate": 5.567999999999999e-07,
      "logits/chosen": -2.9813530445098877,
      "logits/rejected": -2.3082337379455566,
      "logps/chosen": -79.47689819335938,
      "logps/rejected": -202.717529296875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3890424966812134,
      "rewards/margins": 10.684328079223633,
      "rewards/rejected": -12.073369979858398,
      "step": 3325
    },
    {
      "epoch": 1.3304,
      "grad_norm": 0.014762151055037975,
      "learning_rate": 5.566666666666666e-07,
      "logits/chosen": -3.0749075412750244,
      "logits/rejected": -2.514313220977783,
      "logps/chosen": -63.30793380737305,
      "logps/rejected": -146.20367431640625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6005806922912598,
      "rewards/margins": 11.340031623840332,
      "rewards/rejected": -9.73945140838623,
      "step": 3326
    },
    {
      "epoch": 1.3308,
      "grad_norm": 0.05815570428967476,
      "learning_rate": 5.565333333333333e-07,
      "logits/chosen": -2.79010009765625,
      "logits/rejected": -2.1878128051757812,
      "logps/chosen": -116.04398345947266,
      "logps/rejected": -135.73394775390625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3822910189628601,
      "rewards/margins": 9.584650039672852,
      "rewards/rejected": -9.202359199523926,
      "step": 3327
    },
    {
      "epoch": 1.3312,
      "grad_norm": 0.8230701684951782,
      "learning_rate": 5.564e-07,
      "logits/chosen": -2.7230021953582764,
      "logits/rejected": -2.3775625228881836,
      "logps/chosen": -110.4449691772461,
      "logps/rejected": -100.1222152709961,
      "loss": 0.0074,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1594654321670532,
      "rewards/margins": 4.990971088409424,
      "rewards/rejected": -6.1504364013671875,
      "step": 3328
    },
    {
      "epoch": 1.3316,
      "grad_norm": 0.016437234356999397,
      "learning_rate": 5.562666666666667e-07,
      "logits/chosen": -2.5174813270568848,
      "logits/rejected": -2.194908618927002,
      "logps/chosen": -136.13198852539062,
      "logps/rejected": -193.94215393066406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4245464503765106,
      "rewards/margins": 9.999074935913086,
      "rewards/rejected": -10.423622131347656,
      "step": 3329
    },
    {
      "epoch": 1.332,
      "grad_norm": 2.6888794898986816,
      "learning_rate": 5.561333333333334e-07,
      "logits/chosen": -2.7537856101989746,
      "logits/rejected": -2.6553878784179688,
      "logps/chosen": -74.5810317993164,
      "logps/rejected": -94.245361328125,
      "loss": 0.0211,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9322765469551086,
      "rewards/margins": 4.411322593688965,
      "rewards/rejected": -5.34359884262085,
      "step": 3330
    },
    {
      "epoch": 1.3324,
      "grad_norm": 0.006203866563737392,
      "learning_rate": 5.560000000000001e-07,
      "logits/chosen": -2.3515031337738037,
      "logits/rejected": -1.7825216054916382,
      "logps/chosen": -167.35482788085938,
      "logps/rejected": -235.80197143554688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2041099071502686,
      "rewards/margins": 12.497528076171875,
      "rewards/rejected": -11.293418884277344,
      "step": 3331
    },
    {
      "epoch": 1.3328,
      "grad_norm": 1.940271019935608,
      "learning_rate": 5.558666666666666e-07,
      "logits/chosen": -2.8861303329467773,
      "logits/rejected": -2.8723249435424805,
      "logps/chosen": -55.89002990722656,
      "logps/rejected": -77.97638702392578,
      "loss": 0.0174,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.38079968094825745,
      "rewards/margins": 4.80494499206543,
      "rewards/rejected": -5.185744285583496,
      "step": 3332
    },
    {
      "epoch": 1.3332,
      "grad_norm": 0.8013779520988464,
      "learning_rate": 5.557333333333332e-07,
      "logits/chosen": -2.8046183586120605,
      "logits/rejected": -2.4203107357025146,
      "logps/chosen": -121.56468200683594,
      "logps/rejected": -172.49684143066406,
      "loss": 0.0061,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8765005469322205,
      "rewards/margins": 8.718145370483398,
      "rewards/rejected": -9.594646453857422,
      "step": 3333
    },
    {
      "epoch": 1.3336000000000001,
      "grad_norm": 0.3683863580226898,
      "learning_rate": 5.555999999999999e-07,
      "logits/chosen": -3.139680862426758,
      "logits/rejected": -2.750819206237793,
      "logps/chosen": -85.65076446533203,
      "logps/rejected": -151.5897216796875,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.323180228471756,
      "rewards/margins": 6.094637393951416,
      "rewards/rejected": -6.417818069458008,
      "step": 3334
    },
    {
      "epoch": 1.334,
      "grad_norm": 0.07495057582855225,
      "learning_rate": 5.554666666666666e-07,
      "logits/chosen": -2.815868854522705,
      "logits/rejected": -2.5887389183044434,
      "logps/chosen": -63.11224365234375,
      "logps/rejected": -125.49137878417969,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.819837212562561,
      "rewards/margins": 8.01613998413086,
      "rewards/rejected": -8.835977554321289,
      "step": 3335
    },
    {
      "epoch": 1.3344,
      "grad_norm": 0.009760688059031963,
      "learning_rate": 5.553333333333333e-07,
      "logits/chosen": -2.7553820610046387,
      "logits/rejected": -2.2530059814453125,
      "logps/chosen": -101.10598754882812,
      "logps/rejected": -214.62232971191406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.19311222434043884,
      "rewards/margins": 12.059267044067383,
      "rewards/rejected": -12.252378463745117,
      "step": 3336
    },
    {
      "epoch": 1.3348,
      "grad_norm": 1.818565845489502,
      "learning_rate": 5.552e-07,
      "logits/chosen": -2.960465431213379,
      "logits/rejected": -2.2689993381500244,
      "logps/chosen": -81.56743621826172,
      "logps/rejected": -111.2862777709961,
      "loss": 0.0127,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1978099346160889,
      "rewards/margins": 8.569072723388672,
      "rewards/rejected": -7.37126350402832,
      "step": 3337
    },
    {
      "epoch": 1.3352,
      "grad_norm": 0.006567166652530432,
      "learning_rate": 5.550666666666667e-07,
      "logits/chosen": -2.406541585922241,
      "logits/rejected": -1.861110806465149,
      "logps/chosen": -109.79939270019531,
      "logps/rejected": -345.009033203125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2662845849990845,
      "rewards/margins": 12.045927047729492,
      "rewards/rejected": -11.779642105102539,
      "step": 3338
    },
    {
      "epoch": 1.3356,
      "grad_norm": 1.4297435283660889,
      "learning_rate": 5.549333333333333e-07,
      "logits/chosen": -2.629913330078125,
      "logits/rejected": -2.213261127471924,
      "logps/chosen": -215.30690002441406,
      "logps/rejected": -165.5904541015625,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3701162338256836,
      "rewards/margins": 6.4349260330200195,
      "rewards/rejected": -6.805041790008545,
      "step": 3339
    },
    {
      "epoch": 1.336,
      "grad_norm": 0.0068909116089344025,
      "learning_rate": 5.548e-07,
      "logits/chosen": -2.800665855407715,
      "logits/rejected": -2.054112195968628,
      "logps/chosen": -175.88494873046875,
      "logps/rejected": -191.15512084960938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1404106616973877,
      "rewards/margins": 10.902374267578125,
      "rewards/rejected": -12.042784690856934,
      "step": 3340
    },
    {
      "epoch": 1.3364,
      "grad_norm": 0.0029145563021302223,
      "learning_rate": 5.546666666666667e-07,
      "logits/chosen": -2.415271043777466,
      "logits/rejected": -1.3906338214874268,
      "logps/chosen": -130.46524047851562,
      "logps/rejected": -245.5122833251953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.275183916091919,
      "rewards/margins": 15.605074882507324,
      "rewards/rejected": -14.329891204833984,
      "step": 3341
    },
    {
      "epoch": 1.3368,
      "grad_norm": 0.6375557780265808,
      "learning_rate": 5.545333333333333e-07,
      "logits/chosen": -2.9926106929779053,
      "logits/rejected": -2.8496522903442383,
      "logps/chosen": -124.37844848632812,
      "logps/rejected": -94.94129943847656,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2592800259590149,
      "rewards/margins": 6.38645076751709,
      "rewards/rejected": -6.127171039581299,
      "step": 3342
    },
    {
      "epoch": 1.3372,
      "grad_norm": 0.03287658467888832,
      "learning_rate": 5.543999999999999e-07,
      "logits/chosen": -2.5812010765075684,
      "logits/rejected": -2.0681517124176025,
      "logps/chosen": -88.35969543457031,
      "logps/rejected": -128.5784912109375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7242969870567322,
      "rewards/margins": 8.419713973999023,
      "rewards/rejected": -7.6954169273376465,
      "step": 3343
    },
    {
      "epoch": 1.3376000000000001,
      "grad_norm": 0.0941840335726738,
      "learning_rate": 5.542666666666666e-07,
      "logits/chosen": -2.9429702758789062,
      "logits/rejected": -2.1257615089416504,
      "logps/chosen": -68.81741333007812,
      "logps/rejected": -170.74386596679688,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.024810791015625,
      "rewards/margins": 10.867147445678711,
      "rewards/rejected": -9.842336654663086,
      "step": 3344
    },
    {
      "epoch": 1.338,
      "grad_norm": 7.528711795806885,
      "learning_rate": 5.541333333333333e-07,
      "logits/chosen": -3.2670540809631348,
      "logits/rejected": -3.0994865894317627,
      "logps/chosen": -60.30435562133789,
      "logps/rejected": -111.21075439453125,
      "loss": 0.1035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4550018310546875,
      "rewards/margins": 5.465985298156738,
      "rewards/rejected": -6.920987129211426,
      "step": 3345
    },
    {
      "epoch": 1.3384,
      "grad_norm": 0.021736042574048042,
      "learning_rate": 5.54e-07,
      "logits/chosen": -2.8929805755615234,
      "logits/rejected": -1.9964861869812012,
      "logps/chosen": -122.46641540527344,
      "logps/rejected": -196.03573608398438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9971961975097656,
      "rewards/margins": 9.763973236083984,
      "rewards/rejected": -11.76116943359375,
      "step": 3346
    },
    {
      "epoch": 1.3388,
      "grad_norm": 0.3579973578453064,
      "learning_rate": 5.538666666666666e-07,
      "logits/chosen": -2.475192070007324,
      "logits/rejected": -1.9717075824737549,
      "logps/chosen": -128.6002197265625,
      "logps/rejected": -181.28338623046875,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5473190546035767,
      "rewards/margins": 7.032209873199463,
      "rewards/rejected": -8.57952880859375,
      "step": 3347
    },
    {
      "epoch": 1.3392,
      "grad_norm": 0.052148159593343735,
      "learning_rate": 5.537333333333333e-07,
      "logits/chosen": -2.788060188293457,
      "logits/rejected": -2.5154294967651367,
      "logps/chosen": -122.49476623535156,
      "logps/rejected": -150.28233337402344,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2438369989395142,
      "rewards/margins": 8.086749076843262,
      "rewards/rejected": -9.330585479736328,
      "step": 3348
    },
    {
      "epoch": 1.3396,
      "grad_norm": 0.6403159499168396,
      "learning_rate": 5.536e-07,
      "logits/chosen": -3.2399866580963135,
      "logits/rejected": -2.656745195388794,
      "logps/chosen": -52.98233413696289,
      "logps/rejected": -99.8311767578125,
      "loss": 0.0049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9365543127059937,
      "rewards/margins": 5.672357082366943,
      "rewards/rejected": -4.73580265045166,
      "step": 3349
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.6024071574211121,
      "learning_rate": 5.534666666666667e-07,
      "logits/chosen": -3.0638957023620605,
      "logits/rejected": -2.582008123397827,
      "logps/chosen": -65.8452377319336,
      "logps/rejected": -117.02412414550781,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8360394239425659,
      "rewards/margins": 6.591835975646973,
      "rewards/rejected": -5.755796432495117,
      "step": 3350
    },
    {
      "epoch": 1.3404,
      "grad_norm": 16.958066940307617,
      "learning_rate": 5.533333333333334e-07,
      "logits/chosen": -2.629960298538208,
      "logits/rejected": -2.227587938308716,
      "logps/chosen": -167.5509033203125,
      "logps/rejected": -139.99267578125,
      "loss": 0.0878,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9573745727539062,
      "rewards/margins": 7.261425018310547,
      "rewards/rejected": -9.218799591064453,
      "step": 3351
    },
    {
      "epoch": 1.3408,
      "grad_norm": 0.0032376244198530912,
      "learning_rate": 5.532e-07,
      "logits/chosen": -2.8895444869995117,
      "logits/rejected": -2.170030117034912,
      "logps/chosen": -60.46089553833008,
      "logps/rejected": -185.89276123046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.34721839427948,
      "rewards/margins": 11.933469772338867,
      "rewards/rejected": -10.586251258850098,
      "step": 3352
    },
    {
      "epoch": 1.3412,
      "grad_norm": 0.26981350779533386,
      "learning_rate": 5.530666666666666e-07,
      "logits/chosen": -3.1702651977539062,
      "logits/rejected": -2.6986825466156006,
      "logps/chosen": -64.73817443847656,
      "logps/rejected": -119.83202362060547,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5998649597167969,
      "rewards/margins": 7.757978439331055,
      "rewards/rejected": -7.158113479614258,
      "step": 3353
    },
    {
      "epoch": 1.3416000000000001,
      "grad_norm": 4.331331253051758,
      "learning_rate": 5.529333333333333e-07,
      "logits/chosen": -2.9202322959899902,
      "logits/rejected": -2.5172572135925293,
      "logps/chosen": -120.4178466796875,
      "logps/rejected": -150.2188262939453,
      "loss": 0.0271,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.2820866107940674,
      "rewards/margins": 6.076394081115723,
      "rewards/rejected": -9.358480453491211,
      "step": 3354
    },
    {
      "epoch": 1.342,
      "grad_norm": 5.448808670043945,
      "learning_rate": 5.527999999999999e-07,
      "logits/chosen": -2.5401177406311035,
      "logits/rejected": -2.301739454269409,
      "logps/chosen": -120.74359130859375,
      "logps/rejected": -93.7062759399414,
      "loss": 0.0261,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.517236351966858,
      "rewards/margins": 4.405843734741211,
      "rewards/rejected": -5.9230804443359375,
      "step": 3355
    },
    {
      "epoch": 1.3424,
      "grad_norm": 0.0014164578169584274,
      "learning_rate": 5.526666666666666e-07,
      "logits/chosen": -2.7232248783111572,
      "logits/rejected": -2.224318027496338,
      "logps/chosen": -103.62887573242188,
      "logps/rejected": -179.01919555664062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4006820619106293,
      "rewards/margins": 12.201916694641113,
      "rewards/rejected": -11.80123519897461,
      "step": 3356
    },
    {
      "epoch": 1.3428,
      "grad_norm": 0.18568214774131775,
      "learning_rate": 5.525333333333333e-07,
      "logits/chosen": -3.110356330871582,
      "logits/rejected": -2.566066265106201,
      "logps/chosen": -61.04452133178711,
      "logps/rejected": -129.88739013671875,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8070347309112549,
      "rewards/margins": 7.433833122253418,
      "rewards/rejected": -8.240867614746094,
      "step": 3357
    },
    {
      "epoch": 1.3432,
      "grad_norm": 0.06885555386543274,
      "learning_rate": 5.524e-07,
      "logits/chosen": -3.1011500358581543,
      "logits/rejected": -2.667198896408081,
      "logps/chosen": -48.602561950683594,
      "logps/rejected": -107.23945617675781,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5386357307434082,
      "rewards/margins": 8.297761917114258,
      "rewards/rejected": -6.759126663208008,
      "step": 3358
    },
    {
      "epoch": 1.3436,
      "grad_norm": 0.004890039097517729,
      "learning_rate": 5.522666666666667e-07,
      "logits/chosen": -2.4045732021331787,
      "logits/rejected": -1.7321455478668213,
      "logps/chosen": -247.86822509765625,
      "logps/rejected": -247.9350128173828,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15284192562103271,
      "rewards/margins": 12.993947982788086,
      "rewards/rejected": -12.841105461120605,
      "step": 3359
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 0.12102426588535309,
      "learning_rate": 5.521333333333334e-07,
      "logits/chosen": -3.088362216949463,
      "logits/rejected": -2.6831490993499756,
      "logps/chosen": -49.15772247314453,
      "logps/rejected": -104.2232666015625,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09936678409576416,
      "rewards/margins": 7.159475803375244,
      "rewards/rejected": -7.0601091384887695,
      "step": 3360
    },
    {
      "epoch": 1.3444,
      "grad_norm": 2.9423863887786865,
      "learning_rate": 5.520000000000001e-07,
      "logits/chosen": -3.1896023750305176,
      "logits/rejected": -2.8566932678222656,
      "logps/chosen": -54.81722640991211,
      "logps/rejected": -98.88047790527344,
      "loss": 0.0322,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6588783264160156,
      "rewards/margins": 6.9398112297058105,
      "rewards/rejected": -6.280932426452637,
      "step": 3361
    },
    {
      "epoch": 1.3448,
      "grad_norm": 0.16790881752967834,
      "learning_rate": 5.518666666666666e-07,
      "logits/chosen": -3.1465415954589844,
      "logits/rejected": -2.583186626434326,
      "logps/chosen": -65.14688873291016,
      "logps/rejected": -141.71934509277344,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12032242864370346,
      "rewards/margins": 9.138423919677734,
      "rewards/rejected": -9.018101692199707,
      "step": 3362
    },
    {
      "epoch": 1.3452,
      "grad_norm": 0.5585936307907104,
      "learning_rate": 5.517333333333332e-07,
      "logits/chosen": -3.118288516998291,
      "logits/rejected": -2.8725802898406982,
      "logps/chosen": -65.40144348144531,
      "logps/rejected": -120.86785888671875,
      "loss": 0.0051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7325302362442017,
      "rewards/margins": 6.95670747756958,
      "rewards/rejected": -7.689237594604492,
      "step": 3363
    },
    {
      "epoch": 1.3456000000000001,
      "grad_norm": 0.04382716864347458,
      "learning_rate": 5.515999999999999e-07,
      "logits/chosen": -2.7374987602233887,
      "logits/rejected": -2.1319336891174316,
      "logps/chosen": -77.46092987060547,
      "logps/rejected": -154.16390991210938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.46886730194091797,
      "rewards/margins": 8.589394569396973,
      "rewards/rejected": -8.120527267456055,
      "step": 3364
    },
    {
      "epoch": 1.346,
      "grad_norm": 0.16482865810394287,
      "learning_rate": 5.514666666666666e-07,
      "logits/chosen": -2.652740001678467,
      "logits/rejected": -2.1354949474334717,
      "logps/chosen": -133.2014923095703,
      "logps/rejected": -171.737060546875,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0069432258605957,
      "rewards/margins": 7.063727855682373,
      "rewards/rejected": -9.070671081542969,
      "step": 3365
    },
    {
      "epoch": 1.3464,
      "grad_norm": 0.001982232788577676,
      "learning_rate": 5.513333333333333e-07,
      "logits/chosen": -2.7220139503479004,
      "logits/rejected": -2.1395931243896484,
      "logps/chosen": -144.1068572998047,
      "logps/rejected": -208.9766845703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33803367614746094,
      "rewards/margins": 13.367526054382324,
      "rewards/rejected": -13.029492378234863,
      "step": 3366
    },
    {
      "epoch": 1.3468,
      "grad_norm": 0.17612293362617493,
      "learning_rate": 5.512e-07,
      "logits/chosen": -2.857550621032715,
      "logits/rejected": -2.318120002746582,
      "logps/chosen": -106.52784729003906,
      "logps/rejected": -161.59201049804688,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6835960149765015,
      "rewards/margins": 9.979888916015625,
      "rewards/rejected": -9.296292304992676,
      "step": 3367
    },
    {
      "epoch": 1.3472,
      "grad_norm": 0.21558503806591034,
      "learning_rate": 5.510666666666667e-07,
      "logits/chosen": -3.0734214782714844,
      "logits/rejected": -2.409457206726074,
      "logps/chosen": -81.47406005859375,
      "logps/rejected": -231.63987731933594,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.47522851824760437,
      "rewards/margins": 13.10469913482666,
      "rewards/rejected": -13.579927444458008,
      "step": 3368
    },
    {
      "epoch": 1.3476,
      "grad_norm": 0.00459288340061903,
      "learning_rate": 5.509333333333334e-07,
      "logits/chosen": -2.518329620361328,
      "logits/rejected": -1.8238873481750488,
      "logps/chosen": -111.54528045654297,
      "logps/rejected": -236.4472198486328,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8464534282684326,
      "rewards/margins": 12.064423561096191,
      "rewards/rejected": -10.21796989440918,
      "step": 3369
    },
    {
      "epoch": 1.3479999999999999,
      "grad_norm": 0.020882442593574524,
      "learning_rate": 5.508e-07,
      "logits/chosen": -3.012122869491577,
      "logits/rejected": -2.1131248474121094,
      "logps/chosen": -83.4653549194336,
      "logps/rejected": -144.5084991455078,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6985797882080078,
      "rewards/margins": 9.196891784667969,
      "rewards/rejected": -8.498311996459961,
      "step": 3370
    },
    {
      "epoch": 1.3484,
      "grad_norm": 0.031481217592954636,
      "learning_rate": 5.506666666666666e-07,
      "logits/chosen": -3.194727897644043,
      "logits/rejected": -2.699583053588867,
      "logps/chosen": -55.13960647583008,
      "logps/rejected": -120.97553253173828,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8000595569610596,
      "rewards/margins": 9.372756958007812,
      "rewards/rejected": -7.57269811630249,
      "step": 3371
    },
    {
      "epoch": 1.3488,
      "grad_norm": 0.0314473919570446,
      "learning_rate": 5.505333333333333e-07,
      "logits/chosen": -3.0689382553100586,
      "logits/rejected": -2.635603666305542,
      "logps/chosen": -54.72506332397461,
      "logps/rejected": -124.53610229492188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18018606305122375,
      "rewards/margins": 8.8978853225708,
      "rewards/rejected": -8.71769905090332,
      "step": 3372
    },
    {
      "epoch": 1.3492,
      "grad_norm": 0.15707087516784668,
      "learning_rate": 5.504e-07,
      "logits/chosen": -2.9880290031433105,
      "logits/rejected": -2.2619693279266357,
      "logps/chosen": -90.54727935791016,
      "logps/rejected": -129.9890594482422,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8611111044883728,
      "rewards/margins": 7.783360481262207,
      "rewards/rejected": -6.922248840332031,
      "step": 3373
    },
    {
      "epoch": 1.3496000000000001,
      "grad_norm": 1.2764637470245361,
      "learning_rate": 5.502666666666666e-07,
      "logits/chosen": -2.45278263092041,
      "logits/rejected": -1.6682833433151245,
      "logps/chosen": -141.27081298828125,
      "logps/rejected": -152.87576293945312,
      "loss": 0.0073,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14783477783203125,
      "rewards/margins": 9.01213264465332,
      "rewards/rejected": -8.864296913146973,
      "step": 3374
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.08316444605588913,
      "learning_rate": 5.501333333333333e-07,
      "logits/chosen": -2.7690608501434326,
      "logits/rejected": -2.4119768142700195,
      "logps/chosen": -114.04446411132812,
      "logps/rejected": -128.37313842773438,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08425483852624893,
      "rewards/margins": 8.39462947845459,
      "rewards/rejected": -8.47888469696045,
      "step": 3375
    },
    {
      "epoch": 1.3504,
      "grad_norm": 8.430320739746094,
      "learning_rate": 5.5e-07,
      "logits/chosen": -2.9041025638580322,
      "logits/rejected": -2.6730809211730957,
      "logps/chosen": -88.6622314453125,
      "logps/rejected": -115.43476104736328,
      "loss": 0.055,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.6489460468292236,
      "rewards/margins": 3.791738986968994,
      "rewards/rejected": -6.440684795379639,
      "step": 3376
    },
    {
      "epoch": 1.3508,
      "grad_norm": 0.361663818359375,
      "learning_rate": 5.498666666666666e-07,
      "logits/chosen": -3.1796481609344482,
      "logits/rejected": -2.801970958709717,
      "logps/chosen": -33.198524475097656,
      "logps/rejected": -106.56625366210938,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45774316787719727,
      "rewards/margins": 7.256731033325195,
      "rewards/rejected": -6.798988342285156,
      "step": 3377
    },
    {
      "epoch": 1.3512,
      "grad_norm": 0.10979960113763809,
      "learning_rate": 5.497333333333333e-07,
      "logits/chosen": -2.598808765411377,
      "logits/rejected": -2.1294286251068115,
      "logps/chosen": -80.80009460449219,
      "logps/rejected": -118.15646362304688,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9682804346084595,
      "rewards/margins": 7.729733467102051,
      "rewards/rejected": -6.761453151702881,
      "step": 3378
    },
    {
      "epoch": 1.3516,
      "grad_norm": 0.14788387715816498,
      "learning_rate": 5.496e-07,
      "logits/chosen": -2.863337516784668,
      "logits/rejected": -2.1868300437927246,
      "logps/chosen": -91.35853576660156,
      "logps/rejected": -155.50860595703125,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3449132442474365,
      "rewards/margins": 8.49154281616211,
      "rewards/rejected": -8.836456298828125,
      "step": 3379
    },
    {
      "epoch": 1.3519999999999999,
      "grad_norm": 0.508708655834198,
      "learning_rate": 5.494666666666666e-07,
      "logits/chosen": -2.551727294921875,
      "logits/rejected": -2.3226795196533203,
      "logps/chosen": -125.33740234375,
      "logps/rejected": -120.52864837646484,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.70263671875,
      "rewards/margins": 5.829483509063721,
      "rewards/rejected": -7.532120227813721,
      "step": 3380
    },
    {
      "epoch": 1.3524,
      "grad_norm": 0.003449472365900874,
      "learning_rate": 5.493333333333333e-07,
      "logits/chosen": -2.72831130027771,
      "logits/rejected": -2.132761001586914,
      "logps/chosen": -121.14170837402344,
      "logps/rejected": -155.4847412109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7223724722862244,
      "rewards/margins": 10.881353378295898,
      "rewards/rejected": -10.158981323242188,
      "step": 3381
    },
    {
      "epoch": 1.3528,
      "grad_norm": 0.07190188765525818,
      "learning_rate": 5.492e-07,
      "logits/chosen": -2.5490353107452393,
      "logits/rejected": -1.4190161228179932,
      "logps/chosen": -111.18783569335938,
      "logps/rejected": -163.28732299804688,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.20818784832954407,
      "rewards/margins": 8.564142227172852,
      "rewards/rejected": -8.772330284118652,
      "step": 3382
    },
    {
      "epoch": 1.3532,
      "grad_norm": 0.008762641809880733,
      "learning_rate": 5.490666666666667e-07,
      "logits/chosen": -2.8259265422821045,
      "logits/rejected": -2.5696120262145996,
      "logps/chosen": -77.15676879882812,
      "logps/rejected": -153.4403076171875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3787670135498047,
      "rewards/margins": 9.781293869018555,
      "rewards/rejected": -9.40252685546875,
      "step": 3383
    },
    {
      "epoch": 1.3536000000000001,
      "grad_norm": 0.028898851945996284,
      "learning_rate": 5.489333333333334e-07,
      "logits/chosen": -2.6293721199035645,
      "logits/rejected": -2.4208598136901855,
      "logps/chosen": -96.11466217041016,
      "logps/rejected": -172.3009796142578,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.9214305877685547,
      "rewards/margins": 9.031194686889648,
      "rewards/rejected": -11.952625274658203,
      "step": 3384
    },
    {
      "epoch": 1.354,
      "grad_norm": 0.003233511233702302,
      "learning_rate": 5.487999999999999e-07,
      "logits/chosen": -2.9108669757843018,
      "logits/rejected": -2.297424793243408,
      "logps/chosen": -88.66268920898438,
      "logps/rejected": -183.91317749023438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.46047133207321167,
      "rewards/margins": 11.558012962341309,
      "rewards/rejected": -11.097541809082031,
      "step": 3385
    },
    {
      "epoch": 1.3544,
      "grad_norm": 0.770450234413147,
      "learning_rate": 5.486666666666666e-07,
      "logits/chosen": -2.7206835746765137,
      "logits/rejected": -2.0907857418060303,
      "logps/chosen": -131.36346435546875,
      "logps/rejected": -146.74185180664062,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5903534293174744,
      "rewards/margins": 8.144707679748535,
      "rewards/rejected": -8.735060691833496,
      "step": 3386
    },
    {
      "epoch": 1.3548,
      "grad_norm": 0.25444549322128296,
      "learning_rate": 5.485333333333333e-07,
      "logits/chosen": -3.027909278869629,
      "logits/rejected": -2.5736546516418457,
      "logps/chosen": -69.36775207519531,
      "logps/rejected": -179.97251892089844,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02974987030029297,
      "rewards/margins": 10.777369499206543,
      "rewards/rejected": -10.74761962890625,
      "step": 3387
    },
    {
      "epoch": 1.3552,
      "grad_norm": 0.07672806829214096,
      "learning_rate": 5.484e-07,
      "logits/chosen": -2.978576183319092,
      "logits/rejected": -2.1648240089416504,
      "logps/chosen": -74.97908782958984,
      "logps/rejected": -152.9424285888672,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.072789192199707,
      "rewards/margins": 10.551667213439941,
      "rewards/rejected": -9.478878021240234,
      "step": 3388
    },
    {
      "epoch": 1.3556,
      "grad_norm": 0.1730627417564392,
      "learning_rate": 5.482666666666667e-07,
      "logits/chosen": -3.0617117881774902,
      "logits/rejected": -2.637866497039795,
      "logps/chosen": -86.7040786743164,
      "logps/rejected": -106.53517150878906,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2186100035905838,
      "rewards/margins": 7.062867641448975,
      "rewards/rejected": -6.844257354736328,
      "step": 3389
    },
    {
      "epoch": 1.3559999999999999,
      "grad_norm": 0.006508867722004652,
      "learning_rate": 5.481333333333333e-07,
      "logits/chosen": -2.9820923805236816,
      "logits/rejected": -2.4912490844726562,
      "logps/chosen": -78.81646728515625,
      "logps/rejected": -137.61061096191406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9012992978096008,
      "rewards/margins": 10.049217224121094,
      "rewards/rejected": -9.147918701171875,
      "step": 3390
    },
    {
      "epoch": 1.3564,
      "grad_norm": 0.0327981673181057,
      "learning_rate": 5.48e-07,
      "logits/chosen": -2.8020644187927246,
      "logits/rejected": -1.9658734798431396,
      "logps/chosen": -67.43951416015625,
      "logps/rejected": -240.29318237304688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3293296098709106,
      "rewards/margins": 11.843633651733398,
      "rewards/rejected": -10.514303207397461,
      "step": 3391
    },
    {
      "epoch": 1.3568,
      "grad_norm": 2.7936344146728516,
      "learning_rate": 5.478666666666666e-07,
      "logits/chosen": -2.968553066253662,
      "logits/rejected": -3.2096762657165527,
      "logps/chosen": -102.71250915527344,
      "logps/rejected": -81.83737182617188,
      "loss": 0.0232,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5424606800079346,
      "rewards/margins": 3.7548422813415527,
      "rewards/rejected": -5.297303199768066,
      "step": 3392
    },
    {
      "epoch": 1.3572,
      "grad_norm": 0.2701348662376404,
      "learning_rate": 5.477333333333333e-07,
      "logits/chosen": -3.080723524093628,
      "logits/rejected": -2.7632393836975098,
      "logps/chosen": -60.68852996826172,
      "logps/rejected": -105.29545593261719,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.435075283050537,
      "rewards/margins": 6.975592613220215,
      "rewards/rejected": -5.540517807006836,
      "step": 3393
    },
    {
      "epoch": 1.3576,
      "grad_norm": 0.574201226234436,
      "learning_rate": 5.476e-07,
      "logits/chosen": -2.9685187339782715,
      "logits/rejected": -2.6474432945251465,
      "logps/chosen": -62.05626678466797,
      "logps/rejected": -112.3232650756836,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0075809955596924,
      "rewards/margins": 8.088788032531738,
      "rewards/rejected": -7.081207275390625,
      "step": 3394
    },
    {
      "epoch": 1.358,
      "grad_norm": 0.21929384768009186,
      "learning_rate": 5.474666666666666e-07,
      "logits/chosen": -2.9848361015319824,
      "logits/rejected": -2.4993526935577393,
      "logps/chosen": -88.40927124023438,
      "logps/rejected": -123.55934143066406,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6052559018135071,
      "rewards/margins": 7.01406192779541,
      "rewards/rejected": -7.619318008422852,
      "step": 3395
    },
    {
      "epoch": 1.3584,
      "grad_norm": 0.1807611882686615,
      "learning_rate": 5.473333333333333e-07,
      "logits/chosen": -2.723449945449829,
      "logits/rejected": -2.1932952404022217,
      "logps/chosen": -163.87017822265625,
      "logps/rejected": -127.62812042236328,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11088943481445312,
      "rewards/margins": 8.378240585327148,
      "rewards/rejected": -8.267351150512695,
      "step": 3396
    },
    {
      "epoch": 1.3588,
      "grad_norm": 0.00030342384707182646,
      "learning_rate": 5.472e-07,
      "logits/chosen": -2.6771488189697266,
      "logits/rejected": -2.0698606967926025,
      "logps/chosen": -91.52890014648438,
      "logps/rejected": -194.0308837890625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7737683057785034,
      "rewards/margins": 13.50227165222168,
      "rewards/rejected": -11.728504180908203,
      "step": 3397
    },
    {
      "epoch": 1.3592,
      "grad_norm": 1.7983789443969727,
      "learning_rate": 5.470666666666667e-07,
      "logits/chosen": -2.489680290222168,
      "logits/rejected": -2.363642930984497,
      "logps/chosen": -136.0307159423828,
      "logps/rejected": -119.55274200439453,
      "loss": 0.0163,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.830801486968994,
      "rewards/margins": 4.157404899597168,
      "rewards/rejected": -6.988205909729004,
      "step": 3398
    },
    {
      "epoch": 1.3596,
      "grad_norm": 0.05668901652097702,
      "learning_rate": 5.469333333333333e-07,
      "logits/chosen": -3.05560302734375,
      "logits/rejected": -2.7406201362609863,
      "logps/chosen": -119.83977508544922,
      "logps/rejected": -132.56321716308594,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35953599214553833,
      "rewards/margins": 8.837335586547852,
      "rewards/rejected": -8.477799415588379,
      "step": 3399
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 4.902345657348633,
      "learning_rate": 5.467999999999999e-07,
      "logits/chosen": -2.7473363876342773,
      "logits/rejected": -2.5517497062683105,
      "logps/chosen": -135.24038696289062,
      "logps/rejected": -133.65997314453125,
      "loss": 0.0279,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.3192145824432373,
      "rewards/margins": 5.466559410095215,
      "rewards/rejected": -7.785774230957031,
      "step": 3400
    },
    {
      "epoch": 1.3604,
      "grad_norm": 0.026327261701226234,
      "learning_rate": 5.466666666666666e-07,
      "logits/chosen": -2.9186506271362305,
      "logits/rejected": -1.8692865371704102,
      "logps/chosen": -80.95423889160156,
      "logps/rejected": -205.64675903320312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5703299045562744,
      "rewards/margins": 12.72148323059082,
      "rewards/rejected": -11.151153564453125,
      "step": 3401
    },
    {
      "epoch": 1.3608,
      "grad_norm": 0.09886562824249268,
      "learning_rate": 5.465333333333333e-07,
      "logits/chosen": -2.903252124786377,
      "logits/rejected": -2.558037757873535,
      "logps/chosen": -108.83773040771484,
      "logps/rejected": -145.5009765625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.11603426933288574,
      "rewards/margins": 9.440420150756836,
      "rewards/rejected": -9.556453704833984,
      "step": 3402
    },
    {
      "epoch": 1.3612,
      "grad_norm": 2.511611223220825,
      "learning_rate": 5.464e-07,
      "logits/chosen": -2.7132554054260254,
      "logits/rejected": -1.9902753829956055,
      "logps/chosen": -105.59538269042969,
      "logps/rejected": -123.95983123779297,
      "loss": 0.0302,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.954369306564331,
      "rewards/margins": 5.643409729003906,
      "rewards/rejected": -6.597779273986816,
      "step": 3403
    },
    {
      "epoch": 1.3616,
      "grad_norm": 0.06131093204021454,
      "learning_rate": 5.462666666666667e-07,
      "logits/chosen": -2.679992437362671,
      "logits/rejected": -2.0287961959838867,
      "logps/chosen": -109.66780853271484,
      "logps/rejected": -168.76087951660156,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.708234429359436,
      "rewards/margins": 9.050081253051758,
      "rewards/rejected": -8.34184741973877,
      "step": 3404
    },
    {
      "epoch": 1.362,
      "grad_norm": 0.5560759902000427,
      "learning_rate": 5.461333333333334e-07,
      "logits/chosen": -2.5911803245544434,
      "logits/rejected": -2.406651258468628,
      "logps/chosen": -136.32516479492188,
      "logps/rejected": -108.30552673339844,
      "loss": 0.0063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5006502866744995,
      "rewards/margins": 5.378460884094238,
      "rewards/rejected": -6.879111289978027,
      "step": 3405
    },
    {
      "epoch": 1.3624,
      "grad_norm": 3.1081860065460205,
      "learning_rate": 5.46e-07,
      "logits/chosen": -3.0238559246063232,
      "logits/rejected": -2.756791591644287,
      "logps/chosen": -63.44041442871094,
      "logps/rejected": -145.60963439941406,
      "loss": 0.0209,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3712889552116394,
      "rewards/margins": 9.265477180480957,
      "rewards/rejected": -9.63676643371582,
      "step": 3406
    },
    {
      "epoch": 1.3628,
      "grad_norm": 0.12728913128376007,
      "learning_rate": 5.458666666666666e-07,
      "logits/chosen": -3.1405725479125977,
      "logits/rejected": -2.8081891536712646,
      "logps/chosen": -53.24974060058594,
      "logps/rejected": -130.53262329101562,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5900425314903259,
      "rewards/margins": 9.814499855041504,
      "rewards/rejected": -9.224457740783691,
      "step": 3407
    },
    {
      "epoch": 1.3632,
      "grad_norm": 0.010182276368141174,
      "learning_rate": 5.457333333333332e-07,
      "logits/chosen": -2.303947925567627,
      "logits/rejected": -1.8290507793426514,
      "logps/chosen": -127.46192932128906,
      "logps/rejected": -268.09075927734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6075699329376221,
      "rewards/margins": 12.846805572509766,
      "rewards/rejected": -12.239234924316406,
      "step": 3408
    },
    {
      "epoch": 1.3636,
      "grad_norm": 0.024233214557170868,
      "learning_rate": 5.455999999999999e-07,
      "logits/chosen": -2.428544044494629,
      "logits/rejected": -1.6614824533462524,
      "logps/chosen": -190.6147918701172,
      "logps/rejected": -192.42123413085938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3253505229949951,
      "rewards/margins": 9.437135696411133,
      "rewards/rejected": -10.76248550415039,
      "step": 3409
    },
    {
      "epoch": 1.3639999999999999,
      "grad_norm": 1.9752376079559326,
      "learning_rate": 5.454666666666666e-07,
      "logits/chosen": -3.052950382232666,
      "logits/rejected": -2.6359169483184814,
      "logps/chosen": -69.53131866455078,
      "logps/rejected": -138.31011962890625,
      "loss": 0.0163,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6672760248184204,
      "rewards/margins": 7.981212615966797,
      "rewards/rejected": -8.648488998413086,
      "step": 3410
    },
    {
      "epoch": 1.3644,
      "grad_norm": 50.74053955078125,
      "learning_rate": 5.453333333333333e-07,
      "logits/chosen": -2.596332550048828,
      "logits/rejected": -1.9608581066131592,
      "logps/chosen": -194.22195434570312,
      "logps/rejected": -116.03363037109375,
      "loss": 0.3523,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.16851770877838135,
      "rewards/margins": 7.231846809387207,
      "rewards/rejected": -7.063329219818115,
      "step": 3411
    },
    {
      "epoch": 1.3648,
      "grad_norm": 0.19563141465187073,
      "learning_rate": 5.452e-07,
      "logits/chosen": -3.066821575164795,
      "logits/rejected": -2.5987284183502197,
      "logps/chosen": -62.249664306640625,
      "logps/rejected": -114.3060302734375,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5276676416397095,
      "rewards/margins": 7.522068977355957,
      "rewards/rejected": -6.994401931762695,
      "step": 3412
    },
    {
      "epoch": 1.3652,
      "grad_norm": 0.06638049334287643,
      "learning_rate": 5.450666666666667e-07,
      "logits/chosen": -2.787189483642578,
      "logits/rejected": -2.2152132987976074,
      "logps/chosen": -115.9867172241211,
      "logps/rejected": -145.67062377929688,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5520517826080322,
      "rewards/margins": 8.435523986816406,
      "rewards/rejected": -7.883471488952637,
      "step": 3413
    },
    {
      "epoch": 1.3656,
      "grad_norm": 54.489322662353516,
      "learning_rate": 5.449333333333334e-07,
      "logits/chosen": -2.5391697883605957,
      "logits/rejected": -2.4937021732330322,
      "logps/chosen": -170.013671875,
      "logps/rejected": -136.02432250976562,
      "loss": 0.2608,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.079615592956543,
      "rewards/margins": 4.158257007598877,
      "rewards/rejected": -7.23787260055542,
      "step": 3414
    },
    {
      "epoch": 1.366,
      "grad_norm": 161.13636779785156,
      "learning_rate": 5.448e-07,
      "logits/chosen": -2.4828286170959473,
      "logits/rejected": -2.2696690559387207,
      "logps/chosen": -162.2296142578125,
      "logps/rejected": -98.05534362792969,
      "loss": 0.8945,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -6.2827863693237305,
      "rewards/margins": 0.3657522201538086,
      "rewards/rejected": -6.648538589477539,
      "step": 3415
    },
    {
      "epoch": 1.3664,
      "grad_norm": 0.006578358821570873,
      "learning_rate": 5.446666666666666e-07,
      "logits/chosen": -2.3256590366363525,
      "logits/rejected": -1.5227363109588623,
      "logps/chosen": -119.03170776367188,
      "logps/rejected": -221.94935607910156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8000621795654297,
      "rewards/margins": 10.695967674255371,
      "rewards/rejected": -9.895905494689941,
      "step": 3416
    },
    {
      "epoch": 1.3668,
      "grad_norm": 0.09779243171215057,
      "learning_rate": 5.445333333333333e-07,
      "logits/chosen": -2.8707001209259033,
      "logits/rejected": -2.577244997024536,
      "logps/chosen": -74.48538970947266,
      "logps/rejected": -165.90333557128906,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1951715350151062,
      "rewards/margins": 8.268387794494629,
      "rewards/rejected": -8.463560104370117,
      "step": 3417
    },
    {
      "epoch": 1.3672,
      "grad_norm": 0.025353385135531425,
      "learning_rate": 5.443999999999999e-07,
      "logits/chosen": -3.0113677978515625,
      "logits/rejected": -2.4552836418151855,
      "logps/chosen": -74.45024108886719,
      "logps/rejected": -130.21343994140625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2534725069999695,
      "rewards/margins": 8.750345230102539,
      "rewards/rejected": -8.496871948242188,
      "step": 3418
    },
    {
      "epoch": 1.3676,
      "grad_norm": 0.9699089527130127,
      "learning_rate": 5.442666666666666e-07,
      "logits/chosen": -3.180295467376709,
      "logits/rejected": -2.687122344970703,
      "logps/chosen": -77.24407196044922,
      "logps/rejected": -162.51638793945312,
      "loss": 0.0061,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12267529964447021,
      "rewards/margins": 9.898890495300293,
      "rewards/rejected": -9.776215553283691,
      "step": 3419
    },
    {
      "epoch": 1.3679999999999999,
      "grad_norm": 0.09635037928819656,
      "learning_rate": 5.441333333333333e-07,
      "logits/chosen": -2.6202564239501953,
      "logits/rejected": -2.05759334564209,
      "logps/chosen": -100.61338806152344,
      "logps/rejected": -126.19679260253906,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.018919754773378372,
      "rewards/margins": 7.6785101890563965,
      "rewards/rejected": -7.659590244293213,
      "step": 3420
    },
    {
      "epoch": 1.3684,
      "grad_norm": 0.2300039529800415,
      "learning_rate": 5.44e-07,
      "logits/chosen": -3.052030086517334,
      "logits/rejected": -2.8500466346740723,
      "logps/chosen": -154.75657653808594,
      "logps/rejected": -170.31207275390625,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6561530828475952,
      "rewards/margins": 9.746482849121094,
      "rewards/rejected": -11.40263557434082,
      "step": 3421
    },
    {
      "epoch": 1.3688,
      "grad_norm": 0.6234803795814514,
      "learning_rate": 5.438666666666667e-07,
      "logits/chosen": -2.9718198776245117,
      "logits/rejected": -2.2741103172302246,
      "logps/chosen": -70.55838012695312,
      "logps/rejected": -157.45913696289062,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6964204907417297,
      "rewards/margins": 10.115020751953125,
      "rewards/rejected": -9.418600082397461,
      "step": 3422
    },
    {
      "epoch": 1.3692,
      "grad_norm": 0.01938708871603012,
      "learning_rate": 5.437333333333333e-07,
      "logits/chosen": -2.9138436317443848,
      "logits/rejected": -2.6289145946502686,
      "logps/chosen": -59.53050231933594,
      "logps/rejected": -126.54837036132812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9734798669815063,
      "rewards/margins": 9.363645553588867,
      "rewards/rejected": -8.390165328979492,
      "step": 3423
    },
    {
      "epoch": 1.3696,
      "grad_norm": 0.6823880076408386,
      "learning_rate": 5.436e-07,
      "logits/chosen": -2.720968246459961,
      "logits/rejected": -2.557753562927246,
      "logps/chosen": -62.55089569091797,
      "logps/rejected": -127.88926696777344,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9673547744750977,
      "rewards/margins": 6.835113525390625,
      "rewards/rejected": -5.867758274078369,
      "step": 3424
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.004940403159707785,
      "learning_rate": 5.434666666666667e-07,
      "logits/chosen": -2.726322650909424,
      "logits/rejected": -2.2408714294433594,
      "logps/chosen": -78.48064422607422,
      "logps/rejected": -205.72337341308594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.47986698150634766,
      "rewards/margins": 11.174903869628906,
      "rewards/rejected": -10.695037841796875,
      "step": 3425
    },
    {
      "epoch": 1.3704,
      "grad_norm": 0.06964785605669022,
      "learning_rate": 5.433333333333334e-07,
      "logits/chosen": -3.0915355682373047,
      "logits/rejected": -2.770376682281494,
      "logps/chosen": -49.7448844909668,
      "logps/rejected": -100.329833984375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2732607126235962,
      "rewards/margins": 7.759981155395508,
      "rewards/rejected": -6.486720085144043,
      "step": 3426
    },
    {
      "epoch": 1.3708,
      "grad_norm": 0.015427175909280777,
      "learning_rate": 5.431999999999999e-07,
      "logits/chosen": -3.128446578979492,
      "logits/rejected": -2.6596477031707764,
      "logps/chosen": -50.56635284423828,
      "logps/rejected": -133.18051147460938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3398222923278809,
      "rewards/margins": 9.222635269165039,
      "rewards/rejected": -7.882813453674316,
      "step": 3427
    },
    {
      "epoch": 1.3712,
      "grad_norm": 27.86664390563965,
      "learning_rate": 5.430666666666666e-07,
      "logits/chosen": -2.9219985008239746,
      "logits/rejected": -2.616046905517578,
      "logps/chosen": -72.37429809570312,
      "logps/rejected": -111.0604248046875,
      "loss": 0.1585,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.06833100318908691,
      "rewards/margins": 6.906922340393066,
      "rewards/rejected": -6.975253582000732,
      "step": 3428
    },
    {
      "epoch": 1.3716,
      "grad_norm": 0.00902933906763792,
      "learning_rate": 5.429333333333333e-07,
      "logits/chosen": -3.0889668464660645,
      "logits/rejected": -2.100989580154419,
      "logps/chosen": -77.19381713867188,
      "logps/rejected": -160.48764038085938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3895468711853027,
      "rewards/margins": 12.023056030273438,
      "rewards/rejected": -9.633508682250977,
      "step": 3429
    },
    {
      "epoch": 1.3719999999999999,
      "grad_norm": 0.1427212506532669,
      "learning_rate": 5.427999999999999e-07,
      "logits/chosen": -3.2848989963531494,
      "logits/rejected": -2.6567797660827637,
      "logps/chosen": -58.68608856201172,
      "logps/rejected": -174.02040100097656,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.27523499727249146,
      "rewards/margins": 11.14974308013916,
      "rewards/rejected": -11.424978256225586,
      "step": 3430
    },
    {
      "epoch": 1.3724,
      "grad_norm": 0.32528093457221985,
      "learning_rate": 5.426666666666666e-07,
      "logits/chosen": -2.7005438804626465,
      "logits/rejected": -2.0817627906799316,
      "logps/chosen": -67.33343505859375,
      "logps/rejected": -139.1361083984375,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8856945037841797,
      "rewards/margins": 10.095561981201172,
      "rewards/rejected": -9.209867477416992,
      "step": 3431
    },
    {
      "epoch": 1.3728,
      "grad_norm": 0.0049188160337507725,
      "learning_rate": 5.425333333333333e-07,
      "logits/chosen": -2.930661678314209,
      "logits/rejected": -2.0708959102630615,
      "logps/chosen": -84.56683349609375,
      "logps/rejected": -226.0196990966797,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.384239673614502,
      "rewards/margins": 14.141369819641113,
      "rewards/rejected": -12.757129669189453,
      "step": 3432
    },
    {
      "epoch": 1.3732,
      "grad_norm": 0.27766484022140503,
      "learning_rate": 5.424e-07,
      "logits/chosen": -3.1267201900482178,
      "logits/rejected": -2.707883596420288,
      "logps/chosen": -85.36073303222656,
      "logps/rejected": -128.0911865234375,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8634245991706848,
      "rewards/margins": 7.767434120178223,
      "rewards/rejected": -6.904009819030762,
      "step": 3433
    },
    {
      "epoch": 1.3736,
      "grad_norm": 7.049424171447754,
      "learning_rate": 5.422666666666667e-07,
      "logits/chosen": -2.906248092651367,
      "logits/rejected": -2.880662441253662,
      "logps/chosen": -65.52729797363281,
      "logps/rejected": -87.7137222290039,
      "loss": 0.0633,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9354474544525146,
      "rewards/margins": 3.3772809505462646,
      "rewards/rejected": -4.312728404998779,
      "step": 3434
    },
    {
      "epoch": 1.374,
      "grad_norm": 0.012295445427298546,
      "learning_rate": 5.421333333333334e-07,
      "logits/chosen": -2.5455241203308105,
      "logits/rejected": -1.4921940565109253,
      "logps/chosen": -85.95877075195312,
      "logps/rejected": -169.87030029296875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3296482563018799,
      "rewards/margins": 10.935405731201172,
      "rewards/rejected": -9.605758666992188,
      "step": 3435
    },
    {
      "epoch": 1.3744,
      "grad_norm": 0.0004952921299263835,
      "learning_rate": 5.420000000000001e-07,
      "logits/chosen": -2.485841751098633,
      "logits/rejected": -1.640523910522461,
      "logps/chosen": -167.8297576904297,
      "logps/rejected": -220.60438537597656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.511743187904358,
      "rewards/margins": 13.89324951171875,
      "rewards/rejected": -12.381505966186523,
      "step": 3436
    },
    {
      "epoch": 1.3748,
      "grad_norm": 0.0014466705033555627,
      "learning_rate": 5.418666666666666e-07,
      "logits/chosen": -2.448288917541504,
      "logits/rejected": -1.7357455492019653,
      "logps/chosen": -147.95462036132812,
      "logps/rejected": -249.16236877441406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8329781293869019,
      "rewards/margins": 12.791728973388672,
      "rewards/rejected": -11.958751678466797,
      "step": 3437
    },
    {
      "epoch": 1.3752,
      "grad_norm": 0.21510781347751617,
      "learning_rate": 5.417333333333332e-07,
      "logits/chosen": -2.750349998474121,
      "logits/rejected": -2.71547794342041,
      "logps/chosen": -97.02739715576172,
      "logps/rejected": -121.38428497314453,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3755554258823395,
      "rewards/margins": 6.649097442626953,
      "rewards/rejected": -7.024652481079102,
      "step": 3438
    },
    {
      "epoch": 1.3756,
      "grad_norm": 73.11517333984375,
      "learning_rate": 5.415999999999999e-07,
      "logits/chosen": -2.5669589042663574,
      "logits/rejected": -2.386845111846924,
      "logps/chosen": -151.52886962890625,
      "logps/rejected": -186.9442596435547,
      "loss": 0.5485,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -6.0552215576171875,
      "rewards/margins": 5.643503665924072,
      "rewards/rejected": -11.698724746704102,
      "step": 3439
    },
    {
      "epoch": 1.376,
      "grad_norm": 0.11152349412441254,
      "learning_rate": 5.414666666666666e-07,
      "logits/chosen": -2.729757785797119,
      "logits/rejected": -2.243706226348877,
      "logps/chosen": -47.72830581665039,
      "logps/rejected": -197.577392578125,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19158020615577698,
      "rewards/margins": 13.104325294494629,
      "rewards/rejected": -12.912744522094727,
      "step": 3440
    },
    {
      "epoch": 1.3764,
      "grad_norm": 0.20435310900211334,
      "learning_rate": 5.413333333333333e-07,
      "logits/chosen": -2.778933048248291,
      "logits/rejected": -2.318936347961426,
      "logps/chosen": -111.21009826660156,
      "logps/rejected": -174.93429565429688,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.22410546243190765,
      "rewards/margins": 8.97287654876709,
      "rewards/rejected": -9.196982383728027,
      "step": 3441
    },
    {
      "epoch": 1.3768,
      "grad_norm": 0.010534657165408134,
      "learning_rate": 5.412e-07,
      "logits/chosen": -2.4301745891571045,
      "logits/rejected": -1.7162878513336182,
      "logps/chosen": -156.32928466796875,
      "logps/rejected": -228.09152221679688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7388595342636108,
      "rewards/margins": 11.316865921020508,
      "rewards/rejected": -10.578006744384766,
      "step": 3442
    },
    {
      "epoch": 1.3772,
      "grad_norm": 0.1094861626625061,
      "learning_rate": 5.410666666666667e-07,
      "logits/chosen": -2.9272449016571045,
      "logits/rejected": -2.1947011947631836,
      "logps/chosen": -49.30492401123047,
      "logps/rejected": -139.8845672607422,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8570501208305359,
      "rewards/margins": 8.551533699035645,
      "rewards/rejected": -7.694482803344727,
      "step": 3443
    },
    {
      "epoch": 1.3776,
      "grad_norm": 0.06653417646884918,
      "learning_rate": 5.409333333333334e-07,
      "logits/chosen": -3.179050922393799,
      "logits/rejected": -2.6288065910339355,
      "logps/chosen": -93.97235107421875,
      "logps/rejected": -161.4632110595703,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3701538145542145,
      "rewards/margins": 9.581275939941406,
      "rewards/rejected": -9.95142936706543,
      "step": 3444
    },
    {
      "epoch": 1.3780000000000001,
      "grad_norm": 0.00458954693749547,
      "learning_rate": 5.408e-07,
      "logits/chosen": -2.6362438201904297,
      "logits/rejected": -2.0210201740264893,
      "logps/chosen": -129.46722412109375,
      "logps/rejected": -218.5843505859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.15645179152488708,
      "rewards/margins": 11.001840591430664,
      "rewards/rejected": -11.158292770385742,
      "step": 3445
    },
    {
      "epoch": 1.3784,
      "grad_norm": 0.6974892616271973,
      "learning_rate": 5.406666666666666e-07,
      "logits/chosen": -2.1833386421203613,
      "logits/rejected": -1.6886379718780518,
      "logps/chosen": -277.91680908203125,
      "logps/rejected": -170.337646484375,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.7778778076171875,
      "rewards/margins": 7.213981628417969,
      "rewards/rejected": -10.991859436035156,
      "step": 3446
    },
    {
      "epoch": 1.3788,
      "grad_norm": 0.004993358161300421,
      "learning_rate": 5.405333333333333e-07,
      "logits/chosen": -3.223271608352661,
      "logits/rejected": -2.7919318675994873,
      "logps/chosen": -78.9300537109375,
      "logps/rejected": -173.726318359375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6570640802383423,
      "rewards/margins": 11.719927787780762,
      "rewards/rejected": -11.062864303588867,
      "step": 3447
    },
    {
      "epoch": 1.3792,
      "grad_norm": 2.235424518585205,
      "learning_rate": 5.403999999999999e-07,
      "logits/chosen": -3.2169384956359863,
      "logits/rejected": -3.0406665802001953,
      "logps/chosen": -40.40559387207031,
      "logps/rejected": -89.36114501953125,
      "loss": 0.021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35055315494537354,
      "rewards/margins": 4.95105504989624,
      "rewards/rejected": -4.600502014160156,
      "step": 3448
    },
    {
      "epoch": 1.3796,
      "grad_norm": 1.3220337629318237,
      "learning_rate": 5.402666666666666e-07,
      "logits/chosen": -3.30849552154541,
      "logits/rejected": -3.1043686866760254,
      "logps/chosen": -149.4988555908203,
      "logps/rejected": -133.201171875,
      "loss": 0.0081,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9172104001045227,
      "rewards/margins": 6.568397045135498,
      "rewards/rejected": -7.485607147216797,
      "step": 3449
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.27200400829315186,
      "learning_rate": 5.401333333333333e-07,
      "logits/chosen": -2.289750099182129,
      "logits/rejected": -1.5197546482086182,
      "logps/chosen": -197.545654296875,
      "logps/rejected": -202.1217498779297,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4853897094726562,
      "rewards/margins": 10.843527793884277,
      "rewards/rejected": -12.328917503356934,
      "step": 3450
    },
    {
      "epoch": 1.3804,
      "grad_norm": 0.011080605909228325,
      "learning_rate": 5.4e-07,
      "logits/chosen": -3.104538917541504,
      "logits/rejected": -2.6983602046966553,
      "logps/chosen": -60.85291290283203,
      "logps/rejected": -151.8611297607422,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8585175275802612,
      "rewards/margins": 9.866485595703125,
      "rewards/rejected": -8.007967948913574,
      "step": 3451
    },
    {
      "epoch": 1.3808,
      "grad_norm": 34.74466323852539,
      "learning_rate": 5.398666666666667e-07,
      "logits/chosen": -2.8199806213378906,
      "logits/rejected": -3.0375475883483887,
      "logps/chosen": -110.66477966308594,
      "logps/rejected": -86.84444427490234,
      "loss": 0.1949,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8557870388031006,
      "rewards/margins": 3.137036085128784,
      "rewards/rejected": -4.992823123931885,
      "step": 3452
    },
    {
      "epoch": 1.3812,
      "grad_norm": 0.006524522323161364,
      "learning_rate": 5.397333333333333e-07,
      "logits/chosen": -2.5193898677825928,
      "logits/rejected": -2.0328404903411865,
      "logps/chosen": -139.09828186035156,
      "logps/rejected": -205.2739715576172,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9028457403182983,
      "rewards/margins": 11.395622253417969,
      "rewards/rejected": -10.492775917053223,
      "step": 3453
    },
    {
      "epoch": 1.3816,
      "grad_norm": 0.32594719529151917,
      "learning_rate": 5.396e-07,
      "logits/chosen": -3.0051021575927734,
      "logits/rejected": -2.9195661544799805,
      "logps/chosen": -117.84900665283203,
      "logps/rejected": -127.52864074707031,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1215579509735107,
      "rewards/margins": 8.166840553283691,
      "rewards/rejected": -7.045282363891602,
      "step": 3454
    },
    {
      "epoch": 1.3820000000000001,
      "grad_norm": 6.595813751220703,
      "learning_rate": 5.394666666666666e-07,
      "logits/chosen": -3.0111193656921387,
      "logits/rejected": -3.0127334594726562,
      "logps/chosen": -121.0468521118164,
      "logps/rejected": -80.09114074707031,
      "loss": 0.0637,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8692841529846191,
      "rewards/margins": 2.8483355045318604,
      "rewards/rejected": -4.717619895935059,
      "step": 3455
    },
    {
      "epoch": 1.3824,
      "grad_norm": 0.021681293845176697,
      "learning_rate": 5.393333333333333e-07,
      "logits/chosen": -2.7880566120147705,
      "logits/rejected": -1.8209364414215088,
      "logps/chosen": -80.66722106933594,
      "logps/rejected": -150.46429443359375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.670708179473877,
      "rewards/margins": 9.180343627929688,
      "rewards/rejected": -7.509634971618652,
      "step": 3456
    },
    {
      "epoch": 1.3828,
      "grad_norm": 0.8027819395065308,
      "learning_rate": 5.392e-07,
      "logits/chosen": -3.008486270904541,
      "logits/rejected": -2.8259315490722656,
      "logps/chosen": -59.018310546875,
      "logps/rejected": -102.23210144042969,
      "loss": 0.0057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.12251529097557068,
      "rewards/margins": 6.126871109008789,
      "rewards/rejected": -6.249386787414551,
      "step": 3457
    },
    {
      "epoch": 1.3832,
      "grad_norm": 1.9909228086471558,
      "learning_rate": 5.390666666666666e-07,
      "logits/chosen": -2.2064332962036133,
      "logits/rejected": -2.315885066986084,
      "logps/chosen": -169.6581573486328,
      "logps/rejected": -127.88670349121094,
      "loss": 0.0112,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.182651162147522,
      "rewards/margins": 5.614383220672607,
      "rewards/rejected": -6.79703426361084,
      "step": 3458
    },
    {
      "epoch": 1.3836,
      "grad_norm": 0.004031437914818525,
      "learning_rate": 5.389333333333333e-07,
      "logits/chosen": -2.6297900676727295,
      "logits/rejected": -2.205687999725342,
      "logps/chosen": -160.64801025390625,
      "logps/rejected": -213.74325561523438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.32544976472854614,
      "rewards/margins": 11.593080520629883,
      "rewards/rejected": -11.918530464172363,
      "step": 3459
    },
    {
      "epoch": 1.384,
      "grad_norm": 2.663968086242676,
      "learning_rate": 5.387999999999999e-07,
      "logits/chosen": -3.1734871864318848,
      "logits/rejected": -2.8767590522766113,
      "logps/chosen": -49.24824523925781,
      "logps/rejected": -76.35832977294922,
      "loss": 0.0286,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3525468707084656,
      "rewards/margins": 4.431912899017334,
      "rewards/rejected": -4.784460067749023,
      "step": 3460
    },
    {
      "epoch": 1.3844,
      "grad_norm": 0.46355631947517395,
      "learning_rate": 5.386666666666666e-07,
      "logits/chosen": -3.085184335708618,
      "logits/rejected": -2.696883201599121,
      "logps/chosen": -97.09205627441406,
      "logps/rejected": -140.6033935546875,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6676326990127563,
      "rewards/margins": 10.342784881591797,
      "rewards/rejected": -9.675152778625488,
      "step": 3461
    },
    {
      "epoch": 1.3848,
      "grad_norm": 0.1102735623717308,
      "learning_rate": 5.385333333333333e-07,
      "logits/chosen": -2.8268589973449707,
      "logits/rejected": -2.1744110584259033,
      "logps/chosen": -117.56783294677734,
      "logps/rejected": -129.5274658203125,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.17037850618362427,
      "rewards/margins": 7.644080638885498,
      "rewards/rejected": -7.814458847045898,
      "step": 3462
    },
    {
      "epoch": 1.3852,
      "grad_norm": 0.006866102572530508,
      "learning_rate": 5.384e-07,
      "logits/chosen": -3.0939011573791504,
      "logits/rejected": -2.7184078693389893,
      "logps/chosen": -78.11561584472656,
      "logps/rejected": -145.9169921875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9044398069381714,
      "rewards/margins": 10.507476806640625,
      "rewards/rejected": -8.603036880493164,
      "step": 3463
    },
    {
      "epoch": 1.3856,
      "grad_norm": 16.805917739868164,
      "learning_rate": 5.382666666666667e-07,
      "logits/chosen": -2.446591377258301,
      "logits/rejected": -1.7739570140838623,
      "logps/chosen": -183.9268341064453,
      "logps/rejected": -208.8548583984375,
      "loss": 0.0613,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.3638267517089844,
      "rewards/margins": 8.605854988098145,
      "rewards/rejected": -10.969680786132812,
      "step": 3464
    },
    {
      "epoch": 1.3860000000000001,
      "grad_norm": 0.0221621822565794,
      "learning_rate": 5.381333333333333e-07,
      "logits/chosen": -2.534634590148926,
      "logits/rejected": -2.090980291366577,
      "logps/chosen": -88.68521881103516,
      "logps/rejected": -153.224853515625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9789329767227173,
      "rewards/margins": 9.71674633026123,
      "rewards/rejected": -8.737813949584961,
      "step": 3465
    },
    {
      "epoch": 1.3864,
      "grad_norm": 0.0030972920358181,
      "learning_rate": 5.38e-07,
      "logits/chosen": -2.349520683288574,
      "logits/rejected": -1.5637556314468384,
      "logps/chosen": -208.1162109375,
      "logps/rejected": -199.4900360107422,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9046878814697266,
      "rewards/margins": 12.07879638671875,
      "rewards/rejected": -12.983484268188477,
      "step": 3466
    },
    {
      "epoch": 1.3868,
      "grad_norm": 0.14478132128715515,
      "learning_rate": 5.378666666666667e-07,
      "logits/chosen": -3.220400810241699,
      "logits/rejected": -2.9719738960266113,
      "logps/chosen": -85.3944320678711,
      "logps/rejected": -123.14901733398438,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6917788982391357,
      "rewards/margins": 7.752745628356934,
      "rewards/rejected": -6.060966968536377,
      "step": 3467
    },
    {
      "epoch": 1.3872,
      "grad_norm": 0.016502393409609795,
      "learning_rate": 5.377333333333333e-07,
      "logits/chosen": -2.9995360374450684,
      "logits/rejected": -2.2597084045410156,
      "logps/chosen": -108.46366882324219,
      "logps/rejected": -178.20657348632812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7127258777618408,
      "rewards/margins": 11.464155197143555,
      "rewards/rejected": -10.751428604125977,
      "step": 3468
    },
    {
      "epoch": 1.3876,
      "grad_norm": 0.35218149423599243,
      "learning_rate": 5.375999999999999e-07,
      "logits/chosen": -2.9537010192871094,
      "logits/rejected": -2.678471088409424,
      "logps/chosen": -58.483150482177734,
      "logps/rejected": -89.35429382324219,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21956771612167358,
      "rewards/margins": 6.067587375640869,
      "rewards/rejected": -5.848019599914551,
      "step": 3469
    },
    {
      "epoch": 1.388,
      "grad_norm": 0.009213108569383621,
      "learning_rate": 5.374666666666666e-07,
      "logits/chosen": -2.5074973106384277,
      "logits/rejected": -1.7820448875427246,
      "logps/chosen": -131.2228546142578,
      "logps/rejected": -162.06268310546875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1897999048233032,
      "rewards/margins": 10.588895797729492,
      "rewards/rejected": -9.399096488952637,
      "step": 3470
    },
    {
      "epoch": 1.3884,
      "grad_norm": 0.43528056144714355,
      "learning_rate": 5.373333333333333e-07,
      "logits/chosen": -3.007622241973877,
      "logits/rejected": -2.6294546127319336,
      "logps/chosen": -42.08761978149414,
      "logps/rejected": -119.05635070800781,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2131669968366623,
      "rewards/margins": 7.562714576721191,
      "rewards/rejected": -7.349547863006592,
      "step": 3471
    },
    {
      "epoch": 1.3888,
      "grad_norm": 0.04904596880078316,
      "learning_rate": 5.372e-07,
      "logits/chosen": -2.786937713623047,
      "logits/rejected": -2.103710174560547,
      "logps/chosen": -102.93701171875,
      "logps/rejected": -145.00704956054688,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.014054685831069946,
      "rewards/margins": 9.023932456970215,
      "rewards/rejected": -9.037986755371094,
      "step": 3472
    },
    {
      "epoch": 1.3892,
      "grad_norm": 0.004094439558684826,
      "learning_rate": 5.370666666666667e-07,
      "logits/chosen": -2.82305908203125,
      "logits/rejected": -2.435411214828491,
      "logps/chosen": -142.50965881347656,
      "logps/rejected": -305.9138488769531,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9733452796936035,
      "rewards/margins": 11.07049560546875,
      "rewards/rejected": -9.097149848937988,
      "step": 3473
    },
    {
      "epoch": 1.3896,
      "grad_norm": 0.011671044863760471,
      "learning_rate": 5.369333333333333e-07,
      "logits/chosen": -2.722994327545166,
      "logits/rejected": -2.152698040008545,
      "logps/chosen": -73.232177734375,
      "logps/rejected": -145.65684509277344,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5404831171035767,
      "rewards/margins": 10.073189735412598,
      "rewards/rejected": -8.532707214355469,
      "step": 3474
    },
    {
      "epoch": 1.3900000000000001,
      "grad_norm": 0.13164615631103516,
      "learning_rate": 5.368e-07,
      "logits/chosen": -2.790404796600342,
      "logits/rejected": -1.912117600440979,
      "logps/chosen": -123.93248748779297,
      "logps/rejected": -231.1000213623047,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.511562168598175,
      "rewards/margins": 12.36252498626709,
      "rewards/rejected": -12.874086380004883,
      "step": 3475
    },
    {
      "epoch": 1.3904,
      "grad_norm": 0.28371861577033997,
      "learning_rate": 5.366666666666666e-07,
      "logits/chosen": -2.6407854557037354,
      "logits/rejected": -1.9091238975524902,
      "logps/chosen": -95.82854461669922,
      "logps/rejected": -113.76151275634766,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4899107217788696,
      "rewards/margins": 7.086695671081543,
      "rewards/rejected": -5.596785068511963,
      "step": 3476
    },
    {
      "epoch": 1.3908,
      "grad_norm": 0.27668043971061707,
      "learning_rate": 5.365333333333333e-07,
      "logits/chosen": -2.7612316608428955,
      "logits/rejected": -2.0037875175476074,
      "logps/chosen": -99.53427124023438,
      "logps/rejected": -155.97430419921875,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2252923250198364,
      "rewards/margins": 11.218297004699707,
      "rewards/rejected": -9.993005752563477,
      "step": 3477
    },
    {
      "epoch": 1.3912,
      "grad_norm": 0.006407054606825113,
      "learning_rate": 5.364e-07,
      "logits/chosen": -2.7896828651428223,
      "logits/rejected": -1.9179518222808838,
      "logps/chosen": -119.64073181152344,
      "logps/rejected": -200.0353240966797,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8459747433662415,
      "rewards/margins": 12.104683876037598,
      "rewards/rejected": -12.950658798217773,
      "step": 3478
    },
    {
      "epoch": 1.3916,
      "grad_norm": 0.019220085814595222,
      "learning_rate": 5.362666666666667e-07,
      "logits/chosen": -2.96832013130188,
      "logits/rejected": -2.674933433532715,
      "logps/chosen": -78.27191925048828,
      "logps/rejected": -169.10928344726562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22914086282253265,
      "rewards/margins": 11.166829109191895,
      "rewards/rejected": -10.937688827514648,
      "step": 3479
    },
    {
      "epoch": 1.392,
      "grad_norm": 0.034772880375385284,
      "learning_rate": 5.361333333333333e-07,
      "logits/chosen": -3.181220054626465,
      "logits/rejected": -2.6683900356292725,
      "logps/chosen": -57.05488204956055,
      "logps/rejected": -129.07064819335938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5358074307441711,
      "rewards/margins": 8.608146667480469,
      "rewards/rejected": -8.07234001159668,
      "step": 3480
    },
    {
      "epoch": 1.3924,
      "grad_norm": 0.004617064259946346,
      "learning_rate": 5.36e-07,
      "logits/chosen": -2.7466206550598145,
      "logits/rejected": -2.10492205619812,
      "logps/chosen": -68.75740814208984,
      "logps/rejected": -170.7637939453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.717593789100647,
      "rewards/margins": 10.98547077178955,
      "rewards/rejected": -9.267877578735352,
      "step": 3481
    },
    {
      "epoch": 1.3928,
      "grad_norm": 0.006791137158870697,
      "learning_rate": 5.358666666666667e-07,
      "logits/chosen": -3.019178628921509,
      "logits/rejected": -2.448580503463745,
      "logps/chosen": -57.415283203125,
      "logps/rejected": -192.25047302246094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1457178145647049,
      "rewards/margins": 12.010547637939453,
      "rewards/rejected": -11.864830017089844,
      "step": 3482
    },
    {
      "epoch": 1.3932,
      "grad_norm": 0.7138581871986389,
      "learning_rate": 5.357333333333332e-07,
      "logits/chosen": -2.675588846206665,
      "logits/rejected": -2.1134676933288574,
      "logps/chosen": -152.89407348632812,
      "logps/rejected": -159.29672241210938,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.65238618850708,
      "rewards/margins": 7.608316898345947,
      "rewards/rejected": -10.260703086853027,
      "step": 3483
    },
    {
      "epoch": 1.3936,
      "grad_norm": 0.02314659021794796,
      "learning_rate": 5.355999999999999e-07,
      "logits/chosen": -3.110095262527466,
      "logits/rejected": -2.7964365482330322,
      "logps/chosen": -66.35615539550781,
      "logps/rejected": -138.57650756835938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0155494213104248,
      "rewards/margins": 8.734575271606445,
      "rewards/rejected": -7.719025611877441,
      "step": 3484
    },
    {
      "epoch": 1.3940000000000001,
      "grad_norm": 0.6335042119026184,
      "learning_rate": 5.354666666666666e-07,
      "logits/chosen": -2.8520400524139404,
      "logits/rejected": -2.5723228454589844,
      "logps/chosen": -75.29194641113281,
      "logps/rejected": -135.95785522460938,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4234533309936523,
      "rewards/margins": 6.775604724884033,
      "rewards/rejected": -8.199058532714844,
      "step": 3485
    },
    {
      "epoch": 1.3944,
      "grad_norm": 0.04843342676758766,
      "learning_rate": 5.353333333333333e-07,
      "logits/chosen": -2.258603811264038,
      "logits/rejected": -1.6903867721557617,
      "logps/chosen": -193.43789672851562,
      "logps/rejected": -174.06944274902344,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.397273302078247,
      "rewards/margins": 8.333965301513672,
      "rewards/rejected": -9.73123836517334,
      "step": 3486
    },
    {
      "epoch": 1.3948,
      "grad_norm": 49.026615142822266,
      "learning_rate": 5.352e-07,
      "logits/chosen": -2.686138868331909,
      "logits/rejected": -2.069289445877075,
      "logps/chosen": -145.04006958007812,
      "logps/rejected": -130.22216796875,
      "loss": 0.2413,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2030971050262451,
      "rewards/margins": 5.581089019775391,
      "rewards/rejected": -6.784186363220215,
      "step": 3487
    },
    {
      "epoch": 1.3952,
      "grad_norm": 0.32896173000335693,
      "learning_rate": 5.350666666666667e-07,
      "logits/chosen": -2.980393409729004,
      "logits/rejected": -2.776078701019287,
      "logps/chosen": -67.37574005126953,
      "logps/rejected": -115.53397369384766,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.43666306138038635,
      "rewards/margins": 7.75701904296875,
      "rewards/rejected": -7.320355415344238,
      "step": 3488
    },
    {
      "epoch": 1.3956,
      "grad_norm": 9.308051109313965,
      "learning_rate": 5.349333333333334e-07,
      "logits/chosen": -2.795921802520752,
      "logits/rejected": -2.5533647537231445,
      "logps/chosen": -147.73976135253906,
      "logps/rejected": -155.48751831054688,
      "loss": 0.0416,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3188228607177734,
      "rewards/margins": 8.225482940673828,
      "rewards/rejected": -9.544305801391602,
      "step": 3489
    },
    {
      "epoch": 1.396,
      "grad_norm": 1.2180039882659912,
      "learning_rate": 5.348e-07,
      "logits/chosen": -3.06097674369812,
      "logits/rejected": -2.7280845642089844,
      "logps/chosen": -100.90827941894531,
      "logps/rejected": -129.99786376953125,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9566620588302612,
      "rewards/margins": 7.140469551086426,
      "rewards/rejected": -9.097131729125977,
      "step": 3490
    },
    {
      "epoch": 1.3963999999999999,
      "grad_norm": 0.0037105558440089226,
      "learning_rate": 5.346666666666666e-07,
      "logits/chosen": -2.612940788269043,
      "logits/rejected": -2.0361897945404053,
      "logps/chosen": -139.95736694335938,
      "logps/rejected": -176.58836364746094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1890609860420227,
      "rewards/margins": 11.450139999389648,
      "rewards/rejected": -11.261077880859375,
      "step": 3491
    },
    {
      "epoch": 1.3968,
      "grad_norm": 0.27742213010787964,
      "learning_rate": 5.345333333333333e-07,
      "logits/chosen": -3.021268606185913,
      "logits/rejected": -2.8589823246002197,
      "logps/chosen": -83.9261474609375,
      "logps/rejected": -102.29608154296875,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33205854892730713,
      "rewards/margins": 7.530632972717285,
      "rewards/rejected": -7.198574066162109,
      "step": 3492
    },
    {
      "epoch": 1.3972,
      "grad_norm": 11.226950645446777,
      "learning_rate": 5.343999999999999e-07,
      "logits/chosen": -2.868590831756592,
      "logits/rejected": -2.6818933486938477,
      "logps/chosen": -112.98881530761719,
      "logps/rejected": -104.23796081542969,
      "loss": 0.0884,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.558178722858429,
      "rewards/margins": 4.463593006134033,
      "rewards/rejected": -3.905414342880249,
      "step": 3493
    },
    {
      "epoch": 1.3976,
      "grad_norm": 0.3141734004020691,
      "learning_rate": 5.342666666666666e-07,
      "logits/chosen": -2.511033296585083,
      "logits/rejected": -2.0649263858795166,
      "logps/chosen": -46.05814743041992,
      "logps/rejected": -111.97566223144531,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1496381759643555,
      "rewards/margins": 7.351517677307129,
      "rewards/rejected": -6.201879501342773,
      "step": 3494
    },
    {
      "epoch": 1.3980000000000001,
      "grad_norm": 4.118335247039795,
      "learning_rate": 5.341333333333333e-07,
      "logits/chosen": -3.2970170974731445,
      "logits/rejected": -2.8847532272338867,
      "logps/chosen": -43.15190887451172,
      "logps/rejected": -105.66211700439453,
      "loss": 0.0366,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6110261678695679,
      "rewards/margins": 5.212820053100586,
      "rewards/rejected": -5.823845863342285,
      "step": 3495
    },
    {
      "epoch": 1.3984,
      "grad_norm": 1.781785011291504,
      "learning_rate": 5.34e-07,
      "logits/chosen": -2.657115936279297,
      "logits/rejected": -2.3081839084625244,
      "logps/chosen": -143.8219451904297,
      "logps/rejected": -137.31443786621094,
      "loss": 0.0091,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1896011233329773,
      "rewards/margins": 6.674966812133789,
      "rewards/rejected": -6.864567756652832,
      "step": 3496
    },
    {
      "epoch": 1.3988,
      "grad_norm": 0.10229180753231049,
      "learning_rate": 5.338666666666667e-07,
      "logits/chosen": -2.7784321308135986,
      "logits/rejected": -1.7642977237701416,
      "logps/chosen": -81.3375015258789,
      "logps/rejected": -136.4013671875,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.312645673751831,
      "rewards/margins": 10.036706924438477,
      "rewards/rejected": -8.724061012268066,
      "step": 3497
    },
    {
      "epoch": 1.3992,
      "grad_norm": 0.006545594427734613,
      "learning_rate": 5.337333333333333e-07,
      "logits/chosen": -2.8637375831604004,
      "logits/rejected": -2.458441734313965,
      "logps/chosen": -73.67356872558594,
      "logps/rejected": -141.0296630859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8099819421768188,
      "rewards/margins": 10.360403060913086,
      "rewards/rejected": -9.550420761108398,
      "step": 3498
    },
    {
      "epoch": 1.3996,
      "grad_norm": 0.003330314764752984,
      "learning_rate": 5.336e-07,
      "logits/chosen": -2.9945292472839355,
      "logits/rejected": -2.2006897926330566,
      "logps/chosen": -98.0466537475586,
      "logps/rejected": -237.16806030273438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7043443918228149,
      "rewards/margins": 15.775934219360352,
      "rewards/rejected": -15.071588516235352,
      "step": 3499
    },
    {
      "epoch": 1.4,
      "grad_norm": 6.897989749908447,
      "learning_rate": 5.334666666666667e-07,
      "logits/chosen": -3.06901216506958,
      "logits/rejected": -2.8906455039978027,
      "logps/chosen": -54.745880126953125,
      "logps/rejected": -67.07203674316406,
      "loss": 0.0397,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.383989155292511,
      "rewards/margins": 4.618484973907471,
      "rewards/rejected": -4.234495639801025,
      "step": 3500
    },
    {
      "epoch": 1.4003999999999999,
      "grad_norm": 0.3404262959957123,
      "learning_rate": 5.333333333333333e-07,
      "logits/chosen": -2.9895524978637695,
      "logits/rejected": -3.140169382095337,
      "logps/chosen": -75.09559631347656,
      "logps/rejected": -86.15003967285156,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4369983673095703,
      "rewards/margins": 6.0364460945129395,
      "rewards/rejected": -5.599447727203369,
      "step": 3501
    },
    {
      "epoch": 1.4008,
      "grad_norm": 0.017203237861394882,
      "learning_rate": 5.331999999999999e-07,
      "logits/chosen": -2.744377613067627,
      "logits/rejected": -1.9698594808578491,
      "logps/chosen": -71.8508071899414,
      "logps/rejected": -128.73062133789062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4418461322784424,
      "rewards/margins": 9.286914825439453,
      "rewards/rejected": -7.845067977905273,
      "step": 3502
    },
    {
      "epoch": 1.4012,
      "grad_norm": 0.1738172173500061,
      "learning_rate": 5.330666666666666e-07,
      "logits/chosen": -3.460752487182617,
      "logits/rejected": -2.7812347412109375,
      "logps/chosen": -47.88031005859375,
      "logps/rejected": -133.75115966796875,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4591842591762543,
      "rewards/margins": 9.523534774780273,
      "rewards/rejected": -9.064350128173828,
      "step": 3503
    },
    {
      "epoch": 1.4016,
      "grad_norm": 0.10811983048915863,
      "learning_rate": 5.329333333333333e-07,
      "logits/chosen": -2.9570465087890625,
      "logits/rejected": -2.3510260581970215,
      "logps/chosen": -129.47618103027344,
      "logps/rejected": -156.61419677734375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8789856433868408,
      "rewards/margins": 8.039080619812012,
      "rewards/rejected": -8.918066024780273,
      "step": 3504
    },
    {
      "epoch": 1.4020000000000001,
      "grad_norm": 1.2956100702285767,
      "learning_rate": 5.328e-07,
      "logits/chosen": -2.6381211280822754,
      "logits/rejected": -2.3011281490325928,
      "logps/chosen": -170.23245239257812,
      "logps/rejected": -213.0935516357422,
      "loss": 0.0119,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.2763020992279053,
      "rewards/margins": 6.344894886016846,
      "rewards/rejected": -9.621196746826172,
      "step": 3505
    },
    {
      "epoch": 1.4024,
      "grad_norm": 0.10250414907932281,
      "learning_rate": 5.326666666666666e-07,
      "logits/chosen": -2.7052769660949707,
      "logits/rejected": -2.0975186824798584,
      "logps/chosen": -143.07386779785156,
      "logps/rejected": -157.48765563964844,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.508010149002075,
      "rewards/margins": 7.652285575866699,
      "rewards/rejected": -11.160295486450195,
      "step": 3506
    },
    {
      "epoch": 1.4028,
      "grad_norm": 0.3637699484825134,
      "learning_rate": 5.325333333333333e-07,
      "logits/chosen": -3.4327385425567627,
      "logits/rejected": -2.9989891052246094,
      "logps/chosen": -55.45469665527344,
      "logps/rejected": -106.83882904052734,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40584811568260193,
      "rewards/margins": 7.0444416999816895,
      "rewards/rejected": -6.638593673706055,
      "step": 3507
    },
    {
      "epoch": 1.4032,
      "grad_norm": 0.5977998971939087,
      "learning_rate": 5.324e-07,
      "logits/chosen": -2.8041412830352783,
      "logits/rejected": -2.5806941986083984,
      "logps/chosen": -99.21710205078125,
      "logps/rejected": -159.68911743164062,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0329499244689941,
      "rewards/margins": 10.406026840209961,
      "rewards/rejected": -9.373077392578125,
      "step": 3508
    },
    {
      "epoch": 1.4036,
      "grad_norm": 0.1716710925102234,
      "learning_rate": 5.322666666666667e-07,
      "logits/chosen": -2.738565444946289,
      "logits/rejected": -2.2575721740722656,
      "logps/chosen": -170.5961456298828,
      "logps/rejected": -115.17037200927734,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6409927606582642,
      "rewards/margins": 7.472238540649414,
      "rewards/rejected": -8.113231658935547,
      "step": 3509
    },
    {
      "epoch": 1.404,
      "grad_norm": 0.030248591676354408,
      "learning_rate": 5.321333333333334e-07,
      "logits/chosen": -2.85530948638916,
      "logits/rejected": -2.2079434394836426,
      "logps/chosen": -57.941162109375,
      "logps/rejected": -309.71282958984375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5327476263046265,
      "rewards/margins": 12.5879545211792,
      "rewards/rejected": -11.055206298828125,
      "step": 3510
    },
    {
      "epoch": 1.4043999999999999,
      "grad_norm": 28.713781356811523,
      "learning_rate": 5.32e-07,
      "logits/chosen": -2.6907100677490234,
      "logits/rejected": -2.469588279724121,
      "logps/chosen": -115.30947875976562,
      "logps/rejected": -143.55404663085938,
      "loss": 0.1988,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4161487817764282,
      "rewards/margins": 7.937154769897461,
      "rewards/rejected": -8.353303909301758,
      "step": 3511
    },
    {
      "epoch": 1.4048,
      "grad_norm": 0.014638913795351982,
      "learning_rate": 5.318666666666666e-07,
      "logits/chosen": -3.0888376235961914,
      "logits/rejected": -2.5758957862854004,
      "logps/chosen": -54.0067253112793,
      "logps/rejected": -156.34521484375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.261176198720932,
      "rewards/margins": 10.816892623901367,
      "rewards/rejected": -10.555716514587402,
      "step": 3512
    },
    {
      "epoch": 1.4052,
      "grad_norm": 1.851000189781189,
      "learning_rate": 5.317333333333332e-07,
      "logits/chosen": -2.709230422973633,
      "logits/rejected": -2.1523282527923584,
      "logps/chosen": -171.0854034423828,
      "logps/rejected": -168.45263671875,
      "loss": 0.0137,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4356956481933594,
      "rewards/margins": 6.714461326599121,
      "rewards/rejected": -8.15015697479248,
      "step": 3513
    },
    {
      "epoch": 1.4056,
      "grad_norm": 0.013996902853250504,
      "learning_rate": 5.315999999999999e-07,
      "logits/chosen": -3.073078155517578,
      "logits/rejected": -2.692880153656006,
      "logps/chosen": -73.04623413085938,
      "logps/rejected": -144.22283935546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41017037630081177,
      "rewards/margins": 9.336196899414062,
      "rewards/rejected": -8.926026344299316,
      "step": 3514
    },
    {
      "epoch": 1.4060000000000001,
      "grad_norm": 2.1618869304656982,
      "learning_rate": 5.314666666666666e-07,
      "logits/chosen": -2.663846492767334,
      "logits/rejected": -2.1406803131103516,
      "logps/chosen": -64.32421875,
      "logps/rejected": -141.9318389892578,
      "loss": 0.0254,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21252843737602234,
      "rewards/margins": 8.255045890808105,
      "rewards/rejected": -8.04251766204834,
      "step": 3515
    },
    {
      "epoch": 1.4064,
      "grad_norm": 0.5456349849700928,
      "learning_rate": 5.313333333333333e-07,
      "logits/chosen": -2.9650485515594482,
      "logits/rejected": -2.7452244758605957,
      "logps/chosen": -119.09766387939453,
      "logps/rejected": -103.24526977539062,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3455265164375305,
      "rewards/margins": 6.158490180969238,
      "rewards/rejected": -6.504016876220703,
      "step": 3516
    },
    {
      "epoch": 1.4068,
      "grad_norm": 0.005064859054982662,
      "learning_rate": 5.312e-07,
      "logits/chosen": -2.8281378746032715,
      "logits/rejected": -2.1922504901885986,
      "logps/chosen": -105.80033874511719,
      "logps/rejected": -203.0124969482422,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2007122039794922,
      "rewards/margins": 10.717790603637695,
      "rewards/rejected": -9.517078399658203,
      "step": 3517
    },
    {
      "epoch": 1.4072,
      "grad_norm": 0.6653684973716736,
      "learning_rate": 5.310666666666667e-07,
      "logits/chosen": -3.0116329193115234,
      "logits/rejected": -2.806734561920166,
      "logps/chosen": -63.71303176879883,
      "logps/rejected": -119.17762756347656,
      "loss": 0.0045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7303081154823303,
      "rewards/margins": 7.754824161529541,
      "rewards/rejected": -7.0245161056518555,
      "step": 3518
    },
    {
      "epoch": 1.4076,
      "grad_norm": 7.419508934020996,
      "learning_rate": 5.309333333333334e-07,
      "logits/chosen": -3.1734611988067627,
      "logits/rejected": -3.0489277839660645,
      "logps/chosen": -56.72605514526367,
      "logps/rejected": -79.20159149169922,
      "loss": 0.0804,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3198539614677429,
      "rewards/margins": 3.9455959796905518,
      "rewards/rejected": -4.2654500007629395,
      "step": 3519
    },
    {
      "epoch": 1.408,
      "grad_norm": 4.7827839851379395,
      "learning_rate": 5.308000000000001e-07,
      "logits/chosen": -2.762171983718872,
      "logits/rejected": -2.4199423789978027,
      "logps/chosen": -158.5628204345703,
      "logps/rejected": -152.02377319335938,
      "loss": 0.0229,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.807426929473877,
      "rewards/margins": 6.710056781768799,
      "rewards/rejected": -10.517483711242676,
      "step": 3520
    },
    {
      "epoch": 1.4083999999999999,
      "grad_norm": 0.010604945942759514,
      "learning_rate": 5.306666666666665e-07,
      "logits/chosen": -2.783137321472168,
      "logits/rejected": -2.348764419555664,
      "logps/chosen": -76.92706298828125,
      "logps/rejected": -147.35272216796875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0160117149353027,
      "rewards/margins": 9.55816650390625,
      "rewards/rejected": -8.542154312133789,
      "step": 3521
    },
    {
      "epoch": 1.4088,
      "grad_norm": 0.18685956299304962,
      "learning_rate": 5.305333333333332e-07,
      "logits/chosen": -2.902613401412964,
      "logits/rejected": -2.5944933891296387,
      "logps/chosen": -88.88220977783203,
      "logps/rejected": -155.9867706298828,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2017638683319092,
      "rewards/margins": 8.547409057617188,
      "rewards/rejected": -7.345645427703857,
      "step": 3522
    },
    {
      "epoch": 1.4092,
      "grad_norm": 191.26181030273438,
      "learning_rate": 5.303999999999999e-07,
      "logits/chosen": -2.6108837127685547,
      "logits/rejected": -2.2224955558776855,
      "logps/chosen": -225.91404724121094,
      "logps/rejected": -149.23626708984375,
      "loss": 0.9154,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -5.304353713989258,
      "rewards/margins": 3.086338758468628,
      "rewards/rejected": -8.390692710876465,
      "step": 3523
    },
    {
      "epoch": 1.4096,
      "grad_norm": 0.009730867110192776,
      "learning_rate": 5.302666666666666e-07,
      "logits/chosen": -2.7270636558532715,
      "logits/rejected": -2.2116453647613525,
      "logps/chosen": -102.73175048828125,
      "logps/rejected": -155.09158325195312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5847927331924438,
      "rewards/margins": 10.554902076721191,
      "rewards/rejected": -9.970109939575195,
      "step": 3524
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.24213860929012299,
      "learning_rate": 5.301333333333333e-07,
      "logits/chosen": -2.7579808235168457,
      "logits/rejected": -2.3940494060516357,
      "logps/chosen": -178.18548583984375,
      "logps/rejected": -169.5085906982422,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0269246101379395,
      "rewards/margins": 7.506136417388916,
      "rewards/rejected": -9.533061027526855,
      "step": 3525
    },
    {
      "epoch": 1.4104,
      "grad_norm": 0.3145706057548523,
      "learning_rate": 5.3e-07,
      "logits/chosen": -2.734851121902466,
      "logits/rejected": -2.2892894744873047,
      "logps/chosen": -82.58993530273438,
      "logps/rejected": -170.79672241210938,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6852195858955383,
      "rewards/margins": 10.584724426269531,
      "rewards/rejected": -9.899504661560059,
      "step": 3526
    },
    {
      "epoch": 1.4108,
      "grad_norm": 0.052656907588243484,
      "learning_rate": 5.298666666666667e-07,
      "logits/chosen": -2.840291738510132,
      "logits/rejected": -2.1882002353668213,
      "logps/chosen": -119.13818359375,
      "logps/rejected": -120.11321258544922,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2318344116210938,
      "rewards/margins": 8.693510055541992,
      "rewards/rejected": -7.461675643920898,
      "step": 3527
    },
    {
      "epoch": 1.4112,
      "grad_norm": 31.87868309020996,
      "learning_rate": 5.297333333333333e-07,
      "logits/chosen": -2.7814674377441406,
      "logits/rejected": -2.2822444438934326,
      "logps/chosen": -124.4449462890625,
      "logps/rejected": -143.6925048828125,
      "loss": 0.3598,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -1.2374048233032227,
      "rewards/margins": 7.410797119140625,
      "rewards/rejected": -8.648201942443848,
      "step": 3528
    },
    {
      "epoch": 1.4116,
      "grad_norm": 0.033557500690221786,
      "learning_rate": 5.296e-07,
      "logits/chosen": -2.6004867553710938,
      "logits/rejected": -1.643080472946167,
      "logps/chosen": -150.02430725097656,
      "logps/rejected": -167.70419311523438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9645165205001831,
      "rewards/margins": 10.478618621826172,
      "rewards/rejected": -11.443135261535645,
      "step": 3529
    },
    {
      "epoch": 1.412,
      "grad_norm": 0.2537483870983124,
      "learning_rate": 5.294666666666667e-07,
      "logits/chosen": -2.9909043312072754,
      "logits/rejected": -2.466583490371704,
      "logps/chosen": -125.58540344238281,
      "logps/rejected": -152.42601013183594,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8743868470191956,
      "rewards/margins": 8.024025917053223,
      "rewards/rejected": -8.898412704467773,
      "step": 3530
    },
    {
      "epoch": 1.4123999999999999,
      "grad_norm": 0.013116179034113884,
      "learning_rate": 5.293333333333333e-07,
      "logits/chosen": -2.849003314971924,
      "logits/rejected": -2.5034708976745605,
      "logps/chosen": -62.60090637207031,
      "logps/rejected": -132.4695587158203,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2215027809143066,
      "rewards/margins": 9.322442054748535,
      "rewards/rejected": -8.10093879699707,
      "step": 3531
    },
    {
      "epoch": 1.4128,
      "grad_norm": 0.00212471024133265,
      "learning_rate": 5.292e-07,
      "logits/chosen": -2.738802433013916,
      "logits/rejected": -2.375723361968994,
      "logps/chosen": -100.70587158203125,
      "logps/rejected": -206.3438720703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.475454330444336,
      "rewards/margins": 11.843132972717285,
      "rewards/rejected": -10.36767864227295,
      "step": 3532
    },
    {
      "epoch": 1.4132,
      "grad_norm": 104.04206848144531,
      "learning_rate": 5.290666666666666e-07,
      "logits/chosen": -2.389362096786499,
      "logits/rejected": -2.2786238193511963,
      "logps/chosen": -125.71853637695312,
      "logps/rejected": -129.76327514648438,
      "loss": 4.1948,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -5.90700626373291,
      "rewards/margins": 0.9878425598144531,
      "rewards/rejected": -6.894848823547363,
      "step": 3533
    },
    {
      "epoch": 1.4136,
      "grad_norm": 0.5111637711524963,
      "learning_rate": 5.289333333333333e-07,
      "logits/chosen": -3.0334439277648926,
      "logits/rejected": -2.7197296619415283,
      "logps/chosen": -77.87669372558594,
      "logps/rejected": -98.83114624023438,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9726908206939697,
      "rewards/margins": 6.448894500732422,
      "rewards/rejected": -5.476203918457031,
      "step": 3534
    },
    {
      "epoch": 1.414,
      "grad_norm": 0.008049948140978813,
      "learning_rate": 5.288e-07,
      "logits/chosen": -2.450328826904297,
      "logits/rejected": -1.9222708940505981,
      "logps/chosen": -141.69175720214844,
      "logps/rejected": -178.756591796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5626766681671143,
      "rewards/margins": 10.983354568481445,
      "rewards/rejected": -11.546030044555664,
      "step": 3535
    },
    {
      "epoch": 1.4144,
      "grad_norm": 0.13240568339824677,
      "learning_rate": 5.286666666666666e-07,
      "logits/chosen": -2.7862935066223145,
      "logits/rejected": -2.4483141899108887,
      "logps/chosen": -95.89619445800781,
      "logps/rejected": -139.38003540039062,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.14259091019630432,
      "rewards/margins": 7.231868743896484,
      "rewards/rejected": -7.374459743499756,
      "step": 3536
    },
    {
      "epoch": 1.4148,
      "grad_norm": 0.017764680087566376,
      "learning_rate": 5.285333333333333e-07,
      "logits/chosen": -2.669534683227539,
      "logits/rejected": -2.1244685649871826,
      "logps/chosen": -204.58859252929688,
      "logps/rejected": -152.0859375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5968952775001526,
      "rewards/margins": 9.31649398803711,
      "rewards/rejected": -8.719598770141602,
      "step": 3537
    },
    {
      "epoch": 1.4152,
      "grad_norm": 0.05604041740298271,
      "learning_rate": 5.284e-07,
      "logits/chosen": -2.335010528564453,
      "logits/rejected": -1.7617943286895752,
      "logps/chosen": -141.60626220703125,
      "logps/rejected": -242.4290771484375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12017631530761719,
      "rewards/margins": 10.0789155960083,
      "rewards/rejected": -9.958739280700684,
      "step": 3538
    },
    {
      "epoch": 1.4156,
      "grad_norm": 0.080631785094738,
      "learning_rate": 5.282666666666667e-07,
      "logits/chosen": -2.7079710960388184,
      "logits/rejected": -2.2378194332122803,
      "logps/chosen": -100.0988540649414,
      "logps/rejected": -142.64932250976562,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.46756380796432495,
      "rewards/margins": 9.012489318847656,
      "rewards/rejected": -9.480052947998047,
      "step": 3539
    },
    {
      "epoch": 1.416,
      "grad_norm": 0.0006439085700549185,
      "learning_rate": 5.281333333333333e-07,
      "logits/chosen": -2.9625372886657715,
      "logits/rejected": -2.2671878337860107,
      "logps/chosen": -88.23027038574219,
      "logps/rejected": -196.24801635742188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9901241064071655,
      "rewards/margins": 13.642267227172852,
      "rewards/rejected": -12.652143478393555,
      "step": 3540
    },
    {
      "epoch": 1.4163999999999999,
      "grad_norm": 2.146937370300293,
      "learning_rate": 5.28e-07,
      "logits/chosen": -2.9823951721191406,
      "logits/rejected": -2.601926565170288,
      "logps/chosen": -88.99122619628906,
      "logps/rejected": -103.2664794921875,
      "loss": 0.0158,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6832069754600525,
      "rewards/margins": 5.679620265960693,
      "rewards/rejected": -6.362827301025391,
      "step": 3541
    },
    {
      "epoch": 1.4168,
      "grad_norm": 0.2768053412437439,
      "learning_rate": 5.278666666666667e-07,
      "logits/chosen": -2.5891852378845215,
      "logits/rejected": -1.9764864444732666,
      "logps/chosen": -150.2479248046875,
      "logps/rejected": -189.281494140625,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1492996215820312,
      "rewards/margins": 8.897834777832031,
      "rewards/rejected": -10.047134399414062,
      "step": 3542
    },
    {
      "epoch": 1.4172,
      "grad_norm": 75.73208618164062,
      "learning_rate": 5.277333333333333e-07,
      "logits/chosen": -2.665177345275879,
      "logits/rejected": -2.349116325378418,
      "logps/chosen": -163.67666625976562,
      "logps/rejected": -135.2124786376953,
      "loss": 0.8033,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -1.602095127105713,
      "rewards/margins": 6.87620735168457,
      "rewards/rejected": -8.478302955627441,
      "step": 3543
    },
    {
      "epoch": 1.4176,
      "grad_norm": 0.002909379778429866,
      "learning_rate": 5.275999999999999e-07,
      "logits/chosen": -3.2139663696289062,
      "logits/rejected": -2.811357021331787,
      "logps/chosen": -56.02619934082031,
      "logps/rejected": -172.56033325195312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1672592163085938,
      "rewards/margins": 11.150054931640625,
      "rewards/rejected": -9.982795715332031,
      "step": 3544
    },
    {
      "epoch": 1.418,
      "grad_norm": 0.7306540012359619,
      "learning_rate": 5.274666666666666e-07,
      "logits/chosen": -3.0933399200439453,
      "logits/rejected": -2.5201659202575684,
      "logps/chosen": -84.5017318725586,
      "logps/rejected": -159.2967529296875,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6421165466308594,
      "rewards/margins": 9.97031021118164,
      "rewards/rejected": -10.6124267578125,
      "step": 3545
    },
    {
      "epoch": 1.4184,
      "grad_norm": 0.1740954965353012,
      "learning_rate": 5.273333333333333e-07,
      "logits/chosen": -2.8676862716674805,
      "logits/rejected": -2.202749013900757,
      "logps/chosen": -99.30010986328125,
      "logps/rejected": -184.85781860351562,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40426579117774963,
      "rewards/margins": 11.149381637573242,
      "rewards/rejected": -10.745115280151367,
      "step": 3546
    },
    {
      "epoch": 1.4188,
      "grad_norm": 0.02541537582874298,
      "learning_rate": 5.272e-07,
      "logits/chosen": -2.647665500640869,
      "logits/rejected": -1.9683891534805298,
      "logps/chosen": -82.291015625,
      "logps/rejected": -164.37025451660156,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.26673948764801025,
      "rewards/margins": 10.090728759765625,
      "rewards/rejected": -10.357468605041504,
      "step": 3547
    },
    {
      "epoch": 1.4192,
      "grad_norm": 0.03576114773750305,
      "learning_rate": 5.270666666666667e-07,
      "logits/chosen": -2.39326810836792,
      "logits/rejected": -1.553871750831604,
      "logps/chosen": -165.2318572998047,
      "logps/rejected": -286.443603515625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.27156907320022583,
      "rewards/margins": 9.593393325805664,
      "rewards/rejected": -9.864961624145508,
      "step": 3548
    },
    {
      "epoch": 1.4196,
      "grad_norm": 3.0214269161224365,
      "learning_rate": 5.269333333333334e-07,
      "logits/chosen": -2.869203567504883,
      "logits/rejected": -2.5315470695495605,
      "logps/chosen": -120.54391479492188,
      "logps/rejected": -126.01318359375,
      "loss": 0.024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6109775900840759,
      "rewards/margins": 7.270939826965332,
      "rewards/rejected": -6.659962177276611,
      "step": 3549
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.001972012221813202,
      "learning_rate": 5.268e-07,
      "logits/chosen": -2.4403276443481445,
      "logits/rejected": -1.636038064956665,
      "logps/chosen": -101.94596099853516,
      "logps/rejected": -167.9147491455078,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.962794542312622,
      "rewards/margins": 11.99047565460205,
      "rewards/rejected": -10.027681350708008,
      "step": 3550
    },
    {
      "epoch": 1.4203999999999999,
      "grad_norm": 0.008321418426930904,
      "learning_rate": 5.266666666666666e-07,
      "logits/chosen": -2.972046136856079,
      "logits/rejected": -2.3703091144561768,
      "logps/chosen": -42.1724853515625,
      "logps/rejected": -180.0140838623047,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0611097812652588,
      "rewards/margins": 11.42943286895752,
      "rewards/rejected": -10.368322372436523,
      "step": 3551
    },
    {
      "epoch": 1.4208,
      "grad_norm": 0.0018143118359148502,
      "learning_rate": 5.265333333333333e-07,
      "logits/chosen": -2.5424020290374756,
      "logits/rejected": -1.9626165628433228,
      "logps/chosen": -115.56768798828125,
      "logps/rejected": -233.1616973876953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.403212308883667,
      "rewards/margins": 13.525629997253418,
      "rewards/rejected": -12.122417449951172,
      "step": 3552
    },
    {
      "epoch": 1.4212,
      "grad_norm": 0.4717826545238495,
      "learning_rate": 5.264e-07,
      "logits/chosen": -3.3237452507019043,
      "logits/rejected": -2.855823040008545,
      "logps/chosen": -47.86696243286133,
      "logps/rejected": -140.81646728515625,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6219990253448486,
      "rewards/margins": 9.332876205444336,
      "rewards/rejected": -8.71087646484375,
      "step": 3553
    },
    {
      "epoch": 1.4216,
      "grad_norm": 0.005856663919985294,
      "learning_rate": 5.262666666666666e-07,
      "logits/chosen": -2.872577667236328,
      "logits/rejected": -2.063891649246216,
      "logps/chosen": -83.31416320800781,
      "logps/rejected": -202.06365966796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4791831970214844,
      "rewards/margins": 11.867643356323242,
      "rewards/rejected": -10.388460159301758,
      "step": 3554
    },
    {
      "epoch": 1.422,
      "grad_norm": 0.04076141119003296,
      "learning_rate": 5.261333333333333e-07,
      "logits/chosen": -2.725802421569824,
      "logits/rejected": -2.384006977081299,
      "logps/chosen": -93.36087036132812,
      "logps/rejected": -140.88674926757812,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12692910432815552,
      "rewards/margins": 8.47424030303955,
      "rewards/rejected": -8.347311019897461,
      "step": 3555
    },
    {
      "epoch": 1.4224,
      "grad_norm": 0.11322817951440811,
      "learning_rate": 5.26e-07,
      "logits/chosen": -2.657435417175293,
      "logits/rejected": -2.4644834995269775,
      "logps/chosen": -132.239990234375,
      "logps/rejected": -233.0939178466797,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.836347222328186,
      "rewards/margins": 8.256836891174316,
      "rewards/rejected": -7.420489311218262,
      "step": 3556
    },
    {
      "epoch": 1.4228,
      "grad_norm": 0.0411069430410862,
      "learning_rate": 5.258666666666667e-07,
      "logits/chosen": -2.887411117553711,
      "logits/rejected": -2.7425050735473633,
      "logps/chosen": -83.42915344238281,
      "logps/rejected": -139.91006469726562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6064087152481079,
      "rewards/margins": 8.486968994140625,
      "rewards/rejected": -9.093378067016602,
      "step": 3557
    },
    {
      "epoch": 1.4232,
      "grad_norm": 0.005319537594914436,
      "learning_rate": 5.257333333333334e-07,
      "logits/chosen": -2.6713531017303467,
      "logits/rejected": -2.1508991718292236,
      "logps/chosen": -71.2752685546875,
      "logps/rejected": -184.93411254882812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4380565881729126,
      "rewards/margins": 11.71949577331543,
      "rewards/rejected": -10.281438827514648,
      "step": 3558
    },
    {
      "epoch": 1.4236,
      "grad_norm": 0.012512540444731712,
      "learning_rate": 5.255999999999999e-07,
      "logits/chosen": -3.0170717239379883,
      "logits/rejected": -2.3353028297424316,
      "logps/chosen": -73.08596801757812,
      "logps/rejected": -176.78189086914062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7952262759208679,
      "rewards/margins": 10.03573226928711,
      "rewards/rejected": -10.830958366394043,
      "step": 3559
    },
    {
      "epoch": 1.424,
      "grad_norm": 0.11992542445659637,
      "learning_rate": 5.254666666666666e-07,
      "logits/chosen": -2.9678592681884766,
      "logits/rejected": -2.492349147796631,
      "logps/chosen": -89.0509033203125,
      "logps/rejected": -154.46865844726562,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8024330139160156,
      "rewards/margins": 9.238409042358398,
      "rewards/rejected": -8.435975074768066,
      "step": 3560
    },
    {
      "epoch": 1.4243999999999999,
      "grad_norm": 1.6787607669830322,
      "learning_rate": 5.253333333333333e-07,
      "logits/chosen": -2.1503539085388184,
      "logits/rejected": -1.4872997999191284,
      "logps/chosen": -188.32662963867188,
      "logps/rejected": -200.5155487060547,
      "loss": 0.0097,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.4242796897888184,
      "rewards/margins": 6.348616600036621,
      "rewards/rejected": -9.772896766662598,
      "step": 3561
    },
    {
      "epoch": 1.4248,
      "grad_norm": 0.007523412350565195,
      "learning_rate": 5.252e-07,
      "logits/chosen": -2.302196979522705,
      "logits/rejected": -1.6045777797698975,
      "logps/chosen": -173.71524047851562,
      "logps/rejected": -212.1551513671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03114163875579834,
      "rewards/margins": 10.46430778503418,
      "rewards/rejected": -10.43316650390625,
      "step": 3562
    },
    {
      "epoch": 1.4252,
      "grad_norm": 1.6075973510742188,
      "learning_rate": 5.250666666666667e-07,
      "logits/chosen": -3.0958616733551025,
      "logits/rejected": -2.661426067352295,
      "logps/chosen": -47.49385452270508,
      "logps/rejected": -129.332763671875,
      "loss": 0.0089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7418907284736633,
      "rewards/margins": 5.789501667022705,
      "rewards/rejected": -5.047610759735107,
      "step": 3563
    },
    {
      "epoch": 1.4256,
      "grad_norm": 0.09940367192029953,
      "learning_rate": 5.249333333333333e-07,
      "logits/chosen": -2.797386646270752,
      "logits/rejected": -2.3736724853515625,
      "logps/chosen": -101.03285217285156,
      "logps/rejected": -172.9735107421875,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.19384843111038208,
      "rewards/margins": 10.26412582397461,
      "rewards/rejected": -10.45797348022461,
      "step": 3564
    },
    {
      "epoch": 1.426,
      "grad_norm": 0.0069050113670527935,
      "learning_rate": 5.248e-07,
      "logits/chosen": -2.6979174613952637,
      "logits/rejected": -2.052582263946533,
      "logps/chosen": -65.36981964111328,
      "logps/rejected": -162.64788818359375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9516172409057617,
      "rewards/margins": 10.604204177856445,
      "rewards/rejected": -9.652586936950684,
      "step": 3565
    },
    {
      "epoch": 1.4264000000000001,
      "grad_norm": 0.3869127631187439,
      "learning_rate": 5.246666666666666e-07,
      "logits/chosen": -2.92933988571167,
      "logits/rejected": -2.1966872215270996,
      "logps/chosen": -93.99703979492188,
      "logps/rejected": -126.77733612060547,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.635471761226654,
      "rewards/margins": 5.9729814529418945,
      "rewards/rejected": -6.608453273773193,
      "step": 3566
    },
    {
      "epoch": 1.4268,
      "grad_norm": 0.05054411292076111,
      "learning_rate": 5.245333333333333e-07,
      "logits/chosen": -3.140254497528076,
      "logits/rejected": -2.1851518154144287,
      "logps/chosen": -78.06988525390625,
      "logps/rejected": -122.39668273925781,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.09517478942871094,
      "rewards/margins": 7.912137985229492,
      "rewards/rejected": -8.007312774658203,
      "step": 3567
    },
    {
      "epoch": 1.4272,
      "grad_norm": 0.9357491135597229,
      "learning_rate": 5.243999999999999e-07,
      "logits/chosen": -2.5681028366088867,
      "logits/rejected": -2.205811023712158,
      "logps/chosen": -178.95559692382812,
      "logps/rejected": -175.60069274902344,
      "loss": 0.0063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.558998167514801,
      "rewards/margins": 6.895388603210449,
      "rewards/rejected": -7.4543867111206055,
      "step": 3568
    },
    {
      "epoch": 1.4276,
      "grad_norm": 0.2707374691963196,
      "learning_rate": 5.242666666666666e-07,
      "logits/chosen": -3.0763535499572754,
      "logits/rejected": -2.4942710399627686,
      "logps/chosen": -127.37846374511719,
      "logps/rejected": -151.82150268554688,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6735649108886719,
      "rewards/margins": 10.057783126831055,
      "rewards/rejected": -10.731348037719727,
      "step": 3569
    },
    {
      "epoch": 1.428,
      "grad_norm": 0.0041788723319768906,
      "learning_rate": 5.241333333333333e-07,
      "logits/chosen": -2.5327811241149902,
      "logits/rejected": -1.5232583284378052,
      "logps/chosen": -96.68771362304688,
      "logps/rejected": -169.755615234375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20492935180664062,
      "rewards/margins": 11.062240600585938,
      "rewards/rejected": -10.857311248779297,
      "step": 3570
    },
    {
      "epoch": 1.4284,
      "grad_norm": 0.0022020689211785793,
      "learning_rate": 5.24e-07,
      "logits/chosen": -2.9615015983581543,
      "logits/rejected": -2.5069847106933594,
      "logps/chosen": -127.22366333007812,
      "logps/rejected": -199.33212280273438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3154808282852173,
      "rewards/margins": 11.672647476196289,
      "rewards/rejected": -11.988128662109375,
      "step": 3571
    },
    {
      "epoch": 1.4288,
      "grad_norm": 0.2013954073190689,
      "learning_rate": 5.238666666666667e-07,
      "logits/chosen": -2.503061056137085,
      "logits/rejected": -2.2345285415649414,
      "logps/chosen": -178.36431884765625,
      "logps/rejected": -177.3793182373047,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.6918435096740723,
      "rewards/margins": 7.194907188415527,
      "rewards/rejected": -9.886751174926758,
      "step": 3572
    },
    {
      "epoch": 1.4292,
      "grad_norm": 0.10124427080154419,
      "learning_rate": 5.237333333333334e-07,
      "logits/chosen": -3.136796474456787,
      "logits/rejected": -2.359326124191284,
      "logps/chosen": -63.349761962890625,
      "logps/rejected": -161.66659545898438,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4014436602592468,
      "rewards/margins": 10.37791919708252,
      "rewards/rejected": -9.976475715637207,
      "step": 3573
    },
    {
      "epoch": 1.4296,
      "grad_norm": 59.23542785644531,
      "learning_rate": 5.236e-07,
      "logits/chosen": -2.780076265335083,
      "logits/rejected": -2.956721305847168,
      "logps/chosen": -122.40660858154297,
      "logps/rejected": -128.40576171875,
      "loss": 0.3662,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.20687329769134521,
      "rewards/margins": 6.391664505004883,
      "rewards/rejected": -6.598537445068359,
      "step": 3574
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.10570688545703888,
      "learning_rate": 5.234666666666666e-07,
      "logits/chosen": -3.159769296646118,
      "logits/rejected": -2.483196258544922,
      "logps/chosen": -48.84763717651367,
      "logps/rejected": -121.79847717285156,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8761550784111023,
      "rewards/margins": 8.262874603271484,
      "rewards/rejected": -7.386719703674316,
      "step": 3575
    },
    {
      "epoch": 1.4304000000000001,
      "grad_norm": 0.004128691274672747,
      "learning_rate": 5.233333333333333e-07,
      "logits/chosen": -2.8574137687683105,
      "logits/rejected": -2.407102108001709,
      "logps/chosen": -64.84962463378906,
      "logps/rejected": -163.4639434814453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4690265655517578,
      "rewards/margins": 10.716334342956543,
      "rewards/rejected": -10.247307777404785,
      "step": 3576
    },
    {
      "epoch": 1.4308,
      "grad_norm": 0.6261634230613708,
      "learning_rate": 5.232e-07,
      "logits/chosen": -3.0269131660461426,
      "logits/rejected": -2.61336088180542,
      "logps/chosen": -77.19795227050781,
      "logps/rejected": -125.69598388671875,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1997289657592773,
      "rewards/margins": 7.2914228439331055,
      "rewards/rejected": -8.491151809692383,
      "step": 3577
    },
    {
      "epoch": 1.4312,
      "grad_norm": 3.3454668521881104,
      "learning_rate": 5.230666666666666e-07,
      "logits/chosen": -2.683540105819702,
      "logits/rejected": -2.0775184631347656,
      "logps/chosen": -129.864013671875,
      "logps/rejected": -130.158935546875,
      "loss": 0.0136,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4090304970741272,
      "rewards/margins": 6.330209255218506,
      "rewards/rejected": -6.739239692687988,
      "step": 3578
    },
    {
      "epoch": 1.4316,
      "grad_norm": 0.10209138691425323,
      "learning_rate": 5.229333333333333e-07,
      "logits/chosen": -2.788621425628662,
      "logits/rejected": -2.433086395263672,
      "logps/chosen": -121.6578369140625,
      "logps/rejected": -143.0436553955078,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8506526947021484,
      "rewards/margins": 7.797799110412598,
      "rewards/rejected": -8.648452758789062,
      "step": 3579
    },
    {
      "epoch": 1.432,
      "grad_norm": 2.010042190551758,
      "learning_rate": 5.228e-07,
      "logits/chosen": -2.222935676574707,
      "logits/rejected": -1.4962157011032104,
      "logps/chosen": -235.10140991210938,
      "logps/rejected": -210.61683654785156,
      "loss": 0.0057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -5.68629789352417,
      "rewards/margins": 7.516843318939209,
      "rewards/rejected": -13.203141212463379,
      "step": 3580
    },
    {
      "epoch": 1.4324,
      "grad_norm": 0.11040690541267395,
      "learning_rate": 5.226666666666666e-07,
      "logits/chosen": -2.9504826068878174,
      "logits/rejected": -2.535586357116699,
      "logps/chosen": -74.77197265625,
      "logps/rejected": -176.40408325195312,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.023079290986061096,
      "rewards/margins": 10.074188232421875,
      "rewards/rejected": -10.051108360290527,
      "step": 3581
    },
    {
      "epoch": 1.4328,
      "grad_norm": 0.09187939018011093,
      "learning_rate": 5.225333333333333e-07,
      "logits/chosen": -2.96193265914917,
      "logits/rejected": -2.3037261962890625,
      "logps/chosen": -89.10037994384766,
      "logps/rejected": -116.13043212890625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8060567378997803,
      "rewards/margins": 8.073209762573242,
      "rewards/rejected": -6.267153739929199,
      "step": 3582
    },
    {
      "epoch": 1.4332,
      "grad_norm": 0.028568049892783165,
      "learning_rate": 5.224e-07,
      "logits/chosen": -2.779872417449951,
      "logits/rejected": -2.1589105129241943,
      "logps/chosen": -110.73680114746094,
      "logps/rejected": -151.16268920898438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8414134979248047,
      "rewards/margins": 9.589118957519531,
      "rewards/rejected": -8.747705459594727,
      "step": 3583
    },
    {
      "epoch": 1.4336,
      "grad_norm": 0.10258001834154129,
      "learning_rate": 5.222666666666667e-07,
      "logits/chosen": -2.7633514404296875,
      "logits/rejected": -2.358201742172241,
      "logps/chosen": -170.8218994140625,
      "logps/rejected": -158.77923583984375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.610552191734314,
      "rewards/margins": 9.932779312133789,
      "rewards/rejected": -10.543331146240234,
      "step": 3584
    },
    {
      "epoch": 1.434,
      "grad_norm": 0.03279661759734154,
      "learning_rate": 5.221333333333334e-07,
      "logits/chosen": -2.534465789794922,
      "logits/rejected": -1.8621129989624023,
      "logps/chosen": -168.44674682617188,
      "logps/rejected": -276.44512939453125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0615040063858032,
      "rewards/margins": 11.622236251831055,
      "rewards/rejected": -12.683740615844727,
      "step": 3585
    },
    {
      "epoch": 1.4344000000000001,
      "grad_norm": 0.12520372867584229,
      "learning_rate": 5.22e-07,
      "logits/chosen": -2.613311767578125,
      "logits/rejected": -2.208162307739258,
      "logps/chosen": -151.911865234375,
      "logps/rejected": -163.06297302246094,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7309315204620361,
      "rewards/margins": 8.167365074157715,
      "rewards/rejected": -9.898296356201172,
      "step": 3586
    },
    {
      "epoch": 1.4348,
      "grad_norm": 0.02047019451856613,
      "learning_rate": 5.218666666666666e-07,
      "logits/chosen": -2.499690055847168,
      "logits/rejected": -1.5870462656021118,
      "logps/chosen": -96.54602813720703,
      "logps/rejected": -206.6388702392578,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5294383764266968,
      "rewards/margins": 10.833792686462402,
      "rewards/rejected": -9.304353713989258,
      "step": 3587
    },
    {
      "epoch": 1.4352,
      "grad_norm": 0.0036585882771760225,
      "learning_rate": 5.217333333333333e-07,
      "logits/chosen": -2.465975284576416,
      "logits/rejected": -1.4896440505981445,
      "logps/chosen": -206.42697143554688,
      "logps/rejected": -214.09803771972656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8579643368721008,
      "rewards/margins": 11.79476261138916,
      "rewards/rejected": -10.936798095703125,
      "step": 3588
    },
    {
      "epoch": 1.4356,
      "grad_norm": 0.7642541527748108,
      "learning_rate": 5.215999999999999e-07,
      "logits/chosen": -2.6363677978515625,
      "logits/rejected": -2.1547670364379883,
      "logps/chosen": -105.91680908203125,
      "logps/rejected": -137.5928955078125,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.04953122138977051,
      "rewards/margins": 7.126591682434082,
      "rewards/rejected": -7.176122665405273,
      "step": 3589
    },
    {
      "epoch": 1.436,
      "grad_norm": 0.13899509608745575,
      "learning_rate": 5.214666666666666e-07,
      "logits/chosen": -2.5921006202697754,
      "logits/rejected": -1.9726206064224243,
      "logps/chosen": -113.3092041015625,
      "logps/rejected": -113.26278686523438,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7492069005966187,
      "rewards/margins": 7.797332763671875,
      "rewards/rejected": -7.048125743865967,
      "step": 3590
    },
    {
      "epoch": 1.4364,
      "grad_norm": 0.07976271957159042,
      "learning_rate": 5.213333333333333e-07,
      "logits/chosen": -2.4291107654571533,
      "logits/rejected": -1.7037692070007324,
      "logps/chosen": -215.26910400390625,
      "logps/rejected": -276.5832824707031,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6875001192092896,
      "rewards/margins": 8.06917953491211,
      "rewards/rejected": -9.75667953491211,
      "step": 3591
    },
    {
      "epoch": 1.4368,
      "grad_norm": 0.02872106060385704,
      "learning_rate": 5.212e-07,
      "logits/chosen": -2.702671527862549,
      "logits/rejected": -2.571275234222412,
      "logps/chosen": -81.21063232421875,
      "logps/rejected": -227.68727111816406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7321608066558838,
      "rewards/margins": 12.300167083740234,
      "rewards/rejected": -11.56800651550293,
      "step": 3592
    },
    {
      "epoch": 1.4372,
      "grad_norm": 0.008625532500445843,
      "learning_rate": 5.210666666666667e-07,
      "logits/chosen": -2.6949567794799805,
      "logits/rejected": -1.7181360721588135,
      "logps/chosen": -106.69178009033203,
      "logps/rejected": -196.4757843017578,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.040454864501953125,
      "rewards/margins": 12.14776611328125,
      "rewards/rejected": -12.188220977783203,
      "step": 3593
    },
    {
      "epoch": 1.4376,
      "grad_norm": 0.059326477348804474,
      "learning_rate": 5.209333333333334e-07,
      "logits/chosen": -2.793583393096924,
      "logits/rejected": -2.604365110397339,
      "logps/chosen": -96.41905975341797,
      "logps/rejected": -173.50082397460938,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6180866360664368,
      "rewards/margins": 9.310802459716797,
      "rewards/rejected": -9.928890228271484,
      "step": 3594
    },
    {
      "epoch": 1.438,
      "grad_norm": 1.4203450679779053,
      "learning_rate": 5.208000000000001e-07,
      "logits/chosen": -2.837888717651367,
      "logits/rejected": -2.664825439453125,
      "logps/chosen": -92.13984680175781,
      "logps/rejected": -96.76447296142578,
      "loss": 0.0088,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.055263131856918335,
      "rewards/margins": 5.444080352783203,
      "rewards/rejected": -5.388817310333252,
      "step": 3595
    },
    {
      "epoch": 1.4384000000000001,
      "grad_norm": 0.1204972192645073,
      "learning_rate": 5.206666666666667e-07,
      "logits/chosen": -2.5878612995147705,
      "logits/rejected": -2.2894864082336426,
      "logps/chosen": -128.00563049316406,
      "logps/rejected": -120.42478942871094,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1562283039093018,
      "rewards/margins": 8.193833351135254,
      "rewards/rejected": -7.037605285644531,
      "step": 3596
    },
    {
      "epoch": 1.4388,
      "grad_norm": 0.9032660126686096,
      "learning_rate": 5.205333333333332e-07,
      "logits/chosen": -2.7109899520874023,
      "logits/rejected": -2.200578212738037,
      "logps/chosen": -161.90582275390625,
      "logps/rejected": -152.2775421142578,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5709998607635498,
      "rewards/margins": 7.687638282775879,
      "rewards/rejected": -8.258638381958008,
      "step": 3597
    },
    {
      "epoch": 1.4392,
      "grad_norm": 0.14267286658287048,
      "learning_rate": 5.203999999999999e-07,
      "logits/chosen": -3.101635456085205,
      "logits/rejected": -2.7537827491760254,
      "logps/chosen": -98.08538818359375,
      "logps/rejected": -113.98089599609375,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.040838658809661865,
      "rewards/margins": 7.472476005554199,
      "rewards/rejected": -7.513314247131348,
      "step": 3598
    },
    {
      "epoch": 1.4396,
      "grad_norm": 3.452387571334839,
      "learning_rate": 5.202666666666666e-07,
      "logits/chosen": -2.7089505195617676,
      "logits/rejected": -2.4707398414611816,
      "logps/chosen": -99.84469604492188,
      "logps/rejected": -135.56488037109375,
      "loss": 0.0341,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.222533106803894,
      "rewards/margins": 7.200460910797119,
      "rewards/rejected": -8.422993659973145,
      "step": 3599
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.06638792157173157,
      "learning_rate": 5.201333333333333e-07,
      "logits/chosen": -2.563828468322754,
      "logits/rejected": -2.3067150115966797,
      "logps/chosen": -129.10536193847656,
      "logps/rejected": -136.7762908935547,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.17662698030471802,
      "rewards/margins": 7.956438064575195,
      "rewards/rejected": -8.133065223693848,
      "step": 3600
    },
    {
      "epoch": 1.4404,
      "grad_norm": 0.613817036151886,
      "learning_rate": 5.2e-07,
      "logits/chosen": -2.925123691558838,
      "logits/rejected": -2.6566519737243652,
      "logps/chosen": -83.90397644042969,
      "logps/rejected": -130.6993865966797,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7515491843223572,
      "rewards/margins": 7.692500591278076,
      "rewards/rejected": -8.444049835205078,
      "step": 3601
    },
    {
      "epoch": 1.4408,
      "grad_norm": 0.5183314681053162,
      "learning_rate": 5.198666666666667e-07,
      "logits/chosen": -2.7984395027160645,
      "logits/rejected": -2.060467481613159,
      "logps/chosen": -79.7713623046875,
      "logps/rejected": -151.9095458984375,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7922913432121277,
      "rewards/margins": 10.004734992980957,
      "rewards/rejected": -9.212443351745605,
      "step": 3602
    },
    {
      "epoch": 1.4412,
      "grad_norm": 0.0005020427634008229,
      "learning_rate": 5.197333333333334e-07,
      "logits/chosen": -2.725226640701294,
      "logits/rejected": -2.1846165657043457,
      "logps/chosen": -104.18244934082031,
      "logps/rejected": -183.3651123046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0958889722824097,
      "rewards/margins": 13.079573631286621,
      "rewards/rejected": -11.983684539794922,
      "step": 3603
    },
    {
      "epoch": 1.4416,
      "grad_norm": 5.097431182861328,
      "learning_rate": 5.196e-07,
      "logits/chosen": -2.654663562774658,
      "logits/rejected": -2.2415082454681396,
      "logps/chosen": -129.71966552734375,
      "logps/rejected": -161.4505157470703,
      "loss": 0.0303,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2425755262374878,
      "rewards/margins": 8.151126861572266,
      "rewards/rejected": -9.393702507019043,
      "step": 3604
    },
    {
      "epoch": 1.442,
      "grad_norm": 0.08475594967603683,
      "learning_rate": 5.194666666666667e-07,
      "logits/chosen": -2.8560032844543457,
      "logits/rejected": -2.4455018043518066,
      "logps/chosen": -57.441917419433594,
      "logps/rejected": -183.81063842773438,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3628708124160767,
      "rewards/margins": 11.299357414245605,
      "rewards/rejected": -9.93648624420166,
      "step": 3605
    },
    {
      "epoch": 1.4424000000000001,
      "grad_norm": 0.15198703110218048,
      "learning_rate": 5.193333333333332e-07,
      "logits/chosen": -2.667999744415283,
      "logits/rejected": -2.0410170555114746,
      "logps/chosen": -87.62162780761719,
      "logps/rejected": -128.40908813476562,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1978302001953125,
      "rewards/margins": 7.901947975158691,
      "rewards/rejected": -8.099778175354004,
      "step": 3606
    },
    {
      "epoch": 1.4428,
      "grad_norm": 0.00019758401322178543,
      "learning_rate": 5.191999999999999e-07,
      "logits/chosen": -2.4920668601989746,
      "logits/rejected": -1.5796862840652466,
      "logps/chosen": -157.55731201171875,
      "logps/rejected": -205.93771362304688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7187469005584717,
      "rewards/margins": 15.051024436950684,
      "rewards/rejected": -13.332277297973633,
      "step": 3607
    },
    {
      "epoch": 1.4432,
      "grad_norm": 0.004578450229018927,
      "learning_rate": 5.190666666666666e-07,
      "logits/chosen": -2.832714080810547,
      "logits/rejected": -1.9718303680419922,
      "logps/chosen": -148.69277954101562,
      "logps/rejected": -169.43109130859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.45077818632125854,
      "rewards/margins": 10.588428497314453,
      "rewards/rejected": -11.039207458496094,
      "step": 3608
    },
    {
      "epoch": 1.4436,
      "grad_norm": 1.0326370000839233,
      "learning_rate": 5.189333333333333e-07,
      "logits/chosen": -2.5050582885742188,
      "logits/rejected": -2.3696858882904053,
      "logps/chosen": -118.84276580810547,
      "logps/rejected": -114.48725891113281,
      "loss": 0.0078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6259689331054688,
      "rewards/margins": 6.7876739501953125,
      "rewards/rejected": -7.4136433601379395,
      "step": 3609
    },
    {
      "epoch": 1.444,
      "grad_norm": 0.4870629906654358,
      "learning_rate": 5.188e-07,
      "logits/chosen": -3.057206392288208,
      "logits/rejected": -2.3582651615142822,
      "logps/chosen": -93.21659851074219,
      "logps/rejected": -139.7356414794922,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16608011722564697,
      "rewards/margins": 8.134178161621094,
      "rewards/rejected": -7.9680986404418945,
      "step": 3610
    },
    {
      "epoch": 1.4444,
      "grad_norm": 0.00519034406170249,
      "learning_rate": 5.186666666666667e-07,
      "logits/chosen": -2.5201709270477295,
      "logits/rejected": -1.8042558431625366,
      "logps/chosen": -128.651611328125,
      "logps/rejected": -197.70947265625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5557159185409546,
      "rewards/margins": 12.306520462036133,
      "rewards/rejected": -11.75080394744873,
      "step": 3611
    },
    {
      "epoch": 1.4447999999999999,
      "grad_norm": 2.8833227157592773,
      "learning_rate": 5.185333333333333e-07,
      "logits/chosen": -3.1022818088531494,
      "logits/rejected": -2.440650701522827,
      "logps/chosen": -84.92726135253906,
      "logps/rejected": -209.7244415283203,
      "loss": 0.0205,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4137295484542847,
      "rewards/margins": 10.994681358337402,
      "rewards/rejected": -12.408411026000977,
      "step": 3612
    },
    {
      "epoch": 1.4452,
      "grad_norm": 0.0034296419471502304,
      "learning_rate": 5.184e-07,
      "logits/chosen": -3.1879944801330566,
      "logits/rejected": -2.555182456970215,
      "logps/chosen": -51.698326110839844,
      "logps/rejected": -203.9000244140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.23030872642993927,
      "rewards/margins": 13.80958366394043,
      "rewards/rejected": -14.039892196655273,
      "step": 3613
    },
    {
      "epoch": 1.4456,
      "grad_norm": 0.06848479062318802,
      "learning_rate": 5.182666666666667e-07,
      "logits/chosen": -2.533414363861084,
      "logits/rejected": -2.0771360397338867,
      "logps/chosen": -80.95712280273438,
      "logps/rejected": -179.04232788085938,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2045516967773438,
      "rewards/margins": 11.76298713684082,
      "rewards/rejected": -10.558435440063477,
      "step": 3614
    },
    {
      "epoch": 1.446,
      "grad_norm": 0.6349259614944458,
      "learning_rate": 5.181333333333333e-07,
      "logits/chosen": -3.148636817932129,
      "logits/rejected": -2.4777650833129883,
      "logps/chosen": -76.21855926513672,
      "logps/rejected": -124.26278686523438,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9927928447723389,
      "rewards/margins": 7.234308242797852,
      "rewards/rejected": -8.22710132598877,
      "step": 3615
    },
    {
      "epoch": 1.4464000000000001,
      "grad_norm": 0.25642210245132446,
      "learning_rate": 5.18e-07,
      "logits/chosen": -3.080385684967041,
      "logits/rejected": -2.7427597045898438,
      "logps/chosen": -99.36006927490234,
      "logps/rejected": -117.06277465820312,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7272084951400757,
      "rewards/margins": 7.778491973876953,
      "rewards/rejected": -7.05128288269043,
      "step": 3616
    },
    {
      "epoch": 1.4468,
      "grad_norm": 0.009874003008008003,
      "learning_rate": 5.178666666666666e-07,
      "logits/chosen": -2.7753171920776367,
      "logits/rejected": -2.2812254428863525,
      "logps/chosen": -93.70643615722656,
      "logps/rejected": -162.59732055664062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.595244288444519,
      "rewards/margins": 11.551021575927734,
      "rewards/rejected": -9.955777168273926,
      "step": 3617
    },
    {
      "epoch": 1.4472,
      "grad_norm": 0.0009445917094126344,
      "learning_rate": 5.177333333333333e-07,
      "logits/chosen": -2.7298011779785156,
      "logits/rejected": -2.0245814323425293,
      "logps/chosen": -88.06764221191406,
      "logps/rejected": -278.49334716796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0246238708496094,
      "rewards/margins": 13.740192413330078,
      "rewards/rejected": -12.715568542480469,
      "step": 3618
    },
    {
      "epoch": 1.4476,
      "grad_norm": 0.020436102524399757,
      "learning_rate": 5.175999999999999e-07,
      "logits/chosen": -2.950469970703125,
      "logits/rejected": -2.384793758392334,
      "logps/chosen": -80.5964126586914,
      "logps/rejected": -152.7788543701172,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10725539922714233,
      "rewards/margins": 9.082433700561523,
      "rewards/rejected": -9.189688682556152,
      "step": 3619
    },
    {
      "epoch": 1.448,
      "grad_norm": 0.5020135641098022,
      "learning_rate": 5.174666666666666e-07,
      "logits/chosen": -2.5692806243896484,
      "logits/rejected": -2.391845703125,
      "logps/chosen": -132.219970703125,
      "logps/rejected": -145.6092987060547,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.34186017513275146,
      "rewards/margins": 8.20743465423584,
      "rewards/rejected": -8.549295425415039,
      "step": 3620
    },
    {
      "epoch": 1.4484,
      "grad_norm": 0.08217743784189224,
      "learning_rate": 5.173333333333333e-07,
      "logits/chosen": -2.6887075901031494,
      "logits/rejected": -2.1040220260620117,
      "logps/chosen": -135.12008666992188,
      "logps/rejected": -148.922119140625,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.200387954711914,
      "rewards/margins": 7.325313568115234,
      "rewards/rejected": -8.525701522827148,
      "step": 3621
    },
    {
      "epoch": 1.4487999999999999,
      "grad_norm": 0.036272551864385605,
      "learning_rate": 5.172e-07,
      "logits/chosen": -3.1211204528808594,
      "logits/rejected": -2.7639942169189453,
      "logps/chosen": -59.878570556640625,
      "logps/rejected": -124.10668182373047,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9854087829589844,
      "rewards/margins": 8.561288833618164,
      "rewards/rejected": -7.5758795738220215,
      "step": 3622
    },
    {
      "epoch": 1.4492,
      "grad_norm": 7.367965221405029,
      "learning_rate": 5.170666666666667e-07,
      "logits/chosen": -2.619373321533203,
      "logits/rejected": -1.774751901626587,
      "logps/chosen": -144.64639282226562,
      "logps/rejected": -199.37750244140625,
      "loss": 0.0273,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.0390830039978027,
      "rewards/margins": 6.497945785522461,
      "rewards/rejected": -9.537029266357422,
      "step": 3623
    },
    {
      "epoch": 1.4496,
      "grad_norm": 0.03855746611952782,
      "learning_rate": 5.169333333333334e-07,
      "logits/chosen": -3.0034632682800293,
      "logits/rejected": -2.554079055786133,
      "logps/chosen": -84.73174285888672,
      "logps/rejected": -147.555419921875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7222194671630859,
      "rewards/margins": 9.714409828186035,
      "rewards/rejected": -8.99219036102295,
      "step": 3624
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.09334912151098251,
      "learning_rate": 5.168e-07,
      "logits/chosen": -3.041504383087158,
      "logits/rejected": -2.8096065521240234,
      "logps/chosen": -90.09285736083984,
      "logps/rejected": -128.7445831298828,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6932674646377563,
      "rewards/margins": 7.8971052169799805,
      "rewards/rejected": -8.590373039245605,
      "step": 3625
    },
    {
      "epoch": 1.4504000000000001,
      "grad_norm": 0.11161218583583832,
      "learning_rate": 5.166666666666667e-07,
      "logits/chosen": -3.1327614784240723,
      "logits/rejected": -2.6494710445404053,
      "logps/chosen": -83.50025177001953,
      "logps/rejected": -178.23593139648438,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5019149780273438,
      "rewards/margins": 11.272467613220215,
      "rewards/rejected": -10.770551681518555,
      "step": 3626
    },
    {
      "epoch": 1.4508,
      "grad_norm": 0.30878183245658875,
      "learning_rate": 5.165333333333332e-07,
      "logits/chosen": -2.954930305480957,
      "logits/rejected": -2.239049196243286,
      "logps/chosen": -65.72999572753906,
      "logps/rejected": -126.91453552246094,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7321586608886719,
      "rewards/margins": 6.8711700439453125,
      "rewards/rejected": -7.603328704833984,
      "step": 3627
    },
    {
      "epoch": 1.4512,
      "grad_norm": 0.7272739410400391,
      "learning_rate": 5.163999999999999e-07,
      "logits/chosen": -3.1133127212524414,
      "logits/rejected": -2.5613999366760254,
      "logps/chosen": -106.65142059326172,
      "logps/rejected": -144.64678955078125,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06658649444580078,
      "rewards/margins": 8.838357925415039,
      "rewards/rejected": -8.771771430969238,
      "step": 3628
    },
    {
      "epoch": 1.4516,
      "grad_norm": 4.537112236022949,
      "learning_rate": 5.162666666666666e-07,
      "logits/chosen": -2.4981422424316406,
      "logits/rejected": -1.73046875,
      "logps/chosen": -147.384033203125,
      "logps/rejected": -142.95742797851562,
      "loss": 0.0177,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7516343593597412,
      "rewards/margins": 7.541604042053223,
      "rewards/rejected": -9.293238639831543,
      "step": 3629
    },
    {
      "epoch": 1.452,
      "grad_norm": 0.0386849120259285,
      "learning_rate": 5.161333333333333e-07,
      "logits/chosen": -3.092416763305664,
      "logits/rejected": -2.6378326416015625,
      "logps/chosen": -53.29521560668945,
      "logps/rejected": -106.20643615722656,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6379815340042114,
      "rewards/margins": 8.554448127746582,
      "rewards/rejected": -6.91646671295166,
      "step": 3630
    },
    {
      "epoch": 1.4524,
      "grad_norm": 0.04104810208082199,
      "learning_rate": 5.16e-07,
      "logits/chosen": -2.8432254791259766,
      "logits/rejected": -2.135176181793213,
      "logps/chosen": -79.6834716796875,
      "logps/rejected": -176.99234008789062,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9162894487380981,
      "rewards/margins": 11.616547584533691,
      "rewards/rejected": -10.700258255004883,
      "step": 3631
    },
    {
      "epoch": 1.4527999999999999,
      "grad_norm": 0.0017027377616614103,
      "learning_rate": 5.158666666666667e-07,
      "logits/chosen": -3.0833165645599365,
      "logits/rejected": -2.3915929794311523,
      "logps/chosen": -44.98918914794922,
      "logps/rejected": -189.42501831054688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1197967529296875,
      "rewards/margins": 13.113859176635742,
      "rewards/rejected": -11.994062423706055,
      "step": 3632
    },
    {
      "epoch": 1.4532,
      "grad_norm": 0.0008364508976228535,
      "learning_rate": 5.157333333333334e-07,
      "logits/chosen": -2.5703039169311523,
      "logits/rejected": -2.067704200744629,
      "logps/chosen": -133.07687377929688,
      "logps/rejected": -223.2491455078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.44310760498046875,
      "rewards/margins": 13.727296829223633,
      "rewards/rejected": -13.284189224243164,
      "step": 3633
    },
    {
      "epoch": 1.4536,
      "grad_norm": 0.4466581642627716,
      "learning_rate": 5.155999999999999e-07,
      "logits/chosen": -2.8904788494110107,
      "logits/rejected": -2.4437203407287598,
      "logps/chosen": -65.11714935302734,
      "logps/rejected": -144.3251953125,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6246452331542969,
      "rewards/margins": 8.1030912399292,
      "rewards/rejected": -7.478446006774902,
      "step": 3634
    },
    {
      "epoch": 1.454,
      "grad_norm": 0.0031849341467022896,
      "learning_rate": 5.154666666666666e-07,
      "logits/chosen": -2.72855806350708,
      "logits/rejected": -2.062075614929199,
      "logps/chosen": -74.31309509277344,
      "logps/rejected": -208.10525512695312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5645692348480225,
      "rewards/margins": 13.854021072387695,
      "rewards/rejected": -12.289451599121094,
      "step": 3635
    },
    {
      "epoch": 1.4544000000000001,
      "grad_norm": 1.8223254680633545,
      "learning_rate": 5.153333333333333e-07,
      "logits/chosen": -2.6971113681793213,
      "logits/rejected": -2.5395383834838867,
      "logps/chosen": -93.48348236083984,
      "logps/rejected": -110.44401550292969,
      "loss": 0.0112,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8509823083877563,
      "rewards/margins": 6.567436218261719,
      "rewards/rejected": -4.716454029083252,
      "step": 3636
    },
    {
      "epoch": 1.4548,
      "grad_norm": 0.1261083483695984,
      "learning_rate": 5.152e-07,
      "logits/chosen": -2.7936935424804688,
      "logits/rejected": -2.291088104248047,
      "logps/chosen": -84.20927429199219,
      "logps/rejected": -124.52967834472656,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8879993557929993,
      "rewards/margins": 8.987227439880371,
      "rewards/rejected": -8.099227905273438,
      "step": 3637
    },
    {
      "epoch": 1.4552,
      "grad_norm": 0.20485372841358185,
      "learning_rate": 5.150666666666666e-07,
      "logits/chosen": -3.179220676422119,
      "logits/rejected": -2.4061949253082275,
      "logps/chosen": -71.21002197265625,
      "logps/rejected": -137.39968872070312,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08283920586109161,
      "rewards/margins": 8.664304733276367,
      "rewards/rejected": -8.747143745422363,
      "step": 3638
    },
    {
      "epoch": 1.4556,
      "grad_norm": 0.11905493587255478,
      "learning_rate": 5.149333333333333e-07,
      "logits/chosen": -3.1637539863586426,
      "logits/rejected": -2.729011297225952,
      "logps/chosen": -38.054962158203125,
      "logps/rejected": -120.94427490234375,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.15214672684669495,
      "rewards/margins": 7.260485649108887,
      "rewards/rejected": -7.412631988525391,
      "step": 3639
    },
    {
      "epoch": 1.456,
      "grad_norm": 0.044871240854263306,
      "learning_rate": 5.148e-07,
      "logits/chosen": -2.893562078475952,
      "logits/rejected": -2.469744920730591,
      "logps/chosen": -85.417236328125,
      "logps/rejected": -147.55722045898438,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3353509902954102,
      "rewards/margins": 8.67892837524414,
      "rewards/rejected": -7.343576908111572,
      "step": 3640
    },
    {
      "epoch": 1.4564,
      "grad_norm": 0.4060134291648865,
      "learning_rate": 5.146666666666667e-07,
      "logits/chosen": -2.683211326599121,
      "logits/rejected": -2.3506035804748535,
      "logps/chosen": -74.75848388671875,
      "logps/rejected": -168.00640869140625,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3343628644943237,
      "rewards/margins": 9.367416381835938,
      "rewards/rejected": -8.033053398132324,
      "step": 3641
    },
    {
      "epoch": 1.4567999999999999,
      "grad_norm": 0.3262138068675995,
      "learning_rate": 5.145333333333333e-07,
      "logits/chosen": -2.4812963008880615,
      "logits/rejected": -1.8359758853912354,
      "logps/chosen": -180.39947509765625,
      "logps/rejected": -145.20382690429688,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9834275245666504,
      "rewards/margins": 8.829658508300781,
      "rewards/rejected": -9.813085556030273,
      "step": 3642
    },
    {
      "epoch": 1.4572,
      "grad_norm": 0.17657533288002014,
      "learning_rate": 5.143999999999999e-07,
      "logits/chosen": -2.8252556324005127,
      "logits/rejected": -2.21358060836792,
      "logps/chosen": -91.54185485839844,
      "logps/rejected": -128.72862243652344,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8707122802734375,
      "rewards/margins": 8.128150939941406,
      "rewards/rejected": -7.257438659667969,
      "step": 3643
    },
    {
      "epoch": 1.4576,
      "grad_norm": 0.051814429461956024,
      "learning_rate": 5.142666666666666e-07,
      "logits/chosen": -2.9375386238098145,
      "logits/rejected": -2.327310085296631,
      "logps/chosen": -88.29741668701172,
      "logps/rejected": -171.83843994140625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17589706182479858,
      "rewards/margins": 10.730677604675293,
      "rewards/rejected": -10.554780960083008,
      "step": 3644
    },
    {
      "epoch": 1.458,
      "grad_norm": 0.01846955344080925,
      "learning_rate": 5.141333333333333e-07,
      "logits/chosen": -2.884377956390381,
      "logits/rejected": -2.4499430656433105,
      "logps/chosen": -111.98806762695312,
      "logps/rejected": -184.01885986328125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7283527851104736,
      "rewards/margins": 12.84246826171875,
      "rewards/rejected": -12.114114761352539,
      "step": 3645
    },
    {
      "epoch": 1.4584,
      "grad_norm": 0.006329638883471489,
      "learning_rate": 5.14e-07,
      "logits/chosen": -2.5807511806488037,
      "logits/rejected": -2.406937837600708,
      "logps/chosen": -113.29315185546875,
      "logps/rejected": -166.14117431640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.19476884603500366,
      "rewards/margins": 10.873689651489258,
      "rewards/rejected": -11.068458557128906,
      "step": 3646
    },
    {
      "epoch": 1.4588,
      "grad_norm": 0.5280037522315979,
      "learning_rate": 5.138666666666667e-07,
      "logits/chosen": -2.5566494464874268,
      "logits/rejected": -2.562896728515625,
      "logps/chosen": -136.32481384277344,
      "logps/rejected": -145.25428771972656,
      "loss": 0.0055,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.404270648956299,
      "rewards/margins": 5.932489395141602,
      "rewards/rejected": -8.336760520935059,
      "step": 3647
    },
    {
      "epoch": 1.4592,
      "grad_norm": 0.0008493884815834463,
      "learning_rate": 5.137333333333334e-07,
      "logits/chosen": -2.873460292816162,
      "logits/rejected": -1.9582421779632568,
      "logps/chosen": -93.47944641113281,
      "logps/rejected": -194.55203247070312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7927867770195007,
      "rewards/margins": 13.621943473815918,
      "rewards/rejected": -12.829156875610352,
      "step": 3648
    },
    {
      "epoch": 1.4596,
      "grad_norm": 0.030781570822000504,
      "learning_rate": 5.135999999999999e-07,
      "logits/chosen": -2.6469132900238037,
      "logits/rejected": -2.2612829208374023,
      "logps/chosen": -115.96247100830078,
      "logps/rejected": -156.8332061767578,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.43074876070022583,
      "rewards/margins": 8.891902923583984,
      "rewards/rejected": -8.461153984069824,
      "step": 3649
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.001810286077670753,
      "learning_rate": 5.134666666666666e-07,
      "logits/chosen": -2.9573049545288086,
      "logits/rejected": -2.1031808853149414,
      "logps/chosen": -78.05929565429688,
      "logps/rejected": -188.1078643798828,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3221269845962524,
      "rewards/margins": 12.261516571044922,
      "rewards/rejected": -10.939390182495117,
      "step": 3650
    },
    {
      "epoch": 1.4604,
      "grad_norm": 14.094588279724121,
      "learning_rate": 5.133333333333333e-07,
      "logits/chosen": -3.1208009719848633,
      "logits/rejected": -2.844494342803955,
      "logps/chosen": -49.610328674316406,
      "logps/rejected": -94.57719421386719,
      "loss": 0.0981,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7614502310752869,
      "rewards/margins": 6.19312858581543,
      "rewards/rejected": -5.431678295135498,
      "step": 3651
    },
    {
      "epoch": 1.4607999999999999,
      "grad_norm": 0.06824282556772232,
      "learning_rate": 5.132e-07,
      "logits/chosen": -2.730502128601074,
      "logits/rejected": -2.5609889030456543,
      "logps/chosen": -106.53888702392578,
      "logps/rejected": -150.04415893554688,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9300212860107422,
      "rewards/margins": 8.078149795532227,
      "rewards/rejected": -10.008171081542969,
      "step": 3652
    },
    {
      "epoch": 1.4612,
      "grad_norm": 0.10892188549041748,
      "learning_rate": 5.130666666666666e-07,
      "logits/chosen": -2.611847162246704,
      "logits/rejected": -2.1638827323913574,
      "logps/chosen": -122.36051940917969,
      "logps/rejected": -207.50856018066406,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.12497198581695557,
      "rewards/margins": 8.52322006225586,
      "rewards/rejected": -8.648192405700684,
      "step": 3653
    },
    {
      "epoch": 1.4616,
      "grad_norm": 0.2022639513015747,
      "learning_rate": 5.129333333333333e-07,
      "logits/chosen": -3.082653760910034,
      "logits/rejected": -3.0970537662506104,
      "logps/chosen": -78.16165161132812,
      "logps/rejected": -90.1658706665039,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0211944580078125,
      "rewards/margins": 6.631896018981934,
      "rewards/rejected": -5.610701560974121,
      "step": 3654
    },
    {
      "epoch": 1.462,
      "grad_norm": 0.046000782400369644,
      "learning_rate": 5.128e-07,
      "logits/chosen": -2.859553337097168,
      "logits/rejected": -2.5888469219207764,
      "logps/chosen": -46.86861801147461,
      "logps/rejected": -184.46502685546875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42930394411087036,
      "rewards/margins": 12.739295959472656,
      "rewards/rejected": -12.309991836547852,
      "step": 3655
    },
    {
      "epoch": 1.4624,
      "grad_norm": 2.154170036315918,
      "learning_rate": 5.126666666666667e-07,
      "logits/chosen": -2.9579644203186035,
      "logits/rejected": -2.8039746284484863,
      "logps/chosen": -79.50657653808594,
      "logps/rejected": -137.58963012695312,
      "loss": 0.015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.447134405374527,
      "rewards/margins": 7.686423301696777,
      "rewards/rejected": -8.133557319641113,
      "step": 3656
    },
    {
      "epoch": 1.4628,
      "grad_norm": 0.02324499562382698,
      "learning_rate": 5.125333333333333e-07,
      "logits/chosen": -2.7914938926696777,
      "logits/rejected": -2.2675769329071045,
      "logps/chosen": -114.60013580322266,
      "logps/rejected": -146.37899780273438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6325889825820923,
      "rewards/margins": 9.422335624694824,
      "rewards/rejected": -8.78974723815918,
      "step": 3657
    },
    {
      "epoch": 1.4632,
      "grad_norm": 0.6718863844871521,
      "learning_rate": 5.124e-07,
      "logits/chosen": -3.194373846054077,
      "logits/rejected": -2.802377223968506,
      "logps/chosen": -63.37671661376953,
      "logps/rejected": -81.27842712402344,
      "loss": 0.01,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34348565340042114,
      "rewards/margins": 5.000832557678223,
      "rewards/rejected": -4.657346725463867,
      "step": 3658
    },
    {
      "epoch": 1.4636,
      "grad_norm": 0.09554314613342285,
      "learning_rate": 5.122666666666666e-07,
      "logits/chosen": -3.1221375465393066,
      "logits/rejected": -2.699014663696289,
      "logps/chosen": -74.67850494384766,
      "logps/rejected": -199.45449829101562,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5866294503211975,
      "rewards/margins": 8.680109977722168,
      "rewards/rejected": -8.093480110168457,
      "step": 3659
    },
    {
      "epoch": 1.464,
      "grad_norm": 0.18787112832069397,
      "learning_rate": 5.121333333333333e-07,
      "logits/chosen": -3.0926101207733154,
      "logits/rejected": -2.823331832885742,
      "logps/chosen": -49.582176208496094,
      "logps/rejected": -95.04252624511719,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10953961312770844,
      "rewards/margins": 6.462804794311523,
      "rewards/rejected": -6.353265285491943,
      "step": 3660
    },
    {
      "epoch": 1.4644,
      "grad_norm": 3.309551239013672,
      "learning_rate": 5.12e-07,
      "logits/chosen": -2.922795534133911,
      "logits/rejected": -2.172292947769165,
      "logps/chosen": -101.94190979003906,
      "logps/rejected": -116.1891860961914,
      "loss": 0.0228,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.131750464439392,
      "rewards/margins": 6.863644599914551,
      "rewards/rejected": -5.731894016265869,
      "step": 3661
    },
    {
      "epoch": 1.4647999999999999,
      "grad_norm": 3.237787961959839,
      "learning_rate": 5.118666666666666e-07,
      "logits/chosen": -2.551464080810547,
      "logits/rejected": -2.215473175048828,
      "logps/chosen": -221.34707641601562,
      "logps/rejected": -184.90573120117188,
      "loss": 0.0154,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.053039073944092,
      "rewards/margins": 7.559262752532959,
      "rewards/rejected": -11.61230182647705,
      "step": 3662
    },
    {
      "epoch": 1.4652,
      "grad_norm": 0.21839401125907898,
      "learning_rate": 5.117333333333333e-07,
      "logits/chosen": -2.6612563133239746,
      "logits/rejected": -1.980930209159851,
      "logps/chosen": -119.64852905273438,
      "logps/rejected": -150.7271728515625,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3321262300014496,
      "rewards/margins": 9.513948440551758,
      "rewards/rejected": -9.181821823120117,
      "step": 3663
    },
    {
      "epoch": 1.4656,
      "grad_norm": 0.004962224513292313,
      "learning_rate": 5.116e-07,
      "logits/chosen": -2.8198447227478027,
      "logits/rejected": -2.296210527420044,
      "logps/chosen": -112.36590576171875,
      "logps/rejected": -167.56887817382812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8054416179656982,
      "rewards/margins": 10.544744491577148,
      "rewards/rejected": -12.35018539428711,
      "step": 3664
    },
    {
      "epoch": 1.466,
      "grad_norm": 0.11280426383018494,
      "learning_rate": 5.114666666666666e-07,
      "logits/chosen": -2.9487171173095703,
      "logits/rejected": -2.3954262733459473,
      "logps/chosen": -91.49801635742188,
      "logps/rejected": -140.69757080078125,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.07053679972887039,
      "rewards/margins": 7.996048927307129,
      "rewards/rejected": -8.066585540771484,
      "step": 3665
    },
    {
      "epoch": 1.4664,
      "grad_norm": 0.2655237317085266,
      "learning_rate": 5.113333333333333e-07,
      "logits/chosen": -2.504343032836914,
      "logits/rejected": -1.8802014589309692,
      "logps/chosen": -172.78170776367188,
      "logps/rejected": -213.9761962890625,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7317153215408325,
      "rewards/margins": 12.137077331542969,
      "rewards/rejected": -13.868793487548828,
      "step": 3666
    },
    {
      "epoch": 1.4668,
      "grad_norm": 0.0020637637935578823,
      "learning_rate": 5.112e-07,
      "logits/chosen": -2.538825511932373,
      "logits/rejected": -2.037890911102295,
      "logps/chosen": -178.85842895507812,
      "logps/rejected": -187.80587768554688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.26458436250686646,
      "rewards/margins": 11.638358116149902,
      "rewards/rejected": -11.373773574829102,
      "step": 3667
    },
    {
      "epoch": 1.4672,
      "grad_norm": 0.001178695005364716,
      "learning_rate": 5.110666666666667e-07,
      "logits/chosen": -2.6036934852600098,
      "logits/rejected": -1.9996767044067383,
      "logps/chosen": -132.72674560546875,
      "logps/rejected": -197.4180908203125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33467939496040344,
      "rewards/margins": 13.699481964111328,
      "rewards/rejected": -13.364803314208984,
      "step": 3668
    },
    {
      "epoch": 1.4676,
      "grad_norm": 44.32518768310547,
      "learning_rate": 5.109333333333334e-07,
      "logits/chosen": -3.114203453063965,
      "logits/rejected": -2.6574692726135254,
      "logps/chosen": -90.99932098388672,
      "logps/rejected": -105.32483673095703,
      "loss": 0.3154,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8434339761734009,
      "rewards/margins": 4.91087532043457,
      "rewards/rejected": -6.754309177398682,
      "step": 3669
    },
    {
      "epoch": 1.468,
      "grad_norm": 0.021514281630516052,
      "learning_rate": 5.108e-07,
      "logits/chosen": -2.4454522132873535,
      "logits/rejected": -2.405221462249756,
      "logps/chosen": -99.71631622314453,
      "logps/rejected": -198.14956665039062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2353544384241104,
      "rewards/margins": 11.594844818115234,
      "rewards/rejected": -11.8302001953125,
      "step": 3670
    },
    {
      "epoch": 1.4684,
      "grad_norm": 99.75007629394531,
      "learning_rate": 5.106666666666667e-07,
      "logits/chosen": -2.50980544090271,
      "logits/rejected": -2.3719587326049805,
      "logps/chosen": -253.95570373535156,
      "logps/rejected": -174.2694549560547,
      "loss": 0.7272,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -7.783594608306885,
      "rewards/margins": 1.0160918235778809,
      "rewards/rejected": -8.799686431884766,
      "step": 3671
    },
    {
      "epoch": 1.4687999999999999,
      "grad_norm": 0.18870148062705994,
      "learning_rate": 5.105333333333332e-07,
      "logits/chosen": -2.7065255641937256,
      "logits/rejected": -2.0152740478515625,
      "logps/chosen": -75.57817077636719,
      "logps/rejected": -148.61614990234375,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8982768058776855,
      "rewards/margins": 9.960708618164062,
      "rewards/rejected": -8.062431335449219,
      "step": 3672
    },
    {
      "epoch": 1.4692,
      "grad_norm": 1.2893174886703491,
      "learning_rate": 5.103999999999999e-07,
      "logits/chosen": -3.120504379272461,
      "logits/rejected": -2.8280367851257324,
      "logps/chosen": -77.78169250488281,
      "logps/rejected": -116.55763244628906,
      "loss": 0.0141,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0350291728973389,
      "rewards/margins": 5.938996315002441,
      "rewards/rejected": -6.974025726318359,
      "step": 3673
    },
    {
      "epoch": 1.4696,
      "grad_norm": 0.005037185736000538,
      "learning_rate": 5.102666666666666e-07,
      "logits/chosen": -2.7327728271484375,
      "logits/rejected": -2.2260091304779053,
      "logps/chosen": -91.00262451171875,
      "logps/rejected": -131.3089141845703,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.26615571975708,
      "rewards/margins": 10.691872596740723,
      "rewards/rejected": -8.4257173538208,
      "step": 3674
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.12853968143463135,
      "learning_rate": 5.101333333333333e-07,
      "logits/chosen": -2.8940629959106445,
      "logits/rejected": -2.381484270095825,
      "logps/chosen": -107.26409912109375,
      "logps/rejected": -168.66802978515625,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9326618313789368,
      "rewards/margins": 10.303672790527344,
      "rewards/rejected": -11.236333847045898,
      "step": 3675
    },
    {
      "epoch": 1.4704,
      "grad_norm": 4.544658184051514,
      "learning_rate": 5.1e-07,
      "logits/chosen": -2.8206450939178467,
      "logits/rejected": -2.6470911502838135,
      "logps/chosen": -129.5778045654297,
      "logps/rejected": -109.03997802734375,
      "loss": 0.034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7543289661407471,
      "rewards/margins": 5.670134544372559,
      "rewards/rejected": -6.424463272094727,
      "step": 3676
    },
    {
      "epoch": 1.4708,
      "grad_norm": 205.03875732421875,
      "learning_rate": 5.098666666666667e-07,
      "logits/chosen": -2.9250845909118652,
      "logits/rejected": -2.655681610107422,
      "logps/chosen": -193.1375732421875,
      "logps/rejected": -103.07312774658203,
      "loss": 3.6198,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -7.769697189331055,
      "rewards/margins": -0.9583964347839355,
      "rewards/rejected": -6.811300754547119,
      "step": 3677
    },
    {
      "epoch": 1.4712,
      "grad_norm": 0.011904798448085785,
      "learning_rate": 5.097333333333334e-07,
      "logits/chosen": -2.806596279144287,
      "logits/rejected": -2.502450466156006,
      "logps/chosen": -115.30797576904297,
      "logps/rejected": -163.85520935058594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5240547060966492,
      "rewards/margins": 9.91073226928711,
      "rewards/rejected": -9.386677742004395,
      "step": 3678
    },
    {
      "epoch": 1.4716,
      "grad_norm": 2.022322416305542,
      "learning_rate": 5.096000000000001e-07,
      "logits/chosen": -2.3346657752990723,
      "logits/rejected": -1.6433157920837402,
      "logps/chosen": -211.6345672607422,
      "logps/rejected": -187.29129028320312,
      "loss": 0.0071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.7830405235290527,
      "rewards/margins": 6.667789459228516,
      "rewards/rejected": -10.450830459594727,
      "step": 3679
    },
    {
      "epoch": 1.472,
      "grad_norm": 0.4894036054611206,
      "learning_rate": 5.094666666666666e-07,
      "logits/chosen": -3.160325527191162,
      "logits/rejected": -2.8024120330810547,
      "logps/chosen": -49.53445816040039,
      "logps/rejected": -105.63333129882812,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3698451519012451,
      "rewards/margins": 7.7566609382629395,
      "rewards/rejected": -6.386816024780273,
      "step": 3680
    },
    {
      "epoch": 1.4724,
      "grad_norm": 0.05874325707554817,
      "learning_rate": 5.093333333333332e-07,
      "logits/chosen": -2.6663894653320312,
      "logits/rejected": -2.0889148712158203,
      "logps/chosen": -126.77804565429688,
      "logps/rejected": -169.5779571533203,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.595464289188385,
      "rewards/margins": 10.752692222595215,
      "rewards/rejected": -10.157228469848633,
      "step": 3681
    },
    {
      "epoch": 1.4727999999999999,
      "grad_norm": 0.06321217119693756,
      "learning_rate": 5.091999999999999e-07,
      "logits/chosen": -2.870901107788086,
      "logits/rejected": -2.3788580894470215,
      "logps/chosen": -128.2391815185547,
      "logps/rejected": -179.0555419921875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5114086270332336,
      "rewards/margins": 10.930450439453125,
      "rewards/rejected": -10.419041633605957,
      "step": 3682
    },
    {
      "epoch": 1.4732,
      "grad_norm": 0.3233659565448761,
      "learning_rate": 5.090666666666666e-07,
      "logits/chosen": -3.012895107269287,
      "logits/rejected": -2.7302780151367188,
      "logps/chosen": -108.70206451416016,
      "logps/rejected": -112.88743591308594,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14112643897533417,
      "rewards/margins": 5.9093828201293945,
      "rewards/rejected": -5.768256664276123,
      "step": 3683
    },
    {
      "epoch": 1.4736,
      "grad_norm": 18.016639709472656,
      "learning_rate": 5.089333333333333e-07,
      "logits/chosen": -3.051130771636963,
      "logits/rejected": -2.7179694175720215,
      "logps/chosen": -83.66346740722656,
      "logps/rejected": -126.81909942626953,
      "loss": 0.1407,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.1965785026550293,
      "rewards/margins": 5.268779754638672,
      "rewards/rejected": -7.465357780456543,
      "step": 3684
    },
    {
      "epoch": 1.474,
      "grad_norm": 0.007529013324528933,
      "learning_rate": 5.088e-07,
      "logits/chosen": -2.9327871799468994,
      "logits/rejected": -2.305177688598633,
      "logps/chosen": -72.90129089355469,
      "logps/rejected": -166.55517578125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2783889770507812,
      "rewards/margins": 10.400823593139648,
      "rewards/rejected": -9.122434616088867,
      "step": 3685
    },
    {
      "epoch": 1.4744,
      "grad_norm": 0.4051477015018463,
      "learning_rate": 5.086666666666667e-07,
      "logits/chosen": -2.6787309646606445,
      "logits/rejected": -1.9833118915557861,
      "logps/chosen": -112.42406463623047,
      "logps/rejected": -171.08209228515625,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0768585205078125,
      "rewards/margins": 7.883752822875977,
      "rewards/rejected": -9.960611343383789,
      "step": 3686
    },
    {
      "epoch": 1.4748,
      "grad_norm": 0.00742504233494401,
      "learning_rate": 5.085333333333333e-07,
      "logits/chosen": -3.2120208740234375,
      "logits/rejected": -2.128249168395996,
      "logps/chosen": -65.70996856689453,
      "logps/rejected": -217.3109893798828,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.390432596206665,
      "rewards/margins": 13.991093635559082,
      "rewards/rejected": -12.60066032409668,
      "step": 3687
    },
    {
      "epoch": 1.4752,
      "grad_norm": 0.3344201147556305,
      "learning_rate": 5.084e-07,
      "logits/chosen": -2.668405771255493,
      "logits/rejected": -2.5073156356811523,
      "logps/chosen": -144.88568115234375,
      "logps/rejected": -150.01217651367188,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.2997546195983887,
      "rewards/margins": 6.3124895095825195,
      "rewards/rejected": -8.61224365234375,
      "step": 3688
    },
    {
      "epoch": 1.4756,
      "grad_norm": 0.09528131037950516,
      "learning_rate": 5.082666666666667e-07,
      "logits/chosen": -2.915886878967285,
      "logits/rejected": -2.6764652729034424,
      "logps/chosen": -79.50321197509766,
      "logps/rejected": -142.54873657226562,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7000782489776611,
      "rewards/margins": 9.246200561523438,
      "rewards/rejected": -8.546122550964355,
      "step": 3689
    },
    {
      "epoch": 1.476,
      "grad_norm": 0.08629772067070007,
      "learning_rate": 5.081333333333333e-07,
      "logits/chosen": -2.8600735664367676,
      "logits/rejected": -2.075662136077881,
      "logps/chosen": -91.51078796386719,
      "logps/rejected": -146.68728637695312,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.29614871740341187,
      "rewards/margins": 8.512025833129883,
      "rewards/rejected": -8.215877532958984,
      "step": 3690
    },
    {
      "epoch": 1.4764,
      "grad_norm": 0.08643774688243866,
      "learning_rate": 5.079999999999999e-07,
      "logits/chosen": -2.7636780738830566,
      "logits/rejected": -2.602332592010498,
      "logps/chosen": -165.7494354248047,
      "logps/rejected": -146.46759033203125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.002353668212890625,
      "rewards/margins": 7.8369669914245605,
      "rewards/rejected": -7.834613800048828,
      "step": 3691
    },
    {
      "epoch": 1.4768,
      "grad_norm": 0.03536100313067436,
      "learning_rate": 5.078666666666666e-07,
      "logits/chosen": -2.876326560974121,
      "logits/rejected": -2.476975917816162,
      "logps/chosen": -51.735267639160156,
      "logps/rejected": -106.44987487792969,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7324185371398926,
      "rewards/margins": 8.7173490524292,
      "rewards/rejected": -6.984930992126465,
      "step": 3692
    },
    {
      "epoch": 1.4772,
      "grad_norm": 0.007596749812364578,
      "learning_rate": 5.077333333333333e-07,
      "logits/chosen": -3.155745506286621,
      "logits/rejected": -2.681334972381592,
      "logps/chosen": -57.72163391113281,
      "logps/rejected": -134.93917846679688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.44097101688385,
      "rewards/margins": 10.178192138671875,
      "rewards/rejected": -8.737220764160156,
      "step": 3693
    },
    {
      "epoch": 1.4776,
      "grad_norm": 0.022877920418977737,
      "learning_rate": 5.076e-07,
      "logits/chosen": -2.8744640350341797,
      "logits/rejected": -2.3965682983398438,
      "logps/chosen": -98.73930358886719,
      "logps/rejected": -177.49566650390625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3397483825683594,
      "rewards/margins": 12.082834243774414,
      "rewards/rejected": -11.743085861206055,
      "step": 3694
    },
    {
      "epoch": 1.478,
      "grad_norm": 0.05587690696120262,
      "learning_rate": 5.074666666666666e-07,
      "logits/chosen": -2.9317779541015625,
      "logits/rejected": -2.57246732711792,
      "logps/chosen": -91.5553970336914,
      "logps/rejected": -158.41143798828125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.157239556312561,
      "rewards/margins": 8.404281616210938,
      "rewards/rejected": -7.247042655944824,
      "step": 3695
    },
    {
      "epoch": 1.4784,
      "grad_norm": 0.001887928694486618,
      "learning_rate": 5.073333333333333e-07,
      "logits/chosen": -2.774899482727051,
      "logits/rejected": -2.2436559200286865,
      "logps/chosen": -75.81652069091797,
      "logps/rejected": -229.73031616210938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8843361139297485,
      "rewards/margins": 15.458539962768555,
      "rewards/rejected": -14.574204444885254,
      "step": 3696
    },
    {
      "epoch": 1.4788000000000001,
      "grad_norm": 0.006913546472787857,
      "learning_rate": 5.072e-07,
      "logits/chosen": -2.47190523147583,
      "logits/rejected": -1.8956867456436157,
      "logps/chosen": -174.37875366210938,
      "logps/rejected": -187.20361328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.48746681213378906,
      "rewards/margins": 11.670785903930664,
      "rewards/rejected": -11.183319091796875,
      "step": 3697
    },
    {
      "epoch": 1.4792,
      "grad_norm": 0.5526893138885498,
      "learning_rate": 5.070666666666667e-07,
      "logits/chosen": -2.8797500133514404,
      "logits/rejected": -2.4134645462036133,
      "logps/chosen": -122.2308120727539,
      "logps/rejected": -135.36355590820312,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5262023210525513,
      "rewards/margins": 7.182258605957031,
      "rewards/rejected": -8.70846176147461,
      "step": 3698
    },
    {
      "epoch": 1.4796,
      "grad_norm": 0.001150932745076716,
      "learning_rate": 5.069333333333334e-07,
      "logits/chosen": -2.8541040420532227,
      "logits/rejected": -2.4342617988586426,
      "logps/chosen": -83.83079528808594,
      "logps/rejected": -189.2460174560547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15181884169578552,
      "rewards/margins": 13.354148864746094,
      "rewards/rejected": -13.202329635620117,
      "step": 3699
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.01289556547999382,
      "learning_rate": 5.068e-07,
      "logits/chosen": -2.6999406814575195,
      "logits/rejected": -1.968752145767212,
      "logps/chosen": -142.0130615234375,
      "logps/rejected": -171.59896850585938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6442459225654602,
      "rewards/margins": 10.575262069702148,
      "rewards/rejected": -11.219508171081543,
      "step": 3700
    },
    {
      "epoch": 1.4804,
      "grad_norm": 0.050444796681404114,
      "learning_rate": 5.066666666666667e-07,
      "logits/chosen": -2.680166721343994,
      "logits/rejected": -2.185026168823242,
      "logps/chosen": -103.08599853515625,
      "logps/rejected": -233.22225952148438,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.18935546278953552,
      "rewards/margins": 8.749855995178223,
      "rewards/rejected": -8.939210891723633,
      "step": 3701
    },
    {
      "epoch": 1.4808,
      "grad_norm": 0.6748613715171814,
      "learning_rate": 5.065333333333332e-07,
      "logits/chosen": -3.0006113052368164,
      "logits/rejected": -2.597006320953369,
      "logps/chosen": -73.06187438964844,
      "logps/rejected": -109.8392105102539,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2062675654888153,
      "rewards/margins": 7.488785743713379,
      "rewards/rejected": -7.282517433166504,
      "step": 3702
    },
    {
      "epoch": 1.4812,
      "grad_norm": 1.1523876190185547,
      "learning_rate": 5.063999999999999e-07,
      "logits/chosen": -3.095534324645996,
      "logits/rejected": -2.9225058555603027,
      "logps/chosen": -66.84425354003906,
      "logps/rejected": -102.48880004882812,
      "loss": 0.0067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5186458826065063,
      "rewards/margins": 6.63804817199707,
      "rewards/rejected": -6.1194024085998535,
      "step": 3703
    },
    {
      "epoch": 1.4816,
      "grad_norm": 0.051866911351680756,
      "learning_rate": 5.062666666666666e-07,
      "logits/chosen": -2.71120023727417,
      "logits/rejected": -2.4541702270507812,
      "logps/chosen": -105.91146087646484,
      "logps/rejected": -174.63255310058594,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1283782720565796,
      "rewards/margins": 11.787785530090332,
      "rewards/rejected": -10.659407615661621,
      "step": 3704
    },
    {
      "epoch": 1.482,
      "grad_norm": 1.1150614023208618,
      "learning_rate": 5.061333333333333e-07,
      "logits/chosen": -2.7773008346557617,
      "logits/rejected": -2.2233035564422607,
      "logps/chosen": -53.069889068603516,
      "logps/rejected": -114.95784759521484,
      "loss": 0.0079,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7592723369598389,
      "rewards/margins": 8.668484687805176,
      "rewards/rejected": -6.909212112426758,
      "step": 3705
    },
    {
      "epoch": 1.4824,
      "grad_norm": 1.1942795515060425,
      "learning_rate": 5.06e-07,
      "logits/chosen": -2.6220293045043945,
      "logits/rejected": -2.068592071533203,
      "logps/chosen": -185.8253936767578,
      "logps/rejected": -177.99008178710938,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.5631911754608154,
      "rewards/margins": 8.587225914001465,
      "rewards/rejected": -12.15041732788086,
      "step": 3706
    },
    {
      "epoch": 1.4828000000000001,
      "grad_norm": 0.06325642764568329,
      "learning_rate": 5.058666666666667e-07,
      "logits/chosen": -2.737663984298706,
      "logits/rejected": -2.2498786449432373,
      "logps/chosen": -169.12147521972656,
      "logps/rejected": -163.5719451904297,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2162548303604126,
      "rewards/margins": 9.043160438537598,
      "rewards/rejected": -10.259415626525879,
      "step": 3707
    },
    {
      "epoch": 1.4832,
      "grad_norm": 0.09185880422592163,
      "learning_rate": 5.057333333333334e-07,
      "logits/chosen": -3.13165020942688,
      "logits/rejected": -2.924405097961426,
      "logps/chosen": -47.1878662109375,
      "logps/rejected": -107.01412963867188,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8239395618438721,
      "rewards/margins": 7.402782917022705,
      "rewards/rejected": -6.578843593597412,
      "step": 3708
    },
    {
      "epoch": 1.4836,
      "grad_norm": 0.03186368569731712,
      "learning_rate": 5.056e-07,
      "logits/chosen": -2.8588786125183105,
      "logits/rejected": -2.4358224868774414,
      "logps/chosen": -81.63017272949219,
      "logps/rejected": -175.1166229248047,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20506322383880615,
      "rewards/margins": 9.595098495483398,
      "rewards/rejected": -9.390035629272461,
      "step": 3709
    },
    {
      "epoch": 1.484,
      "grad_norm": 0.6094280481338501,
      "learning_rate": 5.054666666666666e-07,
      "logits/chosen": -2.633762836456299,
      "logits/rejected": -2.2070581912994385,
      "logps/chosen": -117.48789978027344,
      "logps/rejected": -203.8581085205078,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9468036890029907,
      "rewards/margins": 11.34400463104248,
      "rewards/rejected": -10.397201538085938,
      "step": 3710
    },
    {
      "epoch": 1.4844,
      "grad_norm": 0.11745836585760117,
      "learning_rate": 5.053333333333333e-07,
      "logits/chosen": -2.9690661430358887,
      "logits/rejected": -2.6025376319885254,
      "logps/chosen": -73.27800750732422,
      "logps/rejected": -170.93572998046875,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.27840059995651245,
      "rewards/margins": 10.469722747802734,
      "rewards/rejected": -10.748123168945312,
      "step": 3711
    },
    {
      "epoch": 1.4848,
      "grad_norm": 0.016684813424944878,
      "learning_rate": 5.051999999999999e-07,
      "logits/chosen": -2.752878189086914,
      "logits/rejected": -2.1989521980285645,
      "logps/chosen": -83.42699432373047,
      "logps/rejected": -200.24415588378906,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0903440713882446,
      "rewards/margins": 11.829063415527344,
      "rewards/rejected": -10.73871898651123,
      "step": 3712
    },
    {
      "epoch": 1.4852,
      "grad_norm": 0.009873637929558754,
      "learning_rate": 5.050666666666666e-07,
      "logits/chosen": -2.8064346313476562,
      "logits/rejected": -2.0224995613098145,
      "logps/chosen": -102.13194274902344,
      "logps/rejected": -150.2023162841797,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6402820348739624,
      "rewards/margins": 9.745109558105469,
      "rewards/rejected": -9.104827880859375,
      "step": 3713
    },
    {
      "epoch": 1.4856,
      "grad_norm": 0.19764479994773865,
      "learning_rate": 5.049333333333333e-07,
      "logits/chosen": -2.7392849922180176,
      "logits/rejected": -2.3176817893981934,
      "logps/chosen": -173.79269409179688,
      "logps/rejected": -191.93051147460938,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.48791390657424927,
      "rewards/margins": 9.871787071228027,
      "rewards/rejected": -10.359701156616211,
      "step": 3714
    },
    {
      "epoch": 1.486,
      "grad_norm": 0.030482089146971703,
      "learning_rate": 5.048e-07,
      "logits/chosen": -2.896632671356201,
      "logits/rejected": -2.322941303253174,
      "logps/chosen": -126.0331039428711,
      "logps/rejected": -174.35191345214844,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4659112691879272,
      "rewards/margins": 10.274856567382812,
      "rewards/rejected": -11.740768432617188,
      "step": 3715
    },
    {
      "epoch": 1.4864,
      "grad_norm": 0.9449768662452698,
      "learning_rate": 5.046666666666667e-07,
      "logits/chosen": -2.995908260345459,
      "logits/rejected": -2.6686723232269287,
      "logps/chosen": -64.1070327758789,
      "logps/rejected": -123.10650634765625,
      "loss": 0.0061,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.12060127407312393,
      "rewards/margins": 7.67592716217041,
      "rewards/rejected": -7.796527862548828,
      "step": 3716
    },
    {
      "epoch": 1.4868000000000001,
      "grad_norm": 4.873634338378906,
      "learning_rate": 5.045333333333333e-07,
      "logits/chosen": -2.707449436187744,
      "logits/rejected": -2.555673599243164,
      "logps/chosen": -116.14798736572266,
      "logps/rejected": -110.91434478759766,
      "loss": 0.0461,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3495903015136719,
      "rewards/margins": 5.800575256347656,
      "rewards/rejected": -6.150165557861328,
      "step": 3717
    },
    {
      "epoch": 1.4872,
      "grad_norm": 0.007293270900845528,
      "learning_rate": 5.043999999999999e-07,
      "logits/chosen": -2.5533738136291504,
      "logits/rejected": -1.882603645324707,
      "logps/chosen": -145.9827423095703,
      "logps/rejected": -157.29522705078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1930255889892578,
      "rewards/margins": 10.381900787353516,
      "rewards/rejected": -9.188875198364258,
      "step": 3718
    },
    {
      "epoch": 1.4876,
      "grad_norm": 0.0011016585631296039,
      "learning_rate": 5.042666666666666e-07,
      "logits/chosen": -2.642397403717041,
      "logits/rejected": -1.9583792686462402,
      "logps/chosen": -69.95744323730469,
      "logps/rejected": -186.84632873535156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5835927128791809,
      "rewards/margins": 12.6879243850708,
      "rewards/rejected": -12.104331970214844,
      "step": 3719
    },
    {
      "epoch": 1.488,
      "grad_norm": 1.3717726469039917,
      "learning_rate": 5.041333333333333e-07,
      "logits/chosen": -3.1839418411254883,
      "logits/rejected": -2.9734082221984863,
      "logps/chosen": -47.73433303833008,
      "logps/rejected": -101.3192367553711,
      "loss": 0.0128,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.058046724647283554,
      "rewards/margins": 5.571780204772949,
      "rewards/rejected": -5.513733386993408,
      "step": 3720
    },
    {
      "epoch": 1.4884,
      "grad_norm": 0.04392419382929802,
      "learning_rate": 5.04e-07,
      "logits/chosen": -2.7689762115478516,
      "logits/rejected": -1.8591430187225342,
      "logps/chosen": -73.28245544433594,
      "logps/rejected": -133.17637634277344,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2604793906211853,
      "rewards/margins": 8.297301292419434,
      "rewards/rejected": -8.036822319030762,
      "step": 3721
    },
    {
      "epoch": 1.4888,
      "grad_norm": 0.2772660553455353,
      "learning_rate": 5.038666666666667e-07,
      "logits/chosen": -2.9920926094055176,
      "logits/rejected": -2.3119070529937744,
      "logps/chosen": -55.664695739746094,
      "logps/rejected": -173.97479248046875,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2758564054965973,
      "rewards/margins": 11.038872718811035,
      "rewards/rejected": -10.763016700744629,
      "step": 3722
    },
    {
      "epoch": 1.4892,
      "grad_norm": 0.00355722289532423,
      "learning_rate": 5.037333333333333e-07,
      "logits/chosen": -2.95381760597229,
      "logits/rejected": -2.415102958679199,
      "logps/chosen": -82.51142120361328,
      "logps/rejected": -156.74395751953125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5251720547676086,
      "rewards/margins": 11.148680686950684,
      "rewards/rejected": -10.62350845336914,
      "step": 3723
    },
    {
      "epoch": 1.4896,
      "grad_norm": 1.1251718997955322,
      "learning_rate": 5.036e-07,
      "logits/chosen": -2.9060847759246826,
      "logits/rejected": -2.4930992126464844,
      "logps/chosen": -81.4815673828125,
      "logps/rejected": -98.16508483886719,
      "loss": 0.009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6835060119628906,
      "rewards/margins": 4.999680042266846,
      "rewards/rejected": -5.683186054229736,
      "step": 3724
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.549257755279541,
      "learning_rate": 5.034666666666666e-07,
      "logits/chosen": -2.7966151237487793,
      "logits/rejected": -2.6653103828430176,
      "logps/chosen": -94.87127685546875,
      "logps/rejected": -109.4183349609375,
      "loss": 0.0114,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5894718170166016,
      "rewards/margins": 5.919463634490967,
      "rewards/rejected": -6.50893497467041,
      "step": 3725
    },
    {
      "epoch": 1.4904,
      "grad_norm": 0.10380393266677856,
      "learning_rate": 5.033333333333333e-07,
      "logits/chosen": -2.6848134994506836,
      "logits/rejected": -2.528484344482422,
      "logps/chosen": -130.5443572998047,
      "logps/rejected": -153.33999633789062,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7915199995040894,
      "rewards/margins": 8.074759483337402,
      "rewards/rejected": -8.866279602050781,
      "step": 3726
    },
    {
      "epoch": 1.4908000000000001,
      "grad_norm": 0.07034282386302948,
      "learning_rate": 5.032e-07,
      "logits/chosen": -2.519167900085449,
      "logits/rejected": -2.0589027404785156,
      "logps/chosen": -176.01519775390625,
      "logps/rejected": -178.30270385742188,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1325031518936157,
      "rewards/margins": 9.042091369628906,
      "rewards/rejected": -10.174593925476074,
      "step": 3727
    },
    {
      "epoch": 1.4912,
      "grad_norm": 2.1737945079803467,
      "learning_rate": 5.030666666666666e-07,
      "logits/chosen": -2.713085651397705,
      "logits/rejected": -2.2032759189605713,
      "logps/chosen": -113.45988464355469,
      "logps/rejected": -112.72697448730469,
      "loss": 0.0129,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.13634414970874786,
      "rewards/margins": 5.9055399894714355,
      "rewards/rejected": -6.041884422302246,
      "step": 3728
    },
    {
      "epoch": 1.4916,
      "grad_norm": 0.03931325674057007,
      "learning_rate": 5.029333333333333e-07,
      "logits/chosen": -2.941648006439209,
      "logits/rejected": -2.4720306396484375,
      "logps/chosen": -90.02864074707031,
      "logps/rejected": -164.86007690429688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5110933184623718,
      "rewards/margins": 10.012016296386719,
      "rewards/rejected": -10.523110389709473,
      "step": 3729
    },
    {
      "epoch": 1.492,
      "grad_norm": 0.0090176397934556,
      "learning_rate": 5.028e-07,
      "logits/chosen": -2.704148292541504,
      "logits/rejected": -2.089332103729248,
      "logps/chosen": -96.05400848388672,
      "logps/rejected": -176.01080322265625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1132221221923828,
      "rewards/margins": 12.529990196228027,
      "rewards/rejected": -11.416768074035645,
      "step": 3730
    },
    {
      "epoch": 1.4924,
      "grad_norm": 0.012548972852528095,
      "learning_rate": 5.026666666666667e-07,
      "logits/chosen": -2.9303343296051025,
      "logits/rejected": -2.076594829559326,
      "logps/chosen": -69.30786895751953,
      "logps/rejected": -128.17636108398438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3006932735443115,
      "rewards/margins": 9.46035385131836,
      "rewards/rejected": -8.159661293029785,
      "step": 3731
    },
    {
      "epoch": 1.4928,
      "grad_norm": 136.71334838867188,
      "learning_rate": 5.025333333333334e-07,
      "logits/chosen": -2.974165916442871,
      "logits/rejected": -2.6601076126098633,
      "logps/chosen": -124.36259460449219,
      "logps/rejected": -133.2157745361328,
      "loss": 1.7765,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -3.1729414463043213,
      "rewards/margins": 6.679678440093994,
      "rewards/rejected": -9.852619171142578,
      "step": 3732
    },
    {
      "epoch": 1.4932,
      "grad_norm": 0.9124687314033508,
      "learning_rate": 5.023999999999999e-07,
      "logits/chosen": -3.112860679626465,
      "logits/rejected": -2.8947958946228027,
      "logps/chosen": -104.88880920410156,
      "logps/rejected": -100.98377990722656,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9442421793937683,
      "rewards/margins": 4.846714973449707,
      "rewards/rejected": -5.790956497192383,
      "step": 3733
    },
    {
      "epoch": 1.4936,
      "grad_norm": 1.0831924676895142,
      "learning_rate": 5.022666666666666e-07,
      "logits/chosen": -2.6215896606445312,
      "logits/rejected": -2.200289249420166,
      "logps/chosen": -93.58914184570312,
      "logps/rejected": -159.58453369140625,
      "loss": 0.0097,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16889458894729614,
      "rewards/margins": 9.351340293884277,
      "rewards/rejected": -9.182445526123047,
      "step": 3734
    },
    {
      "epoch": 1.494,
      "grad_norm": 0.0017873677425086498,
      "learning_rate": 5.021333333333333e-07,
      "logits/chosen": -2.488884925842285,
      "logits/rejected": -1.977912425994873,
      "logps/chosen": -151.53919982910156,
      "logps/rejected": -184.0110626220703,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12791365385055542,
      "rewards/margins": 12.413690567016602,
      "rewards/rejected": -12.28577709197998,
      "step": 3735
    },
    {
      "epoch": 1.4944,
      "grad_norm": 0.01567460224032402,
      "learning_rate": 5.02e-07,
      "logits/chosen": -2.4581429958343506,
      "logits/rejected": -2.0704879760742188,
      "logps/chosen": -174.97671508789062,
      "logps/rejected": -193.10340881347656,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.49616801738739014,
      "rewards/margins": 9.961999893188477,
      "rewards/rejected": -10.458168029785156,
      "step": 3736
    },
    {
      "epoch": 1.4948000000000001,
      "grad_norm": 0.07739812135696411,
      "learning_rate": 5.018666666666666e-07,
      "logits/chosen": -2.9416139125823975,
      "logits/rejected": -2.2381348609924316,
      "logps/chosen": -92.86466217041016,
      "logps/rejected": -150.7450714111328,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8169662952423096,
      "rewards/margins": 7.753625869750977,
      "rewards/rejected": -9.570591926574707,
      "step": 3737
    },
    {
      "epoch": 1.4952,
      "grad_norm": 0.06275215744972229,
      "learning_rate": 5.017333333333333e-07,
      "logits/chosen": -2.8059439659118652,
      "logits/rejected": -1.9995405673980713,
      "logps/chosen": -72.50226593017578,
      "logps/rejected": -138.42115783691406,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.475640058517456,
      "rewards/margins": 10.213997840881348,
      "rewards/rejected": -8.738357543945312,
      "step": 3738
    },
    {
      "epoch": 1.4956,
      "grad_norm": 0.2830853760242462,
      "learning_rate": 5.016e-07,
      "logits/chosen": -2.9631876945495605,
      "logits/rejected": -2.7842674255371094,
      "logps/chosen": -51.12388229370117,
      "logps/rejected": -113.12342834472656,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6315757632255554,
      "rewards/margins": 6.62184476852417,
      "rewards/rejected": -7.253420829772949,
      "step": 3739
    },
    {
      "epoch": 1.496,
      "grad_norm": 0.08723001182079315,
      "learning_rate": 5.014666666666666e-07,
      "logits/chosen": -2.8768606185913086,
      "logits/rejected": -2.180126905441284,
      "logps/chosen": -75.57500457763672,
      "logps/rejected": -129.77432250976562,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0338398218154907,
      "rewards/margins": 9.437885284423828,
      "rewards/rejected": -8.404045104980469,
      "step": 3740
    },
    {
      "epoch": 1.4964,
      "grad_norm": 2.716280460357666,
      "learning_rate": 5.013333333333333e-07,
      "logits/chosen": -2.9135429859161377,
      "logits/rejected": -2.603659152984619,
      "logps/chosen": -86.41900634765625,
      "logps/rejected": -106.06300354003906,
      "loss": 0.0201,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4319484531879425,
      "rewards/margins": 5.854005813598633,
      "rewards/rejected": -6.285954475402832,
      "step": 3741
    },
    {
      "epoch": 1.4968,
      "grad_norm": 0.0141902519389987,
      "learning_rate": 5.012e-07,
      "logits/chosen": -2.7297677993774414,
      "logits/rejected": -2.159036159515381,
      "logps/chosen": -106.44647979736328,
      "logps/rejected": -159.65296936035156,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1617405414581299,
      "rewards/margins": 9.46151065826416,
      "rewards/rejected": -10.623250961303711,
      "step": 3742
    },
    {
      "epoch": 1.4971999999999999,
      "grad_norm": 0.016548939049243927,
      "learning_rate": 5.010666666666667e-07,
      "logits/chosen": -2.7327988147735596,
      "logits/rejected": -2.186563014984131,
      "logps/chosen": -109.0615005493164,
      "logps/rejected": -162.67613220214844,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9439986944198608,
      "rewards/margins": 9.291200637817383,
      "rewards/rejected": -10.235199928283691,
      "step": 3743
    },
    {
      "epoch": 1.4976,
      "grad_norm": 0.2768998146057129,
      "learning_rate": 5.009333333333333e-07,
      "logits/chosen": -3.1389169692993164,
      "logits/rejected": -2.7338266372680664,
      "logps/chosen": -69.77268981933594,
      "logps/rejected": -117.82695007324219,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5116678476333618,
      "rewards/margins": 6.586899280548096,
      "rewards/rejected": -6.075231552124023,
      "step": 3744
    },
    {
      "epoch": 1.498,
      "grad_norm": 0.21679073572158813,
      "learning_rate": 5.008e-07,
      "logits/chosen": -2.390393018722534,
      "logits/rejected": -1.809605360031128,
      "logps/chosen": -135.82223510742188,
      "logps/rejected": -117.5625,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4022812247276306,
      "rewards/margins": 6.327083587646484,
      "rewards/rejected": -6.729364395141602,
      "step": 3745
    },
    {
      "epoch": 1.4984,
      "grad_norm": 12.189373016357422,
      "learning_rate": 5.006666666666667e-07,
      "logits/chosen": -2.8573222160339355,
      "logits/rejected": -2.421107292175293,
      "logps/chosen": -101.53547668457031,
      "logps/rejected": -90.98410034179688,
      "loss": 0.0991,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.037905216217041,
      "rewards/margins": 4.052593231201172,
      "rewards/rejected": -6.090498447418213,
      "step": 3746
    },
    {
      "epoch": 1.4988000000000001,
      "grad_norm": 0.00674233166500926,
      "learning_rate": 5.005333333333333e-07,
      "logits/chosen": -2.552748680114746,
      "logits/rejected": -1.8063948154449463,
      "logps/chosen": -102.47428894042969,
      "logps/rejected": -149.91217041015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7488465309143066,
      "rewards/margins": 10.770244598388672,
      "rewards/rejected": -9.021398544311523,
      "step": 3747
    },
    {
      "epoch": 1.4992,
      "grad_norm": 0.004978439770638943,
      "learning_rate": 5.003999999999999e-07,
      "logits/chosen": -2.8848206996917725,
      "logits/rejected": -2.1853766441345215,
      "logps/chosen": -73.70091247558594,
      "logps/rejected": -199.62118530273438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3569490909576416,
      "rewards/margins": 11.246578216552734,
      "rewards/rejected": -12.603527069091797,
      "step": 3748
    },
    {
      "epoch": 1.4996,
      "grad_norm": 1.456557035446167,
      "learning_rate": 5.002666666666666e-07,
      "logits/chosen": -2.7592248916625977,
      "logits/rejected": -2.375237464904785,
      "logps/chosen": -184.61654663085938,
      "logps/rejected": -124.08739471435547,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.2134039402008057,
      "rewards/margins": 6.300076484680176,
      "rewards/rejected": -8.513481140136719,
      "step": 3749
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.009208551608026028,
      "learning_rate": 5.001333333333333e-07,
      "logits/chosen": -2.5179758071899414,
      "logits/rejected": -1.5787954330444336,
      "logps/chosen": -97.38076782226562,
      "logps/rejected": -196.9801025390625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4733471870422363,
      "rewards/margins": 10.528711318969727,
      "rewards/rejected": -9.055364608764648,
      "step": 3750
    },
    {
      "epoch": 1.5004,
      "grad_norm": 0.12783311307430267,
      "learning_rate": 5e-07,
      "logits/chosen": -2.330551862716675,
      "logits/rejected": -1.8239388465881348,
      "logps/chosen": -166.60366821289062,
      "logps/rejected": -124.83226013183594,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05481719970703125,
      "rewards/margins": 7.130128860473633,
      "rewards/rejected": -7.075311660766602,
      "step": 3751
    },
    {
      "epoch": 1.5008,
      "grad_norm": 0.04741043597459793,
      "learning_rate": 4.998666666666667e-07,
      "logits/chosen": -2.5202035903930664,
      "logits/rejected": -2.1341609954833984,
      "logps/chosen": -124.01810455322266,
      "logps/rejected": -202.0784454345703,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5410928726196289,
      "rewards/margins": 9.979206085205078,
      "rewards/rejected": -9.43811321258545,
      "step": 3752
    },
    {
      "epoch": 1.5011999999999999,
      "grad_norm": 0.0023197224363684654,
      "learning_rate": 4.997333333333333e-07,
      "logits/chosen": -2.7151288986206055,
      "logits/rejected": -2.318993091583252,
      "logps/chosen": -101.70710754394531,
      "logps/rejected": -159.7764434814453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6323429346084595,
      "rewards/margins": 11.190386772155762,
      "rewards/rejected": -9.55804443359375,
      "step": 3753
    },
    {
      "epoch": 1.5016,
      "grad_norm": 0.0035420602653175592,
      "learning_rate": 4.996e-07,
      "logits/chosen": -2.5665066242218018,
      "logits/rejected": -2.1692450046539307,
      "logps/chosen": -79.2302474975586,
      "logps/rejected": -179.89926147460938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.20701712369918823,
      "rewards/margins": 11.727055549621582,
      "rewards/rejected": -11.934072494506836,
      "step": 3754
    },
    {
      "epoch": 1.502,
      "grad_norm": 0.08002408593893051,
      "learning_rate": 4.994666666666666e-07,
      "logits/chosen": -2.991410255432129,
      "logits/rejected": -2.4092092514038086,
      "logps/chosen": -63.02794647216797,
      "logps/rejected": -124.99423217773438,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.086067795753479,
      "rewards/margins": 7.780982971191406,
      "rewards/rejected": -7.694914817810059,
      "step": 3755
    },
    {
      "epoch": 1.5024,
      "grad_norm": 0.00577987264841795,
      "learning_rate": 4.993333333333333e-07,
      "logits/chosen": -2.6262333393096924,
      "logits/rejected": -2.0859436988830566,
      "logps/chosen": -132.96435546875,
      "logps/rejected": -172.71823120117188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2670021057128906,
      "rewards/margins": 11.635082244873047,
      "rewards/rejected": -11.368080139160156,
      "step": 3756
    },
    {
      "epoch": 1.5028000000000001,
      "grad_norm": 0.04297574609518051,
      "learning_rate": 4.991999999999999e-07,
      "logits/chosen": -2.830832004547119,
      "logits/rejected": -2.0781736373901367,
      "logps/chosen": -68.135498046875,
      "logps/rejected": -132.36190795898438,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.842483401298523,
      "rewards/margins": 10.492013931274414,
      "rewards/rejected": -8.649530410766602,
      "step": 3757
    },
    {
      "epoch": 1.5032,
      "grad_norm": 9.399365808349103e-05,
      "learning_rate": 4.990666666666666e-07,
      "logits/chosen": -2.3263282775878906,
      "logits/rejected": -1.3505257368087769,
      "logps/chosen": -94.6060562133789,
      "logps/rejected": -247.70750427246094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4087517261505127,
      "rewards/margins": 17.594520568847656,
      "rewards/rejected": -14.185768127441406,
      "step": 3758
    },
    {
      "epoch": 1.5036,
      "grad_norm": 0.022687513381242752,
      "learning_rate": 4.989333333333333e-07,
      "logits/chosen": -2.917031764984131,
      "logits/rejected": -2.4283361434936523,
      "logps/chosen": -67.823486328125,
      "logps/rejected": -182.09579467773438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9744288921356201,
      "rewards/margins": 9.838600158691406,
      "rewards/rejected": -8.864171028137207,
      "step": 3759
    },
    {
      "epoch": 1.504,
      "grad_norm": 0.00039833359187468886,
      "learning_rate": 4.988e-07,
      "logits/chosen": -2.4683938026428223,
      "logits/rejected": -1.6646499633789062,
      "logps/chosen": -121.65982818603516,
      "logps/rejected": -185.43545532226562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5167924165725708,
      "rewards/margins": 13.800697326660156,
      "rewards/rejected": -12.283905029296875,
      "step": 3760
    },
    {
      "epoch": 1.5044,
      "grad_norm": 0.004514751955866814,
      "learning_rate": 4.986666666666666e-07,
      "logits/chosen": -2.8219032287597656,
      "logits/rejected": -2.065685987472534,
      "logps/chosen": -66.159423828125,
      "logps/rejected": -170.56277465820312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.009690523147583,
      "rewards/margins": 10.89077091217041,
      "rewards/rejected": -9.881080627441406,
      "step": 3761
    },
    {
      "epoch": 1.5048,
      "grad_norm": 0.00016904875519685447,
      "learning_rate": 4.985333333333333e-07,
      "logits/chosen": -2.6376166343688965,
      "logits/rejected": -1.8623621463775635,
      "logps/chosen": -103.23323822021484,
      "logps/rejected": -266.2359619140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9164589643478394,
      "rewards/margins": 14.94391918182373,
      "rewards/rejected": -14.027460098266602,
      "step": 3762
    },
    {
      "epoch": 1.5051999999999999,
      "grad_norm": 0.010173497721552849,
      "learning_rate": 4.984e-07,
      "logits/chosen": -2.541551113128662,
      "logits/rejected": -1.6034644842147827,
      "logps/chosen": -123.19822692871094,
      "logps/rejected": -228.45901489257812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6301418542861938,
      "rewards/margins": 13.016294479370117,
      "rewards/rejected": -14.64643669128418,
      "step": 3763
    },
    {
      "epoch": 1.5056,
      "grad_norm": 0.16269010305404663,
      "learning_rate": 4.982666666666667e-07,
      "logits/chosen": -3.0517654418945312,
      "logits/rejected": -2.693899154663086,
      "logps/chosen": -68.57818603515625,
      "logps/rejected": -140.136474609375,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34811365604400635,
      "rewards/margins": 8.806476593017578,
      "rewards/rejected": -8.458362579345703,
      "step": 3764
    },
    {
      "epoch": 1.506,
      "grad_norm": 0.00034852346288971603,
      "learning_rate": 4.981333333333333e-07,
      "logits/chosen": -2.6179466247558594,
      "logits/rejected": -1.694080114364624,
      "logps/chosen": -153.39967346191406,
      "logps/rejected": -189.46493530273438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.53128582239151,
      "rewards/margins": 14.042905807495117,
      "rewards/rejected": -13.511619567871094,
      "step": 3765
    },
    {
      "epoch": 1.5064,
      "grad_norm": 19.6843204498291,
      "learning_rate": 4.979999999999999e-07,
      "logits/chosen": -2.8517513275146484,
      "logits/rejected": -2.946261405944824,
      "logps/chosen": -113.20207214355469,
      "logps/rejected": -99.00489807128906,
      "loss": 0.1894,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6154314279556274,
      "rewards/margins": 4.2883758544921875,
      "rewards/rejected": -5.903807640075684,
      "step": 3766
    },
    {
      "epoch": 1.5068000000000001,
      "grad_norm": 0.007935375906527042,
      "learning_rate": 4.978666666666666e-07,
      "logits/chosen": -3.0888237953186035,
      "logits/rejected": -2.689627170562744,
      "logps/chosen": -64.58369445800781,
      "logps/rejected": -165.27757263183594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3780983090400696,
      "rewards/margins": 11.003522872924805,
      "rewards/rejected": -10.625425338745117,
      "step": 3767
    },
    {
      "epoch": 1.5072,
      "grad_norm": 1.39227294921875,
      "learning_rate": 4.977333333333333e-07,
      "logits/chosen": -2.7225189208984375,
      "logits/rejected": -2.545715093612671,
      "logps/chosen": -155.24215698242188,
      "logps/rejected": -156.78919982910156,
      "loss": 0.014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0032237768173218,
      "rewards/margins": 9.000758171081543,
      "rewards/rejected": -10.003981590270996,
      "step": 3768
    },
    {
      "epoch": 1.5076,
      "grad_norm": 2.033742904663086,
      "learning_rate": 4.976e-07,
      "logits/chosen": -2.6532020568847656,
      "logits/rejected": -2.4667563438415527,
      "logps/chosen": -129.4450225830078,
      "logps/rejected": -100.64502716064453,
      "loss": 0.0189,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.060854434967041,
      "rewards/margins": 5.284224510192871,
      "rewards/rejected": -6.345078468322754,
      "step": 3769
    },
    {
      "epoch": 1.508,
      "grad_norm": 0.07868041843175888,
      "learning_rate": 4.974666666666666e-07,
      "logits/chosen": -2.853468894958496,
      "logits/rejected": -2.2347371578216553,
      "logps/chosen": -86.47743225097656,
      "logps/rejected": -171.97669982910156,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8434203863143921,
      "rewards/margins": 11.412002563476562,
      "rewards/rejected": -12.255423545837402,
      "step": 3770
    },
    {
      "epoch": 1.5084,
      "grad_norm": 0.031063932925462723,
      "learning_rate": 4.973333333333333e-07,
      "logits/chosen": -2.708366870880127,
      "logits/rejected": -2.2720983028411865,
      "logps/chosen": -159.82766723632812,
      "logps/rejected": -139.00401306152344,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.495897114276886,
      "rewards/margins": 9.155158996582031,
      "rewards/rejected": -9.651055335998535,
      "step": 3771
    },
    {
      "epoch": 1.5088,
      "grad_norm": 0.03515760228037834,
      "learning_rate": 4.972e-07,
      "logits/chosen": -2.8028783798217773,
      "logits/rejected": -2.201883554458618,
      "logps/chosen": -113.40931701660156,
      "logps/rejected": -136.17727661132812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.36843836307525635,
      "rewards/margins": 9.785327911376953,
      "rewards/rejected": -9.416889190673828,
      "step": 3772
    },
    {
      "epoch": 1.5091999999999999,
      "grad_norm": 6.7762322425842285,
      "learning_rate": 4.970666666666667e-07,
      "logits/chosen": -2.942964792251587,
      "logits/rejected": -2.664835214614868,
      "logps/chosen": -102.38772583007812,
      "logps/rejected": -125.01869201660156,
      "loss": 0.0344,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1961078643798828,
      "rewards/margins": 7.453296661376953,
      "rewards/rejected": -7.25718879699707,
      "step": 3773
    },
    {
      "epoch": 1.5096,
      "grad_norm": 0.011694798246026039,
      "learning_rate": 4.969333333333334e-07,
      "logits/chosen": -2.6355414390563965,
      "logits/rejected": -2.078016757965088,
      "logps/chosen": -195.06448364257812,
      "logps/rejected": -242.5389404296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3130073547363281,
      "rewards/margins": 11.45108413696289,
      "rewards/rejected": -10.138075828552246,
      "step": 3774
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.3556016683578491,
      "learning_rate": 4.968e-07,
      "logits/chosen": -2.9524593353271484,
      "logits/rejected": -2.8771073818206787,
      "logps/chosen": -102.59026336669922,
      "logps/rejected": -97.2818603515625,
      "loss": 0.0075,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5938279032707214,
      "rewards/margins": 5.173189163208008,
      "rewards/rejected": -4.5793609619140625,
      "step": 3775
    },
    {
      "epoch": 1.5104,
      "grad_norm": 0.3935559391975403,
      "learning_rate": 4.966666666666666e-07,
      "logits/chosen": -2.7944295406341553,
      "logits/rejected": -2.2882533073425293,
      "logps/chosen": -61.454498291015625,
      "logps/rejected": -110.1199722290039,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1451499462127686,
      "rewards/margins": 7.356173515319824,
      "rewards/rejected": -6.211023330688477,
      "step": 3776
    },
    {
      "epoch": 1.5108000000000001,
      "grad_norm": 1.2924538850784302,
      "learning_rate": 4.965333333333333e-07,
      "logits/chosen": -2.9570984840393066,
      "logits/rejected": -2.5471606254577637,
      "logps/chosen": -40.65446472167969,
      "logps/rejected": -142.4158935546875,
      "loss": 0.01,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9543999433517456,
      "rewards/margins": 6.860891342163086,
      "rewards/rejected": -7.815291404724121,
      "step": 3777
    },
    {
      "epoch": 1.5112,
      "grad_norm": 0.0607154555618763,
      "learning_rate": 4.964e-07,
      "logits/chosen": -2.7561326026916504,
      "logits/rejected": -2.0685999393463135,
      "logps/chosen": -141.950439453125,
      "logps/rejected": -150.45162963867188,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0819168090820312,
      "rewards/margins": 9.139366149902344,
      "rewards/rejected": -10.221282958984375,
      "step": 3778
    },
    {
      "epoch": 1.5116,
      "grad_norm": 0.0953691378235817,
      "learning_rate": 4.962666666666667e-07,
      "logits/chosen": -3.006410598754883,
      "logits/rejected": -2.575507164001465,
      "logps/chosen": -83.56915283203125,
      "logps/rejected": -114.09046936035156,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5717012286186218,
      "rewards/margins": 7.424165725708008,
      "rewards/rejected": -6.852464199066162,
      "step": 3779
    },
    {
      "epoch": 1.512,
      "grad_norm": 0.018974581733345985,
      "learning_rate": 4.961333333333333e-07,
      "logits/chosen": -2.6305346488952637,
      "logits/rejected": -2.1719014644622803,
      "logps/chosen": -117.58779907226562,
      "logps/rejected": -172.36492919921875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5476123690605164,
      "rewards/margins": 10.604772567749023,
      "rewards/rejected": -11.152384757995605,
      "step": 3780
    },
    {
      "epoch": 1.5124,
      "grad_norm": 0.09604237973690033,
      "learning_rate": 4.96e-07,
      "logits/chosen": -2.6385974884033203,
      "logits/rejected": -1.9204704761505127,
      "logps/chosen": -76.81163024902344,
      "logps/rejected": -138.27903747558594,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4806091785430908,
      "rewards/margins": 7.685266017913818,
      "rewards/rejected": -6.204656600952148,
      "step": 3781
    },
    {
      "epoch": 1.5128,
      "grad_norm": 0.7762724161148071,
      "learning_rate": 4.958666666666667e-07,
      "logits/chosen": -3.1409943103790283,
      "logits/rejected": -2.740504741668701,
      "logps/chosen": -42.17735290527344,
      "logps/rejected": -97.15321350097656,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.020910382270813,
      "rewards/margins": 6.940791130065918,
      "rewards/rejected": -5.9198808670043945,
      "step": 3782
    },
    {
      "epoch": 1.5131999999999999,
      "grad_norm": 0.9424019455909729,
      "learning_rate": 4.957333333333334e-07,
      "logits/chosen": -2.744131326675415,
      "logits/rejected": -2.3391411304473877,
      "logps/chosen": -124.51766967773438,
      "logps/rejected": -192.64588928222656,
      "loss": 0.0086,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.233328938484192,
      "rewards/margins": 5.535667896270752,
      "rewards/rejected": -6.7689971923828125,
      "step": 3783
    },
    {
      "epoch": 1.5135999999999998,
      "grad_norm": 0.08841882646083832,
      "learning_rate": 4.956e-07,
      "logits/chosen": -2.8643908500671387,
      "logits/rejected": -2.5716466903686523,
      "logps/chosen": -111.34451293945312,
      "logps/rejected": -153.27670288085938,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.477982759475708,
      "rewards/margins": 8.201433181762695,
      "rewards/rejected": -9.679415702819824,
      "step": 3784
    },
    {
      "epoch": 1.514,
      "grad_norm": 0.20334483683109283,
      "learning_rate": 4.954666666666667e-07,
      "logits/chosen": -3.063185214996338,
      "logits/rejected": -2.5245919227600098,
      "logps/chosen": -44.200374603271484,
      "logps/rejected": -127.73605346679688,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9254078269004822,
      "rewards/margins": 8.162932395935059,
      "rewards/rejected": -7.23752498626709,
      "step": 3785
    },
    {
      "epoch": 1.5144,
      "grad_norm": 0.0722716823220253,
      "learning_rate": 4.953333333333333e-07,
      "logits/chosen": -2.545286178588867,
      "logits/rejected": -1.814255952835083,
      "logps/chosen": -107.23016357421875,
      "logps/rejected": -182.24085998535156,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5974737405776978,
      "rewards/margins": 10.756959915161133,
      "rewards/rejected": -12.354433059692383,
      "step": 3786
    },
    {
      "epoch": 1.5148000000000001,
      "grad_norm": 4.192775726318359,
      "learning_rate": 4.951999999999999e-07,
      "logits/chosen": -3.0055689811706543,
      "logits/rejected": -2.9594669342041016,
      "logps/chosen": -101.92755126953125,
      "logps/rejected": -84.29554748535156,
      "loss": 0.0274,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.592777669429779,
      "rewards/margins": 4.254162788391113,
      "rewards/rejected": -4.846940040588379,
      "step": 3787
    },
    {
      "epoch": 1.5152,
      "grad_norm": 0.27588653564453125,
      "learning_rate": 4.950666666666666e-07,
      "logits/chosen": -2.793478012084961,
      "logits/rejected": -2.1962461471557617,
      "logps/chosen": -90.25559997558594,
      "logps/rejected": -113.68142700195312,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8525466918945312,
      "rewards/margins": 7.2959184646606445,
      "rewards/rejected": -6.443371772766113,
      "step": 3788
    },
    {
      "epoch": 1.5156,
      "grad_norm": 0.4580216705799103,
      "learning_rate": 4.949333333333333e-07,
      "logits/chosen": -2.1627707481384277,
      "logits/rejected": -1.4735422134399414,
      "logps/chosen": -250.8125,
      "logps/rejected": -162.36976623535156,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.319955348968506,
      "rewards/margins": 7.398135185241699,
      "rewards/rejected": -9.718090057373047,
      "step": 3789
    },
    {
      "epoch": 1.516,
      "grad_norm": 0.17941328883171082,
      "learning_rate": 4.948e-07,
      "logits/chosen": -3.1114442348480225,
      "logits/rejected": -2.7794570922851562,
      "logps/chosen": -51.39546203613281,
      "logps/rejected": -110.33413696289062,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5037813186645508,
      "rewards/margins": 7.689665794372559,
      "rewards/rejected": -7.185884475708008,
      "step": 3790
    },
    {
      "epoch": 1.5164,
      "grad_norm": 0.087474524974823,
      "learning_rate": 4.946666666666666e-07,
      "logits/chosen": -2.7322378158569336,
      "logits/rejected": -2.2623910903930664,
      "logps/chosen": -84.27583312988281,
      "logps/rejected": -126.31592559814453,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5178940296173096,
      "rewards/margins": 10.154876708984375,
      "rewards/rejected": -8.636981964111328,
      "step": 3791
    },
    {
      "epoch": 1.5168,
      "grad_norm": 0.9340230226516724,
      "learning_rate": 4.945333333333333e-07,
      "logits/chosen": -2.663933277130127,
      "logits/rejected": -2.229369640350342,
      "logps/chosen": -139.33241271972656,
      "logps/rejected": -220.85794067382812,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.2292137145996094,
      "rewards/margins": 10.798547744750977,
      "rewards/rejected": -13.027761459350586,
      "step": 3792
    },
    {
      "epoch": 1.5171999999999999,
      "grad_norm": 0.4583218991756439,
      "learning_rate": 4.944e-07,
      "logits/chosen": -3.144002914428711,
      "logits/rejected": -2.575610399246216,
      "logps/chosen": -80.12779235839844,
      "logps/rejected": -129.28973388671875,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0190112590789795,
      "rewards/margins": 8.271835327148438,
      "rewards/rejected": -7.252823829650879,
      "step": 3793
    },
    {
      "epoch": 1.5175999999999998,
      "grad_norm": 0.008735066279768944,
      "learning_rate": 4.942666666666667e-07,
      "logits/chosen": -2.6703543663024902,
      "logits/rejected": -2.1021416187286377,
      "logps/chosen": -58.48906707763672,
      "logps/rejected": -135.28829956054688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.030355453491211,
      "rewards/margins": 9.62037181854248,
      "rewards/rejected": -7.5900163650512695,
      "step": 3794
    },
    {
      "epoch": 1.518,
      "grad_norm": 59.082637786865234,
      "learning_rate": 4.941333333333333e-07,
      "logits/chosen": -2.796677589416504,
      "logits/rejected": -2.2545580863952637,
      "logps/chosen": -93.4932861328125,
      "logps/rejected": -77.17674255371094,
      "loss": 0.7325,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -3.0022339820861816,
      "rewards/margins": 0.9332253932952881,
      "rewards/rejected": -3.9354593753814697,
      "step": 3795
    },
    {
      "epoch": 1.5184,
      "grad_norm": 0.5918855667114258,
      "learning_rate": 4.94e-07,
      "logits/chosen": -2.5871057510375977,
      "logits/rejected": -2.234797477722168,
      "logps/chosen": -154.7066650390625,
      "logps/rejected": -153.04556274414062,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3013298511505127,
      "rewards/margins": 6.884374141693115,
      "rewards/rejected": -8.185704231262207,
      "step": 3796
    },
    {
      "epoch": 1.5188000000000001,
      "grad_norm": 0.0022565508261322975,
      "learning_rate": 4.938666666666666e-07,
      "logits/chosen": -2.562067985534668,
      "logits/rejected": -1.9144395589828491,
      "logps/chosen": -140.44833374023438,
      "logps/rejected": -163.244384765625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0699710845947266,
      "rewards/margins": 11.4072904586792,
      "rewards/rejected": -10.337319374084473,
      "step": 3797
    },
    {
      "epoch": 1.5192,
      "grad_norm": 54.578983306884766,
      "learning_rate": 4.937333333333333e-07,
      "logits/chosen": -2.947578191757202,
      "logits/rejected": -2.6431679725646973,
      "logps/chosen": -107.6514663696289,
      "logps/rejected": -111.83946228027344,
      "loss": 0.4599,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -2.305629253387451,
      "rewards/margins": 3.786569356918335,
      "rewards/rejected": -6.092198371887207,
      "step": 3798
    },
    {
      "epoch": 1.5196,
      "grad_norm": 1.7841582298278809,
      "learning_rate": 4.935999999999999e-07,
      "logits/chosen": -3.1529436111450195,
      "logits/rejected": -2.5536439418792725,
      "logps/chosen": -61.88282775878906,
      "logps/rejected": -102.49678039550781,
      "loss": 0.0153,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5973390340805054,
      "rewards/margins": 5.442199230194092,
      "rewards/rejected": -6.039538383483887,
      "step": 3799
    },
    {
      "epoch": 1.52,
      "grad_norm": 19.44565200805664,
      "learning_rate": 4.934666666666666e-07,
      "logits/chosen": -2.843775510787964,
      "logits/rejected": -2.2740185260772705,
      "logps/chosen": -107.11077117919922,
      "logps/rejected": -169.23370361328125,
      "loss": 0.1971,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2096527814865112,
      "rewards/margins": 8.972222328186035,
      "rewards/rejected": -10.181875228881836,
      "step": 3800
    },
    {
      "epoch": 1.5204,
      "grad_norm": 0.03025759384036064,
      "learning_rate": 4.933333333333333e-07,
      "logits/chosen": -2.484731912612915,
      "logits/rejected": -1.7806313037872314,
      "logps/chosen": -153.402587890625,
      "logps/rejected": -171.4355010986328,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2072368860244751,
      "rewards/margins": 8.942619323730469,
      "rewards/rejected": -8.735383033752441,
      "step": 3801
    },
    {
      "epoch": 1.5208,
      "grad_norm": 17.665822982788086,
      "learning_rate": 4.932e-07,
      "logits/chosen": -3.289783000946045,
      "logits/rejected": -2.9610579013824463,
      "logps/chosen": -69.50421142578125,
      "logps/rejected": -136.1908416748047,
      "loss": 0.1823,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.470823049545288,
      "rewards/margins": 5.83409309387207,
      "rewards/rejected": -7.3049163818359375,
      "step": 3802
    },
    {
      "epoch": 1.5211999999999999,
      "grad_norm": 0.013289052993059158,
      "learning_rate": 4.930666666666666e-07,
      "logits/chosen": -2.2643887996673584,
      "logits/rejected": -1.5658009052276611,
      "logps/chosen": -99.72317504882812,
      "logps/rejected": -169.42933654785156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4819092750549316,
      "rewards/margins": 10.096364974975586,
      "rewards/rejected": -8.614456176757812,
      "step": 3803
    },
    {
      "epoch": 1.5215999999999998,
      "grad_norm": 0.0017990185879170895,
      "learning_rate": 4.929333333333333e-07,
      "logits/chosen": -2.5712451934814453,
      "logits/rejected": -2.042478084564209,
      "logps/chosen": -66.4779281616211,
      "logps/rejected": -191.6998291015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.03698291629552841,
      "rewards/margins": 11.906557083129883,
      "rewards/rejected": -11.943538665771484,
      "step": 3804
    },
    {
      "epoch": 1.522,
      "grad_norm": 0.1313624531030655,
      "learning_rate": 4.928e-07,
      "logits/chosen": -3.035288095474243,
      "logits/rejected": -2.411181926727295,
      "logps/chosen": -64.64900207519531,
      "logps/rejected": -129.39971923828125,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1748083084821701,
      "rewards/margins": 8.234724044799805,
      "rewards/rejected": -8.409531593322754,
      "step": 3805
    },
    {
      "epoch": 1.5224,
      "grad_norm": 0.04162689298391342,
      "learning_rate": 4.926666666666667e-07,
      "logits/chosen": -2.7897300720214844,
      "logits/rejected": -2.1197547912597656,
      "logps/chosen": -62.387264251708984,
      "logps/rejected": -160.59246826171875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1845550537109375,
      "rewards/margins": 11.586137771606445,
      "rewards/rejected": -10.401582717895508,
      "step": 3806
    },
    {
      "epoch": 1.5228000000000002,
      "grad_norm": 0.0178240854293108,
      "learning_rate": 4.925333333333333e-07,
      "logits/chosen": -2.7233028411865234,
      "logits/rejected": -1.9627759456634521,
      "logps/chosen": -50.367645263671875,
      "logps/rejected": -188.7099151611328,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8894939422607422,
      "rewards/margins": 12.462091445922852,
      "rewards/rejected": -11.57259750366211,
      "step": 3807
    },
    {
      "epoch": 1.5232,
      "grad_norm": 1.386132001876831,
      "learning_rate": 4.923999999999999e-07,
      "logits/chosen": -2.90114426612854,
      "logits/rejected": -2.693972110748291,
      "logps/chosen": -71.31177520751953,
      "logps/rejected": -131.45584106445312,
      "loss": 0.0079,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0760507583618164,
      "rewards/margins": 6.680377006530762,
      "rewards/rejected": -6.756427764892578,
      "step": 3808
    },
    {
      "epoch": 1.5236,
      "grad_norm": 0.08348137140274048,
      "learning_rate": 4.922666666666666e-07,
      "logits/chosen": -2.9638872146606445,
      "logits/rejected": -2.7965662479400635,
      "logps/chosen": -116.07319641113281,
      "logps/rejected": -150.0078125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2464725375175476,
      "rewards/margins": 7.870427131652832,
      "rewards/rejected": -8.116899490356445,
      "step": 3809
    },
    {
      "epoch": 1.524,
      "grad_norm": 0.051551613956689835,
      "learning_rate": 4.921333333333333e-07,
      "logits/chosen": -2.726430654525757,
      "logits/rejected": -2.191530704498291,
      "logps/chosen": -218.65304565429688,
      "logps/rejected": -178.88516235351562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.1475632190704346,
      "rewards/margins": 9.085200309753418,
      "rewards/rejected": -11.232763290405273,
      "step": 3810
    },
    {
      "epoch": 1.5244,
      "grad_norm": 0.20122471451759338,
      "learning_rate": 4.92e-07,
      "logits/chosen": -2.4537124633789062,
      "logits/rejected": -1.6294903755187988,
      "logps/chosen": -164.95452880859375,
      "logps/rejected": -187.70498657226562,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8215423822402954,
      "rewards/margins": 9.471078872680664,
      "rewards/rejected": -10.292621612548828,
      "step": 3811
    },
    {
      "epoch": 1.5248,
      "grad_norm": 2.782416820526123,
      "learning_rate": 4.918666666666667e-07,
      "logits/chosen": -2.7620644569396973,
      "logits/rejected": -2.6353378295898438,
      "logps/chosen": -83.63292694091797,
      "logps/rejected": -103.85670471191406,
      "loss": 0.0173,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2720130980014801,
      "rewards/margins": 6.557421684265137,
      "rewards/rejected": -6.829434871673584,
      "step": 3812
    },
    {
      "epoch": 1.5252,
      "grad_norm": 0.5146139860153198,
      "learning_rate": 4.917333333333333e-07,
      "logits/chosen": -2.6007165908813477,
      "logits/rejected": -2.2074055671691895,
      "logps/chosen": -79.65419006347656,
      "logps/rejected": -203.13613891601562,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3203117251396179,
      "rewards/margins": 11.794394493103027,
      "rewards/rejected": -12.114706039428711,
      "step": 3813
    },
    {
      "epoch": 1.5255999999999998,
      "grad_norm": 1.8321983814239502,
      "learning_rate": 4.916e-07,
      "logits/chosen": -2.533238410949707,
      "logits/rejected": -2.1749582290649414,
      "logps/chosen": -176.5039825439453,
      "logps/rejected": -186.46910095214844,
      "loss": 0.0082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.232325077056885,
      "rewards/margins": 6.137974262237549,
      "rewards/rejected": -10.370299339294434,
      "step": 3814
    },
    {
      "epoch": 1.526,
      "grad_norm": 0.644278883934021,
      "learning_rate": 4.914666666666667e-07,
      "logits/chosen": -2.9064509868621826,
      "logits/rejected": -2.9811487197875977,
      "logps/chosen": -73.71265411376953,
      "logps/rejected": -103.03042602539062,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.15739020705223083,
      "rewards/margins": 6.248046875,
      "rewards/rejected": -6.4054365158081055,
      "step": 3815
    },
    {
      "epoch": 1.5264,
      "grad_norm": 0.07763452082872391,
      "learning_rate": 4.913333333333334e-07,
      "logits/chosen": -2.9515044689178467,
      "logits/rejected": -2.6881790161132812,
      "logps/chosen": -72.75990295410156,
      "logps/rejected": -135.60415649414062,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45679226517677307,
      "rewards/margins": 8.197333335876465,
      "rewards/rejected": -7.740540504455566,
      "step": 3816
    },
    {
      "epoch": 1.5268000000000002,
      "grad_norm": 0.00012722748215310276,
      "learning_rate": 4.912e-07,
      "logits/chosen": -2.8381967544555664,
      "logits/rejected": -2.2516286373138428,
      "logps/chosen": -71.5565185546875,
      "logps/rejected": -212.93865966796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6397449970245361,
      "rewards/margins": 14.663278579711914,
      "rewards/rejected": -14.023533821105957,
      "step": 3817
    },
    {
      "epoch": 1.5272000000000001,
      "grad_norm": 1.1928555965423584,
      "learning_rate": 4.910666666666666e-07,
      "logits/chosen": -2.867144823074341,
      "logits/rejected": -2.980612277984619,
      "logps/chosen": -69.51079559326172,
      "logps/rejected": -81.01380157470703,
      "loss": 0.0136,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.17958679795265198,
      "rewards/margins": 4.602230072021484,
      "rewards/rejected": -4.781816482543945,
      "step": 3818
    },
    {
      "epoch": 1.5276,
      "grad_norm": 0.05199938267469406,
      "learning_rate": 4.909333333333333e-07,
      "logits/chosen": -3.1175849437713623,
      "logits/rejected": -2.745893955230713,
      "logps/chosen": -68.05905151367188,
      "logps/rejected": -134.2176513671875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3224853277206421,
      "rewards/margins": 8.239680290222168,
      "rewards/rejected": -7.917194843292236,
      "step": 3819
    },
    {
      "epoch": 1.528,
      "grad_norm": 0.11259917169809341,
      "learning_rate": 4.908e-07,
      "logits/chosen": -2.704590082168579,
      "logits/rejected": -2.1644339561462402,
      "logps/chosen": -92.73570251464844,
      "logps/rejected": -130.27301025390625,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4738113284111023,
      "rewards/margins": 9.329500198364258,
      "rewards/rejected": -8.85568904876709,
      "step": 3820
    },
    {
      "epoch": 1.5284,
      "grad_norm": 0.485047847032547,
      "learning_rate": 4.906666666666666e-07,
      "logits/chosen": -2.590070962905884,
      "logits/rejected": -2.5289080142974854,
      "logps/chosen": -118.16552734375,
      "logps/rejected": -132.49307250976562,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0934364795684814,
      "rewards/margins": 6.969180107116699,
      "rewards/rejected": -8.062616348266602,
      "step": 3821
    },
    {
      "epoch": 1.5288,
      "grad_norm": 0.010745209641754627,
      "learning_rate": 4.905333333333333e-07,
      "logits/chosen": -3.2890894412994385,
      "logits/rejected": -2.6324329376220703,
      "logps/chosen": -63.37606430053711,
      "logps/rejected": -135.30169677734375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6345869302749634,
      "rewards/margins": 10.441466331481934,
      "rewards/rejected": -8.806879043579102,
      "step": 3822
    },
    {
      "epoch": 1.5292,
      "grad_norm": 0.17196530103683472,
      "learning_rate": 4.904e-07,
      "logits/chosen": -2.969628095626831,
      "logits/rejected": -2.4613890647888184,
      "logps/chosen": -90.70201110839844,
      "logps/rejected": -164.81243896484375,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1653259992599487,
      "rewards/margins": 10.13914966583252,
      "rewards/rejected": -11.304475784301758,
      "step": 3823
    },
    {
      "epoch": 1.5295999999999998,
      "grad_norm": 0.28125977516174316,
      "learning_rate": 4.902666666666667e-07,
      "logits/chosen": -2.855747699737549,
      "logits/rejected": -2.6836097240448,
      "logps/chosen": -69.38513946533203,
      "logps/rejected": -102.93907165527344,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7482471466064453,
      "rewards/margins": 7.8535356521606445,
      "rewards/rejected": -7.105288505554199,
      "step": 3824
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.08315826952457428,
      "learning_rate": 4.901333333333333e-07,
      "logits/chosen": -2.876194715499878,
      "logits/rejected": -2.3935160636901855,
      "logps/chosen": -111.73780822753906,
      "logps/rejected": -199.90533447265625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8144484758377075,
      "rewards/margins": 11.670838356018066,
      "rewards/rejected": -12.485286712646484,
      "step": 3825
    },
    {
      "epoch": 1.5304,
      "grad_norm": 0.49391865730285645,
      "learning_rate": 4.9e-07,
      "logits/chosen": -2.8224997520446777,
      "logits/rejected": -2.3817996978759766,
      "logps/chosen": -127.8958740234375,
      "logps/rejected": -129.07278442382812,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.42637431621551514,
      "rewards/margins": 7.47573184967041,
      "rewards/rejected": -7.902106285095215,
      "step": 3826
    },
    {
      "epoch": 1.5308000000000002,
      "grad_norm": 0.09042737632989883,
      "learning_rate": 4.898666666666667e-07,
      "logits/chosen": -3.1555373668670654,
      "logits/rejected": -2.5174899101257324,
      "logps/chosen": -49.70318603515625,
      "logps/rejected": -169.59133911132812,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4665672481060028,
      "rewards/margins": 9.918147087097168,
      "rewards/rejected": -10.384714126586914,
      "step": 3827
    },
    {
      "epoch": 1.5312000000000001,
      "grad_norm": 0.0017122444696724415,
      "learning_rate": 4.897333333333334e-07,
      "logits/chosen": -2.5617876052856445,
      "logits/rejected": -1.4442068338394165,
      "logps/chosen": -79.25398254394531,
      "logps/rejected": -192.47665405273438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6000335216522217,
      "rewards/margins": 12.713183403015137,
      "rewards/rejected": -11.113149642944336,
      "step": 3828
    },
    {
      "epoch": 1.5316,
      "grad_norm": 0.011148791760206223,
      "learning_rate": 4.895999999999999e-07,
      "logits/chosen": -2.6096420288085938,
      "logits/rejected": -2.0243635177612305,
      "logps/chosen": -104.5186996459961,
      "logps/rejected": -167.3419952392578,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7836517095565796,
      "rewards/margins": 10.055694580078125,
      "rewards/rejected": -10.839346885681152,
      "step": 3829
    },
    {
      "epoch": 1.532,
      "grad_norm": 0.1094648465514183,
      "learning_rate": 4.894666666666666e-07,
      "logits/chosen": -2.9865665435791016,
      "logits/rejected": -2.7191543579101562,
      "logps/chosen": -80.64944458007812,
      "logps/rejected": -86.3413314819336,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.396144151687622,
      "rewards/margins": 7.218156337738037,
      "rewards/rejected": -5.822011947631836,
      "step": 3830
    },
    {
      "epoch": 1.5324,
      "grad_norm": 2.8419597148895264,
      "learning_rate": 4.893333333333333e-07,
      "logits/chosen": -2.801158905029297,
      "logits/rejected": -2.297650098800659,
      "logps/chosen": -98.0808334350586,
      "logps/rejected": -100.70073699951172,
      "loss": 0.0173,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21475030481815338,
      "rewards/margins": 5.36578893661499,
      "rewards/rejected": -5.151038646697998,
      "step": 3831
    },
    {
      "epoch": 1.5328,
      "grad_norm": 0.1094437688589096,
      "learning_rate": 4.892e-07,
      "logits/chosen": -2.4051616191864014,
      "logits/rejected": -1.883897066116333,
      "logps/chosen": -87.29037475585938,
      "logps/rejected": -145.16490173339844,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.19488373398780823,
      "rewards/margins": 9.226958274841309,
      "rewards/rejected": -9.421842575073242,
      "step": 3832
    },
    {
      "epoch": 1.5332,
      "grad_norm": 0.007559114135801792,
      "learning_rate": 4.890666666666666e-07,
      "logits/chosen": -3.0921640396118164,
      "logits/rejected": -2.8032634258270264,
      "logps/chosen": -72.1351318359375,
      "logps/rejected": -163.39476013183594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.30577582120895386,
      "rewards/margins": 10.781454086303711,
      "rewards/rejected": -10.475677490234375,
      "step": 3833
    },
    {
      "epoch": 1.5335999999999999,
      "grad_norm": 0.005518521647900343,
      "learning_rate": 4.889333333333333e-07,
      "logits/chosen": -2.5343239307403564,
      "logits/rejected": -1.7659382820129395,
      "logps/chosen": -99.56080627441406,
      "logps/rejected": -229.5312957763672,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.387871265411377,
      "rewards/margins": 11.837506294250488,
      "rewards/rejected": -10.449634552001953,
      "step": 3834
    },
    {
      "epoch": 1.534,
      "grad_norm": 0.1753498911857605,
      "learning_rate": 4.888e-07,
      "logits/chosen": -2.7391602993011475,
      "logits/rejected": -2.3280508518218994,
      "logps/chosen": -67.4843978881836,
      "logps/rejected": -191.52711486816406,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4860880374908447,
      "rewards/margins": 11.19560432434082,
      "rewards/rejected": -9.709515571594238,
      "step": 3835
    },
    {
      "epoch": 1.5344,
      "grad_norm": 0.07801502197980881,
      "learning_rate": 4.886666666666667e-07,
      "logits/chosen": -2.980454921722412,
      "logits/rejected": -2.1411752700805664,
      "logps/chosen": -81.9080810546875,
      "logps/rejected": -156.47195434570312,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22060111165046692,
      "rewards/margins": 9.305096626281738,
      "rewards/rejected": -9.084495544433594,
      "step": 3836
    },
    {
      "epoch": 1.5348000000000002,
      "grad_norm": 4.3357367515563965,
      "learning_rate": 4.885333333333333e-07,
      "logits/chosen": -2.8935117721557617,
      "logits/rejected": -2.654024124145508,
      "logps/chosen": -121.423828125,
      "logps/rejected": -125.1501693725586,
      "loss": 0.0279,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.101822853088379,
      "rewards/margins": 6.0113067626953125,
      "rewards/rejected": -8.113129615783691,
      "step": 3837
    },
    {
      "epoch": 1.5352000000000001,
      "grad_norm": 0.0013038263423368335,
      "learning_rate": 4.884e-07,
      "logits/chosen": -2.6644082069396973,
      "logits/rejected": -2.007525682449341,
      "logps/chosen": -112.68061065673828,
      "logps/rejected": -187.62716674804688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4147754907608032,
      "rewards/margins": 12.13461685180664,
      "rewards/rejected": -11.719841003417969,
      "step": 3838
    },
    {
      "epoch": 1.5356,
      "grad_norm": 0.21832019090652466,
      "learning_rate": 4.882666666666666e-07,
      "logits/chosen": -2.6699371337890625,
      "logits/rejected": -2.210679531097412,
      "logps/chosen": -81.67353820800781,
      "logps/rejected": -120.73139953613281,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5513231158256531,
      "rewards/margins": 6.642690658569336,
      "rewards/rejected": -7.194013595581055,
      "step": 3839
    },
    {
      "epoch": 1.536,
      "grad_norm": 0.270694375038147,
      "learning_rate": 4.881333333333333e-07,
      "logits/chosen": -2.620919704437256,
      "logits/rejected": -1.9824028015136719,
      "logps/chosen": -125.58184814453125,
      "logps/rejected": -147.0050811767578,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.238132119178772,
      "rewards/margins": 8.211156845092773,
      "rewards/rejected": -9.449288368225098,
      "step": 3840
    },
    {
      "epoch": 1.5364,
      "grad_norm": 0.7570884823799133,
      "learning_rate": 4.879999999999999e-07,
      "logits/chosen": -2.902982234954834,
      "logits/rejected": -2.3024306297302246,
      "logps/chosen": -73.85556030273438,
      "logps/rejected": -102.26477813720703,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6218066811561584,
      "rewards/margins": 5.770642280578613,
      "rewards/rejected": -6.392449378967285,
      "step": 3841
    },
    {
      "epoch": 1.5368,
      "grad_norm": 0.031569816172122955,
      "learning_rate": 4.878666666666666e-07,
      "logits/chosen": -3.007352113723755,
      "logits/rejected": -2.6369457244873047,
      "logps/chosen": -50.91460418701172,
      "logps/rejected": -121.68048858642578,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.766558289527893,
      "rewards/margins": 9.416918754577637,
      "rewards/rejected": -7.650360584259033,
      "step": 3842
    },
    {
      "epoch": 1.5372,
      "grad_norm": 0.0008040242828428745,
      "learning_rate": 4.877333333333333e-07,
      "logits/chosen": -2.732314109802246,
      "logits/rejected": -1.9929239749908447,
      "logps/chosen": -100.66854095458984,
      "logps/rejected": -189.22824096679688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10470503568649292,
      "rewards/margins": 13.017757415771484,
      "rewards/rejected": -12.913052558898926,
      "step": 3843
    },
    {
      "epoch": 1.5375999999999999,
      "grad_norm": 0.01200715359300375,
      "learning_rate": 4.876e-07,
      "logits/chosen": -2.611192226409912,
      "logits/rejected": -2.0026705265045166,
      "logps/chosen": -111.33113098144531,
      "logps/rejected": -221.60548400878906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3412456512451172,
      "rewards/margins": 12.160945892333984,
      "rewards/rejected": -11.819700241088867,
      "step": 3844
    },
    {
      "epoch": 1.538,
      "grad_norm": 0.8421986699104309,
      "learning_rate": 4.874666666666666e-07,
      "logits/chosen": -3.1126017570495605,
      "logits/rejected": -2.6484808921813965,
      "logps/chosen": -73.0733642578125,
      "logps/rejected": -140.2429656982422,
      "loss": 0.0056,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4163929224014282,
      "rewards/margins": 9.418365478515625,
      "rewards/rejected": -9.001972198486328,
      "step": 3845
    },
    {
      "epoch": 1.5384,
      "grad_norm": 0.9580599665641785,
      "learning_rate": 4.873333333333333e-07,
      "logits/chosen": -2.9016852378845215,
      "logits/rejected": -2.833083152770996,
      "logps/chosen": -70.2628402709961,
      "logps/rejected": -107.07650756835938,
      "loss": 0.0061,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6920572519302368,
      "rewards/margins": 6.014631271362305,
      "rewards/rejected": -5.322574615478516,
      "step": 3846
    },
    {
      "epoch": 1.5388,
      "grad_norm": 0.0881829485297203,
      "learning_rate": 4.872e-07,
      "logits/chosen": -2.621838331222534,
      "logits/rejected": -2.1622443199157715,
      "logps/chosen": -125.62567138671875,
      "logps/rejected": -122.4109878540039,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7736637592315674,
      "rewards/margins": 8.30335521697998,
      "rewards/rejected": -7.529691219329834,
      "step": 3847
    },
    {
      "epoch": 1.5392000000000001,
      "grad_norm": 8.374550816370174e-06,
      "learning_rate": 4.870666666666667e-07,
      "logits/chosen": -2.7199440002441406,
      "logits/rejected": -1.8996862173080444,
      "logps/chosen": -55.876426696777344,
      "logps/rejected": -260.1370849609375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2757515907287598,
      "rewards/margins": 17.652236938476562,
      "rewards/rejected": -15.376486778259277,
      "step": 3848
    },
    {
      "epoch": 1.5396,
      "grad_norm": 0.0007665271987207234,
      "learning_rate": 4.869333333333334e-07,
      "logits/chosen": -2.5985512733459473,
      "logits/rejected": -1.767390489578247,
      "logps/chosen": -86.1077651977539,
      "logps/rejected": -238.15127563476562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4819614887237549,
      "rewards/margins": 13.970029830932617,
      "rewards/rejected": -12.488067626953125,
      "step": 3849
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.000775730877649039,
      "learning_rate": 4.867999999999999e-07,
      "logits/chosen": -2.496187210083008,
      "logits/rejected": -1.9371309280395508,
      "logps/chosen": -123.33108520507812,
      "logps/rejected": -201.08587646484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0089130401611328,
      "rewards/margins": 13.288455963134766,
      "rewards/rejected": -12.279542922973633,
      "step": 3850
    },
    {
      "epoch": 1.5404,
      "grad_norm": 0.0188511423766613,
      "learning_rate": 4.866666666666666e-07,
      "logits/chosen": -2.8232338428497314,
      "logits/rejected": -2.286341428756714,
      "logps/chosen": -101.89920043945312,
      "logps/rejected": -133.3670196533203,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1014033555984497,
      "rewards/margins": 9.084592819213867,
      "rewards/rejected": -7.983189582824707,
      "step": 3851
    },
    {
      "epoch": 1.5408,
      "grad_norm": 0.009634762071073055,
      "learning_rate": 4.865333333333333e-07,
      "logits/chosen": -2.9311420917510986,
      "logits/rejected": -2.432544231414795,
      "logps/chosen": -60.01909637451172,
      "logps/rejected": -146.00230407714844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9997928142547607,
      "rewards/margins": 10.242462158203125,
      "rewards/rejected": -9.242669105529785,
      "step": 3852
    },
    {
      "epoch": 1.5412,
      "grad_norm": 5.591257095336914,
      "learning_rate": 4.864e-07,
      "logits/chosen": -2.741901397705078,
      "logits/rejected": -2.3027429580688477,
      "logps/chosen": -97.57935333251953,
      "logps/rejected": -147.7825164794922,
      "loss": 0.0308,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3359927535057068,
      "rewards/margins": 9.080405235290527,
      "rewards/rejected": -8.744412422180176,
      "step": 3853
    },
    {
      "epoch": 1.5415999999999999,
      "grad_norm": 0.022522147744894028,
      "learning_rate": 4.862666666666667e-07,
      "logits/chosen": -2.7012672424316406,
      "logits/rejected": -2.134805202484131,
      "logps/chosen": -56.03079605102539,
      "logps/rejected": -176.27992248535156,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.17721068859100342,
      "rewards/margins": 11.0238618850708,
      "rewards/rejected": -11.201072692871094,
      "step": 3854
    },
    {
      "epoch": 1.542,
      "grad_norm": 0.0008987531764432788,
      "learning_rate": 4.861333333333333e-07,
      "logits/chosen": -2.4475371837615967,
      "logits/rejected": -1.5165536403656006,
      "logps/chosen": -154.36196899414062,
      "logps/rejected": -192.1248016357422,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7496970891952515,
      "rewards/margins": 12.775755882263184,
      "rewards/rejected": -11.026058197021484,
      "step": 3855
    },
    {
      "epoch": 1.5424,
      "grad_norm": 0.9688804745674133,
      "learning_rate": 4.86e-07,
      "logits/chosen": -2.9624500274658203,
      "logits/rejected": -2.4203457832336426,
      "logps/chosen": -76.5055923461914,
      "logps/rejected": -136.79373168945312,
      "loss": 0.0061,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1623849868774414,
      "rewards/margins": 8.793872833251953,
      "rewards/rejected": -7.631487846374512,
      "step": 3856
    },
    {
      "epoch": 1.5428,
      "grad_norm": 0.0004558487853500992,
      "learning_rate": 4.858666666666667e-07,
      "logits/chosen": -2.778963088989258,
      "logits/rejected": -1.8322092294692993,
      "logps/chosen": -118.3360824584961,
      "logps/rejected": -209.87966918945312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.19646680355072021,
      "rewards/margins": 14.164310455322266,
      "rewards/rejected": -14.360776901245117,
      "step": 3857
    },
    {
      "epoch": 1.5432000000000001,
      "grad_norm": 0.08476797491312027,
      "learning_rate": 4.857333333333334e-07,
      "logits/chosen": -2.771613597869873,
      "logits/rejected": -2.145434856414795,
      "logps/chosen": -196.3294677734375,
      "logps/rejected": -175.089599609375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5970451831817627,
      "rewards/margins": 8.802759170532227,
      "rewards/rejected": -10.399805068969727,
      "step": 3858
    },
    {
      "epoch": 1.5436,
      "grad_norm": 0.0075064306147396564,
      "learning_rate": 4.856e-07,
      "logits/chosen": -2.865471839904785,
      "logits/rejected": -2.0490541458129883,
      "logps/chosen": -79.32109069824219,
      "logps/rejected": -158.640869140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1248459815979004,
      "rewards/margins": 11.274982452392578,
      "rewards/rejected": -10.150136947631836,
      "step": 3859
    },
    {
      "epoch": 1.544,
      "grad_norm": 0.10491091012954712,
      "learning_rate": 4.854666666666666e-07,
      "logits/chosen": -2.465059757232666,
      "logits/rejected": -2.239063262939453,
      "logps/chosen": -165.25546264648438,
      "logps/rejected": -181.0197296142578,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.230269193649292,
      "rewards/margins": 8.425893783569336,
      "rewards/rejected": -11.65616226196289,
      "step": 3860
    },
    {
      "epoch": 1.5444,
      "grad_norm": 0.20779064297676086,
      "learning_rate": 4.853333333333333e-07,
      "logits/chosen": -2.6408023834228516,
      "logits/rejected": -2.1982080936431885,
      "logps/chosen": -95.25621032714844,
      "logps/rejected": -93.90602111816406,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.05001678317785263,
      "rewards/margins": 6.776988983154297,
      "rewards/rejected": -6.827005386352539,
      "step": 3861
    },
    {
      "epoch": 1.5448,
      "grad_norm": 0.19401739537715912,
      "learning_rate": 4.852e-07,
      "logits/chosen": -2.801787853240967,
      "logits/rejected": -2.3006980419158936,
      "logps/chosen": -120.15899658203125,
      "logps/rejected": -190.22337341308594,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5219429135322571,
      "rewards/margins": 9.549850463867188,
      "rewards/rejected": -10.071793556213379,
      "step": 3862
    },
    {
      "epoch": 1.5452,
      "grad_norm": 0.03153824433684349,
      "learning_rate": 4.850666666666666e-07,
      "logits/chosen": -2.8817505836486816,
      "logits/rejected": -2.2849674224853516,
      "logps/chosen": -137.312744140625,
      "logps/rejected": -181.38827514648438,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6173528432846069,
      "rewards/margins": 11.433671951293945,
      "rewards/rejected": -12.051025390625,
      "step": 3863
    },
    {
      "epoch": 1.5455999999999999,
      "grad_norm": 0.06883406639099121,
      "learning_rate": 4.849333333333333e-07,
      "logits/chosen": -3.191685199737549,
      "logits/rejected": -2.6924657821655273,
      "logps/chosen": -96.1291275024414,
      "logps/rejected": -123.42207336425781,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7988243103027344,
      "rewards/margins": 7.540801525115967,
      "rewards/rejected": -6.741977214813232,
      "step": 3864
    },
    {
      "epoch": 1.546,
      "grad_norm": 62.023193359375,
      "learning_rate": 4.848e-07,
      "logits/chosen": -2.7795190811157227,
      "logits/rejected": -2.5005698204040527,
      "logps/chosen": -159.57540893554688,
      "logps/rejected": -144.207275390625,
      "loss": 0.4554,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -3.4773974418640137,
      "rewards/margins": 5.7537007331848145,
      "rewards/rejected": -9.231098175048828,
      "step": 3865
    },
    {
      "epoch": 1.5464,
      "grad_norm": 1.4441438913345337,
      "learning_rate": 4.846666666666667e-07,
      "logits/chosen": -2.6883199214935303,
      "logits/rejected": -2.6768174171447754,
      "logps/chosen": -118.44776916503906,
      "logps/rejected": -94.88343811035156,
      "loss": 0.0106,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3347336053848267,
      "rewards/margins": 4.638558387756348,
      "rewards/rejected": -5.973292350769043,
      "step": 3866
    },
    {
      "epoch": 1.5468,
      "grad_norm": 0.6304996013641357,
      "learning_rate": 4.845333333333333e-07,
      "logits/chosen": -2.646927833557129,
      "logits/rejected": -2.128811836242676,
      "logps/chosen": -95.54961395263672,
      "logps/rejected": -118.64485931396484,
      "loss": 0.0045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0853896141052246,
      "rewards/margins": 6.726688861846924,
      "rewards/rejected": -7.812078475952148,
      "step": 3867
    },
    {
      "epoch": 1.5472000000000001,
      "grad_norm": 0.003081989474594593,
      "learning_rate": 4.844e-07,
      "logits/chosen": -3.021182060241699,
      "logits/rejected": -2.5376834869384766,
      "logps/chosen": -53.218353271484375,
      "logps/rejected": -153.157958984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.102966070175171,
      "rewards/margins": 11.431358337402344,
      "rewards/rejected": -10.328392028808594,
      "step": 3868
    },
    {
      "epoch": 1.5476,
      "grad_norm": 0.7304610013961792,
      "learning_rate": 4.842666666666667e-07,
      "logits/chosen": -3.0493264198303223,
      "logits/rejected": -2.825814723968506,
      "logps/chosen": -85.03480529785156,
      "logps/rejected": -121.56482696533203,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5507416725158691,
      "rewards/margins": 6.291288375854492,
      "rewards/rejected": -7.842030048370361,
      "step": 3869
    },
    {
      "epoch": 1.548,
      "grad_norm": 0.026492824777960777,
      "learning_rate": 4.841333333333334e-07,
      "logits/chosen": -2.8118364810943604,
      "logits/rejected": -2.4573163986206055,
      "logps/chosen": -89.3722152709961,
      "logps/rejected": -189.81668090820312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6220111846923828,
      "rewards/margins": 10.989652633666992,
      "rewards/rejected": -11.611663818359375,
      "step": 3870
    },
    {
      "epoch": 1.5484,
      "grad_norm": 0.11812549084424973,
      "learning_rate": 4.839999999999999e-07,
      "logits/chosen": -2.9054136276245117,
      "logits/rejected": -2.8860816955566406,
      "logps/chosen": -93.9205322265625,
      "logps/rejected": -105.76707458496094,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8739913702011108,
      "rewards/margins": 7.538793087005615,
      "rewards/rejected": -6.664801597595215,
      "step": 3871
    },
    {
      "epoch": 1.5488,
      "grad_norm": 0.15700000524520874,
      "learning_rate": 4.838666666666666e-07,
      "logits/chosen": -2.937685012817383,
      "logits/rejected": -2.4659628868103027,
      "logps/chosen": -69.12025451660156,
      "logps/rejected": -114.24586486816406,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.18358191847801208,
      "rewards/margins": 7.060826301574707,
      "rewards/rejected": -7.244408130645752,
      "step": 3872
    },
    {
      "epoch": 1.5492,
      "grad_norm": 0.18647798895835876,
      "learning_rate": 4.837333333333333e-07,
      "logits/chosen": -2.8565521240234375,
      "logits/rejected": -2.507253408432007,
      "logps/chosen": -107.75663757324219,
      "logps/rejected": -203.0453643798828,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2850513458251953,
      "rewards/margins": 11.500286102294922,
      "rewards/rejected": -11.785337448120117,
      "step": 3873
    },
    {
      "epoch": 1.5495999999999999,
      "grad_norm": 2.4418883323669434,
      "learning_rate": 4.835999999999999e-07,
      "logits/chosen": -2.763117551803589,
      "logits/rejected": -2.45644474029541,
      "logps/chosen": -53.73255920410156,
      "logps/rejected": -125.90623474121094,
      "loss": 0.0146,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6291465759277344,
      "rewards/margins": 7.118869781494141,
      "rewards/rejected": -7.748016357421875,
      "step": 3874
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.05250919982790947,
      "learning_rate": 4.834666666666666e-07,
      "logits/chosen": -2.619678258895874,
      "logits/rejected": -1.7833049297332764,
      "logps/chosen": -90.67417907714844,
      "logps/rejected": -263.4635009765625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5243118405342102,
      "rewards/margins": 10.03628158569336,
      "rewards/rejected": -9.511970520019531,
      "step": 3875
    },
    {
      "epoch": 1.5504,
      "grad_norm": 0.034016285091638565,
      "learning_rate": 4.833333333333333e-07,
      "logits/chosen": -2.5629706382751465,
      "logits/rejected": -2.1662657260894775,
      "logps/chosen": -129.300048828125,
      "logps/rejected": -155.86697387695312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8814874887466431,
      "rewards/margins": 9.164688110351562,
      "rewards/rejected": -10.046175956726074,
      "step": 3876
    },
    {
      "epoch": 1.5508,
      "grad_norm": 0.0026180443819612265,
      "learning_rate": 4.832e-07,
      "logits/chosen": -2.5820493698120117,
      "logits/rejected": -1.8658347129821777,
      "logps/chosen": -79.14363098144531,
      "logps/rejected": -276.1542053222656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3336330652236938,
      "rewards/margins": 14.389104843139648,
      "rewards/rejected": -13.055473327636719,
      "step": 3877
    },
    {
      "epoch": 1.5512000000000001,
      "grad_norm": 0.03932790085673332,
      "learning_rate": 4.830666666666666e-07,
      "logits/chosen": -3.0401341915130615,
      "logits/rejected": -2.56384539604187,
      "logps/chosen": -103.98847198486328,
      "logps/rejected": -144.3009033203125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.013586223125457764,
      "rewards/margins": 8.507157325744629,
      "rewards/rejected": -8.520743370056152,
      "step": 3878
    },
    {
      "epoch": 1.5516,
      "grad_norm": 0.038514576852321625,
      "learning_rate": 4.829333333333333e-07,
      "logits/chosen": -2.8217110633850098,
      "logits/rejected": -1.9139976501464844,
      "logps/chosen": -100.51890563964844,
      "logps/rejected": -150.04176330566406,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.288290798664093,
      "rewards/margins": 9.57044506072998,
      "rewards/rejected": -9.282154083251953,
      "step": 3879
    },
    {
      "epoch": 1.552,
      "grad_norm": 0.16891105473041534,
      "learning_rate": 4.828e-07,
      "logits/chosen": -2.858057975769043,
      "logits/rejected": -2.5746593475341797,
      "logps/chosen": -97.57622528076172,
      "logps/rejected": -132.02001953125,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16860809922218323,
      "rewards/margins": 7.904945373535156,
      "rewards/rejected": -7.736336708068848,
      "step": 3880
    },
    {
      "epoch": 1.5524,
      "grad_norm": 0.005135344807058573,
      "learning_rate": 4.826666666666666e-07,
      "logits/chosen": -2.8692822456359863,
      "logits/rejected": -2.086613655090332,
      "logps/chosen": -40.25701904296875,
      "logps/rejected": -145.40814208984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3809435367584229,
      "rewards/margins": 11.019102096557617,
      "rewards/rejected": -9.638158798217773,
      "step": 3881
    },
    {
      "epoch": 1.5528,
      "grad_norm": 0.018300455063581467,
      "learning_rate": 4.825333333333333e-07,
      "logits/chosen": -2.7078683376312256,
      "logits/rejected": -2.01560378074646,
      "logps/chosen": -79.27197265625,
      "logps/rejected": -129.89227294921875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4179502725601196,
      "rewards/margins": 9.13079833984375,
      "rewards/rejected": -7.712847709655762,
      "step": 3882
    },
    {
      "epoch": 1.5532,
      "grad_norm": 0.030626103281974792,
      "learning_rate": 4.823999999999999e-07,
      "logits/chosen": -2.581730842590332,
      "logits/rejected": -2.0217933654785156,
      "logps/chosen": -123.29953002929688,
      "logps/rejected": -181.78848266601562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08851508796215057,
      "rewards/margins": 10.253419876098633,
      "rewards/rejected": -10.341935157775879,
      "step": 3883
    },
    {
      "epoch": 1.5535999999999999,
      "grad_norm": 1.0794477462768555,
      "learning_rate": 4.822666666666666e-07,
      "logits/chosen": -2.569782018661499,
      "logits/rejected": -2.0318596363067627,
      "logps/chosen": -65.21431732177734,
      "logps/rejected": -108.75541687011719,
      "loss": 0.0083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23065602779388428,
      "rewards/margins": 5.792880535125732,
      "rewards/rejected": -5.562224388122559,
      "step": 3884
    },
    {
      "epoch": 1.554,
      "grad_norm": 2.2959160804748535,
      "learning_rate": 4.821333333333333e-07,
      "logits/chosen": -2.64676570892334,
      "logits/rejected": -2.233841896057129,
      "logps/chosen": -117.193115234375,
      "logps/rejected": -129.88624572753906,
      "loss": 0.0096,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8289774656295776,
      "rewards/margins": 6.390339374542236,
      "rewards/rejected": -7.219316482543945,
      "step": 3885
    },
    {
      "epoch": 1.5544,
      "grad_norm": 0.011898865923285484,
      "learning_rate": 4.82e-07,
      "logits/chosen": -2.5474560260772705,
      "logits/rejected": -1.9791853427886963,
      "logps/chosen": -202.18751525878906,
      "logps/rejected": -207.276611328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6801483631134033,
      "rewards/margins": 10.374032974243164,
      "rewards/rejected": -12.054182052612305,
      "step": 3886
    },
    {
      "epoch": 1.5548,
      "grad_norm": 5.526773452758789,
      "learning_rate": 4.818666666666667e-07,
      "logits/chosen": -2.916059970855713,
      "logits/rejected": -2.627727508544922,
      "logps/chosen": -93.11678314208984,
      "logps/rejected": -111.31428527832031,
      "loss": 0.0443,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1161930114030838,
      "rewards/margins": 6.694109916687012,
      "rewards/rejected": -6.577916622161865,
      "step": 3887
    },
    {
      "epoch": 1.5552000000000001,
      "grad_norm": 0.4634278416633606,
      "learning_rate": 4.817333333333333e-07,
      "logits/chosen": -2.48734712600708,
      "logits/rejected": -2.350552558898926,
      "logps/chosen": -143.9808807373047,
      "logps/rejected": -121.87196350097656,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2208404541015625,
      "rewards/margins": 5.762172698974609,
      "rewards/rejected": -6.983013153076172,
      "step": 3888
    },
    {
      "epoch": 1.5556,
      "grad_norm": 1.0129400491714478,
      "learning_rate": 4.816e-07,
      "logits/chosen": -3.1210010051727295,
      "logits/rejected": -3.016885280609131,
      "logps/chosen": -74.44728088378906,
      "logps/rejected": -102.0448989868164,
      "loss": 0.0071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3645656704902649,
      "rewards/margins": 6.595889091491699,
      "rewards/rejected": -6.231323719024658,
      "step": 3889
    },
    {
      "epoch": 1.556,
      "grad_norm": 0.25276944041252136,
      "learning_rate": 4.814666666666667e-07,
      "logits/chosen": -3.0086724758148193,
      "logits/rejected": -2.7125861644744873,
      "logps/chosen": -69.59165954589844,
      "logps/rejected": -120.35040283203125,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6274860501289368,
      "rewards/margins": 7.486948490142822,
      "rewards/rejected": -6.859462738037109,
      "step": 3890
    },
    {
      "epoch": 1.5564,
      "grad_norm": 0.1779889464378357,
      "learning_rate": 4.813333333333334e-07,
      "logits/chosen": -3.085415840148926,
      "logits/rejected": -2.4818456172943115,
      "logps/chosen": -50.569297790527344,
      "logps/rejected": -119.63960266113281,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.49750593304634094,
      "rewards/margins": 8.557424545288086,
      "rewards/rejected": -8.059918403625488,
      "step": 3891
    },
    {
      "epoch": 1.5568,
      "grad_norm": 0.00464183185249567,
      "learning_rate": 4.812e-07,
      "logits/chosen": -2.9047293663024902,
      "logits/rejected": -2.06472110748291,
      "logps/chosen": -55.464725494384766,
      "logps/rejected": -174.79928588867188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2556782066822052,
      "rewards/margins": 10.871950149536133,
      "rewards/rejected": -10.61627197265625,
      "step": 3892
    },
    {
      "epoch": 1.5572,
      "grad_norm": 0.0355449803173542,
      "learning_rate": 4.810666666666666e-07,
      "logits/chosen": -2.8188576698303223,
      "logits/rejected": -2.272505283355713,
      "logps/chosen": -68.5484848022461,
      "logps/rejected": -197.0493621826172,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2752397060394287,
      "rewards/margins": 11.932762145996094,
      "rewards/rejected": -10.657522201538086,
      "step": 3893
    },
    {
      "epoch": 1.5575999999999999,
      "grad_norm": 0.2624101936817169,
      "learning_rate": 4.809333333333333e-07,
      "logits/chosen": -2.3558056354522705,
      "logits/rejected": -1.8406751155853271,
      "logps/chosen": -126.34706115722656,
      "logps/rejected": -191.16567993164062,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2289336919784546,
      "rewards/margins": 10.796476364135742,
      "rewards/rejected": -12.025410652160645,
      "step": 3894
    },
    {
      "epoch": 1.558,
      "grad_norm": 0.0336407907307148,
      "learning_rate": 4.808e-07,
      "logits/chosen": -2.8603062629699707,
      "logits/rejected": -2.1641316413879395,
      "logps/chosen": -146.5186767578125,
      "logps/rejected": -142.12200927734375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2197704315185547,
      "rewards/margins": 9.567195892333984,
      "rewards/rejected": -9.34742546081543,
      "step": 3895
    },
    {
      "epoch": 1.5584,
      "grad_norm": 0.07814996689558029,
      "learning_rate": 4.806666666666667e-07,
      "logits/chosen": -2.806896686553955,
      "logits/rejected": -2.1691110134124756,
      "logps/chosen": -81.63124084472656,
      "logps/rejected": -155.18020629882812,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.779510498046875,
      "rewards/margins": 9.60592269897461,
      "rewards/rejected": -8.826412200927734,
      "step": 3896
    },
    {
      "epoch": 1.5588,
      "grad_norm": 0.25793319940567017,
      "learning_rate": 4.805333333333333e-07,
      "logits/chosen": -2.592571973800659,
      "logits/rejected": -2.2436020374298096,
      "logps/chosen": -178.56143188476562,
      "logps/rejected": -148.26089477539062,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7380051612854004,
      "rewards/margins": 6.342314720153809,
      "rewards/rejected": -8.080320358276367,
      "step": 3897
    },
    {
      "epoch": 1.5592000000000001,
      "grad_norm": 0.11489173769950867,
      "learning_rate": 4.804e-07,
      "logits/chosen": -2.59112811088562,
      "logits/rejected": -2.163240909576416,
      "logps/chosen": -107.72584533691406,
      "logps/rejected": -150.78453063964844,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1918514370918274,
      "rewards/margins": 9.401500701904297,
      "rewards/rejected": -9.209650039672852,
      "step": 3898
    },
    {
      "epoch": 1.5596,
      "grad_norm": 0.001988503383472562,
      "learning_rate": 4.802666666666667e-07,
      "logits/chosen": -2.6989405155181885,
      "logits/rejected": -2.208127498626709,
      "logps/chosen": -82.86446380615234,
      "logps/rejected": -217.731689453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2802507877349854,
      "rewards/margins": 12.65619945526123,
      "rewards/rejected": -11.375947952270508,
      "step": 3899
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.3419018089771271,
      "learning_rate": 4.801333333333334e-07,
      "logits/chosen": -2.501742362976074,
      "logits/rejected": -2.1481285095214844,
      "logps/chosen": -135.61459350585938,
      "logps/rejected": -149.07254028320312,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.3761491775512695,
      "rewards/margins": 6.646920204162598,
      "rewards/rejected": -9.023069381713867,
      "step": 3900
    },
    {
      "epoch": 1.5604,
      "grad_norm": 0.21750672161579132,
      "learning_rate": 4.8e-07,
      "logits/chosen": -2.869103193283081,
      "logits/rejected": -2.4611432552337646,
      "logps/chosen": -104.95683288574219,
      "logps/rejected": -112.31263732910156,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05745011568069458,
      "rewards/margins": 6.966813087463379,
      "rewards/rejected": -6.90936279296875,
      "step": 3901
    },
    {
      "epoch": 1.5608,
      "grad_norm": 0.000717836432158947,
      "learning_rate": 4.798666666666666e-07,
      "logits/chosen": -2.4285330772399902,
      "logits/rejected": -1.6850738525390625,
      "logps/chosen": -84.90438842773438,
      "logps/rejected": -283.6716613769531,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4792931079864502,
      "rewards/margins": 13.88714599609375,
      "rewards/rejected": -12.407853126525879,
      "step": 3902
    },
    {
      "epoch": 1.5612,
      "grad_norm": 0.008079316467046738,
      "learning_rate": 4.797333333333333e-07,
      "logits/chosen": -2.8586463928222656,
      "logits/rejected": -2.332813262939453,
      "logps/chosen": -111.15154266357422,
      "logps/rejected": -187.5237274169922,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.09636873006820679,
      "rewards/margins": 12.861422538757324,
      "rewards/rejected": -12.957791328430176,
      "step": 3903
    },
    {
      "epoch": 1.5615999999999999,
      "grad_norm": 0.0828106552362442,
      "learning_rate": 4.796e-07,
      "logits/chosen": -2.4514455795288086,
      "logits/rejected": -2.1359405517578125,
      "logps/chosen": -79.62080383300781,
      "logps/rejected": -118.22232818603516,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.604007363319397,
      "rewards/margins": 8.760746002197266,
      "rewards/rejected": -7.15673828125,
      "step": 3904
    },
    {
      "epoch": 1.562,
      "grad_norm": 1.0776939392089844,
      "learning_rate": 4.794666666666666e-07,
      "logits/chosen": -2.688767910003662,
      "logits/rejected": -2.1856882572174072,
      "logps/chosen": -126.49508666992188,
      "logps/rejected": -164.92227172851562,
      "loss": 0.0075,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1053991317749023,
      "rewards/margins": 8.230330467224121,
      "rewards/rejected": -9.335729598999023,
      "step": 3905
    },
    {
      "epoch": 1.5624,
      "grad_norm": 0.15085247159004211,
      "learning_rate": 4.793333333333333e-07,
      "logits/chosen": -2.908992052078247,
      "logits/rejected": -2.4094748497009277,
      "logps/chosen": -55.329769134521484,
      "logps/rejected": -140.9097442626953,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.768550157546997,
      "rewards/margins": 11.104628562927246,
      "rewards/rejected": -9.336077690124512,
      "step": 3906
    },
    {
      "epoch": 1.5628,
      "grad_norm": 0.031159888952970505,
      "learning_rate": 4.792e-07,
      "logits/chosen": -2.578808307647705,
      "logits/rejected": -2.1728386878967285,
      "logps/chosen": -101.4781494140625,
      "logps/rejected": -205.09213256835938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6858307123184204,
      "rewards/margins": 11.769240379333496,
      "rewards/rejected": -11.083410263061523,
      "step": 3907
    },
    {
      "epoch": 1.5632000000000001,
      "grad_norm": 15.98867130279541,
      "learning_rate": 4.790666666666666e-07,
      "logits/chosen": -2.56447172164917,
      "logits/rejected": -2.065577507019043,
      "logps/chosen": -143.99029541015625,
      "logps/rejected": -256.630126953125,
      "loss": 0.0652,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.243080496788025,
      "rewards/margins": 11.261235237121582,
      "rewards/rejected": -12.504315376281738,
      "step": 3908
    },
    {
      "epoch": 1.5636,
      "grad_norm": 0.2108575999736786,
      "learning_rate": 4.789333333333333e-07,
      "logits/chosen": -2.800920248031616,
      "logits/rejected": -2.7622814178466797,
      "logps/chosen": -134.85665893554688,
      "logps/rejected": -129.9635772705078,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.37176090478897095,
      "rewards/margins": 6.947009086608887,
      "rewards/rejected": -7.318770408630371,
      "step": 3909
    },
    {
      "epoch": 1.564,
      "grad_norm": 0.0003308738814666867,
      "learning_rate": 4.788e-07,
      "logits/chosen": -2.7143301963806152,
      "logits/rejected": -1.9314801692962646,
      "logps/chosen": -169.51425170898438,
      "logps/rejected": -251.4768524169922,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7134795784950256,
      "rewards/margins": 18.105642318725586,
      "rewards/rejected": -17.392162322998047,
      "step": 3910
    },
    {
      "epoch": 1.5644,
      "grad_norm": 0.03502465412020683,
      "learning_rate": 4.786666666666667e-07,
      "logits/chosen": -2.8717918395996094,
      "logits/rejected": -2.2131731510162354,
      "logps/chosen": -97.95079803466797,
      "logps/rejected": -141.3381805419922,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6375153064727783,
      "rewards/margins": 9.560195922851562,
      "rewards/rejected": -8.92268180847168,
      "step": 3911
    },
    {
      "epoch": 1.5648,
      "grad_norm": 0.0005574519163928926,
      "learning_rate": 4.785333333333333e-07,
      "logits/chosen": -2.997443675994873,
      "logits/rejected": -2.1323957443237305,
      "logps/chosen": -100.76219177246094,
      "logps/rejected": -202.07418823242188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7852687835693359,
      "rewards/margins": 13.35738468170166,
      "rewards/rejected": -12.572115898132324,
      "step": 3912
    },
    {
      "epoch": 1.5652,
      "grad_norm": 0.0014228778891265392,
      "learning_rate": 4.783999999999999e-07,
      "logits/chosen": -2.6882340908050537,
      "logits/rejected": -1.955646276473999,
      "logps/chosen": -95.1385269165039,
      "logps/rejected": -160.66207885742188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2575443983078003,
      "rewards/margins": 12.071369171142578,
      "rewards/rejected": -10.813825607299805,
      "step": 3913
    },
    {
      "epoch": 1.5655999999999999,
      "grad_norm": 9.38448429107666,
      "learning_rate": 4.782666666666666e-07,
      "logits/chosen": -2.3062350749969482,
      "logits/rejected": -1.9219582080841064,
      "logps/chosen": -240.9186553955078,
      "logps/rejected": -229.63543701171875,
      "loss": 0.0259,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.153470516204834,
      "rewards/margins": 7.9340033531188965,
      "rewards/rejected": -12.08747386932373,
      "step": 3914
    },
    {
      "epoch": 1.5659999999999998,
      "grad_norm": 0.004806716926395893,
      "learning_rate": 4.781333333333333e-07,
      "logits/chosen": -2.7548348903656006,
      "logits/rejected": -2.1012771129608154,
      "logps/chosen": -145.06466674804688,
      "logps/rejected": -187.8025360107422,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5453258752822876,
      "rewards/margins": 10.884336471557617,
      "rewards/rejected": -11.429662704467773,
      "step": 3915
    },
    {
      "epoch": 1.5664,
      "grad_norm": 1.4831933975219727,
      "learning_rate": 4.779999999999999e-07,
      "logits/chosen": -2.946073532104492,
      "logits/rejected": -2.775867462158203,
      "logps/chosen": -103.03494262695312,
      "logps/rejected": -141.54600524902344,
      "loss": 0.0069,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7182258367538452,
      "rewards/margins": 8.479361534118652,
      "rewards/rejected": -7.761136054992676,
      "step": 3916
    },
    {
      "epoch": 1.5668,
      "grad_norm": 0.007142969407141209,
      "learning_rate": 4.778666666666666e-07,
      "logits/chosen": -2.7193877696990967,
      "logits/rejected": -2.2518930435180664,
      "logps/chosen": -87.14056396484375,
      "logps/rejected": -131.75576782226562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8896114826202393,
      "rewards/margins": 10.16753101348877,
      "rewards/rejected": -8.27791976928711,
      "step": 3917
    },
    {
      "epoch": 1.5672000000000001,
      "grad_norm": 0.029525982216000557,
      "learning_rate": 4.777333333333333e-07,
      "logits/chosen": -2.7191758155822754,
      "logits/rejected": -2.7544167041778564,
      "logps/chosen": -128.16119384765625,
      "logps/rejected": -123.38822937011719,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5288757085800171,
      "rewards/margins": 8.718978881835938,
      "rewards/rejected": -8.190102577209473,
      "step": 3918
    },
    {
      "epoch": 1.5676,
      "grad_norm": 26.794620513916016,
      "learning_rate": 4.776e-07,
      "logits/chosen": -2.924422264099121,
      "logits/rejected": -2.8241519927978516,
      "logps/chosen": -93.25407409667969,
      "logps/rejected": -76.92753601074219,
      "loss": 0.1837,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.235724925994873,
      "rewards/margins": 2.695551872253418,
      "rewards/rejected": -4.931277275085449,
      "step": 3919
    },
    {
      "epoch": 1.568,
      "grad_norm": 0.00034159398637712,
      "learning_rate": 4.774666666666667e-07,
      "logits/chosen": -2.5998263359069824,
      "logits/rejected": -1.903444766998291,
      "logps/chosen": -213.84967041015625,
      "logps/rejected": -234.95570373535156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2376495599746704,
      "rewards/margins": 14.243016242980957,
      "rewards/rejected": -14.005367279052734,
      "step": 3920
    },
    {
      "epoch": 1.5684,
      "grad_norm": 1.557755470275879,
      "learning_rate": 4.773333333333333e-07,
      "logits/chosen": -2.863361358642578,
      "logits/rejected": -2.5984201431274414,
      "logps/chosen": -44.265869140625,
      "logps/rejected": -80.05342864990234,
      "loss": 0.0146,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40709152817726135,
      "rewards/margins": 5.855850696563721,
      "rewards/rejected": -5.448759078979492,
      "step": 3921
    },
    {
      "epoch": 1.5688,
      "grad_norm": 0.013911228626966476,
      "learning_rate": 4.772e-07,
      "logits/chosen": -3.009450912475586,
      "logits/rejected": -2.2607808113098145,
      "logps/chosen": -71.6662368774414,
      "logps/rejected": -179.07733154296875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0309514999389648,
      "rewards/margins": 11.388689994812012,
      "rewards/rejected": -10.357738494873047,
      "step": 3922
    },
    {
      "epoch": 1.5692,
      "grad_norm": 0.0012434811796993017,
      "learning_rate": 4.770666666666667e-07,
      "logits/chosen": -2.500013589859009,
      "logits/rejected": -1.7182728052139282,
      "logps/chosen": -124.42676544189453,
      "logps/rejected": -223.2886199951172,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.02360844612121582,
      "rewards/margins": 12.482361793518066,
      "rewards/rejected": -12.505970001220703,
      "step": 3923
    },
    {
      "epoch": 1.5695999999999999,
      "grad_norm": 0.23093697428703308,
      "learning_rate": 4.769333333333333e-07,
      "logits/chosen": -3.051443576812744,
      "logits/rejected": -2.7897133827209473,
      "logps/chosen": -53.37509536743164,
      "logps/rejected": -112.243896484375,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1333116590976715,
      "rewards/margins": 7.705891132354736,
      "rewards/rejected": -7.572579383850098,
      "step": 3924
    },
    {
      "epoch": 1.5699999999999998,
      "grad_norm": 0.08220487087965012,
      "learning_rate": 4.768e-07,
      "logits/chosen": -2.6933655738830566,
      "logits/rejected": -2.2136881351470947,
      "logps/chosen": -91.71234130859375,
      "logps/rejected": -127.00883483886719,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08076745271682739,
      "rewards/margins": 7.656117916107178,
      "rewards/rejected": -7.736885070800781,
      "step": 3925
    },
    {
      "epoch": 1.5704,
      "grad_norm": 0.002205201657488942,
      "learning_rate": 4.7666666666666667e-07,
      "logits/chosen": -2.485670566558838,
      "logits/rejected": -1.9324274063110352,
      "logps/chosen": -115.1019058227539,
      "logps/rejected": -224.7481689453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.06520974636077881,
      "rewards/margins": 12.669414520263672,
      "rewards/rejected": -12.734623908996582,
      "step": 3926
    },
    {
      "epoch": 1.5708,
      "grad_norm": 0.0024688339326530695,
      "learning_rate": 4.765333333333333e-07,
      "logits/chosen": -2.4922595024108887,
      "logits/rejected": -1.9031827449798584,
      "logps/chosen": -93.0459213256836,
      "logps/rejected": -230.84133911132812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10458546876907349,
      "rewards/margins": 11.681617736816406,
      "rewards/rejected": -11.786202430725098,
      "step": 3927
    },
    {
      "epoch": 1.5712000000000002,
      "grad_norm": 0.0013131349114701152,
      "learning_rate": 4.7639999999999995e-07,
      "logits/chosen": -2.9452786445617676,
      "logits/rejected": -2.044058322906494,
      "logps/chosen": -111.29310607910156,
      "logps/rejected": -189.00270080566406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7034404873847961,
      "rewards/margins": 12.192292213439941,
      "rewards/rejected": -11.488851547241211,
      "step": 3928
    },
    {
      "epoch": 1.5716,
      "grad_norm": 0.03566998243331909,
      "learning_rate": 4.7626666666666664e-07,
      "logits/chosen": -3.108785629272461,
      "logits/rejected": -2.4486498832702637,
      "logps/chosen": -45.47964859008789,
      "logps/rejected": -149.59567260742188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06413127481937408,
      "rewards/margins": 9.327860832214355,
      "rewards/rejected": -9.263729095458984,
      "step": 3929
    },
    {
      "epoch": 1.572,
      "grad_norm": 2.2397968769073486,
      "learning_rate": 4.7613333333333334e-07,
      "logits/chosen": -2.8416190147399902,
      "logits/rejected": -2.470903158187866,
      "logps/chosen": -114.95419311523438,
      "logps/rejected": -127.24710845947266,
      "loss": 0.0096,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.07349511981010437,
      "rewards/margins": 7.819809913635254,
      "rewards/rejected": -7.89330530166626,
      "step": 3930
    },
    {
      "epoch": 1.5724,
      "grad_norm": 0.16113847494125366,
      "learning_rate": 4.76e-07,
      "logits/chosen": -3.138843536376953,
      "logits/rejected": -2.6319046020507812,
      "logps/chosen": -69.56808471679688,
      "logps/rejected": -127.75310516357422,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.38421326875686646,
      "rewards/margins": 7.6109185218811035,
      "rewards/rejected": -7.995131492614746,
      "step": 3931
    },
    {
      "epoch": 1.5728,
      "grad_norm": 0.26298728585243225,
      "learning_rate": 4.758666666666666e-07,
      "logits/chosen": -2.3916726112365723,
      "logits/rejected": -1.8895869255065918,
      "logps/chosen": -118.07340240478516,
      "logps/rejected": -134.9021759033203,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.86424720287323,
      "rewards/margins": 9.84307861328125,
      "rewards/rejected": -8.97883129119873,
      "step": 3932
    },
    {
      "epoch": 1.5732,
      "grad_norm": 0.040835294872522354,
      "learning_rate": 4.757333333333333e-07,
      "logits/chosen": -2.959949493408203,
      "logits/rejected": -2.4659018516540527,
      "logps/chosen": -94.96846008300781,
      "logps/rejected": -223.51829528808594,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1345484256744385,
      "rewards/margins": 11.434839248657227,
      "rewards/rejected": -12.569387435913086,
      "step": 3933
    },
    {
      "epoch": 1.5735999999999999,
      "grad_norm": 0.27315258979797363,
      "learning_rate": 4.756e-07,
      "logits/chosen": -2.682915210723877,
      "logits/rejected": -1.7017037868499756,
      "logps/chosen": -116.10079956054688,
      "logps/rejected": -176.49560546875,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.609789252281189,
      "rewards/margins": 9.222871780395508,
      "rewards/rejected": -10.832661628723145,
      "step": 3934
    },
    {
      "epoch": 1.5739999999999998,
      "grad_norm": 4.010223388671875,
      "learning_rate": 4.7546666666666664e-07,
      "logits/chosen": -2.489250898361206,
      "logits/rejected": -2.063690662384033,
      "logps/chosen": -209.66847229003906,
      "logps/rejected": -153.46249389648438,
      "loss": 0.0185,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1389052867889404,
      "rewards/margins": 7.666021347045898,
      "rewards/rejected": -8.804926872253418,
      "step": 3935
    },
    {
      "epoch": 1.5744,
      "grad_norm": 0.03158949315547943,
      "learning_rate": 4.7533333333333333e-07,
      "logits/chosen": -2.812685966491699,
      "logits/rejected": -2.140136241912842,
      "logps/chosen": -63.161556243896484,
      "logps/rejected": -143.47677612304688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4605660438537598,
      "rewards/margins": 10.38171672821045,
      "rewards/rejected": -8.921150207519531,
      "step": 3936
    },
    {
      "epoch": 1.5748,
      "grad_norm": 0.7653211355209351,
      "learning_rate": 4.7519999999999997e-07,
      "logits/chosen": -3.01633620262146,
      "logits/rejected": -2.8479323387145996,
      "logps/chosen": -77.5716552734375,
      "logps/rejected": -126.61168670654297,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07545816898345947,
      "rewards/margins": 7.676531791687012,
      "rewards/rejected": -7.601073741912842,
      "step": 3937
    },
    {
      "epoch": 1.5752000000000002,
      "grad_norm": 0.3457705080509186,
      "learning_rate": 4.7506666666666666e-07,
      "logits/chosen": -2.77803897857666,
      "logits/rejected": -2.5903115272521973,
      "logps/chosen": -62.636924743652344,
      "logps/rejected": -117.81148529052734,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0056836605072021484,
      "rewards/margins": 8.518442153930664,
      "rewards/rejected": -8.524126052856445,
      "step": 3938
    },
    {
      "epoch": 1.5756000000000001,
      "grad_norm": 0.010422454215586185,
      "learning_rate": 4.749333333333333e-07,
      "logits/chosen": -3.1323111057281494,
      "logits/rejected": -2.625871181488037,
      "logps/chosen": -68.58352661132812,
      "logps/rejected": -163.52069091796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14314496517181396,
      "rewards/margins": 9.948100090026855,
      "rewards/rejected": -9.804954528808594,
      "step": 3939
    },
    {
      "epoch": 1.576,
      "grad_norm": 0.017002984881401062,
      "learning_rate": 4.748e-07,
      "logits/chosen": -2.59917950630188,
      "logits/rejected": -2.2191715240478516,
      "logps/chosen": -75.41455078125,
      "logps/rejected": -190.7903289794922,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.36245882511138916,
      "rewards/margins": 10.865578651428223,
      "rewards/rejected": -11.228036880493164,
      "step": 3940
    },
    {
      "epoch": 1.5764,
      "grad_norm": 0.09359219670295715,
      "learning_rate": 4.746666666666667e-07,
      "logits/chosen": -2.885979652404785,
      "logits/rejected": -2.167905807495117,
      "logps/chosen": -114.87725830078125,
      "logps/rejected": -184.69189453125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6536622643470764,
      "rewards/margins": 9.329170227050781,
      "rewards/rejected": -9.982832908630371,
      "step": 3941
    },
    {
      "epoch": 1.5768,
      "grad_norm": 0.11470311880111694,
      "learning_rate": 4.7453333333333327e-07,
      "logits/chosen": -2.8086113929748535,
      "logits/rejected": -2.4753007888793945,
      "logps/chosen": -39.91130828857422,
      "logps/rejected": -145.71412658691406,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06285686790943146,
      "rewards/margins": 8.860837936401367,
      "rewards/rejected": -8.797980308532715,
      "step": 3942
    },
    {
      "epoch": 1.5772,
      "grad_norm": 0.1801001876592636,
      "learning_rate": 4.7439999999999996e-07,
      "logits/chosen": -2.975759506225586,
      "logits/rejected": -3.050351619720459,
      "logps/chosen": -66.77578735351562,
      "logps/rejected": -112.05062866210938,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9981975555419922,
      "rewards/margins": 6.928441524505615,
      "rewards/rejected": -5.930243968963623,
      "step": 3943
    },
    {
      "epoch": 1.5776,
      "grad_norm": 0.106386698782444,
      "learning_rate": 4.7426666666666665e-07,
      "logits/chosen": -2.659142017364502,
      "logits/rejected": -2.1026391983032227,
      "logps/chosen": -107.92672729492188,
      "logps/rejected": -155.25213623046875,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.683550238609314,
      "rewards/margins": 10.798304557800293,
      "rewards/rejected": -10.114754676818848,
      "step": 3944
    },
    {
      "epoch": 1.5779999999999998,
      "grad_norm": 2.817232370376587,
      "learning_rate": 4.7413333333333334e-07,
      "logits/chosen": -2.7281150817871094,
      "logits/rejected": -2.4951364994049072,
      "logps/chosen": -191.3897705078125,
      "logps/rejected": -184.24240112304688,
      "loss": 0.0088,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.252794027328491,
      "rewards/margins": 9.52367115020752,
      "rewards/rejected": -12.776464462280273,
      "step": 3945
    },
    {
      "epoch": 1.5784,
      "grad_norm": 3.2384743690490723,
      "learning_rate": 4.7399999999999993e-07,
      "logits/chosen": -2.9747605323791504,
      "logits/rejected": -2.8128743171691895,
      "logps/chosen": -122.17095947265625,
      "logps/rejected": -164.5127410888672,
      "loss": 0.014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.06080588698387146,
      "rewards/margins": 7.87376594543457,
      "rewards/rejected": -7.934571266174316,
      "step": 3946
    },
    {
      "epoch": 1.5788,
      "grad_norm": 0.0815591961145401,
      "learning_rate": 4.738666666666666e-07,
      "logits/chosen": -2.5136213302612305,
      "logits/rejected": -2.0451138019561768,
      "logps/chosen": -156.72535705566406,
      "logps/rejected": -197.93531799316406,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.9778130054473877,
      "rewards/margins": 8.610897064208984,
      "rewards/rejected": -11.588709831237793,
      "step": 3947
    },
    {
      "epoch": 1.5792000000000002,
      "grad_norm": 0.03515676409006119,
      "learning_rate": 4.737333333333333e-07,
      "logits/chosen": -2.522732734680176,
      "logits/rejected": -2.0816588401794434,
      "logps/chosen": -225.50906372070312,
      "logps/rejected": -181.6986846923828,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.689180850982666,
      "rewards/margins": 9.92677116394043,
      "rewards/rejected": -11.615951538085938,
      "step": 3948
    },
    {
      "epoch": 1.5796000000000001,
      "grad_norm": 0.0018720021471381187,
      "learning_rate": 4.736e-07,
      "logits/chosen": -2.590132236480713,
      "logits/rejected": -1.9444001913070679,
      "logps/chosen": -129.8157958984375,
      "logps/rejected": -176.79217529296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6339370608329773,
      "rewards/margins": 11.928730010986328,
      "rewards/rejected": -11.294794082641602,
      "step": 3949
    },
    {
      "epoch": 1.58,
      "grad_norm": 2.930250644683838,
      "learning_rate": 4.7346666666666664e-07,
      "logits/chosen": -2.584102153778076,
      "logits/rejected": -2.2709810733795166,
      "logps/chosen": -86.26492309570312,
      "logps/rejected": -94.93705749511719,
      "loss": 0.0131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6125600934028625,
      "rewards/margins": 4.460745811462402,
      "rewards/rejected": -5.073305606842041,
      "step": 3950
    },
    {
      "epoch": 1.5804,
      "grad_norm": 0.005735128652304411,
      "learning_rate": 4.733333333333333e-07,
      "logits/chosen": -2.760303497314453,
      "logits/rejected": -1.9120197296142578,
      "logps/chosen": -140.7173309326172,
      "logps/rejected": -194.8634033203125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1791846752166748,
      "rewards/margins": 12.451824188232422,
      "rewards/rejected": -12.63100814819336,
      "step": 3951
    },
    {
      "epoch": 1.5808,
      "grad_norm": 0.0064828600734472275,
      "learning_rate": 4.732e-07,
      "logits/chosen": -2.533601999282837,
      "logits/rejected": -2.2568321228027344,
      "logps/chosen": -124.58439636230469,
      "logps/rejected": -224.03067016601562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6548198461532593,
      "rewards/margins": 10.644543647766113,
      "rewards/rejected": -11.299363136291504,
      "step": 3952
    },
    {
      "epoch": 1.5812,
      "grad_norm": 4.405664443969727,
      "learning_rate": 4.7306666666666667e-07,
      "logits/chosen": -2.6820874214172363,
      "logits/rejected": -2.019016981124878,
      "logps/chosen": -115.91876983642578,
      "logps/rejected": -132.80752563476562,
      "loss": 0.0311,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41835176944732666,
      "rewards/margins": 8.465346336364746,
      "rewards/rejected": -8.04699420928955,
      "step": 3953
    },
    {
      "epoch": 1.5816,
      "grad_norm": 0.015546070411801338,
      "learning_rate": 4.729333333333333e-07,
      "logits/chosen": -2.957111358642578,
      "logits/rejected": -2.5019924640655518,
      "logps/chosen": -95.17416381835938,
      "logps/rejected": -139.82302856445312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.45351943373680115,
      "rewards/margins": 9.536725997924805,
      "rewards/rejected": -9.990245819091797,
      "step": 3954
    },
    {
      "epoch": 1.5819999999999999,
      "grad_norm": 1.3353005647659302,
      "learning_rate": 4.728e-07,
      "logits/chosen": -3.0076022148132324,
      "logits/rejected": -2.94260311126709,
      "logps/chosen": -94.84564971923828,
      "logps/rejected": -80.16984558105469,
      "loss": 0.0171,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8218185305595398,
      "rewards/margins": 4.094199180603027,
      "rewards/rejected": -4.916017532348633,
      "step": 3955
    },
    {
      "epoch": 1.5824,
      "grad_norm": 0.0002715927257668227,
      "learning_rate": 4.7266666666666664e-07,
      "logits/chosen": -2.6190896034240723,
      "logits/rejected": -1.6823616027832031,
      "logps/chosen": -104.38682556152344,
      "logps/rejected": -215.05218505859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5480797290802002,
      "rewards/margins": 14.151569366455078,
      "rewards/rejected": -12.603489875793457,
      "step": 3956
    },
    {
      "epoch": 1.5828,
      "grad_norm": 0.03460388630628586,
      "learning_rate": 4.7253333333333333e-07,
      "logits/chosen": -2.7906975746154785,
      "logits/rejected": -2.0046026706695557,
      "logps/chosen": -49.59695816040039,
      "logps/rejected": -134.05995178222656,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1071404218673706,
      "rewards/margins": 9.615228652954102,
      "rewards/rejected": -8.508089065551758,
      "step": 3957
    },
    {
      "epoch": 1.5832000000000002,
      "grad_norm": 0.8060594797134399,
      "learning_rate": 4.7239999999999997e-07,
      "logits/chosen": -2.883240222930908,
      "logits/rejected": -2.5247466564178467,
      "logps/chosen": -114.04684448242188,
      "logps/rejected": -175.29415893554688,
      "loss": 0.0063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7976452112197876,
      "rewards/margins": 12.205316543579102,
      "rewards/rejected": -11.407670974731445,
      "step": 3958
    },
    {
      "epoch": 1.5836000000000001,
      "grad_norm": 0.0025769034400582314,
      "learning_rate": 4.7226666666666666e-07,
      "logits/chosen": -2.904419422149658,
      "logits/rejected": -2.0375585556030273,
      "logps/chosen": -66.18275451660156,
      "logps/rejected": -181.04122924804688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6839775443077087,
      "rewards/margins": 12.451902389526367,
      "rewards/rejected": -13.135880470275879,
      "step": 3959
    },
    {
      "epoch": 1.584,
      "grad_norm": 0.08300606906414032,
      "learning_rate": 4.7213333333333335e-07,
      "logits/chosen": -2.9974470138549805,
      "logits/rejected": -2.6718623638153076,
      "logps/chosen": -123.00395202636719,
      "logps/rejected": -122.36236572265625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35638999938964844,
      "rewards/margins": 8.316819190979004,
      "rewards/rejected": -7.9604291915893555,
      "step": 3960
    },
    {
      "epoch": 1.5844,
      "grad_norm": 1.9055438041687012,
      "learning_rate": 4.7199999999999994e-07,
      "logits/chosen": -3.029911994934082,
      "logits/rejected": -2.7993454933166504,
      "logps/chosen": -84.31901550292969,
      "logps/rejected": -134.07916259765625,
      "loss": 0.0116,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7980293035507202,
      "rewards/margins": 7.289710521697998,
      "rewards/rejected": -8.087739944458008,
      "step": 3961
    },
    {
      "epoch": 1.5848,
      "grad_norm": 0.01850678212940693,
      "learning_rate": 4.7186666666666663e-07,
      "logits/chosen": -2.709850788116455,
      "logits/rejected": -2.0980358123779297,
      "logps/chosen": -104.8638916015625,
      "logps/rejected": -157.4186553955078,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9183002710342407,
      "rewards/margins": 9.87336254119873,
      "rewards/rejected": -8.955062866210938,
      "step": 3962
    },
    {
      "epoch": 1.5852,
      "grad_norm": 0.0022714422084391117,
      "learning_rate": 4.717333333333333e-07,
      "logits/chosen": -2.606717586517334,
      "logits/rejected": -1.4419195652008057,
      "logps/chosen": -112.53172302246094,
      "logps/rejected": -184.9179229736328,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.294593095779419,
      "rewards/margins": 12.392053604125977,
      "rewards/rejected": -11.09745979309082,
      "step": 3963
    },
    {
      "epoch": 1.5856,
      "grad_norm": 39.81948471069336,
      "learning_rate": 4.716e-07,
      "logits/chosen": -2.351167678833008,
      "logits/rejected": -2.060521125793457,
      "logps/chosen": -193.68850708007812,
      "logps/rejected": -134.9975128173828,
      "loss": 0.1914,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.416571617126465,
      "rewards/margins": 4.482508659362793,
      "rewards/rejected": -8.899080276489258,
      "step": 3964
    },
    {
      "epoch": 1.5859999999999999,
      "grad_norm": 0.17559394240379333,
      "learning_rate": 4.714666666666666e-07,
      "logits/chosen": -3.0664515495300293,
      "logits/rejected": -2.8653035163879395,
      "logps/chosen": -89.94831848144531,
      "logps/rejected": -159.54595947265625,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9945635199546814,
      "rewards/margins": 8.812153816223145,
      "rewards/rejected": -9.806716918945312,
      "step": 3965
    },
    {
      "epoch": 1.5864,
      "grad_norm": 63.24531555175781,
      "learning_rate": 4.713333333333333e-07,
      "logits/chosen": -2.1859989166259766,
      "logits/rejected": -1.7266733646392822,
      "logps/chosen": -227.99002075195312,
      "logps/rejected": -193.57785034179688,
      "loss": 0.3079,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.53047251701355,
      "rewards/margins": 6.049614906311035,
      "rewards/rejected": -8.580087661743164,
      "step": 3966
    },
    {
      "epoch": 1.5868,
      "grad_norm": 0.035958319902420044,
      "learning_rate": 4.712e-07,
      "logits/chosen": -2.6573610305786133,
      "logits/rejected": -2.1431097984313965,
      "logps/chosen": -74.21087646484375,
      "logps/rejected": -188.98458862304688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.086228609085083,
      "rewards/margins": 11.715229034423828,
      "rewards/rejected": -10.629000663757324,
      "step": 3967
    },
    {
      "epoch": 1.5872000000000002,
      "grad_norm": 7.438485622406006,
      "learning_rate": 4.710666666666667e-07,
      "logits/chosen": -3.0595285892486572,
      "logits/rejected": -2.7310619354248047,
      "logps/chosen": -72.42294311523438,
      "logps/rejected": -147.00491333007812,
      "loss": 0.0501,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.976510226726532,
      "rewards/margins": 7.100934982299805,
      "rewards/rejected": -8.077445030212402,
      "step": 3968
    },
    {
      "epoch": 1.5876000000000001,
      "grad_norm": 1.2061446905136108,
      "learning_rate": 4.709333333333333e-07,
      "logits/chosen": -2.9839978218078613,
      "logits/rejected": -2.842500686645508,
      "logps/chosen": -85.41315460205078,
      "logps/rejected": -102.24894714355469,
      "loss": 0.0096,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2588341236114502,
      "rewards/margins": 4.6998443603515625,
      "rewards/rejected": -5.958678245544434,
      "step": 3969
    },
    {
      "epoch": 1.588,
      "grad_norm": 0.045325085520744324,
      "learning_rate": 4.7079999999999995e-07,
      "logits/chosen": -2.7851767539978027,
      "logits/rejected": -1.9993271827697754,
      "logps/chosen": -98.83871459960938,
      "logps/rejected": -128.38461303710938,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.67535400390625,
      "rewards/margins": 8.33737564086914,
      "rewards/rejected": -7.662022113800049,
      "step": 3970
    },
    {
      "epoch": 1.5884,
      "grad_norm": 0.0439673587679863,
      "learning_rate": 4.7066666666666665e-07,
      "logits/chosen": -2.8121848106384277,
      "logits/rejected": -2.7570619583129883,
      "logps/chosen": -114.05714416503906,
      "logps/rejected": -145.955078125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14586982131004333,
      "rewards/margins": 8.298267364501953,
      "rewards/rejected": -8.152397155761719,
      "step": 3971
    },
    {
      "epoch": 1.5888,
      "grad_norm": 2.35843825340271,
      "learning_rate": 4.7053333333333334e-07,
      "logits/chosen": -3.0508389472961426,
      "logits/rejected": -2.8787574768066406,
      "logps/chosen": -53.87925338745117,
      "logps/rejected": -72.25384521484375,
      "loss": 0.0209,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5106489062309265,
      "rewards/margins": 3.875988483428955,
      "rewards/rejected": -3.365339517593384,
      "step": 3972
    },
    {
      "epoch": 1.5892,
      "grad_norm": 1.172702670097351,
      "learning_rate": 4.704e-07,
      "logits/chosen": -3.0775275230407715,
      "logits/rejected": -2.607435941696167,
      "logps/chosen": -46.05321502685547,
      "logps/rejected": -84.22965240478516,
      "loss": 0.011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6098983883857727,
      "rewards/margins": 5.989691734313965,
      "rewards/rejected": -5.379793167114258,
      "step": 3973
    },
    {
      "epoch": 1.5896,
      "grad_norm": 0.03795165941119194,
      "learning_rate": 4.7026666666666667e-07,
      "logits/chosen": -3.0238983631134033,
      "logits/rejected": -2.7692980766296387,
      "logps/chosen": -55.64452362060547,
      "logps/rejected": -135.67520141601562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3142154216766357,
      "rewards/margins": 10.22616958618164,
      "rewards/rejected": -8.911954879760742,
      "step": 3974
    },
    {
      "epoch": 1.5899999999999999,
      "grad_norm": 4.656042575836182,
      "learning_rate": 4.701333333333333e-07,
      "logits/chosen": -2.7825798988342285,
      "logits/rejected": -2.6174466609954834,
      "logps/chosen": -64.79827880859375,
      "logps/rejected": -83.31045532226562,
      "loss": 0.0268,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0213277339935303,
      "rewards/margins": 4.3801116943359375,
      "rewards/rejected": -5.401439666748047,
      "step": 3975
    },
    {
      "epoch": 1.5904,
      "grad_norm": 0.8649731874465942,
      "learning_rate": 4.6999999999999995e-07,
      "logits/chosen": -2.9910888671875,
      "logits/rejected": -2.9951322078704834,
      "logps/chosen": -117.7177734375,
      "logps/rejected": -123.25202178955078,
      "loss": 0.0063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09655913710594177,
      "rewards/margins": 5.8058319091796875,
      "rewards/rejected": -5.709272384643555,
      "step": 3976
    },
    {
      "epoch": 1.5908,
      "grad_norm": 0.29852160811424255,
      "learning_rate": 4.6986666666666664e-07,
      "logits/chosen": -2.5086190700531006,
      "logits/rejected": -2.3399572372436523,
      "logps/chosen": -138.35704040527344,
      "logps/rejected": -147.04583740234375,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0811803340911865,
      "rewards/margins": 6.235259532928467,
      "rewards/rejected": -8.316439628601074,
      "step": 3977
    },
    {
      "epoch": 1.5912,
      "grad_norm": 0.0017965481383726,
      "learning_rate": 4.6973333333333333e-07,
      "logits/chosen": -2.7384800910949707,
      "logits/rejected": -2.013885498046875,
      "logps/chosen": -73.45187377929688,
      "logps/rejected": -191.30905151367188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1226654052734375,
      "rewards/margins": 12.852998733520508,
      "rewards/rejected": -12.73033332824707,
      "step": 3978
    },
    {
      "epoch": 1.5916000000000001,
      "grad_norm": 0.008197406306862831,
      "learning_rate": 4.6959999999999997e-07,
      "logits/chosen": -2.759460926055908,
      "logits/rejected": -2.428539752960205,
      "logps/chosen": -143.67271423339844,
      "logps/rejected": -170.8544921875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6899227499961853,
      "rewards/margins": 10.32899284362793,
      "rewards/rejected": -11.018915176391602,
      "step": 3979
    },
    {
      "epoch": 1.592,
      "grad_norm": 0.0006204072269611061,
      "learning_rate": 4.694666666666666e-07,
      "logits/chosen": -2.5383710861206055,
      "logits/rejected": -2.044834852218628,
      "logps/chosen": -95.3655776977539,
      "logps/rejected": -204.4051513671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7175214886665344,
      "rewards/margins": 13.913246154785156,
      "rewards/rejected": -13.195724487304688,
      "step": 3980
    },
    {
      "epoch": 1.5924,
      "grad_norm": 0.00696940952911973,
      "learning_rate": 4.693333333333333e-07,
      "logits/chosen": -2.9679722785949707,
      "logits/rejected": -2.2619705200195312,
      "logps/chosen": -75.25641632080078,
      "logps/rejected": -187.08526611328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6173171997070312,
      "rewards/margins": 11.422506332397461,
      "rewards/rejected": -12.039823532104492,
      "step": 3981
    },
    {
      "epoch": 1.5928,
      "grad_norm": 0.002669584471732378,
      "learning_rate": 4.692e-07,
      "logits/chosen": -2.728631019592285,
      "logits/rejected": -2.0169296264648438,
      "logps/chosen": -107.26596069335938,
      "logps/rejected": -205.73826599121094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7941269278526306,
      "rewards/margins": 12.197659492492676,
      "rewards/rejected": -11.403532028198242,
      "step": 3982
    },
    {
      "epoch": 1.5932,
      "grad_norm": 0.0016533627640455961,
      "learning_rate": 4.690666666666667e-07,
      "logits/chosen": -2.936615467071533,
      "logits/rejected": -2.5176591873168945,
      "logps/chosen": -64.8245849609375,
      "logps/rejected": -187.8760223388672,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4871072769165039,
      "rewards/margins": 11.8637113571167,
      "rewards/rejected": -12.350818634033203,
      "step": 3983
    },
    {
      "epoch": 1.5936,
      "grad_norm": 0.0018623430514708161,
      "learning_rate": 4.6893333333333327e-07,
      "logits/chosen": -2.769000768661499,
      "logits/rejected": -1.9699527025222778,
      "logps/chosen": -62.187339782714844,
      "logps/rejected": -154.47421264648438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1759088039398193,
      "rewards/margins": 11.803777694702148,
      "rewards/rejected": -10.62786865234375,
      "step": 3984
    },
    {
      "epoch": 1.5939999999999999,
      "grad_norm": 0.0013708348851650953,
      "learning_rate": 4.6879999999999996e-07,
      "logits/chosen": -3.0359678268432617,
      "logits/rejected": -2.2378759384155273,
      "logps/chosen": -62.38313293457031,
      "logps/rejected": -204.84861755371094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.49323004484176636,
      "rewards/margins": 13.981117248535156,
      "rewards/rejected": -13.487886428833008,
      "step": 3985
    },
    {
      "epoch": 1.5944,
      "grad_norm": 0.09377554804086685,
      "learning_rate": 4.6866666666666665e-07,
      "logits/chosen": -2.802562713623047,
      "logits/rejected": -2.279144763946533,
      "logps/chosen": -145.13059997558594,
      "logps/rejected": -175.68634033203125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8233253955841064,
      "rewards/margins": 11.43747615814209,
      "rewards/rejected": -10.614150047302246,
      "step": 3986
    },
    {
      "epoch": 1.5948,
      "grad_norm": 0.20233866572380066,
      "learning_rate": 4.6853333333333335e-07,
      "logits/chosen": -2.9347755908966064,
      "logits/rejected": -2.766077995300293,
      "logps/chosen": -74.27169799804688,
      "logps/rejected": -115.95027923583984,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3675132989883423,
      "rewards/margins": 7.6923980712890625,
      "rewards/rejected": -7.324885368347168,
      "step": 3987
    },
    {
      "epoch": 1.5952,
      "grad_norm": 0.18978813290596008,
      "learning_rate": 4.684e-07,
      "logits/chosen": -2.584970474243164,
      "logits/rejected": -2.151825428009033,
      "logps/chosen": -96.59431457519531,
      "logps/rejected": -127.6383285522461,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8950812816619873,
      "rewards/margins": 8.375823974609375,
      "rewards/rejected": -7.480742454528809,
      "step": 3988
    },
    {
      "epoch": 1.5956000000000001,
      "grad_norm": 0.003284917213022709,
      "learning_rate": 4.682666666666666e-07,
      "logits/chosen": -2.8749027252197266,
      "logits/rejected": -2.3767476081848145,
      "logps/chosen": -99.75946044921875,
      "logps/rejected": -176.48004150390625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.007797598838806152,
      "rewards/margins": 11.435824394226074,
      "rewards/rejected": -11.428027153015137,
      "step": 3989
    },
    {
      "epoch": 1.596,
      "grad_norm": 0.052829232066869736,
      "learning_rate": 4.681333333333333e-07,
      "logits/chosen": -2.6782708168029785,
      "logits/rejected": -1.9494373798370361,
      "logps/chosen": -93.69100952148438,
      "logps/rejected": -167.98556518554688,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07232511043548584,
      "rewards/margins": 10.020071983337402,
      "rewards/rejected": -9.947747230529785,
      "step": 3990
    },
    {
      "epoch": 1.5964,
      "grad_norm": 0.025507859885692596,
      "learning_rate": 4.68e-07,
      "logits/chosen": -2.784789562225342,
      "logits/rejected": -2.0252556800842285,
      "logps/chosen": -70.26077270507812,
      "logps/rejected": -148.28274536132812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.29920005798339844,
      "rewards/margins": 10.125492095947266,
      "rewards/rejected": -9.826292037963867,
      "step": 3991
    },
    {
      "epoch": 1.5968,
      "grad_norm": 0.10995303094387054,
      "learning_rate": 4.6786666666666665e-07,
      "logits/chosen": -2.9668731689453125,
      "logits/rejected": -2.80601167678833,
      "logps/chosen": -52.76755905151367,
      "logps/rejected": -126.72935485839844,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.21791258454322815,
      "rewards/margins": 8.083332061767578,
      "rewards/rejected": -8.301244735717773,
      "step": 3992
    },
    {
      "epoch": 1.5972,
      "grad_norm": 0.037363506853580475,
      "learning_rate": 4.6773333333333334e-07,
      "logits/chosen": -2.704556941986084,
      "logits/rejected": -2.2705349922180176,
      "logps/chosen": -127.22111511230469,
      "logps/rejected": -193.1503448486328,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9105732440948486,
      "rewards/margins": 11.972776412963867,
      "rewards/rejected": -12.883350372314453,
      "step": 3993
    },
    {
      "epoch": 1.5976,
      "grad_norm": 0.042253438383340836,
      "learning_rate": 4.676e-07,
      "logits/chosen": -2.433781147003174,
      "logits/rejected": -1.749043583869934,
      "logps/chosen": -116.46556854248047,
      "logps/rejected": -205.5255126953125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35678520798683167,
      "rewards/margins": 10.455446243286133,
      "rewards/rejected": -10.098661422729492,
      "step": 3994
    },
    {
      "epoch": 1.5979999999999999,
      "grad_norm": 0.002229975303635001,
      "learning_rate": 4.674666666666666e-07,
      "logits/chosen": -2.626443386077881,
      "logits/rejected": -1.9422636032104492,
      "logps/chosen": -152.10963439941406,
      "logps/rejected": -242.43765258789062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.583158493041992,
      "rewards/margins": 11.733233451843262,
      "rewards/rejected": -15.31639289855957,
      "step": 3995
    },
    {
      "epoch": 1.5984,
      "grad_norm": 0.13812826573848724,
      "learning_rate": 4.673333333333333e-07,
      "logits/chosen": -2.1088900566101074,
      "logits/rejected": -1.5252913236618042,
      "logps/chosen": -249.52365112304688,
      "logps/rejected": -205.27487182617188,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0846831798553467,
      "rewards/margins": 7.954968452453613,
      "rewards/rejected": -10.039651870727539,
      "step": 3996
    },
    {
      "epoch": 1.5988,
      "grad_norm": 2.2295076847076416,
      "learning_rate": 4.672e-07,
      "logits/chosen": -3.0369348526000977,
      "logits/rejected": -2.8786425590515137,
      "logps/chosen": -116.10003662109375,
      "logps/rejected": -128.36761474609375,
      "loss": 0.0172,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5453236103057861,
      "rewards/margins": 6.290970802307129,
      "rewards/rejected": -7.836294174194336,
      "step": 3997
    },
    {
      "epoch": 1.5992,
      "grad_norm": 0.008320191875100136,
      "learning_rate": 4.6706666666666664e-07,
      "logits/chosen": -2.724200487136841,
      "logits/rejected": -2.139235019683838,
      "logps/chosen": -102.99751281738281,
      "logps/rejected": -164.02194213867188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19476433098316193,
      "rewards/margins": 10.692784309387207,
      "rewards/rejected": -10.49802017211914,
      "step": 3998
    },
    {
      "epoch": 1.5996000000000001,
      "grad_norm": 0.0012420136481523514,
      "learning_rate": 4.669333333333333e-07,
      "logits/chosen": -3.0503416061401367,
      "logits/rejected": -2.493730068206787,
      "logps/chosen": -78.40673828125,
      "logps/rejected": -225.7369384765625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16280098259449005,
      "rewards/margins": 12.567142486572266,
      "rewards/rejected": -12.404340744018555,
      "step": 3999
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.13844458758831024,
      "learning_rate": 4.6679999999999997e-07,
      "logits/chosen": -2.720656156539917,
      "logits/rejected": -2.0249812602996826,
      "logps/chosen": -102.22627258300781,
      "logps/rejected": -161.98455810546875,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5353078842163086,
      "rewards/margins": 9.396692276000977,
      "rewards/rejected": -9.932000160217285,
      "step": 4000
    },
    {
      "epoch": 1.6004,
      "grad_norm": 0.4796788692474365,
      "learning_rate": 4.6666666666666666e-07,
      "logits/chosen": -2.3020927906036377,
      "logits/rejected": -1.7405117750167847,
      "logps/chosen": -139.744384765625,
      "logps/rejected": -115.54878234863281,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8185306787490845,
      "rewards/margins": 6.778989791870117,
      "rewards/rejected": -7.597520351409912,
      "step": 4001
    },
    {
      "epoch": 1.6008,
      "grad_norm": 0.0021617787424474955,
      "learning_rate": 4.6653333333333336e-07,
      "logits/chosen": -2.611665725708008,
      "logits/rejected": -1.621964454650879,
      "logps/chosen": -62.82288360595703,
      "logps/rejected": -211.52752685546875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3943283557891846,
      "rewards/margins": 12.067977905273438,
      "rewards/rejected": -9.673649787902832,
      "step": 4002
    },
    {
      "epoch": 1.6012,
      "grad_norm": 0.0007465067901648581,
      "learning_rate": 4.6639999999999994e-07,
      "logits/chosen": -2.9750113487243652,
      "logits/rejected": -2.310534954071045,
      "logps/chosen": -72.2668228149414,
      "logps/rejected": -202.31137084960938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1758144497871399,
      "rewards/margins": 13.210803985595703,
      "rewards/rejected": -13.034990310668945,
      "step": 4003
    },
    {
      "epoch": 1.6016,
      "grad_norm": 0.6000261306762695,
      "learning_rate": 4.6626666666666663e-07,
      "logits/chosen": -2.8431591987609863,
      "logits/rejected": -2.422306537628174,
      "logps/chosen": -72.48847961425781,
      "logps/rejected": -188.61239624023438,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1321840286254883,
      "rewards/margins": 11.218899726867676,
      "rewards/rejected": -12.351083755493164,
      "step": 4004
    },
    {
      "epoch": 1.6019999999999999,
      "grad_norm": 0.0305487010627985,
      "learning_rate": 4.661333333333333e-07,
      "logits/chosen": -2.6846365928649902,
      "logits/rejected": -2.1875064373016357,
      "logps/chosen": -130.3699188232422,
      "logps/rejected": -137.2119140625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2576107084751129,
      "rewards/margins": 8.753012657165527,
      "rewards/rejected": -9.01062297821045,
      "step": 4005
    },
    {
      "epoch": 1.6024,
      "grad_norm": 0.09019602090120316,
      "learning_rate": 4.66e-07,
      "logits/chosen": -2.6607158184051514,
      "logits/rejected": -2.271547555923462,
      "logps/chosen": -85.11180114746094,
      "logps/rejected": -128.27203369140625,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1642945408821106,
      "rewards/margins": 7.8980889320373535,
      "rewards/rejected": -7.733794689178467,
      "step": 4006
    },
    {
      "epoch": 1.6028,
      "grad_norm": 0.7728676795959473,
      "learning_rate": 4.6586666666666666e-07,
      "logits/chosen": -2.9664840698242188,
      "logits/rejected": -2.8405346870422363,
      "logps/chosen": -164.77362060546875,
      "logps/rejected": -134.64967346191406,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.041698455810546875,
      "rewards/margins": 5.640460014343262,
      "rewards/rejected": -5.682158946990967,
      "step": 4007
    },
    {
      "epoch": 1.6032,
      "grad_norm": 2.909684658050537,
      "learning_rate": 4.657333333333333e-07,
      "logits/chosen": -2.764338970184326,
      "logits/rejected": -2.619879722595215,
      "logps/chosen": -60.24175262451172,
      "logps/rejected": -108.61967468261719,
      "loss": 0.0245,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08036059141159058,
      "rewards/margins": 4.686513423919678,
      "rewards/rejected": -4.606152534484863,
      "step": 4008
    },
    {
      "epoch": 1.6036000000000001,
      "grad_norm": 0.00639763381332159,
      "learning_rate": 4.656e-07,
      "logits/chosen": -2.908897876739502,
      "logits/rejected": -2.4296770095825195,
      "logps/chosen": -114.01406860351562,
      "logps/rejected": -139.3359832763672,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3769066333770752,
      "rewards/margins": 10.639636993408203,
      "rewards/rejected": -10.26272964477539,
      "step": 4009
    },
    {
      "epoch": 1.604,
      "grad_norm": 0.051963187754154205,
      "learning_rate": 4.654666666666666e-07,
      "logits/chosen": -2.76713228225708,
      "logits/rejected": -2.6062612533569336,
      "logps/chosen": -156.96829223632812,
      "logps/rejected": -156.7755584716797,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.676904320716858,
      "rewards/margins": 8.616989135742188,
      "rewards/rejected": -10.293893814086914,
      "step": 4010
    },
    {
      "epoch": 1.6044,
      "grad_norm": 0.05682205781340599,
      "learning_rate": 4.653333333333333e-07,
      "logits/chosen": -2.953099012374878,
      "logits/rejected": -2.3984429836273193,
      "logps/chosen": -75.12672424316406,
      "logps/rejected": -147.36859130859375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.15422096848487854,
      "rewards/margins": 9.316193580627441,
      "rewards/rejected": -9.470415115356445,
      "step": 4011
    },
    {
      "epoch": 1.6048,
      "grad_norm": 0.20949341356754303,
      "learning_rate": 4.6519999999999996e-07,
      "logits/chosen": -3.080842971801758,
      "logits/rejected": -2.693948268890381,
      "logps/chosen": -69.12898254394531,
      "logps/rejected": -92.57865905761719,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8035122156143188,
      "rewards/margins": 6.6581711769104,
      "rewards/rejected": -5.854659080505371,
      "step": 4012
    },
    {
      "epoch": 1.6052,
      "grad_norm": 0.06715938448905945,
      "learning_rate": 4.6506666666666665e-07,
      "logits/chosen": -3.0189969539642334,
      "logits/rejected": -2.812812566757202,
      "logps/chosen": -77.78495788574219,
      "logps/rejected": -102.4968490600586,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5082939863204956,
      "rewards/margins": 7.507892608642578,
      "rewards/rejected": -6.999598503112793,
      "step": 4013
    },
    {
      "epoch": 1.6056,
      "grad_norm": 1.4001587629318237,
      "learning_rate": 4.649333333333333e-07,
      "logits/chosen": -2.69205379486084,
      "logits/rejected": -2.0997846126556396,
      "logps/chosen": -136.4911651611328,
      "logps/rejected": -118.84546661376953,
      "loss": 0.0077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3991180658340454,
      "rewards/margins": 5.362399578094482,
      "rewards/rejected": -6.761517524719238,
      "step": 4014
    },
    {
      "epoch": 1.6059999999999999,
      "grad_norm": 0.0002187932695960626,
      "learning_rate": 4.648e-07,
      "logits/chosen": -2.4733715057373047,
      "logits/rejected": -1.6747145652770996,
      "logps/chosen": -65.34356689453125,
      "logps/rejected": -191.00924682617188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.699075698852539,
      "rewards/margins": 14.68964958190918,
      "rewards/rejected": -12.99057388305664,
      "step": 4015
    },
    {
      "epoch": 1.6064,
      "grad_norm": 4.645843982696533,
      "learning_rate": 4.6466666666666667e-07,
      "logits/chosen": -2.6105175018310547,
      "logits/rejected": -2.4080722332000732,
      "logps/chosen": -168.39822387695312,
      "logps/rejected": -134.16844177246094,
      "loss": 0.0168,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.6614186763763428,
      "rewards/margins": 5.664653778076172,
      "rewards/rejected": -8.326072692871094,
      "step": 4016
    },
    {
      "epoch": 1.6068,
      "grad_norm": 0.7962733507156372,
      "learning_rate": 4.645333333333333e-07,
      "logits/chosen": -2.809718608856201,
      "logits/rejected": -2.2608933448791504,
      "logps/chosen": -109.89222717285156,
      "logps/rejected": -165.92645263671875,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.16806483268737793,
      "rewards/margins": 10.722421646118164,
      "rewards/rejected": -10.890486717224121,
      "step": 4017
    },
    {
      "epoch": 1.6072,
      "grad_norm": 0.05122903734445572,
      "learning_rate": 4.6439999999999995e-07,
      "logits/chosen": -3.0038342475891113,
      "logits/rejected": -2.424086570739746,
      "logps/chosen": -85.37958526611328,
      "logps/rejected": -161.4930877685547,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3725929260253906,
      "rewards/margins": 9.23530101776123,
      "rewards/rejected": -9.607893943786621,
      "step": 4018
    },
    {
      "epoch": 1.6076000000000001,
      "grad_norm": 0.06434114277362823,
      "learning_rate": 4.6426666666666664e-07,
      "logits/chosen": -2.6919851303100586,
      "logits/rejected": -2.278623104095459,
      "logps/chosen": -170.24046325683594,
      "logps/rejected": -142.90682983398438,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5284568667411804,
      "rewards/margins": 8.425029754638672,
      "rewards/rejected": -8.953486442565918,
      "step": 4019
    },
    {
      "epoch": 1.608,
      "grad_norm": 0.03603086993098259,
      "learning_rate": 4.6413333333333333e-07,
      "logits/chosen": -2.8999338150024414,
      "logits/rejected": -2.5291879177093506,
      "logps/chosen": -52.44327163696289,
      "logps/rejected": -180.66119384765625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5578815937042236,
      "rewards/margins": 13.737892150878906,
      "rewards/rejected": -12.180010795593262,
      "step": 4020
    },
    {
      "epoch": 1.6084,
      "grad_norm": 1.1522566080093384,
      "learning_rate": 4.64e-07,
      "logits/chosen": -2.895941734313965,
      "logits/rejected": -2.5748653411865234,
      "logps/chosen": -98.88128662109375,
      "logps/rejected": -150.97862243652344,
      "loss": 0.007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5501881241798401,
      "rewards/margins": 9.578399658203125,
      "rewards/rejected": -10.128588676452637,
      "step": 4021
    },
    {
      "epoch": 1.6088,
      "grad_norm": 2.7747814655303955,
      "learning_rate": 4.638666666666666e-07,
      "logits/chosen": -2.356327533721924,
      "logits/rejected": -1.524446964263916,
      "logps/chosen": -229.50177001953125,
      "logps/rejected": -190.91244506835938,
      "loss": 0.011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.429985761642456,
      "rewards/margins": 9.4212007522583,
      "rewards/rejected": -10.851186752319336,
      "step": 4022
    },
    {
      "epoch": 1.6092,
      "grad_norm": 1.0527665615081787,
      "learning_rate": 4.637333333333333e-07,
      "logits/chosen": -2.4392290115356445,
      "logits/rejected": -2.1409754753112793,
      "logps/chosen": -102.94558715820312,
      "logps/rejected": -106.56221771240234,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3128702640533447,
      "rewards/margins": 4.902734279632568,
      "rewards/rejected": -6.215604782104492,
      "step": 4023
    },
    {
      "epoch": 1.6096,
      "grad_norm": 0.0012061697198078036,
      "learning_rate": 4.636e-07,
      "logits/chosen": -3.029357671737671,
      "logits/rejected": -2.3305485248565674,
      "logps/chosen": -51.712486267089844,
      "logps/rejected": -186.2707061767578,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4747072160243988,
      "rewards/margins": 12.366860389709473,
      "rewards/rejected": -11.892152786254883,
      "step": 4024
    },
    {
      "epoch": 1.6099999999999999,
      "grad_norm": 0.026687949895858765,
      "learning_rate": 4.634666666666667e-07,
      "logits/chosen": -2.755701780319214,
      "logits/rejected": -1.969706654548645,
      "logps/chosen": -61.08982849121094,
      "logps/rejected": -163.68223571777344,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.696272075176239,
      "rewards/margins": 9.080923080444336,
      "rewards/rejected": -8.384651184082031,
      "step": 4025
    },
    {
      "epoch": 1.6104,
      "grad_norm": 0.12834861874580383,
      "learning_rate": 4.633333333333333e-07,
      "logits/chosen": -2.7412281036376953,
      "logits/rejected": -2.1401145458221436,
      "logps/chosen": -84.57940673828125,
      "logps/rejected": -122.37760925292969,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4800102710723877,
      "rewards/margins": 9.08344554901123,
      "rewards/rejected": -7.603435516357422,
      "step": 4026
    },
    {
      "epoch": 1.6108,
      "grad_norm": 0.00355352065525949,
      "learning_rate": 4.6319999999999997e-07,
      "logits/chosen": -2.3137903213500977,
      "logits/rejected": -1.8609676361083984,
      "logps/chosen": -231.9384765625,
      "logps/rejected": -268.87139892578125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0393860340118408,
      "rewards/margins": 11.449438095092773,
      "rewards/rejected": -12.488823890686035,
      "step": 4027
    },
    {
      "epoch": 1.6112,
      "grad_norm": 0.0030199051834642887,
      "learning_rate": 4.6306666666666666e-07,
      "logits/chosen": -2.453890085220337,
      "logits/rejected": -1.6226871013641357,
      "logps/chosen": -113.52357482910156,
      "logps/rejected": -235.98114013671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.914255142211914,
      "rewards/margins": 12.548099517822266,
      "rewards/rejected": -10.633844375610352,
      "step": 4028
    },
    {
      "epoch": 1.6116000000000001,
      "grad_norm": 0.22401386499404907,
      "learning_rate": 4.629333333333333e-07,
      "logits/chosen": -2.7120792865753174,
      "logits/rejected": -2.2066597938537598,
      "logps/chosen": -115.46913146972656,
      "logps/rejected": -127.94865417480469,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.838721513748169,
      "rewards/margins": 8.977046012878418,
      "rewards/rejected": -8.138324737548828,
      "step": 4029
    },
    {
      "epoch": 1.612,
      "grad_norm": 0.09293175488710403,
      "learning_rate": 4.628e-07,
      "logits/chosen": -2.9673047065734863,
      "logits/rejected": -2.7062599658966064,
      "logps/chosen": -98.85232543945312,
      "logps/rejected": -119.2656021118164,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4387981593608856,
      "rewards/margins": 8.223645210266113,
      "rewards/rejected": -7.784847259521484,
      "step": 4030
    },
    {
      "epoch": 1.6124,
      "grad_norm": 0.013889298774302006,
      "learning_rate": 4.6266666666666663e-07,
      "logits/chosen": -2.6926121711730957,
      "logits/rejected": -2.065312385559082,
      "logps/chosen": -210.041259765625,
      "logps/rejected": -181.5907745361328,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8263717889785767,
      "rewards/margins": 9.85434627532959,
      "rewards/rejected": -10.680717468261719,
      "step": 4031
    },
    {
      "epoch": 1.6128,
      "grad_norm": 93.569091796875,
      "learning_rate": 4.625333333333333e-07,
      "logits/chosen": -2.869081497192383,
      "logits/rejected": -2.710875988006592,
      "logps/chosen": -162.91778564453125,
      "logps/rejected": -152.73846435546875,
      "loss": 0.6725,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -5.632970333099365,
      "rewards/margins": 4.253050804138184,
      "rewards/rejected": -9.88602066040039,
      "step": 4032
    },
    {
      "epoch": 1.6132,
      "grad_norm": 0.3561886250972748,
      "learning_rate": 4.6239999999999996e-07,
      "logits/chosen": -2.870875597000122,
      "logits/rejected": -2.47068452835083,
      "logps/chosen": -76.15138244628906,
      "logps/rejected": -151.1204833984375,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8234058618545532,
      "rewards/margins": 9.884500503540039,
      "rewards/rejected": -9.061094284057617,
      "step": 4033
    },
    {
      "epoch": 1.6136,
      "grad_norm": 0.001185945002362132,
      "learning_rate": 4.6226666666666665e-07,
      "logits/chosen": -2.5322437286376953,
      "logits/rejected": -1.6519107818603516,
      "logps/chosen": -146.0185546875,
      "logps/rejected": -173.08554077148438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5475136041641235,
      "rewards/margins": 12.432849884033203,
      "rewards/rejected": -10.885335922241211,
      "step": 4034
    },
    {
      "epoch": 1.6139999999999999,
      "grad_norm": 0.025359928607940674,
      "learning_rate": 4.6213333333333334e-07,
      "logits/chosen": -3.032928943634033,
      "logits/rejected": -2.394805431365967,
      "logps/chosen": -72.10230255126953,
      "logps/rejected": -165.88955688476562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6927230954170227,
      "rewards/margins": 9.659831047058105,
      "rewards/rejected": -10.352554321289062,
      "step": 4035
    },
    {
      "epoch": 1.6143999999999998,
      "grad_norm": 1.4654444456100464,
      "learning_rate": 4.62e-07,
      "logits/chosen": -2.7965610027313232,
      "logits/rejected": -2.436704158782959,
      "logps/chosen": -79.83954620361328,
      "logps/rejected": -134.95281982421875,
      "loss": 0.0104,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.051011085510253906,
      "rewards/margins": 8.309198379516602,
      "rewards/rejected": -8.360209465026855,
      "step": 4036
    },
    {
      "epoch": 1.6148,
      "grad_norm": 0.32307466864585876,
      "learning_rate": 4.618666666666666e-07,
      "logits/chosen": -2.867626428604126,
      "logits/rejected": -2.2138986587524414,
      "logps/chosen": -98.96080017089844,
      "logps/rejected": -132.02975463867188,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9815429449081421,
      "rewards/margins": 7.870497703552246,
      "rewards/rejected": -8.85204029083252,
      "step": 4037
    },
    {
      "epoch": 1.6152,
      "grad_norm": 0.6103931665420532,
      "learning_rate": 4.617333333333333e-07,
      "logits/chosen": -2.7701940536499023,
      "logits/rejected": -2.208024024963379,
      "logps/chosen": -74.00331115722656,
      "logps/rejected": -221.08047485351562,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2796425223350525,
      "rewards/margins": 10.14098072052002,
      "rewards/rejected": -9.86133861541748,
      "step": 4038
    },
    {
      "epoch": 1.6156000000000001,
      "grad_norm": 1.0046992301940918,
      "learning_rate": 4.616e-07,
      "logits/chosen": -2.5285301208496094,
      "logits/rejected": -2.0286364555358887,
      "logps/chosen": -173.72203063964844,
      "logps/rejected": -167.65476989746094,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9853684902191162,
      "rewards/margins": 7.247287750244141,
      "rewards/rejected": -9.232656478881836,
      "step": 4039
    },
    {
      "epoch": 1.616,
      "grad_norm": 0.4981423616409302,
      "learning_rate": 4.614666666666667e-07,
      "logits/chosen": -3.050081253051758,
      "logits/rejected": -2.853081703186035,
      "logps/chosen": -76.97130584716797,
      "logps/rejected": -88.5456314086914,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12584036588668823,
      "rewards/margins": 5.671442031860352,
      "rewards/rejected": -5.545601844787598,
      "step": 4040
    },
    {
      "epoch": 1.6164,
      "grad_norm": 0.13872694969177246,
      "learning_rate": 4.613333333333333e-07,
      "logits/chosen": -3.253455638885498,
      "logits/rejected": -2.738485813140869,
      "logps/chosen": -53.46525955200195,
      "logps/rejected": -118.66768646240234,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9619250297546387,
      "rewards/margins": 6.99687385559082,
      "rewards/rejected": -7.958798408508301,
      "step": 4041
    },
    {
      "epoch": 1.6168,
      "grad_norm": 0.002096633892506361,
      "learning_rate": 4.612e-07,
      "logits/chosen": -2.6981749534606934,
      "logits/rejected": -1.959719181060791,
      "logps/chosen": -110.78431701660156,
      "logps/rejected": -161.2747344970703,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5252113342285156,
      "rewards/margins": 11.690546035766602,
      "rewards/rejected": -11.165334701538086,
      "step": 4042
    },
    {
      "epoch": 1.6172,
      "grad_norm": 0.07827622443437576,
      "learning_rate": 4.6106666666666667e-07,
      "logits/chosen": -3.100661039352417,
      "logits/rejected": -2.2968831062316895,
      "logps/chosen": -67.1722640991211,
      "logps/rejected": -162.67137145996094,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8311252593994141,
      "rewards/margins": 11.45348834991455,
      "rewards/rejected": -10.622363090515137,
      "step": 4043
    },
    {
      "epoch": 1.6176,
      "grad_norm": 0.0724540650844574,
      "learning_rate": 4.609333333333333e-07,
      "logits/chosen": -2.815113067626953,
      "logits/rejected": -2.1198081970214844,
      "logps/chosen": -64.61235046386719,
      "logps/rejected": -142.64793395996094,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4086967706680298,
      "rewards/margins": 9.052231788635254,
      "rewards/rejected": -7.6435346603393555,
      "step": 4044
    },
    {
      "epoch": 1.6179999999999999,
      "grad_norm": 0.0005237299483269453,
      "learning_rate": 4.6079999999999994e-07,
      "logits/chosen": -2.594611167907715,
      "logits/rejected": -1.8346707820892334,
      "logps/chosen": -173.19110107421875,
      "logps/rejected": -304.92681884765625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.015697956085205,
      "rewards/margins": 15.58912181854248,
      "rewards/rejected": -17.604820251464844,
      "step": 4045
    },
    {
      "epoch": 1.6183999999999998,
      "grad_norm": 0.00012032379163429141,
      "learning_rate": 4.6066666666666664e-07,
      "logits/chosen": -2.464782238006592,
      "logits/rejected": -1.7308635711669922,
      "logps/chosen": -84.26457214355469,
      "logps/rejected": -196.98410034179688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6615837812423706,
      "rewards/margins": 15.292633056640625,
      "rewards/rejected": -13.631049156188965,
      "step": 4046
    },
    {
      "epoch": 1.6188,
      "grad_norm": 0.9261522889137268,
      "learning_rate": 4.6053333333333333e-07,
      "logits/chosen": -2.5908217430114746,
      "logits/rejected": -2.179316520690918,
      "logps/chosen": -163.69070434570312,
      "logps/rejected": -174.80307006835938,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4939038753509521,
      "rewards/margins": 10.791417121887207,
      "rewards/rejected": -12.285320281982422,
      "step": 4047
    },
    {
      "epoch": 1.6192,
      "grad_norm": 0.12255024164915085,
      "learning_rate": 4.6039999999999997e-07,
      "logits/chosen": -2.6000800132751465,
      "logits/rejected": -2.2881054878234863,
      "logps/chosen": -86.97296142578125,
      "logps/rejected": -159.37506103515625,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7604049444198608,
      "rewards/margins": 8.868500709533691,
      "rewards/rejected": -8.108095169067383,
      "step": 4048
    },
    {
      "epoch": 1.6196000000000002,
      "grad_norm": 0.16286148130893707,
      "learning_rate": 4.6026666666666666e-07,
      "logits/chosen": -2.505156993865967,
      "logits/rejected": -2.088526725769043,
      "logps/chosen": -166.09298706054688,
      "logps/rejected": -156.29454040527344,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4235877990722656,
      "rewards/margins": 9.500484466552734,
      "rewards/rejected": -9.924072265625,
      "step": 4049
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.4848445653915405,
      "learning_rate": 4.601333333333333e-07,
      "logits/chosen": -2.6562347412109375,
      "logits/rejected": -2.225172996520996,
      "logps/chosen": -162.9529266357422,
      "logps/rejected": -136.87933349609375,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1771671772003174,
      "rewards/margins": 8.178998947143555,
      "rewards/rejected": -9.356165885925293,
      "step": 4050
    },
    {
      "epoch": 1.6204,
      "grad_norm": 0.04912576451897621,
      "learning_rate": 4.6e-07,
      "logits/chosen": -2.86724591255188,
      "logits/rejected": -2.6688711643218994,
      "logps/chosen": -83.09339904785156,
      "logps/rejected": -108.44232177734375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4209332466125488,
      "rewards/margins": 8.026304244995117,
      "rewards/rejected": -6.605371475219727,
      "step": 4051
    },
    {
      "epoch": 1.6208,
      "grad_norm": 0.47047725319862366,
      "learning_rate": 4.5986666666666663e-07,
      "logits/chosen": -2.827017307281494,
      "logits/rejected": -2.7372541427612305,
      "logps/chosen": -70.26402282714844,
      "logps/rejected": -112.22467803955078,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4064760208129883,
      "rewards/margins": 5.914374351501465,
      "rewards/rejected": -7.320850372314453,
      "step": 4052
    },
    {
      "epoch": 1.6212,
      "grad_norm": 0.0005124767776578665,
      "learning_rate": 4.597333333333333e-07,
      "logits/chosen": -2.753547191619873,
      "logits/rejected": -2.2226715087890625,
      "logps/chosen": -134.32745361328125,
      "logps/rejected": -202.7272186279297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.931296169757843,
      "rewards/margins": 13.289312362670898,
      "rewards/rejected": -14.220609664916992,
      "step": 4053
    },
    {
      "epoch": 1.6216,
      "grad_norm": 0.10354418307542801,
      "learning_rate": 4.596e-07,
      "logits/chosen": -3.101740837097168,
      "logits/rejected": -2.6521782875061035,
      "logps/chosen": -58.82920837402344,
      "logps/rejected": -134.0240478515625,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3918016254901886,
      "rewards/margins": 7.69504451751709,
      "rewards/rejected": -8.086846351623535,
      "step": 4054
    },
    {
      "epoch": 1.6219999999999999,
      "grad_norm": 0.08652153611183167,
      "learning_rate": 4.5946666666666665e-07,
      "logits/chosen": -2.9618146419525146,
      "logits/rejected": -2.6186180114746094,
      "logps/chosen": -89.65253448486328,
      "logps/rejected": -147.30191040039062,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45262986421585083,
      "rewards/margins": 8.869030952453613,
      "rewards/rejected": -8.416400909423828,
      "step": 4055
    },
    {
      "epoch": 1.6223999999999998,
      "grad_norm": 0.00756373256444931,
      "learning_rate": 4.593333333333333e-07,
      "logits/chosen": -2.960897445678711,
      "logits/rejected": -2.382265567779541,
      "logps/chosen": -81.41947937011719,
      "logps/rejected": -205.97222900390625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5070056915283203,
      "rewards/margins": 13.73765754699707,
      "rewards/rejected": -12.23065185546875,
      "step": 4056
    },
    {
      "epoch": 1.6228,
      "grad_norm": 0.20132005214691162,
      "learning_rate": 4.592e-07,
      "logits/chosen": -2.655660390853882,
      "logits/rejected": -1.8365917205810547,
      "logps/chosen": -129.1727752685547,
      "logps/rejected": -186.0313720703125,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7726871371269226,
      "rewards/margins": 10.168781280517578,
      "rewards/rejected": -10.941468238830566,
      "step": 4057
    },
    {
      "epoch": 1.6232,
      "grad_norm": 0.042622294276952744,
      "learning_rate": 4.590666666666667e-07,
      "logits/chosen": -3.0731287002563477,
      "logits/rejected": -2.5362191200256348,
      "logps/chosen": -53.00713348388672,
      "logps/rejected": -115.49653625488281,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2291860580444336,
      "rewards/margins": 8.19996452331543,
      "rewards/rejected": -7.970778465270996,
      "step": 4058
    },
    {
      "epoch": 1.6236000000000002,
      "grad_norm": 0.07396905869245529,
      "learning_rate": 4.589333333333333e-07,
      "logits/chosen": -2.882652759552002,
      "logits/rejected": -2.4388365745544434,
      "logps/chosen": -64.11758422851562,
      "logps/rejected": -160.31494140625,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4015592634677887,
      "rewards/margins": 10.221380233764648,
      "rewards/rejected": -9.81982135772705,
      "step": 4059
    },
    {
      "epoch": 1.624,
      "grad_norm": 1.3829677104949951,
      "learning_rate": 4.5879999999999995e-07,
      "logits/chosen": -3.267435073852539,
      "logits/rejected": -3.125372886657715,
      "logps/chosen": -53.54359436035156,
      "logps/rejected": -100.46744537353516,
      "loss": 0.0093,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5051088333129883,
      "rewards/margins": 5.596723556518555,
      "rewards/rejected": -4.091614246368408,
      "step": 4060
    },
    {
      "epoch": 1.6244,
      "grad_norm": 1.2501932382583618,
      "learning_rate": 4.5866666666666664e-07,
      "logits/chosen": -3.1252307891845703,
      "logits/rejected": -2.430420398712158,
      "logps/chosen": -62.484619140625,
      "logps/rejected": -131.25872802734375,
      "loss": 0.0097,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4665413200855255,
      "rewards/margins": 8.46325969696045,
      "rewards/rejected": -7.996718406677246,
      "step": 4061
    },
    {
      "epoch": 1.6248,
      "grad_norm": 2.9716076850891113,
      "learning_rate": 4.5853333333333334e-07,
      "logits/chosen": -2.9822425842285156,
      "logits/rejected": -2.6675643920898438,
      "logps/chosen": -86.24268341064453,
      "logps/rejected": -82.15776062011719,
      "loss": 0.0207,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5260448455810547,
      "rewards/margins": 4.340616703033447,
      "rewards/rejected": -4.866661548614502,
      "step": 4062
    },
    {
      "epoch": 1.6252,
      "grad_norm": 0.1359749585390091,
      "learning_rate": 4.584e-07,
      "logits/chosen": -2.7860894203186035,
      "logits/rejected": -2.6014232635498047,
      "logps/chosen": -102.9742431640625,
      "logps/rejected": -131.1339111328125,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8069713115692139,
      "rewards/margins": 7.702948570251465,
      "rewards/rejected": -8.509919166564941,
      "step": 4063
    },
    {
      "epoch": 1.6256,
      "grad_norm": 0.007858186028897762,
      "learning_rate": 4.582666666666666e-07,
      "logits/chosen": -2.8581714630126953,
      "logits/rejected": -2.018611192703247,
      "logps/chosen": -89.29473876953125,
      "logps/rejected": -184.9517364501953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6941105127334595,
      "rewards/margins": 11.44388198852539,
      "rewards/rejected": -10.749771118164062,
      "step": 4064
    },
    {
      "epoch": 1.626,
      "grad_norm": 0.0011711131082847714,
      "learning_rate": 4.581333333333333e-07,
      "logits/chosen": -2.836850166320801,
      "logits/rejected": -2.47067928314209,
      "logps/chosen": -94.14761352539062,
      "logps/rejected": -195.1616973876953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.27870258688926697,
      "rewards/margins": 12.042329788208008,
      "rewards/rejected": -12.32103157043457,
      "step": 4065
    },
    {
      "epoch": 1.6263999999999998,
      "grad_norm": 0.33219996094703674,
      "learning_rate": 4.58e-07,
      "logits/chosen": -2.172292470932007,
      "logits/rejected": -1.4180713891983032,
      "logps/chosen": -232.22817993164062,
      "logps/rejected": -163.2196502685547,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4018380641937256,
      "rewards/margins": 8.20535659790039,
      "rewards/rejected": -9.607194900512695,
      "step": 4066
    },
    {
      "epoch": 1.6268,
      "grad_norm": 0.14624547958374023,
      "learning_rate": 4.5786666666666664e-07,
      "logits/chosen": -2.8775746822357178,
      "logits/rejected": -2.4347383975982666,
      "logps/chosen": -71.78756713867188,
      "logps/rejected": -158.57225036621094,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8698753118515015,
      "rewards/margins": 11.442760467529297,
      "rewards/rejected": -10.572885513305664,
      "step": 4067
    },
    {
      "epoch": 1.6272,
      "grad_norm": 0.06672915816307068,
      "learning_rate": 4.5773333333333333e-07,
      "logits/chosen": -3.0801448822021484,
      "logits/rejected": -2.7501273155212402,
      "logps/chosen": -62.37824249267578,
      "logps/rejected": -93.66056823730469,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2768280506134033,
      "rewards/margins": 7.472739219665527,
      "rewards/rejected": -6.195910930633545,
      "step": 4068
    },
    {
      "epoch": 1.6276000000000002,
      "grad_norm": 0.000905758875887841,
      "learning_rate": 4.5759999999999997e-07,
      "logits/chosen": -2.5758347511291504,
      "logits/rejected": -1.7997691631317139,
      "logps/chosen": -84.25922393798828,
      "logps/rejected": -161.3802490234375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.851625442504883,
      "rewards/margins": 12.697891235351562,
      "rewards/rejected": -9.84626579284668,
      "step": 4069
    },
    {
      "epoch": 1.6280000000000001,
      "grad_norm": 0.17568159103393555,
      "learning_rate": 4.5746666666666666e-07,
      "logits/chosen": -2.594975471496582,
      "logits/rejected": -2.075430393218994,
      "logps/chosen": -101.74258422851562,
      "logps/rejected": -185.749755859375,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9694232940673828,
      "rewards/margins": 9.353578567504883,
      "rewards/rejected": -10.323001861572266,
      "step": 4070
    },
    {
      "epoch": 1.6284,
      "grad_norm": 0.04056358337402344,
      "learning_rate": 4.573333333333333e-07,
      "logits/chosen": -2.8536758422851562,
      "logits/rejected": -2.755201578140259,
      "logps/chosen": -120.83697509765625,
      "logps/rejected": -158.0756378173828,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9020576477050781,
      "rewards/margins": 8.708902359008789,
      "rewards/rejected": -9.610960006713867,
      "step": 4071
    },
    {
      "epoch": 1.6288,
      "grad_norm": 0.0007902250508777797,
      "learning_rate": 4.572e-07,
      "logits/chosen": -2.754318952560425,
      "logits/rejected": -2.1337180137634277,
      "logps/chosen": -71.21444702148438,
      "logps/rejected": -217.72964477539062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.018639087677002,
      "rewards/margins": 13.97626781463623,
      "rewards/rejected": -12.95762825012207,
      "step": 4072
    },
    {
      "epoch": 1.6292,
      "grad_norm": 0.6023217439651489,
      "learning_rate": 4.5706666666666663e-07,
      "logits/chosen": -2.611788272857666,
      "logits/rejected": -2.1657214164733887,
      "logps/chosen": -107.16230773925781,
      "logps/rejected": -167.80990600585938,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7161834836006165,
      "rewards/margins": 10.584717750549316,
      "rewards/rejected": -9.868534088134766,
      "step": 4073
    },
    {
      "epoch": 1.6296,
      "grad_norm": 0.005208618473261595,
      "learning_rate": 4.569333333333333e-07,
      "logits/chosen": -2.7858071327209473,
      "logits/rejected": -2.3371894359588623,
      "logps/chosen": -113.34678649902344,
      "logps/rejected": -168.89340209960938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1845695525407791,
      "rewards/margins": 10.686473846435547,
      "rewards/rejected": -10.501903533935547,
      "step": 4074
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.2573169767856598,
      "learning_rate": 4.5679999999999996e-07,
      "logits/chosen": -3.047316789627075,
      "logits/rejected": -2.6028356552124023,
      "logps/chosen": -98.57864379882812,
      "logps/rejected": -144.12548828125,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0989341735839844,
      "rewards/margins": 7.935053825378418,
      "rewards/rejected": -9.033987998962402,
      "step": 4075
    },
    {
      "epoch": 1.6303999999999998,
      "grad_norm": 0.02308855950832367,
      "learning_rate": 4.5666666666666665e-07,
      "logits/chosen": -2.756281852722168,
      "logits/rejected": -2.459477186203003,
      "logps/chosen": -103.48423767089844,
      "logps/rejected": -119.19978332519531,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.568365454673767,
      "rewards/margins": 9.778709411621094,
      "rewards/rejected": -8.210344314575195,
      "step": 4076
    },
    {
      "epoch": 1.6308,
      "grad_norm": 8.562529563903809,
      "learning_rate": 4.5653333333333335e-07,
      "logits/chosen": -2.535061836242676,
      "logits/rejected": -2.1724929809570312,
      "logps/chosen": -91.15690612792969,
      "logps/rejected": -148.03402709960938,
      "loss": 0.0491,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.15204626321792603,
      "rewards/margins": 8.516257286071777,
      "rewards/rejected": -8.668303489685059,
      "step": 4077
    },
    {
      "epoch": 1.6312,
      "grad_norm": 0.16725371778011322,
      "learning_rate": 4.5639999999999993e-07,
      "logits/chosen": -2.4821743965148926,
      "logits/rejected": -2.1302363872528076,
      "logps/chosen": -138.81027221679688,
      "logps/rejected": -184.4437713623047,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6494300961494446,
      "rewards/margins": 8.490957260131836,
      "rewards/rejected": -9.140387535095215,
      "step": 4078
    },
    {
      "epoch": 1.6316000000000002,
      "grad_norm": 0.00038729861262254417,
      "learning_rate": 4.562666666666666e-07,
      "logits/chosen": -2.479794502258301,
      "logits/rejected": -1.4259742498397827,
      "logps/chosen": -107.01564025878906,
      "logps/rejected": -170.51809692382812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9327635765075684,
      "rewards/margins": 14.472289085388184,
      "rewards/rejected": -11.539525985717773,
      "step": 4079
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 0.005113991908729076,
      "learning_rate": 4.561333333333333e-07,
      "logits/chosen": -3.0735533237457275,
      "logits/rejected": -2.436396360397339,
      "logps/chosen": -57.59186553955078,
      "logps/rejected": -198.39016723632812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0396827459335327,
      "rewards/margins": 12.111618995666504,
      "rewards/rejected": -13.151302337646484,
      "step": 4080
    },
    {
      "epoch": 1.6324,
      "grad_norm": 0.3000529110431671,
      "learning_rate": 4.56e-07,
      "logits/chosen": -3.1514549255371094,
      "logits/rejected": -3.171006917953491,
      "logps/chosen": -60.225643157958984,
      "logps/rejected": -160.20376586914062,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.48022520542144775,
      "rewards/margins": 8.836824417114258,
      "rewards/rejected": -9.317049980163574,
      "step": 4081
    },
    {
      "epoch": 1.6328,
      "grad_norm": 0.03493006154894829,
      "learning_rate": 4.5586666666666665e-07,
      "logits/chosen": -2.624720573425293,
      "logits/rejected": -2.3670670986175537,
      "logps/chosen": -139.88943481445312,
      "logps/rejected": -169.004638671875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.08965003490448,
      "rewards/margins": 9.56978988647461,
      "rewards/rejected": -10.659439086914062,
      "step": 4082
    },
    {
      "epoch": 1.6332,
      "grad_norm": 0.039076775312423706,
      "learning_rate": 4.557333333333333e-07,
      "logits/chosen": -3.295915126800537,
      "logits/rejected": -2.7208147048950195,
      "logps/chosen": -61.727447509765625,
      "logps/rejected": -145.52557373046875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1946921348571777,
      "rewards/margins": 9.9151611328125,
      "rewards/rejected": -8.72046947479248,
      "step": 4083
    },
    {
      "epoch": 1.6336,
      "grad_norm": 0.01331019215285778,
      "learning_rate": 4.556e-07,
      "logits/chosen": -2.6830668449401855,
      "logits/rejected": -2.1476802825927734,
      "logps/chosen": -85.1387939453125,
      "logps/rejected": -169.54519653320312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8190364837646484,
      "rewards/margins": 12.052305221557617,
      "rewards/rejected": -10.233268737792969,
      "step": 4084
    },
    {
      "epoch": 1.634,
      "grad_norm": 1.281759262084961,
      "learning_rate": 4.5546666666666667e-07,
      "logits/chosen": -2.530575752258301,
      "logits/rejected": -2.0714035034179688,
      "logps/chosen": -97.65811920166016,
      "logps/rejected": -146.45689392089844,
      "loss": 0.0136,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.33121606707572937,
      "rewards/margins": 8.228549003601074,
      "rewards/rejected": -8.559765815734863,
      "step": 4085
    },
    {
      "epoch": 1.6343999999999999,
      "grad_norm": 0.3000743091106415,
      "learning_rate": 4.553333333333333e-07,
      "logits/chosen": -2.583590507507324,
      "logits/rejected": -2.575072765350342,
      "logps/chosen": -143.25509643554688,
      "logps/rejected": -109.19232177734375,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.976789116859436,
      "rewards/margins": 6.269191265106201,
      "rewards/rejected": -7.245980262756348,
      "step": 4086
    },
    {
      "epoch": 1.6348,
      "grad_norm": 1.0340722799301147,
      "learning_rate": 4.5519999999999995e-07,
      "logits/chosen": -2.951633930206299,
      "logits/rejected": -2.5011439323425293,
      "logps/chosen": -84.18953704833984,
      "logps/rejected": -128.01473999023438,
      "loss": 0.0049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8547034859657288,
      "rewards/margins": 7.800860404968262,
      "rewards/rejected": -8.655563354492188,
      "step": 4087
    },
    {
      "epoch": 1.6352,
      "grad_norm": 0.05998000502586365,
      "learning_rate": 4.5506666666666664e-07,
      "logits/chosen": -2.849921703338623,
      "logits/rejected": -2.1865394115448,
      "logps/chosen": -102.08511352539062,
      "logps/rejected": -137.5732421875,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0153900384902954,
      "rewards/margins": 9.843305587768555,
      "rewards/rejected": -8.82791519165039,
      "step": 4088
    },
    {
      "epoch": 1.6356000000000002,
      "grad_norm": 0.23217391967773438,
      "learning_rate": 4.5493333333333333e-07,
      "logits/chosen": -2.6785049438476562,
      "logits/rejected": -2.4037415981292725,
      "logps/chosen": -156.9535675048828,
      "logps/rejected": -177.3464813232422,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4399147033691406,
      "rewards/margins": 12.396484375,
      "rewards/rejected": -12.83639907836914,
      "step": 4089
    },
    {
      "epoch": 1.6360000000000001,
      "grad_norm": 0.015146809630095959,
      "learning_rate": 4.5479999999999997e-07,
      "logits/chosen": -2.142090320587158,
      "logits/rejected": -1.3198492527008057,
      "logps/chosen": -96.25019836425781,
      "logps/rejected": -217.235107421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.725325107574463,
      "rewards/margins": 11.511831283569336,
      "rewards/rejected": -9.786506652832031,
      "step": 4090
    },
    {
      "epoch": 1.6364,
      "grad_norm": 0.2192750871181488,
      "learning_rate": 4.5466666666666666e-07,
      "logits/chosen": -2.74505877494812,
      "logits/rejected": -2.1325342655181885,
      "logps/chosen": -142.65281677246094,
      "logps/rejected": -139.9278106689453,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4790080785751343,
      "rewards/margins": 7.062819480895996,
      "rewards/rejected": -8.541828155517578,
      "step": 4091
    },
    {
      "epoch": 1.6368,
      "grad_norm": 0.03586861491203308,
      "learning_rate": 4.545333333333333e-07,
      "logits/chosen": -3.1684722900390625,
      "logits/rejected": -2.489823579788208,
      "logps/chosen": -36.592613220214844,
      "logps/rejected": -150.08273315429688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5809699296951294,
      "rewards/margins": 11.071783065795898,
      "rewards/rejected": -10.490813255310059,
      "step": 4092
    },
    {
      "epoch": 1.6372,
      "grad_norm": 0.46118077635765076,
      "learning_rate": 4.544e-07,
      "logits/chosen": -2.328596353530884,
      "logits/rejected": -2.0368266105651855,
      "logps/chosen": -164.8653106689453,
      "logps/rejected": -153.8371124267578,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.050851345062256,
      "rewards/margins": 6.045902252197266,
      "rewards/rejected": -8.096753120422363,
      "step": 4093
    },
    {
      "epoch": 1.6376,
      "grad_norm": 0.00030780574888922274,
      "learning_rate": 4.5426666666666663e-07,
      "logits/chosen": -2.348797082901001,
      "logits/rejected": -1.749922275543213,
      "logps/chosen": -129.48712158203125,
      "logps/rejected": -187.0934295654297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1016712188720703,
      "rewards/margins": 15.036934852600098,
      "rewards/rejected": -12.935263633728027,
      "step": 4094
    },
    {
      "epoch": 1.638,
      "grad_norm": 0.00014723728236276656,
      "learning_rate": 4.541333333333333e-07,
      "logits/chosen": -2.7993106842041016,
      "logits/rejected": -2.5025577545166016,
      "logps/chosen": -86.24488830566406,
      "logps/rejected": -214.93186950683594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24892044067382812,
      "rewards/margins": 14.715473175048828,
      "rewards/rejected": -14.466552734375,
      "step": 4095
    },
    {
      "epoch": 1.6383999999999999,
      "grad_norm": 0.09594227373600006,
      "learning_rate": 4.54e-07,
      "logits/chosen": -2.3530466556549072,
      "logits/rejected": -1.8252925872802734,
      "logps/chosen": -240.56973266601562,
      "logps/rejected": -140.07705688476562,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6374717950820923,
      "rewards/margins": 7.662585258483887,
      "rewards/rejected": -9.300056457519531,
      "step": 4096
    },
    {
      "epoch": 1.6388,
      "grad_norm": 7.767573356628418,
      "learning_rate": 4.538666666666666e-07,
      "logits/chosen": -2.553589344024658,
      "logits/rejected": -2.0463337898254395,
      "logps/chosen": -197.44082641601562,
      "logps/rejected": -160.14385986328125,
      "loss": 0.0318,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.624379873275757,
      "rewards/margins": 6.100975036621094,
      "rewards/rejected": -8.72535514831543,
      "step": 4097
    },
    {
      "epoch": 1.6392,
      "grad_norm": 0.013818341307342052,
      "learning_rate": 4.537333333333333e-07,
      "logits/chosen": -2.8681464195251465,
      "logits/rejected": -2.1138648986816406,
      "logps/chosen": -92.27871704101562,
      "logps/rejected": -261.9910583496094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9216629266738892,
      "rewards/margins": 12.716710090637207,
      "rewards/rejected": -11.795047760009766,
      "step": 4098
    },
    {
      "epoch": 1.6396,
      "grad_norm": 0.05763746798038483,
      "learning_rate": 4.536e-07,
      "logits/chosen": -2.9959306716918945,
      "logits/rejected": -2.679454803466797,
      "logps/chosen": -68.06199645996094,
      "logps/rejected": -111.99818420410156,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4702394008636475,
      "rewards/margins": 8.330839157104492,
      "rewards/rejected": -6.860600471496582,
      "step": 4099
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.43890538811683655,
      "learning_rate": 4.534666666666667e-07,
      "logits/chosen": -3.012943744659424,
      "logits/rejected": -2.666779041290283,
      "logps/chosen": -74.00021362304688,
      "logps/rejected": -96.23623657226562,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.23487740755081177,
      "rewards/margins": 5.803096771240234,
      "rewards/rejected": -6.0379743576049805,
      "step": 4100
    },
    {
      "epoch": 1.6404,
      "grad_norm": 0.0304743442684412,
      "learning_rate": 4.5333333333333326e-07,
      "logits/chosen": -2.4057633876800537,
      "logits/rejected": -1.8870997428894043,
      "logps/chosen": -206.29461669921875,
      "logps/rejected": -214.25340270996094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9697624444961548,
      "rewards/margins": 9.929243087768555,
      "rewards/rejected": -11.899004936218262,
      "step": 4101
    },
    {
      "epoch": 1.6408,
      "grad_norm": 0.0007429186371155083,
      "learning_rate": 4.5319999999999996e-07,
      "logits/chosen": -2.6320037841796875,
      "logits/rejected": -1.9412903785705566,
      "logps/chosen": -91.33834838867188,
      "logps/rejected": -211.9269561767578,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.14414560794830322,
      "rewards/margins": 12.847583770751953,
      "rewards/rejected": -12.991729736328125,
      "step": 4102
    },
    {
      "epoch": 1.6412,
      "grad_norm": 0.1287028193473816,
      "learning_rate": 4.5306666666666665e-07,
      "logits/chosen": -2.8695855140686035,
      "logits/rejected": -2.6251745223999023,
      "logps/chosen": -60.85735321044922,
      "logps/rejected": -101.50387573242188,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6082429885864258,
      "rewards/margins": 8.036788940429688,
      "rewards/rejected": -6.4285454750061035,
      "step": 4103
    },
    {
      "epoch": 1.6416,
      "grad_norm": 0.18801750242710114,
      "learning_rate": 4.5293333333333334e-07,
      "logits/chosen": -3.0436463356018066,
      "logits/rejected": -2.9175562858581543,
      "logps/chosen": -65.11430358886719,
      "logps/rejected": -95.86990356445312,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.009180068969726562,
      "rewards/margins": 6.30096435546875,
      "rewards/rejected": -6.310144424438477,
      "step": 4104
    },
    {
      "epoch": 1.642,
      "grad_norm": 0.6367607116699219,
      "learning_rate": 4.528e-07,
      "logits/chosen": -3.0575919151306152,
      "logits/rejected": -3.0256786346435547,
      "logps/chosen": -75.10636901855469,
      "logps/rejected": -112.30035400390625,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5865949988365173,
      "rewards/margins": 7.742071628570557,
      "rewards/rejected": -8.328666687011719,
      "step": 4105
    },
    {
      "epoch": 1.6423999999999999,
      "grad_norm": 0.004168901592493057,
      "learning_rate": 4.526666666666666e-07,
      "logits/chosen": -2.562161922454834,
      "logits/rejected": -1.8095207214355469,
      "logps/chosen": -82.74942016601562,
      "logps/rejected": -250.05593872070312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5508718490600586,
      "rewards/margins": 12.618536949157715,
      "rewards/rejected": -12.067665100097656,
      "step": 4106
    },
    {
      "epoch": 1.6428,
      "grad_norm": 0.23132362961769104,
      "learning_rate": 4.525333333333333e-07,
      "logits/chosen": -2.690591812133789,
      "logits/rejected": -2.4347052574157715,
      "logps/chosen": -155.75689697265625,
      "logps/rejected": -166.29257202148438,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.356274127960205,
      "rewards/margins": 7.477546215057373,
      "rewards/rejected": -9.833820343017578,
      "step": 4107
    },
    {
      "epoch": 1.6432,
      "grad_norm": 0.05479617416858673,
      "learning_rate": 4.524e-07,
      "logits/chosen": -2.690676689147949,
      "logits/rejected": -2.183878183364868,
      "logps/chosen": -68.932861328125,
      "logps/rejected": -150.64627075195312,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7529295086860657,
      "rewards/margins": 10.498984336853027,
      "rewards/rejected": -9.746054649353027,
      "step": 4108
    },
    {
      "epoch": 1.6436,
      "grad_norm": 0.42979350686073303,
      "learning_rate": 4.5226666666666664e-07,
      "logits/chosen": -2.7826499938964844,
      "logits/rejected": -2.7014389038085938,
      "logps/chosen": -98.9064712524414,
      "logps/rejected": -97.36856842041016,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06411077082157135,
      "rewards/margins": 5.56973123550415,
      "rewards/rejected": -5.50562047958374,
      "step": 4109
    },
    {
      "epoch": 1.6440000000000001,
      "grad_norm": 0.006932214833796024,
      "learning_rate": 4.5213333333333333e-07,
      "logits/chosen": -2.881300926208496,
      "logits/rejected": -2.1676647663116455,
      "logps/chosen": -81.53600311279297,
      "logps/rejected": -188.09854125976562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5194628238677979,
      "rewards/margins": 11.697909355163574,
      "rewards/rejected": -10.178446769714355,
      "step": 4110
    },
    {
      "epoch": 1.6444,
      "grad_norm": 0.14499716460704803,
      "learning_rate": 4.5199999999999997e-07,
      "logits/chosen": -2.762622594833374,
      "logits/rejected": -2.380528450012207,
      "logps/chosen": -110.0597152709961,
      "logps/rejected": -136.75155639648438,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4453915357589722,
      "rewards/margins": 7.737722873687744,
      "rewards/rejected": -9.183115005493164,
      "step": 4111
    },
    {
      "epoch": 1.6448,
      "grad_norm": 0.1294742077589035,
      "learning_rate": 4.5186666666666666e-07,
      "logits/chosen": -3.1079115867614746,
      "logits/rejected": -2.644479274749756,
      "logps/chosen": -53.12580108642578,
      "logps/rejected": -123.95695495605469,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19193288683891296,
      "rewards/margins": 8.625808715820312,
      "rewards/rejected": -8.433876037597656,
      "step": 4112
    },
    {
      "epoch": 1.6452,
      "grad_norm": 0.00971286278218031,
      "learning_rate": 4.517333333333333e-07,
      "logits/chosen": -2.8644518852233887,
      "logits/rejected": -2.115995168685913,
      "logps/chosen": -71.46773529052734,
      "logps/rejected": -169.8415985107422,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.244757890701294,
      "rewards/margins": 12.84874153137207,
      "rewards/rejected": -11.603983879089355,
      "step": 4113
    },
    {
      "epoch": 1.6456,
      "grad_norm": 0.5940761566162109,
      "learning_rate": 4.516e-07,
      "logits/chosen": -2.463520050048828,
      "logits/rejected": -2.1338772773742676,
      "logps/chosen": -128.73471069335938,
      "logps/rejected": -123.89751434326172,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9089959859848022,
      "rewards/margins": 5.620052337646484,
      "rewards/rejected": -7.529047966003418,
      "step": 4114
    },
    {
      "epoch": 1.646,
      "grad_norm": 0.010112418793141842,
      "learning_rate": 4.514666666666667e-07,
      "logits/chosen": -2.3387115001678467,
      "logits/rejected": -1.6163949966430664,
      "logps/chosen": -85.66754913330078,
      "logps/rejected": -205.23406982421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7036681175231934,
      "rewards/margins": 10.22653579711914,
      "rewards/rejected": -8.522867202758789,
      "step": 4115
    },
    {
      "epoch": 1.6463999999999999,
      "grad_norm": 0.09057072550058365,
      "learning_rate": 4.5133333333333327e-07,
      "logits/chosen": -2.640120029449463,
      "logits/rejected": -2.25229549407959,
      "logps/chosen": -152.40463256835938,
      "logps/rejected": -147.38829040527344,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09396514296531677,
      "rewards/margins": 9.668444633483887,
      "rewards/rejected": -9.574479103088379,
      "step": 4116
    },
    {
      "epoch": 1.6468,
      "grad_norm": 1.9880874156951904,
      "learning_rate": 4.5119999999999996e-07,
      "logits/chosen": -2.7695517539978027,
      "logits/rejected": -2.9144859313964844,
      "logps/chosen": -61.09125518798828,
      "logps/rejected": -74.83369445800781,
      "loss": 0.0311,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2888551950454712,
      "rewards/margins": 3.981525421142578,
      "rewards/rejected": -4.270380973815918,
      "step": 4117
    },
    {
      "epoch": 1.6472,
      "grad_norm": 1.1586276292800903,
      "learning_rate": 4.5106666666666666e-07,
      "logits/chosen": -2.9096579551696777,
      "logits/rejected": -2.6477742195129395,
      "logps/chosen": -95.30485534667969,
      "logps/rejected": -150.45834350585938,
      "loss": 0.0063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.29662013053894043,
      "rewards/margins": 9.974660873413086,
      "rewards/rejected": -9.678041458129883,
      "step": 4118
    },
    {
      "epoch": 1.6476,
      "grad_norm": 0.8769190907478333,
      "learning_rate": 4.5093333333333335e-07,
      "logits/chosen": -2.7155911922454834,
      "logits/rejected": -2.3225958347320557,
      "logps/chosen": -141.5343017578125,
      "logps/rejected": -139.19203186035156,
      "loss": 0.0048,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5743145942687988,
      "rewards/margins": 7.929224491119385,
      "rewards/rejected": -6.354909896850586,
      "step": 4119
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 0.005396182183176279,
      "learning_rate": 4.5079999999999993e-07,
      "logits/chosen": -2.7876272201538086,
      "logits/rejected": -2.2419261932373047,
      "logps/chosen": -84.08258056640625,
      "logps/rejected": -156.00326538085938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.004796266555786,
      "rewards/margins": 12.511028289794922,
      "rewards/rejected": -10.506231307983398,
      "step": 4120
    },
    {
      "epoch": 1.6484,
      "grad_norm": 29.92232894897461,
      "learning_rate": 4.506666666666666e-07,
      "logits/chosen": -2.6409552097320557,
      "logits/rejected": -2.3516924381256104,
      "logps/chosen": -186.56602478027344,
      "logps/rejected": -141.25987243652344,
      "loss": 0.1727,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.181089401245117,
      "rewards/margins": 5.1081132888793945,
      "rewards/rejected": -8.289202690124512,
      "step": 4121
    },
    {
      "epoch": 1.6488,
      "grad_norm": 0.04519965872168541,
      "learning_rate": 4.505333333333333e-07,
      "logits/chosen": -2.7784764766693115,
      "logits/rejected": -2.220414161682129,
      "logps/chosen": -82.61392211914062,
      "logps/rejected": -147.51773071289062,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9933229684829712,
      "rewards/margins": 9.757619857788086,
      "rewards/rejected": -10.750943183898926,
      "step": 4122
    },
    {
      "epoch": 1.6492,
      "grad_norm": 0.03686394542455673,
      "learning_rate": 4.504e-07,
      "logits/chosen": -2.4094674587249756,
      "logits/rejected": -1.5523085594177246,
      "logps/chosen": -129.23965454101562,
      "logps/rejected": -199.9374542236328,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7777454257011414,
      "rewards/margins": 12.227380752563477,
      "rewards/rejected": -13.005125045776367,
      "step": 4123
    },
    {
      "epoch": 1.6496,
      "grad_norm": 0.0002869327727239579,
      "learning_rate": 4.5026666666666665e-07,
      "logits/chosen": -2.8974475860595703,
      "logits/rejected": -1.97934889793396,
      "logps/chosen": -112.50638580322266,
      "logps/rejected": -208.58621215820312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5372333526611328,
      "rewards/margins": 14.18386459350586,
      "rewards/rejected": -13.646631240844727,
      "step": 4124
    },
    {
      "epoch": 1.65,
      "grad_norm": 8.243239402770996,
      "learning_rate": 4.501333333333333e-07,
      "logits/chosen": -2.7196927070617676,
      "logits/rejected": -2.212831497192383,
      "logps/chosen": -82.25947570800781,
      "logps/rejected": -132.00572204589844,
      "loss": 0.0847,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7942783236503601,
      "rewards/margins": 8.08395004272461,
      "rewards/rejected": -8.878229141235352,
      "step": 4125
    },
    {
      "epoch": 1.6503999999999999,
      "grad_norm": 0.05875960364937782,
      "learning_rate": 4.5e-07,
      "logits/chosen": -2.7552576065063477,
      "logits/rejected": -2.0210440158843994,
      "logps/chosen": -122.30340576171875,
      "logps/rejected": -142.65208435058594,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.160289004445076,
      "rewards/margins": 9.940969467163086,
      "rewards/rejected": -9.780680656433105,
      "step": 4126
    },
    {
      "epoch": 1.6508,
      "grad_norm": 8.013392448425293,
      "learning_rate": 4.4986666666666667e-07,
      "logits/chosen": -2.8085761070251465,
      "logits/rejected": -2.5240511894226074,
      "logps/chosen": -116.32937622070312,
      "logps/rejected": -102.39376831054688,
      "loss": 0.0431,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.49005547165870667,
      "rewards/margins": 6.272578716278076,
      "rewards/rejected": -6.76263427734375,
      "step": 4127
    },
    {
      "epoch": 1.6512,
      "grad_norm": 0.19237707555294037,
      "learning_rate": 4.497333333333333e-07,
      "logits/chosen": -2.777522087097168,
      "logits/rejected": -2.5754237174987793,
      "logps/chosen": -111.75569152832031,
      "logps/rejected": -169.70785522460938,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.471181869506836,
      "rewards/margins": 8.773478507995605,
      "rewards/rejected": -11.244660377502441,
      "step": 4128
    },
    {
      "epoch": 1.6516,
      "grad_norm": 0.4195586144924164,
      "learning_rate": 4.496e-07,
      "logits/chosen": -2.889847993850708,
      "logits/rejected": -2.6921234130859375,
      "logps/chosen": -78.91490173339844,
      "logps/rejected": -114.80754089355469,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.41279566287994385,
      "rewards/margins": 6.343652725219727,
      "rewards/rejected": -6.756448268890381,
      "step": 4129
    },
    {
      "epoch": 1.6520000000000001,
      "grad_norm": 0.02550610713660717,
      "learning_rate": 4.4946666666666664e-07,
      "logits/chosen": -2.646646022796631,
      "logits/rejected": -2.4010415077209473,
      "logps/chosen": -84.69805145263672,
      "logps/rejected": -180.4801788330078,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9903625249862671,
      "rewards/margins": 9.876991271972656,
      "rewards/rejected": -8.886629104614258,
      "step": 4130
    },
    {
      "epoch": 1.6524,
      "grad_norm": 7.0652875900268555,
      "learning_rate": 4.493333333333333e-07,
      "logits/chosen": -2.580303192138672,
      "logits/rejected": -2.024359941482544,
      "logps/chosen": -193.0006866455078,
      "logps/rejected": -142.9283447265625,
      "loss": 0.0315,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.296559810638428,
      "rewards/margins": 5.32874059677124,
      "rewards/rejected": -9.625300407409668,
      "step": 4131
    },
    {
      "epoch": 1.6528,
      "grad_norm": 0.0005463853012770414,
      "learning_rate": 4.4919999999999997e-07,
      "logits/chosen": -2.396183490753174,
      "logits/rejected": -1.5882610082626343,
      "logps/chosen": -156.2034149169922,
      "logps/rejected": -235.59555053710938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3932815492153168,
      "rewards/margins": 14.334734916687012,
      "rewards/rejected": -14.728015899658203,
      "step": 4132
    },
    {
      "epoch": 1.6532,
      "grad_norm": 0.005476356949657202,
      "learning_rate": 4.4906666666666666e-07,
      "logits/chosen": -2.961890459060669,
      "logits/rejected": -2.35068941116333,
      "logps/chosen": -57.102500915527344,
      "logps/rejected": -191.4918212890625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6412750482559204,
      "rewards/margins": 14.028177261352539,
      "rewards/rejected": -13.38690185546875,
      "step": 4133
    },
    {
      "epoch": 1.6536,
      "grad_norm": 1.2026070356369019,
      "learning_rate": 4.4893333333333336e-07,
      "logits/chosen": -2.969985246658325,
      "logits/rejected": -2.721364974975586,
      "logps/chosen": -48.36063766479492,
      "logps/rejected": -129.76657104492188,
      "loss": 0.0115,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5963438153266907,
      "rewards/margins": 9.223215103149414,
      "rewards/rejected": -8.626871109008789,
      "step": 4134
    },
    {
      "epoch": 1.654,
      "grad_norm": 0.06623765826225281,
      "learning_rate": 4.4879999999999994e-07,
      "logits/chosen": -2.8179311752319336,
      "logits/rejected": -2.3739356994628906,
      "logps/chosen": -100.36810302734375,
      "logps/rejected": -140.00738525390625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2128334045410156,
      "rewards/margins": 7.940558433532715,
      "rewards/rejected": -9.15339183807373,
      "step": 4135
    },
    {
      "epoch": 1.6543999999999999,
      "grad_norm": 0.029784930869936943,
      "learning_rate": 4.4866666666666663e-07,
      "logits/chosen": -3.0666306018829346,
      "logits/rejected": -2.5295639038085938,
      "logps/chosen": -46.777591705322266,
      "logps/rejected": -137.65200805664062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5644984245300293,
      "rewards/margins": 9.73106575012207,
      "rewards/rejected": -9.1665678024292,
      "step": 4136
    },
    {
      "epoch": 1.6548,
      "grad_norm": 343.8042297363281,
      "learning_rate": 4.485333333333333e-07,
      "logits/chosen": -2.463864803314209,
      "logits/rejected": -2.328465223312378,
      "logps/chosen": -222.13290405273438,
      "logps/rejected": -121.43065643310547,
      "loss": 2.2291,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -7.972908973693848,
      "rewards/margins": 0.12656521797180176,
      "rewards/rejected": -8.09947395324707,
      "step": 4137
    },
    {
      "epoch": 1.6552,
      "grad_norm": 0.43509742617607117,
      "learning_rate": 4.484e-07,
      "logits/chosen": -2.4842772483825684,
      "logits/rejected": -2.041794776916504,
      "logps/chosen": -209.1980438232422,
      "logps/rejected": -138.98025512695312,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3578277826309204,
      "rewards/margins": 7.589658737182617,
      "rewards/rejected": -7.94748592376709,
      "step": 4138
    },
    {
      "epoch": 1.6556,
      "grad_norm": 0.8620109558105469,
      "learning_rate": 4.482666666666666e-07,
      "logits/chosen": -3.04158091545105,
      "logits/rejected": -2.8263864517211914,
      "logps/chosen": -74.388427734375,
      "logps/rejected": -89.48614501953125,
      "loss": 0.0075,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6092939376831055,
      "rewards/margins": 5.536590099334717,
      "rewards/rejected": -4.927296161651611,
      "step": 4139
    },
    {
      "epoch": 1.6560000000000001,
      "grad_norm": 5.603920936584473,
      "learning_rate": 4.481333333333333e-07,
      "logits/chosen": -2.9232826232910156,
      "logits/rejected": -2.72706937789917,
      "logps/chosen": -106.22989654541016,
      "logps/rejected": -108.69657135009766,
      "loss": 0.0287,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3378177881240845,
      "rewards/margins": 5.202157974243164,
      "rewards/rejected": -6.539976119995117,
      "step": 4140
    },
    {
      "epoch": 1.6564,
      "grad_norm": 4.34376335144043,
      "learning_rate": 4.48e-07,
      "logits/chosen": -2.977571487426758,
      "logits/rejected": -2.604912281036377,
      "logps/chosen": -60.44074249267578,
      "logps/rejected": -100.77241516113281,
      "loss": 0.0259,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5307996869087219,
      "rewards/margins": 5.900278568267822,
      "rewards/rejected": -6.43107795715332,
      "step": 4141
    },
    {
      "epoch": 1.6568,
      "grad_norm": 0.011112111620604992,
      "learning_rate": 4.478666666666667e-07,
      "logits/chosen": -2.6906354427337646,
      "logits/rejected": -1.9956281185150146,
      "logps/chosen": -115.1772232055664,
      "logps/rejected": -162.2476806640625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7544649243354797,
      "rewards/margins": 10.998015403747559,
      "rewards/rejected": -10.243550300598145,
      "step": 4142
    },
    {
      "epoch": 1.6572,
      "grad_norm": 0.0009412592044100165,
      "learning_rate": 4.477333333333333e-07,
      "logits/chosen": -2.5401744842529297,
      "logits/rejected": -1.9449102878570557,
      "logps/chosen": -149.72315979003906,
      "logps/rejected": -217.25619506835938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.20024719834327698,
      "rewards/margins": 12.686248779296875,
      "rewards/rejected": -12.886495590209961,
      "step": 4143
    },
    {
      "epoch": 1.6576,
      "grad_norm": 0.15789131820201874,
      "learning_rate": 4.4759999999999996e-07,
      "logits/chosen": -3.173715353012085,
      "logits/rejected": -2.728219985961914,
      "logps/chosen": -49.59857940673828,
      "logps/rejected": -167.67709350585938,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9773505926132202,
      "rewards/margins": 10.526662826538086,
      "rewards/rejected": -11.504013061523438,
      "step": 4144
    },
    {
      "epoch": 1.658,
      "grad_norm": 0.008879915811121464,
      "learning_rate": 4.4746666666666665e-07,
      "logits/chosen": -2.7713208198547363,
      "logits/rejected": -2.2763094902038574,
      "logps/chosen": -46.03868865966797,
      "logps/rejected": -152.31033325195312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5364025831222534,
      "rewards/margins": 10.439130783081055,
      "rewards/rejected": -8.902727127075195,
      "step": 4145
    },
    {
      "epoch": 1.6583999999999999,
      "grad_norm": 3.608635187149048,
      "learning_rate": 4.4733333333333334e-07,
      "logits/chosen": -3.029259443283081,
      "logits/rejected": -2.8813750743865967,
      "logps/chosen": -55.05880355834961,
      "logps/rejected": -119.212158203125,
      "loss": 0.0235,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.31489086151123047,
      "rewards/margins": 7.565112590789795,
      "rewards/rejected": -7.880003452301025,
      "step": 4146
    },
    {
      "epoch": 1.6588,
      "grad_norm": 0.000240402776398696,
      "learning_rate": 4.472e-07,
      "logits/chosen": -2.1358022689819336,
      "logits/rejected": -1.4623923301696777,
      "logps/chosen": -245.37789916992188,
      "logps/rejected": -260.0548095703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.16244661808013916,
      "rewards/margins": 14.124053955078125,
      "rewards/rejected": -14.286499977111816,
      "step": 4147
    },
    {
      "epoch": 1.6592,
      "grad_norm": 0.16254422068595886,
      "learning_rate": 4.4706666666666667e-07,
      "logits/chosen": -2.5379133224487305,
      "logits/rejected": -2.2371861934661865,
      "logps/chosen": -234.89686584472656,
      "logps/rejected": -213.41778564453125,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.477241516113281,
      "rewards/margins": 7.747454643249512,
      "rewards/rejected": -14.224696159362793,
      "step": 4148
    },
    {
      "epoch": 1.6596,
      "grad_norm": 0.025260023772716522,
      "learning_rate": 4.469333333333333e-07,
      "logits/chosen": -2.3860185146331787,
      "logits/rejected": -1.5025430917739868,
      "logps/chosen": -152.11013793945312,
      "logps/rejected": -199.0316162109375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4782814979553223,
      "rewards/margins": 11.161117553710938,
      "rewards/rejected": -12.639399528503418,
      "step": 4149
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 0.003290200373157859,
      "learning_rate": 4.4679999999999995e-07,
      "logits/chosen": -2.565513849258423,
      "logits/rejected": -2.3638088703155518,
      "logps/chosen": -138.15582275390625,
      "logps/rejected": -212.31829833984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0643776655197144,
      "rewards/margins": 12.487380981445312,
      "rewards/rejected": -11.423002243041992,
      "step": 4150
    },
    {
      "epoch": 1.6604,
      "grad_norm": 0.014615979045629501,
      "learning_rate": 4.4666666666666664e-07,
      "logits/chosen": -2.453549861907959,
      "logits/rejected": -1.5150225162506104,
      "logps/chosen": -135.27362060546875,
      "logps/rejected": -179.67288208007812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.03445279598236084,
      "rewards/margins": 10.755624771118164,
      "rewards/rejected": -10.790078163146973,
      "step": 4151
    },
    {
      "epoch": 1.6608,
      "grad_norm": 0.03615783900022507,
      "learning_rate": 4.4653333333333333e-07,
      "logits/chosen": -2.747368335723877,
      "logits/rejected": -2.111372709274292,
      "logps/chosen": -112.71488952636719,
      "logps/rejected": -162.5737762451172,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.846360445022583,
      "rewards/margins": 10.885590553283691,
      "rewards/rejected": -10.039229393005371,
      "step": 4152
    },
    {
      "epoch": 1.6612,
      "grad_norm": 0.06067522242665291,
      "learning_rate": 4.464e-07,
      "logits/chosen": -2.6081180572509766,
      "logits/rejected": -2.5065393447875977,
      "logps/chosen": -123.56259155273438,
      "logps/rejected": -156.06382751464844,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0062038898468018,
      "rewards/margins": 8.216521263122559,
      "rewards/rejected": -9.222724914550781,
      "step": 4153
    },
    {
      "epoch": 1.6616,
      "grad_norm": 3.611772298812866,
      "learning_rate": 4.462666666666666e-07,
      "logits/chosen": -2.439720630645752,
      "logits/rejected": -1.8359450101852417,
      "logps/chosen": -161.33425903320312,
      "logps/rejected": -151.95201110839844,
      "loss": 0.0222,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.104315280914307,
      "rewards/margins": 4.385356903076172,
      "rewards/rejected": -8.48967170715332,
      "step": 4154
    },
    {
      "epoch": 1.662,
      "grad_norm": 1.2971031665802002,
      "learning_rate": 4.461333333333333e-07,
      "logits/chosen": -2.7775933742523193,
      "logits/rejected": -2.512425184249878,
      "logps/chosen": -151.6559600830078,
      "logps/rejected": -169.9688720703125,
      "loss": 0.0077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.003796100616455,
      "rewards/margins": 4.8651628494262695,
      "rewards/rejected": -8.868959426879883,
      "step": 4155
    },
    {
      "epoch": 1.6623999999999999,
      "grad_norm": 0.001189833739772439,
      "learning_rate": 4.46e-07,
      "logits/chosen": -2.781081199645996,
      "logits/rejected": -1.919346809387207,
      "logps/chosen": -76.52247619628906,
      "logps/rejected": -332.74365234375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2340980768203735,
      "rewards/margins": 12.900314331054688,
      "rewards/rejected": -11.666215896606445,
      "step": 4156
    },
    {
      "epoch": 1.6627999999999998,
      "grad_norm": 0.3469350039958954,
      "learning_rate": 4.458666666666667e-07,
      "logits/chosen": -2.9487686157226562,
      "logits/rejected": -2.574444055557251,
      "logps/chosen": -105.54452514648438,
      "logps/rejected": -131.18800354003906,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0972213745117188,
      "rewards/margins": 7.499614715576172,
      "rewards/rejected": -8.59683609008789,
      "step": 4157
    },
    {
      "epoch": 1.6632,
      "grad_norm": 0.020668860524892807,
      "learning_rate": 4.457333333333333e-07,
      "logits/chosen": -2.891507625579834,
      "logits/rejected": -2.7208282947540283,
      "logps/chosen": -122.00963592529297,
      "logps/rejected": -168.9702606201172,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08130797743797302,
      "rewards/margins": 9.956939697265625,
      "rewards/rejected": -10.038248062133789,
      "step": 4158
    },
    {
      "epoch": 1.6636,
      "grad_norm": 0.008471877314150333,
      "learning_rate": 4.4559999999999997e-07,
      "logits/chosen": -2.6175241470336914,
      "logits/rejected": -2.111292839050293,
      "logps/chosen": -114.618896484375,
      "logps/rejected": -149.66209411621094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.46001398563385,
      "rewards/margins": 10.328380584716797,
      "rewards/rejected": -8.868367195129395,
      "step": 4159
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 182.45201110839844,
      "learning_rate": 4.4546666666666666e-07,
      "logits/chosen": -2.861300468444824,
      "logits/rejected": -2.6748781204223633,
      "logps/chosen": -182.8285675048828,
      "logps/rejected": -99.32289123535156,
      "loss": 1.9021,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -3.938965320587158,
      "rewards/margins": 1.740638017654419,
      "rewards/rejected": -5.679603576660156,
      "step": 4160
    },
    {
      "epoch": 1.6644,
      "grad_norm": 0.0069395494647324085,
      "learning_rate": 4.4533333333333335e-07,
      "logits/chosen": -2.6630544662475586,
      "logits/rejected": -2.271472692489624,
      "logps/chosen": -112.4798583984375,
      "logps/rejected": -211.43707275390625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8672706484794617,
      "rewards/margins": 10.87973403930664,
      "rewards/rejected": -10.012463569641113,
      "step": 4161
    },
    {
      "epoch": 1.6648,
      "grad_norm": 0.976305365562439,
      "learning_rate": 4.452e-07,
      "logits/chosen": -2.979135751724243,
      "logits/rejected": -2.884340524673462,
      "logps/chosen": -92.39704895019531,
      "logps/rejected": -83.47291564941406,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7397063970565796,
      "rewards/margins": 6.164247512817383,
      "rewards/rejected": -5.424540996551514,
      "step": 4162
    },
    {
      "epoch": 1.6652,
      "grad_norm": 0.006548741832375526,
      "learning_rate": 4.4506666666666663e-07,
      "logits/chosen": -2.5837645530700684,
      "logits/rejected": -2.262538433074951,
      "logps/chosen": -71.83641815185547,
      "logps/rejected": -204.15858459472656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0982558727264404,
      "rewards/margins": 11.571243286132812,
      "rewards/rejected": -10.47298812866211,
      "step": 4163
    },
    {
      "epoch": 1.6656,
      "grad_norm": 0.04378193989396095,
      "learning_rate": 4.449333333333333e-07,
      "logits/chosen": -3.186178684234619,
      "logits/rejected": -2.502096176147461,
      "logps/chosen": -52.10157775878906,
      "logps/rejected": -124.93330383300781,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5863388180732727,
      "rewards/margins": 8.671480178833008,
      "rewards/rejected": -8.085142135620117,
      "step": 4164
    },
    {
      "epoch": 1.666,
      "grad_norm": 0.1262422800064087,
      "learning_rate": 4.4479999999999996e-07,
      "logits/chosen": -2.959379196166992,
      "logits/rejected": -2.453145980834961,
      "logps/chosen": -64.73249816894531,
      "logps/rejected": -137.74847412109375,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.356367290019989,
      "rewards/margins": 8.770891189575195,
      "rewards/rejected": -9.12725830078125,
      "step": 4165
    },
    {
      "epoch": 1.6663999999999999,
      "grad_norm": 1.783463478088379,
      "learning_rate": 4.4466666666666665e-07,
      "logits/chosen": -3.0625035762786865,
      "logits/rejected": -2.9693756103515625,
      "logps/chosen": -69.75373077392578,
      "logps/rejected": -96.21794128417969,
      "loss": 0.0128,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.27987784147262573,
      "rewards/margins": 4.352477073669434,
      "rewards/rejected": -4.632355213165283,
      "step": 4166
    },
    {
      "epoch": 1.6667999999999998,
      "grad_norm": 0.8571630716323853,
      "learning_rate": 4.445333333333333e-07,
      "logits/chosen": -2.637113332748413,
      "logits/rejected": -2.1294174194335938,
      "logps/chosen": -104.30133056640625,
      "logps/rejected": -197.7665557861328,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.488759994506836,
      "rewards/margins": 10.113964080810547,
      "rewards/rejected": -13.602724075317383,
      "step": 4167
    },
    {
      "epoch": 1.6672,
      "grad_norm": 0.4038580656051636,
      "learning_rate": 4.444e-07,
      "logits/chosen": -2.752556324005127,
      "logits/rejected": -2.1876204013824463,
      "logps/chosen": -101.1043472290039,
      "logps/rejected": -138.5732421875,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.831950306892395,
      "rewards/margins": 9.223034858703613,
      "rewards/rejected": -8.391084671020508,
      "step": 4168
    },
    {
      "epoch": 1.6676,
      "grad_norm": 0.0007091259467415512,
      "learning_rate": 4.442666666666666e-07,
      "logits/chosen": -2.8415966033935547,
      "logits/rejected": -2.2452168464660645,
      "logps/chosen": -93.73478698730469,
      "logps/rejected": -202.56594848632812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.234513521194458,
      "rewards/margins": 12.689298629760742,
      "rewards/rejected": -13.923810958862305,
      "step": 4169
    },
    {
      "epoch": 1.6680000000000001,
      "grad_norm": 0.003227998735383153,
      "learning_rate": 4.441333333333333e-07,
      "logits/chosen": -2.715712070465088,
      "logits/rejected": -2.283947467803955,
      "logps/chosen": -124.40200805664062,
      "logps/rejected": -229.73245239257812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.282357394695282,
      "rewards/margins": 12.057258605957031,
      "rewards/rejected": -12.339614868164062,
      "step": 4170
    },
    {
      "epoch": 1.6684,
      "grad_norm": 0.10651744157075882,
      "learning_rate": 4.44e-07,
      "logits/chosen": -2.9835522174835205,
      "logits/rejected": -2.53190541267395,
      "logps/chosen": -91.47015380859375,
      "logps/rejected": -154.72994995117188,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.07021942734718323,
      "rewards/margins": 10.221536636352539,
      "rewards/rejected": -10.291755676269531,
      "step": 4171
    },
    {
      "epoch": 1.6688,
      "grad_norm": 0.07413826882839203,
      "learning_rate": 4.4386666666666664e-07,
      "logits/chosen": -3.0177979469299316,
      "logits/rejected": -2.64528751373291,
      "logps/chosen": -64.06695556640625,
      "logps/rejected": -127.75407409667969,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1627689599990845,
      "rewards/margins": 9.380599975585938,
      "rewards/rejected": -8.217830657958984,
      "step": 4172
    },
    {
      "epoch": 1.6692,
      "grad_norm": 53.859825134277344,
      "learning_rate": 4.437333333333333e-07,
      "logits/chosen": -2.7895047664642334,
      "logits/rejected": -2.222360372543335,
      "logps/chosen": -118.39366149902344,
      "logps/rejected": -165.14755249023438,
      "loss": 0.3779,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.7858784198760986,
      "rewards/margins": 8.768157958984375,
      "rewards/rejected": -9.554036140441895,
      "step": 4173
    },
    {
      "epoch": 1.6696,
      "grad_norm": 0.10674861818552017,
      "learning_rate": 4.436e-07,
      "logits/chosen": -2.78194522857666,
      "logits/rejected": -2.319042205810547,
      "logps/chosen": -141.43463134765625,
      "logps/rejected": -144.48062133789062,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3911014795303345,
      "rewards/margins": 9.572404861450195,
      "rewards/rejected": -9.963506698608398,
      "step": 4174
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.0011663902550935745,
      "learning_rate": 4.4346666666666667e-07,
      "logits/chosen": -2.452820301055908,
      "logits/rejected": -1.430635929107666,
      "logps/chosen": -145.73353576660156,
      "logps/rejected": -178.06912231445312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9730014801025391,
      "rewards/margins": 12.629159927368164,
      "rewards/rejected": -11.656158447265625,
      "step": 4175
    },
    {
      "epoch": 1.6703999999999999,
      "grad_norm": 4.2035298347473145,
      "learning_rate": 4.4333333333333336e-07,
      "logits/chosen": -2.583706855773926,
      "logits/rejected": -2.072111129760742,
      "logps/chosen": -124.410400390625,
      "logps/rejected": -194.18185424804688,
      "loss": 0.0199,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.201580047607422,
      "rewards/margins": 6.910243034362793,
      "rewards/rejected": -11.111823081970215,
      "step": 4176
    },
    {
      "epoch": 1.6707999999999998,
      "grad_norm": 0.0003270671295467764,
      "learning_rate": 4.4319999999999995e-07,
      "logits/chosen": -2.8360097408294678,
      "logits/rejected": -2.391296625137329,
      "logps/chosen": -57.14006042480469,
      "logps/rejected": -208.166259765625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25794583559036255,
      "rewards/margins": 13.586979866027832,
      "rewards/rejected": -13.329033851623535,
      "step": 4177
    },
    {
      "epoch": 1.6712,
      "grad_norm": 0.49532368779182434,
      "learning_rate": 4.4306666666666664e-07,
      "logits/chosen": -2.8911523818969727,
      "logits/rejected": -2.5102062225341797,
      "logps/chosen": -98.41749572753906,
      "logps/rejected": -119.97410583496094,
      "loss": 0.0055,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7707386016845703,
      "rewards/margins": 7.159147262573242,
      "rewards/rejected": -7.9298858642578125,
      "step": 4178
    },
    {
      "epoch": 1.6716,
      "grad_norm": 0.2543153464794159,
      "learning_rate": 4.4293333333333333e-07,
      "logits/chosen": -3.022697925567627,
      "logits/rejected": -2.6179404258728027,
      "logps/chosen": -56.573001861572266,
      "logps/rejected": -103.58789825439453,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.660287082195282,
      "rewards/margins": 7.314759254455566,
      "rewards/rejected": -6.6544718742370605,
      "step": 4179
    },
    {
      "epoch": 1.6720000000000002,
      "grad_norm": 0.49322813749313354,
      "learning_rate": 4.428e-07,
      "logits/chosen": -2.7056312561035156,
      "logits/rejected": -2.523470878601074,
      "logps/chosen": -113.38925170898438,
      "logps/rejected": -121.56993865966797,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.041057974100112915,
      "rewards/margins": 8.053132057189941,
      "rewards/rejected": -8.01207447052002,
      "step": 4180
    },
    {
      "epoch": 1.6724,
      "grad_norm": 0.02802167646586895,
      "learning_rate": 4.426666666666666e-07,
      "logits/chosen": -3.0883686542510986,
      "logits/rejected": -2.5831518173217773,
      "logps/chosen": -62.26569747924805,
      "logps/rejected": -162.47731018066406,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4567646086215973,
      "rewards/margins": 9.727771759033203,
      "rewards/rejected": -10.18453598022461,
      "step": 4181
    },
    {
      "epoch": 1.6728,
      "grad_norm": 0.5144457817077637,
      "learning_rate": 4.425333333333333e-07,
      "logits/chosen": -3.09633731842041,
      "logits/rejected": -2.59989333152771,
      "logps/chosen": -78.45037841796875,
      "logps/rejected": -140.35406494140625,
      "loss": 0.0051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.2553045749664307,
      "rewards/margins": 6.2396721839904785,
      "rewards/rejected": -8.494976997375488,
      "step": 4182
    },
    {
      "epoch": 1.6732,
      "grad_norm": 2.936941385269165,
      "learning_rate": 4.424e-07,
      "logits/chosen": -2.7332444190979004,
      "logits/rejected": -2.4170007705688477,
      "logps/chosen": -89.9493637084961,
      "logps/rejected": -138.57933044433594,
      "loss": 0.0161,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.165708541870117,
      "rewards/margins": 7.267958641052246,
      "rewards/rejected": -9.433667182922363,
      "step": 4183
    },
    {
      "epoch": 1.6736,
      "grad_norm": 0.15691231191158295,
      "learning_rate": 4.4226666666666663e-07,
      "logits/chosen": -2.824402332305908,
      "logits/rejected": -2.3166396617889404,
      "logps/chosen": -124.8388442993164,
      "logps/rejected": -132.0109100341797,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.02007216215133667,
      "rewards/margins": 8.182880401611328,
      "rewards/rejected": -8.20295238494873,
      "step": 4184
    },
    {
      "epoch": 1.674,
      "grad_norm": 0.13575777411460876,
      "learning_rate": 4.421333333333333e-07,
      "logits/chosen": -2.8160290718078613,
      "logits/rejected": -2.5859780311584473,
      "logps/chosen": -134.50596618652344,
      "logps/rejected": -149.48919677734375,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31026819348335266,
      "rewards/margins": 9.859793663024902,
      "rewards/rejected": -9.549525260925293,
      "step": 4185
    },
    {
      "epoch": 1.6743999999999999,
      "grad_norm": 0.00661705806851387,
      "learning_rate": 4.4199999999999996e-07,
      "logits/chosen": -2.97880220413208,
      "logits/rejected": -2.50872802734375,
      "logps/chosen": -103.07528686523438,
      "logps/rejected": -179.4824981689453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9719429016113281,
      "rewards/margins": 12.52815055847168,
      "rewards/rejected": -10.556207656860352,
      "step": 4186
    },
    {
      "epoch": 1.6747999999999998,
      "grad_norm": 0.009784857742488384,
      "learning_rate": 4.4186666666666665e-07,
      "logits/chosen": -3.009880542755127,
      "logits/rejected": -2.3287971019744873,
      "logps/chosen": -83.03467559814453,
      "logps/rejected": -192.04367065429688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7242122888565063,
      "rewards/margins": 13.057549476623535,
      "rewards/rejected": -11.333337783813477,
      "step": 4187
    },
    {
      "epoch": 1.6752,
      "grad_norm": 0.05122411996126175,
      "learning_rate": 4.417333333333333e-07,
      "logits/chosen": -2.8582139015197754,
      "logits/rejected": -2.543686866760254,
      "logps/chosen": -45.67103576660156,
      "logps/rejected": -145.826904296875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17935523390769958,
      "rewards/margins": 9.972309112548828,
      "rewards/rejected": -9.792953491210938,
      "step": 4188
    },
    {
      "epoch": 1.6756,
      "grad_norm": 3.0222907066345215,
      "learning_rate": 4.416e-07,
      "logits/chosen": -2.469884157180786,
      "logits/rejected": -2.3107175827026367,
      "logps/chosen": -188.7851104736328,
      "logps/rejected": -126.48005676269531,
      "loss": 0.0256,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.4194235801696777,
      "rewards/margins": 3.7118966579437256,
      "rewards/rejected": -7.131319999694824,
      "step": 4189
    },
    {
      "epoch": 1.6760000000000002,
      "grad_norm": 0.39310356974601746,
      "learning_rate": 4.414666666666667e-07,
      "logits/chosen": -2.946911573410034,
      "logits/rejected": -2.536717176437378,
      "logps/chosen": -84.9201889038086,
      "logps/rejected": -164.2122039794922,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5145409107208252,
      "rewards/margins": 11.666369438171387,
      "rewards/rejected": -11.15182876586914,
      "step": 4190
    },
    {
      "epoch": 1.6764000000000001,
      "grad_norm": 0.030510371550917625,
      "learning_rate": 4.413333333333333e-07,
      "logits/chosen": -2.5822229385375977,
      "logits/rejected": -2.2886180877685547,
      "logps/chosen": -75.37799835205078,
      "logps/rejected": -138.2223663330078,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4374992251396179,
      "rewards/margins": 8.73840045928955,
      "rewards/rejected": -9.175899505615234,
      "step": 4191
    },
    {
      "epoch": 1.6768,
      "grad_norm": 0.007993870414793491,
      "learning_rate": 4.4119999999999995e-07,
      "logits/chosen": -2.543435573577881,
      "logits/rejected": -1.8737215995788574,
      "logps/chosen": -78.80427551269531,
      "logps/rejected": -178.67877197265625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19250336289405823,
      "rewards/margins": 11.38317584991455,
      "rewards/rejected": -11.190671920776367,
      "step": 4192
    },
    {
      "epoch": 1.6772,
      "grad_norm": 0.018405921757221222,
      "learning_rate": 4.4106666666666665e-07,
      "logits/chosen": -3.0542097091674805,
      "logits/rejected": -2.4517314434051514,
      "logps/chosen": -60.22578048706055,
      "logps/rejected": -129.52279663085938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19096606969833374,
      "rewards/margins": 9.15135669708252,
      "rewards/rejected": -8.9603910446167,
      "step": 4193
    },
    {
      "epoch": 1.6776,
      "grad_norm": 0.587748110294342,
      "learning_rate": 4.4093333333333334e-07,
      "logits/chosen": -2.802046537399292,
      "logits/rejected": -2.3515095710754395,
      "logps/chosen": -154.11297607421875,
      "logps/rejected": -164.4986572265625,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.495661973953247,
      "rewards/margins": 8.52233600616455,
      "rewards/rejected": -10.017997741699219,
      "step": 4194
    },
    {
      "epoch": 1.678,
      "grad_norm": 0.029835665598511696,
      "learning_rate": 4.4080000000000003e-07,
      "logits/chosen": -2.6353001594543457,
      "logits/rejected": -1.8628971576690674,
      "logps/chosen": -90.37342834472656,
      "logps/rejected": -189.54953002929688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.606047511100769,
      "rewards/margins": 13.572330474853516,
      "rewards/rejected": -11.966282844543457,
      "step": 4195
    },
    {
      "epoch": 1.6784,
      "grad_norm": 0.15732631087303162,
      "learning_rate": 4.406666666666666e-07,
      "logits/chosen": -2.6548261642456055,
      "logits/rejected": -2.039628505706787,
      "logps/chosen": -75.27003479003906,
      "logps/rejected": -148.63597106933594,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5693081021308899,
      "rewards/margins": 9.444711685180664,
      "rewards/rejected": -8.87540340423584,
      "step": 4196
    },
    {
      "epoch": 1.6787999999999998,
      "grad_norm": 0.030632449313998222,
      "learning_rate": 4.405333333333333e-07,
      "logits/chosen": -2.772228717803955,
      "logits/rejected": -2.705613136291504,
      "logps/chosen": -90.93861389160156,
      "logps/rejected": -188.4310302734375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8886074423789978,
      "rewards/margins": 10.099214553833008,
      "rewards/rejected": -9.210607528686523,
      "step": 4197
    },
    {
      "epoch": 1.6792,
      "grad_norm": 0.5260164141654968,
      "learning_rate": 4.404e-07,
      "logits/chosen": -3.0614240169525146,
      "logits/rejected": -2.852725028991699,
      "logps/chosen": -38.041412353515625,
      "logps/rejected": -146.8284912109375,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19037282466888428,
      "rewards/margins": 9.397369384765625,
      "rewards/rejected": -9.20699691772461,
      "step": 4198
    },
    {
      "epoch": 1.6796,
      "grad_norm": 0.20418302714824677,
      "learning_rate": 4.4026666666666664e-07,
      "logits/chosen": -2.7793822288513184,
      "logits/rejected": -2.246422290802002,
      "logps/chosen": -60.588321685791016,
      "logps/rejected": -181.13636779785156,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3975820541381836,
      "rewards/margins": 12.766915321350098,
      "rewards/rejected": -12.369333267211914,
      "step": 4199
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.8021888732910156,
      "learning_rate": 4.401333333333333e-07,
      "logits/chosen": -3.047762870788574,
      "logits/rejected": -2.733004093170166,
      "logps/chosen": -68.24989318847656,
      "logps/rejected": -108.18968200683594,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6781198978424072,
      "rewards/margins": 6.98836612701416,
      "rewards/rejected": -6.310245990753174,
      "step": 4200
    },
    {
      "epoch": 1.6804000000000001,
      "grad_norm": 0.03349743410944939,
      "learning_rate": 4.3999999999999997e-07,
      "logits/chosen": -2.59356689453125,
      "logits/rejected": -2.2064454555511475,
      "logps/chosen": -108.76805114746094,
      "logps/rejected": -216.9022216796875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1990383267402649,
      "rewards/margins": 9.978179931640625,
      "rewards/rejected": -10.177217483520508,
      "step": 4201
    },
    {
      "epoch": 1.6808,
      "grad_norm": 0.04255286604166031,
      "learning_rate": 4.3986666666666666e-07,
      "logits/chosen": -2.4219162464141846,
      "logits/rejected": -1.9900453090667725,
      "logps/chosen": -119.86100006103516,
      "logps/rejected": -177.83831787109375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.603174090385437,
      "rewards/margins": 9.108726501464844,
      "rewards/rejected": -9.71190071105957,
      "step": 4202
    },
    {
      "epoch": 1.6812,
      "grad_norm": 0.005670260172337294,
      "learning_rate": 4.397333333333333e-07,
      "logits/chosen": -2.5404486656188965,
      "logits/rejected": -1.920536756515503,
      "logps/chosen": -122.87618255615234,
      "logps/rejected": -189.19715881347656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.18240472674369812,
      "rewards/margins": 11.665321350097656,
      "rewards/rejected": -11.847725868225098,
      "step": 4203
    },
    {
      "epoch": 1.6816,
      "grad_norm": 0.00599894393235445,
      "learning_rate": 4.396e-07,
      "logits/chosen": -2.8528974056243896,
      "logits/rejected": -2.179316997528076,
      "logps/chosen": -116.17256164550781,
      "logps/rejected": -205.62136840820312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.24888229370117188,
      "rewards/margins": 12.676155090332031,
      "rewards/rejected": -12.925037384033203,
      "step": 4204
    },
    {
      "epoch": 1.682,
      "grad_norm": 0.027211258187890053,
      "learning_rate": 4.3946666666666663e-07,
      "logits/chosen": -2.804652690887451,
      "logits/rejected": -2.3594346046447754,
      "logps/chosen": -104.54661560058594,
      "logps/rejected": -161.45651245117188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6598331332206726,
      "rewards/margins": 10.242823600769043,
      "rewards/rejected": -10.902656555175781,
      "step": 4205
    },
    {
      "epoch": 1.6824,
      "grad_norm": 0.046499427407979965,
      "learning_rate": 4.393333333333333e-07,
      "logits/chosen": -3.130373954772949,
      "logits/rejected": -2.7830123901367188,
      "logps/chosen": -73.2516098022461,
      "logps/rejected": -128.16653442382812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5071665048599243,
      "rewards/margins": 9.155818939208984,
      "rewards/rejected": -7.64865255355835,
      "step": 4206
    },
    {
      "epoch": 1.6827999999999999,
      "grad_norm": 0.012648205272853374,
      "learning_rate": 4.3919999999999996e-07,
      "logits/chosen": -2.287778377532959,
      "logits/rejected": -1.5342280864715576,
      "logps/chosen": -143.12045288085938,
      "logps/rejected": -213.446044921875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40599673986434937,
      "rewards/margins": 11.824586868286133,
      "rewards/rejected": -11.418590545654297,
      "step": 4207
    },
    {
      "epoch": 1.6832,
      "grad_norm": 0.04397683963179588,
      "learning_rate": 4.3906666666666665e-07,
      "logits/chosen": -3.0398755073547363,
      "logits/rejected": -2.614447593688965,
      "logps/chosen": -67.30097198486328,
      "logps/rejected": -253.3663787841797,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6305555105209351,
      "rewards/margins": 10.910223960876465,
      "rewards/rejected": -10.279668807983398,
      "step": 4208
    },
    {
      "epoch": 1.6836,
      "grad_norm": 0.01548615749925375,
      "learning_rate": 4.3893333333333335e-07,
      "logits/chosen": -3.3130545616149902,
      "logits/rejected": -2.7426915168762207,
      "logps/chosen": -79.8397216796875,
      "logps/rejected": -144.35565185546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.29127466678619385,
      "rewards/margins": 9.37200927734375,
      "rewards/rejected": -9.663284301757812,
      "step": 4209
    },
    {
      "epoch": 1.6840000000000002,
      "grad_norm": 1.986861228942871,
      "learning_rate": 4.388e-07,
      "logits/chosen": -2.8083205223083496,
      "logits/rejected": -2.306428909301758,
      "logps/chosen": -109.14303588867188,
      "logps/rejected": -120.03997039794922,
      "loss": 0.0185,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.38046035170555115,
      "rewards/margins": 6.8458476066589355,
      "rewards/rejected": -7.2263078689575195,
      "step": 4210
    },
    {
      "epoch": 1.6844000000000001,
      "grad_norm": 0.03834536299109459,
      "learning_rate": 4.386666666666666e-07,
      "logits/chosen": -3.053941249847412,
      "logits/rejected": -2.657447576522827,
      "logps/chosen": -79.68354034423828,
      "logps/rejected": -131.41375732421875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2022136449813843,
      "rewards/margins": 9.741378784179688,
      "rewards/rejected": -8.539164543151855,
      "step": 4211
    },
    {
      "epoch": 1.6848,
      "grad_norm": 0.0914817601442337,
      "learning_rate": 4.385333333333333e-07,
      "logits/chosen": -3.1645541191101074,
      "logits/rejected": -2.5119874477386475,
      "logps/chosen": -63.504905700683594,
      "logps/rejected": -196.33700561523438,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.28751105070114136,
      "rewards/margins": 10.823783874511719,
      "rewards/rejected": -11.111294746398926,
      "step": 4212
    },
    {
      "epoch": 1.6852,
      "grad_norm": 0.0005410375306382775,
      "learning_rate": 4.384e-07,
      "logits/chosen": -2.8967173099517822,
      "logits/rejected": -2.0724618434906006,
      "logps/chosen": -68.32328033447266,
      "logps/rejected": -240.2266845703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6119571924209595,
      "rewards/margins": 14.021773338317871,
      "rewards/rejected": -13.40981674194336,
      "step": 4213
    },
    {
      "epoch": 1.6856,
      "grad_norm": 23.538999557495117,
      "learning_rate": 4.3826666666666665e-07,
      "logits/chosen": -2.656372547149658,
      "logits/rejected": -1.978346347808838,
      "logps/chosen": -142.34573364257812,
      "logps/rejected": -260.9361572265625,
      "loss": 0.1412,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.341315984725952,
      "rewards/margins": 12.821986198425293,
      "rewards/rejected": -16.163301467895508,
      "step": 4214
    },
    {
      "epoch": 1.686,
      "grad_norm": 0.0020714332349598408,
      "learning_rate": 4.381333333333333e-07,
      "logits/chosen": -3.033468723297119,
      "logits/rejected": -2.1108226776123047,
      "logps/chosen": -67.42855834960938,
      "logps/rejected": -165.8100128173828,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2956784963607788,
      "rewards/margins": 12.310722351074219,
      "rewards/rejected": -11.015043258666992,
      "step": 4215
    },
    {
      "epoch": 1.6864,
      "grad_norm": 0.06910637021064758,
      "learning_rate": 4.38e-07,
      "logits/chosen": -2.6431446075439453,
      "logits/rejected": -2.2569336891174316,
      "logps/chosen": -101.63236999511719,
      "logps/rejected": -142.69822692871094,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.315806269645691,
      "rewards/margins": 9.491056442260742,
      "rewards/rejected": -8.175250053405762,
      "step": 4216
    },
    {
      "epoch": 1.6867999999999999,
      "grad_norm": 0.04491931200027466,
      "learning_rate": 4.3786666666666667e-07,
      "logits/chosen": -2.5635013580322266,
      "logits/rejected": -1.8449900150299072,
      "logps/chosen": -139.86993408203125,
      "logps/rejected": -154.55584716796875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6104942560195923,
      "rewards/margins": 10.113688468933105,
      "rewards/rejected": -9.503194808959961,
      "step": 4217
    },
    {
      "epoch": 1.6872,
      "grad_norm": 0.025290023535490036,
      "learning_rate": 4.377333333333333e-07,
      "logits/chosen": -2.8606042861938477,
      "logits/rejected": -2.6270523071289062,
      "logps/chosen": -59.31475830078125,
      "logps/rejected": -151.40834045410156,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8224378824234009,
      "rewards/margins": 9.111047744750977,
      "rewards/rejected": -9.933485984802246,
      "step": 4218
    },
    {
      "epoch": 1.6876,
      "grad_norm": 0.1483875811100006,
      "learning_rate": 4.3759999999999995e-07,
      "logits/chosen": -2.606661081314087,
      "logits/rejected": -2.105334520339966,
      "logps/chosen": -221.70628356933594,
      "logps/rejected": -188.70948791503906,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4782074689865112,
      "rewards/margins": 8.072735786437988,
      "rewards/rejected": -9.550943374633789,
      "step": 4219
    },
    {
      "epoch": 1.688,
      "grad_norm": 0.016856664791703224,
      "learning_rate": 4.3746666666666664e-07,
      "logits/chosen": -2.722551107406616,
      "logits/rejected": -2.12076735496521,
      "logps/chosen": -69.01719665527344,
      "logps/rejected": -140.79742431640625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2611364126205444,
      "rewards/margins": 10.607915878295898,
      "rewards/rejected": -9.346778869628906,
      "step": 4220
    },
    {
      "epoch": 1.6884000000000001,
      "grad_norm": 9.852073669433594,
      "learning_rate": 4.3733333333333333e-07,
      "logits/chosen": -2.6406149864196777,
      "logits/rejected": -2.1060147285461426,
      "logps/chosen": -118.92990112304688,
      "logps/rejected": -178.59689331054688,
      "loss": 0.0409,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.192218780517578,
      "rewards/margins": 9.43574047088623,
      "rewards/rejected": -11.627959251403809,
      "step": 4221
    },
    {
      "epoch": 1.6888,
      "grad_norm": 0.04678666219115257,
      "learning_rate": 4.3719999999999997e-07,
      "logits/chosen": -2.426407814025879,
      "logits/rejected": -1.5722110271453857,
      "logps/chosen": -162.5739288330078,
      "logps/rejected": -182.689697265625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8833043575286865,
      "rewards/margins": 11.874210357666016,
      "rewards/rejected": -10.99090576171875,
      "step": 4222
    },
    {
      "epoch": 1.6892,
      "grad_norm": 0.00948428176343441,
      "learning_rate": 4.3706666666666666e-07,
      "logits/chosen": -2.8112711906433105,
      "logits/rejected": -2.289341926574707,
      "logps/chosen": -74.21200561523438,
      "logps/rejected": -188.4826202392578,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8930467367172241,
      "rewards/margins": 12.329263687133789,
      "rewards/rejected": -13.222310066223145,
      "step": 4223
    },
    {
      "epoch": 1.6896,
      "grad_norm": 0.31522804498672485,
      "learning_rate": 4.369333333333333e-07,
      "logits/chosen": -2.928044319152832,
      "logits/rejected": -2.562615156173706,
      "logps/chosen": -56.21684265136719,
      "logps/rejected": -117.40353393554688,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3795236647129059,
      "rewards/margins": 7.8881425857543945,
      "rewards/rejected": -7.50861930847168,
      "step": 4224
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.026932181790471077,
      "learning_rate": 4.368e-07,
      "logits/chosen": -2.5941131114959717,
      "logits/rejected": -1.9651119709014893,
      "logps/chosen": -104.8038330078125,
      "logps/rejected": -134.5432586669922,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5670933127403259,
      "rewards/margins": 9.152303695678711,
      "rewards/rejected": -8.585209846496582,
      "step": 4225
    },
    {
      "epoch": 1.6904,
      "grad_norm": 0.015119943767786026,
      "learning_rate": 4.3666666666666663e-07,
      "logits/chosen": -2.9773709774017334,
      "logits/rejected": -2.577036142349243,
      "logps/chosen": -58.456085205078125,
      "logps/rejected": -135.47991943359375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13141575455665588,
      "rewards/margins": 9.767667770385742,
      "rewards/rejected": -9.636251449584961,
      "step": 4226
    },
    {
      "epoch": 1.6907999999999999,
      "grad_norm": 6.050969123840332,
      "learning_rate": 4.365333333333333e-07,
      "logits/chosen": -2.822561264038086,
      "logits/rejected": -2.8044090270996094,
      "logps/chosen": -124.89747619628906,
      "logps/rejected": -93.68072509765625,
      "loss": 0.0242,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.748793363571167,
      "rewards/margins": 4.547597885131836,
      "rewards/rejected": -6.296391487121582,
      "step": 4227
    },
    {
      "epoch": 1.6912,
      "grad_norm": 0.002181508345529437,
      "learning_rate": 4.364e-07,
      "logits/chosen": -3.0213537216186523,
      "logits/rejected": -2.3657498359680176,
      "logps/chosen": -64.73670196533203,
      "logps/rejected": -188.958984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8045921325683594,
      "rewards/margins": 12.104469299316406,
      "rewards/rejected": -12.909061431884766,
      "step": 4228
    },
    {
      "epoch": 1.6916,
      "grad_norm": 0.0024701347574591637,
      "learning_rate": 4.3626666666666666e-07,
      "logits/chosen": -2.4194812774658203,
      "logits/rejected": -1.7653696537017822,
      "logps/chosen": -67.50164031982422,
      "logps/rejected": -174.81317138671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9347689151763916,
      "rewards/margins": 11.976459503173828,
      "rewards/rejected": -11.041690826416016,
      "step": 4229
    },
    {
      "epoch": 1.692,
      "grad_norm": 0.06234809011220932,
      "learning_rate": 4.361333333333333e-07,
      "logits/chosen": -3.0403027534484863,
      "logits/rejected": -2.3612303733825684,
      "logps/chosen": -44.57426834106445,
      "logps/rejected": -140.3907470703125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.042940903455019,
      "rewards/margins": 8.825730323791504,
      "rewards/rejected": -8.868671417236328,
      "step": 4230
    },
    {
      "epoch": 1.6924000000000001,
      "grad_norm": 0.04005276411771774,
      "learning_rate": 4.36e-07,
      "logits/chosen": -2.5979552268981934,
      "logits/rejected": -2.119182825088501,
      "logps/chosen": -116.1134262084961,
      "logps/rejected": -177.171142578125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15767556428909302,
      "rewards/margins": 10.127551078796387,
      "rewards/rejected": -9.96987533569336,
      "step": 4231
    },
    {
      "epoch": 1.6928,
      "grad_norm": 3.288012981414795,
      "learning_rate": 4.358666666666667e-07,
      "logits/chosen": -2.5825142860412598,
      "logits/rejected": -2.551964282989502,
      "logps/chosen": -81.54329681396484,
      "logps/rejected": -89.00077056884766,
      "loss": 0.0165,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2454124540090561,
      "rewards/margins": 5.351345062255859,
      "rewards/rejected": -5.105932712554932,
      "step": 4232
    },
    {
      "epoch": 1.6932,
      "grad_norm": 0.08008473366498947,
      "learning_rate": 4.3573333333333326e-07,
      "logits/chosen": -2.7841334342956543,
      "logits/rejected": -2.31447434425354,
      "logps/chosen": -118.81007385253906,
      "logps/rejected": -129.55511474609375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27136462926864624,
      "rewards/margins": 8.646617889404297,
      "rewards/rejected": -8.375252723693848,
      "step": 4233
    },
    {
      "epoch": 1.6936,
      "grad_norm": 0.28877750039100647,
      "learning_rate": 4.3559999999999996e-07,
      "logits/chosen": -2.945178508758545,
      "logits/rejected": -2.5572285652160645,
      "logps/chosen": -92.23863220214844,
      "logps/rejected": -98.53132629394531,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.37145498394966125,
      "rewards/margins": 6.949126243591309,
      "rewards/rejected": -6.577671527862549,
      "step": 4234
    },
    {
      "epoch": 1.694,
      "grad_norm": 0.017046933993697166,
      "learning_rate": 4.3546666666666665e-07,
      "logits/chosen": -2.645303249359131,
      "logits/rejected": -1.9115753173828125,
      "logps/chosen": -117.75225830078125,
      "logps/rejected": -175.59927368164062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.44134521484375,
      "rewards/margins": 11.173462867736816,
      "rewards/rejected": -11.614808082580566,
      "step": 4235
    },
    {
      "epoch": 1.6944,
      "grad_norm": 0.06736070662736893,
      "learning_rate": 4.3533333333333334e-07,
      "logits/chosen": -2.8539834022521973,
      "logits/rejected": -2.0630970001220703,
      "logps/chosen": -102.57381439208984,
      "logps/rejected": -143.29922485351562,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19003163278102875,
      "rewards/margins": 9.517717361450195,
      "rewards/rejected": -9.327686309814453,
      "step": 4236
    },
    {
      "epoch": 1.6947999999999999,
      "grad_norm": 0.02989134192466736,
      "learning_rate": 4.352e-07,
      "logits/chosen": -3.2155892848968506,
      "logits/rejected": -2.870211362838745,
      "logps/chosen": -42.37517166137695,
      "logps/rejected": -134.6268310546875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0998986959457397,
      "rewards/margins": 9.953895568847656,
      "rewards/rejected": -8.853997230529785,
      "step": 4237
    },
    {
      "epoch": 1.6952,
      "grad_norm": 0.015237857587635517,
      "learning_rate": 4.350666666666666e-07,
      "logits/chosen": -2.576610565185547,
      "logits/rejected": -2.2794981002807617,
      "logps/chosen": -56.38089370727539,
      "logps/rejected": -208.70919799804688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40542101860046387,
      "rewards/margins": 13.275371551513672,
      "rewards/rejected": -12.869951248168945,
      "step": 4238
    },
    {
      "epoch": 1.6956,
      "grad_norm": 0.21844498813152313,
      "learning_rate": 4.349333333333333e-07,
      "logits/chosen": -2.837367057800293,
      "logits/rejected": -2.589682102203369,
      "logps/chosen": -95.60346984863281,
      "logps/rejected": -120.37149047851562,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10577124357223511,
      "rewards/margins": 7.560528755187988,
      "rewards/rejected": -7.666299819946289,
      "step": 4239
    },
    {
      "epoch": 1.696,
      "grad_norm": 0.009919937700033188,
      "learning_rate": 4.348e-07,
      "logits/chosen": -2.6903674602508545,
      "logits/rejected": -2.044058084487915,
      "logps/chosen": -69.17471313476562,
      "logps/rejected": -151.000244140625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9163551330566406,
      "rewards/margins": 12.221736907958984,
      "rewards/rejected": -10.305380821228027,
      "step": 4240
    },
    {
      "epoch": 1.6964000000000001,
      "grad_norm": 0.054200492799282074,
      "learning_rate": 4.3466666666666664e-07,
      "logits/chosen": -2.8349199295043945,
      "logits/rejected": -2.1263773441314697,
      "logps/chosen": -124.87210083007812,
      "logps/rejected": -184.35914611816406,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0064754486083984375,
      "rewards/margins": 12.105881690979004,
      "rewards/rejected": -12.112357139587402,
      "step": 4241
    },
    {
      "epoch": 1.6968,
      "grad_norm": 0.4858986735343933,
      "learning_rate": 4.3453333333333333e-07,
      "logits/chosen": -2.8484883308410645,
      "logits/rejected": -2.797983169555664,
      "logps/chosen": -36.80310821533203,
      "logps/rejected": -120.32239532470703,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.005342721939087,
      "rewards/margins": 8.28911304473877,
      "rewards/rejected": -7.283770561218262,
      "step": 4242
    },
    {
      "epoch": 1.6972,
      "grad_norm": 0.04235778748989105,
      "learning_rate": 4.3439999999999997e-07,
      "logits/chosen": -2.6473588943481445,
      "logits/rejected": -2.3286871910095215,
      "logps/chosen": -40.63701629638672,
      "logps/rejected": -142.52749633789062,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4832383394241333,
      "rewards/margins": 8.467838287353516,
      "rewards/rejected": -8.95107650756836,
      "step": 4243
    },
    {
      "epoch": 1.6976,
      "grad_norm": 0.2712242603302002,
      "learning_rate": 4.3426666666666666e-07,
      "logits/chosen": -2.928302526473999,
      "logits/rejected": -2.660491466522217,
      "logps/chosen": -83.71482849121094,
      "logps/rejected": -112.96633911132812,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.06882643699646,
      "rewards/margins": 6.421202659606934,
      "rewards/rejected": -7.490029335021973,
      "step": 4244
    },
    {
      "epoch": 1.698,
      "grad_norm": 0.6294240355491638,
      "learning_rate": 4.341333333333333e-07,
      "logits/chosen": -2.9756693840026855,
      "logits/rejected": -2.745436191558838,
      "logps/chosen": -97.76014709472656,
      "logps/rejected": -106.01456451416016,
      "loss": 0.0057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.046472907066345215,
      "rewards/margins": 5.271873474121094,
      "rewards/rejected": -5.225400447845459,
      "step": 4245
    },
    {
      "epoch": 1.6984,
      "grad_norm": 0.6133331656455994,
      "learning_rate": 4.34e-07,
      "logits/chosen": -2.751455783843994,
      "logits/rejected": -2.500120162963867,
      "logps/chosen": -121.56834411621094,
      "logps/rejected": -163.38917541503906,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.965316653251648,
      "rewards/margins": 7.131473541259766,
      "rewards/rejected": -9.096790313720703,
      "step": 4246
    },
    {
      "epoch": 1.6987999999999999,
      "grad_norm": 0.00029212923254817724,
      "learning_rate": 4.3386666666666663e-07,
      "logits/chosen": -2.5813302993774414,
      "logits/rejected": -1.7438892126083374,
      "logps/chosen": -61.07168960571289,
      "logps/rejected": -179.80133056640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8929073810577393,
      "rewards/margins": 14.300044059753418,
      "rewards/rejected": -12.407136917114258,
      "step": 4247
    },
    {
      "epoch": 1.6992,
      "grad_norm": 0.0851459950208664,
      "learning_rate": 4.337333333333333e-07,
      "logits/chosen": -2.8818533420562744,
      "logits/rejected": -2.624886989593506,
      "logps/chosen": -94.24166870117188,
      "logps/rejected": -130.5161590576172,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.23391838371753693,
      "rewards/margins": 8.781246185302734,
      "rewards/rejected": -9.015164375305176,
      "step": 4248
    },
    {
      "epoch": 1.6996,
      "grad_norm": 0.305059552192688,
      "learning_rate": 4.3359999999999997e-07,
      "logits/chosen": -2.7693495750427246,
      "logits/rejected": -2.463841676712036,
      "logps/chosen": -139.01214599609375,
      "logps/rejected": -129.34622192382812,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1498959064483643,
      "rewards/margins": 7.110116958618164,
      "rewards/rejected": -8.26001262664795,
      "step": 4249
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.04422575607895851,
      "learning_rate": 4.3346666666666666e-07,
      "logits/chosen": -2.8781578540802,
      "logits/rejected": -2.3797616958618164,
      "logps/chosen": -71.29176330566406,
      "logps/rejected": -138.46075439453125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.42533189058303833,
      "rewards/margins": 8.80642318725586,
      "rewards/rejected": -9.231755256652832,
      "step": 4250
    },
    {
      "epoch": 1.7004000000000001,
      "grad_norm": 1.106846570968628,
      "learning_rate": 4.3333333333333335e-07,
      "logits/chosen": -2.883636951446533,
      "logits/rejected": -3.1337225437164307,
      "logps/chosen": -111.29815673828125,
      "logps/rejected": -131.79991149902344,
      "loss": 0.0064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.664191484451294,
      "rewards/margins": 7.909625053405762,
      "rewards/rejected": -7.245433330535889,
      "step": 4251
    },
    {
      "epoch": 1.7008,
      "grad_norm": 0.0062374090775847435,
      "learning_rate": 4.3319999999999994e-07,
      "logits/chosen": -2.690666913986206,
      "logits/rejected": -2.23329758644104,
      "logps/chosen": -148.69674682617188,
      "logps/rejected": -173.1446533203125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.022016897797584534,
      "rewards/margins": 10.84394645690918,
      "rewards/rejected": -10.821928977966309,
      "step": 4252
    },
    {
      "epoch": 1.7012,
      "grad_norm": 0.09652450680732727,
      "learning_rate": 4.3306666666666663e-07,
      "logits/chosen": -3.232159376144409,
      "logits/rejected": -2.925938129425049,
      "logps/chosen": -58.61375427246094,
      "logps/rejected": -97.62501525878906,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.526511013507843,
      "rewards/margins": 6.883072376251221,
      "rewards/rejected": -6.356561660766602,
      "step": 4253
    },
    {
      "epoch": 1.7016,
      "grad_norm": 0.754226565361023,
      "learning_rate": 4.329333333333333e-07,
      "logits/chosen": -2.7084920406341553,
      "logits/rejected": -2.730205535888672,
      "logps/chosen": -77.20663452148438,
      "logps/rejected": -116.14620971679688,
      "loss": 0.0055,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3621841371059418,
      "rewards/margins": 7.280514717102051,
      "rewards/rejected": -6.918330192565918,
      "step": 4254
    },
    {
      "epoch": 1.702,
      "grad_norm": 0.7706319689750671,
      "learning_rate": 4.328e-07,
      "logits/chosen": -2.5458319187164307,
      "logits/rejected": -1.9568936824798584,
      "logps/chosen": -189.76092529296875,
      "logps/rejected": -138.67784118652344,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.13638973236084,
      "rewards/margins": 5.970669746398926,
      "rewards/rejected": -9.107059478759766,
      "step": 4255
    },
    {
      "epoch": 1.7024,
      "grad_norm": 0.0060638547874987125,
      "learning_rate": 4.3266666666666665e-07,
      "logits/chosen": -2.471140146255493,
      "logits/rejected": -1.9436591863632202,
      "logps/chosen": -116.18290710449219,
      "logps/rejected": -224.60546875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7492381930351257,
      "rewards/margins": 13.766582489013672,
      "rewards/rejected": -13.01734447479248,
      "step": 4256
    },
    {
      "epoch": 1.7027999999999999,
      "grad_norm": 0.001659740461036563,
      "learning_rate": 4.325333333333333e-07,
      "logits/chosen": -2.70821475982666,
      "logits/rejected": -2.5584468841552734,
      "logps/chosen": -113.73197937011719,
      "logps/rejected": -185.73692321777344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7669017314910889,
      "rewards/margins": 12.404586791992188,
      "rewards/rejected": -10.63768482208252,
      "step": 4257
    },
    {
      "epoch": 1.7032,
      "grad_norm": 2.2079203128814697,
      "learning_rate": 4.324e-07,
      "logits/chosen": -2.613126039505005,
      "logits/rejected": -2.13323712348938,
      "logps/chosen": -113.51724243164062,
      "logps/rejected": -133.62704467773438,
      "loss": 0.0123,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7265274524688721,
      "rewards/margins": 7.804006576538086,
      "rewards/rejected": -8.530533790588379,
      "step": 4258
    },
    {
      "epoch": 1.7036,
      "grad_norm": 0.2185734212398529,
      "learning_rate": 4.3226666666666667e-07,
      "logits/chosen": -2.6403555870056152,
      "logits/rejected": -2.421600818634033,
      "logps/chosen": -90.92721557617188,
      "logps/rejected": -113.66664123535156,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3136707544326782,
      "rewards/margins": 7.266168594360352,
      "rewards/rejected": -6.952497959136963,
      "step": 4259
    },
    {
      "epoch": 1.704,
      "grad_norm": 1.294199824333191,
      "learning_rate": 4.321333333333333e-07,
      "logits/chosen": -2.9710254669189453,
      "logits/rejected": -2.5069336891174316,
      "logps/chosen": -126.33392333984375,
      "logps/rejected": -151.7694854736328,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3634147047996521,
      "rewards/margins": 9.761064529418945,
      "rewards/rejected": -10.124479293823242,
      "step": 4260
    },
    {
      "epoch": 1.7044000000000001,
      "grad_norm": 0.023762917146086693,
      "learning_rate": 4.3199999999999995e-07,
      "logits/chosen": -2.729473114013672,
      "logits/rejected": -2.273406505584717,
      "logps/chosen": -65.61636352539062,
      "logps/rejected": -156.54444885253906,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1101254224777222,
      "rewards/margins": 11.708372116088867,
      "rewards/rejected": -10.598246574401855,
      "step": 4261
    },
    {
      "epoch": 1.7048,
      "grad_norm": 0.04514777660369873,
      "learning_rate": 4.3186666666666664e-07,
      "logits/chosen": -2.6528522968292236,
      "logits/rejected": -1.9973069429397583,
      "logps/chosen": -86.00115966796875,
      "logps/rejected": -133.60748291015625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8595055341720581,
      "rewards/margins": 8.699592590332031,
      "rewards/rejected": -7.840086936950684,
      "step": 4262
    },
    {
      "epoch": 1.7052,
      "grad_norm": 0.01080197561532259,
      "learning_rate": 4.3173333333333333e-07,
      "logits/chosen": -2.475276470184326,
      "logits/rejected": -2.120645523071289,
      "logps/chosen": -147.3271026611328,
      "logps/rejected": -148.60484313964844,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7914730906486511,
      "rewards/margins": 9.544663429260254,
      "rewards/rejected": -10.336136817932129,
      "step": 4263
    },
    {
      "epoch": 1.7056,
      "grad_norm": 2.411118745803833,
      "learning_rate": 4.316e-07,
      "logits/chosen": -2.9785971641540527,
      "logits/rejected": -2.749182939529419,
      "logps/chosen": -77.3897705078125,
      "logps/rejected": -70.81802368164062,
      "loss": 0.0198,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.12369883060455322,
      "rewards/margins": 4.139381408691406,
      "rewards/rejected": -4.263080596923828,
      "step": 4264
    },
    {
      "epoch": 1.706,
      "grad_norm": 0.10141497850418091,
      "learning_rate": 4.3146666666666667e-07,
      "logits/chosen": -3.0485572814941406,
      "logits/rejected": -2.7257184982299805,
      "logps/chosen": -107.71321105957031,
      "logps/rejected": -163.6366424560547,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6802891492843628,
      "rewards/margins": 8.097919464111328,
      "rewards/rejected": -9.778207778930664,
      "step": 4265
    },
    {
      "epoch": 1.7064,
      "grad_norm": 0.035187967121601105,
      "learning_rate": 4.313333333333333e-07,
      "logits/chosen": -2.5977745056152344,
      "logits/rejected": -1.9318335056304932,
      "logps/chosen": -94.97240447998047,
      "logps/rejected": -148.49179077148438,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2923023700714111,
      "rewards/margins": 9.824705123901367,
      "rewards/rejected": -8.532402992248535,
      "step": 4266
    },
    {
      "epoch": 1.7067999999999999,
      "grad_norm": 1.1739987134933472,
      "learning_rate": 4.312e-07,
      "logits/chosen": -3.1197686195373535,
      "logits/rejected": -2.977229595184326,
      "logps/chosen": -59.86223602294922,
      "logps/rejected": -79.96774291992188,
      "loss": 0.007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3519028127193451,
      "rewards/margins": 5.321759223937988,
      "rewards/rejected": -4.969856262207031,
      "step": 4267
    },
    {
      "epoch": 1.7072,
      "grad_norm": 0.058909665793180466,
      "learning_rate": 4.3106666666666664e-07,
      "logits/chosen": -3.006744384765625,
      "logits/rejected": -2.6698238849639893,
      "logps/chosen": -56.11590576171875,
      "logps/rejected": -116.69915771484375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13573014736175537,
      "rewards/margins": 7.897157669067383,
      "rewards/rejected": -7.761427879333496,
      "step": 4268
    },
    {
      "epoch": 1.7076,
      "grad_norm": 1.3866186141967773,
      "learning_rate": 4.3093333333333333e-07,
      "logits/chosen": -2.646050214767456,
      "logits/rejected": -2.278316020965576,
      "logps/chosen": -87.32971954345703,
      "logps/rejected": -96.61933898925781,
      "loss": 0.0107,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41278475522994995,
      "rewards/margins": 6.155760288238525,
      "rewards/rejected": -5.742975234985352,
      "step": 4269
    },
    {
      "epoch": 1.708,
      "grad_norm": 5.8040008544921875,
      "learning_rate": 4.308e-07,
      "logits/chosen": -2.6503219604492188,
      "logits/rejected": -2.2873575687408447,
      "logps/chosen": -86.52401733398438,
      "logps/rejected": -124.72936248779297,
      "loss": 0.05,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.576159119606018,
      "rewards/margins": 6.488960266113281,
      "rewards/rejected": -8.065118789672852,
      "step": 4270
    },
    {
      "epoch": 1.7084000000000001,
      "grad_norm": 0.5688474178314209,
      "learning_rate": 4.306666666666666e-07,
      "logits/chosen": -2.63027024269104,
      "logits/rejected": -2.2242190837860107,
      "logps/chosen": -122.7811050415039,
      "logps/rejected": -101.57054138183594,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8302513360977173,
      "rewards/margins": 5.552850723266602,
      "rewards/rejected": -7.3831024169921875,
      "step": 4271
    },
    {
      "epoch": 1.7088,
      "grad_norm": 3.009289264678955,
      "learning_rate": 4.305333333333333e-07,
      "logits/chosen": -2.6519832611083984,
      "logits/rejected": -2.4685845375061035,
      "logps/chosen": -140.34249877929688,
      "logps/rejected": -106.64237976074219,
      "loss": 0.0261,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.11352276802063,
      "rewards/margins": 3.6365723609924316,
      "rewards/rejected": -5.750095367431641,
      "step": 4272
    },
    {
      "epoch": 1.7092,
      "grad_norm": 25.59782600402832,
      "learning_rate": 4.304e-07,
      "logits/chosen": -3.033386707305908,
      "logits/rejected": -3.0295262336730957,
      "logps/chosen": -65.39578247070312,
      "logps/rejected": -91.11854553222656,
      "loss": 0.1776,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4390439987182617,
      "rewards/margins": 3.452366828918457,
      "rewards/rejected": -4.891410827636719,
      "step": 4273
    },
    {
      "epoch": 1.7096,
      "grad_norm": 0.03758404403924942,
      "learning_rate": 4.302666666666667e-07,
      "logits/chosen": -2.593494415283203,
      "logits/rejected": -2.3953776359558105,
      "logps/chosen": -72.04576110839844,
      "logps/rejected": -190.8660430908203,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.997326135635376,
      "rewards/margins": 10.51778793334961,
      "rewards/rejected": -9.520462036132812,
      "step": 4274
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.03801465407013893,
      "learning_rate": 4.3013333333333327e-07,
      "logits/chosen": -2.8616397380828857,
      "logits/rejected": -2.605405807495117,
      "logps/chosen": -80.87565612792969,
      "logps/rejected": -127.5436782836914,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9592552185058594,
      "rewards/margins": 8.989814758300781,
      "rewards/rejected": -8.030559539794922,
      "step": 4275
    },
    {
      "epoch": 1.7104,
      "grad_norm": 0.05413365736603737,
      "learning_rate": 4.2999999999999996e-07,
      "logits/chosen": -2.4389307498931885,
      "logits/rejected": -1.7160475254058838,
      "logps/chosen": -134.0126190185547,
      "logps/rejected": -154.19656372070312,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7441517114639282,
      "rewards/margins": 10.934971809387207,
      "rewards/rejected": -10.19081974029541,
      "step": 4276
    },
    {
      "epoch": 1.7107999999999999,
      "grad_norm": 0.16498364508152008,
      "learning_rate": 4.2986666666666665e-07,
      "logits/chosen": -2.8695380687713623,
      "logits/rejected": -2.505225419998169,
      "logps/chosen": -51.51741409301758,
      "logps/rejected": -109.15147399902344,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7195640802383423,
      "rewards/margins": 8.422664642333984,
      "rewards/rejected": -6.703100204467773,
      "step": 4277
    },
    {
      "epoch": 1.7112,
      "grad_norm": 0.5541043281555176,
      "learning_rate": 4.2973333333333334e-07,
      "logits/chosen": -2.5893282890319824,
      "logits/rejected": -1.972872257232666,
      "logps/chosen": -119.1927261352539,
      "logps/rejected": -167.69143676757812,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5877915024757385,
      "rewards/margins": 8.344502449035645,
      "rewards/rejected": -8.932293891906738,
      "step": 4278
    },
    {
      "epoch": 1.7116,
      "grad_norm": 24.37651824951172,
      "learning_rate": 4.296e-07,
      "logits/chosen": -2.5623035430908203,
      "logits/rejected": -2.5315165519714355,
      "logps/chosen": -165.02438354492188,
      "logps/rejected": -189.39027404785156,
      "loss": 0.0742,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -5.022330284118652,
      "rewards/margins": 8.163732528686523,
      "rewards/rejected": -13.18606185913086,
      "step": 4279
    },
    {
      "epoch": 1.712,
      "grad_norm": 0.01196416188031435,
      "learning_rate": 4.294666666666666e-07,
      "logits/chosen": -2.679096221923828,
      "logits/rejected": -2.0514721870422363,
      "logps/chosen": -116.9088363647461,
      "logps/rejected": -138.09555053710938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23211058974266052,
      "rewards/margins": 9.784170150756836,
      "rewards/rejected": -9.5520601272583,
      "step": 4280
    },
    {
      "epoch": 1.7124000000000001,
      "grad_norm": 0.02442609891295433,
      "learning_rate": 4.293333333333333e-07,
      "logits/chosen": -2.2648019790649414,
      "logits/rejected": -1.7120379209518433,
      "logps/chosen": -174.73828125,
      "logps/rejected": -212.30096435546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39699745178222656,
      "rewards/margins": 12.277477264404297,
      "rewards/rejected": -11.88047981262207,
      "step": 4281
    },
    {
      "epoch": 1.7128,
      "grad_norm": 0.5867877006530762,
      "learning_rate": 4.292e-07,
      "logits/chosen": -2.727721691131592,
      "logits/rejected": -2.208078622817993,
      "logps/chosen": -112.04234313964844,
      "logps/rejected": -163.23583984375,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.26870766282081604,
      "rewards/margins": 9.900803565979004,
      "rewards/rejected": -9.632096290588379,
      "step": 4282
    },
    {
      "epoch": 1.7132,
      "grad_norm": 0.18424926698207855,
      "learning_rate": 4.2906666666666664e-07,
      "logits/chosen": -2.5212650299072266,
      "logits/rejected": -2.1281471252441406,
      "logps/chosen": -114.1018295288086,
      "logps/rejected": -177.66444396972656,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2126595973968506,
      "rewards/margins": 8.21690559387207,
      "rewards/rejected": -9.4295654296875,
      "step": 4283
    },
    {
      "epoch": 1.7136,
      "grad_norm": 2.5379862563568167e-05,
      "learning_rate": 4.2893333333333334e-07,
      "logits/chosen": -2.4077038764953613,
      "logits/rejected": -1.7152178287506104,
      "logps/chosen": -115.92742919921875,
      "logps/rejected": -283.1834716796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1865277290344238,
      "rewards/margins": 17.73196792602539,
      "rewards/rejected": -16.545438766479492,
      "step": 4284
    },
    {
      "epoch": 1.714,
      "grad_norm": 0.006995948497205973,
      "learning_rate": 4.288e-07,
      "logits/chosen": -2.4410767555236816,
      "logits/rejected": -1.5406758785247803,
      "logps/chosen": -181.53610229492188,
      "logps/rejected": -145.69488525390625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8946735858917236,
      "rewards/margins": 10.265546798706055,
      "rewards/rejected": -9.370872497558594,
      "step": 4285
    },
    {
      "epoch": 1.7144,
      "grad_norm": 2.5237998962402344,
      "learning_rate": 4.286666666666666e-07,
      "logits/chosen": -2.9370293617248535,
      "logits/rejected": -2.8312132358551025,
      "logps/chosen": -73.440673828125,
      "logps/rejected": -92.54106903076172,
      "loss": 0.0157,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2176597118377686,
      "rewards/margins": 5.330976963043213,
      "rewards/rejected": -6.548636436462402,
      "step": 4286
    },
    {
      "epoch": 1.7147999999999999,
      "grad_norm": 0.013914264738559723,
      "learning_rate": 4.285333333333333e-07,
      "logits/chosen": -3.0088794231414795,
      "logits/rejected": -2.5336246490478516,
      "logps/chosen": -49.37596130371094,
      "logps/rejected": -143.69168090820312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.729006767272949,
      "rewards/margins": 12.409788131713867,
      "rewards/rejected": -9.680780410766602,
      "step": 4287
    },
    {
      "epoch": 1.7151999999999998,
      "grad_norm": 0.006303573492914438,
      "learning_rate": 4.284e-07,
      "logits/chosen": -3.0758988857269287,
      "logits/rejected": -2.6275343894958496,
      "logps/chosen": -38.623008728027344,
      "logps/rejected": -153.032470703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1520426273345947,
      "rewards/margins": 10.429625511169434,
      "rewards/rejected": -9.277583122253418,
      "step": 4288
    },
    {
      "epoch": 1.7156,
      "grad_norm": 0.09164869040250778,
      "learning_rate": 4.282666666666667e-07,
      "logits/chosen": -2.8738982677459717,
      "logits/rejected": -2.4337730407714844,
      "logps/chosen": -51.190574645996094,
      "logps/rejected": -144.27352905273438,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6986215710639954,
      "rewards/margins": 9.67460823059082,
      "rewards/rejected": -10.37322998046875,
      "step": 4289
    },
    {
      "epoch": 1.716,
      "grad_norm": 0.48856890201568604,
      "learning_rate": 4.281333333333333e-07,
      "logits/chosen": -2.566223382949829,
      "logits/rejected": -1.8677723407745361,
      "logps/chosen": -122.74931335449219,
      "logps/rejected": -204.20098876953125,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1643238067626953,
      "rewards/margins": 11.692052841186523,
      "rewards/rejected": -11.856376647949219,
      "step": 4290
    },
    {
      "epoch": 1.7164000000000001,
      "grad_norm": 0.0017722956836223602,
      "learning_rate": 4.2799999999999997e-07,
      "logits/chosen": -2.4553050994873047,
      "logits/rejected": -1.5716407299041748,
      "logps/chosen": -139.40847778320312,
      "logps/rejected": -249.92190551757812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1171973943710327,
      "rewards/margins": 13.494766235351562,
      "rewards/rejected": -12.377568244934082,
      "step": 4291
    },
    {
      "epoch": 1.7168,
      "grad_norm": 10.062860488891602,
      "learning_rate": 4.2786666666666666e-07,
      "logits/chosen": -2.6212596893310547,
      "logits/rejected": -2.2167935371398926,
      "logps/chosen": -135.8087615966797,
      "logps/rejected": -143.98770141601562,
      "loss": 0.0562,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2773915529251099,
      "rewards/margins": 7.659409046173096,
      "rewards/rejected": -8.936800003051758,
      "step": 4292
    },
    {
      "epoch": 1.7172,
      "grad_norm": 0.21745476126670837,
      "learning_rate": 4.2773333333333335e-07,
      "logits/chosen": -2.7930245399475098,
      "logits/rejected": -2.2230515480041504,
      "logps/chosen": -69.25727081298828,
      "logps/rejected": -156.13623046875,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8586555123329163,
      "rewards/margins": 9.581808090209961,
      "rewards/rejected": -8.723152160644531,
      "step": 4293
    },
    {
      "epoch": 1.7176,
      "grad_norm": 0.0833839476108551,
      "learning_rate": 4.2759999999999994e-07,
      "logits/chosen": -2.7527754306793213,
      "logits/rejected": -2.2033886909484863,
      "logps/chosen": -62.83814239501953,
      "logps/rejected": -117.65648651123047,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2190988063812256,
      "rewards/margins": 9.63636589050293,
      "rewards/rejected": -7.417267322540283,
      "step": 4294
    },
    {
      "epoch": 1.718,
      "grad_norm": 0.02687070704996586,
      "learning_rate": 4.2746666666666663e-07,
      "logits/chosen": -2.744081974029541,
      "logits/rejected": -2.4813954830169678,
      "logps/chosen": -58.35004425048828,
      "logps/rejected": -163.7011260986328,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7418167591094971,
      "rewards/margins": 10.985700607299805,
      "rewards/rejected": -10.24388313293457,
      "step": 4295
    },
    {
      "epoch": 1.7184,
      "grad_norm": 0.0005207592621445656,
      "learning_rate": 4.273333333333333e-07,
      "logits/chosen": -3.206559181213379,
      "logits/rejected": -2.3449947834014893,
      "logps/chosen": -42.337562561035156,
      "logps/rejected": -182.65341186523438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6759451031684875,
      "rewards/margins": 13.463859558105469,
      "rewards/rejected": -12.787914276123047,
      "step": 4296
    },
    {
      "epoch": 1.7187999999999999,
      "grad_norm": 0.23238611221313477,
      "learning_rate": 4.272e-07,
      "logits/chosen": -2.7577402591705322,
      "logits/rejected": -2.1957814693450928,
      "logps/chosen": -97.43136596679688,
      "logps/rejected": -166.71316528320312,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9767615795135498,
      "rewards/margins": 10.094831466674805,
      "rewards/rejected": -11.071592330932617,
      "step": 4297
    },
    {
      "epoch": 1.7191999999999998,
      "grad_norm": 44.83136749267578,
      "learning_rate": 4.2706666666666665e-07,
      "logits/chosen": -2.8117246627807617,
      "logits/rejected": -2.6717748641967773,
      "logps/chosen": -147.9210205078125,
      "logps/rejected": -103.61405944824219,
      "loss": 0.1781,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.389174461364746,
      "rewards/margins": 3.508680820465088,
      "rewards/rejected": -5.897855281829834,
      "step": 4298
    },
    {
      "epoch": 1.7196,
      "grad_norm": 0.00813550315797329,
      "learning_rate": 4.269333333333333e-07,
      "logits/chosen": -2.660212993621826,
      "logits/rejected": -2.1681442260742188,
      "logps/chosen": -70.92494201660156,
      "logps/rejected": -148.39718627929688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4259193539619446,
      "rewards/margins": 10.900461196899414,
      "rewards/rejected": -10.474542617797852,
      "step": 4299
    },
    {
      "epoch": 1.72,
      "grad_norm": 4.834540843963623,
      "learning_rate": 4.268e-07,
      "logits/chosen": -2.737682342529297,
      "logits/rejected": -2.666998863220215,
      "logps/chosen": -77.75193786621094,
      "logps/rejected": -97.73192596435547,
      "loss": 0.0559,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2975160479545593,
      "rewards/margins": 6.935213088989258,
      "rewards/rejected": -6.637697219848633,
      "step": 4300
    },
    {
      "epoch": 1.7204000000000002,
      "grad_norm": 0.06423739343881607,
      "learning_rate": 4.266666666666667e-07,
      "logits/chosen": -2.1565911769866943,
      "logits/rejected": -1.616835117340088,
      "logps/chosen": -155.4153594970703,
      "logps/rejected": -198.64927673339844,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3581688404083252,
      "rewards/margins": 10.035722732543945,
      "rewards/rejected": -11.393890380859375,
      "step": 4301
    },
    {
      "epoch": 1.7208,
      "grad_norm": 0.19578059017658234,
      "learning_rate": 4.265333333333333e-07,
      "logits/chosen": -3.0512499809265137,
      "logits/rejected": -2.639889717102051,
      "logps/chosen": -58.36077117919922,
      "logps/rejected": -135.03945922851562,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4157491624355316,
      "rewards/margins": 8.836760520935059,
      "rewards/rejected": -8.421010971069336,
      "step": 4302
    },
    {
      "epoch": 1.7212,
      "grad_norm": 0.006243259645998478,
      "learning_rate": 4.264e-07,
      "logits/chosen": -2.487316370010376,
      "logits/rejected": -2.331552028656006,
      "logps/chosen": -103.77972412109375,
      "logps/rejected": -175.13473510742188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6380172967910767,
      "rewards/margins": 14.199548721313477,
      "rewards/rejected": -12.561531066894531,
      "step": 4303
    },
    {
      "epoch": 1.7216,
      "grad_norm": 0.0023982063867151737,
      "learning_rate": 4.2626666666666665e-07,
      "logits/chosen": -3.0683815479278564,
      "logits/rejected": -2.594684600830078,
      "logps/chosen": -86.64456939697266,
      "logps/rejected": -181.46170043945312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3651321530342102,
      "rewards/margins": 11.406654357910156,
      "rewards/rejected": -11.7717866897583,
      "step": 4304
    },
    {
      "epoch": 1.722,
      "grad_norm": 0.0007903426885604858,
      "learning_rate": 4.261333333333333e-07,
      "logits/chosen": -2.8285117149353027,
      "logits/rejected": -1.989443302154541,
      "logps/chosen": -68.26036834716797,
      "logps/rejected": -177.9256591796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2205636501312256,
      "rewards/margins": 13.182441711425781,
      "rewards/rejected": -10.961878776550293,
      "step": 4305
    },
    {
      "epoch": 1.7224,
      "grad_norm": 0.00969808828085661,
      "learning_rate": 4.26e-07,
      "logits/chosen": -2.8679397106170654,
      "logits/rejected": -1.9984877109527588,
      "logps/chosen": -64.54965209960938,
      "logps/rejected": -155.7438201904297,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.800113320350647,
      "rewards/margins": 10.653133392333984,
      "rewards/rejected": -9.853019714355469,
      "step": 4306
    },
    {
      "epoch": 1.7227999999999999,
      "grad_norm": 0.012829207815229893,
      "learning_rate": 4.2586666666666667e-07,
      "logits/chosen": -2.735900402069092,
      "logits/rejected": -2.196591377258301,
      "logps/chosen": -119.44520568847656,
      "logps/rejected": -170.8559112548828,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8766247034072876,
      "rewards/margins": 11.094310760498047,
      "rewards/rejected": -10.217686653137207,
      "step": 4307
    },
    {
      "epoch": 1.7231999999999998,
      "grad_norm": 0.5673213005065918,
      "learning_rate": 4.257333333333333e-07,
      "logits/chosen": -2.3731393814086914,
      "logits/rejected": -1.6972589492797852,
      "logps/chosen": -146.17494201660156,
      "logps/rejected": -237.74676513671875,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.22316551208496094,
      "rewards/margins": 14.21369457244873,
      "rewards/rejected": -14.436860084533691,
      "step": 4308
    },
    {
      "epoch": 1.7236,
      "grad_norm": 0.036497123539447784,
      "learning_rate": 4.2559999999999995e-07,
      "logits/chosen": -2.8837552070617676,
      "logits/rejected": -2.2167296409606934,
      "logps/chosen": -132.25442504882812,
      "logps/rejected": -150.79519653320312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1850685030221939,
      "rewards/margins": 8.499115943908691,
      "rewards/rejected": -8.314046859741211,
      "step": 4309
    },
    {
      "epoch": 1.724,
      "grad_norm": 4.6382832527160645,
      "learning_rate": 4.2546666666666664e-07,
      "logits/chosen": -2.885794162750244,
      "logits/rejected": -2.497140407562256,
      "logps/chosen": -100.64158630371094,
      "logps/rejected": -143.0962677001953,
      "loss": 0.0422,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2278159856796265,
      "rewards/margins": 7.1770782470703125,
      "rewards/rejected": -8.40489387512207,
      "step": 4310
    },
    {
      "epoch": 1.7244000000000002,
      "grad_norm": 0.06175108253955841,
      "learning_rate": 4.2533333333333333e-07,
      "logits/chosen": -3.062981605529785,
      "logits/rejected": -2.572155475616455,
      "logps/chosen": -57.39894104003906,
      "logps/rejected": -131.1793670654297,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1039656400680542,
      "rewards/margins": 10.206857681274414,
      "rewards/rejected": -9.10289192199707,
      "step": 4311
    },
    {
      "epoch": 1.7248,
      "grad_norm": 0.029359860345721245,
      "learning_rate": 4.252e-07,
      "logits/chosen": -3.1469528675079346,
      "logits/rejected": -2.6656291484832764,
      "logps/chosen": -62.37108612060547,
      "logps/rejected": -131.0328369140625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25476646423339844,
      "rewards/margins": 8.663382530212402,
      "rewards/rejected": -8.408616065979004,
      "step": 4312
    },
    {
      "epoch": 1.7252,
      "grad_norm": 21.855876922607422,
      "learning_rate": 4.250666666666666e-07,
      "logits/chosen": -2.873330593109131,
      "logits/rejected": -2.4102725982666016,
      "logps/chosen": -103.1169204711914,
      "logps/rejected": -106.73261260986328,
      "loss": 0.1412,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6840289831161499,
      "rewards/margins": 6.136915683746338,
      "rewards/rejected": -6.820944786071777,
      "step": 4313
    },
    {
      "epoch": 1.7256,
      "grad_norm": 0.02729460410773754,
      "learning_rate": 4.249333333333333e-07,
      "logits/chosen": -2.26248836517334,
      "logits/rejected": -1.302061915397644,
      "logps/chosen": -184.29000854492188,
      "logps/rejected": -194.41552734375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06807172298431396,
      "rewards/margins": 10.404102325439453,
      "rewards/rejected": -10.336030960083008,
      "step": 4314
    },
    {
      "epoch": 1.726,
      "grad_norm": 0.6416904330253601,
      "learning_rate": 4.248e-07,
      "logits/chosen": -3.0010862350463867,
      "logits/rejected": -2.7290682792663574,
      "logps/chosen": -99.74305725097656,
      "logps/rejected": -115.79601287841797,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3526966571807861,
      "rewards/margins": 6.746409893035889,
      "rewards/rejected": -8.099106788635254,
      "step": 4315
    },
    {
      "epoch": 1.7264,
      "grad_norm": 0.22404049336910248,
      "learning_rate": 4.246666666666667e-07,
      "logits/chosen": -2.9135212898254395,
      "logits/rejected": -2.794750690460205,
      "logps/chosen": -104.56385803222656,
      "logps/rejected": -123.01608276367188,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.138850450515747,
      "rewards/margins": 6.579154014587402,
      "rewards/rejected": -7.71800422668457,
      "step": 4316
    },
    {
      "epoch": 1.7268,
      "grad_norm": 0.07885777950286865,
      "learning_rate": 4.245333333333333e-07,
      "logits/chosen": -3.0366196632385254,
      "logits/rejected": -2.3726799488067627,
      "logps/chosen": -82.6282958984375,
      "logps/rejected": -130.58499145507812,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.011403083801269531,
      "rewards/margins": 8.05688762664795,
      "rewards/rejected": -8.04548454284668,
      "step": 4317
    },
    {
      "epoch": 1.7271999999999998,
      "grad_norm": 0.0961310938000679,
      "learning_rate": 4.2439999999999996e-07,
      "logits/chosen": -2.5332422256469727,
      "logits/rejected": -2.543614387512207,
      "logps/chosen": -69.30182647705078,
      "logps/rejected": -145.94683837890625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.306642770767212,
      "rewards/margins": 7.517009735107422,
      "rewards/rejected": -8.823652267456055,
      "step": 4318
    },
    {
      "epoch": 1.7276,
      "grad_norm": 0.04442973434925079,
      "learning_rate": 4.2426666666666665e-07,
      "logits/chosen": -2.826164722442627,
      "logits/rejected": -2.559000015258789,
      "logps/chosen": -81.94999694824219,
      "logps/rejected": -166.30076599121094,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4506044387817383,
      "rewards/margins": 8.829418182373047,
      "rewards/rejected": -10.280022621154785,
      "step": 4319
    },
    {
      "epoch": 1.728,
      "grad_norm": 0.002290242351591587,
      "learning_rate": 4.241333333333333e-07,
      "logits/chosen": -2.4785046577453613,
      "logits/rejected": -2.0979881286621094,
      "logps/chosen": -111.69938659667969,
      "logps/rejected": -245.15914916992188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8758826851844788,
      "rewards/margins": 12.11259651184082,
      "rewards/rejected": -11.236713409423828,
      "step": 4320
    },
    {
      "epoch": 1.7284000000000002,
      "grad_norm": 0.32612186670303345,
      "learning_rate": 4.24e-07,
      "logits/chosen": -3.072458267211914,
      "logits/rejected": -2.3218536376953125,
      "logps/chosen": -76.57403564453125,
      "logps/rejected": -133.05169677734375,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5744370222091675,
      "rewards/margins": 8.719610214233398,
      "rewards/rejected": -8.145173072814941,
      "step": 4321
    },
    {
      "epoch": 1.7288000000000001,
      "grad_norm": 0.023445066064596176,
      "learning_rate": 4.238666666666666e-07,
      "logits/chosen": -3.0363609790802,
      "logits/rejected": -2.322774887084961,
      "logps/chosen": -54.82736587524414,
      "logps/rejected": -182.3433837890625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.024578094482421875,
      "rewards/margins": 12.907697677612305,
      "rewards/rejected": -12.883119583129883,
      "step": 4322
    },
    {
      "epoch": 1.7292,
      "grad_norm": 0.05444416031241417,
      "learning_rate": 4.237333333333333e-07,
      "logits/chosen": -2.6694459915161133,
      "logits/rejected": -2.0197465419769287,
      "logps/chosen": -151.91448974609375,
      "logps/rejected": -142.1134033203125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.20112305879592896,
      "rewards/margins": 8.886462211608887,
      "rewards/rejected": -9.08758544921875,
      "step": 4323
    },
    {
      "epoch": 1.7296,
      "grad_norm": 0.009200985543429852,
      "learning_rate": 4.2359999999999995e-07,
      "logits/chosen": -2.9100186824798584,
      "logits/rejected": -2.424522638320923,
      "logps/chosen": -75.20198822021484,
      "logps/rejected": -187.281982421875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.561178207397461,
      "rewards/margins": 15.05915355682373,
      "rewards/rejected": -13.49797534942627,
      "step": 4324
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.07939042150974274,
      "learning_rate": 4.2346666666666665e-07,
      "logits/chosen": -3.102520227432251,
      "logits/rejected": -2.622076988220215,
      "logps/chosen": -117.7765121459961,
      "logps/rejected": -166.026611328125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9217851758003235,
      "rewards/margins": 9.828398704528809,
      "rewards/rejected": -10.750184059143066,
      "step": 4325
    },
    {
      "epoch": 1.7304,
      "grad_norm": 0.008555734530091286,
      "learning_rate": 4.2333333333333334e-07,
      "logits/chosen": -2.8251214027404785,
      "logits/rejected": -2.2031517028808594,
      "logps/chosen": -52.94794464111328,
      "logps/rejected": -170.2213897705078,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7930841445922852,
      "rewards/margins": 10.715989112854004,
      "rewards/rejected": -9.922904968261719,
      "step": 4326
    },
    {
      "epoch": 1.7308,
      "grad_norm": 121.81603240966797,
      "learning_rate": 4.232e-07,
      "logits/chosen": -2.323242664337158,
      "logits/rejected": -2.107628345489502,
      "logps/chosen": -194.22708129882812,
      "logps/rejected": -270.9727478027344,
      "loss": 0.9359,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -7.850144386291504,
      "rewards/margins": 8.181146621704102,
      "rewards/rejected": -16.031291961669922,
      "step": 4327
    },
    {
      "epoch": 1.7311999999999999,
      "grad_norm": 0.21214181184768677,
      "learning_rate": 4.230666666666666e-07,
      "logits/chosen": -2.6018333435058594,
      "logits/rejected": -2.294437885284424,
      "logps/chosen": -206.55442810058594,
      "logps/rejected": -158.3923797607422,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.8657071590423584,
      "rewards/margins": 7.1978349685668945,
      "rewards/rejected": -10.063541412353516,
      "step": 4328
    },
    {
      "epoch": 1.7316,
      "grad_norm": 0.16377997398376465,
      "learning_rate": 4.229333333333333e-07,
      "logits/chosen": -2.6622228622436523,
      "logits/rejected": -2.129746675491333,
      "logps/chosen": -90.76895904541016,
      "logps/rejected": -135.09474182128906,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7579811215400696,
      "rewards/margins": 8.843879699707031,
      "rewards/rejected": -8.085898399353027,
      "step": 4329
    },
    {
      "epoch": 1.732,
      "grad_norm": 0.06698392331600189,
      "learning_rate": 4.228e-07,
      "logits/chosen": -3.0664453506469727,
      "logits/rejected": -2.5333328247070312,
      "logps/chosen": -85.28207397460938,
      "logps/rejected": -139.17654418945312,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.463571161031723,
      "rewards/margins": 7.948274612426758,
      "rewards/rejected": -8.411845207214355,
      "step": 4330
    },
    {
      "epoch": 1.7324000000000002,
      "grad_norm": 0.06833845376968384,
      "learning_rate": 4.226666666666667e-07,
      "logits/chosen": -2.2619423866271973,
      "logits/rejected": -1.769347071647644,
      "logps/chosen": -211.85110473632812,
      "logps/rejected": -217.94529724121094,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.272139072418213,
      "rewards/margins": 10.149455070495605,
      "rewards/rejected": -13.421594619750977,
      "step": 4331
    },
    {
      "epoch": 1.7328000000000001,
      "grad_norm": 0.036854088306427,
      "learning_rate": 4.225333333333333e-07,
      "logits/chosen": -2.765570640563965,
      "logits/rejected": -2.0887184143066406,
      "logps/chosen": -67.78446960449219,
      "logps/rejected": -170.41363525390625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.053330659866333,
      "rewards/margins": 11.775002479553223,
      "rewards/rejected": -10.721672058105469,
      "step": 4332
    },
    {
      "epoch": 1.7332,
      "grad_norm": 0.7746415734291077,
      "learning_rate": 4.2239999999999997e-07,
      "logits/chosen": -2.673666477203369,
      "logits/rejected": -2.113823890686035,
      "logps/chosen": -97.91573333740234,
      "logps/rejected": -124.25870513916016,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4211750030517578,
      "rewards/margins": 7.108579158782959,
      "rewards/rejected": -7.529754638671875,
      "step": 4333
    },
    {
      "epoch": 1.7336,
      "grad_norm": 0.003376569366082549,
      "learning_rate": 4.2226666666666666e-07,
      "logits/chosen": -2.7418222427368164,
      "logits/rejected": -2.457232713699341,
      "logps/chosen": -96.42296600341797,
      "logps/rejected": -163.59886169433594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.13887691497802734,
      "rewards/margins": 11.047464370727539,
      "rewards/rejected": -11.18634033203125,
      "step": 4334
    },
    {
      "epoch": 1.734,
      "grad_norm": 1.657828761381097e-05,
      "learning_rate": 4.2213333333333335e-07,
      "logits/chosen": -2.812429666519165,
      "logits/rejected": -2.0309534072875977,
      "logps/chosen": -96.64718627929688,
      "logps/rejected": -249.02308654785156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39121514558792114,
      "rewards/margins": 17.372940063476562,
      "rewards/rejected": -16.981725692749023,
      "step": 4335
    },
    {
      "epoch": 1.7344,
      "grad_norm": 0.0005785241955891252,
      "learning_rate": 4.2199999999999994e-07,
      "logits/chosen": -2.726926565170288,
      "logits/rejected": -2.7742233276367188,
      "logps/chosen": -81.54458618164062,
      "logps/rejected": -192.2613525390625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8938384652137756,
      "rewards/margins": 12.895684242248535,
      "rewards/rejected": -12.001846313476562,
      "step": 4336
    },
    {
      "epoch": 1.7348,
      "grad_norm": 0.001764219137839973,
      "learning_rate": 4.2186666666666663e-07,
      "logits/chosen": -2.511181592941284,
      "logits/rejected": -1.9919655323028564,
      "logps/chosen": -56.48240661621094,
      "logps/rejected": -186.8497772216797,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8437482118606567,
      "rewards/margins": 11.999302864074707,
      "rewards/rejected": -11.15555477142334,
      "step": 4337
    },
    {
      "epoch": 1.7351999999999999,
      "grad_norm": 0.48217496275901794,
      "learning_rate": 4.217333333333333e-07,
      "logits/chosen": -2.987610340118408,
      "logits/rejected": -2.5414390563964844,
      "logps/chosen": -63.552398681640625,
      "logps/rejected": -141.05682373046875,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4405393600463867,
      "rewards/margins": 8.865970611572266,
      "rewards/rejected": -8.425431251525879,
      "step": 4338
    },
    {
      "epoch": 1.7356,
      "grad_norm": 0.038164157420396805,
      "learning_rate": 4.2159999999999996e-07,
      "logits/chosen": -2.5105252265930176,
      "logits/rejected": -2.0537846088409424,
      "logps/chosen": -137.8720703125,
      "logps/rejected": -212.73321533203125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.440477728843689,
      "rewards/margins": 11.242905616760254,
      "rewards/rejected": -12.68338394165039,
      "step": 4339
    },
    {
      "epoch": 1.736,
      "grad_norm": 1.0946530103683472,
      "learning_rate": 4.2146666666666666e-07,
      "logits/chosen": -2.6328699588775635,
      "logits/rejected": -2.3391599655151367,
      "logps/chosen": -129.96633911132812,
      "logps/rejected": -198.34884643554688,
      "loss": 0.0061,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9427059292793274,
      "rewards/margins": 8.998863220214844,
      "rewards/rejected": -9.941569328308105,
      "step": 4340
    },
    {
      "epoch": 1.7364000000000002,
      "grad_norm": 0.13984352350234985,
      "learning_rate": 4.213333333333333e-07,
      "logits/chosen": -2.7705206871032715,
      "logits/rejected": -2.3406970500946045,
      "logps/chosen": -110.18145751953125,
      "logps/rejected": -167.20689392089844,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.773314356803894,
      "rewards/margins": 10.818132400512695,
      "rewards/rejected": -11.591445922851562,
      "step": 4341
    },
    {
      "epoch": 1.7368000000000001,
      "grad_norm": 0.009190133772790432,
      "learning_rate": 4.212e-07,
      "logits/chosen": -2.331070899963379,
      "logits/rejected": -1.7068517208099365,
      "logps/chosen": -201.56072998046875,
      "logps/rejected": -162.3090057373047,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.17866897583007812,
      "rewards/margins": 10.418161392211914,
      "rewards/rejected": -10.596830368041992,
      "step": 4342
    },
    {
      "epoch": 1.7372,
      "grad_norm": 0.014351711608469486,
      "learning_rate": 4.210666666666666e-07,
      "logits/chosen": -2.610825538635254,
      "logits/rejected": -1.8709781169891357,
      "logps/chosen": -84.57188415527344,
      "logps/rejected": -189.2699432373047,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05887603759765625,
      "rewards/margins": 11.78360366821289,
      "rewards/rejected": -11.724727630615234,
      "step": 4343
    },
    {
      "epoch": 1.7376,
      "grad_norm": 0.609600305557251,
      "learning_rate": 4.209333333333333e-07,
      "logits/chosen": -2.8391175270080566,
      "logits/rejected": -2.566417694091797,
      "logps/chosen": -115.66970825195312,
      "logps/rejected": -116.99015808105469,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.184512734413147,
      "rewards/margins": 6.331600189208984,
      "rewards/rejected": -7.51611328125,
      "step": 4344
    },
    {
      "epoch": 1.738,
      "grad_norm": 0.038195155560970306,
      "learning_rate": 4.208e-07,
      "logits/chosen": -3.1803221702575684,
      "logits/rejected": -2.811375379562378,
      "logps/chosen": -82.76345825195312,
      "logps/rejected": -135.4667205810547,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7523159384727478,
      "rewards/margins": 8.165559768676758,
      "rewards/rejected": -8.917876243591309,
      "step": 4345
    },
    {
      "epoch": 1.7384,
      "grad_norm": 1.2644517421722412,
      "learning_rate": 4.2066666666666665e-07,
      "logits/chosen": -2.5276103019714355,
      "logits/rejected": -2.1567840576171875,
      "logps/chosen": -150.2832489013672,
      "logps/rejected": -163.87136840820312,
      "loss": 0.0045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.6315789222717285,
      "rewards/margins": 7.152101993560791,
      "rewards/rejected": -10.78368091583252,
      "step": 4346
    },
    {
      "epoch": 1.7388,
      "grad_norm": 0.10695452243089676,
      "learning_rate": 4.205333333333333e-07,
      "logits/chosen": -2.7952136993408203,
      "logits/rejected": -2.1053709983825684,
      "logps/chosen": -144.95767211914062,
      "logps/rejected": -181.633056640625,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1360043287277222,
      "rewards/margins": 9.720008850097656,
      "rewards/rejected": -10.856013298034668,
      "step": 4347
    },
    {
      "epoch": 1.7391999999999999,
      "grad_norm": 0.044655732810497284,
      "learning_rate": 4.204e-07,
      "logits/chosen": -2.763570785522461,
      "logits/rejected": -2.394533157348633,
      "logps/chosen": -87.03767395019531,
      "logps/rejected": -142.39971923828125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3185073733329773,
      "rewards/margins": 9.035970687866211,
      "rewards/rejected": -9.354477882385254,
      "step": 4348
    },
    {
      "epoch": 1.7396,
      "grad_norm": 0.09183774888515472,
      "learning_rate": 4.2026666666666667e-07,
      "logits/chosen": -2.751966953277588,
      "logits/rejected": -1.911170244216919,
      "logps/chosen": -58.828548431396484,
      "logps/rejected": -148.24594116210938,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.11962834000587463,
      "rewards/margins": 9.103824615478516,
      "rewards/rejected": -9.223453521728516,
      "step": 4349
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.006706615909934044,
      "learning_rate": 4.2013333333333336e-07,
      "logits/chosen": -2.6862988471984863,
      "logits/rejected": -1.8246535062789917,
      "logps/chosen": -37.80570983886719,
      "logps/rejected": -159.20809936523438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6436419486999512,
      "rewards/margins": 10.469103813171387,
      "rewards/rejected": -8.825462341308594,
      "step": 4350
    },
    {
      "epoch": 1.7404,
      "grad_norm": 0.0008048378513194621,
      "learning_rate": 4.1999999999999995e-07,
      "logits/chosen": -2.7472147941589355,
      "logits/rejected": -2.392685890197754,
      "logps/chosen": -45.5992546081543,
      "logps/rejected": -205.5756072998047,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.42917975783348083,
      "rewards/margins": 14.26469612121582,
      "rewards/rejected": -14.693876266479492,
      "step": 4351
    },
    {
      "epoch": 1.7408000000000001,
      "grad_norm": 0.016259675845503807,
      "learning_rate": 4.1986666666666664e-07,
      "logits/chosen": -2.2723164558410645,
      "logits/rejected": -1.5072062015533447,
      "logps/chosen": -212.06076049804688,
      "logps/rejected": -250.06753540039062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5298856496810913,
      "rewards/margins": 12.8442964553833,
      "rewards/rejected": -14.374181747436523,
      "step": 4352
    },
    {
      "epoch": 1.7412,
      "grad_norm": 0.17055431008338928,
      "learning_rate": 4.1973333333333333e-07,
      "logits/chosen": -2.4950525760650635,
      "logits/rejected": -2.257136344909668,
      "logps/chosen": -109.61260986328125,
      "logps/rejected": -148.80630493164062,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.15252341330051422,
      "rewards/margins": 8.621068000793457,
      "rewards/rejected": -8.773591995239258,
      "step": 4353
    },
    {
      "epoch": 1.7416,
      "grad_norm": 0.06965155154466629,
      "learning_rate": 4.1959999999999997e-07,
      "logits/chosen": -2.66441011428833,
      "logits/rejected": -1.759645938873291,
      "logps/chosen": -102.54576110839844,
      "logps/rejected": -158.440185546875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.37445202469825745,
      "rewards/margins": 9.119972229003906,
      "rewards/rejected": -8.745519638061523,
      "step": 4354
    },
    {
      "epoch": 1.742,
      "grad_norm": 0.013933856040239334,
      "learning_rate": 4.194666666666666e-07,
      "logits/chosen": -2.521078109741211,
      "logits/rejected": -2.2151052951812744,
      "logps/chosen": -117.90621948242188,
      "logps/rejected": -166.18472290039062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9717121720314026,
      "rewards/margins": 9.759725570678711,
      "rewards/rejected": -10.731438636779785,
      "step": 4355
    },
    {
      "epoch": 1.7424,
      "grad_norm": 0.08066444844007492,
      "learning_rate": 4.193333333333333e-07,
      "logits/chosen": -2.84605073928833,
      "logits/rejected": -2.061095952987671,
      "logps/chosen": -88.97962951660156,
      "logps/rejected": -155.57020568847656,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1497468948364258,
      "rewards/margins": 11.603201866149902,
      "rewards/rejected": -10.453454971313477,
      "step": 4356
    },
    {
      "epoch": 1.7428,
      "grad_norm": 0.9301729202270508,
      "learning_rate": 4.192e-07,
      "logits/chosen": -3.0042247772216797,
      "logits/rejected": -2.700517177581787,
      "logps/chosen": -72.11936950683594,
      "logps/rejected": -155.01686096191406,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9634730815887451,
      "rewards/margins": 7.6904683113098145,
      "rewards/rejected": -8.65394115447998,
      "step": 4357
    },
    {
      "epoch": 1.7431999999999999,
      "grad_norm": 2.6263599395751953,
      "learning_rate": 4.1906666666666663e-07,
      "logits/chosen": -3.1324210166931152,
      "logits/rejected": -2.6076183319091797,
      "logps/chosen": -76.0723648071289,
      "logps/rejected": -137.19537353515625,
      "loss": 0.0205,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.021663665771484375,
      "rewards/margins": 8.746932029724121,
      "rewards/rejected": -8.768596649169922,
      "step": 4358
    },
    {
      "epoch": 1.7436,
      "grad_norm": 0.029403941705822945,
      "learning_rate": 4.189333333333333e-07,
      "logits/chosen": -2.760244607925415,
      "logits/rejected": -2.404794692993164,
      "logps/chosen": -117.81127166748047,
      "logps/rejected": -153.01658630371094,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21021214127540588,
      "rewards/margins": 9.35056209564209,
      "rewards/rejected": -9.140350341796875,
      "step": 4359
    },
    {
      "epoch": 1.744,
      "grad_norm": 0.014844165183603764,
      "learning_rate": 4.1879999999999996e-07,
      "logits/chosen": -2.901029586791992,
      "logits/rejected": -2.4666218757629395,
      "logps/chosen": -90.26255798339844,
      "logps/rejected": -163.40232849121094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.14090880751609802,
      "rewards/margins": 10.624427795410156,
      "rewards/rejected": -10.765336990356445,
      "step": 4360
    },
    {
      "epoch": 1.7444,
      "grad_norm": 1.842355728149414,
      "learning_rate": 4.1866666666666666e-07,
      "logits/chosen": -2.544619083404541,
      "logits/rejected": -2.2255914211273193,
      "logps/chosen": -130.97686767578125,
      "logps/rejected": -145.222900390625,
      "loss": 0.009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.981326699256897,
      "rewards/margins": 6.081122398376465,
      "rewards/rejected": -8.06244945526123,
      "step": 4361
    },
    {
      "epoch": 1.7448000000000001,
      "grad_norm": 0.5267391204833984,
      "learning_rate": 4.185333333333333e-07,
      "logits/chosen": -2.780275821685791,
      "logits/rejected": -2.573777198791504,
      "logps/chosen": -145.89730834960938,
      "logps/rejected": -147.834716796875,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.590528964996338,
      "rewards/margins": 6.388467788696289,
      "rewards/rejected": -8.978997230529785,
      "step": 4362
    },
    {
      "epoch": 1.7452,
      "grad_norm": 0.007732939440757036,
      "learning_rate": 4.184e-07,
      "logits/chosen": -2.619462251663208,
      "logits/rejected": -2.068636894226074,
      "logps/chosen": -84.61737060546875,
      "logps/rejected": -166.4963836669922,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.011686325073242188,
      "rewards/margins": 11.551920890808105,
      "rewards/rejected": -11.563607215881348,
      "step": 4363
    },
    {
      "epoch": 1.7456,
      "grad_norm": 0.04977871850132942,
      "learning_rate": 4.182666666666667e-07,
      "logits/chosen": -2.8031563758850098,
      "logits/rejected": -2.5986528396606445,
      "logps/chosen": -94.46896362304688,
      "logps/rejected": -148.23797607421875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3349786400794983,
      "rewards/margins": 9.091666221618652,
      "rewards/rejected": -9.426645278930664,
      "step": 4364
    },
    {
      "epoch": 1.746,
      "grad_norm": 0.06084710359573364,
      "learning_rate": 4.181333333333333e-07,
      "logits/chosen": -2.9491512775421143,
      "logits/rejected": -2.3381400108337402,
      "logps/chosen": -67.73458099365234,
      "logps/rejected": -168.886474609375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4855003356933594,
      "rewards/margins": 10.926959991455078,
      "rewards/rejected": -10.441460609436035,
      "step": 4365
    },
    {
      "epoch": 1.7464,
      "grad_norm": 0.00895550288259983,
      "learning_rate": 4.1799999999999996e-07,
      "logits/chosen": -2.940897226333618,
      "logits/rejected": -2.4278311729431152,
      "logps/chosen": -72.11664581298828,
      "logps/rejected": -149.51132202148438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.400341510772705,
      "rewards/margins": 10.773909568786621,
      "rewards/rejected": -9.373567581176758,
      "step": 4366
    },
    {
      "epoch": 1.7468,
      "grad_norm": 0.4013917148113251,
      "learning_rate": 4.1786666666666665e-07,
      "logits/chosen": -2.7979817390441895,
      "logits/rejected": -2.398648738861084,
      "logps/chosen": -133.3370361328125,
      "logps/rejected": -141.12416076660156,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.14440728724002838,
      "rewards/margins": 8.277524948120117,
      "rewards/rejected": -8.421932220458984,
      "step": 4367
    },
    {
      "epoch": 1.7471999999999999,
      "grad_norm": 0.01536715216934681,
      "learning_rate": 4.1773333333333334e-07,
      "logits/chosen": -2.6765694618225098,
      "logits/rejected": -2.1344428062438965,
      "logps/chosen": -67.42776489257812,
      "logps/rejected": -172.94020080566406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.687748908996582,
      "rewards/margins": 11.584630966186523,
      "rewards/rejected": -10.896882057189941,
      "step": 4368
    },
    {
      "epoch": 1.7476,
      "grad_norm": 0.00168900890275836,
      "learning_rate": 4.1760000000000003e-07,
      "logits/chosen": -2.696530818939209,
      "logits/rejected": -2.1331114768981934,
      "logps/chosen": -104.26310729980469,
      "logps/rejected": -237.79714965820312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.37911301851272583,
      "rewards/margins": 13.634422302246094,
      "rewards/rejected": -13.255309104919434,
      "step": 4369
    },
    {
      "epoch": 1.748,
      "grad_norm": 0.22889254987239838,
      "learning_rate": 4.174666666666666e-07,
      "logits/chosen": -2.4637603759765625,
      "logits/rejected": -2.013503313064575,
      "logps/chosen": -107.71673583984375,
      "logps/rejected": -138.95285034179688,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.00494384765625,
      "rewards/margins": 10.102241516113281,
      "rewards/rejected": -10.107185363769531,
      "step": 4370
    },
    {
      "epoch": 1.7484,
      "grad_norm": 0.16038285195827484,
      "learning_rate": 4.173333333333333e-07,
      "logits/chosen": -2.9719948768615723,
      "logits/rejected": -2.838609218597412,
      "logps/chosen": -91.92349243164062,
      "logps/rejected": -102.70014953613281,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5975849628448486,
      "rewards/margins": 7.025110244750977,
      "rewards/rejected": -6.427525520324707,
      "step": 4371
    },
    {
      "epoch": 1.7488000000000001,
      "grad_norm": 0.16986563801765442,
      "learning_rate": 4.172e-07,
      "logits/chosen": -3.10343861579895,
      "logits/rejected": -2.545576572418213,
      "logps/chosen": -86.4444808959961,
      "logps/rejected": -126.0442886352539,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.018651582300662994,
      "rewards/margins": 7.215865135192871,
      "rewards/rejected": -7.197213172912598,
      "step": 4372
    },
    {
      "epoch": 1.7492,
      "grad_norm": 0.0038086925633251667,
      "learning_rate": 4.1706666666666664e-07,
      "logits/chosen": -3.270439624786377,
      "logits/rejected": -2.701829671859741,
      "logps/chosen": -35.701072692871094,
      "logps/rejected": -195.3834991455078,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0934128761291504,
      "rewards/margins": 13.577800750732422,
      "rewards/rejected": -12.484387397766113,
      "step": 4373
    },
    {
      "epoch": 1.7496,
      "grad_norm": 0.0057393587194383144,
      "learning_rate": 4.169333333333333e-07,
      "logits/chosen": -2.43387508392334,
      "logits/rejected": -1.3865315914154053,
      "logps/chosen": -119.28211212158203,
      "logps/rejected": -189.715087890625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.21773910522460938,
      "rewards/margins": 11.09791088104248,
      "rewards/rejected": -11.31564998626709,
      "step": 4374
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.29778605699539185,
      "learning_rate": 4.1679999999999997e-07,
      "logits/chosen": -2.5119681358337402,
      "logits/rejected": -2.2555365562438965,
      "logps/chosen": -125.40853118896484,
      "logps/rejected": -149.07034301757812,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6828727722167969,
      "rewards/margins": 10.229915618896484,
      "rewards/rejected": -9.547041893005371,
      "step": 4375
    },
    {
      "epoch": 1.7504,
      "grad_norm": 1.0975395441055298,
      "learning_rate": 4.1666666666666667e-07,
      "logits/chosen": -2.734992504119873,
      "logits/rejected": -2.354672908782959,
      "logps/chosen": -159.82913208007812,
      "logps/rejected": -207.33749389648438,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.507392644882202,
      "rewards/margins": 10.072261810302734,
      "rewards/rejected": -12.579654693603516,
      "step": 4376
    },
    {
      "epoch": 1.7508,
      "grad_norm": 0.03811308741569519,
      "learning_rate": 4.165333333333333e-07,
      "logits/chosen": -2.8263556957244873,
      "logits/rejected": -2.0352044105529785,
      "logps/chosen": -105.63151550292969,
      "logps/rejected": -198.81295776367188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39650994539260864,
      "rewards/margins": 13.414603233337402,
      "rewards/rejected": -13.01809310913086,
      "step": 4377
    },
    {
      "epoch": 1.7511999999999999,
      "grad_norm": 1.6766138076782227,
      "learning_rate": 4.164e-07,
      "logits/chosen": -2.655994415283203,
      "logits/rejected": -2.247945547103882,
      "logps/chosen": -107.63685607910156,
      "logps/rejected": -201.87086486816406,
      "loss": 0.0095,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35137081146240234,
      "rewards/margins": 9.40866470336914,
      "rewards/rejected": -9.057293891906738,
      "step": 4378
    },
    {
      "epoch": 1.7516,
      "grad_norm": 0.09068578481674194,
      "learning_rate": 4.1626666666666664e-07,
      "logits/chosen": -2.8850693702697754,
      "logits/rejected": -2.5574679374694824,
      "logps/chosen": -70.34968566894531,
      "logps/rejected": -116.16439056396484,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4130542278289795,
      "rewards/margins": 8.777953147888184,
      "rewards/rejected": -7.364898681640625,
      "step": 4379
    },
    {
      "epoch": 1.752,
      "grad_norm": 0.03595958650112152,
      "learning_rate": 4.1613333333333333e-07,
      "logits/chosen": -2.3860015869140625,
      "logits/rejected": -1.84676992893219,
      "logps/chosen": -119.92327880859375,
      "logps/rejected": -157.54595947265625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18836480379104614,
      "rewards/margins": 9.828325271606445,
      "rewards/rejected": -9.639960289001465,
      "step": 4380
    },
    {
      "epoch": 1.7524,
      "grad_norm": 0.0006448940257541835,
      "learning_rate": 4.1599999999999997e-07,
      "logits/chosen": -2.808110237121582,
      "logits/rejected": -2.007556915283203,
      "logps/chosen": -64.12403869628906,
      "logps/rejected": -270.92633056640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.235308885574341,
      "rewards/margins": 13.53249740600586,
      "rewards/rejected": -11.297188758850098,
      "step": 4381
    },
    {
      "epoch": 1.7528000000000001,
      "grad_norm": 0.08123015612363815,
      "learning_rate": 4.1586666666666666e-07,
      "logits/chosen": -2.767061233520508,
      "logits/rejected": -2.2711596488952637,
      "logps/chosen": -125.81916809082031,
      "logps/rejected": -165.9390869140625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6635156869888306,
      "rewards/margins": 10.290122985839844,
      "rewards/rejected": -10.953638076782227,
      "step": 4382
    },
    {
      "epoch": 1.7532,
      "grad_norm": 0.025429394096136093,
      "learning_rate": 4.1573333333333335e-07,
      "logits/chosen": -2.669466257095337,
      "logits/rejected": -1.8655937910079956,
      "logps/chosen": -90.62515258789062,
      "logps/rejected": -182.87167358398438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5143177509307861,
      "rewards/margins": 11.885580062866211,
      "rewards/rejected": -10.371262550354004,
      "step": 4383
    },
    {
      "epoch": 1.7536,
      "grad_norm": 0.008557985536754131,
      "learning_rate": 4.156e-07,
      "logits/chosen": -2.658389091491699,
      "logits/rejected": -1.9959847927093506,
      "logps/chosen": -137.57008361816406,
      "logps/rejected": -153.77137756347656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.18673020601272583,
      "rewards/margins": 10.566781997680664,
      "rewards/rejected": -10.753511428833008,
      "step": 4384
    },
    {
      "epoch": 1.754,
      "grad_norm": 0.6223580837249756,
      "learning_rate": 4.1546666666666663e-07,
      "logits/chosen": -3.0628910064697266,
      "logits/rejected": -2.8463470935821533,
      "logps/chosen": -76.4862060546875,
      "logps/rejected": -131.37301635742188,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6910789608955383,
      "rewards/margins": 7.77202033996582,
      "rewards/rejected": -8.463099479675293,
      "step": 4385
    },
    {
      "epoch": 1.7544,
      "grad_norm": 0.2273734211921692,
      "learning_rate": 4.153333333333333e-07,
      "logits/chosen": -2.446614980697632,
      "logits/rejected": -1.8932162523269653,
      "logps/chosen": -117.46156311035156,
      "logps/rejected": -157.44529724121094,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2927791476249695,
      "rewards/margins": 9.816259384155273,
      "rewards/rejected": -9.523479461669922,
      "step": 4386
    },
    {
      "epoch": 1.7548,
      "grad_norm": 0.11802367866039276,
      "learning_rate": 4.152e-07,
      "logits/chosen": -2.905735969543457,
      "logits/rejected": -2.087040901184082,
      "logps/chosen": -95.08122253417969,
      "logps/rejected": -230.8479766845703,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.03341369330883026,
      "rewards/margins": 13.30734920501709,
      "rewards/rejected": -13.340763092041016,
      "step": 4387
    },
    {
      "epoch": 1.7551999999999999,
      "grad_norm": 0.5874855518341064,
      "learning_rate": 4.150666666666666e-07,
      "logits/chosen": -2.547122001647949,
      "logits/rejected": -2.1737332344055176,
      "logps/chosen": -48.24060821533203,
      "logps/rejected": -193.15367126464844,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4281063079833984,
      "rewards/margins": 10.48196029663086,
      "rewards/rejected": -9.053853988647461,
      "step": 4388
    },
    {
      "epoch": 1.7556,
      "grad_norm": 0.0553450770676136,
      "learning_rate": 4.149333333333333e-07,
      "logits/chosen": -2.846930980682373,
      "logits/rejected": -2.088202953338623,
      "logps/chosen": -85.45120239257812,
      "logps/rejected": -133.30006408691406,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7804908752441406,
      "rewards/margins": 9.704424858093262,
      "rewards/rejected": -8.923933982849121,
      "step": 4389
    },
    {
      "epoch": 1.756,
      "grad_norm": 0.13861095905303955,
      "learning_rate": 4.148e-07,
      "logits/chosen": -2.375113010406494,
      "logits/rejected": -2.1608972549438477,
      "logps/chosen": -108.9383544921875,
      "logps/rejected": -192.73953247070312,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.447596788406372,
      "rewards/margins": 8.251912117004395,
      "rewards/rejected": -11.699508666992188,
      "step": 4390
    },
    {
      "epoch": 1.7564,
      "grad_norm": 0.42188704013824463,
      "learning_rate": 4.146666666666667e-07,
      "logits/chosen": -2.86617112159729,
      "logits/rejected": -2.733320713043213,
      "logps/chosen": -103.17911529541016,
      "logps/rejected": -134.53756713867188,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4239673614501953,
      "rewards/margins": 7.4973464012146,
      "rewards/rejected": -7.921314239501953,
      "step": 4391
    },
    {
      "epoch": 1.7568000000000001,
      "grad_norm": 0.7410925030708313,
      "learning_rate": 4.145333333333333e-07,
      "logits/chosen": -2.7903988361358643,
      "logits/rejected": -2.2920613288879395,
      "logps/chosen": -120.13236999511719,
      "logps/rejected": -185.01345825195312,
      "loss": 0.0049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3755874633789062,
      "rewards/margins": 10.160866737365723,
      "rewards/rejected": -11.536454200744629,
      "step": 4392
    },
    {
      "epoch": 1.7572,
      "grad_norm": 0.0703325942158699,
      "learning_rate": 4.1439999999999995e-07,
      "logits/chosen": -3.337021589279175,
      "logits/rejected": -2.722642421722412,
      "logps/chosen": -75.8174819946289,
      "logps/rejected": -105.33086395263672,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2443825006484985,
      "rewards/margins": 7.887088775634766,
      "rewards/rejected": -6.642705917358398,
      "step": 4393
    },
    {
      "epoch": 1.7576,
      "grad_norm": 0.1856456845998764,
      "learning_rate": 4.1426666666666664e-07,
      "logits/chosen": -3.03240966796875,
      "logits/rejected": -2.8217122554779053,
      "logps/chosen": -89.60285949707031,
      "logps/rejected": -123.82687377929688,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16602249443531036,
      "rewards/margins": 8.653395652770996,
      "rewards/rejected": -8.487372398376465,
      "step": 4394
    },
    {
      "epoch": 1.758,
      "grad_norm": 0.0036071704234927893,
      "learning_rate": 4.1413333333333334e-07,
      "logits/chosen": -2.608455181121826,
      "logits/rejected": -1.5837461948394775,
      "logps/chosen": -115.96253967285156,
      "logps/rejected": -208.75506591796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2569530010223389,
      "rewards/margins": 12.052749633789062,
      "rewards/rejected": -10.795796394348145,
      "step": 4395
    },
    {
      "epoch": 1.7584,
      "grad_norm": 0.2521919012069702,
      "learning_rate": 4.14e-07,
      "logits/chosen": -3.1651244163513184,
      "logits/rejected": -2.8886706829071045,
      "logps/chosen": -36.15304946899414,
      "logps/rejected": -137.62245178222656,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27593040466308594,
      "rewards/margins": 8.071914672851562,
      "rewards/rejected": -7.795984268188477,
      "step": 4396
    },
    {
      "epoch": 1.7588,
      "grad_norm": 0.030128134414553642,
      "learning_rate": 4.1386666666666667e-07,
      "logits/chosen": -2.628459930419922,
      "logits/rejected": -2.058659076690674,
      "logps/chosen": -154.9214324951172,
      "logps/rejected": -185.46795654296875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.567411422729492,
      "rewards/margins": 9.327613830566406,
      "rewards/rejected": -11.895025253295898,
      "step": 4397
    },
    {
      "epoch": 1.7591999999999999,
      "grad_norm": 0.008203985169529915,
      "learning_rate": 4.137333333333333e-07,
      "logits/chosen": -2.731827974319458,
      "logits/rejected": -1.9476512670516968,
      "logps/chosen": -139.44290161132812,
      "logps/rejected": -163.4899139404297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.06796760857105255,
      "rewards/margins": 9.974020004272461,
      "rewards/rejected": -10.041988372802734,
      "step": 4398
    },
    {
      "epoch": 1.7596,
      "grad_norm": 0.00035344940260984004,
      "learning_rate": 4.136e-07,
      "logits/chosen": -2.665963649749756,
      "logits/rejected": -2.004570960998535,
      "logps/chosen": -110.94869995117188,
      "logps/rejected": -213.23162841796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.618111789226532,
      "rewards/margins": 14.429804801940918,
      "rewards/rejected": -13.81169319152832,
      "step": 4399
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.046966295689344406,
      "learning_rate": 4.1346666666666664e-07,
      "logits/chosen": -2.819455862045288,
      "logits/rejected": -2.5859436988830566,
      "logps/chosen": -64.05348205566406,
      "logps/rejected": -129.04043579101562,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7453218698501587,
      "rewards/margins": 8.87806224822998,
      "rewards/rejected": -8.132740020751953,
      "step": 4400
    },
    {
      "epoch": 1.7604,
      "grad_norm": 0.5627437829971313,
      "learning_rate": 4.1333333333333333e-07,
      "logits/chosen": -2.9821882247924805,
      "logits/rejected": -2.769796371459961,
      "logps/chosen": -125.77545928955078,
      "logps/rejected": -102.10784912109375,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12617376446723938,
      "rewards/margins": 6.451861381530762,
      "rewards/rejected": -6.325687408447266,
      "step": 4401
    },
    {
      "epoch": 1.7608000000000001,
      "grad_norm": 1.9674570560455322,
      "learning_rate": 4.1319999999999997e-07,
      "logits/chosen": -3.205794334411621,
      "logits/rejected": -3.1079764366149902,
      "logps/chosen": -83.08712005615234,
      "logps/rejected": -73.51768493652344,
      "loss": 0.0205,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.47676849365234375,
      "rewards/margins": 4.041568279266357,
      "rewards/rejected": -4.518336772918701,
      "step": 4402
    },
    {
      "epoch": 1.7612,
      "grad_norm": 7.699268817901611,
      "learning_rate": 4.1306666666666666e-07,
      "logits/chosen": -2.513489246368408,
      "logits/rejected": -2.17437744140625,
      "logps/chosen": -144.4857940673828,
      "logps/rejected": -167.41912841796875,
      "loss": 0.0353,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.327700614929199,
      "rewards/margins": 7.985913276672363,
      "rewards/rejected": -10.313613891601562,
      "step": 4403
    },
    {
      "epoch": 1.7616,
      "grad_norm": 0.1154865175485611,
      "learning_rate": 4.129333333333333e-07,
      "logits/chosen": -2.694672107696533,
      "logits/rejected": -2.3491055965423584,
      "logps/chosen": -126.4073715209961,
      "logps/rejected": -142.2396697998047,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8262245059013367,
      "rewards/margins": 10.15462589263916,
      "rewards/rejected": -9.328401565551758,
      "step": 4404
    },
    {
      "epoch": 1.762,
      "grad_norm": 0.04294734075665474,
      "learning_rate": 4.128e-07,
      "logits/chosen": -2.730531692504883,
      "logits/rejected": -1.9418721199035645,
      "logps/chosen": -107.04307556152344,
      "logps/rejected": -154.75518798828125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.23305082321167,
      "rewards/margins": 11.45571517944336,
      "rewards/rejected": -9.222663879394531,
      "step": 4405
    },
    {
      "epoch": 1.7624,
      "grad_norm": 0.03349659591913223,
      "learning_rate": 4.126666666666667e-07,
      "logits/chosen": -2.6165943145751953,
      "logits/rejected": -2.2665982246398926,
      "logps/chosen": -85.88595581054688,
      "logps/rejected": -139.2857208251953,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.900660753250122,
      "rewards/margins": 10.13969612121582,
      "rewards/rejected": -8.239035606384277,
      "step": 4406
    },
    {
      "epoch": 1.7628,
      "grad_norm": 0.024730058386921883,
      "learning_rate": 4.1253333333333327e-07,
      "logits/chosen": -2.7259581089019775,
      "logits/rejected": -2.4139270782470703,
      "logps/chosen": -62.029212951660156,
      "logps/rejected": -232.59153747558594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9597915410995483,
      "rewards/margins": 12.94771957397461,
      "rewards/rejected": -11.98792839050293,
      "step": 4407
    },
    {
      "epoch": 1.7631999999999999,
      "grad_norm": 0.4404650330543518,
      "learning_rate": 4.1239999999999996e-07,
      "logits/chosen": -2.656367778778076,
      "logits/rejected": -2.3586761951446533,
      "logps/chosen": -100.01435852050781,
      "logps/rejected": -155.28094482421875,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7378852963447571,
      "rewards/margins": 8.109559059143066,
      "rewards/rejected": -8.847444534301758,
      "step": 4408
    },
    {
      "epoch": 1.7635999999999998,
      "grad_norm": 0.010798457078635693,
      "learning_rate": 4.1226666666666665e-07,
      "logits/chosen": -2.62613582611084,
      "logits/rejected": -2.26442289352417,
      "logps/chosen": -136.89251708984375,
      "logps/rejected": -171.61398315429688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.13835754990577698,
      "rewards/margins": 10.307817459106445,
      "rewards/rejected": -10.446174621582031,
      "step": 4409
    },
    {
      "epoch": 1.764,
      "grad_norm": 0.26231101155281067,
      "learning_rate": 4.1213333333333334e-07,
      "logits/chosen": -2.5635907649993896,
      "logits/rejected": -1.9739720821380615,
      "logps/chosen": -130.95143127441406,
      "logps/rejected": -150.44480895996094,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.34340134263038635,
      "rewards/margins": 9.308483123779297,
      "rewards/rejected": -9.651885032653809,
      "step": 4410
    },
    {
      "epoch": 1.7644,
      "grad_norm": 0.07712046802043915,
      "learning_rate": 4.12e-07,
      "logits/chosen": -3.0695619583129883,
      "logits/rejected": -2.6740424633026123,
      "logps/chosen": -46.63186264038086,
      "logps/rejected": -152.88922119140625,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0568374395370483,
      "rewards/margins": 10.840326309204102,
      "rewards/rejected": -9.783489227294922,
      "step": 4411
    },
    {
      "epoch": 1.7648000000000001,
      "grad_norm": 0.35834625363349915,
      "learning_rate": 4.118666666666666e-07,
      "logits/chosen": -2.834902286529541,
      "logits/rejected": -2.451462745666504,
      "logps/chosen": -136.60552978515625,
      "logps/rejected": -122.84428405761719,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9376533627510071,
      "rewards/margins": 6.085597038269043,
      "rewards/rejected": -7.023250579833984,
      "step": 4412
    },
    {
      "epoch": 1.7652,
      "grad_norm": 0.01292828842997551,
      "learning_rate": 4.117333333333333e-07,
      "logits/chosen": -3.0235044956207275,
      "logits/rejected": -2.376709461212158,
      "logps/chosen": -65.4205322265625,
      "logps/rejected": -167.86842346191406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.747693657875061,
      "rewards/margins": 9.935336112976074,
      "rewards/rejected": -10.683029174804688,
      "step": 4413
    },
    {
      "epoch": 1.7656,
      "grad_norm": 0.011319633573293686,
      "learning_rate": 4.116e-07,
      "logits/chosen": -3.183032989501953,
      "logits/rejected": -2.475188970565796,
      "logps/chosen": -42.14542007446289,
      "logps/rejected": -193.09475708007812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2536001205444336,
      "rewards/margins": 12.586509704589844,
      "rewards/rejected": -12.33290958404541,
      "step": 4414
    },
    {
      "epoch": 1.766,
      "grad_norm": 0.238297238945961,
      "learning_rate": 4.1146666666666665e-07,
      "logits/chosen": -2.7216134071350098,
      "logits/rejected": -2.2531213760375977,
      "logps/chosen": -99.70939636230469,
      "logps/rejected": -156.4864501953125,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.44498369097709656,
      "rewards/margins": 9.822407722473145,
      "rewards/rejected": -9.377424240112305,
      "step": 4415
    },
    {
      "epoch": 1.7664,
      "grad_norm": 0.3038232624530792,
      "learning_rate": 4.113333333333333e-07,
      "logits/chosen": -2.9144625663757324,
      "logits/rejected": -2.8025331497192383,
      "logps/chosen": -70.90451049804688,
      "logps/rejected": -106.76011657714844,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0323340892791748,
      "rewards/margins": 6.128207206726074,
      "rewards/rejected": -7.16054105758667,
      "step": 4416
    },
    {
      "epoch": 1.7668,
      "grad_norm": 4.845829486846924,
      "learning_rate": 4.112e-07,
      "logits/chosen": -2.82669734954834,
      "logits/rejected": -2.7706947326660156,
      "logps/chosen": -73.26244354248047,
      "logps/rejected": -119.03253173828125,
      "loss": 0.0305,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3479894399642944,
      "rewards/margins": 5.712615013122559,
      "rewards/rejected": -7.060604095458984,
      "step": 4417
    },
    {
      "epoch": 1.7671999999999999,
      "grad_norm": 0.006006028037518263,
      "learning_rate": 4.1106666666666667e-07,
      "logits/chosen": -2.3521313667297363,
      "logits/rejected": -1.5038573741912842,
      "logps/chosen": -168.7886962890625,
      "logps/rejected": -175.265625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8137832880020142,
      "rewards/margins": 10.610998153686523,
      "rewards/rejected": -9.79721450805664,
      "step": 4418
    },
    {
      "epoch": 1.7675999999999998,
      "grad_norm": 0.002571903867647052,
      "learning_rate": 4.109333333333333e-07,
      "logits/chosen": -2.873879909515381,
      "logits/rejected": -2.486179828643799,
      "logps/chosen": -79.8962173461914,
      "logps/rejected": -155.2088623046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9598491787910461,
      "rewards/margins": 11.436433792114258,
      "rewards/rejected": -10.476585388183594,
      "step": 4419
    },
    {
      "epoch": 1.768,
      "grad_norm": 2.3566906452178955,
      "learning_rate": 4.108e-07,
      "logits/chosen": -2.948629856109619,
      "logits/rejected": -2.770781993865967,
      "logps/chosen": -89.02671813964844,
      "logps/rejected": -97.84286499023438,
      "loss": 0.0243,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1060374975204468,
      "rewards/margins": 5.204041481018066,
      "rewards/rejected": -6.3100786209106445,
      "step": 4420
    },
    {
      "epoch": 1.7684,
      "grad_norm": 0.0011420587543398142,
      "learning_rate": 4.1066666666666664e-07,
      "logits/chosen": -2.875439167022705,
      "logits/rejected": -2.190976142883301,
      "logps/chosen": -82.39620971679688,
      "logps/rejected": -162.7213134765625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6543309688568115,
      "rewards/margins": 13.662023544311523,
      "rewards/rejected": -11.007692337036133,
      "step": 4421
    },
    {
      "epoch": 1.7688000000000001,
      "grad_norm": 1.7513058185577393,
      "learning_rate": 4.105333333333333e-07,
      "logits/chosen": -2.9149818420410156,
      "logits/rejected": -2.942080497741699,
      "logps/chosen": -97.85594177246094,
      "logps/rejected": -99.85762023925781,
      "loss": 0.0135,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2000541687011719,
      "rewards/margins": 4.528866291046143,
      "rewards/rejected": -5.7289204597473145,
      "step": 4422
    },
    {
      "epoch": 1.7692,
      "grad_norm": 0.008150209672749043,
      "learning_rate": 4.1039999999999997e-07,
      "logits/chosen": -1.988713026046753,
      "logits/rejected": -1.4233901500701904,
      "logps/chosen": -128.7014923095703,
      "logps/rejected": -227.13876342773438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21604347229003906,
      "rewards/margins": 11.253179550170898,
      "rewards/rejected": -11.03713607788086,
      "step": 4423
    },
    {
      "epoch": 1.7696,
      "grad_norm": 0.005861575715243816,
      "learning_rate": 4.1026666666666666e-07,
      "logits/chosen": -2.99501371383667,
      "logits/rejected": -2.658282518386841,
      "logps/chosen": -66.42697143554688,
      "logps/rejected": -152.1620635986328,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8644695281982422,
      "rewards/margins": 10.846769332885742,
      "rewards/rejected": -9.9822998046875,
      "step": 4424
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.016154179349541664,
      "learning_rate": 4.1013333333333335e-07,
      "logits/chosen": -2.915951728820801,
      "logits/rejected": -2.4412765502929688,
      "logps/chosen": -83.32088470458984,
      "logps/rejected": -149.093505859375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.023779764771461487,
      "rewards/margins": 9.454195022583008,
      "rewards/rejected": -9.477974891662598,
      "step": 4425
    },
    {
      "epoch": 1.7704,
      "grad_norm": 0.04342154413461685,
      "learning_rate": 4.0999999999999994e-07,
      "logits/chosen": -3.208498477935791,
      "logits/rejected": -2.7608580589294434,
      "logps/chosen": -61.694976806640625,
      "logps/rejected": -145.1650390625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.338526725769043,
      "rewards/margins": 9.507978439331055,
      "rewards/rejected": -8.169450759887695,
      "step": 4426
    },
    {
      "epoch": 1.7708,
      "grad_norm": 0.0020185247994959354,
      "learning_rate": 4.0986666666666663e-07,
      "logits/chosen": -2.566720485687256,
      "logits/rejected": -2.3264896869659424,
      "logps/chosen": -104.38221740722656,
      "logps/rejected": -207.90667724609375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.47327500581741333,
      "rewards/margins": 12.500614166259766,
      "rewards/rejected": -12.027339935302734,
      "step": 4427
    },
    {
      "epoch": 1.7711999999999999,
      "grad_norm": 0.5433048605918884,
      "learning_rate": 4.097333333333333e-07,
      "logits/chosen": -2.8279826641082764,
      "logits/rejected": -2.540354013442993,
      "logps/chosen": -104.50881958007812,
      "logps/rejected": -126.82482147216797,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7104341387748718,
      "rewards/margins": 7.548741340637207,
      "rewards/rejected": -8.259176254272461,
      "step": 4428
    },
    {
      "epoch": 1.7715999999999998,
      "grad_norm": 0.003891591215506196,
      "learning_rate": 4.096e-07,
      "logits/chosen": -2.7408828735351562,
      "logits/rejected": -1.6533143520355225,
      "logps/chosen": -85.29631805419922,
      "logps/rejected": -186.34310913085938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9390869140625,
      "rewards/margins": 12.63835334777832,
      "rewards/rejected": -10.69926643371582,
      "step": 4429
    },
    {
      "epoch": 1.772,
      "grad_norm": 2.3269312381744385,
      "learning_rate": 4.094666666666666e-07,
      "logits/chosen": -2.6149826049804688,
      "logits/rejected": -2.547344207763672,
      "logps/chosen": -111.70285034179688,
      "logps/rejected": -115.77789306640625,
      "loss": 0.0099,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8625298738479614,
      "rewards/margins": 6.795530319213867,
      "rewards/rejected": -7.658060550689697,
      "step": 4430
    },
    {
      "epoch": 1.7724,
      "grad_norm": 0.8734120726585388,
      "learning_rate": 4.093333333333333e-07,
      "logits/chosen": -2.8508834838867188,
      "logits/rejected": -2.704409122467041,
      "logps/chosen": -178.1424102783203,
      "logps/rejected": -98.11495971679688,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7467780709266663,
      "rewards/margins": 5.539037227630615,
      "rewards/rejected": -6.285815238952637,
      "step": 4431
    },
    {
      "epoch": 1.7728000000000002,
      "grad_norm": 0.1640351265668869,
      "learning_rate": 4.092e-07,
      "logits/chosen": -2.6958091259002686,
      "logits/rejected": -1.8801569938659668,
      "logps/chosen": -133.69859313964844,
      "logps/rejected": -146.62510681152344,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.06730766594409943,
      "rewards/margins": 9.158964157104492,
      "rewards/rejected": -9.226271629333496,
      "step": 4432
    },
    {
      "epoch": 1.7732,
      "grad_norm": 0.004865746013820171,
      "learning_rate": 4.090666666666667e-07,
      "logits/chosen": -2.691042423248291,
      "logits/rejected": -1.9329259395599365,
      "logps/chosen": -64.11979675292969,
      "logps/rejected": -143.26498413085938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4614105224609375,
      "rewards/margins": 11.396095275878906,
      "rewards/rejected": -8.934684753417969,
      "step": 4433
    },
    {
      "epoch": 1.7736,
      "grad_norm": 1.4309276342391968,
      "learning_rate": 4.089333333333333e-07,
      "logits/chosen": -3.010571002960205,
      "logits/rejected": -2.399533987045288,
      "logps/chosen": -135.00265502929688,
      "logps/rejected": -120.58364868164062,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.204144686460495,
      "rewards/margins": 6.973040580749512,
      "rewards/rejected": -7.17718505859375,
      "step": 4434
    },
    {
      "epoch": 1.774,
      "grad_norm": 3.0900163650512695,
      "learning_rate": 4.0879999999999995e-07,
      "logits/chosen": -2.4760141372680664,
      "logits/rejected": -2.380786895751953,
      "logps/chosen": -201.7357635498047,
      "logps/rejected": -176.7576446533203,
      "loss": 0.0188,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.013176679611206,
      "rewards/margins": 5.512103080749512,
      "rewards/rejected": -7.525279998779297,
      "step": 4435
    },
    {
      "epoch": 1.7744,
      "grad_norm": 0.29181817173957825,
      "learning_rate": 4.0866666666666665e-07,
      "logits/chosen": -2.178300380706787,
      "logits/rejected": -1.7656209468841553,
      "logps/chosen": -211.2991943359375,
      "logps/rejected": -241.8285369873047,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.6150338649749756,
      "rewards/margins": 6.66435432434082,
      "rewards/rejected": -10.279388427734375,
      "step": 4436
    },
    {
      "epoch": 1.7748,
      "grad_norm": 6.096818923950195,
      "learning_rate": 4.0853333333333334e-07,
      "logits/chosen": -2.769615411758423,
      "logits/rejected": -3.2054905891418457,
      "logps/chosen": -83.28587341308594,
      "logps/rejected": -66.67422485351562,
      "loss": 0.0675,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2766695022583008,
      "rewards/margins": 2.8041110038757324,
      "rewards/rejected": -4.080780506134033,
      "step": 4437
    },
    {
      "epoch": 1.7752,
      "grad_norm": 0.07020173966884613,
      "learning_rate": 4.084e-07,
      "logits/chosen": -2.7983479499816895,
      "logits/rejected": -2.518584728240967,
      "logps/chosen": -72.11796569824219,
      "logps/rejected": -111.9722671508789,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.24290546774864197,
      "rewards/margins": 7.402081489562988,
      "rewards/rejected": -7.644987106323242,
      "step": 4438
    },
    {
      "epoch": 1.7755999999999998,
      "grad_norm": 0.0013219264801591635,
      "learning_rate": 4.0826666666666667e-07,
      "logits/chosen": -2.9510140419006348,
      "logits/rejected": -2.300321578979492,
      "logps/chosen": -64.09616088867188,
      "logps/rejected": -184.27064514160156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06658096611499786,
      "rewards/margins": 13.138404846191406,
      "rewards/rejected": -13.07182502746582,
      "step": 4439
    },
    {
      "epoch": 1.776,
      "grad_norm": 0.022996727377176285,
      "learning_rate": 4.081333333333333e-07,
      "logits/chosen": -2.3134047985076904,
      "logits/rejected": -1.580780267715454,
      "logps/chosen": -158.74876403808594,
      "logps/rejected": -170.90863037109375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7681487798690796,
      "rewards/margins": 9.844522476196289,
      "rewards/rejected": -10.6126708984375,
      "step": 4440
    },
    {
      "epoch": 1.7764,
      "grad_norm": 4.368940353393555,
      "learning_rate": 4.0799999999999995e-07,
      "logits/chosen": -2.733480215072632,
      "logits/rejected": -2.9920530319213867,
      "logps/chosen": -101.26863861083984,
      "logps/rejected": -108.89677429199219,
      "loss": 0.0259,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3347440958023071,
      "rewards/margins": 5.185354709625244,
      "rewards/rejected": -6.520098686218262,
      "step": 4441
    },
    {
      "epoch": 1.7768000000000002,
      "grad_norm": 0.0002310705604031682,
      "learning_rate": 4.0786666666666664e-07,
      "logits/chosen": -2.7527947425842285,
      "logits/rejected": -1.926184892654419,
      "logps/chosen": -107.68574523925781,
      "logps/rejected": -196.9908447265625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6711557507514954,
      "rewards/margins": 14.09814453125,
      "rewards/rejected": -13.42698860168457,
      "step": 4442
    },
    {
      "epoch": 1.7772000000000001,
      "grad_norm": 0.0033895522356033325,
      "learning_rate": 4.0773333333333333e-07,
      "logits/chosen": -3.0284271240234375,
      "logits/rejected": -2.4508538246154785,
      "logps/chosen": -47.159584045410156,
      "logps/rejected": -187.62298583984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.19875967502594,
      "rewards/margins": 12.198731422424316,
      "rewards/rejected": -10.999971389770508,
      "step": 4443
    },
    {
      "epoch": 1.7776,
      "grad_norm": 0.003541195299476385,
      "learning_rate": 4.076e-07,
      "logits/chosen": -2.666863441467285,
      "logits/rejected": -1.8919050693511963,
      "logps/chosen": -92.90074157714844,
      "logps/rejected": -186.37474060058594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1046336889266968,
      "rewards/margins": 12.08390998840332,
      "rewards/rejected": -10.979276657104492,
      "step": 4444
    },
    {
      "epoch": 1.778,
      "grad_norm": 0.052526310086250305,
      "learning_rate": 4.074666666666666e-07,
      "logits/chosen": -3.175346851348877,
      "logits/rejected": -2.534550189971924,
      "logps/chosen": -40.76347732543945,
      "logps/rejected": -169.73280334472656,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6477808952331543,
      "rewards/margins": 12.959274291992188,
      "rewards/rejected": -12.311492919921875,
      "step": 4445
    },
    {
      "epoch": 1.7784,
      "grad_norm": 0.11380524933338165,
      "learning_rate": 4.073333333333333e-07,
      "logits/chosen": -2.547168731689453,
      "logits/rejected": -2.1446099281311035,
      "logps/chosen": -167.34434509277344,
      "logps/rejected": -148.97796630859375,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.1296634674072266,
      "rewards/margins": 7.317154884338379,
      "rewards/rejected": -9.446818351745605,
      "step": 4446
    },
    {
      "epoch": 1.7788,
      "grad_norm": 0.0002204659831477329,
      "learning_rate": 4.072e-07,
      "logits/chosen": -2.767817974090576,
      "logits/rejected": -2.0826902389526367,
      "logps/chosen": -69.61212158203125,
      "logps/rejected": -203.30477905273438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.492911159992218,
      "rewards/margins": 13.984914779663086,
      "rewards/rejected": -13.492003440856934,
      "step": 4447
    },
    {
      "epoch": 1.7792,
      "grad_norm": 1.1385669708251953,
      "learning_rate": 4.070666666666667e-07,
      "logits/chosen": -2.766700267791748,
      "logits/rejected": -2.39102840423584,
      "logps/chosen": -101.99163818359375,
      "logps/rejected": -133.2989501953125,
      "loss": 0.0069,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.677768349647522,
      "rewards/margins": 6.643386363983154,
      "rewards/rejected": -7.321154594421387,
      "step": 4448
    },
    {
      "epoch": 1.7795999999999998,
      "grad_norm": 2.7913494704989716e-05,
      "learning_rate": 4.0693333333333327e-07,
      "logits/chosen": -2.74943470954895,
      "logits/rejected": -1.85054349899292,
      "logps/chosen": -92.95799255371094,
      "logps/rejected": -216.81912231445312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.413512706756592,
      "rewards/margins": 16.78988265991211,
      "rewards/rejected": -14.37636947631836,
      "step": 4449
    },
    {
      "epoch": 1.78,
      "grad_norm": 7.540877819061279,
      "learning_rate": 4.0679999999999996e-07,
      "logits/chosen": -2.522798538208008,
      "logits/rejected": -2.079318046569824,
      "logps/chosen": -87.57307434082031,
      "logps/rejected": -119.15663146972656,
      "loss": 0.0565,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21320877969264984,
      "rewards/margins": 6.747096538543701,
      "rewards/rejected": -6.53388786315918,
      "step": 4450
    },
    {
      "epoch": 1.7804,
      "grad_norm": 0.08780652284622192,
      "learning_rate": 4.0666666666666666e-07,
      "logits/chosen": -2.778646469116211,
      "logits/rejected": -2.4609336853027344,
      "logps/chosen": -87.56443786621094,
      "logps/rejected": -128.3524169921875,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.604915976524353,
      "rewards/margins": 9.701507568359375,
      "rewards/rejected": -8.09659194946289,
      "step": 4451
    },
    {
      "epoch": 1.7808000000000002,
      "grad_norm": 0.004730858840048313,
      "learning_rate": 4.0653333333333335e-07,
      "logits/chosen": -2.6745011806488037,
      "logits/rejected": -1.99239182472229,
      "logps/chosen": -90.68753814697266,
      "logps/rejected": -149.31100463867188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0860252380371094,
      "rewards/margins": 11.146206855773926,
      "rewards/rejected": -10.060181617736816,
      "step": 4452
    },
    {
      "epoch": 1.7812000000000001,
      "grad_norm": 0.056941382586956024,
      "learning_rate": 4.064e-07,
      "logits/chosen": -2.3768484592437744,
      "logits/rejected": -1.6253280639648438,
      "logps/chosen": -140.54415893554688,
      "logps/rejected": -180.68252563476562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3374066352844238,
      "rewards/margins": 11.22889518737793,
      "rewards/rejected": -12.566301345825195,
      "step": 4453
    },
    {
      "epoch": 1.7816,
      "grad_norm": 0.5047497153282166,
      "learning_rate": 4.062666666666666e-07,
      "logits/chosen": -2.5882821083068848,
      "logits/rejected": -2.5623879432678223,
      "logps/chosen": -113.88837432861328,
      "logps/rejected": -115.01983642578125,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4370265603065491,
      "rewards/margins": 7.421407699584961,
      "rewards/rejected": -6.984381198883057,
      "step": 4454
    },
    {
      "epoch": 1.782,
      "grad_norm": 0.3648417592048645,
      "learning_rate": 4.061333333333333e-07,
      "logits/chosen": -2.5608625411987305,
      "logits/rejected": -2.4019880294799805,
      "logps/chosen": -80.124267578125,
      "logps/rejected": -117.37322998046875,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7885521650314331,
      "rewards/margins": 7.685330390930176,
      "rewards/rejected": -6.896778583526611,
      "step": 4455
    },
    {
      "epoch": 1.7824,
      "grad_norm": 0.32163166999816895,
      "learning_rate": 4.06e-07,
      "logits/chosen": -2.8115007877349854,
      "logits/rejected": -2.007275342941284,
      "logps/chosen": -83.85858154296875,
      "logps/rejected": -140.51864624023438,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5301950573921204,
      "rewards/margins": 9.769046783447266,
      "rewards/rejected": -9.238852500915527,
      "step": 4456
    },
    {
      "epoch": 1.7828,
      "grad_norm": 0.05446016788482666,
      "learning_rate": 4.0586666666666665e-07,
      "logits/chosen": -2.327836275100708,
      "logits/rejected": -2.2136359214782715,
      "logps/chosen": -108.77069854736328,
      "logps/rejected": -132.57870483398438,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6057742834091187,
      "rewards/margins": 9.059991836547852,
      "rewards/rejected": -8.454217910766602,
      "step": 4457
    },
    {
      "epoch": 1.7832,
      "grad_norm": 3.321255922317505,
      "learning_rate": 4.0573333333333334e-07,
      "logits/chosen": -2.994950771331787,
      "logits/rejected": -2.556743621826172,
      "logps/chosen": -100.57870483398438,
      "logps/rejected": -110.87845611572266,
      "loss": 0.0177,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0379912853240967,
      "rewards/margins": 4.133728981018066,
      "rewards/rejected": -6.171720504760742,
      "step": 4458
    },
    {
      "epoch": 1.7835999999999999,
      "grad_norm": 1.0838792324066162,
      "learning_rate": 4.056e-07,
      "logits/chosen": -2.8266029357910156,
      "logits/rejected": -2.6014251708984375,
      "logps/chosen": -77.03829956054688,
      "logps/rejected": -141.10264587402344,
      "loss": 0.0081,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.898566484451294,
      "rewards/margins": 8.517995834350586,
      "rewards/rejected": -9.416563034057617,
      "step": 4459
    },
    {
      "epoch": 1.784,
      "grad_norm": 1.6774582862854004,
      "learning_rate": 4.054666666666666e-07,
      "logits/chosen": -3.0038185119628906,
      "logits/rejected": -3.080613613128662,
      "logps/chosen": -64.36036682128906,
      "logps/rejected": -71.47850799560547,
      "loss": 0.0098,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7978968024253845,
      "rewards/margins": 5.717768669128418,
      "rewards/rejected": -4.919871807098389,
      "step": 4460
    },
    {
      "epoch": 1.7844,
      "grad_norm": 0.3847498893737793,
      "learning_rate": 4.053333333333333e-07,
      "logits/chosen": -2.9628639221191406,
      "logits/rejected": -2.826296806335449,
      "logps/chosen": -97.29585266113281,
      "logps/rejected": -102.99791717529297,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.18115615844726562,
      "rewards/margins": 6.26038932800293,
      "rewards/rejected": -6.441545486450195,
      "step": 4461
    },
    {
      "epoch": 1.7848000000000002,
      "grad_norm": 0.6099174618721008,
      "learning_rate": 4.052e-07,
      "logits/chosen": -2.6697516441345215,
      "logits/rejected": -2.5576860904693604,
      "logps/chosen": -80.96707916259766,
      "logps/rejected": -85.30037689208984,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8959881067276,
      "rewards/margins": 5.963771820068359,
      "rewards/rejected": -4.067783832550049,
      "step": 4462
    },
    {
      "epoch": 1.7852000000000001,
      "grad_norm": 4.835101127624512,
      "learning_rate": 4.050666666666667e-07,
      "logits/chosen": -2.6850035190582275,
      "logits/rejected": -2.0895988941192627,
      "logps/chosen": -89.32398986816406,
      "logps/rejected": -111.72477722167969,
      "loss": 0.0409,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2570793032646179,
      "rewards/margins": 6.593540191650391,
      "rewards/rejected": -6.336461067199707,
      "step": 4463
    },
    {
      "epoch": 1.7856,
      "grad_norm": 0.09266433119773865,
      "learning_rate": 4.049333333333333e-07,
      "logits/chosen": -2.946989059448242,
      "logits/rejected": -2.6708903312683105,
      "logps/chosen": -113.31805419921875,
      "logps/rejected": -117.34773254394531,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5113426446914673,
      "rewards/margins": 7.333390235900879,
      "rewards/rejected": -7.844732761383057,
      "step": 4464
    },
    {
      "epoch": 1.786,
      "grad_norm": 0.615662693977356,
      "learning_rate": 4.0479999999999997e-07,
      "logits/chosen": -2.643097400665283,
      "logits/rejected": -2.7165584564208984,
      "logps/chosen": -161.76739501953125,
      "logps/rejected": -169.12774658203125,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.348138332366943,
      "rewards/margins": 5.976202964782715,
      "rewards/rejected": -10.324341773986816,
      "step": 4465
    },
    {
      "epoch": 1.7864,
      "grad_norm": 0.004019022453576326,
      "learning_rate": 4.0466666666666666e-07,
      "logits/chosen": -2.5441040992736816,
      "logits/rejected": -1.9211071729660034,
      "logps/chosen": -91.26884460449219,
      "logps/rejected": -181.16285705566406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6921634674072266,
      "rewards/margins": 11.27580451965332,
      "rewards/rejected": -10.583641052246094,
      "step": 4466
    },
    {
      "epoch": 1.7868,
      "grad_norm": 0.8553417325019836,
      "learning_rate": 4.0453333333333336e-07,
      "logits/chosen": -2.7350940704345703,
      "logits/rejected": -2.5741240978240967,
      "logps/chosen": -79.24761962890625,
      "logps/rejected": -79.88410949707031,
      "loss": 0.0074,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.009344473481178284,
      "rewards/margins": 4.929905891418457,
      "rewards/rejected": -4.92056131362915,
      "step": 4467
    },
    {
      "epoch": 1.7872,
      "grad_norm": 17.155601501464844,
      "learning_rate": 4.0439999999999994e-07,
      "logits/chosen": -2.411191940307617,
      "logits/rejected": -2.287341594696045,
      "logps/chosen": -174.13186645507812,
      "logps/rejected": -135.7971954345703,
      "loss": 0.1246,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.20232892036438,
      "rewards/margins": 4.060969352722168,
      "rewards/rejected": -7.263298034667969,
      "step": 4468
    },
    {
      "epoch": 1.7875999999999999,
      "grad_norm": 0.003375393571332097,
      "learning_rate": 4.0426666666666663e-07,
      "logits/chosen": -2.8190107345581055,
      "logits/rejected": -2.0557899475097656,
      "logps/chosen": -74.6626968383789,
      "logps/rejected": -176.98904418945312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3769874572753906,
      "rewards/margins": 11.193965911865234,
      "rewards/rejected": -9.816978454589844,
      "step": 4469
    },
    {
      "epoch": 1.788,
      "grad_norm": 0.4314063489437103,
      "learning_rate": 4.041333333333333e-07,
      "logits/chosen": -2.7158565521240234,
      "logits/rejected": -2.0412094593048096,
      "logps/chosen": -108.8081283569336,
      "logps/rejected": -131.4869384765625,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.868375539779663,
      "rewards/margins": 6.531248092651367,
      "rewards/rejected": -8.39962387084961,
      "step": 4470
    },
    {
      "epoch": 1.7884,
      "grad_norm": 0.3238461911678314,
      "learning_rate": 4.04e-07,
      "logits/chosen": -3.0087008476257324,
      "logits/rejected": -2.4887919425964355,
      "logps/chosen": -75.94249725341797,
      "logps/rejected": -138.1306610107422,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.48216915130615234,
      "rewards/margins": 10.029966354370117,
      "rewards/rejected": -9.547797203063965,
      "step": 4471
    },
    {
      "epoch": 1.7888,
      "grad_norm": 3.912679433822632,
      "learning_rate": 4.0386666666666666e-07,
      "logits/chosen": -2.7077057361602783,
      "logits/rejected": -2.672102928161621,
      "logps/chosen": -133.7165069580078,
      "logps/rejected": -142.32574462890625,
      "loss": 0.0209,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.3040976524353027,
      "rewards/margins": 7.041346549987793,
      "rewards/rejected": -9.345443725585938,
      "step": 4472
    },
    {
      "epoch": 1.7892000000000001,
      "grad_norm": 0.0015492943348363042,
      "learning_rate": 4.037333333333333e-07,
      "logits/chosen": -2.833683967590332,
      "logits/rejected": -2.1225156784057617,
      "logps/chosen": -121.4120864868164,
      "logps/rejected": -172.44796752929688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6140823364257812,
      "rewards/margins": 12.368974685668945,
      "rewards/rejected": -11.754892349243164,
      "step": 4473
    },
    {
      "epoch": 1.7896,
      "grad_norm": 0.0400959849357605,
      "learning_rate": 4.036e-07,
      "logits/chosen": -2.6494686603546143,
      "logits/rejected": -2.1573400497436523,
      "logps/chosen": -142.72866821289062,
      "logps/rejected": -135.67869567871094,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4312751889228821,
      "rewards/margins": 8.471305847167969,
      "rewards/rejected": -8.902581214904785,
      "step": 4474
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.005105721298605204,
      "learning_rate": 4.0346666666666663e-07,
      "logits/chosen": -2.9230942726135254,
      "logits/rejected": -2.4254331588745117,
      "logps/chosen": -92.99473571777344,
      "logps/rejected": -213.46888732910156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.5548367500305176,
      "rewards/margins": 11.48207950592041,
      "rewards/rejected": -14.03691577911377,
      "step": 4475
    },
    {
      "epoch": 1.7904,
      "grad_norm": 0.00010172790643991902,
      "learning_rate": 4.033333333333333e-07,
      "logits/chosen": -2.2940897941589355,
      "logits/rejected": -1.7984888553619385,
      "logps/chosen": -101.95747375488281,
      "logps/rejected": -282.45849609375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9051117300987244,
      "rewards/margins": 15.421344757080078,
      "rewards/rejected": -14.51623249053955,
      "step": 4476
    },
    {
      "epoch": 1.7908,
      "grad_norm": 0.00545997079461813,
      "learning_rate": 4.032e-07,
      "logits/chosen": -3.101776599884033,
      "logits/rejected": -2.414349317550659,
      "logps/chosen": -51.07083511352539,
      "logps/rejected": -171.96055603027344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7689235806465149,
      "rewards/margins": 10.96074390411377,
      "rewards/rejected": -11.729667663574219,
      "step": 4477
    },
    {
      "epoch": 1.7912,
      "grad_norm": 0.03149524703621864,
      "learning_rate": 4.0306666666666665e-07,
      "logits/chosen": -2.87526273727417,
      "logits/rejected": -2.3405909538269043,
      "logps/chosen": -61.605865478515625,
      "logps/rejected": -144.21514892578125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27832716703414917,
      "rewards/margins": 9.679179191589355,
      "rewards/rejected": -9.40085220336914,
      "step": 4478
    },
    {
      "epoch": 1.7915999999999999,
      "grad_norm": 3.8006396293640137,
      "learning_rate": 4.029333333333333e-07,
      "logits/chosen": -3.059793472290039,
      "logits/rejected": -2.682955741882324,
      "logps/chosen": -83.60560607910156,
      "logps/rejected": -108.12533569335938,
      "loss": 0.0208,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.007755756378174,
      "rewards/margins": 4.690879821777344,
      "rewards/rejected": -6.698635101318359,
      "step": 4479
    },
    {
      "epoch": 1.792,
      "grad_norm": 0.10805398225784302,
      "learning_rate": 4.028e-07,
      "logits/chosen": -2.7575366497039795,
      "logits/rejected": -2.5962297916412354,
      "logps/chosen": -109.89710998535156,
      "logps/rejected": -133.09814453125,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.33530768752098083,
      "rewards/margins": 7.67147159576416,
      "rewards/rejected": -8.006778717041016,
      "step": 4480
    },
    {
      "epoch": 1.7924,
      "grad_norm": 0.007150307297706604,
      "learning_rate": 4.0266666666666667e-07,
      "logits/chosen": -2.439328670501709,
      "logits/rejected": -1.8389415740966797,
      "logps/chosen": -129.15675354003906,
      "logps/rejected": -169.50462341308594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.080617904663086,
      "rewards/margins": 11.366808891296387,
      "rewards/rejected": -9.2861909866333,
      "step": 4481
    },
    {
      "epoch": 1.7928,
      "grad_norm": 0.016872094944119453,
      "learning_rate": 4.025333333333333e-07,
      "logits/chosen": -2.9508824348449707,
      "logits/rejected": -2.5284461975097656,
      "logps/chosen": -75.79266357421875,
      "logps/rejected": -159.98944091796875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0468511581420898,
      "rewards/margins": 10.583417892456055,
      "rewards/rejected": -9.536566734313965,
      "step": 4482
    },
    {
      "epoch": 1.7932000000000001,
      "grad_norm": 8.96069622039795,
      "learning_rate": 4.0239999999999995e-07,
      "logits/chosen": -2.9301106929779053,
      "logits/rejected": -2.6540379524230957,
      "logps/chosen": -86.10015869140625,
      "logps/rejected": -97.68912506103516,
      "loss": 0.0605,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5483293533325195,
      "rewards/margins": 3.930222749710083,
      "rewards/rejected": -5.478551864624023,
      "step": 4483
    },
    {
      "epoch": 1.7936,
      "grad_norm": 0.00010472514986759052,
      "learning_rate": 4.0226666666666664e-07,
      "logits/chosen": -2.4079947471618652,
      "logits/rejected": -1.964064121246338,
      "logps/chosen": -172.85845947265625,
      "logps/rejected": -362.420166015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.022138208150863647,
      "rewards/margins": 17.27656364440918,
      "rewards/rejected": -17.254425048828125,
      "step": 4484
    },
    {
      "epoch": 1.794,
      "grad_norm": 0.19400708377361298,
      "learning_rate": 4.0213333333333333e-07,
      "logits/chosen": -2.844172477722168,
      "logits/rejected": -2.230329990386963,
      "logps/chosen": -136.6703643798828,
      "logps/rejected": -145.2308807373047,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5193374752998352,
      "rewards/margins": 9.504024505615234,
      "rewards/rejected": -10.023361206054688,
      "step": 4485
    },
    {
      "epoch": 1.7944,
      "grad_norm": 0.000614987569861114,
      "learning_rate": 4.02e-07,
      "logits/chosen": -2.496530055999756,
      "logits/rejected": -1.9195382595062256,
      "logps/chosen": -110.99505615234375,
      "logps/rejected": -223.40740966796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5433002710342407,
      "rewards/margins": 13.572890281677246,
      "rewards/rejected": -13.029589653015137,
      "step": 4486
    },
    {
      "epoch": 1.7948,
      "grad_norm": 191.91676330566406,
      "learning_rate": 4.018666666666666e-07,
      "logits/chosen": -2.7651662826538086,
      "logits/rejected": -2.5717005729675293,
      "logps/chosen": -201.07054138183594,
      "logps/rejected": -105.70048522949219,
      "loss": 0.9708,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -3.3980164527893066,
      "rewards/margins": 2.9136648178100586,
      "rewards/rejected": -6.311681747436523,
      "step": 4487
    },
    {
      "epoch": 1.7952,
      "grad_norm": 0.27170437574386597,
      "learning_rate": 4.017333333333333e-07,
      "logits/chosen": -3.0123958587646484,
      "logits/rejected": -2.517493724822998,
      "logps/chosen": -44.888145446777344,
      "logps/rejected": -153.92002868652344,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09263381361961365,
      "rewards/margins": 10.270912170410156,
      "rewards/rejected": -10.178278923034668,
      "step": 4488
    },
    {
      "epoch": 1.7955999999999999,
      "grad_norm": 0.3018321096897125,
      "learning_rate": 4.016e-07,
      "logits/chosen": -2.6488170623779297,
      "logits/rejected": -1.935065507888794,
      "logps/chosen": -161.79750061035156,
      "logps/rejected": -163.8521270751953,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0157588720321655,
      "rewards/margins": 8.718181610107422,
      "rewards/rejected": -9.733940124511719,
      "step": 4489
    },
    {
      "epoch": 1.796,
      "grad_norm": 3.7657313346862793,
      "learning_rate": 4.014666666666667e-07,
      "logits/chosen": -3.199669361114502,
      "logits/rejected": -2.637498378753662,
      "logps/chosen": -104.43692779541016,
      "logps/rejected": -112.7951889038086,
      "loss": 0.0183,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9511764645576477,
      "rewards/margins": 7.655245304107666,
      "rewards/rejected": -6.704068660736084,
      "step": 4490
    },
    {
      "epoch": 1.7964,
      "grad_norm": 0.003334255423396826,
      "learning_rate": 4.0133333333333333e-07,
      "logits/chosen": -2.8739686012268066,
      "logits/rejected": -2.4144012928009033,
      "logps/chosen": -55.550071716308594,
      "logps/rejected": -175.31460571289062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05379205942153931,
      "rewards/margins": 11.57014274597168,
      "rewards/rejected": -11.516350746154785,
      "step": 4491
    },
    {
      "epoch": 1.7968,
      "grad_norm": 0.12290967255830765,
      "learning_rate": 4.0119999999999997e-07,
      "logits/chosen": -2.849750518798828,
      "logits/rejected": -2.337413787841797,
      "logps/chosen": -79.44720458984375,
      "logps/rejected": -124.67778015136719,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6881084442138672,
      "rewards/margins": 8.68612289428711,
      "rewards/rejected": -7.998013496398926,
      "step": 4492
    },
    {
      "epoch": 1.7972000000000001,
      "grad_norm": 0.37977170944213867,
      "learning_rate": 4.0106666666666666e-07,
      "logits/chosen": -2.458054542541504,
      "logits/rejected": -1.999446153640747,
      "logps/chosen": -173.5188446044922,
      "logps/rejected": -218.16421508789062,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.449501991271973,
      "rewards/margins": 7.450563907623291,
      "rewards/rejected": -11.900066375732422,
      "step": 4493
    },
    {
      "epoch": 1.7976,
      "grad_norm": 0.26365020871162415,
      "learning_rate": 4.009333333333333e-07,
      "logits/chosen": -2.5783755779266357,
      "logits/rejected": -2.296969413757324,
      "logps/chosen": -199.50315856933594,
      "logps/rejected": -157.45590209960938,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3655483722686768,
      "rewards/margins": 8.433948516845703,
      "rewards/rejected": -9.7994966506958,
      "step": 4494
    },
    {
      "epoch": 1.798,
      "grad_norm": 0.0012354654027149081,
      "learning_rate": 4.008e-07,
      "logits/chosen": -2.875856637954712,
      "logits/rejected": -2.248988389968872,
      "logps/chosen": -60.23181915283203,
      "logps/rejected": -228.33917236328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0748275518417358,
      "rewards/margins": 15.71014404296875,
      "rewards/rejected": -14.635315895080566,
      "step": 4495
    },
    {
      "epoch": 1.7984,
      "grad_norm": 0.011191416531801224,
      "learning_rate": 4.0066666666666663e-07,
      "logits/chosen": -2.609046697616577,
      "logits/rejected": -2.1515145301818848,
      "logps/chosen": -121.71479034423828,
      "logps/rejected": -156.13018798828125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7308040857315063,
      "rewards/margins": 9.702695846557617,
      "rewards/rejected": -11.433500289916992,
      "step": 4496
    },
    {
      "epoch": 1.7988,
      "grad_norm": 0.03316779062151909,
      "learning_rate": 4.005333333333333e-07,
      "logits/chosen": -2.795323133468628,
      "logits/rejected": -2.228665351867676,
      "logps/chosen": -76.39595031738281,
      "logps/rejected": -135.25721740722656,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.255275011062622,
      "rewards/margins": 10.667526245117188,
      "rewards/rejected": -8.412251472473145,
      "step": 4497
    },
    {
      "epoch": 1.7992,
      "grad_norm": 0.06379679590463638,
      "learning_rate": 4.0039999999999996e-07,
      "logits/chosen": -2.895195960998535,
      "logits/rejected": -2.3859775066375732,
      "logps/chosen": -98.36901092529297,
      "logps/rejected": -149.27890014648438,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.015771090984344482,
      "rewards/margins": 8.486207008361816,
      "rewards/rejected": -8.501977920532227,
      "step": 4498
    },
    {
      "epoch": 1.7995999999999999,
      "grad_norm": 1.9631613492965698,
      "learning_rate": 4.0026666666666665e-07,
      "logits/chosen": -2.946518898010254,
      "logits/rejected": -2.6609649658203125,
      "logps/chosen": -132.79498291015625,
      "logps/rejected": -107.29774475097656,
      "loss": 0.0096,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1505585014820099,
      "rewards/margins": 6.5261006355285645,
      "rewards/rejected": -6.375542163848877,
      "step": 4499
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.1125737801194191,
      "learning_rate": 4.0013333333333334e-07,
      "logits/chosen": -2.9135115146636963,
      "logits/rejected": -2.306216239929199,
      "logps/chosen": -112.89058685302734,
      "logps/rejected": -153.1859130859375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.29889681935310364,
      "rewards/margins": 9.723668098449707,
      "rewards/rejected": -9.424771308898926,
      "step": 4500
    },
    {
      "epoch": 1.8004,
      "grad_norm": 0.11476115137338638,
      "learning_rate": 4e-07,
      "logits/chosen": -3.1726789474487305,
      "logits/rejected": -2.782179355621338,
      "logps/chosen": -45.16790771484375,
      "logps/rejected": -133.69830322265625,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08871765434741974,
      "rewards/margins": 7.261656284332275,
      "rewards/rejected": -7.350374221801758,
      "step": 4501
    },
    {
      "epoch": 1.8008,
      "grad_norm": 0.48456496000289917,
      "learning_rate": 3.998666666666666e-07,
      "logits/chosen": -3.0190048217773438,
      "logits/rejected": -2.6230835914611816,
      "logps/chosen": -78.67840576171875,
      "logps/rejected": -160.6199188232422,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.38606205582618713,
      "rewards/margins": 8.791874885559082,
      "rewards/rejected": -9.177936553955078,
      "step": 4502
    },
    {
      "epoch": 1.8012000000000001,
      "grad_norm": 0.7698144912719727,
      "learning_rate": 3.997333333333333e-07,
      "logits/chosen": -2.829434394836426,
      "logits/rejected": -2.225165843963623,
      "logps/chosen": -100.60847473144531,
      "logps/rejected": -141.68382263183594,
      "loss": 0.0049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0002754330635070801,
      "rewards/margins": 8.53510856628418,
      "rewards/rejected": -8.535384178161621,
      "step": 4503
    },
    {
      "epoch": 1.8016,
      "grad_norm": 0.021009931340813637,
      "learning_rate": 3.996e-07,
      "logits/chosen": -3.1810262203216553,
      "logits/rejected": -2.6714329719543457,
      "logps/chosen": -67.09512329101562,
      "logps/rejected": -143.38648986816406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.024578869342803955,
      "rewards/margins": 9.37497329711914,
      "rewards/rejected": -9.399553298950195,
      "step": 4504
    },
    {
      "epoch": 1.802,
      "grad_norm": 0.19581031799316406,
      "learning_rate": 3.994666666666667e-07,
      "logits/chosen": -2.803255558013916,
      "logits/rejected": -2.4827775955200195,
      "logps/chosen": -71.8805160522461,
      "logps/rejected": -115.52357482910156,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2605861723423004,
      "rewards/margins": 7.2355852127075195,
      "rewards/rejected": -6.974998950958252,
      "step": 4505
    },
    {
      "epoch": 1.8024,
      "grad_norm": 0.44100379943847656,
      "learning_rate": 3.993333333333333e-07,
      "logits/chosen": -2.7194340229034424,
      "logits/rejected": -2.2157130241394043,
      "logps/chosen": -181.14451599121094,
      "logps/rejected": -196.3194580078125,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.6173043251037598,
      "rewards/margins": 9.224530220031738,
      "rewards/rejected": -11.841835021972656,
      "step": 4506
    },
    {
      "epoch": 1.8028,
      "grad_norm": 14.679368019104004,
      "learning_rate": 3.992e-07,
      "logits/chosen": -2.6215949058532715,
      "logits/rejected": -2.559072256088257,
      "logps/chosen": -128.85525512695312,
      "logps/rejected": -111.01411437988281,
      "loss": 0.0775,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8844704031944275,
      "rewards/margins": 5.162856578826904,
      "rewards/rejected": -6.047327041625977,
      "step": 4507
    },
    {
      "epoch": 1.8032,
      "grad_norm": 12.316129684448242,
      "learning_rate": 3.9906666666666667e-07,
      "logits/chosen": -2.8854851722717285,
      "logits/rejected": -2.665515422821045,
      "logps/chosen": -77.0880126953125,
      "logps/rejected": -104.04905700683594,
      "loss": 0.0845,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5945980548858643,
      "rewards/margins": 5.115311145782471,
      "rewards/rejected": -6.709909439086914,
      "step": 4508
    },
    {
      "epoch": 1.8035999999999999,
      "grad_norm": 0.04792894050478935,
      "learning_rate": 3.989333333333333e-07,
      "logits/chosen": -2.7646484375,
      "logits/rejected": -2.5120551586151123,
      "logps/chosen": -194.745361328125,
      "logps/rejected": -195.20265197753906,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.680382251739502,
      "rewards/margins": 8.70727252960205,
      "rewards/rejected": -11.387655258178711,
      "step": 4509
    },
    {
      "epoch": 1.804,
      "grad_norm": 0.4743114709854126,
      "learning_rate": 3.9879999999999994e-07,
      "logits/chosen": -2.8777389526367188,
      "logits/rejected": -2.524976968765259,
      "logps/chosen": -86.83979797363281,
      "logps/rejected": -147.97596740722656,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.999560594558716,
      "rewards/margins": 6.276021480560303,
      "rewards/rejected": -9.275582313537598,
      "step": 4510
    },
    {
      "epoch": 1.8044,
      "grad_norm": 0.01569190062582493,
      "learning_rate": 3.9866666666666664e-07,
      "logits/chosen": -2.591878890991211,
      "logits/rejected": -2.408177614212036,
      "logps/chosen": -85.92536163330078,
      "logps/rejected": -219.88368225097656,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0434341430664062,
      "rewards/margins": 11.019360542297363,
      "rewards/rejected": -9.975926399230957,
      "step": 4511
    },
    {
      "epoch": 1.8048,
      "grad_norm": 0.054850101470947266,
      "learning_rate": 3.9853333333333333e-07,
      "logits/chosen": -2.786785125732422,
      "logits/rejected": -2.300961494445801,
      "logps/chosen": -75.88030242919922,
      "logps/rejected": -176.1234130859375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3670669794082642,
      "rewards/margins": 9.14118480682373,
      "rewards/rejected": -7.774117469787598,
      "step": 4512
    },
    {
      "epoch": 1.8052000000000001,
      "grad_norm": 0.03568417206406593,
      "learning_rate": 3.9839999999999997e-07,
      "logits/chosen": -2.613997220993042,
      "logits/rejected": -2.0273044109344482,
      "logps/chosen": -121.24032592773438,
      "logps/rejected": -172.9509735107422,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5806965827941895,
      "rewards/margins": 8.967899322509766,
      "rewards/rejected": -10.548595428466797,
      "step": 4513
    },
    {
      "epoch": 1.8056,
      "grad_norm": 0.45886027812957764,
      "learning_rate": 3.9826666666666666e-07,
      "logits/chosen": -2.5340399742126465,
      "logits/rejected": -2.2293131351470947,
      "logps/chosen": -86.85092163085938,
      "logps/rejected": -227.73208618164062,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8677905797958374,
      "rewards/margins": 10.385960578918457,
      "rewards/rejected": -11.253751754760742,
      "step": 4514
    },
    {
      "epoch": 1.806,
      "grad_norm": 1.1869025230407715,
      "learning_rate": 3.981333333333333e-07,
      "logits/chosen": -2.681185483932495,
      "logits/rejected": -2.4925999641418457,
      "logps/chosen": -202.3131866455078,
      "logps/rejected": -163.74856567382812,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.0289697647094727,
      "rewards/margins": 8.637468338012695,
      "rewards/rejected": -11.666437149047852,
      "step": 4515
    },
    {
      "epoch": 1.8064,
      "grad_norm": 0.14849379658699036,
      "learning_rate": 3.98e-07,
      "logits/chosen": -2.6782963275909424,
      "logits/rejected": -1.8338263034820557,
      "logps/chosen": -92.90824890136719,
      "logps/rejected": -139.26412963867188,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.11186981201171875,
      "rewards/margins": 8.764971733093262,
      "rewards/rejected": -8.876842498779297,
      "step": 4516
    },
    {
      "epoch": 1.8068,
      "grad_norm": 8.426716804504395,
      "learning_rate": 3.9786666666666663e-07,
      "logits/chosen": -2.831681251525879,
      "logits/rejected": -2.792222023010254,
      "logps/chosen": -112.10877227783203,
      "logps/rejected": -85.23424530029297,
      "loss": 0.0456,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.2567920684814453,
      "rewards/margins": 3.153614044189453,
      "rewards/rejected": -5.410406112670898,
      "step": 4517
    },
    {
      "epoch": 1.8072,
      "grad_norm": 0.05272146686911583,
      "learning_rate": 3.977333333333333e-07,
      "logits/chosen": -2.457288980484009,
      "logits/rejected": -1.8774977922439575,
      "logps/chosen": -242.5892333984375,
      "logps/rejected": -220.5048828125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.215947151184082,
      "rewards/margins": 8.239191055297852,
      "rewards/rejected": -11.45513916015625,
      "step": 4518
    },
    {
      "epoch": 1.8075999999999999,
      "grad_norm": 1.9469120502471924,
      "learning_rate": 3.976e-07,
      "logits/chosen": -2.770771026611328,
      "logits/rejected": -2.284332752227783,
      "logps/chosen": -137.67335510253906,
      "logps/rejected": -157.33377075195312,
      "loss": 0.0122,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6907989978790283,
      "rewards/margins": 8.57438850402832,
      "rewards/rejected": -9.26518726348877,
      "step": 4519
    },
    {
      "epoch": 1.808,
      "grad_norm": 0.0004977519274689257,
      "learning_rate": 3.9746666666666665e-07,
      "logits/chosen": -2.586608648300171,
      "logits/rejected": -2.0586466789245605,
      "logps/chosen": -85.85385131835938,
      "logps/rejected": -174.40594482421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.132556438446045,
      "rewards/margins": 13.139790534973145,
      "rewards/rejected": -12.007234573364258,
      "step": 4520
    },
    {
      "epoch": 1.8084,
      "grad_norm": 0.7694226503372192,
      "learning_rate": 3.973333333333333e-07,
      "logits/chosen": -2.7974343299865723,
      "logits/rejected": -2.8498783111572266,
      "logps/chosen": -103.8948974609375,
      "logps/rejected": -111.20140075683594,
      "loss": 0.0061,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.207251787185669,
      "rewards/margins": 5.184671401977539,
      "rewards/rejected": -7.391922950744629,
      "step": 4521
    },
    {
      "epoch": 1.8088,
      "grad_norm": 0.03819968178868294,
      "learning_rate": 3.972e-07,
      "logits/chosen": -2.8960070610046387,
      "logits/rejected": -2.3126015663146973,
      "logps/chosen": -105.6240234375,
      "logps/rejected": -223.2471923828125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.29841727018356323,
      "rewards/margins": 11.278694152832031,
      "rewards/rejected": -11.57711124420166,
      "step": 4522
    },
    {
      "epoch": 1.8092000000000001,
      "grad_norm": 0.8951252698898315,
      "learning_rate": 3.970666666666667e-07,
      "logits/chosen": -2.959813117980957,
      "logits/rejected": -2.6245276927948,
      "logps/chosen": -45.665016174316406,
      "logps/rejected": -113.00578308105469,
      "loss": 0.0051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.48518505692481995,
      "rewards/margins": 7.055698394775391,
      "rewards/rejected": -6.5705132484436035,
      "step": 4523
    },
    {
      "epoch": 1.8096,
      "grad_norm": 0.07239775359630585,
      "learning_rate": 3.9693333333333337e-07,
      "logits/chosen": -2.9221861362457275,
      "logits/rejected": -2.1638829708099365,
      "logps/chosen": -99.19363403320312,
      "logps/rejected": -187.34136962890625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6217349767684937,
      "rewards/margins": 11.486906051635742,
      "rewards/rejected": -12.108641624450684,
      "step": 4524
    },
    {
      "epoch": 1.81,
      "grad_norm": 49.21861267089844,
      "learning_rate": 3.9679999999999995e-07,
      "logits/chosen": -2.3676533699035645,
      "logits/rejected": -2.3293027877807617,
      "logps/chosen": -170.96920776367188,
      "logps/rejected": -143.8945770263672,
      "loss": 0.2412,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.3480350971221924,
      "rewards/margins": 3.230869770050049,
      "rewards/rejected": -6.57890510559082,
      "step": 4525
    },
    {
      "epoch": 1.8104,
      "grad_norm": 0.0006002442678436637,
      "learning_rate": 3.9666666666666665e-07,
      "logits/chosen": -2.51560378074646,
      "logits/rejected": -1.8837357759475708,
      "logps/chosen": -80.41749572753906,
      "logps/rejected": -174.2738037109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2655129432678223,
      "rewards/margins": 13.277521133422852,
      "rewards/rejected": -12.012008666992188,
      "step": 4526
    },
    {
      "epoch": 1.8108,
      "grad_norm": 0.006447929423302412,
      "learning_rate": 3.9653333333333334e-07,
      "logits/chosen": -2.8231592178344727,
      "logits/rejected": -2.0074920654296875,
      "logps/chosen": -47.4021110534668,
      "logps/rejected": -163.31959533691406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.793872594833374,
      "rewards/margins": 13.681920051574707,
      "rewards/rejected": -10.888047218322754,
      "step": 4527
    },
    {
      "epoch": 1.8112,
      "grad_norm": 2.383100748062134,
      "learning_rate": 3.964e-07,
      "logits/chosen": -2.3936331272125244,
      "logits/rejected": -1.9631342887878418,
      "logps/chosen": -197.52664184570312,
      "logps/rejected": -143.2111053466797,
      "loss": 0.0084,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.4777753353118896,
      "rewards/margins": 5.942687034606934,
      "rewards/rejected": -8.420462608337402,
      "step": 4528
    },
    {
      "epoch": 1.8115999999999999,
      "grad_norm": 0.02340344712138176,
      "learning_rate": 3.962666666666666e-07,
      "logits/chosen": -2.9279656410217285,
      "logits/rejected": -2.3161890506744385,
      "logps/chosen": -105.11846160888672,
      "logps/rejected": -161.75390625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4866009950637817,
      "rewards/margins": 9.881647109985352,
      "rewards/rejected": -11.368247985839844,
      "step": 4529
    },
    {
      "epoch": 1.812,
      "grad_norm": 0.021343475207686424,
      "learning_rate": 3.961333333333333e-07,
      "logits/chosen": -2.7317702770233154,
      "logits/rejected": -2.4053022861480713,
      "logps/chosen": -121.11952209472656,
      "logps/rejected": -154.15228271484375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2749301791191101,
      "rewards/margins": 9.430877685546875,
      "rewards/rejected": -9.70580768585205,
      "step": 4530
    },
    {
      "epoch": 1.8124,
      "grad_norm": 0.07282791286706924,
      "learning_rate": 3.96e-07,
      "logits/chosen": -2.6975557804107666,
      "logits/rejected": -2.536255359649658,
      "logps/chosen": -112.60916137695312,
      "logps/rejected": -167.88763427734375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.8017489910125732,
      "rewards/margins": 8.623032569885254,
      "rewards/rejected": -11.424781799316406,
      "step": 4531
    },
    {
      "epoch": 1.8128,
      "grad_norm": 0.019776439294219017,
      "learning_rate": 3.9586666666666664e-07,
      "logits/chosen": -2.530694007873535,
      "logits/rejected": -2.0171356201171875,
      "logps/chosen": -124.13449096679688,
      "logps/rejected": -151.87240600585938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.25839537382125854,
      "rewards/margins": 9.42932415008545,
      "rewards/rejected": -9.687719345092773,
      "step": 4532
    },
    {
      "epoch": 1.8132000000000001,
      "grad_norm": 0.09320563822984695,
      "learning_rate": 3.9573333333333333e-07,
      "logits/chosen": -2.472203254699707,
      "logits/rejected": -2.2247400283813477,
      "logps/chosen": -102.08094787597656,
      "logps/rejected": -181.65432739257812,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5061883926391602,
      "rewards/margins": 10.08549976348877,
      "rewards/rejected": -11.59168815612793,
      "step": 4533
    },
    {
      "epoch": 1.8136,
      "grad_norm": 0.016292350366711617,
      "learning_rate": 3.9559999999999997e-07,
      "logits/chosen": -2.952892780303955,
      "logits/rejected": -2.4311609268188477,
      "logps/chosen": -73.08482360839844,
      "logps/rejected": -162.41358947753906,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45131227374076843,
      "rewards/margins": 11.404431343078613,
      "rewards/rejected": -10.953119277954102,
      "step": 4534
    },
    {
      "epoch": 1.814,
      "grad_norm": 8.77130514709279e-05,
      "learning_rate": 3.9546666666666666e-07,
      "logits/chosen": -2.8307342529296875,
      "logits/rejected": -2.304456949234009,
      "logps/chosen": -62.952476501464844,
      "logps/rejected": -241.53944396972656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0016453266143799,
      "rewards/margins": 16.88159942626953,
      "rewards/rejected": -15.879955291748047,
      "step": 4535
    },
    {
      "epoch": 1.8144,
      "grad_norm": 0.17555846273899078,
      "learning_rate": 3.953333333333333e-07,
      "logits/chosen": -3.1463255882263184,
      "logits/rejected": -2.62170147895813,
      "logps/chosen": -53.557228088378906,
      "logps/rejected": -146.90243530273438,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0028585195541382,
      "rewards/margins": 9.935806274414062,
      "rewards/rejected": -8.932947158813477,
      "step": 4536
    },
    {
      "epoch": 1.8148,
      "grad_norm": 0.0018450889037922025,
      "learning_rate": 3.952e-07,
      "logits/chosen": -2.648803234100342,
      "logits/rejected": -1.8012499809265137,
      "logps/chosen": -107.52208709716797,
      "logps/rejected": -212.19480895996094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45282381772994995,
      "rewards/margins": 13.29694938659668,
      "rewards/rejected": -12.844125747680664,
      "step": 4537
    },
    {
      "epoch": 1.8152,
      "grad_norm": 0.11215919256210327,
      "learning_rate": 3.950666666666667e-07,
      "logits/chosen": -2.89711594581604,
      "logits/rejected": -2.604418992996216,
      "logps/chosen": -133.702392578125,
      "logps/rejected": -134.2181396484375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0664310455322266,
      "rewards/margins": 8.291046142578125,
      "rewards/rejected": -9.357477188110352,
      "step": 4538
    },
    {
      "epoch": 1.8155999999999999,
      "grad_norm": 0.058343593031167984,
      "learning_rate": 3.949333333333333e-07,
      "logits/chosen": -2.831292152404785,
      "logits/rejected": -2.55574893951416,
      "logps/chosen": -53.548583984375,
      "logps/rejected": -93.19557189941406,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8422694206237793,
      "rewards/margins": 8.394286155700684,
      "rewards/rejected": -6.552016258239746,
      "step": 4539
    },
    {
      "epoch": 1.8159999999999998,
      "grad_norm": 0.06906218081712723,
      "learning_rate": 3.9479999999999996e-07,
      "logits/chosen": -2.9278242588043213,
      "logits/rejected": -2.2978053092956543,
      "logps/chosen": -83.2391586303711,
      "logps/rejected": -134.77078247070312,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5276527404785156,
      "rewards/margins": 8.540570259094238,
      "rewards/rejected": -9.068222999572754,
      "step": 4540
    },
    {
      "epoch": 1.8164,
      "grad_norm": 0.8881392478942871,
      "learning_rate": 3.9466666666666665e-07,
      "logits/chosen": -2.5590786933898926,
      "logits/rejected": -2.4856457710266113,
      "logps/chosen": -103.0696029663086,
      "logps/rejected": -132.2816925048828,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45246970653533936,
      "rewards/margins": 8.911022186279297,
      "rewards/rejected": -8.458552360534668,
      "step": 4541
    },
    {
      "epoch": 1.8168,
      "grad_norm": 215.8030242919922,
      "learning_rate": 3.9453333333333335e-07,
      "logits/chosen": -2.4505701065063477,
      "logits/rejected": -1.8812658786773682,
      "logps/chosen": -236.18109130859375,
      "logps/rejected": -175.7625274658203,
      "loss": 1.9078,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -9.437982559204102,
      "rewards/margins": 1.501065731048584,
      "rewards/rejected": -10.939047813415527,
      "step": 4542
    },
    {
      "epoch": 1.8172000000000001,
      "grad_norm": 0.14172036945819855,
      "learning_rate": 3.9439999999999993e-07,
      "logits/chosen": -2.7988717555999756,
      "logits/rejected": -2.489041328430176,
      "logps/chosen": -107.89859008789062,
      "logps/rejected": -175.15347290039062,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9289089441299438,
      "rewards/margins": 9.97408390045166,
      "rewards/rejected": -10.902992248535156,
      "step": 4543
    },
    {
      "epoch": 1.8176,
      "grad_norm": 2.303701639175415,
      "learning_rate": 3.942666666666666e-07,
      "logits/chosen": -2.3723771572113037,
      "logits/rejected": -1.9191999435424805,
      "logps/chosen": -119.18309783935547,
      "logps/rejected": -110.94525146484375,
      "loss": 0.0138,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04643899202346802,
      "rewards/margins": 7.137218475341797,
      "rewards/rejected": -7.0907793045043945,
      "step": 4544
    },
    {
      "epoch": 1.818,
      "grad_norm": 3.6415507793426514,
      "learning_rate": 3.941333333333333e-07,
      "logits/chosen": -2.5925769805908203,
      "logits/rejected": -2.2543067932128906,
      "logps/chosen": -143.53680419921875,
      "logps/rejected": -121.22428894042969,
      "loss": 0.0192,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4141327142715454,
      "rewards/margins": 8.758864402770996,
      "rewards/rejected": -8.344732284545898,
      "step": 4545
    },
    {
      "epoch": 1.8184,
      "grad_norm": 2.009392499923706,
      "learning_rate": 3.94e-07,
      "logits/chosen": -3.3561692237854004,
      "logits/rejected": -3.2146048545837402,
      "logps/chosen": -58.04913330078125,
      "logps/rejected": -112.29135131835938,
      "loss": 0.0122,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.6092240810394287,
      "rewards/margins": 4.556764125823975,
      "rewards/rejected": -7.165987968444824,
      "step": 4546
    },
    {
      "epoch": 1.8188,
      "grad_norm": 0.009961890056729317,
      "learning_rate": 3.9386666666666665e-07,
      "logits/chosen": -2.8364453315734863,
      "logits/rejected": -2.554893970489502,
      "logps/chosen": -111.80601501464844,
      "logps/rejected": -156.25042724609375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15029066801071167,
      "rewards/margins": 10.760501861572266,
      "rewards/rejected": -10.610212326049805,
      "step": 4547
    },
    {
      "epoch": 1.8192,
      "grad_norm": 0.03415314853191376,
      "learning_rate": 3.937333333333333e-07,
      "logits/chosen": -2.785080671310425,
      "logits/rejected": -2.2381701469421387,
      "logps/chosen": -80.43560028076172,
      "logps/rejected": -175.3951416015625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0021001100540161,
      "rewards/margins": 12.241254806518555,
      "rewards/rejected": -11.239154815673828,
      "step": 4548
    },
    {
      "epoch": 1.8195999999999999,
      "grad_norm": 91.98957824707031,
      "learning_rate": 3.936e-07,
      "logits/chosen": -2.580254554748535,
      "logits/rejected": -2.3455278873443604,
      "logps/chosen": -221.54518127441406,
      "logps/rejected": -159.22389221191406,
      "loss": 0.3771,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -2.4765238761901855,
      "rewards/margins": 6.797662734985352,
      "rewards/rejected": -9.274187088012695,
      "step": 4549
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 0.7254754900932312,
      "learning_rate": 3.9346666666666667e-07,
      "logits/chosen": -2.5681381225585938,
      "logits/rejected": -2.3145592212677,
      "logps/chosen": -83.9443588256836,
      "logps/rejected": -135.64649963378906,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.47306403517723083,
      "rewards/margins": 7.644997596740723,
      "rewards/rejected": -7.171933650970459,
      "step": 4550
    },
    {
      "epoch": 1.8204,
      "grad_norm": 0.4873189628124237,
      "learning_rate": 3.933333333333333e-07,
      "logits/chosen": -2.738760471343994,
      "logits/rejected": -2.111459732055664,
      "logps/chosen": -110.80345916748047,
      "logps/rejected": -141.0941162109375,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.21468737721443176,
      "rewards/margins": 7.644021987915039,
      "rewards/rejected": -7.858709335327148,
      "step": 4551
    },
    {
      "epoch": 1.8208,
      "grad_norm": 1.3493437767028809,
      "learning_rate": 3.932e-07,
      "logits/chosen": -3.043158531188965,
      "logits/rejected": -3.065206527709961,
      "logps/chosen": -68.73236083984375,
      "logps/rejected": -89.84860229492188,
      "loss": 0.0084,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.059785276651382446,
      "rewards/margins": 5.678576469421387,
      "rewards/rejected": -5.7383623123168945,
      "step": 4552
    },
    {
      "epoch": 1.8212000000000002,
      "grad_norm": 0.0026410629507154226,
      "learning_rate": 3.9306666666666664e-07,
      "logits/chosen": -2.7001705169677734,
      "logits/rejected": -2.1671414375305176,
      "logps/chosen": -127.28206634521484,
      "logps/rejected": -196.7000274658203,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.46378859877586365,
      "rewards/margins": 11.515539169311523,
      "rewards/rejected": -11.051750183105469,
      "step": 4553
    },
    {
      "epoch": 1.8216,
      "grad_norm": 7.251346111297607,
      "learning_rate": 3.9293333333333333e-07,
      "logits/chosen": -3.0590038299560547,
      "logits/rejected": -2.5900352001190186,
      "logps/chosen": -70.9420166015625,
      "logps/rejected": -134.95614624023438,
      "loss": 0.0498,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8321835994720459,
      "rewards/margins": 7.498514175415039,
      "rewards/rejected": -8.330698013305664,
      "step": 4554
    },
    {
      "epoch": 1.822,
      "grad_norm": 0.0049950904212892056,
      "learning_rate": 3.9279999999999997e-07,
      "logits/chosen": -2.6859467029571533,
      "logits/rejected": -1.9129385948181152,
      "logps/chosen": -99.556884765625,
      "logps/rejected": -171.25921630859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5401630401611328,
      "rewards/margins": 11.28555679321289,
      "rewards/rejected": -10.745393753051758,
      "step": 4555
    },
    {
      "epoch": 1.8224,
      "grad_norm": 0.001133520039729774,
      "learning_rate": 3.9266666666666666e-07,
      "logits/chosen": -2.4885802268981934,
      "logits/rejected": -1.4398539066314697,
      "logps/chosen": -79.0599365234375,
      "logps/rejected": -198.9959716796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.787061870098114,
      "rewards/margins": 12.742866516113281,
      "rewards/rejected": -11.955804824829102,
      "step": 4556
    },
    {
      "epoch": 1.8228,
      "grad_norm": 0.0018326580757275224,
      "learning_rate": 3.925333333333333e-07,
      "logits/chosen": -3.002476215362549,
      "logits/rejected": -2.6398346424102783,
      "logps/chosen": -51.63948059082031,
      "logps/rejected": -201.51229858398438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5601996183395386,
      "rewards/margins": 14.797306060791016,
      "rewards/rejected": -13.237106323242188,
      "step": 4557
    },
    {
      "epoch": 1.8232,
      "grad_norm": 0.05560355633497238,
      "learning_rate": 3.924e-07,
      "logits/chosen": -2.9468400478363037,
      "logits/rejected": -2.3476734161376953,
      "logps/chosen": -78.02871704101562,
      "logps/rejected": -155.1826934814453,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5366228222846985,
      "rewards/margins": 8.879332542419434,
      "rewards/rejected": -9.415955543518066,
      "step": 4558
    },
    {
      "epoch": 1.8235999999999999,
      "grad_norm": 0.0046743061393499374,
      "learning_rate": 3.9226666666666663e-07,
      "logits/chosen": -2.78145694732666,
      "logits/rejected": -1.97450590133667,
      "logps/chosen": -84.31462860107422,
      "logps/rejected": -189.698486328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3509079217910767,
      "rewards/margins": 14.055072784423828,
      "rewards/rejected": -12.704164505004883,
      "step": 4559
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 0.6042490601539612,
      "learning_rate": 3.921333333333333e-07,
      "logits/chosen": -2.550023078918457,
      "logits/rejected": -2.16982102394104,
      "logps/chosen": -172.07659912109375,
      "logps/rejected": -132.53375244140625,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15578612685203552,
      "rewards/margins": 7.618539810180664,
      "rewards/rejected": -7.4627532958984375,
      "step": 4560
    },
    {
      "epoch": 1.8244,
      "grad_norm": 3.9945366382598877,
      "learning_rate": 3.92e-07,
      "logits/chosen": -3.2447292804718018,
      "logits/rejected": -3.0421342849731445,
      "logps/chosen": -73.08036804199219,
      "logps/rejected": -94.09452819824219,
      "loss": 0.0339,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7294756174087524,
      "rewards/margins": 4.962213516235352,
      "rewards/rejected": -5.691689491271973,
      "step": 4561
    },
    {
      "epoch": 1.8248,
      "grad_norm": 0.39905452728271484,
      "learning_rate": 3.918666666666666e-07,
      "logits/chosen": -2.8208858966827393,
      "logits/rejected": -2.506013870239258,
      "logps/chosen": -129.1302490234375,
      "logps/rejected": -137.4212646484375,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.336535692214966,
      "rewards/margins": 6.108223915100098,
      "rewards/rejected": -8.444759368896484,
      "step": 4562
    },
    {
      "epoch": 1.8252000000000002,
      "grad_norm": 0.24509145319461823,
      "learning_rate": 3.917333333333333e-07,
      "logits/chosen": -2.6318163871765137,
      "logits/rejected": -2.1139564514160156,
      "logps/chosen": -137.1973114013672,
      "logps/rejected": -139.7559356689453,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.37546801567077637,
      "rewards/margins": 8.220329284667969,
      "rewards/rejected": -8.595796585083008,
      "step": 4563
    },
    {
      "epoch": 1.8256000000000001,
      "grad_norm": 0.016775723546743393,
      "learning_rate": 3.916e-07,
      "logits/chosen": -3.0381383895874023,
      "logits/rejected": -2.6058130264282227,
      "logps/chosen": -85.69404602050781,
      "logps/rejected": -154.15982055664062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.743229329586029,
      "rewards/margins": 11.119766235351562,
      "rewards/rejected": -10.376537322998047,
      "step": 4564
    },
    {
      "epoch": 1.826,
      "grad_norm": 0.04823987931013107,
      "learning_rate": 3.914666666666667e-07,
      "logits/chosen": -2.874882698059082,
      "logits/rejected": -2.8769726753234863,
      "logps/chosen": -116.22840881347656,
      "logps/rejected": -108.61285400390625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5638908743858337,
      "rewards/margins": 8.190298080444336,
      "rewards/rejected": -7.626407623291016,
      "step": 4565
    },
    {
      "epoch": 1.8264,
      "grad_norm": 0.7633172273635864,
      "learning_rate": 3.913333333333333e-07,
      "logits/chosen": -3.0939595699310303,
      "logits/rejected": -2.8554699420928955,
      "logps/chosen": -98.16563415527344,
      "logps/rejected": -134.95208740234375,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.029316328465938568,
      "rewards/margins": 9.198314666748047,
      "rewards/rejected": -9.168997764587402,
      "step": 4566
    },
    {
      "epoch": 1.8268,
      "grad_norm": 0.0048274570144712925,
      "learning_rate": 3.9119999999999996e-07,
      "logits/chosen": -2.488568067550659,
      "logits/rejected": -1.8534197807312012,
      "logps/chosen": -108.34925842285156,
      "logps/rejected": -216.42413330078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1845347881317139,
      "rewards/margins": 14.837740898132324,
      "rewards/rejected": -13.653205871582031,
      "step": 4567
    },
    {
      "epoch": 1.8272,
      "grad_norm": 0.027834303677082062,
      "learning_rate": 3.9106666666666665e-07,
      "logits/chosen": -2.7017624378204346,
      "logits/rejected": -2.3838062286376953,
      "logps/chosen": -117.10693359375,
      "logps/rejected": -151.44839477539062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7515079975128174,
      "rewards/margins": 10.14158821105957,
      "rewards/rejected": -9.390079498291016,
      "step": 4568
    },
    {
      "epoch": 1.8276,
      "grad_norm": 0.00018527133215684444,
      "learning_rate": 3.9093333333333334e-07,
      "logits/chosen": -2.759280204772949,
      "logits/rejected": -2.3080506324768066,
      "logps/chosen": -78.72845458984375,
      "logps/rejected": -242.92169189453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7941501140594482,
      "rewards/margins": 14.181812286376953,
      "rewards/rejected": -12.387661933898926,
      "step": 4569
    },
    {
      "epoch": 1.8279999999999998,
      "grad_norm": 1.4931782484054565,
      "learning_rate": 3.908e-07,
      "logits/chosen": -2.899953603744507,
      "logits/rejected": -3.0654191970825195,
      "logps/chosen": -197.1439208984375,
      "logps/rejected": -137.93392944335938,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.473285436630249,
      "rewards/margins": 5.663847923278809,
      "rewards/rejected": -9.137133598327637,
      "step": 4570
    },
    {
      "epoch": 1.8284,
      "grad_norm": 0.999565601348877,
      "learning_rate": 3.906666666666666e-07,
      "logits/chosen": -2.6482787132263184,
      "logits/rejected": -1.9931892156600952,
      "logps/chosen": -114.31804656982422,
      "logps/rejected": -121.56855773925781,
      "loss": 0.0064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0325343608856201,
      "rewards/margins": 7.1214518547058105,
      "rewards/rejected": -8.153985977172852,
      "step": 4571
    },
    {
      "epoch": 1.8288,
      "grad_norm": 0.5675477981567383,
      "learning_rate": 3.905333333333333e-07,
      "logits/chosen": -2.645174503326416,
      "logits/rejected": -1.9471276998519897,
      "logps/chosen": -116.65415954589844,
      "logps/rejected": -150.7813720703125,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1831989288330078,
      "rewards/margins": 8.441540718078613,
      "rewards/rejected": -8.258341789245605,
      "step": 4572
    },
    {
      "epoch": 1.8292000000000002,
      "grad_norm": 0.0017060512909665704,
      "learning_rate": 3.904e-07,
      "logits/chosen": -2.356320858001709,
      "logits/rejected": -1.6974575519561768,
      "logps/chosen": -135.25079345703125,
      "logps/rejected": -223.69033813476562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02734375,
      "rewards/margins": 12.171040534973145,
      "rewards/rejected": -12.143696784973145,
      "step": 4573
    },
    {
      "epoch": 1.8296000000000001,
      "grad_norm": 0.21775294840335846,
      "learning_rate": 3.9026666666666664e-07,
      "logits/chosen": -2.880497932434082,
      "logits/rejected": -2.75715708732605,
      "logps/chosen": -68.20915222167969,
      "logps/rejected": -93.21338653564453,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2886501550674438,
      "rewards/margins": 6.886058807373047,
      "rewards/rejected": -5.597408771514893,
      "step": 4574
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.008123597130179405,
      "learning_rate": 3.9013333333333333e-07,
      "logits/chosen": -2.606011390686035,
      "logits/rejected": -1.7371132373809814,
      "logps/chosen": -69.87969207763672,
      "logps/rejected": -171.16920471191406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6574810147285461,
      "rewards/margins": 10.694284439086914,
      "rewards/rejected": -10.03680419921875,
      "step": 4575
    },
    {
      "epoch": 1.8304,
      "grad_norm": 0.017274029552936554,
      "learning_rate": 3.8999999999999997e-07,
      "logits/chosen": -2.394702911376953,
      "logits/rejected": -1.338935136795044,
      "logps/chosen": -136.20465087890625,
      "logps/rejected": -199.2078399658203,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.31003040075302124,
      "rewards/margins": 10.861760139465332,
      "rewards/rejected": -11.171791076660156,
      "step": 4576
    },
    {
      "epoch": 1.8308,
      "grad_norm": 0.011813243851065636,
      "learning_rate": 3.898666666666666e-07,
      "logits/chosen": -2.33402419090271,
      "logits/rejected": -1.4574376344680786,
      "logps/chosen": -138.0051727294922,
      "logps/rejected": -207.3929443359375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5405548214912415,
      "rewards/margins": 11.210233688354492,
      "rewards/rejected": -10.669678688049316,
      "step": 4577
    },
    {
      "epoch": 1.8312,
      "grad_norm": 0.020127072930336,
      "learning_rate": 3.897333333333333e-07,
      "logits/chosen": -2.616720199584961,
      "logits/rejected": -1.8911933898925781,
      "logps/chosen": -174.01071166992188,
      "logps/rejected": -186.89019775390625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21937942504882812,
      "rewards/margins": 11.628035545349121,
      "rewards/rejected": -11.408656120300293,
      "step": 4578
    },
    {
      "epoch": 1.8316,
      "grad_norm": 0.0008293812861666083,
      "learning_rate": 3.896e-07,
      "logits/chosen": -2.8863420486450195,
      "logits/rejected": -2.320957660675049,
      "logps/chosen": -114.68588256835938,
      "logps/rejected": -212.4897003173828,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7612667679786682,
      "rewards/margins": 12.714544296264648,
      "rewards/rejected": -13.475811004638672,
      "step": 4579
    },
    {
      "epoch": 1.8319999999999999,
      "grad_norm": 0.004969966597855091,
      "learning_rate": 3.894666666666667e-07,
      "logits/chosen": -2.7555043697357178,
      "logits/rejected": -1.881734848022461,
      "logps/chosen": -117.5642318725586,
      "logps/rejected": -215.9254608154297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9931659698486328,
      "rewards/margins": 14.324379920959473,
      "rewards/rejected": -13.33121395111084,
      "step": 4580
    },
    {
      "epoch": 1.8324,
      "grad_norm": 13.440582275390625,
      "learning_rate": 3.8933333333333327e-07,
      "logits/chosen": -2.485992193222046,
      "logits/rejected": -2.35733962059021,
      "logps/chosen": -69.74153137207031,
      "logps/rejected": -138.16912841796875,
      "loss": 0.0831,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6470010280609131,
      "rewards/margins": 5.801537036895752,
      "rewards/rejected": -6.448537826538086,
      "step": 4581
    },
    {
      "epoch": 1.8328,
      "grad_norm": 0.005409850738942623,
      "learning_rate": 3.8919999999999996e-07,
      "logits/chosen": -2.6936686038970947,
      "logits/rejected": -2.3327536582946777,
      "logps/chosen": -129.71005249023438,
      "logps/rejected": -186.42416381835938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8220984935760498,
      "rewards/margins": 12.578179359436035,
      "rewards/rejected": -11.756080627441406,
      "step": 4582
    },
    {
      "epoch": 1.8332000000000002,
      "grad_norm": 1.0574203729629517,
      "learning_rate": 3.8906666666666666e-07,
      "logits/chosen": -2.7519617080688477,
      "logits/rejected": -2.785407304763794,
      "logps/chosen": -127.29226684570312,
      "logps/rejected": -127.17623138427734,
      "loss": 0.0056,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.159468173980713,
      "rewards/margins": 6.205758094787598,
      "rewards/rejected": -7.365225791931152,
      "step": 4583
    },
    {
      "epoch": 1.8336000000000001,
      "grad_norm": 0.007642735261470079,
      "learning_rate": 3.8893333333333335e-07,
      "logits/chosen": -2.4752304553985596,
      "logits/rejected": -1.5572710037231445,
      "logps/chosen": -105.5119857788086,
      "logps/rejected": -179.66688537597656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7761654257774353,
      "rewards/margins": 11.524445533752441,
      "rewards/rejected": -10.748279571533203,
      "step": 4584
    },
    {
      "epoch": 1.834,
      "grad_norm": 1.5391118722618558e-05,
      "learning_rate": 3.888e-07,
      "logits/chosen": -2.596431255340576,
      "logits/rejected": -1.9581329822540283,
      "logps/chosen": -119.67534637451172,
      "logps/rejected": -289.335693359375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0388206243515015,
      "rewards/margins": 19.21051025390625,
      "rewards/rejected": -18.171688079833984,
      "step": 4585
    },
    {
      "epoch": 1.8344,
      "grad_norm": 1.3244885206222534,
      "learning_rate": 3.8866666666666663e-07,
      "logits/chosen": -2.3188319206237793,
      "logits/rejected": -1.514837384223938,
      "logps/chosen": -231.96676635742188,
      "logps/rejected": -170.26565551757812,
      "loss": 0.0056,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6557987928390503,
      "rewards/margins": 8.293349266052246,
      "rewards/rejected": -9.949148178100586,
      "step": 4586
    },
    {
      "epoch": 1.8348,
      "grad_norm": 0.005100124049931765,
      "learning_rate": 3.885333333333333e-07,
      "logits/chosen": -2.9850869178771973,
      "logits/rejected": -2.4262516498565674,
      "logps/chosen": -56.91712951660156,
      "logps/rejected": -150.9618377685547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0750770568847656,
      "rewards/margins": 12.033435821533203,
      "rewards/rejected": -9.958358764648438,
      "step": 4587
    },
    {
      "epoch": 1.8352,
      "grad_norm": 0.2003643959760666,
      "learning_rate": 3.884e-07,
      "logits/chosen": -2.80203914642334,
      "logits/rejected": -2.3017730712890625,
      "logps/chosen": -75.287841796875,
      "logps/rejected": -132.29281616210938,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1065109968185425,
      "rewards/margins": 9.962137222290039,
      "rewards/rejected": -8.855627059936523,
      "step": 4588
    },
    {
      "epoch": 1.8356,
      "grad_norm": 0.03487067297101021,
      "learning_rate": 3.8826666666666665e-07,
      "logits/chosen": -2.3827695846557617,
      "logits/rejected": -2.0182342529296875,
      "logps/chosen": -101.13568115234375,
      "logps/rejected": -122.82233428955078,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1888330578804016,
      "rewards/margins": 8.398199081420898,
      "rewards/rejected": -8.587032318115234,
      "step": 4589
    },
    {
      "epoch": 1.8359999999999999,
      "grad_norm": 0.25029656291007996,
      "learning_rate": 3.881333333333333e-07,
      "logits/chosen": -2.407496452331543,
      "logits/rejected": -2.0070037841796875,
      "logps/chosen": -215.1774139404297,
      "logps/rejected": -180.16358947753906,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9596465826034546,
      "rewards/margins": 8.793848037719727,
      "rewards/rejected": -10.753495216369629,
      "step": 4590
    },
    {
      "epoch": 1.8364,
      "grad_norm": 0.1409534364938736,
      "learning_rate": 3.88e-07,
      "logits/chosen": -3.015839099884033,
      "logits/rejected": -2.7472426891326904,
      "logps/chosen": -78.55852508544922,
      "logps/rejected": -116.36860656738281,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.21439039707183838,
      "rewards/margins": 7.519824981689453,
      "rewards/rejected": -7.73421573638916,
      "step": 4591
    },
    {
      "epoch": 1.8368,
      "grad_norm": 0.06271719932556152,
      "learning_rate": 3.8786666666666667e-07,
      "logits/chosen": -3.0522279739379883,
      "logits/rejected": -2.6179986000061035,
      "logps/chosen": -60.69915008544922,
      "logps/rejected": -132.2642822265625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.559664785861969,
      "rewards/margins": 7.827231407165527,
      "rewards/rejected": -7.267566680908203,
      "step": 4592
    },
    {
      "epoch": 1.8372000000000002,
      "grad_norm": 0.06188981980085373,
      "learning_rate": 3.877333333333333e-07,
      "logits/chosen": -2.641170024871826,
      "logits/rejected": -1.938207983970642,
      "logps/chosen": -86.87541198730469,
      "logps/rejected": -139.70167541503906,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03774869441986084,
      "rewards/margins": 9.04488754272461,
      "rewards/rejected": -9.0071382522583,
      "step": 4593
    },
    {
      "epoch": 1.8376000000000001,
      "grad_norm": 0.01568165421485901,
      "learning_rate": 3.876e-07,
      "logits/chosen": -2.4910340309143066,
      "logits/rejected": -2.0866243839263916,
      "logps/chosen": -121.382568359375,
      "logps/rejected": -159.5705108642578,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.997589111328125,
      "rewards/margins": 11.734745979309082,
      "rewards/rejected": -9.737156867980957,
      "step": 4594
    },
    {
      "epoch": 1.838,
      "grad_norm": 0.022726761177182198,
      "learning_rate": 3.8746666666666664e-07,
      "logits/chosen": -2.5608339309692383,
      "logits/rejected": -2.1179592609405518,
      "logps/chosen": -114.51898956298828,
      "logps/rejected": -203.35479736328125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.499079942703247,
      "rewards/margins": 9.877981185913086,
      "rewards/rejected": -12.37706184387207,
      "step": 4595
    },
    {
      "epoch": 1.8384,
      "grad_norm": 0.017740029841661453,
      "learning_rate": 3.873333333333333e-07,
      "logits/chosen": -2.906214952468872,
      "logits/rejected": -2.5759224891662598,
      "logps/chosen": -60.584327697753906,
      "logps/rejected": -129.66839599609375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2206430435180664,
      "rewards/margins": 9.237662315368652,
      "rewards/rejected": -8.017019271850586,
      "step": 4596
    },
    {
      "epoch": 1.8388,
      "grad_norm": 0.0005281981430016458,
      "learning_rate": 3.8719999999999997e-07,
      "logits/chosen": -2.5111708641052246,
      "logits/rejected": -1.5959653854370117,
      "logps/chosen": -81.82896423339844,
      "logps/rejected": -261.4156494140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5890693664550781,
      "rewards/margins": 16.910266876220703,
      "rewards/rejected": -15.321197509765625,
      "step": 4597
    },
    {
      "epoch": 1.8392,
      "grad_norm": 0.007587301079183817,
      "learning_rate": 3.8706666666666667e-07,
      "logits/chosen": -2.8039565086364746,
      "logits/rejected": -2.0112133026123047,
      "logps/chosen": -65.71708679199219,
      "logps/rejected": -153.36964416503906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.584365725517273,
      "rewards/margins": 10.602184295654297,
      "rewards/rejected": -10.01781940460205,
      "step": 4598
    },
    {
      "epoch": 1.8396,
      "grad_norm": 0.029467549175024033,
      "learning_rate": 3.8693333333333336e-07,
      "logits/chosen": -2.5090556144714355,
      "logits/rejected": -2.4192559719085693,
      "logps/chosen": -107.73054504394531,
      "logps/rejected": -146.8096923828125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6348804235458374,
      "rewards/margins": 9.424858093261719,
      "rewards/rejected": -8.789977073669434,
      "step": 4599
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 5.494937067851424e-05,
      "learning_rate": 3.8679999999999994e-07,
      "logits/chosen": -2.6173906326293945,
      "logits/rejected": -1.7153432369232178,
      "logps/chosen": -94.28575134277344,
      "logps/rejected": -212.6388397216797,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9238567352294922,
      "rewards/margins": 16.68134307861328,
      "rewards/rejected": -14.757486343383789,
      "step": 4600
    },
    {
      "epoch": 1.8404,
      "grad_norm": 0.0068981340155005455,
      "learning_rate": 3.8666666666666664e-07,
      "logits/chosen": -2.6405434608459473,
      "logits/rejected": -1.6508805751800537,
      "logps/chosen": -89.82897186279297,
      "logps/rejected": -167.0152130126953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7762947678565979,
      "rewards/margins": 10.733342170715332,
      "rewards/rejected": -9.957047462463379,
      "step": 4601
    },
    {
      "epoch": 1.8408,
      "grad_norm": 0.3390091359615326,
      "learning_rate": 3.8653333333333333e-07,
      "logits/chosen": -3.162199020385742,
      "logits/rejected": -2.547718048095703,
      "logps/chosen": -60.90593719482422,
      "logps/rejected": -126.43276977539062,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3507906198501587,
      "rewards/margins": 9.44051742553711,
      "rewards/rejected": -8.089726448059082,
      "step": 4602
    },
    {
      "epoch": 1.8412,
      "grad_norm": 0.30023154616355896,
      "learning_rate": 3.864e-07,
      "logits/chosen": -2.7180209159851074,
      "logits/rejected": -2.529979705810547,
      "logps/chosen": -48.30156707763672,
      "logps/rejected": -119.85790252685547,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0951990932226181,
      "rewards/margins": 7.7371039390563965,
      "rewards/rejected": -7.641904830932617,
      "step": 4603
    },
    {
      "epoch": 1.8416000000000001,
      "grad_norm": 1.0372873544692993,
      "learning_rate": 3.862666666666666e-07,
      "logits/chosen": -2.7286691665649414,
      "logits/rejected": -2.613630771636963,
      "logps/chosen": -71.09034729003906,
      "logps/rejected": -177.10556030273438,
      "loss": 0.0074,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1730735301971436,
      "rewards/margins": 9.618318557739258,
      "rewards/rejected": -10.79139232635498,
      "step": 4604
    },
    {
      "epoch": 1.842,
      "grad_norm": 0.011455507017672062,
      "learning_rate": 3.861333333333333e-07,
      "logits/chosen": -2.668822765350342,
      "logits/rejected": -2.1706905364990234,
      "logps/chosen": -101.61334991455078,
      "logps/rejected": -178.97154235839844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.22217559814453125,
      "rewards/margins": 10.511652946472168,
      "rewards/rejected": -10.7338285446167,
      "step": 4605
    },
    {
      "epoch": 1.8424,
      "grad_norm": 0.022024091333150864,
      "learning_rate": 3.86e-07,
      "logits/chosen": -2.922433376312256,
      "logits/rejected": -2.431901216506958,
      "logps/chosen": -98.4334716796875,
      "logps/rejected": -168.97329711914062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5972893238067627,
      "rewards/margins": 10.194398880004883,
      "rewards/rejected": -11.791688919067383,
      "step": 4606
    },
    {
      "epoch": 1.8428,
      "grad_norm": 0.027745934203267097,
      "learning_rate": 3.858666666666667e-07,
      "logits/chosen": -2.7092247009277344,
      "logits/rejected": -2.198216199874878,
      "logps/chosen": -101.84940338134766,
      "logps/rejected": -186.4339141845703,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7084171772003174,
      "rewards/margins": 12.252350807189941,
      "rewards/rejected": -11.543933868408203,
      "step": 4607
    },
    {
      "epoch": 1.8432,
      "grad_norm": 0.01323775015771389,
      "learning_rate": 3.857333333333333e-07,
      "logits/chosen": -2.5833935737609863,
      "logits/rejected": -1.9523382186889648,
      "logps/chosen": -129.72935485839844,
      "logps/rejected": -172.23045349121094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6678444147109985,
      "rewards/margins": 12.262408256530762,
      "rewards/rejected": -11.594563484191895,
      "step": 4608
    },
    {
      "epoch": 1.8436,
      "grad_norm": 0.000737110385671258,
      "learning_rate": 3.8559999999999996e-07,
      "logits/chosen": -2.513061046600342,
      "logits/rejected": -1.5650722980499268,
      "logps/chosen": -116.3010482788086,
      "logps/rejected": -198.9056854248047,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9193305969238281,
      "rewards/margins": 13.997108459472656,
      "rewards/rejected": -13.077777862548828,
      "step": 4609
    },
    {
      "epoch": 1.8439999999999999,
      "grad_norm": 0.009930695407092571,
      "learning_rate": 3.8546666666666665e-07,
      "logits/chosen": -2.8747963905334473,
      "logits/rejected": -2.626781702041626,
      "logps/chosen": -91.1584243774414,
      "logps/rejected": -162.60760498046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.19251763820648193,
      "rewards/margins": 10.255142211914062,
      "rewards/rejected": -10.447659492492676,
      "step": 4610
    },
    {
      "epoch": 1.8444,
      "grad_norm": 0.0007582689286209643,
      "learning_rate": 3.8533333333333334e-07,
      "logits/chosen": -2.1978659629821777,
      "logits/rejected": -1.6487581729888916,
      "logps/chosen": -81.6597900390625,
      "logps/rejected": -190.51449584960938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0031862258911133,
      "rewards/margins": 12.900154113769531,
      "rewards/rejected": -10.896968841552734,
      "step": 4611
    },
    {
      "epoch": 1.8448,
      "grad_norm": 0.1650104522705078,
      "learning_rate": 3.852e-07,
      "logits/chosen": -2.458456516265869,
      "logits/rejected": -1.972661018371582,
      "logps/chosen": -79.41244506835938,
      "logps/rejected": -164.32418823242188,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1913793087005615,
      "rewards/margins": 7.583856582641602,
      "rewards/rejected": -8.775236129760742,
      "step": 4612
    },
    {
      "epoch": 1.8452,
      "grad_norm": 0.1526254266500473,
      "learning_rate": 3.850666666666667e-07,
      "logits/chosen": -2.6918647289276123,
      "logits/rejected": -2.0287528038024902,
      "logps/chosen": -98.85337829589844,
      "logps/rejected": -133.36123657226562,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08736419677734375,
      "rewards/margins": 9.449043273925781,
      "rewards/rejected": -9.536407470703125,
      "step": 4613
    },
    {
      "epoch": 1.8456000000000001,
      "grad_norm": 0.0022484082728624344,
      "learning_rate": 3.849333333333333e-07,
      "logits/chosen": -2.6019954681396484,
      "logits/rejected": -2.0271148681640625,
      "logps/chosen": -87.54390716552734,
      "logps/rejected": -183.0790252685547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0275200605392456,
      "rewards/margins": 11.476432800292969,
      "rewards/rejected": -10.44891357421875,
      "step": 4614
    },
    {
      "epoch": 1.846,
      "grad_norm": 0.03765840828418732,
      "learning_rate": 3.8479999999999995e-07,
      "logits/chosen": -2.494636058807373,
      "logits/rejected": -2.2339789867401123,
      "logps/chosen": -121.29700469970703,
      "logps/rejected": -141.8255615234375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17445679008960724,
      "rewards/margins": 8.473836898803711,
      "rewards/rejected": -8.2993803024292,
      "step": 4615
    },
    {
      "epoch": 1.8464,
      "grad_norm": 8.265341758728027,
      "learning_rate": 3.8466666666666664e-07,
      "logits/chosen": -2.6122987270355225,
      "logits/rejected": -2.240067720413208,
      "logps/chosen": -161.4422149658203,
      "logps/rejected": -98.39512634277344,
      "loss": 0.037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.566307544708252,
      "rewards/margins": 3.6044740676879883,
      "rewards/rejected": -6.17078161239624,
      "step": 4616
    },
    {
      "epoch": 1.8468,
      "grad_norm": 0.010582362301647663,
      "learning_rate": 3.8453333333333334e-07,
      "logits/chosen": -2.892982006072998,
      "logits/rejected": -2.34334135055542,
      "logps/chosen": -117.78208923339844,
      "logps/rejected": -194.35194396972656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4169145822525024,
      "rewards/margins": 10.653210639953613,
      "rewards/rejected": -12.070125579833984,
      "step": 4617
    },
    {
      "epoch": 1.8472,
      "grad_norm": 0.5225895047187805,
      "learning_rate": 3.8440000000000003e-07,
      "logits/chosen": -2.447350025177002,
      "logits/rejected": -1.899923324584961,
      "logps/chosen": -92.72504425048828,
      "logps/rejected": -119.81871795654297,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.016108751296997,
      "rewards/margins": 7.7560319900512695,
      "rewards/rejected": -6.739923477172852,
      "step": 4618
    },
    {
      "epoch": 1.8476,
      "grad_norm": 0.004532190039753914,
      "learning_rate": 3.842666666666666e-07,
      "logits/chosen": -2.5823135375976562,
      "logits/rejected": -2.1579132080078125,
      "logps/chosen": -85.92807006835938,
      "logps/rejected": -201.23028564453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4705654382705688,
      "rewards/margins": 12.651326179504395,
      "rewards/rejected": -11.180761337280273,
      "step": 4619
    },
    {
      "epoch": 1.8479999999999999,
      "grad_norm": 0.000686673098243773,
      "learning_rate": 3.841333333333333e-07,
      "logits/chosen": -2.7561404705047607,
      "logits/rejected": -2.3666958808898926,
      "logps/chosen": -98.1793441772461,
      "logps/rejected": -232.2832794189453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8721284866333008,
      "rewards/margins": 14.536630630493164,
      "rewards/rejected": -15.408760070800781,
      "step": 4620
    },
    {
      "epoch": 1.8484,
      "grad_norm": 2.176521062850952,
      "learning_rate": 3.84e-07,
      "logits/chosen": -2.6820034980773926,
      "logits/rejected": -2.073491096496582,
      "logps/chosen": -112.87844848632812,
      "logps/rejected": -133.90472412109375,
      "loss": 0.0137,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.1915862560272217,
      "rewards/margins": 6.197916030883789,
      "rewards/rejected": -8.38950252532959,
      "step": 4621
    },
    {
      "epoch": 1.8488,
      "grad_norm": 0.13694356381893158,
      "learning_rate": 3.838666666666667e-07,
      "logits/chosen": -2.9698705673217773,
      "logits/rejected": -2.64007306098938,
      "logps/chosen": -54.152496337890625,
      "logps/rejected": -162.087158203125,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.18719272315502167,
      "rewards/margins": 11.409557342529297,
      "rewards/rejected": -11.596750259399414,
      "step": 4622
    },
    {
      "epoch": 1.8492,
      "grad_norm": 5.859975135535933e-05,
      "learning_rate": 3.837333333333333e-07,
      "logits/chosen": -2.6636202335357666,
      "logits/rejected": -2.010286808013916,
      "logps/chosen": -130.93096923828125,
      "logps/rejected": -256.99176025390625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3349258303642273,
      "rewards/margins": 15.830638885498047,
      "rewards/rejected": -16.165565490722656,
      "step": 4623
    },
    {
      "epoch": 1.8496000000000001,
      "grad_norm": 0.00680359685793519,
      "learning_rate": 3.8359999999999997e-07,
      "logits/chosen": -2.7877211570739746,
      "logits/rejected": -2.498743772506714,
      "logps/chosen": -44.05018615722656,
      "logps/rejected": -152.66116333007812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34104079008102417,
      "rewards/margins": 10.474457740783691,
      "rewards/rejected": -10.133417129516602,
      "step": 4624
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.0680423378944397,
      "learning_rate": 3.8346666666666666e-07,
      "logits/chosen": -2.360374927520752,
      "logits/rejected": -1.595278263092041,
      "logps/chosen": -174.33685302734375,
      "logps/rejected": -220.89028930664062,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.041674852371216,
      "rewards/margins": 12.249503135681152,
      "rewards/rejected": -14.291177749633789,
      "step": 4625
    },
    {
      "epoch": 1.8504,
      "grad_norm": 0.013438868336379528,
      "learning_rate": 3.8333333333333335e-07,
      "logits/chosen": -2.761593818664551,
      "logits/rejected": -1.8961095809936523,
      "logps/chosen": -167.19297790527344,
      "logps/rejected": -195.11280822753906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2872875928878784,
      "rewards/margins": 12.477508544921875,
      "rewards/rejected": -12.190220832824707,
      "step": 4626
    },
    {
      "epoch": 1.8508,
      "grad_norm": 0.2897513806819916,
      "learning_rate": 3.832e-07,
      "logits/chosen": -2.4926609992980957,
      "logits/rejected": -2.0335915088653564,
      "logps/chosen": -136.07171630859375,
      "logps/rejected": -139.29891967773438,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40636059641838074,
      "rewards/margins": 10.050103187561035,
      "rewards/rejected": -9.643743515014648,
      "step": 4627
    },
    {
      "epoch": 1.8512,
      "grad_norm": 0.025393648073077202,
      "learning_rate": 3.8306666666666663e-07,
      "logits/chosen": -2.7111058235168457,
      "logits/rejected": -2.2070493698120117,
      "logps/chosen": -86.09504699707031,
      "logps/rejected": -170.22299194335938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8028408288955688,
      "rewards/margins": 12.582398414611816,
      "rewards/rejected": -11.779557228088379,
      "step": 4628
    },
    {
      "epoch": 1.8516,
      "grad_norm": 0.023836946114897728,
      "learning_rate": 3.829333333333333e-07,
      "logits/chosen": -2.6022207736968994,
      "logits/rejected": -2.270670175552368,
      "logps/chosen": -148.400634765625,
      "logps/rejected": -181.27684020996094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5011955499649048,
      "rewards/margins": 10.34939193725586,
      "rewards/rejected": -10.850587844848633,
      "step": 4629
    },
    {
      "epoch": 1.8519999999999999,
      "grad_norm": 0.0118482057005167,
      "learning_rate": 3.8279999999999996e-07,
      "logits/chosen": -2.9366631507873535,
      "logits/rejected": -2.0852677822113037,
      "logps/chosen": -75.26268768310547,
      "logps/rejected": -161.11863708496094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9508216977119446,
      "rewards/margins": 10.959117889404297,
      "rewards/rejected": -10.008296966552734,
      "step": 4630
    },
    {
      "epoch": 1.8524,
      "grad_norm": 85.8673095703125,
      "learning_rate": 3.8266666666666665e-07,
      "logits/chosen": -2.4832606315612793,
      "logits/rejected": -2.230433940887451,
      "logps/chosen": -264.4188232421875,
      "logps/rejected": -135.83145141601562,
      "loss": 0.3865,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -5.341452598571777,
      "rewards/margins": 2.5557773113250732,
      "rewards/rejected": -7.89723014831543,
      "step": 4631
    },
    {
      "epoch": 1.8528,
      "grad_norm": 0.3882451355457306,
      "learning_rate": 3.8253333333333334e-07,
      "logits/chosen": -2.3802385330200195,
      "logits/rejected": -2.1614601612091064,
      "logps/chosen": -147.2191619873047,
      "logps/rejected": -144.33847045898438,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1835747957229614,
      "rewards/margins": 9.92773723602295,
      "rewards/rejected": -8.744162559509277,
      "step": 4632
    },
    {
      "epoch": 1.8532,
      "grad_norm": 3.345496952533722e-05,
      "learning_rate": 3.824e-07,
      "logits/chosen": -2.9798333644866943,
      "logits/rejected": -1.9611082077026367,
      "logps/chosen": -35.508522033691406,
      "logps/rejected": -220.92379760742188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0667619705200195,
      "rewards/margins": 16.900653839111328,
      "rewards/rejected": -14.833891868591309,
      "step": 4633
    },
    {
      "epoch": 1.8536000000000001,
      "grad_norm": 0.011255411431193352,
      "learning_rate": 3.822666666666666e-07,
      "logits/chosen": -2.1808438301086426,
      "logits/rejected": -1.58268141746521,
      "logps/chosen": -215.04928588867188,
      "logps/rejected": -215.88360595703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.8387253284454346,
      "rewards/margins": 11.157111167907715,
      "rewards/rejected": -13.99583625793457,
      "step": 4634
    },
    {
      "epoch": 1.854,
      "grad_norm": 0.0624568872153759,
      "learning_rate": 3.821333333333333e-07,
      "logits/chosen": -2.8877079486846924,
      "logits/rejected": -2.3343608379364014,
      "logps/chosen": -150.0240478515625,
      "logps/rejected": -193.3990478515625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.6277694702148438,
      "rewards/margins": 9.47776985168457,
      "rewards/rejected": -12.105539321899414,
      "step": 4635
    },
    {
      "epoch": 1.8544,
      "grad_norm": 0.007271988783031702,
      "learning_rate": 3.82e-07,
      "logits/chosen": -2.4264140129089355,
      "logits/rejected": -1.8366954326629639,
      "logps/chosen": -175.9021453857422,
      "logps/rejected": -182.7520294189453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.35638427734375,
      "rewards/margins": 10.874124526977539,
      "rewards/rejected": -11.230508804321289,
      "step": 4636
    },
    {
      "epoch": 1.8548,
      "grad_norm": 0.04962917044758797,
      "learning_rate": 3.8186666666666665e-07,
      "logits/chosen": -2.9862396717071533,
      "logits/rejected": -2.787123680114746,
      "logps/chosen": -83.66230773925781,
      "logps/rejected": -124.1983642578125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2414749264717102,
      "rewards/margins": 9.202859878540039,
      "rewards/rejected": -8.961384773254395,
      "step": 4637
    },
    {
      "epoch": 1.8552,
      "grad_norm": 0.05151347815990448,
      "learning_rate": 3.817333333333333e-07,
      "logits/chosen": -2.8802690505981445,
      "logits/rejected": -2.7161660194396973,
      "logps/chosen": -89.85404968261719,
      "logps/rejected": -185.92678833007812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.37828677892684937,
      "rewards/margins": 10.014238357543945,
      "rewards/rejected": -10.392524719238281,
      "step": 4638
    },
    {
      "epoch": 1.8556,
      "grad_norm": 0.002062527695670724,
      "learning_rate": 3.816e-07,
      "logits/chosen": -2.902243137359619,
      "logits/rejected": -2.0086612701416016,
      "logps/chosen": -112.17961120605469,
      "logps/rejected": -171.8336181640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2250509262084961,
      "rewards/margins": 11.835610389709473,
      "rewards/rejected": -12.060661315917969,
      "step": 4639
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 0.004231148399412632,
      "learning_rate": 3.8146666666666667e-07,
      "logits/chosen": -2.969104528427124,
      "logits/rejected": -2.384697437286377,
      "logps/chosen": -117.52540588378906,
      "logps/rejected": -174.51541137695312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9215240478515625,
      "rewards/margins": 11.466422080993652,
      "rewards/rejected": -12.387946128845215,
      "step": 4640
    },
    {
      "epoch": 1.8564,
      "grad_norm": 0.12019574642181396,
      "learning_rate": 3.8133333333333336e-07,
      "logits/chosen": -2.873063087463379,
      "logits/rejected": -2.4968533515930176,
      "logps/chosen": -48.906272888183594,
      "logps/rejected": -119.08329772949219,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8537836074829102,
      "rewards/margins": 9.267682075500488,
      "rewards/rejected": -7.413898468017578,
      "step": 4641
    },
    {
      "epoch": 1.8568,
      "grad_norm": 0.021783078089356422,
      "learning_rate": 3.8119999999999995e-07,
      "logits/chosen": -2.843146324157715,
      "logits/rejected": -2.3852486610412598,
      "logps/chosen": -99.95877075195312,
      "logps/rejected": -153.58876037597656,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.28024840354919434,
      "rewards/margins": 9.815603256225586,
      "rewards/rejected": -10.095850944519043,
      "step": 4642
    },
    {
      "epoch": 1.8572,
      "grad_norm": 1.4111065864562988,
      "learning_rate": 3.8106666666666664e-07,
      "logits/chosen": -2.7847070693969727,
      "logits/rejected": -2.47531795501709,
      "logps/chosen": -102.32171630859375,
      "logps/rejected": -104.42117309570312,
      "loss": 0.0078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9900447726249695,
      "rewards/margins": 4.987095355987549,
      "rewards/rejected": -5.977140426635742,
      "step": 4643
    },
    {
      "epoch": 1.8576000000000001,
      "grad_norm": 0.0012147227535024285,
      "learning_rate": 3.8093333333333333e-07,
      "logits/chosen": -2.6832900047302246,
      "logits/rejected": -1.8418433666229248,
      "logps/chosen": -75.11487579345703,
      "logps/rejected": -166.57618713378906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2710249423980713,
      "rewards/margins": 12.678702354431152,
      "rewards/rejected": -11.40767765045166,
      "step": 4644
    },
    {
      "epoch": 1.858,
      "grad_norm": 5.5157318115234375,
      "learning_rate": 3.808e-07,
      "logits/chosen": -3.137228012084961,
      "logits/rejected": -2.2258477210998535,
      "logps/chosen": -87.58047485351562,
      "logps/rejected": -150.7784423828125,
      "loss": 0.0259,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02490997314453125,
      "rewards/margins": 8.954391479492188,
      "rewards/rejected": -8.929481506347656,
      "step": 4645
    },
    {
      "epoch": 1.8584,
      "grad_norm": 0.0020751722622662783,
      "learning_rate": 3.8066666666666666e-07,
      "logits/chosen": -2.4163260459899902,
      "logits/rejected": -1.9885921478271484,
      "logps/chosen": -127.33445739746094,
      "logps/rejected": -238.17724609375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6148929595947266,
      "rewards/margins": 11.695195198059082,
      "rewards/rejected": -11.080302238464355,
      "step": 4646
    },
    {
      "epoch": 1.8588,
      "grad_norm": 0.055863961577415466,
      "learning_rate": 3.805333333333333e-07,
      "logits/chosen": -2.9281668663024902,
      "logits/rejected": -2.8080711364746094,
      "logps/chosen": -75.07133483886719,
      "logps/rejected": -100.70233917236328,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7246536016464233,
      "rewards/margins": 8.130819320678711,
      "rewards/rejected": -6.406166076660156,
      "step": 4647
    },
    {
      "epoch": 1.8592,
      "grad_norm": 0.21530242264270782,
      "learning_rate": 3.804e-07,
      "logits/chosen": -2.555180549621582,
      "logits/rejected": -1.9277149438858032,
      "logps/chosen": -89.88257598876953,
      "logps/rejected": -157.8867950439453,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2439872920513153,
      "rewards/margins": 10.080312728881836,
      "rewards/rejected": -9.836324691772461,
      "step": 4648
    },
    {
      "epoch": 1.8596,
      "grad_norm": 0.008418786339461803,
      "learning_rate": 3.8026666666666663e-07,
      "logits/chosen": -2.705686569213867,
      "logits/rejected": -1.5568140745162964,
      "logps/chosen": -168.16366577148438,
      "logps/rejected": -175.64700317382812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4399383068084717,
      "rewards/margins": 12.37335205078125,
      "rewards/rejected": -10.9334135055542,
      "step": 4649
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 0.0012645686510950327,
      "learning_rate": 3.801333333333333e-07,
      "logits/chosen": -2.6585569381713867,
      "logits/rejected": -2.277585506439209,
      "logps/chosen": -100.26555633544922,
      "logps/rejected": -193.20169067382812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6063774228096008,
      "rewards/margins": 12.183292388916016,
      "rewards/rejected": -11.576915740966797,
      "step": 4650
    },
    {
      "epoch": 1.8604,
      "grad_norm": 0.0009651230066083372,
      "learning_rate": 3.7999999999999996e-07,
      "logits/chosen": -2.476050853729248,
      "logits/rejected": -1.9068965911865234,
      "logps/chosen": -231.14060974121094,
      "logps/rejected": -241.45619201660156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.9023866653442383,
      "rewards/margins": 13.639352798461914,
      "rewards/rejected": -16.54174041748047,
      "step": 4651
    },
    {
      "epoch": 1.8608,
      "grad_norm": 0.011399724520742893,
      "learning_rate": 3.7986666666666665e-07,
      "logits/chosen": -2.611309051513672,
      "logits/rejected": -2.200512409210205,
      "logps/chosen": -63.31705856323242,
      "logps/rejected": -160.26934814453125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7798831462860107,
      "rewards/margins": 10.547868728637695,
      "rewards/rejected": -9.767985343933105,
      "step": 4652
    },
    {
      "epoch": 1.8612,
      "grad_norm": 0.15981805324554443,
      "learning_rate": 3.797333333333333e-07,
      "logits/chosen": -3.1862077713012695,
      "logits/rejected": -2.936391830444336,
      "logps/chosen": -70.37688446044922,
      "logps/rejected": -101.75912475585938,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3333891034126282,
      "rewards/margins": 6.789033889770508,
      "rewards/rejected": -6.455644607543945,
      "step": 4653
    },
    {
      "epoch": 1.8616000000000001,
      "grad_norm": 0.09007617831230164,
      "learning_rate": 3.796e-07,
      "logits/chosen": -2.969256639480591,
      "logits/rejected": -2.493011474609375,
      "logps/chosen": -66.04425048828125,
      "logps/rejected": -129.17977905273438,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1489967405796051,
      "rewards/margins": 8.414562225341797,
      "rewards/rejected": -8.563558578491211,
      "step": 4654
    },
    {
      "epoch": 1.862,
      "grad_norm": 0.06141968443989754,
      "learning_rate": 3.794666666666667e-07,
      "logits/chosen": -2.428781509399414,
      "logits/rejected": -1.7973105907440186,
      "logps/chosen": -125.27494812011719,
      "logps/rejected": -167.91574096679688,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.35637131333351135,
      "rewards/margins": 8.640769958496094,
      "rewards/rejected": -8.997140884399414,
      "step": 4655
    },
    {
      "epoch": 1.8624,
      "grad_norm": 0.05085337534546852,
      "learning_rate": 3.793333333333333e-07,
      "logits/chosen": -2.834256649017334,
      "logits/rejected": -2.1901144981384277,
      "logps/chosen": -142.24838256835938,
      "logps/rejected": -181.99542236328125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1667202115058899,
      "rewards/margins": 9.024547576904297,
      "rewards/rejected": -8.857827186584473,
      "step": 4656
    },
    {
      "epoch": 1.8628,
      "grad_norm": 0.023053139448165894,
      "learning_rate": 3.7919999999999995e-07,
      "logits/chosen": -3.0405540466308594,
      "logits/rejected": -2.297037124633789,
      "logps/chosen": -77.98036193847656,
      "logps/rejected": -161.65386962890625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.15744400024414062,
      "rewards/margins": 9.679203033447266,
      "rewards/rejected": -9.836647033691406,
      "step": 4657
    },
    {
      "epoch": 1.8632,
      "grad_norm": 0.00042976593249477446,
      "learning_rate": 3.7906666666666665e-07,
      "logits/chosen": -2.5202689170837402,
      "logits/rejected": -1.5867457389831543,
      "logps/chosen": -162.55963134765625,
      "logps/rejected": -232.2135009765625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6030510663986206,
      "rewards/margins": 15.38080883026123,
      "rewards/rejected": -13.77775764465332,
      "step": 4658
    },
    {
      "epoch": 1.8636,
      "grad_norm": 0.017162326723337173,
      "learning_rate": 3.7893333333333334e-07,
      "logits/chosen": -2.529797315597534,
      "logits/rejected": -1.9229645729064941,
      "logps/chosen": -130.6240692138672,
      "logps/rejected": -184.6712646484375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0433616638183594,
      "rewards/margins": 12.814796447753906,
      "rewards/rejected": -11.771434783935547,
      "step": 4659
    },
    {
      "epoch": 1.8639999999999999,
      "grad_norm": 5.470878601074219,
      "learning_rate": 3.7880000000000003e-07,
      "logits/chosen": -2.9396796226501465,
      "logits/rejected": -2.8838162422180176,
      "logps/chosen": -140.39630126953125,
      "logps/rejected": -141.57566833496094,
      "loss": 0.0215,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3276378810405731,
      "rewards/margins": 6.582141399383545,
      "rewards/rejected": -6.9097795486450195,
      "step": 4660
    },
    {
      "epoch": 1.8643999999999998,
      "grad_norm": 0.004999793134629726,
      "learning_rate": 3.786666666666666e-07,
      "logits/chosen": -2.692206382751465,
      "logits/rejected": -2.3489761352539062,
      "logps/chosen": -62.51790237426758,
      "logps/rejected": -160.7301025390625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.096049189567566,
      "rewards/margins": 10.72733211517334,
      "rewards/rejected": -9.631282806396484,
      "step": 4661
    },
    {
      "epoch": 1.8648,
      "grad_norm": 0.001314992317929864,
      "learning_rate": 3.785333333333333e-07,
      "logits/chosen": -2.4757657051086426,
      "logits/rejected": -1.9107000827789307,
      "logps/chosen": -132.02011108398438,
      "logps/rejected": -218.89492797851562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7804988622665405,
      "rewards/margins": 13.05502700805664,
      "rewards/rejected": -12.274528503417969,
      "step": 4662
    },
    {
      "epoch": 1.8652,
      "grad_norm": 0.12141761928796768,
      "learning_rate": 3.784e-07,
      "logits/chosen": -2.839383602142334,
      "logits/rejected": -2.4260571002960205,
      "logps/chosen": -82.49137115478516,
      "logps/rejected": -155.08609008789062,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7057434320449829,
      "rewards/margins": 10.538253784179688,
      "rewards/rejected": -9.832509994506836,
      "step": 4663
    },
    {
      "epoch": 1.8656000000000001,
      "grad_norm": 23.938039779663086,
      "learning_rate": 3.7826666666666664e-07,
      "logits/chosen": -2.41510272026062,
      "logits/rejected": -2.190471649169922,
      "logps/chosen": -205.9113006591797,
      "logps/rejected": -177.9408416748047,
      "loss": 0.1054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.7381467819213867,
      "rewards/margins": 4.601957321166992,
      "rewards/rejected": -8.340104103088379,
      "step": 4664
    },
    {
      "epoch": 1.866,
      "grad_norm": 132.78192138671875,
      "learning_rate": 3.781333333333333e-07,
      "logits/chosen": -2.7360076904296875,
      "logits/rejected": -2.267202377319336,
      "logps/chosen": -149.23760986328125,
      "logps/rejected": -115.76165771484375,
      "loss": 0.8583,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -2.378351926803589,
      "rewards/margins": 4.305091857910156,
      "rewards/rejected": -6.683444023132324,
      "step": 4665
    },
    {
      "epoch": 1.8664,
      "grad_norm": 0.0010657265083864331,
      "learning_rate": 3.7799999999999997e-07,
      "logits/chosen": -3.0093271732330322,
      "logits/rejected": -2.479948043823242,
      "logps/chosen": -65.19645690917969,
      "logps/rejected": -189.11045837402344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6371849179267883,
      "rewards/margins": 13.47572135925293,
      "rewards/rejected": -12.838536262512207,
      "step": 4666
    },
    {
      "epoch": 1.8668,
      "grad_norm": 0.05714796110987663,
      "learning_rate": 3.7786666666666666e-07,
      "logits/chosen": -2.420548439025879,
      "logits/rejected": -1.4976444244384766,
      "logps/chosen": -190.8528594970703,
      "logps/rejected": -288.0821533203125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.261575937271118,
      "rewards/margins": 12.072423934936523,
      "rewards/rejected": -14.333999633789062,
      "step": 4667
    },
    {
      "epoch": 1.8672,
      "grad_norm": 0.048877689987421036,
      "learning_rate": 3.777333333333333e-07,
      "logits/chosen": -2.2870259284973145,
      "logits/rejected": -1.4743363857269287,
      "logps/chosen": -189.0634765625,
      "logps/rejected": -139.191162109375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2728066444396973,
      "rewards/margins": 10.530181884765625,
      "rewards/rejected": -9.257375717163086,
      "step": 4668
    },
    {
      "epoch": 1.8676,
      "grad_norm": 0.08819834887981415,
      "learning_rate": 3.776e-07,
      "logits/chosen": -2.9347951412200928,
      "logits/rejected": -2.510589122772217,
      "logps/chosen": -95.92906951904297,
      "logps/rejected": -171.53829956054688,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.150484561920166,
      "rewards/margins": 9.686845779418945,
      "rewards/rejected": -10.837329864501953,
      "step": 4669
    },
    {
      "epoch": 1.8679999999999999,
      "grad_norm": 0.052779100835323334,
      "learning_rate": 3.7746666666666663e-07,
      "logits/chosen": -3.1039907932281494,
      "logits/rejected": -2.663081169128418,
      "logps/chosen": -80.07124328613281,
      "logps/rejected": -143.71282958984375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5431327819824219,
      "rewards/margins": 9.611772537231445,
      "rewards/rejected": -9.068639755249023,
      "step": 4670
    },
    {
      "epoch": 1.8683999999999998,
      "grad_norm": 0.0028483050409704447,
      "learning_rate": 3.773333333333333e-07,
      "logits/chosen": -2.934114456176758,
      "logits/rejected": -2.2320923805236816,
      "logps/chosen": -86.29875183105469,
      "logps/rejected": -145.2845458984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2253189086914062,
      "rewards/margins": 11.375930786132812,
      "rewards/rejected": -10.150611877441406,
      "step": 4671
    },
    {
      "epoch": 1.8688,
      "grad_norm": 0.06546978652477264,
      "learning_rate": 3.7719999999999996e-07,
      "logits/chosen": -2.554079055786133,
      "logits/rejected": -2.210726737976074,
      "logps/chosen": -142.68560791015625,
      "logps/rejected": -144.71389770507812,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9931110143661499,
      "rewards/margins": 7.858750343322754,
      "rewards/rejected": -8.851861953735352,
      "step": 4672
    },
    {
      "epoch": 1.8692,
      "grad_norm": 0.0076279304921627045,
      "learning_rate": 3.7706666666666665e-07,
      "logits/chosen": -2.905109167098999,
      "logits/rejected": -2.4789390563964844,
      "logps/chosen": -108.23908996582031,
      "logps/rejected": -160.90887451171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6898033022880554,
      "rewards/margins": 10.284256935119629,
      "rewards/rejected": -10.97406005859375,
      "step": 4673
    },
    {
      "epoch": 1.8696000000000002,
      "grad_norm": 0.1276916265487671,
      "learning_rate": 3.7693333333333335e-07,
      "logits/chosen": -2.5291690826416016,
      "logits/rejected": -2.595600128173828,
      "logps/chosen": -117.40858459472656,
      "logps/rejected": -128.79580688476562,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.06941187381744385,
      "rewards/margins": 7.708069801330566,
      "rewards/rejected": -7.7774810791015625,
      "step": 4674
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.04484083876013756,
      "learning_rate": 3.768e-07,
      "logits/chosen": -2.966599941253662,
      "logits/rejected": -2.2679224014282227,
      "logps/chosen": -48.45218276977539,
      "logps/rejected": -139.29026794433594,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6015846133232117,
      "rewards/margins": 9.028600692749023,
      "rewards/rejected": -8.427016258239746,
      "step": 4675
    },
    {
      "epoch": 1.8704,
      "grad_norm": 0.008693477138876915,
      "learning_rate": 3.766666666666666e-07,
      "logits/chosen": -2.7784619331359863,
      "logits/rejected": -2.464837074279785,
      "logps/chosen": -68.94003295898438,
      "logps/rejected": -119.90365600585938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9314653873443604,
      "rewards/margins": 10.175577163696289,
      "rewards/rejected": -8.244111061096191,
      "step": 4676
    },
    {
      "epoch": 1.8708,
      "grad_norm": 0.0162176676094532,
      "learning_rate": 3.765333333333333e-07,
      "logits/chosen": -2.5762338638305664,
      "logits/rejected": -2.1130943298339844,
      "logps/chosen": -78.14865112304688,
      "logps/rejected": -223.0320587158203,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5767949819564819,
      "rewards/margins": 11.74484634399414,
      "rewards/rejected": -11.168051719665527,
      "step": 4677
    },
    {
      "epoch": 1.8712,
      "grad_norm": 8.905804634094238,
      "learning_rate": 3.764e-07,
      "logits/chosen": -2.926868438720703,
      "logits/rejected": -2.376303195953369,
      "logps/chosen": -96.23800659179688,
      "logps/rejected": -119.95999145507812,
      "loss": 0.0265,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.56473970413208,
      "rewards/margins": 4.879672050476074,
      "rewards/rejected": -7.444411277770996,
      "step": 4678
    },
    {
      "epoch": 1.8716,
      "grad_norm": 0.0006353995995596051,
      "learning_rate": 3.762666666666667e-07,
      "logits/chosen": -2.3696889877319336,
      "logits/rejected": -2.033404588699341,
      "logps/chosen": -108.934326171875,
      "logps/rejected": -201.01641845703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0444965362548828,
      "rewards/margins": 14.643117904663086,
      "rewards/rejected": -13.598621368408203,
      "step": 4679
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 0.059620101004838943,
      "learning_rate": 3.761333333333333e-07,
      "logits/chosen": -2.8070240020751953,
      "logits/rejected": -2.8027584552764893,
      "logps/chosen": -100.77386474609375,
      "logps/rejected": -153.84268188476562,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8790849447250366,
      "rewards/margins": 8.386894226074219,
      "rewards/rejected": -9.265979766845703,
      "step": 4680
    },
    {
      "epoch": 1.8723999999999998,
      "grad_norm": 0.004207438323646784,
      "learning_rate": 3.76e-07,
      "logits/chosen": -2.618180990219116,
      "logits/rejected": -1.8868813514709473,
      "logps/chosen": -135.854736328125,
      "logps/rejected": -194.59228515625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3050277531147003,
      "rewards/margins": 13.037832260131836,
      "rewards/rejected": -13.342859268188477,
      "step": 4681
    },
    {
      "epoch": 1.8728,
      "grad_norm": 0.03984862193465233,
      "learning_rate": 3.7586666666666667e-07,
      "logits/chosen": -2.651522397994995,
      "logits/rejected": -1.943054437637329,
      "logps/chosen": -112.07059478759766,
      "logps/rejected": -159.19203186035156,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0458476543426514,
      "rewards/margins": 10.724113464355469,
      "rewards/rejected": -9.678266525268555,
      "step": 4682
    },
    {
      "epoch": 1.8732,
      "grad_norm": 0.2906058728694916,
      "learning_rate": 3.757333333333333e-07,
      "logits/chosen": -3.0374410152435303,
      "logits/rejected": -2.6801228523254395,
      "logps/chosen": -76.10083770751953,
      "logps/rejected": -108.34269714355469,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5054562091827393,
      "rewards/margins": 6.640275001525879,
      "rewards/rejected": -7.145730972290039,
      "step": 4683
    },
    {
      "epoch": 1.8736000000000002,
      "grad_norm": 0.0009860994759947062,
      "learning_rate": 3.7559999999999995e-07,
      "logits/chosen": -2.433603048324585,
      "logits/rejected": -1.4834201335906982,
      "logps/chosen": -60.93731689453125,
      "logps/rejected": -225.5003204345703,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.43731385469436646,
      "rewards/margins": 13.121074676513672,
      "rewards/rejected": -12.683760643005371,
      "step": 4684
    },
    {
      "epoch": 1.874,
      "grad_norm": 0.028017325326800346,
      "learning_rate": 3.7546666666666664e-07,
      "logits/chosen": -2.907362937927246,
      "logits/rejected": -2.404970645904541,
      "logps/chosen": -68.23869323730469,
      "logps/rejected": -146.42091369628906,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.157930850982666,
      "rewards/margins": 10.954988479614258,
      "rewards/rejected": -8.797057151794434,
      "step": 4685
    },
    {
      "epoch": 1.8744,
      "grad_norm": 0.005691297352313995,
      "learning_rate": 3.7533333333333333e-07,
      "logits/chosen": -2.7640769481658936,
      "logits/rejected": -2.197033166885376,
      "logps/chosen": -67.4180679321289,
      "logps/rejected": -211.46189880371094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5091163516044617,
      "rewards/margins": 11.300201416015625,
      "rewards/rejected": -10.791084289550781,
      "step": 4686
    },
    {
      "epoch": 1.8748,
      "grad_norm": 0.02114294283092022,
      "learning_rate": 3.7519999999999997e-07,
      "logits/chosen": -2.7520694732666016,
      "logits/rejected": -2.3086366653442383,
      "logps/chosen": -88.96038818359375,
      "logps/rejected": -136.97134399414062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.375388503074646,
      "rewards/margins": 9.556167602539062,
      "rewards/rejected": -8.180779457092285,
      "step": 4687
    },
    {
      "epoch": 1.8752,
      "grad_norm": 0.4284028708934784,
      "learning_rate": 3.7506666666666666e-07,
      "logits/chosen": -2.9243781566619873,
      "logits/rejected": -2.5490212440490723,
      "logps/chosen": -73.13871765136719,
      "logps/rejected": -87.18889617919922,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4167366027832031,
      "rewards/margins": 6.250292778015137,
      "rewards/rejected": -5.833556175231934,
      "step": 4688
    },
    {
      "epoch": 1.8756,
      "grad_norm": 1.881468415260315,
      "learning_rate": 3.749333333333333e-07,
      "logits/chosen": -2.7243118286132812,
      "logits/rejected": -2.594684600830078,
      "logps/chosen": -82.38922119140625,
      "logps/rejected": -101.77366638183594,
      "loss": 0.0122,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1255851984024048,
      "rewards/margins": 5.456960678100586,
      "rewards/rejected": -6.582546234130859,
      "step": 4689
    },
    {
      "epoch": 1.876,
      "grad_norm": 0.04862014204263687,
      "learning_rate": 3.748e-07,
      "logits/chosen": -3.185835123062134,
      "logits/rejected": -2.852186679840088,
      "logps/chosen": -51.383697509765625,
      "logps/rejected": -112.05259704589844,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9323354363441467,
      "rewards/margins": 8.094356536865234,
      "rewards/rejected": -7.162021636962891,
      "step": 4690
    },
    {
      "epoch": 1.8763999999999998,
      "grad_norm": 32.8997917175293,
      "learning_rate": 3.7466666666666663e-07,
      "logits/chosen": -2.4271187782287598,
      "logits/rejected": -1.7642391920089722,
      "logps/chosen": -120.24928283691406,
      "logps/rejected": -143.217041015625,
      "loss": 0.2166,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.3795688152313232,
      "rewards/margins": 6.512059211730957,
      "rewards/rejected": -8.89162826538086,
      "step": 4691
    },
    {
      "epoch": 1.8768,
      "grad_norm": 0.08691289275884628,
      "learning_rate": 3.745333333333333e-07,
      "logits/chosen": -2.553534507751465,
      "logits/rejected": -2.1369056701660156,
      "logps/chosen": -56.82089614868164,
      "logps/rejected": -131.90914916992188,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4762588441371918,
      "rewards/margins": 8.350316047668457,
      "rewards/rejected": -7.874057769775391,
      "step": 4692
    },
    {
      "epoch": 1.8772,
      "grad_norm": 0.051291074603796005,
      "learning_rate": 3.744e-07,
      "logits/chosen": -2.7561445236206055,
      "logits/rejected": -2.4683942794799805,
      "logps/chosen": -53.808250427246094,
      "logps/rejected": -107.82014465332031,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4351028203964233,
      "rewards/margins": 8.51839828491211,
      "rewards/rejected": -7.083294868469238,
      "step": 4693
    },
    {
      "epoch": 1.8776000000000002,
      "grad_norm": 0.09801416844129562,
      "learning_rate": 3.7426666666666666e-07,
      "logits/chosen": -2.7101595401763916,
      "logits/rejected": -2.095968008041382,
      "logps/chosen": -125.03810119628906,
      "logps/rejected": -160.49603271484375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0631214380264282,
      "rewards/margins": 10.619302749633789,
      "rewards/rejected": -11.682424545288086,
      "step": 4694
    },
    {
      "epoch": 1.8780000000000001,
      "grad_norm": 1.6407041549682617,
      "learning_rate": 3.741333333333333e-07,
      "logits/chosen": -2.961635112762451,
      "logits/rejected": -3.087293863296509,
      "logps/chosen": -86.99586486816406,
      "logps/rejected": -81.76045227050781,
      "loss": 0.0135,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8259601593017578,
      "rewards/margins": 4.81974458694458,
      "rewards/rejected": -5.645704746246338,
      "step": 4695
    },
    {
      "epoch": 1.8784,
      "grad_norm": 0.0003137824242003262,
      "learning_rate": 3.74e-07,
      "logits/chosen": -2.6845412254333496,
      "logits/rejected": -1.7328804731369019,
      "logps/chosen": -93.09828186035156,
      "logps/rejected": -212.2280731201172,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07539862394332886,
      "rewards/margins": 14.177650451660156,
      "rewards/rejected": -14.102251052856445,
      "step": 4696
    },
    {
      "epoch": 1.8788,
      "grad_norm": 0.03137871250510216,
      "learning_rate": 3.738666666666667e-07,
      "logits/chosen": -2.613370180130005,
      "logits/rejected": -2.1646924018859863,
      "logps/chosen": -109.82368469238281,
      "logps/rejected": -174.92288208007812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.41310617327690125,
      "rewards/margins": 11.070317268371582,
      "rewards/rejected": -11.483423233032227,
      "step": 4697
    },
    {
      "epoch": 1.8792,
      "grad_norm": 0.6752604246139526,
      "learning_rate": 3.7373333333333327e-07,
      "logits/chosen": -2.5517578125,
      "logits/rejected": -2.124312400817871,
      "logps/chosen": -123.37045288085938,
      "logps/rejected": -121.26870727539062,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7427837252616882,
      "rewards/margins": 6.5012922286987305,
      "rewards/rejected": -7.244076251983643,
      "step": 4698
    },
    {
      "epoch": 1.8796,
      "grad_norm": 0.10673145204782486,
      "learning_rate": 3.7359999999999996e-07,
      "logits/chosen": -2.6838345527648926,
      "logits/rejected": -2.419468402862549,
      "logps/chosen": -90.8011245727539,
      "logps/rejected": -133.76776123046875,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.04366913437843323,
      "rewards/margins": 9.111249923706055,
      "rewards/rejected": -9.154918670654297,
      "step": 4699
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.029707057401537895,
      "learning_rate": 3.7346666666666665e-07,
      "logits/chosen": -3.0506339073181152,
      "logits/rejected": -2.642411947250366,
      "logps/chosen": -84.62446594238281,
      "logps/rejected": -132.8198699951172,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.006773754954338074,
      "rewards/margins": 8.489729881286621,
      "rewards/rejected": -8.496503829956055,
      "step": 4700
    },
    {
      "epoch": 1.8803999999999998,
      "grad_norm": 0.1786651909351349,
      "learning_rate": 3.7333333333333334e-07,
      "logits/chosen": -2.942553997039795,
      "logits/rejected": -2.364758014678955,
      "logps/chosen": -52.288780212402344,
      "logps/rejected": -114.957763671875,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22406789660453796,
      "rewards/margins": 7.636145114898682,
      "rewards/rejected": -7.412076950073242,
      "step": 4701
    },
    {
      "epoch": 1.8808,
      "grad_norm": 0.7718933820724487,
      "learning_rate": 3.732e-07,
      "logits/chosen": -2.7619376182556152,
      "logits/rejected": -2.608882427215576,
      "logps/chosen": -78.89166259765625,
      "logps/rejected": -100.31330108642578,
      "loss": 0.0064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7815283536911011,
      "rewards/margins": 7.376832008361816,
      "rewards/rejected": -6.595303535461426,
      "step": 4702
    },
    {
      "epoch": 1.8812,
      "grad_norm": 2.8506669998168945,
      "learning_rate": 3.730666666666666e-07,
      "logits/chosen": -2.6294960975646973,
      "logits/rejected": -2.3085861206054688,
      "logps/chosen": -130.3826904296875,
      "logps/rejected": -196.2954864501953,
      "loss": 0.0168,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.248973846435547,
      "rewards/margins": 9.578095436096191,
      "rewards/rejected": -12.827069282531738,
      "step": 4703
    },
    {
      "epoch": 1.8816000000000002,
      "grad_norm": 2.129629319824744e-05,
      "learning_rate": 3.729333333333333e-07,
      "logits/chosen": -2.776183843612671,
      "logits/rejected": -1.7121261358261108,
      "logps/chosen": -69.6595458984375,
      "logps/rejected": -240.53729248046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9743292331695557,
      "rewards/margins": 16.819766998291016,
      "rewards/rejected": -14.845436096191406,
      "step": 4704
    },
    {
      "epoch": 1.8820000000000001,
      "grad_norm": 0.08191481977701187,
      "learning_rate": 3.728e-07,
      "logits/chosen": -2.8624582290649414,
      "logits/rejected": -2.5088796615600586,
      "logps/chosen": -69.02220153808594,
      "logps/rejected": -140.6079864501953,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08507287502288818,
      "rewards/margins": 7.604607582092285,
      "rewards/rejected": -7.689680099487305,
      "step": 4705
    },
    {
      "epoch": 1.8824,
      "grad_norm": 0.0127714853733778,
      "learning_rate": 3.7266666666666664e-07,
      "logits/chosen": -3.0336270332336426,
      "logits/rejected": -2.454249858856201,
      "logps/chosen": -45.57213592529297,
      "logps/rejected": -136.85049438476562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7230347394943237,
      "rewards/margins": 10.103689193725586,
      "rewards/rejected": -8.380653381347656,
      "step": 4706
    },
    {
      "epoch": 1.8828,
      "grad_norm": 0.0006289934390224516,
      "learning_rate": 3.7253333333333333e-07,
      "logits/chosen": -2.451949119567871,
      "logits/rejected": -1.8735246658325195,
      "logps/chosen": -107.17149353027344,
      "logps/rejected": -217.45858764648438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.328883409500122,
      "rewards/margins": 14.033707618713379,
      "rewards/rejected": -12.704824447631836,
      "step": 4707
    },
    {
      "epoch": 1.8832,
      "grad_norm": 9.748384763952345e-05,
      "learning_rate": 3.7239999999999997e-07,
      "logits/chosen": -2.314006805419922,
      "logits/rejected": -1.4903154373168945,
      "logps/chosen": -135.92495727539062,
      "logps/rejected": -256.41082763671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0251243114471436,
      "rewards/margins": 17.298322677612305,
      "rewards/rejected": -15.273199081420898,
      "step": 4708
    },
    {
      "epoch": 1.8836,
      "grad_norm": 3.257990837097168,
      "learning_rate": 3.7226666666666666e-07,
      "logits/chosen": -2.4548134803771973,
      "logits/rejected": -2.1664953231811523,
      "logps/chosen": -153.98057556152344,
      "logps/rejected": -202.27944946289062,
      "loss": 0.0144,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.786437511444092,
      "rewards/margins": 8.85471248626709,
      "rewards/rejected": -11.641149520874023,
      "step": 4709
    },
    {
      "epoch": 1.884,
      "grad_norm": 0.019861089065670967,
      "learning_rate": 3.721333333333333e-07,
      "logits/chosen": -2.8282041549682617,
      "logits/rejected": -2.335714340209961,
      "logps/chosen": -80.96723937988281,
      "logps/rejected": -143.5289306640625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.053897500038147,
      "rewards/margins": 9.06590461730957,
      "rewards/rejected": -10.119802474975586,
      "step": 4710
    },
    {
      "epoch": 1.8843999999999999,
      "grad_norm": 0.01895969919860363,
      "learning_rate": 3.72e-07,
      "logits/chosen": -2.651470184326172,
      "logits/rejected": -1.903586745262146,
      "logps/chosen": -149.96240234375,
      "logps/rejected": -157.69744873046875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.077275037765503,
      "rewards/margins": 9.520307540893555,
      "rewards/rejected": -8.443033218383789,
      "step": 4711
    },
    {
      "epoch": 1.8848,
      "grad_norm": 0.518176257610321,
      "learning_rate": 3.718666666666667e-07,
      "logits/chosen": -2.871119737625122,
      "logits/rejected": -2.382662296295166,
      "logps/chosen": -92.8931884765625,
      "logps/rejected": -132.24581909179688,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9811590313911438,
      "rewards/margins": 6.9668707847595215,
      "rewards/rejected": -7.948029518127441,
      "step": 4712
    },
    {
      "epoch": 1.8852,
      "grad_norm": 0.00033414733479730785,
      "learning_rate": 3.7173333333333333e-07,
      "logits/chosen": -2.511258602142334,
      "logits/rejected": -1.7943764925003052,
      "logps/chosen": -101.90910339355469,
      "logps/rejected": -179.923095703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.360120415687561,
      "rewards/margins": 13.777558326721191,
      "rewards/rejected": -12.417438507080078,
      "step": 4713
    },
    {
      "epoch": 1.8856000000000002,
      "grad_norm": 1.6243574619293213,
      "learning_rate": 3.7159999999999997e-07,
      "logits/chosen": -2.4675493240356445,
      "logits/rejected": -2.0144457817077637,
      "logps/chosen": -162.42340087890625,
      "logps/rejected": -128.2298126220703,
      "loss": 0.0056,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.15332412719726562,
      "rewards/margins": 5.995394229888916,
      "rewards/rejected": -6.148717880249023,
      "step": 4714
    },
    {
      "epoch": 1.8860000000000001,
      "grad_norm": 0.04282835125923157,
      "learning_rate": 3.7146666666666666e-07,
      "logits/chosen": -2.7337846755981445,
      "logits/rejected": -2.2261099815368652,
      "logps/chosen": -114.19985961914062,
      "logps/rejected": -139.94073486328125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3270851373672485,
      "rewards/margins": 8.467994689941406,
      "rewards/rejected": -9.795080184936523,
      "step": 4715
    },
    {
      "epoch": 1.8864,
      "grad_norm": 0.10008104890584946,
      "learning_rate": 3.7133333333333335e-07,
      "logits/chosen": -3.0633857250213623,
      "logits/rejected": -2.5607476234436035,
      "logps/chosen": -81.37213134765625,
      "logps/rejected": -127.4300308227539,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6437634229660034,
      "rewards/margins": 8.449810028076172,
      "rewards/rejected": -7.806046485900879,
      "step": 4716
    },
    {
      "epoch": 1.8868,
      "grad_norm": 0.5053128600120544,
      "learning_rate": 3.7119999999999994e-07,
      "logits/chosen": -2.7961478233337402,
      "logits/rejected": -2.450356960296631,
      "logps/chosen": -153.00027465820312,
      "logps/rejected": -151.1227569580078,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9291777610778809,
      "rewards/margins": 7.264360427856445,
      "rewards/rejected": -9.193538665771484,
      "step": 4717
    },
    {
      "epoch": 1.8872,
      "grad_norm": 0.007808807771652937,
      "learning_rate": 3.7106666666666663e-07,
      "logits/chosen": -2.252967357635498,
      "logits/rejected": -1.8599319458007812,
      "logps/chosen": -139.1322021484375,
      "logps/rejected": -229.2512969970703,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8718376159667969,
      "rewards/margins": 15.486151695251465,
      "rewards/rejected": -14.614314079284668,
      "step": 4718
    },
    {
      "epoch": 1.8876,
      "grad_norm": 0.04237007722258568,
      "learning_rate": 3.709333333333333e-07,
      "logits/chosen": -2.536285877227783,
      "logits/rejected": -1.7172093391418457,
      "logps/chosen": -209.80682373046875,
      "logps/rejected": -149.16085815429688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08028110861778259,
      "rewards/margins": 8.616304397583008,
      "rewards/rejected": -8.696584701538086,
      "step": 4719
    },
    {
      "epoch": 1.888,
      "grad_norm": 0.00020870042499154806,
      "learning_rate": 3.708e-07,
      "logits/chosen": -2.828996181488037,
      "logits/rejected": -2.0218393802642822,
      "logps/chosen": -90.19023895263672,
      "logps/rejected": -199.85037231445312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.238355278968811,
      "rewards/margins": 14.767704010009766,
      "rewards/rejected": -13.529348373413086,
      "step": 4720
    },
    {
      "epoch": 1.8883999999999999,
      "grad_norm": 0.4298858046531677,
      "learning_rate": 3.7066666666666665e-07,
      "logits/chosen": -2.7649776935577393,
      "logits/rejected": -2.245384454727173,
      "logps/chosen": -90.38954162597656,
      "logps/rejected": -148.37460327148438,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1362758874893188,
      "rewards/margins": 11.463205337524414,
      "rewards/rejected": -10.326929092407227,
      "step": 4721
    },
    {
      "epoch": 1.8888,
      "grad_norm": 0.5277209281921387,
      "learning_rate": 3.705333333333333e-07,
      "logits/chosen": -2.5018720626831055,
      "logits/rejected": -2.3283660411834717,
      "logps/chosen": -103.42252349853516,
      "logps/rejected": -96.73359680175781,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5195846557617188,
      "rewards/margins": 7.01438045501709,
      "rewards/rejected": -6.494795799255371,
      "step": 4722
    },
    {
      "epoch": 1.8892,
      "grad_norm": 0.003914341330528259,
      "learning_rate": 3.704e-07,
      "logits/chosen": -2.3991260528564453,
      "logits/rejected": -1.6510928869247437,
      "logps/chosen": -114.6153335571289,
      "logps/rejected": -205.48162841796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2003930807113647,
      "rewards/margins": 12.766838073730469,
      "rewards/rejected": -11.566444396972656,
      "step": 4723
    },
    {
      "epoch": 1.8896,
      "grad_norm": 0.0205085426568985,
      "learning_rate": 3.7026666666666667e-07,
      "logits/chosen": -2.529587745666504,
      "logits/rejected": -1.6037745475769043,
      "logps/chosen": -94.33747863769531,
      "logps/rejected": -158.77159118652344,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0267086029052734,
      "rewards/margins": 11.91005802154541,
      "rewards/rejected": -9.883349418640137,
      "step": 4724
    },
    {
      "epoch": 1.8900000000000001,
      "grad_norm": 0.004618719685822725,
      "learning_rate": 3.701333333333333e-07,
      "logits/chosen": -2.6323580741882324,
      "logits/rejected": -2.325859546661377,
      "logps/chosen": -54.92131042480469,
      "logps/rejected": -167.00137329101562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.083443284034729,
      "rewards/margins": 13.144170761108398,
      "rewards/rejected": -12.060728073120117,
      "step": 4725
    },
    {
      "epoch": 1.8904,
      "grad_norm": 0.461739718914032,
      "learning_rate": 3.7e-07,
      "logits/chosen": -2.7472124099731445,
      "logits/rejected": -2.245542287826538,
      "logps/chosen": -123.4727783203125,
      "logps/rejected": -164.31243896484375,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.48670196533203125,
      "rewards/margins": 9.802959442138672,
      "rewards/rejected": -9.31625747680664,
      "step": 4726
    },
    {
      "epoch": 1.8908,
      "grad_norm": 0.08835471421480179,
      "learning_rate": 3.6986666666666664e-07,
      "logits/chosen": -2.8150970935821533,
      "logits/rejected": -2.405320405960083,
      "logps/chosen": -99.26309204101562,
      "logps/rejected": -146.1060333251953,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5026432275772095,
      "rewards/margins": 8.998005867004395,
      "rewards/rejected": -9.500649452209473,
      "step": 4727
    },
    {
      "epoch": 1.8912,
      "grad_norm": 0.02169124409556389,
      "learning_rate": 3.6973333333333334e-07,
      "logits/chosen": -3.0865533351898193,
      "logits/rejected": -2.6206629276275635,
      "logps/chosen": -78.99169158935547,
      "logps/rejected": -99.16841888427734,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7832481861114502,
      "rewards/margins": 8.951044082641602,
      "rewards/rejected": -7.167795658111572,
      "step": 4728
    },
    {
      "epoch": 1.8916,
      "grad_norm": 0.0039443159475922585,
      "learning_rate": 3.696e-07,
      "logits/chosen": -2.8056278228759766,
      "logits/rejected": -2.198579788208008,
      "logps/chosen": -84.75350189208984,
      "logps/rejected": -212.0283966064453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1438247710466385,
      "rewards/margins": 12.910664558410645,
      "rewards/rejected": -13.054489135742188,
      "step": 4729
    },
    {
      "epoch": 1.892,
      "grad_norm": 3.7787771224975586,
      "learning_rate": 3.6946666666666667e-07,
      "logits/chosen": -2.657968282699585,
      "logits/rejected": -2.5384206771850586,
      "logps/chosen": -120.83848571777344,
      "logps/rejected": -170.0452423095703,
      "loss": 0.0109,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0328540802001953,
      "rewards/margins": 7.301722049713135,
      "rewards/rejected": -9.334575653076172,
      "step": 4730
    },
    {
      "epoch": 1.8923999999999999,
      "grad_norm": 6.805291652679443,
      "learning_rate": 3.693333333333333e-07,
      "logits/chosen": -2.423581838607788,
      "logits/rejected": -2.095151424407959,
      "logps/chosen": -208.53536987304688,
      "logps/rejected": -143.87667846679688,
      "loss": 0.0266,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.5070457458496094,
      "rewards/margins": 5.823728561401367,
      "rewards/rejected": -8.330774307250977,
      "step": 4731
    },
    {
      "epoch": 1.8928,
      "grad_norm": 0.009563494473695755,
      "learning_rate": 3.6919999999999994e-07,
      "logits/chosen": -2.8380584716796875,
      "logits/rejected": -2.011136531829834,
      "logps/chosen": -105.13957214355469,
      "logps/rejected": -137.3604278564453,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1929004192352295,
      "rewards/margins": 9.852900505065918,
      "rewards/rejected": -8.65999984741211,
      "step": 4732
    },
    {
      "epoch": 1.8932,
      "grad_norm": 0.22917218506336212,
      "learning_rate": 3.6906666666666664e-07,
      "logits/chosen": -3.010450601577759,
      "logits/rejected": -2.725320339202881,
      "logps/chosen": -106.35263061523438,
      "logps/rejected": -133.51466369628906,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.193016767501831,
      "rewards/margins": 7.763669490814209,
      "rewards/rejected": -8.956686019897461,
      "step": 4733
    },
    {
      "epoch": 1.8936,
      "grad_norm": 0.034977175295352936,
      "learning_rate": 3.6893333333333333e-07,
      "logits/chosen": -2.9544906616210938,
      "logits/rejected": -2.67398738861084,
      "logps/chosen": -93.37085723876953,
      "logps/rejected": -124.44023132324219,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4316568672657013,
      "rewards/margins": 8.565589904785156,
      "rewards/rejected": -8.133933067321777,
      "step": 4734
    },
    {
      "epoch": 1.8940000000000001,
      "grad_norm": 0.24626104533672333,
      "learning_rate": 3.688e-07,
      "logits/chosen": -2.903902053833008,
      "logits/rejected": -2.5962486267089844,
      "logps/chosen": -92.1983871459961,
      "logps/rejected": -122.38511657714844,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0065033435821533,
      "rewards/margins": 7.043037414550781,
      "rewards/rejected": -8.049541473388672,
      "step": 4735
    },
    {
      "epoch": 1.8944,
      "grad_norm": 0.04207771643996239,
      "learning_rate": 3.686666666666666e-07,
      "logits/chosen": -2.3510661125183105,
      "logits/rejected": -1.7100169658660889,
      "logps/chosen": -190.08145141601562,
      "logps/rejected": -183.6217498779297,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.421830892562866,
      "rewards/margins": 10.492737770080566,
      "rewards/rejected": -12.914568901062012,
      "step": 4736
    },
    {
      "epoch": 1.8948,
      "grad_norm": 0.25945913791656494,
      "learning_rate": 3.685333333333333e-07,
      "logits/chosen": -2.664701461791992,
      "logits/rejected": -2.538578510284424,
      "logps/chosen": -56.362571716308594,
      "logps/rejected": -126.14391326904297,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8023183941841125,
      "rewards/margins": 8.706117630004883,
      "rewards/rejected": -7.903799057006836,
      "step": 4737
    },
    {
      "epoch": 1.8952,
      "grad_norm": 0.00530247250571847,
      "learning_rate": 3.684e-07,
      "logits/chosen": -2.635334014892578,
      "logits/rejected": -2.2814249992370605,
      "logps/chosen": -93.24003601074219,
      "logps/rejected": -190.39076232910156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.031396508216858,
      "rewards/margins": 13.297647476196289,
      "rewards/rejected": -12.266250610351562,
      "step": 4738
    },
    {
      "epoch": 1.8956,
      "grad_norm": 0.01705356128513813,
      "learning_rate": 3.682666666666667e-07,
      "logits/chosen": -2.80861234664917,
      "logits/rejected": -2.5296566486358643,
      "logps/chosen": -92.03990936279297,
      "logps/rejected": -142.579833984375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.24466687440872192,
      "rewards/margins": 9.366632461547852,
      "rewards/rejected": -9.611299514770508,
      "step": 4739
    },
    {
      "epoch": 1.896,
      "grad_norm": 47.09217834472656,
      "learning_rate": 3.681333333333333e-07,
      "logits/chosen": -2.723487377166748,
      "logits/rejected": -2.826117515563965,
      "logps/chosen": -91.68586730957031,
      "logps/rejected": -65.21408081054688,
      "loss": 0.3126,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7311694622039795,
      "rewards/margins": 2.6913132667541504,
      "rewards/rejected": -4.422482967376709,
      "step": 4740
    },
    {
      "epoch": 1.8963999999999999,
      "grad_norm": 0.023209111765027046,
      "learning_rate": 3.6799999999999996e-07,
      "logits/chosen": -2.6601827144622803,
      "logits/rejected": -1.8994109630584717,
      "logps/chosen": -136.8839874267578,
      "logps/rejected": -148.8487548828125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6164195537567139,
      "rewards/margins": 9.690629959106445,
      "rewards/rejected": -9.074209213256836,
      "step": 4741
    },
    {
      "epoch": 1.8968,
      "grad_norm": 0.002748588565737009,
      "learning_rate": 3.6786666666666665e-07,
      "logits/chosen": -2.6232898235321045,
      "logits/rejected": -1.9600995779037476,
      "logps/chosen": -128.97543334960938,
      "logps/rejected": -287.737548828125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5098960399627686,
      "rewards/margins": 14.706494331359863,
      "rewards/rejected": -13.196598052978516,
      "step": 4742
    },
    {
      "epoch": 1.8972,
      "grad_norm": 0.47679147124290466,
      "learning_rate": 3.6773333333333334e-07,
      "logits/chosen": -2.5963339805603027,
      "logits/rejected": -1.8242456912994385,
      "logps/chosen": -86.1004638671875,
      "logps/rejected": -152.73077392578125,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20277255773544312,
      "rewards/margins": 10.114030838012695,
      "rewards/rejected": -9.911258697509766,
      "step": 4743
    },
    {
      "epoch": 1.8976,
      "grad_norm": 0.15494997799396515,
      "learning_rate": 3.676e-07,
      "logits/chosen": -2.568058967590332,
      "logits/rejected": -2.1160049438476562,
      "logps/chosen": -143.82351684570312,
      "logps/rejected": -138.39283752441406,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0479484498500824,
      "rewards/margins": 9.421967506408691,
      "rewards/rejected": -9.469915390014648,
      "step": 4744
    },
    {
      "epoch": 1.8980000000000001,
      "grad_norm": 0.014375553466379642,
      "learning_rate": 3.674666666666666e-07,
      "logits/chosen": -2.6648032665252686,
      "logits/rejected": -2.1396279335021973,
      "logps/chosen": -67.87797546386719,
      "logps/rejected": -165.50225830078125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4230769872665405,
      "rewards/margins": 11.539159774780273,
      "rewards/rejected": -11.116083145141602,
      "step": 4745
    },
    {
      "epoch": 1.8984,
      "grad_norm": 0.010931815020740032,
      "learning_rate": 3.673333333333333e-07,
      "logits/chosen": -2.858348846435547,
      "logits/rejected": -2.371734857559204,
      "logps/chosen": -92.77124786376953,
      "logps/rejected": -256.2456970214844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1892168521881104,
      "rewards/margins": 14.134384155273438,
      "rewards/rejected": -15.323600769042969,
      "step": 4746
    },
    {
      "epoch": 1.8988,
      "grad_norm": 0.08452879637479782,
      "learning_rate": 3.672e-07,
      "logits/chosen": -2.4263625144958496,
      "logits/rejected": -1.9926402568817139,
      "logps/chosen": -199.64706420898438,
      "logps/rejected": -149.39073181152344,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7146469354629517,
      "rewards/margins": 7.670474052429199,
      "rewards/rejected": -9.38512134552002,
      "step": 4747
    },
    {
      "epoch": 1.8992,
      "grad_norm": 0.009200461208820343,
      "learning_rate": 3.6706666666666664e-07,
      "logits/chosen": -2.6282992362976074,
      "logits/rejected": -2.3154871463775635,
      "logps/chosen": -60.81593322753906,
      "logps/rejected": -138.85960388183594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3017075061798096,
      "rewards/margins": 10.155795097351074,
      "rewards/rejected": -8.854087829589844,
      "step": 4748
    },
    {
      "epoch": 1.8996,
      "grad_norm": 1.667091965675354,
      "learning_rate": 3.6693333333333334e-07,
      "logits/chosen": -2.768071174621582,
      "logits/rejected": -2.550140619277954,
      "logps/chosen": -151.61441040039062,
      "logps/rejected": -129.1348876953125,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.966532588005066,
      "rewards/margins": 6.19601583480835,
      "rewards/rejected": -8.162548065185547,
      "step": 4749
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.9233338832855225,
      "learning_rate": 3.668e-07,
      "logits/chosen": -2.684840679168701,
      "logits/rejected": -2.907778263092041,
      "logps/chosen": -62.055389404296875,
      "logps/rejected": -182.08432006835938,
      "loss": 0.011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6243829727172852,
      "rewards/margins": 7.751208305358887,
      "rewards/rejected": -8.375591278076172,
      "step": 4750
    },
    {
      "epoch": 1.9003999999999999,
      "grad_norm": 0.33996450901031494,
      "learning_rate": 3.666666666666666e-07,
      "logits/chosen": -2.8491873741149902,
      "logits/rejected": -2.936756134033203,
      "logps/chosen": -113.26953887939453,
      "logps/rejected": -118.6529541015625,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.2291171550750732,
      "rewards/margins": 6.051492214202881,
      "rewards/rejected": -8.280609130859375,
      "step": 4751
    },
    {
      "epoch": 1.9008,
      "grad_norm": 0.06604352593421936,
      "learning_rate": 3.665333333333333e-07,
      "logits/chosen": -2.117604970932007,
      "logits/rejected": -1.263758897781372,
      "logps/chosen": -163.52938842773438,
      "logps/rejected": -208.95196533203125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2619954347610474,
      "rewards/margins": 10.573162078857422,
      "rewards/rejected": -11.83515739440918,
      "step": 4752
    },
    {
      "epoch": 1.9012,
      "grad_norm": 0.07682037353515625,
      "learning_rate": 3.664e-07,
      "logits/chosen": -2.604720115661621,
      "logits/rejected": -1.9269566535949707,
      "logps/chosen": -135.46066284179688,
      "logps/rejected": -203.1407012939453,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.45057445764541626,
      "rewards/margins": 10.865171432495117,
      "rewards/rejected": -11.315746307373047,
      "step": 4753
    },
    {
      "epoch": 1.9016,
      "grad_norm": 0.4487609267234802,
      "learning_rate": 3.662666666666667e-07,
      "logits/chosen": -2.835413932800293,
      "logits/rejected": -2.9009084701538086,
      "logps/chosen": -76.15081024169922,
      "logps/rejected": -102.79182434082031,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.25423678755760193,
      "rewards/margins": 6.561641693115234,
      "rewards/rejected": -6.815877914428711,
      "step": 4754
    },
    {
      "epoch": 1.9020000000000001,
      "grad_norm": 0.0008612991077825427,
      "learning_rate": 3.661333333333333e-07,
      "logits/chosen": -2.6110687255859375,
      "logits/rejected": -2.2209200859069824,
      "logps/chosen": -89.79815673828125,
      "logps/rejected": -209.06488037109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5997310876846313,
      "rewards/margins": 14.867864608764648,
      "rewards/rejected": -13.268133163452148,
      "step": 4755
    },
    {
      "epoch": 1.9024,
      "grad_norm": 0.0015102396719157696,
      "learning_rate": 3.6599999999999997e-07,
      "logits/chosen": -2.7021169662475586,
      "logits/rejected": -1.8165864944458008,
      "logps/chosen": -90.09542846679688,
      "logps/rejected": -193.16845703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.896265983581543,
      "rewards/margins": 14.594329833984375,
      "rewards/rejected": -13.698064804077148,
      "step": 4756
    },
    {
      "epoch": 1.9028,
      "grad_norm": 0.0014208473730832338,
      "learning_rate": 3.6586666666666666e-07,
      "logits/chosen": -2.721881866455078,
      "logits/rejected": -1.9351835250854492,
      "logps/chosen": -94.35481262207031,
      "logps/rejected": -183.6011505126953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34243375062942505,
      "rewards/margins": 12.104945182800293,
      "rewards/rejected": -11.762511253356934,
      "step": 4757
    },
    {
      "epoch": 1.9032,
      "grad_norm": 0.18361715972423553,
      "learning_rate": 3.6573333333333335e-07,
      "logits/chosen": -2.469360589981079,
      "logits/rejected": -2.118168354034424,
      "logps/chosen": -115.54985046386719,
      "logps/rejected": -136.72268676757812,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.506737470626831,
      "rewards/margins": 7.272768974304199,
      "rewards/rejected": -8.77950668334961,
      "step": 4758
    },
    {
      "epoch": 1.9036,
      "grad_norm": 0.008425742387771606,
      "learning_rate": 3.6559999999999994e-07,
      "logits/chosen": -2.419376850128174,
      "logits/rejected": -2.0636982917785645,
      "logps/chosen": -87.98821258544922,
      "logps/rejected": -185.72894287109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2641807794570923,
      "rewards/margins": 13.334898948669434,
      "rewards/rejected": -12.070718765258789,
      "step": 4759
    },
    {
      "epoch": 1.904,
      "grad_norm": 0.1383625715970993,
      "learning_rate": 3.6546666666666663e-07,
      "logits/chosen": -2.5809173583984375,
      "logits/rejected": -2.02781343460083,
      "logps/chosen": -180.3280029296875,
      "logps/rejected": -160.45620727539062,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5471944808959961,
      "rewards/margins": 9.296318054199219,
      "rewards/rejected": -9.843513488769531,
      "step": 4760
    },
    {
      "epoch": 1.9043999999999999,
      "grad_norm": 0.00017463663243688643,
      "learning_rate": 3.653333333333333e-07,
      "logits/chosen": -2.6115336418151855,
      "logits/rejected": -1.7523952722549438,
      "logps/chosen": -145.20822143554688,
      "logps/rejected": -259.94891357421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.226816177368164,
      "rewards/margins": 14.50374984741211,
      "rewards/rejected": -16.730566024780273,
      "step": 4761
    },
    {
      "epoch": 1.9048,
      "grad_norm": 5.416380882263184,
      "learning_rate": 3.652e-07,
      "logits/chosen": -2.450320243835449,
      "logits/rejected": -2.22678804397583,
      "logps/chosen": -218.86831665039062,
      "logps/rejected": -171.27035522460938,
      "loss": 0.0228,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.354306697845459,
      "rewards/margins": 4.9302239418029785,
      "rewards/rejected": -11.284530639648438,
      "step": 4762
    },
    {
      "epoch": 1.9052,
      "grad_norm": 0.04764975979924202,
      "learning_rate": 3.6506666666666665e-07,
      "logits/chosen": -2.7555432319641113,
      "logits/rejected": -2.241379499435425,
      "logps/chosen": -49.261661529541016,
      "logps/rejected": -117.35440063476562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.150871515274048,
      "rewards/margins": 8.802392959594727,
      "rewards/rejected": -6.651521682739258,
      "step": 4763
    },
    {
      "epoch": 1.9056,
      "grad_norm": 0.042578551918268204,
      "learning_rate": 3.649333333333333e-07,
      "logits/chosen": -3.045440673828125,
      "logits/rejected": -2.6474533081054688,
      "logps/chosen": -54.54935073852539,
      "logps/rejected": -136.6935272216797,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8977898359298706,
      "rewards/margins": 9.578468322753906,
      "rewards/rejected": -8.680678367614746,
      "step": 4764
    },
    {
      "epoch": 1.9060000000000001,
      "grad_norm": 0.06753722578287125,
      "learning_rate": 3.648e-07,
      "logits/chosen": -2.6739118099212646,
      "logits/rejected": -2.5407602787017822,
      "logps/chosen": -92.96888732910156,
      "logps/rejected": -125.32569885253906,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1333160400390625,
      "rewards/margins": 8.559696197509766,
      "rewards/rejected": -8.426380157470703,
      "step": 4765
    },
    {
      "epoch": 1.9064,
      "grad_norm": 0.09899183362722397,
      "learning_rate": 3.646666666666666e-07,
      "logits/chosen": -2.8827247619628906,
      "logits/rejected": -2.556422233581543,
      "logps/chosen": -47.841400146484375,
      "logps/rejected": -133.80615234375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7281904220581055,
      "rewards/margins": 9.921836853027344,
      "rewards/rejected": -9.193645477294922,
      "step": 4766
    },
    {
      "epoch": 1.9068,
      "grad_norm": 0.0027967465575784445,
      "learning_rate": 3.645333333333333e-07,
      "logits/chosen": -2.317227840423584,
      "logits/rejected": -1.9638230800628662,
      "logps/chosen": -145.48451232910156,
      "logps/rejected": -269.90252685546875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09054451435804367,
      "rewards/margins": 11.736844062805176,
      "rewards/rejected": -11.646299362182617,
      "step": 4767
    },
    {
      "epoch": 1.9072,
      "grad_norm": 0.3994225561618805,
      "learning_rate": 3.644e-07,
      "logits/chosen": -2.5480751991271973,
      "logits/rejected": -1.9373655319213867,
      "logps/chosen": -92.55410766601562,
      "logps/rejected": -236.666015625,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7735538482666016,
      "rewards/margins": 11.668663024902344,
      "rewards/rejected": -12.442217826843262,
      "step": 4768
    },
    {
      "epoch": 1.9076,
      "grad_norm": 0.03194447234272957,
      "learning_rate": 3.6426666666666665e-07,
      "logits/chosen": -2.955386161804199,
      "logits/rejected": -2.4993343353271484,
      "logps/chosen": -83.72749328613281,
      "logps/rejected": -173.15121459960938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.585244357585907,
      "rewards/margins": 11.722816467285156,
      "rewards/rejected": -11.137571334838867,
      "step": 4769
    },
    {
      "epoch": 1.908,
      "grad_norm": 0.008542665280401707,
      "learning_rate": 3.641333333333333e-07,
      "logits/chosen": -2.6333823204040527,
      "logits/rejected": -2.4126574993133545,
      "logps/chosen": -134.98223876953125,
      "logps/rejected": -200.41766357421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.938460111618042,
      "rewards/margins": 10.294357299804688,
      "rewards/rejected": -12.232817649841309,
      "step": 4770
    },
    {
      "epoch": 1.9083999999999999,
      "grad_norm": 4.015222549438477,
      "learning_rate": 3.64e-07,
      "logits/chosen": -2.6554603576660156,
      "logits/rejected": -2.2429113388061523,
      "logps/chosen": -110.86471557617188,
      "logps/rejected": -146.59130859375,
      "loss": 0.0233,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.240168809890747,
      "rewards/margins": 6.805479049682617,
      "rewards/rejected": -8.045647621154785,
      "step": 4771
    },
    {
      "epoch": 1.9088,
      "grad_norm": 0.3268719017505646,
      "learning_rate": 3.6386666666666667e-07,
      "logits/chosen": -3.016075611114502,
      "logits/rejected": -2.3475356101989746,
      "logps/chosen": -92.71209716796875,
      "logps/rejected": -247.3038787841797,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7276945114135742,
      "rewards/margins": 13.17170238494873,
      "rewards/rejected": -13.899396896362305,
      "step": 4772
    },
    {
      "epoch": 1.9092,
      "grad_norm": 0.018484922125935555,
      "learning_rate": 3.6373333333333336e-07,
      "logits/chosen": -2.712127923965454,
      "logits/rejected": -2.31009578704834,
      "logps/chosen": -139.81265258789062,
      "logps/rejected": -234.25595092773438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3686420917510986,
      "rewards/margins": 10.951780319213867,
      "rewards/rejected": -12.320422172546387,
      "step": 4773
    },
    {
      "epoch": 1.9096,
      "grad_norm": 0.0028814193792641163,
      "learning_rate": 3.6359999999999995e-07,
      "logits/chosen": -2.954021453857422,
      "logits/rejected": -2.6506428718566895,
      "logps/chosen": -99.00071716308594,
      "logps/rejected": -161.34466552734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42143136262893677,
      "rewards/margins": 11.27474594116211,
      "rewards/rejected": -10.853315353393555,
      "step": 4774
    },
    {
      "epoch": 1.9100000000000001,
      "grad_norm": 0.3326748311519623,
      "learning_rate": 3.6346666666666664e-07,
      "logits/chosen": -2.679330348968506,
      "logits/rejected": -2.4840784072875977,
      "logps/chosen": -147.647216796875,
      "logps/rejected": -177.1138916015625,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.033195972442627,
      "rewards/margins": 8.811517715454102,
      "rewards/rejected": -10.844714164733887,
      "step": 4775
    },
    {
      "epoch": 1.9104,
      "grad_norm": 0.058706220239400864,
      "learning_rate": 3.6333333333333333e-07,
      "logits/chosen": -2.611635208129883,
      "logits/rejected": -2.1424922943115234,
      "logps/chosen": -108.03945922851562,
      "logps/rejected": -232.92019653320312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7380084991455078,
      "rewards/margins": 11.744806289672852,
      "rewards/rejected": -11.006797790527344,
      "step": 4776
    },
    {
      "epoch": 1.9108,
      "grad_norm": 0.8239785432815552,
      "learning_rate": 3.632e-07,
      "logits/chosen": -2.7774763107299805,
      "logits/rejected": -2.499390125274658,
      "logps/chosen": -85.8520278930664,
      "logps/rejected": -229.57669067382812,
      "loss": 0.0045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.974399983882904,
      "rewards/margins": 11.883148193359375,
      "rewards/rejected": -12.857548713684082,
      "step": 4777
    },
    {
      "epoch": 1.9112,
      "grad_norm": 17.62148666381836,
      "learning_rate": 3.630666666666666e-07,
      "logits/chosen": -2.6267337799072266,
      "logits/rejected": -2.301791191101074,
      "logps/chosen": -124.65568542480469,
      "logps/rejected": -124.03974151611328,
      "loss": 0.0866,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8515918850898743,
      "rewards/margins": 6.954704761505127,
      "rewards/rejected": -7.806296348571777,
      "step": 4778
    },
    {
      "epoch": 1.9116,
      "grad_norm": 0.004673913586884737,
      "learning_rate": 3.629333333333333e-07,
      "logits/chosen": -2.49605393409729,
      "logits/rejected": -1.7380768060684204,
      "logps/chosen": -101.24226379394531,
      "logps/rejected": -170.65342712402344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.12200665473938,
      "rewards/margins": 12.816213607788086,
      "rewards/rejected": -10.694206237792969,
      "step": 4779
    },
    {
      "epoch": 1.912,
      "grad_norm": 0.00010357708379160613,
      "learning_rate": 3.628e-07,
      "logits/chosen": -2.8219943046569824,
      "logits/rejected": -2.148918390274048,
      "logps/chosen": -142.85220336914062,
      "logps/rejected": -238.43505859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.04431113600730896,
      "rewards/margins": 15.824630737304688,
      "rewards/rejected": -15.868941307067871,
      "step": 4780
    },
    {
      "epoch": 1.9123999999999999,
      "grad_norm": 19.343219757080078,
      "learning_rate": 3.626666666666667e-07,
      "logits/chosen": -2.9106407165527344,
      "logits/rejected": -2.6522390842437744,
      "logps/chosen": -78.06205749511719,
      "logps/rejected": -79.63158416748047,
      "loss": 0.1223,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8092666864395142,
      "rewards/margins": 3.912214756011963,
      "rewards/rejected": -4.7214813232421875,
      "step": 4781
    },
    {
      "epoch": 1.9127999999999998,
      "grad_norm": 0.008137332275509834,
      "learning_rate": 3.625333333333333e-07,
      "logits/chosen": -2.883279800415039,
      "logits/rejected": -2.3612680435180664,
      "logps/chosen": -117.14464569091797,
      "logps/rejected": -179.29803466796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9154819250106812,
      "rewards/margins": 10.492019653320312,
      "rewards/rejected": -11.407501220703125,
      "step": 4782
    },
    {
      "epoch": 1.9132,
      "grad_norm": 0.70736163854599,
      "learning_rate": 3.6239999999999996e-07,
      "logits/chosen": -2.8473730087280273,
      "logits/rejected": -2.753885507583618,
      "logps/chosen": -94.15950775146484,
      "logps/rejected": -105.93431091308594,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2890239953994751,
      "rewards/margins": 5.942518711090088,
      "rewards/rejected": -5.653494834899902,
      "step": 4783
    },
    {
      "epoch": 1.9136,
      "grad_norm": 0.037145812064409256,
      "learning_rate": 3.6226666666666665e-07,
      "logits/chosen": -2.484011173248291,
      "logits/rejected": -1.9226841926574707,
      "logps/chosen": -226.01834106445312,
      "logps/rejected": -226.32748413085938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.897629499435425,
      "rewards/margins": 13.709272384643555,
      "rewards/rejected": -16.606903076171875,
      "step": 4784
    },
    {
      "epoch": 1.9140000000000001,
      "grad_norm": 0.0006078192382119596,
      "learning_rate": 3.621333333333333e-07,
      "logits/chosen": -2.5720467567443848,
      "logits/rejected": -1.9272420406341553,
      "logps/chosen": -78.17401123046875,
      "logps/rejected": -188.83628845214844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.737687349319458,
      "rewards/margins": 13.270383834838867,
      "rewards/rejected": -11.532696723937988,
      "step": 4785
    },
    {
      "epoch": 1.9144,
      "grad_norm": 0.0020439685322344303,
      "learning_rate": 3.62e-07,
      "logits/chosen": -2.5304055213928223,
      "logits/rejected": -2.2110650539398193,
      "logps/chosen": -53.4542121887207,
      "logps/rejected": -155.78738403320312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5562379360198975,
      "rewards/margins": 12.623425483703613,
      "rewards/rejected": -11.067188262939453,
      "step": 4786
    },
    {
      "epoch": 1.9148,
      "grad_norm": 0.011517820879817009,
      "learning_rate": 3.618666666666667e-07,
      "logits/chosen": -2.7881062030792236,
      "logits/rejected": -2.534320592880249,
      "logps/chosen": -64.63873291015625,
      "logps/rejected": -189.9723358154297,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7469898462295532,
      "rewards/margins": 13.625850677490234,
      "rewards/rejected": -12.878860473632812,
      "step": 4787
    },
    {
      "epoch": 1.9152,
      "grad_norm": 0.48131856322288513,
      "learning_rate": 3.617333333333333e-07,
      "logits/chosen": -3.138720989227295,
      "logits/rejected": -3.281435012817383,
      "logps/chosen": -83.36105346679688,
      "logps/rejected": -140.3719940185547,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9435697793960571,
      "rewards/margins": 6.8983964920043945,
      "rewards/rejected": -8.84196662902832,
      "step": 4788
    },
    {
      "epoch": 1.9156,
      "grad_norm": 0.002119878539815545,
      "learning_rate": 3.6159999999999996e-07,
      "logits/chosen": -2.5748348236083984,
      "logits/rejected": -2.1527340412139893,
      "logps/chosen": -150.07284545898438,
      "logps/rejected": -258.009765625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4060455560684204,
      "rewards/margins": 12.120734214782715,
      "rewards/rejected": -13.526779174804688,
      "step": 4789
    },
    {
      "epoch": 1.916,
      "grad_norm": 0.027579186484217644,
      "learning_rate": 3.6146666666666665e-07,
      "logits/chosen": -2.603266716003418,
      "logits/rejected": -2.075568914413452,
      "logps/chosen": -108.68489837646484,
      "logps/rejected": -166.31179809570312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7167148590087891,
      "rewards/margins": 10.79930305480957,
      "rewards/rejected": -10.082588195800781,
      "step": 4790
    },
    {
      "epoch": 1.9163999999999999,
      "grad_norm": 0.04582234099507332,
      "learning_rate": 3.6133333333333334e-07,
      "logits/chosen": -3.0898594856262207,
      "logits/rejected": -3.02549409866333,
      "logps/chosen": -44.9703369140625,
      "logps/rejected": -97.67437744140625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2803349494934082,
      "rewards/margins": 8.230816841125488,
      "rewards/rejected": -6.950482368469238,
      "step": 4791
    },
    {
      "epoch": 1.9167999999999998,
      "grad_norm": 0.29564812779426575,
      "learning_rate": 3.612e-07,
      "logits/chosen": -2.6630897521972656,
      "logits/rejected": -2.334865093231201,
      "logps/chosen": -106.30780792236328,
      "logps/rejected": -207.06553649902344,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.36811619997024536,
      "rewards/margins": 11.600948333740234,
      "rewards/rejected": -11.969063758850098,
      "step": 4792
    },
    {
      "epoch": 1.9172,
      "grad_norm": 0.017121585085988045,
      "learning_rate": 3.610666666666666e-07,
      "logits/chosen": -3.000617027282715,
      "logits/rejected": -2.679053783416748,
      "logps/chosen": -52.05271530151367,
      "logps/rejected": -138.2847900390625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2428206205368042,
      "rewards/margins": 9.94559097290039,
      "rewards/rejected": -8.702770233154297,
      "step": 4793
    },
    {
      "epoch": 1.9176,
      "grad_norm": 0.6777088046073914,
      "learning_rate": 3.609333333333333e-07,
      "logits/chosen": -3.078641891479492,
      "logits/rejected": -2.777564525604248,
      "logps/chosen": -61.073509216308594,
      "logps/rejected": -101.409912109375,
      "loss": 0.0064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.06834906339645386,
      "rewards/margins": 6.144671440124512,
      "rewards/rejected": -6.2130208015441895,
      "step": 4794
    },
    {
      "epoch": 1.9180000000000001,
      "grad_norm": 0.07201769202947617,
      "learning_rate": 3.608e-07,
      "logits/chosen": -3.0036871433258057,
      "logits/rejected": -2.509059429168701,
      "logps/chosen": -49.151058197021484,
      "logps/rejected": -144.47235107421875,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7267400622367859,
      "rewards/margins": 10.53406810760498,
      "rewards/rejected": -9.807328224182129,
      "step": 4795
    },
    {
      "epoch": 1.9184,
      "grad_norm": 0.01073865219950676,
      "learning_rate": 3.606666666666667e-07,
      "logits/chosen": -2.5197906494140625,
      "logits/rejected": -1.8541532754898071,
      "logps/chosen": -150.8777313232422,
      "logps/rejected": -143.7415008544922,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3367787003517151,
      "rewards/margins": 9.726692199707031,
      "rewards/rejected": -10.063470840454102,
      "step": 4796
    },
    {
      "epoch": 1.9188,
      "grad_norm": 0.36354151368141174,
      "learning_rate": 3.605333333333333e-07,
      "logits/chosen": -3.0075807571411133,
      "logits/rejected": -2.371429920196533,
      "logps/chosen": -69.59429168701172,
      "logps/rejected": -221.8817596435547,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.020501732826233,
      "rewards/margins": 15.45781135559082,
      "rewards/rejected": -14.437309265136719,
      "step": 4797
    },
    {
      "epoch": 1.9192,
      "grad_norm": 0.3770638704299927,
      "learning_rate": 3.6039999999999997e-07,
      "logits/chosen": -2.9476847648620605,
      "logits/rejected": -2.445465087890625,
      "logps/chosen": -99.33891296386719,
      "logps/rejected": -144.05860900878906,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4419994354248047,
      "rewards/margins": 6.689458847045898,
      "rewards/rejected": -8.131458282470703,
      "step": 4798
    },
    {
      "epoch": 1.9196,
      "grad_norm": 0.0742376372218132,
      "learning_rate": 3.6026666666666666e-07,
      "logits/chosen": -2.5188751220703125,
      "logits/rejected": -1.9376821517944336,
      "logps/chosen": -161.18246459960938,
      "logps/rejected": -130.5554962158203,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25409775972366333,
      "rewards/margins": 7.724973678588867,
      "rewards/rejected": -7.4708757400512695,
      "step": 4799
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.0017079602694138885,
      "learning_rate": 3.6013333333333336e-07,
      "logits/chosen": -2.5615639686584473,
      "logits/rejected": -2.033740282058716,
      "logps/chosen": -143.30575561523438,
      "logps/rejected": -188.74917602539062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9643001556396484,
      "rewards/margins": 12.001559257507324,
      "rewards/rejected": -11.037259101867676,
      "step": 4800
    },
    {
      "epoch": 1.9203999999999999,
      "grad_norm": 0.09668388962745667,
      "learning_rate": 3.6e-07,
      "logits/chosen": -2.9429402351379395,
      "logits/rejected": -2.6138205528259277,
      "logps/chosen": -61.38139724731445,
      "logps/rejected": -220.6468505859375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23023033142089844,
      "rewards/margins": 14.871786117553711,
      "rewards/rejected": -14.641555786132812,
      "step": 4801
    },
    {
      "epoch": 1.9207999999999998,
      "grad_norm": 1.2268503904342651,
      "learning_rate": 3.5986666666666663e-07,
      "logits/chosen": -2.9021623134613037,
      "logits/rejected": -2.61287260055542,
      "logps/chosen": -32.692413330078125,
      "logps/rejected": -156.68360900878906,
      "loss": 0.0089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1121278703212738,
      "rewards/margins": 10.352364540100098,
      "rewards/rejected": -10.24023723602295,
      "step": 4802
    },
    {
      "epoch": 1.9212,
      "grad_norm": 0.47798410058021545,
      "learning_rate": 3.597333333333333e-07,
      "logits/chosen": -2.6685333251953125,
      "logits/rejected": -2.464376926422119,
      "logps/chosen": -140.2803192138672,
      "logps/rejected": -164.239501953125,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.0588724613189697,
      "rewards/margins": 8.537941932678223,
      "rewards/rejected": -11.59681510925293,
      "step": 4803
    },
    {
      "epoch": 1.9216,
      "grad_norm": 0.07399604469537735,
      "learning_rate": 3.5959999999999996e-07,
      "logits/chosen": -2.629464626312256,
      "logits/rejected": -2.2425127029418945,
      "logps/chosen": -73.60643005371094,
      "logps/rejected": -127.62239074707031,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5192413330078125,
      "rewards/margins": 7.628324508666992,
      "rewards/rejected": -7.10908317565918,
      "step": 4804
    },
    {
      "epoch": 1.9220000000000002,
      "grad_norm": 0.02767205983400345,
      "learning_rate": 3.5946666666666666e-07,
      "logits/chosen": -3.065474510192871,
      "logits/rejected": -2.776332378387451,
      "logps/chosen": -88.98371887207031,
      "logps/rejected": -157.72903442382812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8259357810020447,
      "rewards/margins": 10.303091049194336,
      "rewards/rejected": -9.477155685424805,
      "step": 4805
    },
    {
      "epoch": 1.9224,
      "grad_norm": 3.848130464553833,
      "learning_rate": 3.5933333333333335e-07,
      "logits/chosen": -2.9155640602111816,
      "logits/rejected": -2.5343852043151855,
      "logps/chosen": -77.48574829101562,
      "logps/rejected": -110.3968505859375,
      "loss": 0.0257,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2393728494644165,
      "rewards/margins": 6.084359645843506,
      "rewards/rejected": -7.323732376098633,
      "step": 4806
    },
    {
      "epoch": 1.9228,
      "grad_norm": 0.024874797090888023,
      "learning_rate": 3.592e-07,
      "logits/chosen": -3.149787425994873,
      "logits/rejected": -2.7228198051452637,
      "logps/chosen": -56.356109619140625,
      "logps/rejected": -133.51783752441406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24918079376220703,
      "rewards/margins": 8.869763374328613,
      "rewards/rejected": -8.620582580566406,
      "step": 4807
    },
    {
      "epoch": 1.9232,
      "grad_norm": 0.002590821823105216,
      "learning_rate": 3.590666666666666e-07,
      "logits/chosen": -2.3616952896118164,
      "logits/rejected": -1.910203456878662,
      "logps/chosen": -89.5020751953125,
      "logps/rejected": -191.93960571289062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9059818387031555,
      "rewards/margins": 12.178630828857422,
      "rewards/rejected": -11.272649765014648,
      "step": 4808
    },
    {
      "epoch": 1.9236,
      "grad_norm": 0.0005068348837085068,
      "learning_rate": 3.589333333333333e-07,
      "logits/chosen": -2.510171890258789,
      "logits/rejected": -1.9043445587158203,
      "logps/chosen": -89.67096710205078,
      "logps/rejected": -203.37954711914062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.069183349609375,
      "rewards/margins": 14.369647979736328,
      "rewards/rejected": -13.300464630126953,
      "step": 4809
    },
    {
      "epoch": 1.924,
      "grad_norm": 0.7487406730651855,
      "learning_rate": 3.588e-07,
      "logits/chosen": -2.8201258182525635,
      "logits/rejected": -2.0454344749450684,
      "logps/chosen": -151.87486267089844,
      "logps/rejected": -180.94558715820312,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.2191965579986572,
      "rewards/margins": 9.789056777954102,
      "rewards/rejected": -13.00825309753418,
      "step": 4810
    },
    {
      "epoch": 1.9243999999999999,
      "grad_norm": 0.0011565809836611152,
      "learning_rate": 3.5866666666666665e-07,
      "logits/chosen": -2.3472063541412354,
      "logits/rejected": -1.3665664196014404,
      "logps/chosen": -116.64029693603516,
      "logps/rejected": -228.2445526123047,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.29073941707611084,
      "rewards/margins": 14.184810638427734,
      "rewards/rejected": -13.894071578979492,
      "step": 4811
    },
    {
      "epoch": 1.9247999999999998,
      "grad_norm": 25.63616371154785,
      "learning_rate": 3.585333333333333e-07,
      "logits/chosen": -2.4923806190490723,
      "logits/rejected": -2.2290592193603516,
      "logps/chosen": -151.10064697265625,
      "logps/rejected": -173.32643127441406,
      "loss": 0.0914,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.3827598094940186,
      "rewards/margins": 8.105035781860352,
      "rewards/rejected": -10.48779582977295,
      "step": 4812
    },
    {
      "epoch": 1.9252,
      "grad_norm": 0.01180378906428814,
      "learning_rate": 3.584e-07,
      "logits/chosen": -2.976433277130127,
      "logits/rejected": -2.510038375854492,
      "logps/chosen": -80.1063461303711,
      "logps/rejected": -178.21495056152344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8982794284820557,
      "rewards/margins": 11.073564529418945,
      "rewards/rejected": -12.971844673156738,
      "step": 4813
    },
    {
      "epoch": 1.9256,
      "grad_norm": 0.03172438591718674,
      "learning_rate": 3.5826666666666667e-07,
      "logits/chosen": -2.7531495094299316,
      "logits/rejected": -1.9880728721618652,
      "logps/chosen": -45.889564514160156,
      "logps/rejected": -152.8881378173828,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4852405786514282,
      "rewards/margins": 10.855350494384766,
      "rewards/rejected": -9.370109558105469,
      "step": 4814
    },
    {
      "epoch": 1.9260000000000002,
      "grad_norm": 0.05935187637805939,
      "learning_rate": 3.5813333333333336e-07,
      "logits/chosen": -2.9954378604888916,
      "logits/rejected": -2.6366610527038574,
      "logps/chosen": -79.47437286376953,
      "logps/rejected": -171.88946533203125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14482572674751282,
      "rewards/margins": 11.112793922424316,
      "rewards/rejected": -10.967967987060547,
      "step": 4815
    },
    {
      "epoch": 1.9264000000000001,
      "grad_norm": 1.0383975505828857,
      "learning_rate": 3.5799999999999995e-07,
      "logits/chosen": -2.752984046936035,
      "logits/rejected": -2.1297390460968018,
      "logps/chosen": -82.12117767333984,
      "logps/rejected": -160.15501403808594,
      "loss": 0.0071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.44931259751319885,
      "rewards/margins": 10.026247024536133,
      "rewards/rejected": -9.576934814453125,
      "step": 4816
    },
    {
      "epoch": 1.9268,
      "grad_norm": 5.0359206199646,
      "learning_rate": 3.5786666666666664e-07,
      "logits/chosen": -2.0822196006774902,
      "logits/rejected": -1.6626136302947998,
      "logps/chosen": -190.66549682617188,
      "logps/rejected": -249.59298706054688,
      "loss": 0.0182,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -5.211742877960205,
      "rewards/margins": 6.748379230499268,
      "rewards/rejected": -11.960122108459473,
      "step": 4817
    },
    {
      "epoch": 1.9272,
      "grad_norm": 0.19118095934391022,
      "learning_rate": 3.5773333333333333e-07,
      "logits/chosen": -2.739905595779419,
      "logits/rejected": -2.181807041168213,
      "logps/chosen": -91.58349609375,
      "logps/rejected": -217.79449462890625,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.093794584274292,
      "rewards/margins": 12.930985450744629,
      "rewards/rejected": -14.0247802734375,
      "step": 4818
    },
    {
      "epoch": 1.9276,
      "grad_norm": 0.7770013213157654,
      "learning_rate": 3.5759999999999997e-07,
      "logits/chosen": -2.833575487136841,
      "logits/rejected": -2.660037040710449,
      "logps/chosen": -86.22865295410156,
      "logps/rejected": -128.06365966796875,
      "loss": 0.0049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.871808648109436,
      "rewards/margins": 7.531315326690674,
      "rewards/rejected": -8.40312385559082,
      "step": 4819
    },
    {
      "epoch": 1.928,
      "grad_norm": 0.0009872911032289267,
      "learning_rate": 3.5746666666666666e-07,
      "logits/chosen": -2.4613037109375,
      "logits/rejected": -1.6180009841918945,
      "logps/chosen": -103.96455383300781,
      "logps/rejected": -176.57110595703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.258136749267578,
      "rewards/margins": 12.591909408569336,
      "rewards/rejected": -10.333771705627441,
      "step": 4820
    },
    {
      "epoch": 1.9284,
      "grad_norm": 0.0008807669510133564,
      "learning_rate": 3.573333333333333e-07,
      "logits/chosen": -2.4719929695129395,
      "logits/rejected": -2.021576404571533,
      "logps/chosen": -59.18937683105469,
      "logps/rejected": -210.54421997070312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.21435587108135223,
      "rewards/margins": 12.999643325805664,
      "rewards/rejected": -13.213998794555664,
      "step": 4821
    },
    {
      "epoch": 1.9287999999999998,
      "grad_norm": 0.062406908720731735,
      "learning_rate": 3.572e-07,
      "logits/chosen": -2.803276538848877,
      "logits/rejected": -2.3735902309417725,
      "logps/chosen": -68.01457214355469,
      "logps/rejected": -142.3720703125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.30392152070999146,
      "rewards/margins": 8.472505569458008,
      "rewards/rejected": -8.776427268981934,
      "step": 4822
    },
    {
      "epoch": 1.9292,
      "grad_norm": 0.031654391437768936,
      "learning_rate": 3.5706666666666663e-07,
      "logits/chosen": -2.7401082515716553,
      "logits/rejected": -2.424421787261963,
      "logps/chosen": -77.37428283691406,
      "logps/rejected": -156.92074584960938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.49126169085502625,
      "rewards/margins": 10.89187240600586,
      "rewards/rejected": -10.400609970092773,
      "step": 4823
    },
    {
      "epoch": 1.9296,
      "grad_norm": 0.0009104376658797264,
      "learning_rate": 3.5693333333333333e-07,
      "logits/chosen": -2.9376115798950195,
      "logits/rejected": -2.2523107528686523,
      "logps/chosen": -84.090087890625,
      "logps/rejected": -288.10498046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08239185810089111,
      "rewards/margins": 16.13205337524414,
      "rewards/rejected": -16.214445114135742,
      "step": 4824
    },
    {
      "epoch": 1.9300000000000002,
      "grad_norm": 0.08986523747444153,
      "learning_rate": 3.5679999999999997e-07,
      "logits/chosen": -2.8692831993103027,
      "logits/rejected": -2.3238019943237305,
      "logps/chosen": -147.79103088378906,
      "logps/rejected": -147.39120483398438,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.32174721360206604,
      "rewards/margins": 8.397865295410156,
      "rewards/rejected": -8.719612121582031,
      "step": 4825
    },
    {
      "epoch": 1.9304000000000001,
      "grad_norm": 0.029321786016225815,
      "learning_rate": 3.5666666666666666e-07,
      "logits/chosen": -2.8082520961761475,
      "logits/rejected": -2.6645350456237793,
      "logps/chosen": -86.7587661743164,
      "logps/rejected": -149.68270874023438,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7563520669937134,
      "rewards/margins": 8.6924409866333,
      "rewards/rejected": -9.448793411254883,
      "step": 4826
    },
    {
      "epoch": 1.9308,
      "grad_norm": 0.05124364793300629,
      "learning_rate": 3.565333333333333e-07,
      "logits/chosen": -2.651426076889038,
      "logits/rejected": -2.20413875579834,
      "logps/chosen": -138.52337646484375,
      "logps/rejected": -165.59393310546875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6889435052871704,
      "rewards/margins": 9.765249252319336,
      "rewards/rejected": -10.454193115234375,
      "step": 4827
    },
    {
      "epoch": 1.9312,
      "grad_norm": 0.059886861592531204,
      "learning_rate": 3.564e-07,
      "logits/chosen": -2.6773271560668945,
      "logits/rejected": -1.773162841796875,
      "logps/chosen": -54.215415954589844,
      "logps/rejected": -147.78500366210938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7719959020614624,
      "rewards/margins": 10.291112899780273,
      "rewards/rejected": -8.519116401672363,
      "step": 4828
    },
    {
      "epoch": 1.9316,
      "grad_norm": 1.117982268333435,
      "learning_rate": 3.562666666666667e-07,
      "logits/chosen": -2.812528133392334,
      "logits/rejected": -2.6466779708862305,
      "logps/chosen": -128.24415588378906,
      "logps/rejected": -128.0223388671875,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9899585843086243,
      "rewards/margins": 7.306982517242432,
      "rewards/rejected": -8.296941757202148,
      "step": 4829
    },
    {
      "epoch": 1.932,
      "grad_norm": 0.38645821809768677,
      "learning_rate": 3.561333333333333e-07,
      "logits/chosen": -3.3416590690612793,
      "logits/rejected": -2.7200489044189453,
      "logps/chosen": -57.530818939208984,
      "logps/rejected": -148.41180419921875,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.43939292430877686,
      "rewards/margins": 10.060470581054688,
      "rewards/rejected": -10.499863624572754,
      "step": 4830
    },
    {
      "epoch": 1.9324,
      "grad_norm": 0.08231956511735916,
      "learning_rate": 3.5599999999999996e-07,
      "logits/chosen": -2.8894100189208984,
      "logits/rejected": -2.724383592605591,
      "logps/chosen": -58.47583770751953,
      "logps/rejected": -117.53096771240234,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.010981172323226929,
      "rewards/margins": 8.238410949707031,
      "rewards/rejected": -8.249391555786133,
      "step": 4831
    },
    {
      "epoch": 1.9327999999999999,
      "grad_norm": 5.811337471008301,
      "learning_rate": 3.5586666666666665e-07,
      "logits/chosen": -2.386509418487549,
      "logits/rejected": -2.1192498207092285,
      "logps/chosen": -152.19178771972656,
      "logps/rejected": -163.37796020507812,
      "loss": 0.0296,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.493859887123108,
      "rewards/margins": 8.678754806518555,
      "rewards/rejected": -10.172615051269531,
      "step": 4832
    },
    {
      "epoch": 1.9332,
      "grad_norm": 0.13275004923343658,
      "learning_rate": 3.5573333333333334e-07,
      "logits/chosen": -2.8996527194976807,
      "logits/rejected": -2.7637722492218018,
      "logps/chosen": -96.0328140258789,
      "logps/rejected": -135.89959716796875,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2059582471847534,
      "rewards/margins": 7.192877769470215,
      "rewards/rejected": -8.398836135864258,
      "step": 4833
    },
    {
      "epoch": 1.9336,
      "grad_norm": 2.7071380615234375,
      "learning_rate": 3.5560000000000003e-07,
      "logits/chosen": -3.013720989227295,
      "logits/rejected": -2.9110565185546875,
      "logps/chosen": -57.90101623535156,
      "logps/rejected": -115.45023345947266,
      "loss": 0.0195,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4402232766151428,
      "rewards/margins": 7.233210563659668,
      "rewards/rejected": -6.792986869812012,
      "step": 4834
    },
    {
      "epoch": 1.9340000000000002,
      "grad_norm": 0.02289760112762451,
      "learning_rate": 3.554666666666666e-07,
      "logits/chosen": -2.5393624305725098,
      "logits/rejected": -1.8951570987701416,
      "logps/chosen": -113.09326934814453,
      "logps/rejected": -187.08444213867188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.43796154856681824,
      "rewards/margins": 12.273775100708008,
      "rewards/rejected": -11.835813522338867,
      "step": 4835
    },
    {
      "epoch": 1.9344000000000001,
      "grad_norm": 0.0008055772050283849,
      "learning_rate": 3.553333333333333e-07,
      "logits/chosen": -2.769981622695923,
      "logits/rejected": -1.8004446029663086,
      "logps/chosen": -77.80422973632812,
      "logps/rejected": -188.3110809326172,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.006817579269409,
      "rewards/margins": 13.277994155883789,
      "rewards/rejected": -11.271177291870117,
      "step": 4836
    },
    {
      "epoch": 1.9348,
      "grad_norm": 0.00425831601023674,
      "learning_rate": 3.552e-07,
      "logits/chosen": -2.3119077682495117,
      "logits/rejected": -1.9427216053009033,
      "logps/chosen": -125.05418395996094,
      "logps/rejected": -239.85546875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9772709608078003,
      "rewards/margins": 13.167985916137695,
      "rewards/rejected": -12.190715789794922,
      "step": 4837
    },
    {
      "epoch": 1.9352,
      "grad_norm": 0.20084495842456818,
      "learning_rate": 3.5506666666666664e-07,
      "logits/chosen": -2.3045496940612793,
      "logits/rejected": -1.5319736003875732,
      "logps/chosen": -263.8011779785156,
      "logps/rejected": -219.31588745117188,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.7761383056640625,
      "rewards/margins": 9.16379451751709,
      "rewards/rejected": -12.939932823181152,
      "step": 4838
    },
    {
      "epoch": 1.9356,
      "grad_norm": 0.032813962548971176,
      "learning_rate": 3.549333333333333e-07,
      "logits/chosen": -2.59279203414917,
      "logits/rejected": -2.0537354946136475,
      "logps/chosen": -54.30429458618164,
      "logps/rejected": -149.5467987060547,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3924893140792847,
      "rewards/margins": 11.312654495239258,
      "rewards/rejected": -9.920165061950684,
      "step": 4839
    },
    {
      "epoch": 1.936,
      "grad_norm": 4.2178192138671875,
      "learning_rate": 3.548e-07,
      "logits/chosen": -3.011258125305176,
      "logits/rejected": -2.528824806213379,
      "logps/chosen": -119.78944396972656,
      "logps/rejected": -129.34844970703125,
      "loss": 0.0132,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6421852111816406,
      "rewards/margins": 6.559389114379883,
      "rewards/rejected": -8.201574325561523,
      "step": 4840
    },
    {
      "epoch": 1.9364,
      "grad_norm": 0.025440862402319908,
      "learning_rate": 3.5466666666666667e-07,
      "logits/chosen": -2.570707321166992,
      "logits/rejected": -1.9562232494354248,
      "logps/chosen": -50.212310791015625,
      "logps/rejected": -153.598876953125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6077299118041992,
      "rewards/margins": 10.464618682861328,
      "rewards/rejected": -9.856888771057129,
      "step": 4841
    },
    {
      "epoch": 1.9367999999999999,
      "grad_norm": 1.3923412561416626,
      "learning_rate": 3.545333333333333e-07,
      "logits/chosen": -2.757620334625244,
      "logits/rejected": -2.510462760925293,
      "logps/chosen": -174.85179138183594,
      "logps/rejected": -141.05413818359375,
      "loss": 0.006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.5482661724090576,
      "rewards/margins": 5.192276954650879,
      "rewards/rejected": -7.740543365478516,
      "step": 4842
    },
    {
      "epoch": 1.9372,
      "grad_norm": 0.0011561316205188632,
      "learning_rate": 3.544e-07,
      "logits/chosen": -2.4531288146972656,
      "logits/rejected": -1.7444407939910889,
      "logps/chosen": -135.3168182373047,
      "logps/rejected": -250.90188598632812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8116322159767151,
      "rewards/margins": 14.406087875366211,
      "rewards/rejected": -15.217720031738281,
      "step": 4843
    },
    {
      "epoch": 1.9376,
      "grad_norm": 0.047940339893102646,
      "learning_rate": 3.5426666666666664e-07,
      "logits/chosen": -2.550288677215576,
      "logits/rejected": -2.144303321838379,
      "logps/chosen": -106.095703125,
      "logps/rejected": -187.85369873046875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.1661033630371094,
      "rewards/margins": 9.647411346435547,
      "rewards/rejected": -11.813514709472656,
      "step": 4844
    },
    {
      "epoch": 1.938,
      "grad_norm": 4.9006812332663685e-05,
      "learning_rate": 3.5413333333333333e-07,
      "logits/chosen": -2.454505443572998,
      "logits/rejected": -1.731747031211853,
      "logps/chosen": -85.32215881347656,
      "logps/rejected": -219.60116577148438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9833717346191406,
      "rewards/margins": 17.048635482788086,
      "rewards/rejected": -14.065262794494629,
      "step": 4845
    },
    {
      "epoch": 1.9384000000000001,
      "grad_norm": 0.016446541994810104,
      "learning_rate": 3.5399999999999997e-07,
      "logits/chosen": -2.8686108589172363,
      "logits/rejected": -2.7489676475524902,
      "logps/chosen": -75.06007385253906,
      "logps/rejected": -140.10423278808594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9397913217544556,
      "rewards/margins": 10.076553344726562,
      "rewards/rejected": -9.136761665344238,
      "step": 4846
    },
    {
      "epoch": 1.9388,
      "grad_norm": 0.4274216294288635,
      "learning_rate": 3.5386666666666666e-07,
      "logits/chosen": -2.63260817527771,
      "logits/rejected": -2.2735042572021484,
      "logps/chosen": -88.56405639648438,
      "logps/rejected": -111.57398986816406,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9023792743682861,
      "rewards/margins": 8.601022720336914,
      "rewards/rejected": -6.698643684387207,
      "step": 4847
    },
    {
      "epoch": 1.9392,
      "grad_norm": 0.05659458786249161,
      "learning_rate": 3.5373333333333335e-07,
      "logits/chosen": -2.4350671768188477,
      "logits/rejected": -1.9038727283477783,
      "logps/chosen": -95.33522033691406,
      "logps/rejected": -181.08303833007812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.45018500089645386,
      "rewards/margins": 11.096049308776855,
      "rewards/rejected": -11.546234130859375,
      "step": 4848
    },
    {
      "epoch": 1.9396,
      "grad_norm": 0.0022891955450177193,
      "learning_rate": 3.536e-07,
      "logits/chosen": -2.504204511642456,
      "logits/rejected": -2.0175974369049072,
      "logps/chosen": -88.60726928710938,
      "logps/rejected": -176.217041015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6455703973770142,
      "rewards/margins": 11.845163345336914,
      "rewards/rejected": -10.199593544006348,
      "step": 4849
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.1385686993598938,
      "learning_rate": 3.5346666666666663e-07,
      "logits/chosen": -2.8217015266418457,
      "logits/rejected": -2.0259249210357666,
      "logps/chosen": -102.20206451416016,
      "logps/rejected": -186.40933227539062,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6069564819335938,
      "rewards/margins": 12.817360877990723,
      "rewards/rejected": -12.210403442382812,
      "step": 4850
    },
    {
      "epoch": 1.9404,
      "grad_norm": 0.0016474539879709482,
      "learning_rate": 3.533333333333333e-07,
      "logits/chosen": -2.333494186401367,
      "logits/rejected": -1.508056402206421,
      "logps/chosen": -115.98623657226562,
      "logps/rejected": -181.432373046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6594169735908508,
      "rewards/margins": 12.136837005615234,
      "rewards/rejected": -11.477420806884766,
      "step": 4851
    },
    {
      "epoch": 1.9407999999999999,
      "grad_norm": 0.0014025013661012053,
      "learning_rate": 3.532e-07,
      "logits/chosen": -2.256298065185547,
      "logits/rejected": -1.7273545265197754,
      "logps/chosen": -161.01065063476562,
      "logps/rejected": -223.1832733154297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9897995591163635,
      "rewards/margins": 12.580490112304688,
      "rewards/rejected": -13.570289611816406,
      "step": 4852
    },
    {
      "epoch": 1.9412,
      "grad_norm": 0.0011731121921911836,
      "learning_rate": 3.530666666666666e-07,
      "logits/chosen": -3.0346362590789795,
      "logits/rejected": -2.403632640838623,
      "logps/chosen": -67.92435455322266,
      "logps/rejected": -177.81143188476562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34453412890434265,
      "rewards/margins": 12.60793685913086,
      "rewards/rejected": -12.263401985168457,
      "step": 4853
    },
    {
      "epoch": 1.9416,
      "grad_norm": 1.0085128545761108,
      "learning_rate": 3.529333333333333e-07,
      "logits/chosen": -2.6509547233581543,
      "logits/rejected": -2.0296764373779297,
      "logps/chosen": -128.72317504882812,
      "logps/rejected": -138.24917602539062,
      "loss": 0.0081,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4743245840072632,
      "rewards/margins": 8.281660079956055,
      "rewards/rejected": -8.755985260009766,
      "step": 4854
    },
    {
      "epoch": 1.942,
      "grad_norm": 0.20683249831199646,
      "learning_rate": 3.528e-07,
      "logits/chosen": -2.9019572734832764,
      "logits/rejected": -2.5712485313415527,
      "logps/chosen": -90.02513122558594,
      "logps/rejected": -107.46265411376953,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1789478063583374,
      "rewards/margins": 6.870379447937012,
      "rewards/rejected": -7.0493268966674805,
      "step": 4855
    },
    {
      "epoch": 1.9424000000000001,
      "grad_norm": 0.01132886577397585,
      "learning_rate": 3.526666666666667e-07,
      "logits/chosen": -2.5373709201812744,
      "logits/rejected": -2.3213460445404053,
      "logps/chosen": -131.0526123046875,
      "logps/rejected": -154.49758911132812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.42115479707717896,
      "rewards/margins": 9.482722282409668,
      "rewards/rejected": -9.903877258300781,
      "step": 4856
    },
    {
      "epoch": 1.9428,
      "grad_norm": 0.0018697987543419003,
      "learning_rate": 3.525333333333333e-07,
      "logits/chosen": -2.6517443656921387,
      "logits/rejected": -1.9417390823364258,
      "logps/chosen": -68.58638763427734,
      "logps/rejected": -178.86712646484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7104947566986084,
      "rewards/margins": 12.373414993286133,
      "rewards/rejected": -10.662919998168945,
      "step": 4857
    },
    {
      "epoch": 1.9432,
      "grad_norm": 0.10490377247333527,
      "learning_rate": 3.5239999999999995e-07,
      "logits/chosen": -3.011992931365967,
      "logits/rejected": -2.401365280151367,
      "logps/chosen": -44.24310302734375,
      "logps/rejected": -167.05340576171875,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42100790143013,
      "rewards/margins": 11.237850189208984,
      "rewards/rejected": -10.816843032836914,
      "step": 4858
    },
    {
      "epoch": 1.9436,
      "grad_norm": 0.018037589266896248,
      "learning_rate": 3.5226666666666664e-07,
      "logits/chosen": -2.285975217819214,
      "logits/rejected": -1.8030763864517212,
      "logps/chosen": -174.1221466064453,
      "logps/rejected": -159.96527099609375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2578689754009247,
      "rewards/margins": 9.68324089050293,
      "rewards/rejected": -9.425371170043945,
      "step": 4859
    },
    {
      "epoch": 1.944,
      "grad_norm": 0.6000463962554932,
      "learning_rate": 3.5213333333333334e-07,
      "logits/chosen": -2.7035465240478516,
      "logits/rejected": -2.251493215560913,
      "logps/chosen": -149.69903564453125,
      "logps/rejected": -138.3242645263672,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3514556884765625,
      "rewards/margins": 7.836854934692383,
      "rewards/rejected": -8.188310623168945,
      "step": 4860
    },
    {
      "epoch": 1.9444,
      "grad_norm": 0.4323124587535858,
      "learning_rate": 3.52e-07,
      "logits/chosen": -2.561725616455078,
      "logits/rejected": -2.0098395347595215,
      "logps/chosen": -143.07974243164062,
      "logps/rejected": -150.57077026367188,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.9990692138671875,
      "rewards/margins": 7.343270301818848,
      "rewards/rejected": -10.342339515686035,
      "step": 4861
    },
    {
      "epoch": 1.9447999999999999,
      "grad_norm": 0.2672920227050781,
      "learning_rate": 3.5186666666666667e-07,
      "logits/chosen": -2.3686108589172363,
      "logits/rejected": -2.001577377319336,
      "logps/chosen": -173.6637420654297,
      "logps/rejected": -175.47457885742188,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.343487501144409,
      "rewards/margins": 9.482791900634766,
      "rewards/rejected": -11.826279640197754,
      "step": 4862
    },
    {
      "epoch": 1.9452,
      "grad_norm": 9.573066711425781,
      "learning_rate": 3.517333333333333e-07,
      "logits/chosen": -2.4978315830230713,
      "logits/rejected": -2.1878747940063477,
      "logps/chosen": -174.79676818847656,
      "logps/rejected": -139.036376953125,
      "loss": 0.0826,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -5.436483383178711,
      "rewards/margins": 2.6367931365966797,
      "rewards/rejected": -8.07327651977539,
      "step": 4863
    },
    {
      "epoch": 1.9456,
      "grad_norm": 0.6408518552780151,
      "learning_rate": 3.516e-07,
      "logits/chosen": -2.560790538787842,
      "logits/rejected": -2.0871968269348145,
      "logps/chosen": -63.398582458496094,
      "logps/rejected": -194.96511840820312,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.022490710020065308,
      "rewards/margins": 9.526918411254883,
      "rewards/rejected": -9.549409866333008,
      "step": 4864
    },
    {
      "epoch": 1.946,
      "grad_norm": 0.03863571211695671,
      "learning_rate": 3.5146666666666664e-07,
      "logits/chosen": -2.6701955795288086,
      "logits/rejected": -1.9568586349487305,
      "logps/chosen": -71.16449737548828,
      "logps/rejected": -191.2463836669922,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.43602561950683594,
      "rewards/margins": 11.625539779663086,
      "rewards/rejected": -11.18951416015625,
      "step": 4865
    },
    {
      "epoch": 1.9464000000000001,
      "grad_norm": 0.011052964255213737,
      "learning_rate": 3.5133333333333333e-07,
      "logits/chosen": -2.5468597412109375,
      "logits/rejected": -2.2624096870422363,
      "logps/chosen": -79.81069946289062,
      "logps/rejected": -163.0517578125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7304043769836426,
      "rewards/margins": 12.965463638305664,
      "rewards/rejected": -11.235058784484863,
      "step": 4866
    },
    {
      "epoch": 1.9468,
      "grad_norm": 0.2723529636859894,
      "learning_rate": 3.512e-07,
      "logits/chosen": -2.274219036102295,
      "logits/rejected": -1.922062635421753,
      "logps/chosen": -74.094482421875,
      "logps/rejected": -141.83590698242188,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8054695129394531,
      "rewards/margins": 8.645987510681152,
      "rewards/rejected": -7.840517997741699,
      "step": 4867
    },
    {
      "epoch": 1.9472,
      "grad_norm": 0.9510383009910583,
      "learning_rate": 3.5106666666666666e-07,
      "logits/chosen": -2.692495822906494,
      "logits/rejected": -2.4537882804870605,
      "logps/chosen": -92.29278564453125,
      "logps/rejected": -120.84224700927734,
      "loss": 0.0061,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1615726500749588,
      "rewards/margins": 8.366750717163086,
      "rewards/rejected": -8.205178260803223,
      "step": 4868
    },
    {
      "epoch": 1.9476,
      "grad_norm": 0.004879284650087357,
      "learning_rate": 3.509333333333333e-07,
      "logits/chosen": -2.463996410369873,
      "logits/rejected": -1.7881309986114502,
      "logps/chosen": -115.84984588623047,
      "logps/rejected": -156.855712890625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.30497971177101135,
      "rewards/margins": 10.762619972229004,
      "rewards/rejected": -10.457639694213867,
      "step": 4869
    },
    {
      "epoch": 1.948,
      "grad_norm": 0.15558497607707977,
      "learning_rate": 3.508e-07,
      "logits/chosen": -2.556717872619629,
      "logits/rejected": -2.169095277786255,
      "logps/chosen": -107.80082702636719,
      "logps/rejected": -129.44921875,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.571242094039917,
      "rewards/margins": 8.222867965698242,
      "rewards/rejected": -8.794110298156738,
      "step": 4870
    },
    {
      "epoch": 1.9484,
      "grad_norm": 0.005972664803266525,
      "learning_rate": 3.506666666666667e-07,
      "logits/chosen": -2.334806442260742,
      "logits/rejected": -1.4868593215942383,
      "logps/chosen": -226.92251586914062,
      "logps/rejected": -181.704833984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5019668340682983,
      "rewards/margins": 10.645058631896973,
      "rewards/rejected": -11.147026062011719,
      "step": 4871
    },
    {
      "epoch": 1.9487999999999999,
      "grad_norm": 0.26759806275367737,
      "learning_rate": 3.5053333333333327e-07,
      "logits/chosen": -2.614614725112915,
      "logits/rejected": -2.1284265518188477,
      "logps/chosen": -130.11827087402344,
      "logps/rejected": -132.71981811523438,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6129956245422363,
      "rewards/margins": 7.276718616485596,
      "rewards/rejected": -8.889714241027832,
      "step": 4872
    },
    {
      "epoch": 1.9492,
      "grad_norm": 0.008401960134506226,
      "learning_rate": 3.5039999999999996e-07,
      "logits/chosen": -2.8803305625915527,
      "logits/rejected": -2.281841993331909,
      "logps/chosen": -73.35884857177734,
      "logps/rejected": -151.00450134277344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6624591946601868,
      "rewards/margins": 9.993266105651855,
      "rewards/rejected": -9.330806732177734,
      "step": 4873
    },
    {
      "epoch": 1.9496,
      "grad_norm": 0.731674313545227,
      "learning_rate": 3.5026666666666665e-07,
      "logits/chosen": -2.776017665863037,
      "logits/rejected": -2.485623836517334,
      "logps/chosen": -88.5319595336914,
      "logps/rejected": -117.06826782226562,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5824283957481384,
      "rewards/margins": 6.812227249145508,
      "rewards/rejected": -7.394655704498291,
      "step": 4874
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.007998287677764893,
      "learning_rate": 3.5013333333333335e-07,
      "logits/chosen": -2.377201557159424,
      "logits/rejected": -1.9395897388458252,
      "logps/chosen": -99.66546630859375,
      "logps/rejected": -193.06216430664062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5157921314239502,
      "rewards/margins": 11.636493682861328,
      "rewards/rejected": -11.12070083618164,
      "step": 4875
    },
    {
      "epoch": 1.9504000000000001,
      "grad_norm": 0.00015660181816201657,
      "learning_rate": 3.5e-07,
      "logits/chosen": -2.5349016189575195,
      "logits/rejected": -1.9862889051437378,
      "logps/chosen": -148.02597045898438,
      "logps/rejected": -225.38330078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8403412103652954,
      "rewards/margins": 14.538381576538086,
      "rewards/rejected": -15.37872314453125,
      "step": 4876
    },
    {
      "epoch": 1.9508,
      "grad_norm": 11.499560356140137,
      "learning_rate": 3.498666666666666e-07,
      "logits/chosen": -2.6644346714019775,
      "logits/rejected": -2.6542153358459473,
      "logps/chosen": -108.77545166015625,
      "logps/rejected": -90.7152328491211,
      "loss": 0.0819,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4930778443813324,
      "rewards/margins": 5.238809108734131,
      "rewards/rejected": -5.731886863708496,
      "step": 4877
    },
    {
      "epoch": 1.9512,
      "grad_norm": 0.011494028382003307,
      "learning_rate": 3.497333333333333e-07,
      "logits/chosen": -2.6295411586761475,
      "logits/rejected": -2.0493483543395996,
      "logps/chosen": -78.383544921875,
      "logps/rejected": -162.44090270996094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9767696857452393,
      "rewards/margins": 11.459066390991211,
      "rewards/rejected": -10.482295989990234,
      "step": 4878
    },
    {
      "epoch": 1.9516,
      "grad_norm": 0.0013345663901418447,
      "learning_rate": 3.496e-07,
      "logits/chosen": -3.039745569229126,
      "logits/rejected": -2.51981258392334,
      "logps/chosen": -43.62382507324219,
      "logps/rejected": -185.2864227294922,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.250540167093277,
      "rewards/margins": 13.153547286987305,
      "rewards/rejected": -12.903007507324219,
      "step": 4879
    },
    {
      "epoch": 1.952,
      "grad_norm": 0.059079304337501526,
      "learning_rate": 3.4946666666666665e-07,
      "logits/chosen": -2.560296058654785,
      "logits/rejected": -2.298011302947998,
      "logps/chosen": -87.20274353027344,
      "logps/rejected": -220.44680786132812,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1422626972198486,
      "rewards/margins": 10.251751899719238,
      "rewards/rejected": -9.109489440917969,
      "step": 4880
    },
    {
      "epoch": 1.9524,
      "grad_norm": 0.017783785238862038,
      "learning_rate": 3.4933333333333334e-07,
      "logits/chosen": -2.638728380203247,
      "logits/rejected": -2.0768442153930664,
      "logps/chosen": -85.57008361816406,
      "logps/rejected": -160.6572265625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8771881461143494,
      "rewards/margins": 10.123420715332031,
      "rewards/rejected": -9.246232032775879,
      "step": 4881
    },
    {
      "epoch": 1.9527999999999999,
      "grad_norm": 0.005885339807718992,
      "learning_rate": 3.492e-07,
      "logits/chosen": -3.056912899017334,
      "logits/rejected": -2.3582420349121094,
      "logps/chosen": -73.65663146972656,
      "logps/rejected": -194.24778747558594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1321921944618225,
      "rewards/margins": 11.844141006469727,
      "rewards/rejected": -11.711949348449707,
      "step": 4882
    },
    {
      "epoch": 1.9532,
      "grad_norm": 0.008064426481723785,
      "learning_rate": 3.4906666666666667e-07,
      "logits/chosen": -2.5275821685791016,
      "logits/rejected": -2.1858134269714355,
      "logps/chosen": -99.34590148925781,
      "logps/rejected": -151.07571411132812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4806396961212158,
      "rewards/margins": 10.764139175415039,
      "rewards/rejected": -9.283498764038086,
      "step": 4883
    },
    {
      "epoch": 1.9536,
      "grad_norm": 1.4229135513305664,
      "learning_rate": 3.489333333333333e-07,
      "logits/chosen": -2.8381309509277344,
      "logits/rejected": -2.6366591453552246,
      "logps/chosen": -104.68482208251953,
      "logps/rejected": -190.31141662597656,
      "loss": 0.0062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.503063976764679,
      "rewards/margins": 11.01852035522461,
      "rewards/rejected": -11.521584510803223,
      "step": 4884
    },
    {
      "epoch": 1.954,
      "grad_norm": 0.1356254518032074,
      "learning_rate": 3.488e-07,
      "logits/chosen": -2.9684970378875732,
      "logits/rejected": -2.6424546241760254,
      "logps/chosen": -54.621498107910156,
      "logps/rejected": -111.85934448242188,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.028746962547302246,
      "rewards/margins": 7.325965881347656,
      "rewards/rejected": -7.2972187995910645,
      "step": 4885
    },
    {
      "epoch": 1.9544000000000001,
      "grad_norm": 0.07751879096031189,
      "learning_rate": 3.4866666666666664e-07,
      "logits/chosen": -2.886802911758423,
      "logits/rejected": -2.2547361850738525,
      "logps/chosen": -63.51767349243164,
      "logps/rejected": -156.2060546875,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1991298496723175,
      "rewards/margins": 11.161581039428711,
      "rewards/rejected": -10.962450981140137,
      "step": 4886
    },
    {
      "epoch": 1.9548,
      "grad_norm": 0.006574236787855625,
      "learning_rate": 3.485333333333333e-07,
      "logits/chosen": -2.2116072177886963,
      "logits/rejected": -1.2116570472717285,
      "logps/chosen": -192.48284912109375,
      "logps/rejected": -208.73873901367188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8478119373321533,
      "rewards/margins": 12.538042068481445,
      "rewards/rejected": -13.385854721069336,
      "step": 4887
    },
    {
      "epoch": 1.9552,
      "grad_norm": 0.02148011140525341,
      "learning_rate": 3.4839999999999997e-07,
      "logits/chosen": -2.7978596687316895,
      "logits/rejected": -2.5571255683898926,
      "logps/chosen": -117.15577697753906,
      "logps/rejected": -147.47052001953125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6201778054237366,
      "rewards/margins": 10.081443786621094,
      "rewards/rejected": -9.461265563964844,
      "step": 4888
    },
    {
      "epoch": 1.9556,
      "grad_norm": 0.003179978346452117,
      "learning_rate": 3.4826666666666666e-07,
      "logits/chosen": -2.8492047786712646,
      "logits/rejected": -2.4434285163879395,
      "logps/chosen": -59.78697204589844,
      "logps/rejected": -174.7325897216797,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04623943567276001,
      "rewards/margins": 11.335685729980469,
      "rewards/rejected": -11.289445877075195,
      "step": 4889
    },
    {
      "epoch": 1.956,
      "grad_norm": 3.2716784477233887,
      "learning_rate": 3.4813333333333335e-07,
      "logits/chosen": -3.004343032836914,
      "logits/rejected": -2.8362183570861816,
      "logps/chosen": -110.98655700683594,
      "logps/rejected": -115.24899291992188,
      "loss": 0.0231,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.46842461824417114,
      "rewards/margins": 7.213075160980225,
      "rewards/rejected": -7.68149995803833,
      "step": 4890
    },
    {
      "epoch": 1.9564,
      "grad_norm": 0.00030673903529532254,
      "learning_rate": 3.4799999999999994e-07,
      "logits/chosen": -2.399653673171997,
      "logits/rejected": -2.21579647064209,
      "logps/chosen": -116.98159790039062,
      "logps/rejected": -224.7549285888672,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.11396443843841553,
      "rewards/margins": 14.980112075805664,
      "rewards/rejected": -15.094076156616211,
      "step": 4891
    },
    {
      "epoch": 1.9567999999999999,
      "grad_norm": 0.06999135762453079,
      "learning_rate": 3.4786666666666663e-07,
      "logits/chosen": -2.966494083404541,
      "logits/rejected": -1.871625542640686,
      "logps/chosen": -54.698509216308594,
      "logps/rejected": -127.46904754638672,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.403093159198761,
      "rewards/margins": 8.54831314086914,
      "rewards/rejected": -8.145219802856445,
      "step": 4892
    },
    {
      "epoch": 1.9572,
      "grad_norm": 0.0023443554528057575,
      "learning_rate": 3.477333333333333e-07,
      "logits/chosen": -2.871762752532959,
      "logits/rejected": -2.3788485527038574,
      "logps/chosen": -63.75375747680664,
      "logps/rejected": -174.39566040039062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34589213132858276,
      "rewards/margins": 12.743707656860352,
      "rewards/rejected": -12.397815704345703,
      "step": 4893
    },
    {
      "epoch": 1.9576,
      "grad_norm": 0.0009719129302538931,
      "learning_rate": 3.476e-07,
      "logits/chosen": -2.769352674484253,
      "logits/rejected": -2.038072109222412,
      "logps/chosen": -76.06794738769531,
      "logps/rejected": -174.60891723632812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15389251708984375,
      "rewards/margins": 12.751201629638672,
      "rewards/rejected": -12.597309112548828,
      "step": 4894
    },
    {
      "epoch": 1.958,
      "grad_norm": 0.3065355122089386,
      "learning_rate": 3.4746666666666665e-07,
      "logits/chosen": -2.7890405654907227,
      "logits/rejected": -2.6267576217651367,
      "logps/chosen": -69.57267761230469,
      "logps/rejected": -87.0797119140625,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5307831764221191,
      "rewards/margins": 6.890763282775879,
      "rewards/rejected": -5.359980583190918,
      "step": 4895
    },
    {
      "epoch": 1.9584000000000001,
      "grad_norm": 0.012855786830186844,
      "learning_rate": 3.473333333333333e-07,
      "logits/chosen": -2.2372469902038574,
      "logits/rejected": -1.3484270572662354,
      "logps/chosen": -176.80453491210938,
      "logps/rejected": -184.5384979248047,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0096641778945923,
      "rewards/margins": 10.925381660461426,
      "rewards/rejected": -11.935046195983887,
      "step": 4896
    },
    {
      "epoch": 1.9588,
      "grad_norm": 0.0014309324324131012,
      "learning_rate": 3.472e-07,
      "logits/chosen": -2.575082540512085,
      "logits/rejected": -1.843374490737915,
      "logps/chosen": -96.2124252319336,
      "logps/rejected": -197.17489624023438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.542401134967804,
      "rewards/margins": 13.00595760345459,
      "rewards/rejected": -12.463556289672852,
      "step": 4897
    },
    {
      "epoch": 1.9592,
      "grad_norm": 0.3880552351474762,
      "learning_rate": 3.470666666666667e-07,
      "logits/chosen": -2.6824512481689453,
      "logits/rejected": -2.221059799194336,
      "logps/chosen": -100.75651550292969,
      "logps/rejected": -101.81826782226562,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3784404695034027,
      "rewards/margins": 6.113533020019531,
      "rewards/rejected": -6.491972923278809,
      "step": 4898
    },
    {
      "epoch": 1.9596,
      "grad_norm": 0.6203566193580627,
      "learning_rate": 3.469333333333333e-07,
      "logits/chosen": -2.30483341217041,
      "logits/rejected": -1.803675651550293,
      "logps/chosen": -176.00836181640625,
      "logps/rejected": -262.6726989746094,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.884716033935547,
      "rewards/margins": 11.0037841796875,
      "rewards/rejected": -13.888500213623047,
      "step": 4899
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.11318105459213257,
      "learning_rate": 3.4679999999999996e-07,
      "logits/chosen": -2.4232048988342285,
      "logits/rejected": -2.310213088989258,
      "logps/chosen": -143.47210693359375,
      "logps/rejected": -163.74636840820312,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.49682310223579407,
      "rewards/margins": 9.48294448852539,
      "rewards/rejected": -9.979766845703125,
      "step": 4900
    },
    {
      "epoch": 1.9604,
      "grad_norm": 0.004263695795089006,
      "learning_rate": 3.4666666666666665e-07,
      "logits/chosen": -2.625861644744873,
      "logits/rejected": -2.05462908744812,
      "logps/chosen": -135.79959106445312,
      "logps/rejected": -205.85647583007812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9788675308227539,
      "rewards/margins": 12.400667190551758,
      "rewards/rejected": -11.421798706054688,
      "step": 4901
    },
    {
      "epoch": 1.9607999999999999,
      "grad_norm": 0.18573790788650513,
      "learning_rate": 3.4653333333333334e-07,
      "logits/chosen": -2.83278751373291,
      "logits/rejected": -2.482619285583496,
      "logps/chosen": -59.75321960449219,
      "logps/rejected": -112.19197082519531,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.263505756855011,
      "rewards/margins": 6.925217151641846,
      "rewards/rejected": -7.188723087310791,
      "step": 4902
    },
    {
      "epoch": 1.9612,
      "grad_norm": 0.0007175502250902355,
      "learning_rate": 3.464e-07,
      "logits/chosen": -2.6962342262268066,
      "logits/rejected": -1.9570294618606567,
      "logps/chosen": -81.13877868652344,
      "logps/rejected": -216.3056640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.49812009930610657,
      "rewards/margins": 13.658329963684082,
      "rewards/rejected": -13.160209655761719,
      "step": 4903
    },
    {
      "epoch": 1.9616,
      "grad_norm": 0.1026189848780632,
      "learning_rate": 3.4626666666666667e-07,
      "logits/chosen": -2.6663715839385986,
      "logits/rejected": -2.2968499660491943,
      "logps/chosen": -93.47163391113281,
      "logps/rejected": -182.5312042236328,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.36707037687301636,
      "rewards/margins": 9.089508056640625,
      "rewards/rejected": -8.722437858581543,
      "step": 4904
    },
    {
      "epoch": 1.962,
      "grad_norm": 0.010290670208632946,
      "learning_rate": 3.461333333333333e-07,
      "logits/chosen": -3.044006109237671,
      "logits/rejected": -2.4032411575317383,
      "logps/chosen": -71.27203369140625,
      "logps/rejected": -223.1629638671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.38737472891807556,
      "rewards/margins": 13.5904541015625,
      "rewards/rejected": -13.977828979492188,
      "step": 4905
    },
    {
      "epoch": 1.9624000000000001,
      "grad_norm": 0.11769301444292068,
      "learning_rate": 3.4599999999999995e-07,
      "logits/chosen": -2.3019046783447266,
      "logits/rejected": -1.8092873096466064,
      "logps/chosen": -171.13446044921875,
      "logps/rejected": -150.82522583007812,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.017556726932525635,
      "rewards/margins": 8.967022895812988,
      "rewards/rejected": -8.984579086303711,
      "step": 4906
    },
    {
      "epoch": 1.9628,
      "grad_norm": 0.06148682162165642,
      "learning_rate": 3.4586666666666664e-07,
      "logits/chosen": -2.3482506275177,
      "logits/rejected": -1.4801340103149414,
      "logps/chosen": -144.5777130126953,
      "logps/rejected": -182.29425048828125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11328357458114624,
      "rewards/margins": 10.878744125366211,
      "rewards/rejected": -10.765460968017578,
      "step": 4907
    },
    {
      "epoch": 1.9632,
      "grad_norm": 26.50924301147461,
      "learning_rate": 3.4573333333333333e-07,
      "logits/chosen": -2.4505038261413574,
      "logits/rejected": -2.2784037590026855,
      "logps/chosen": -213.3638458251953,
      "logps/rejected": -147.03466796875,
      "loss": 0.1003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.898027181625366,
      "rewards/margins": 4.956024646759033,
      "rewards/rejected": -8.85405158996582,
      "step": 4908
    },
    {
      "epoch": 1.9636,
      "grad_norm": 0.00013840780593454838,
      "learning_rate": 3.456e-07,
      "logits/chosen": -2.407984733581543,
      "logits/rejected": -1.5165069103240967,
      "logps/chosen": -72.14292907714844,
      "logps/rejected": -240.0563201904297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6848742961883545,
      "rewards/margins": 15.42364501953125,
      "rewards/rejected": -13.738770484924316,
      "step": 4909
    },
    {
      "epoch": 1.964,
      "grad_norm": 0.00990862213075161,
      "learning_rate": 3.454666666666666e-07,
      "logits/chosen": -2.5110907554626465,
      "logits/rejected": -1.9656810760498047,
      "logps/chosen": -130.19805908203125,
      "logps/rejected": -231.85006713867188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5609070062637329,
      "rewards/margins": 12.195670127868652,
      "rewards/rejected": -12.756577491760254,
      "step": 4910
    },
    {
      "epoch": 1.9644,
      "grad_norm": 0.007616265676915646,
      "learning_rate": 3.453333333333333e-07,
      "logits/chosen": -3.051124095916748,
      "logits/rejected": -2.510315179824829,
      "logps/chosen": -82.27295684814453,
      "logps/rejected": -157.23284912109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.035889625549316406,
      "rewards/margins": 10.077155113220215,
      "rewards/rejected": -10.113044738769531,
      "step": 4911
    },
    {
      "epoch": 1.9647999999999999,
      "grad_norm": 0.00874787662178278,
      "learning_rate": 3.452e-07,
      "logits/chosen": -2.5960593223571777,
      "logits/rejected": -1.9912095069885254,
      "logps/chosen": -122.75157928466797,
      "logps/rejected": -202.41278076171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.02353934943675995,
      "rewards/margins": 11.103116989135742,
      "rewards/rejected": -11.126655578613281,
      "step": 4912
    },
    {
      "epoch": 1.9651999999999998,
      "grad_norm": 0.8852004408836365,
      "learning_rate": 3.450666666666667e-07,
      "logits/chosen": -2.3944091796875,
      "logits/rejected": -1.9701564311981201,
      "logps/chosen": -152.01856994628906,
      "logps/rejected": -180.59622192382812,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.631761312484741,
      "rewards/margins": 9.031155586242676,
      "rewards/rejected": -11.66291618347168,
      "step": 4913
    },
    {
      "epoch": 1.9656,
      "grad_norm": 9.495131962466985e-05,
      "learning_rate": 3.4493333333333327e-07,
      "logits/chosen": -2.999089002609253,
      "logits/rejected": -2.500062942504883,
      "logps/chosen": -58.897438049316406,
      "logps/rejected": -210.71902465820312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.585135281085968,
      "rewards/margins": 16.095504760742188,
      "rewards/rejected": -15.510368347167969,
      "step": 4914
    },
    {
      "epoch": 1.966,
      "grad_norm": 0.1542675942182541,
      "learning_rate": 3.4479999999999996e-07,
      "logits/chosen": -2.809953212738037,
      "logits/rejected": -2.5786547660827637,
      "logps/chosen": -57.956382751464844,
      "logps/rejected": -175.19564819335938,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41822028160095215,
      "rewards/margins": 11.466195106506348,
      "rewards/rejected": -11.047975540161133,
      "step": 4915
    },
    {
      "epoch": 1.9664000000000001,
      "grad_norm": 0.13795645534992218,
      "learning_rate": 3.4466666666666666e-07,
      "logits/chosen": -2.9496665000915527,
      "logits/rejected": -2.253551483154297,
      "logps/chosen": -44.14692687988281,
      "logps/rejected": -141.80206298828125,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.109958291053772,
      "rewards/margins": 10.675485610961914,
      "rewards/rejected": -9.56552791595459,
      "step": 4916
    },
    {
      "epoch": 1.9668,
      "grad_norm": 0.05367179214954376,
      "learning_rate": 3.4453333333333335e-07,
      "logits/chosen": -2.6606945991516113,
      "logits/rejected": -1.9988501071929932,
      "logps/chosen": -68.57255554199219,
      "logps/rejected": -209.30191040039062,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12606582045555115,
      "rewards/margins": 10.056070327758789,
      "rewards/rejected": -9.930004119873047,
      "step": 4917
    },
    {
      "epoch": 1.9672,
      "grad_norm": 0.043305568397045135,
      "learning_rate": 3.444e-07,
      "logits/chosen": -2.5573267936706543,
      "logits/rejected": -2.315640926361084,
      "logps/chosen": -83.78823852539062,
      "logps/rejected": -140.86798095703125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22307968139648438,
      "rewards/margins": 9.325883865356445,
      "rewards/rejected": -9.102804183959961,
      "step": 4918
    },
    {
      "epoch": 1.9676,
      "grad_norm": 0.029215877875685692,
      "learning_rate": 3.442666666666666e-07,
      "logits/chosen": -2.7000927925109863,
      "logits/rejected": -2.1028757095336914,
      "logps/chosen": -65.35295867919922,
      "logps/rejected": -249.01539611816406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5362000465393066,
      "rewards/margins": 14.637300491333008,
      "rewards/rejected": -14.10110092163086,
      "step": 4919
    },
    {
      "epoch": 1.968,
      "grad_norm": 0.0006420084973797202,
      "learning_rate": 3.441333333333333e-07,
      "logits/chosen": -2.2052059173583984,
      "logits/rejected": -1.448792815208435,
      "logps/chosen": -141.46461486816406,
      "logps/rejected": -221.72898864746094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3892582058906555,
      "rewards/margins": 13.885056495666504,
      "rewards/rejected": -14.274314880371094,
      "step": 4920
    },
    {
      "epoch": 1.9684,
      "grad_norm": 0.0017254063859581947,
      "learning_rate": 3.4399999999999996e-07,
      "logits/chosen": -2.3308794498443604,
      "logits/rejected": -1.6167714595794678,
      "logps/chosen": -90.71247863769531,
      "logps/rejected": -233.78985595703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06675243377685547,
      "rewards/margins": 13.881071090698242,
      "rewards/rejected": -13.81431770324707,
      "step": 4921
    },
    {
      "epoch": 1.9687999999999999,
      "grad_norm": 0.5699549913406372,
      "learning_rate": 3.4386666666666665e-07,
      "logits/chosen": -2.8590831756591797,
      "logits/rejected": -2.505803108215332,
      "logps/chosen": -88.70845794677734,
      "logps/rejected": -103.6666259765625,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7673052549362183,
      "rewards/margins": 5.938683032989502,
      "rewards/rejected": -6.70598840713501,
      "step": 4922
    },
    {
      "epoch": 1.9691999999999998,
      "grad_norm": 0.013060661032795906,
      "learning_rate": 3.4373333333333334e-07,
      "logits/chosen": -2.544492244720459,
      "logits/rejected": -1.8142454624176025,
      "logps/chosen": -88.7228012084961,
      "logps/rejected": -146.81593322753906,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.838829755783081,
      "rewards/margins": 10.371723175048828,
      "rewards/rejected": -8.532892227172852,
      "step": 4923
    },
    {
      "epoch": 1.9696,
      "grad_norm": 0.03867461904883385,
      "learning_rate": 3.436e-07,
      "logits/chosen": -2.9746923446655273,
      "logits/rejected": -2.5484673976898193,
      "logps/chosen": -72.44341278076172,
      "logps/rejected": -176.72372436523438,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7414436936378479,
      "rewards/margins": 11.414363861083984,
      "rewards/rejected": -10.672919273376465,
      "step": 4924
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.030565904453396797,
      "learning_rate": 3.434666666666666e-07,
      "logits/chosen": -3.1501970291137695,
      "logits/rejected": -2.5715014934539795,
      "logps/chosen": -62.129695892333984,
      "logps/rejected": -147.1564178466797,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2029081583023071,
      "rewards/margins": 9.725960731506348,
      "rewards/rejected": -8.523052215576172,
      "step": 4925
    },
    {
      "epoch": 1.9704000000000002,
      "grad_norm": 0.07577590644359589,
      "learning_rate": 3.433333333333333e-07,
      "logits/chosen": -2.6332194805145264,
      "logits/rejected": -1.9342552423477173,
      "logps/chosen": -90.0751953125,
      "logps/rejected": -160.81552124023438,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6651460528373718,
      "rewards/margins": 11.299615859985352,
      "rewards/rejected": -10.634469985961914,
      "step": 4926
    },
    {
      "epoch": 1.9708,
      "grad_norm": 0.00023346624220721424,
      "learning_rate": 3.432e-07,
      "logits/chosen": -2.8709306716918945,
      "logits/rejected": -2.2931535243988037,
      "logps/chosen": -58.98820495605469,
      "logps/rejected": -182.70770263671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5298267602920532,
      "rewards/margins": 14.156713485717773,
      "rewards/rejected": -13.626886367797852,
      "step": 4927
    },
    {
      "epoch": 1.9712,
      "grad_norm": 0.00012582354247570038,
      "learning_rate": 3.430666666666667e-07,
      "logits/chosen": -2.5425467491149902,
      "logits/rejected": -1.9732118844985962,
      "logps/chosen": -112.14229583740234,
      "logps/rejected": -269.35125732421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5369665622711182,
      "rewards/margins": 14.927955627441406,
      "rewards/rejected": -15.464921951293945,
      "step": 4928
    },
    {
      "epoch": 1.9716,
      "grad_norm": 0.19349202513694763,
      "learning_rate": 3.429333333333333e-07,
      "logits/chosen": -2.8814635276794434,
      "logits/rejected": -2.553544521331787,
      "logps/chosen": -91.00291442871094,
      "logps/rejected": -124.53379821777344,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0329926013946533,
      "rewards/margins": 6.981362342834473,
      "rewards/rejected": -8.014354705810547,
      "step": 4929
    },
    {
      "epoch": 1.972,
      "grad_norm": 0.08538943529129028,
      "learning_rate": 3.4279999999999997e-07,
      "logits/chosen": -2.876636028289795,
      "logits/rejected": -2.5492491722106934,
      "logps/chosen": -109.45064544677734,
      "logps/rejected": -259.087646484375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18314819037914276,
      "rewards/margins": 11.222246170043945,
      "rewards/rejected": -11.039098739624023,
      "step": 4930
    },
    {
      "epoch": 1.9724,
      "grad_norm": 0.0012349430471658707,
      "learning_rate": 3.4266666666666666e-07,
      "logits/chosen": -3.135908603668213,
      "logits/rejected": -2.527444362640381,
      "logps/chosen": -37.41807174682617,
      "logps/rejected": -197.70028686523438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.920983910560608,
      "rewards/margins": 15.362667083740234,
      "rewards/rejected": -13.441682815551758,
      "step": 4931
    },
    {
      "epoch": 1.9727999999999999,
      "grad_norm": 0.8886861801147461,
      "learning_rate": 3.4253333333333336e-07,
      "logits/chosen": -2.643625259399414,
      "logits/rejected": -2.384798288345337,
      "logps/chosen": -195.01283264160156,
      "logps/rejected": -93.80935668945312,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.195086270570755,
      "rewards/margins": 5.576459884643555,
      "rewards/rejected": -5.771545886993408,
      "step": 4932
    },
    {
      "epoch": 1.9731999999999998,
      "grad_norm": 0.32108673453330994,
      "learning_rate": 3.4239999999999994e-07,
      "logits/chosen": -2.6528053283691406,
      "logits/rejected": -2.215264320373535,
      "logps/chosen": -61.546241760253906,
      "logps/rejected": -140.34194946289062,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7114613056182861,
      "rewards/margins": 9.469528198242188,
      "rewards/rejected": -8.75806713104248,
      "step": 4933
    },
    {
      "epoch": 1.9736,
      "grad_norm": 0.9113957285881042,
      "learning_rate": 3.4226666666666663e-07,
      "logits/chosen": -2.5228567123413086,
      "logits/rejected": -2.1812009811401367,
      "logps/chosen": -97.4853286743164,
      "logps/rejected": -174.67428588867188,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0065292119979858,
      "rewards/margins": 8.605677604675293,
      "rewards/rejected": -9.61220645904541,
      "step": 4934
    },
    {
      "epoch": 1.974,
      "grad_norm": 0.5706345438957214,
      "learning_rate": 3.421333333333333e-07,
      "logits/chosen": -2.8168563842773438,
      "logits/rejected": -2.4314987659454346,
      "logps/chosen": -118.7864990234375,
      "logps/rejected": -146.27938842773438,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7117355465888977,
      "rewards/margins": 8.672229766845703,
      "rewards/rejected": -9.383965492248535,
      "step": 4935
    },
    {
      "epoch": 1.9744000000000002,
      "grad_norm": 2.420474052429199,
      "learning_rate": 3.42e-07,
      "logits/chosen": -2.6582837104797363,
      "logits/rejected": -2.420694351196289,
      "logps/chosen": -69.31269836425781,
      "logps/rejected": -98.00729370117188,
      "loss": 0.0168,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4767061471939087,
      "rewards/margins": 4.871699333190918,
      "rewards/rejected": -5.348405361175537,
      "step": 4936
    },
    {
      "epoch": 1.9748,
      "grad_norm": 0.005948469042778015,
      "learning_rate": 3.4186666666666666e-07,
      "logits/chosen": -3.1872141361236572,
      "logits/rejected": -2.5866217613220215,
      "logps/chosen": -53.715980529785156,
      "logps/rejected": -184.65914916992188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6737537384033203,
      "rewards/margins": 12.82735824584961,
      "rewards/rejected": -12.153604507446289,
      "step": 4937
    },
    {
      "epoch": 1.9752,
      "grad_norm": 19.588748931884766,
      "learning_rate": 3.417333333333333e-07,
      "logits/chosen": -2.7795159816741943,
      "logits/rejected": -2.660841464996338,
      "logps/chosen": -98.04934692382812,
      "logps/rejected": -85.00288391113281,
      "loss": 0.0897,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2799772322177887,
      "rewards/margins": 3.926483631134033,
      "rewards/rejected": -4.206460952758789,
      "step": 4938
    },
    {
      "epoch": 1.9756,
      "grad_norm": 0.059434715658426285,
      "learning_rate": 3.416e-07,
      "logits/chosen": -2.4619269371032715,
      "logits/rejected": -2.0937986373901367,
      "logps/chosen": -134.14027404785156,
      "logps/rejected": -177.54254150390625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6310100555419922,
      "rewards/margins": 8.953577041625977,
      "rewards/rejected": -9.584587097167969,
      "step": 4939
    },
    {
      "epoch": 1.976,
      "grad_norm": 1.02048659324646,
      "learning_rate": 3.4146666666666663e-07,
      "logits/chosen": -2.7433524131774902,
      "logits/rejected": -2.711385726928711,
      "logps/chosen": -108.21276092529297,
      "logps/rejected": -95.02594757080078,
      "loss": 0.0069,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.281468152999878,
      "rewards/margins": 5.362083435058594,
      "rewards/rejected": -6.643551826477051,
      "step": 4940
    },
    {
      "epoch": 1.9764,
      "grad_norm": 0.8942306041717529,
      "learning_rate": 3.413333333333333e-07,
      "logits/chosen": -2.477815866470337,
      "logits/rejected": -1.8953497409820557,
      "logps/chosen": -86.57685852050781,
      "logps/rejected": -153.06451416015625,
      "loss": 0.005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6463899612426758,
      "rewards/margins": 7.959834575653076,
      "rewards/rejected": -8.60622501373291,
      "step": 4941
    },
    {
      "epoch": 1.9768,
      "grad_norm": 17.537967681884766,
      "learning_rate": 3.412e-07,
      "logits/chosen": -2.7279434204101562,
      "logits/rejected": -2.9933013916015625,
      "logps/chosen": -126.87367248535156,
      "logps/rejected": -88.79022216796875,
      "loss": 0.108,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1024372577667236,
      "rewards/margins": 5.022506237030029,
      "rewards/rejected": -6.124943256378174,
      "step": 4942
    },
    {
      "epoch": 1.9771999999999998,
      "grad_norm": 1.1954182386398315,
      "learning_rate": 3.4106666666666665e-07,
      "logits/chosen": -2.8190808296203613,
      "logits/rejected": -2.7236523628234863,
      "logps/chosen": -95.65184783935547,
      "logps/rejected": -134.144775390625,
      "loss": 0.0094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.3469486236572266,
      "rewards/margins": 6.966146469116211,
      "rewards/rejected": -9.313095092773438,
      "step": 4943
    },
    {
      "epoch": 1.9776,
      "grad_norm": 1.7010537385940552,
      "learning_rate": 3.409333333333333e-07,
      "logits/chosen": -2.6971449851989746,
      "logits/rejected": -2.703972339630127,
      "logps/chosen": -121.1667251586914,
      "logps/rejected": -124.30123901367188,
      "loss": 0.0129,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.850353240966797,
      "rewards/margins": 4.807867527008057,
      "rewards/rejected": -8.658220291137695,
      "step": 4944
    },
    {
      "epoch": 1.978,
      "grad_norm": 0.48561185598373413,
      "learning_rate": 3.408e-07,
      "logits/chosen": -2.5845460891723633,
      "logits/rejected": -2.079477310180664,
      "logps/chosen": -87.52500915527344,
      "logps/rejected": -145.55322265625,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5157691836357117,
      "rewards/margins": 9.275801658630371,
      "rewards/rejected": -8.760032653808594,
      "step": 4945
    },
    {
      "epoch": 1.9784000000000002,
      "grad_norm": 0.005905201192945242,
      "learning_rate": 3.4066666666666667e-07,
      "logits/chosen": -3.0356531143188477,
      "logits/rejected": -2.4317550659179688,
      "logps/chosen": -53.761329650878906,
      "logps/rejected": -154.3411865234375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8732340335845947,
      "rewards/margins": 11.330923080444336,
      "rewards/rejected": -9.45768928527832,
      "step": 4946
    },
    {
      "epoch": 1.9788000000000001,
      "grad_norm": 0.05031398683786392,
      "learning_rate": 3.4053333333333337e-07,
      "logits/chosen": -2.820797920227051,
      "logits/rejected": -2.3618273735046387,
      "logps/chosen": -149.9306640625,
      "logps/rejected": -129.52423095703125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0333725214004517,
      "rewards/margins": 8.168432235717773,
      "rewards/rejected": -7.135059833526611,
      "step": 4947
    },
    {
      "epoch": 1.9792,
      "grad_norm": 0.019428135827183723,
      "learning_rate": 3.4039999999999995e-07,
      "logits/chosen": -2.7817821502685547,
      "logits/rejected": -2.4522173404693604,
      "logps/chosen": -136.2984161376953,
      "logps/rejected": -175.68125915527344,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8314388990402222,
      "rewards/margins": 9.700689315795898,
      "rewards/rejected": -10.532129287719727,
      "step": 4948
    },
    {
      "epoch": 1.9796,
      "grad_norm": 0.0063025769777596,
      "learning_rate": 3.4026666666666664e-07,
      "logits/chosen": -2.53849196434021,
      "logits/rejected": -1.8930695056915283,
      "logps/chosen": -107.92864227294922,
      "logps/rejected": -230.7938995361328,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6346371173858643,
      "rewards/margins": 12.792049407958984,
      "rewards/rejected": -11.157411575317383,
      "step": 4949
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.0005999888526275754,
      "learning_rate": 3.4013333333333334e-07,
      "logits/chosen": -2.4615941047668457,
      "logits/rejected": -2.083815813064575,
      "logps/chosen": -97.30865478515625,
      "logps/rejected": -187.53086853027344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.915625810623169,
      "rewards/margins": 12.920333862304688,
      "rewards/rejected": -12.004708290100098,
      "step": 4950
    },
    {
      "epoch": 1.9804,
      "grad_norm": 0.0027782542165368795,
      "learning_rate": 3.4000000000000003e-07,
      "logits/chosen": -2.7577009201049805,
      "logits/rejected": -2.199103593826294,
      "logps/chosen": -82.60388946533203,
      "logps/rejected": -259.32806396484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.33186477422714233,
      "rewards/margins": 11.982488632202148,
      "rewards/rejected": -12.314353942871094,
      "step": 4951
    },
    {
      "epoch": 1.9808,
      "grad_norm": 0.001464066095650196,
      "learning_rate": 3.398666666666666e-07,
      "logits/chosen": -2.299764394760132,
      "logits/rejected": -1.655883550643921,
      "logps/chosen": -141.8040771484375,
      "logps/rejected": -279.418701171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9124526977539062,
      "rewards/margins": 12.516098976135254,
      "rewards/rejected": -13.42855167388916,
      "step": 4952
    },
    {
      "epoch": 1.9811999999999999,
      "grad_norm": 0.005500529892742634,
      "learning_rate": 3.397333333333333e-07,
      "logits/chosen": -2.6820826530456543,
      "logits/rejected": -1.9101028442382812,
      "logps/chosen": -124.38145446777344,
      "logps/rejected": -192.25372314453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.963799238204956,
      "rewards/margins": 12.741777420043945,
      "rewards/rejected": -11.777978897094727,
      "step": 4953
    },
    {
      "epoch": 1.9816,
      "grad_norm": 0.1854797601699829,
      "learning_rate": 3.396e-07,
      "logits/chosen": -2.6323025226593018,
      "logits/rejected": -2.151243209838867,
      "logps/chosen": -92.70024108886719,
      "logps/rejected": -151.6226806640625,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.86053466796875,
      "rewards/margins": 9.877382278442383,
      "rewards/rejected": -10.737916946411133,
      "step": 4954
    },
    {
      "epoch": 1.982,
      "grad_norm": 0.04313800111413002,
      "learning_rate": 3.394666666666667e-07,
      "logits/chosen": -2.7337827682495117,
      "logits/rejected": -2.195960760116577,
      "logps/chosen": -122.54273986816406,
      "logps/rejected": -146.43435668945312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3316582143306732,
      "rewards/margins": 9.873869895935059,
      "rewards/rejected": -9.542211532592773,
      "step": 4955
    },
    {
      "epoch": 1.9824000000000002,
      "grad_norm": 0.00745544396340847,
      "learning_rate": 3.3933333333333333e-07,
      "logits/chosen": -2.518036127090454,
      "logits/rejected": -1.974671483039856,
      "logps/chosen": -84.48486328125,
      "logps/rejected": -200.59304809570312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1218504905700684,
      "rewards/margins": 12.533445358276367,
      "rewards/rejected": -10.41159439086914,
      "step": 4956
    },
    {
      "epoch": 1.9828000000000001,
      "grad_norm": 0.13462236523628235,
      "learning_rate": 3.3919999999999997e-07,
      "logits/chosen": -2.368619441986084,
      "logits/rejected": -1.7975189685821533,
      "logps/chosen": -91.37986755371094,
      "logps/rejected": -132.88893127441406,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.917373776435852,
      "rewards/margins": 7.23453426361084,
      "rewards/rejected": -8.151907920837402,
      "step": 4957
    },
    {
      "epoch": 1.9832,
      "grad_norm": 155.26397705078125,
      "learning_rate": 3.3906666666666666e-07,
      "logits/chosen": -2.4408063888549805,
      "logits/rejected": -2.216543197631836,
      "logps/chosen": -249.0955810546875,
      "logps/rejected": -195.25567626953125,
      "loss": 0.9088,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -4.977153301239014,
      "rewards/margins": 5.628178119659424,
      "rewards/rejected": -10.605331420898438,
      "step": 4958
    },
    {
      "epoch": 1.9836,
      "grad_norm": 0.1286178082227707,
      "learning_rate": 3.389333333333333e-07,
      "logits/chosen": -2.766223907470703,
      "logits/rejected": -2.3503496646881104,
      "logps/chosen": -92.560302734375,
      "logps/rejected": -160.74404907226562,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.3009393215179443,
      "rewards/margins": 8.14033317565918,
      "rewards/rejected": -10.441271781921387,
      "step": 4959
    },
    {
      "epoch": 1.984,
      "grad_norm": 0.43084627389907837,
      "learning_rate": 3.388e-07,
      "logits/chosen": -2.694800853729248,
      "logits/rejected": -2.1680479049682617,
      "logps/chosen": -65.70207214355469,
      "logps/rejected": -119.78058624267578,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9659786224365234,
      "rewards/margins": 9.030284881591797,
      "rewards/rejected": -8.064306259155273,
      "step": 4960
    },
    {
      "epoch": 1.9844,
      "grad_norm": 0.1785179078578949,
      "learning_rate": 3.386666666666667e-07,
      "logits/chosen": -2.9152791500091553,
      "logits/rejected": -2.4027299880981445,
      "logps/chosen": -74.79359436035156,
      "logps/rejected": -184.47232055664062,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5692167282104492,
      "rewards/margins": 11.300483703613281,
      "rewards/rejected": -11.869701385498047,
      "step": 4961
    },
    {
      "epoch": 1.9848,
      "grad_norm": 0.1576407551765442,
      "learning_rate": 3.385333333333333e-07,
      "logits/chosen": -2.690937042236328,
      "logits/rejected": -2.236583709716797,
      "logps/chosen": -93.67979431152344,
      "logps/rejected": -190.83645629882812,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.422929048538208,
      "rewards/margins": 10.709115982055664,
      "rewards/rejected": -12.13204574584961,
      "step": 4962
    },
    {
      "epoch": 1.9851999999999999,
      "grad_norm": 0.07294947654008865,
      "learning_rate": 3.3839999999999996e-07,
      "logits/chosen": -2.3345460891723633,
      "logits/rejected": -1.683830976486206,
      "logps/chosen": -190.38162231445312,
      "logps/rejected": -186.2532958984375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.310293585062027,
      "rewards/margins": 11.598381042480469,
      "rewards/rejected": -11.908675193786621,
      "step": 4963
    },
    {
      "epoch": 1.9856,
      "grad_norm": 0.01759999617934227,
      "learning_rate": 3.3826666666666665e-07,
      "logits/chosen": -2.737525463104248,
      "logits/rejected": -2.2202932834625244,
      "logps/chosen": -98.4990005493164,
      "logps/rejected": -140.51309204101562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2348605990409851,
      "rewards/margins": 9.574893951416016,
      "rewards/rejected": -9.80975341796875,
      "step": 4964
    },
    {
      "epoch": 1.986,
      "grad_norm": 0.4032771587371826,
      "learning_rate": 3.3813333333333334e-07,
      "logits/chosen": -2.6658740043640137,
      "logits/rejected": -2.3437061309814453,
      "logps/chosen": -201.49908447265625,
      "logps/rejected": -117.85029602050781,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.14176788926124573,
      "rewards/margins": 7.175880432128906,
      "rewards/rejected": -7.317648887634277,
      "step": 4965
    },
    {
      "epoch": 1.9864000000000002,
      "grad_norm": 0.005035512149333954,
      "learning_rate": 3.38e-07,
      "logits/chosen": -2.8210582733154297,
      "logits/rejected": -2.505436658859253,
      "logps/chosen": -109.402587890625,
      "logps/rejected": -164.9303741455078,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.347459077835083,
      "rewards/margins": 10.578678131103516,
      "rewards/rejected": -11.92613697052002,
      "step": 4966
    },
    {
      "epoch": 1.9868000000000001,
      "grad_norm": 0.020311733707785606,
      "learning_rate": 3.378666666666666e-07,
      "logits/chosen": -3.0804178714752197,
      "logits/rejected": -2.4812512397766113,
      "logps/chosen": -53.96300506591797,
      "logps/rejected": -146.74063110351562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.09763602912425995,
      "rewards/margins": 10.100645065307617,
      "rewards/rejected": -10.198280334472656,
      "step": 4967
    },
    {
      "epoch": 1.9872,
      "grad_norm": 0.016278931871056557,
      "learning_rate": 3.377333333333333e-07,
      "logits/chosen": -2.7781214714050293,
      "logits/rejected": -2.6279008388519287,
      "logps/chosen": -83.30430603027344,
      "logps/rejected": -141.71510314941406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4555630087852478,
      "rewards/margins": 9.198018074035645,
      "rewards/rejected": -9.653580665588379,
      "step": 4968
    },
    {
      "epoch": 1.9876,
      "grad_norm": 13.647554397583008,
      "learning_rate": 3.376e-07,
      "logits/chosen": -2.376704216003418,
      "logits/rejected": -1.9961621761322021,
      "logps/chosen": -215.13607788085938,
      "logps/rejected": -157.32809448242188,
      "loss": 0.0488,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.7671334743499756,
      "rewards/margins": 3.765946388244629,
      "rewards/rejected": -7.533080101013184,
      "step": 4969
    },
    {
      "epoch": 1.988,
      "grad_norm": 0.00020046171266585588,
      "learning_rate": 3.374666666666667e-07,
      "logits/chosen": -2.680990219116211,
      "logits/rejected": -1.9172204732894897,
      "logps/chosen": -79.06470489501953,
      "logps/rejected": -207.09654235839844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0259387493133545,
      "rewards/margins": 15.67447280883789,
      "rewards/rejected": -13.648534774780273,
      "step": 4970
    },
    {
      "epoch": 1.9884,
      "grad_norm": 0.27014294266700745,
      "learning_rate": 3.373333333333333e-07,
      "logits/chosen": -2.510281562805176,
      "logits/rejected": -2.2695460319519043,
      "logps/chosen": -85.45989990234375,
      "logps/rejected": -91.08282470703125,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.811408281326294,
      "rewards/margins": 7.137494087219238,
      "rewards/rejected": -6.326086044311523,
      "step": 4971
    },
    {
      "epoch": 1.9888,
      "grad_norm": 0.44299283623695374,
      "learning_rate": 3.372e-07,
      "logits/chosen": -2.7560653686523438,
      "logits/rejected": -2.243438243865967,
      "logps/chosen": -115.02452850341797,
      "logps/rejected": -161.14279174804688,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5738117694854736,
      "rewards/margins": 10.95423412322998,
      "rewards/rejected": -11.528045654296875,
      "step": 4972
    },
    {
      "epoch": 1.9891999999999999,
      "grad_norm": 0.07106364518404007,
      "learning_rate": 3.3706666666666667e-07,
      "logits/chosen": -2.4972033500671387,
      "logits/rejected": -1.9128553867340088,
      "logps/chosen": -137.84439086914062,
      "logps/rejected": -130.12030029296875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8166935443878174,
      "rewards/margins": 8.101531028747559,
      "rewards/rejected": -7.284836769104004,
      "step": 4973
    },
    {
      "epoch": 1.9896,
      "grad_norm": 0.0009296596981585026,
      "learning_rate": 3.369333333333333e-07,
      "logits/chosen": -2.702357053756714,
      "logits/rejected": -1.839137077331543,
      "logps/chosen": -81.69721984863281,
      "logps/rejected": -197.6133575439453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7773303985595703,
      "rewards/margins": 14.007638931274414,
      "rewards/rejected": -13.230308532714844,
      "step": 4974
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.43482503294944763,
      "learning_rate": 3.368e-07,
      "logits/chosen": -2.1910197734832764,
      "logits/rejected": -1.431471824645996,
      "logps/chosen": -168.63128662109375,
      "logps/rejected": -188.59725952148438,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.224338054656982,
      "rewards/margins": 6.817053318023682,
      "rewards/rejected": -11.041391372680664,
      "step": 4975
    },
    {
      "epoch": 1.9904,
      "grad_norm": 0.8354971408843994,
      "learning_rate": 3.3666666666666664e-07,
      "logits/chosen": -2.7385640144348145,
      "logits/rejected": -2.4169883728027344,
      "logps/chosen": -109.14909362792969,
      "logps/rejected": -251.2270965576172,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7515331506729126,
      "rewards/margins": 10.287956237792969,
      "rewards/rejected": -11.03948974609375,
      "step": 4976
    },
    {
      "epoch": 1.9908000000000001,
      "grad_norm": 3.283785918029025e-05,
      "learning_rate": 3.3653333333333333e-07,
      "logits/chosen": -2.5003864765167236,
      "logits/rejected": -1.5982701778411865,
      "logps/chosen": -120.02477264404297,
      "logps/rejected": -231.64395141601562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2407917976379395,
      "rewards/margins": 17.583717346191406,
      "rewards/rejected": -16.342924118041992,
      "step": 4977
    },
    {
      "epoch": 1.9912,
      "grad_norm": 0.13851326704025269,
      "learning_rate": 3.3639999999999997e-07,
      "logits/chosen": -2.870338201522827,
      "logits/rejected": -2.254526138305664,
      "logps/chosen": -93.40478515625,
      "logps/rejected": -153.62513732910156,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.807559609413147,
      "rewards/margins": 10.376985549926758,
      "rewards/rejected": -8.569426536560059,
      "step": 4978
    },
    {
      "epoch": 1.9916,
      "grad_norm": 0.008572184480726719,
      "learning_rate": 3.3626666666666666e-07,
      "logits/chosen": -2.7015347480773926,
      "logits/rejected": -2.4912424087524414,
      "logps/chosen": -48.522186279296875,
      "logps/rejected": -165.9267120361328,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.808400571346283,
      "rewards/margins": 10.201583862304688,
      "rewards/rejected": -9.393183708190918,
      "step": 4979
    },
    {
      "epoch": 1.992,
      "grad_norm": 2.1998565196990967,
      "learning_rate": 3.361333333333333e-07,
      "logits/chosen": -3.0205838680267334,
      "logits/rejected": -2.899329423904419,
      "logps/chosen": -55.489253997802734,
      "logps/rejected": -93.431396484375,
      "loss": 0.0121,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1091622114181519,
      "rewards/margins": 6.063233375549316,
      "rewards/rejected": -4.954071044921875,
      "step": 4980
    },
    {
      "epoch": 1.9924,
      "grad_norm": 0.09894868731498718,
      "learning_rate": 3.36e-07,
      "logits/chosen": -2.2541582584381104,
      "logits/rejected": -1.6470255851745605,
      "logps/chosen": -107.29862976074219,
      "logps/rejected": -173.34478759765625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3681175410747528,
      "rewards/margins": 10.606385231018066,
      "rewards/rejected": -10.23826789855957,
      "step": 4981
    },
    {
      "epoch": 1.9928,
      "grad_norm": 0.0006844442686997354,
      "learning_rate": 3.3586666666666663e-07,
      "logits/chosen": -2.936983585357666,
      "logits/rejected": -2.42254638671875,
      "logps/chosen": -75.19001770019531,
      "logps/rejected": -179.24578857421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7010130286216736,
      "rewards/margins": 13.075611114501953,
      "rewards/rejected": -12.374597549438477,
      "step": 4982
    },
    {
      "epoch": 1.9931999999999999,
      "grad_norm": 0.004310056567192078,
      "learning_rate": 3.357333333333333e-07,
      "logits/chosen": -3.040168285369873,
      "logits/rejected": -2.1241390705108643,
      "logps/chosen": -45.43353271484375,
      "logps/rejected": -179.71109008789062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15530967712402344,
      "rewards/margins": 12.722187042236328,
      "rewards/rejected": -12.566877365112305,
      "step": 4983
    },
    {
      "epoch": 1.9936,
      "grad_norm": 0.182518869638443,
      "learning_rate": 3.356e-07,
      "logits/chosen": -2.799093723297119,
      "logits/rejected": -2.3930788040161133,
      "logps/chosen": -95.88934326171875,
      "logps/rejected": -116.26918029785156,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7653347253799438,
      "rewards/margins": 8.387107849121094,
      "rewards/rejected": -7.621773719787598,
      "step": 4984
    },
    {
      "epoch": 1.994,
      "grad_norm": 0.0029453181196004152,
      "learning_rate": 3.3546666666666665e-07,
      "logits/chosen": -3.07258677482605,
      "logits/rejected": -2.430251121520996,
      "logps/chosen": -68.7098388671875,
      "logps/rejected": -184.3894805908203,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07718296349048615,
      "rewards/margins": 12.28702163696289,
      "rewards/rejected": -12.2098388671875,
      "step": 4985
    },
    {
      "epoch": 1.9944,
      "grad_norm": 0.4966927766799927,
      "learning_rate": 3.353333333333333e-07,
      "logits/chosen": -2.6470515727996826,
      "logits/rejected": -2.227281093597412,
      "logps/chosen": -103.48368835449219,
      "logps/rejected": -120.15785217285156,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0233490467071533,
      "rewards/margins": 8.98321533203125,
      "rewards/rejected": -7.959866523742676,
      "step": 4986
    },
    {
      "epoch": 1.9948000000000001,
      "grad_norm": 1.41741144657135,
      "learning_rate": 3.352e-07,
      "logits/chosen": -2.908250331878662,
      "logits/rejected": -2.748218536376953,
      "logps/chosen": -71.11621856689453,
      "logps/rejected": -112.21781921386719,
      "loss": 0.0088,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.16397860646247864,
      "rewards/margins": 7.18200159072876,
      "rewards/rejected": -7.345980167388916,
      "step": 4987
    },
    {
      "epoch": 1.9952,
      "grad_norm": 0.0042645568028092384,
      "learning_rate": 3.350666666666667e-07,
      "logits/chosen": -2.7158007621765137,
      "logits/rejected": -2.0951309204101562,
      "logps/chosen": -111.9004898071289,
      "logps/rejected": -193.1148681640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05097275972366333,
      "rewards/margins": 13.381160736083984,
      "rewards/rejected": -13.330187797546387,
      "step": 4988
    },
    {
      "epoch": 1.9956,
      "grad_norm": 0.008196205832064152,
      "learning_rate": 3.3493333333333337e-07,
      "logits/chosen": -2.599379062652588,
      "logits/rejected": -2.15824556350708,
      "logps/chosen": -109.26714324951172,
      "logps/rejected": -149.70309448242188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2504333555698395,
      "rewards/margins": 10.756854057312012,
      "rewards/rejected": -10.506420135498047,
      "step": 4989
    },
    {
      "epoch": 1.996,
      "grad_norm": 0.01985594816505909,
      "learning_rate": 3.3479999999999995e-07,
      "logits/chosen": -2.2719836235046387,
      "logits/rejected": -1.8930790424346924,
      "logps/chosen": -136.1850128173828,
      "logps/rejected": -135.3050537109375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.206472396850586,
      "rewards/margins": 11.026853561401367,
      "rewards/rejected": -9.820382118225098,
      "step": 4990
    },
    {
      "epoch": 1.9964,
      "grad_norm": 0.04708581417798996,
      "learning_rate": 3.3466666666666665e-07,
      "logits/chosen": -2.91713285446167,
      "logits/rejected": -2.5530569553375244,
      "logps/chosen": -161.5086669921875,
      "logps/rejected": -147.49270629882812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.261483758687973,
      "rewards/margins": 9.055521011352539,
      "rewards/rejected": -8.794036865234375,
      "step": 4991
    },
    {
      "epoch": 1.9968,
      "grad_norm": 0.10766234993934631,
      "learning_rate": 3.3453333333333334e-07,
      "logits/chosen": -2.811072826385498,
      "logits/rejected": -2.179253339767456,
      "logps/chosen": -80.3485107421875,
      "logps/rejected": -167.7508544921875,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8521862030029297,
      "rewards/margins": 13.008116722106934,
      "rewards/rejected": -12.155930519104004,
      "step": 4992
    },
    {
      "epoch": 1.9971999999999999,
      "grad_norm": 0.3501724302768707,
      "learning_rate": 3.344e-07,
      "logits/chosen": -2.828068256378174,
      "logits/rejected": -2.591459274291992,
      "logps/chosen": -76.1405029296875,
      "logps/rejected": -107.59532928466797,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20952185988426208,
      "rewards/margins": 7.053441047668457,
      "rewards/rejected": -6.843918800354004,
      "step": 4993
    },
    {
      "epoch": 1.9976,
      "grad_norm": 0.02914491854608059,
      "learning_rate": 3.342666666666666e-07,
      "logits/chosen": -2.510925531387329,
      "logits/rejected": -2.020052433013916,
      "logps/chosen": -150.3585662841797,
      "logps/rejected": -169.52679443359375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.322452574968338,
      "rewards/margins": 9.890284538269043,
      "rewards/rejected": -10.212737083435059,
      "step": 4994
    },
    {
      "epoch": 1.998,
      "grad_norm": 0.3953416645526886,
      "learning_rate": 3.341333333333333e-07,
      "logits/chosen": -2.5426716804504395,
      "logits/rejected": -1.97674560546875,
      "logps/chosen": -44.624996185302734,
      "logps/rejected": -165.2515411376953,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.11891257762908936,
      "rewards/margins": 10.44396686553955,
      "rewards/rejected": -10.56287956237793,
      "step": 4995
    },
    {
      "epoch": 1.9984,
      "grad_norm": 0.001179440412670374,
      "learning_rate": 3.34e-07,
      "logits/chosen": -2.316494941711426,
      "logits/rejected": -1.3865346908569336,
      "logps/chosen": -124.86195373535156,
      "logps/rejected": -227.6403045654297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4429359436035156,
      "rewards/margins": 13.485300064086914,
      "rewards/rejected": -13.92823600769043,
      "step": 4996
    },
    {
      "epoch": 1.9988000000000001,
      "grad_norm": 0.18883182108402252,
      "learning_rate": 3.3386666666666664e-07,
      "logits/chosen": -3.0033960342407227,
      "logits/rejected": -2.6058497428894043,
      "logps/chosen": -79.77790832519531,
      "logps/rejected": -179.3766632080078,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3872074484825134,
      "rewards/margins": 10.018367767333984,
      "rewards/rejected": -10.405574798583984,
      "step": 4997
    },
    {
      "epoch": 1.9992,
      "grad_norm": 0.010477526113390923,
      "learning_rate": 3.3373333333333333e-07,
      "logits/chosen": -2.838616371154785,
      "logits/rejected": -2.434042453765869,
      "logps/chosen": -65.85798645019531,
      "logps/rejected": -138.47894287109375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8548812866210938,
      "rewards/margins": 9.655801773071289,
      "rewards/rejected": -8.800921440124512,
      "step": 4998
    },
    {
      "epoch": 1.9996,
      "grad_norm": 0.0011648335494101048,
      "learning_rate": 3.3359999999999997e-07,
      "logits/chosen": -2.849215030670166,
      "logits/rejected": -2.3843815326690674,
      "logps/chosen": -92.21794128417969,
      "logps/rejected": -190.43789672851562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6420402526855469,
      "rewards/margins": 12.750500679016113,
      "rewards/rejected": -13.39254093170166,
      "step": 4999
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.018406372517347336,
      "learning_rate": 3.3346666666666666e-07,
      "logits/chosen": -2.902686595916748,
      "logits/rejected": -2.2600226402282715,
      "logps/chosen": -74.51950073242188,
      "logps/rejected": -162.69448852539062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42568129301071167,
      "rewards/margins": 10.306893348693848,
      "rewards/rejected": -9.88121223449707,
      "step": 5000
    },
    {
      "epoch": 2.0004,
      "grad_norm": 0.013606885448098183,
      "learning_rate": 3.333333333333333e-07,
      "logits/chosen": -2.8232197761535645,
      "logits/rejected": -2.29618763923645,
      "logps/chosen": -105.94557189941406,
      "logps/rejected": -145.28822326660156,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.46306076645851135,
      "rewards/margins": 9.748832702636719,
      "rewards/rejected": -9.285772323608398,
      "step": 5001
    },
    {
      "epoch": 2.0008,
      "grad_norm": 0.8856906294822693,
      "learning_rate": 3.332e-07,
      "logits/chosen": -2.6270577907562256,
      "logits/rejected": -2.147859573364258,
      "logps/chosen": -98.21771240234375,
      "logps/rejected": -164.01268005371094,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1245365142822266,
      "rewards/margins": 8.562780380249023,
      "rewards/rejected": -9.68731689453125,
      "step": 5002
    },
    {
      "epoch": 2.0012,
      "grad_norm": 0.018877506256103516,
      "learning_rate": 3.330666666666667e-07,
      "logits/chosen": -2.7251405715942383,
      "logits/rejected": -2.108938217163086,
      "logps/chosen": -117.5078353881836,
      "logps/rejected": -162.86000061035156,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.059854865074157715,
      "rewards/margins": 10.468589782714844,
      "rewards/rejected": -10.408735275268555,
      "step": 5003
    },
    {
      "epoch": 2.0016,
      "grad_norm": 0.19906534254550934,
      "learning_rate": 3.329333333333333e-07,
      "logits/chosen": -2.7873849868774414,
      "logits/rejected": -2.038883924484253,
      "logps/chosen": -58.6019287109375,
      "logps/rejected": -144.96902465820312,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6225506067276001,
      "rewards/margins": 8.994911193847656,
      "rewards/rejected": -8.372360229492188,
      "step": 5004
    },
    {
      "epoch": 2.002,
      "grad_norm": 0.27540215849876404,
      "learning_rate": 3.3279999999999996e-07,
      "logits/chosen": -2.958780288696289,
      "logits/rejected": -2.628807544708252,
      "logps/chosen": -95.14018249511719,
      "logps/rejected": -121.3518295288086,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32594990730285645,
      "rewards/margins": 6.972990036010742,
      "rewards/rejected": -6.647039890289307,
      "step": 5005
    },
    {
      "epoch": 2.0024,
      "grad_norm": 1.3184099197387695,
      "learning_rate": 3.3266666666666665e-07,
      "logits/chosen": -2.6914520263671875,
      "logits/rejected": -2.5477232933044434,
      "logps/chosen": -156.44873046875,
      "logps/rejected": -153.9506378173828,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4823249876499176,
      "rewards/margins": 8.304712295532227,
      "rewards/rejected": -8.787036895751953,
      "step": 5006
    },
    {
      "epoch": 2.0028,
      "grad_norm": 0.14253105223178864,
      "learning_rate": 3.3253333333333335e-07,
      "logits/chosen": -2.6385512351989746,
      "logits/rejected": -2.250209331512451,
      "logps/chosen": -60.86473846435547,
      "logps/rejected": -145.59286499023438,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2095565795898438,
      "rewards/margins": 10.362993240356445,
      "rewards/rejected": -8.153436660766602,
      "step": 5007
    },
    {
      "epoch": 2.0032,
      "grad_norm": 0.3631685674190521,
      "learning_rate": 3.3239999999999993e-07,
      "logits/chosen": -2.958897113800049,
      "logits/rejected": -2.4854140281677246,
      "logps/chosen": -98.50270080566406,
      "logps/rejected": -168.88720703125,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4113327264785767,
      "rewards/margins": 9.774763107299805,
      "rewards/rejected": -11.18609619140625,
      "step": 5008
    },
    {
      "epoch": 2.0036,
      "grad_norm": 308.03851318359375,
      "learning_rate": 3.322666666666666e-07,
      "logits/chosen": -2.4270026683807373,
      "logits/rejected": -2.007429599761963,
      "logps/chosen": -238.84158325195312,
      "logps/rejected": -201.78390502929688,
      "loss": 3.958,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -8.030841827392578,
      "rewards/margins": 5.055450916290283,
      "rewards/rejected": -13.086292266845703,
      "step": 5009
    },
    {
      "epoch": 2.004,
      "grad_norm": 0.9836226105690002,
      "learning_rate": 3.321333333333333e-07,
      "logits/chosen": -2.548096179962158,
      "logits/rejected": -2.1556828022003174,
      "logps/chosen": -188.75665283203125,
      "logps/rejected": -144.343505859375,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7088713645935059,
      "rewards/margins": 7.202878952026367,
      "rewards/rejected": -8.911750793457031,
      "step": 5010
    },
    {
      "epoch": 2.0044,
      "grad_norm": 6.56960810374585e-06,
      "learning_rate": 3.32e-07,
      "logits/chosen": -2.7266287803649902,
      "logits/rejected": -2.1879477500915527,
      "logps/chosen": -56.203460693359375,
      "logps/rejected": -280.20892333984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7936411499977112,
      "rewards/margins": 19.541038513183594,
      "rewards/rejected": -18.74739646911621,
      "step": 5011
    },
    {
      "epoch": 2.0048,
      "grad_norm": 0.028123905882239342,
      "learning_rate": 3.3186666666666665e-07,
      "logits/chosen": -3.126461982727051,
      "logits/rejected": -2.6891260147094727,
      "logps/chosen": -38.840599060058594,
      "logps/rejected": -140.99533081054688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9758211970329285,
      "rewards/margins": 9.569171905517578,
      "rewards/rejected": -8.593351364135742,
      "step": 5012
    },
    {
      "epoch": 2.0052,
      "grad_norm": 0.001759956358000636,
      "learning_rate": 3.317333333333333e-07,
      "logits/chosen": -2.1354429721832275,
      "logits/rejected": -1.504823088645935,
      "logps/chosen": -141.49029541015625,
      "logps/rejected": -185.18829345703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.007696986198425293,
      "rewards/margins": 12.636434555053711,
      "rewards/rejected": -12.628737449645996,
      "step": 5013
    },
    {
      "epoch": 2.0056,
      "grad_norm": 0.06237262487411499,
      "learning_rate": 3.316e-07,
      "logits/chosen": -2.66900372505188,
      "logits/rejected": -2.062199115753174,
      "logps/chosen": -100.80769348144531,
      "logps/rejected": -146.2211151123047,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.238172173500061,
      "rewards/margins": 10.588118553161621,
      "rewards/rejected": -9.349946022033691,
      "step": 5014
    },
    {
      "epoch": 2.006,
      "grad_norm": 0.05864795297384262,
      "learning_rate": 3.3146666666666667e-07,
      "logits/chosen": -2.595116138458252,
      "logits/rejected": -2.057535171508789,
      "logps/chosen": -154.04620361328125,
      "logps/rejected": -172.03945922851562,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0692996978759766,
      "rewards/margins": 8.63136100769043,
      "rewards/rejected": -9.700660705566406,
      "step": 5015
    },
    {
      "epoch": 2.0064,
      "grad_norm": 0.5970991253852844,
      "learning_rate": 3.313333333333333e-07,
      "logits/chosen": -2.3927078247070312,
      "logits/rejected": -2.216465473175049,
      "logps/chosen": -86.548095703125,
      "logps/rejected": -125.41354370117188,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5373132824897766,
      "rewards/margins": 7.044770240783691,
      "rewards/rejected": -7.582083702087402,
      "step": 5016
    },
    {
      "epoch": 2.0068,
      "grad_norm": 0.03344043344259262,
      "learning_rate": 3.312e-07,
      "logits/chosen": -2.9116082191467285,
      "logits/rejected": -2.386448860168457,
      "logps/chosen": -128.49334716796875,
      "logps/rejected": -144.94400024414062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10825538635253906,
      "rewards/margins": 9.407205581665039,
      "rewards/rejected": -9.2989501953125,
      "step": 5017
    },
    {
      "epoch": 2.0072,
      "grad_norm": 0.0012784303398802876,
      "learning_rate": 3.3106666666666664e-07,
      "logits/chosen": -2.5122969150543213,
      "logits/rejected": -1.972404956817627,
      "logps/chosen": -84.61412811279297,
      "logps/rejected": -214.21302795410156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.46301084756851196,
      "rewards/margins": 14.139984130859375,
      "rewards/rejected": -13.676973342895508,
      "step": 5018
    },
    {
      "epoch": 2.0076,
      "grad_norm": 0.35549280047416687,
      "learning_rate": 3.3093333333333333e-07,
      "logits/chosen": -2.757707357406616,
      "logits/rejected": -2.279689073562622,
      "logps/chosen": -112.65360260009766,
      "logps/rejected": -160.56808471679688,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7225303649902344,
      "rewards/margins": 10.400562286376953,
      "rewards/rejected": -9.678031921386719,
      "step": 5019
    },
    {
      "epoch": 2.008,
      "grad_norm": 0.3904851973056793,
      "learning_rate": 3.3079999999999997e-07,
      "logits/chosen": -2.7472753524780273,
      "logits/rejected": -2.5852513313293457,
      "logps/chosen": -98.91140747070312,
      "logps/rejected": -204.68800354003906,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8525745868682861,
      "rewards/margins": 15.28579330444336,
      "rewards/rejected": -14.433219909667969,
      "step": 5020
    },
    {
      "epoch": 2.0084,
      "grad_norm": 1.3990422487258911,
      "learning_rate": 3.3066666666666666e-07,
      "logits/chosen": -2.6937530040740967,
      "logits/rejected": -2.564509868621826,
      "logps/chosen": -66.26539611816406,
      "logps/rejected": -100.61448669433594,
      "loss": 0.0104,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.050548791885376,
      "rewards/margins": 5.293023586273193,
      "rewards/rejected": -6.343572616577148,
      "step": 5021
    },
    {
      "epoch": 2.0088,
      "grad_norm": 0.037766728550195694,
      "learning_rate": 3.3053333333333335e-07,
      "logits/chosen": -3.034435510635376,
      "logits/rejected": -2.2732510566711426,
      "logps/chosen": -62.316864013671875,
      "logps/rejected": -132.9984130859375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4125089645385742,
      "rewards/margins": 8.673372268676758,
      "rewards/rejected": -8.260863304138184,
      "step": 5022
    },
    {
      "epoch": 2.0092,
      "grad_norm": 3.372710943222046,
      "learning_rate": 3.304e-07,
      "logits/chosen": -2.7304563522338867,
      "logits/rejected": -2.328939914703369,
      "logps/chosen": -122.31742095947266,
      "logps/rejected": -154.50086975097656,
      "loss": 0.0197,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7234466075897217,
      "rewards/margins": 8.573637008666992,
      "rewards/rejected": -10.297083854675293,
      "step": 5023
    },
    {
      "epoch": 2.0096,
      "grad_norm": 0.025528037920594215,
      "learning_rate": 3.3026666666666663e-07,
      "logits/chosen": -2.600404739379883,
      "logits/rejected": -2.5162158012390137,
      "logps/chosen": -91.96818542480469,
      "logps/rejected": -132.1602783203125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.011199951171875,
      "rewards/margins": 9.568557739257812,
      "rewards/rejected": -8.557357788085938,
      "step": 5024
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.23697501420974731,
      "learning_rate": 3.301333333333333e-07,
      "logits/chosen": -2.6408045291900635,
      "logits/rejected": -2.3944478034973145,
      "logps/chosen": -91.37826538085938,
      "logps/rejected": -121.22779846191406,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0633327960968018,
      "rewards/margins": 8.507091522216797,
      "rewards/rejected": -7.443758964538574,
      "step": 5025
    },
    {
      "epoch": 2.0104,
      "grad_norm": 1.441192626953125,
      "learning_rate": 3.3e-07,
      "logits/chosen": -2.84224796295166,
      "logits/rejected": -2.6728084087371826,
      "logps/chosen": -67.09270477294922,
      "logps/rejected": -90.07672119140625,
      "loss": 0.0081,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7395251989364624,
      "rewards/margins": 5.301822185516357,
      "rewards/rejected": -6.041347503662109,
      "step": 5026
    },
    {
      "epoch": 2.0108,
      "grad_norm": 0.1566956788301468,
      "learning_rate": 3.298666666666666e-07,
      "logits/chosen": -2.709528923034668,
      "logits/rejected": -2.5201847553253174,
      "logps/chosen": -150.9368438720703,
      "logps/rejected": -160.55841064453125,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2918674945831299,
      "rewards/margins": 9.396154403686523,
      "rewards/rejected": -10.688021659851074,
      "step": 5027
    },
    {
      "epoch": 2.0112,
      "grad_norm": 0.007418094668537378,
      "learning_rate": 3.297333333333333e-07,
      "logits/chosen": -2.5521326065063477,
      "logits/rejected": -2.121212959289551,
      "logps/chosen": -111.88337707519531,
      "logps/rejected": -192.8982391357422,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7558941841125488,
      "rewards/margins": 10.485610961914062,
      "rewards/rejected": -12.241504669189453,
      "step": 5028
    },
    {
      "epoch": 2.0116,
      "grad_norm": 0.0003557628660928458,
      "learning_rate": 3.296e-07,
      "logits/chosen": -2.6155927181243896,
      "logits/rejected": -1.9829694032669067,
      "logps/chosen": -132.9452667236328,
      "logps/rejected": -193.102294921875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0647633075714111,
      "rewards/margins": 13.4605131149292,
      "rewards/rejected": -14.525276184082031,
      "step": 5029
    },
    {
      "epoch": 2.012,
      "grad_norm": 0.17460843920707703,
      "learning_rate": 3.294666666666667e-07,
      "logits/chosen": -2.8015904426574707,
      "logits/rejected": -2.388270378112793,
      "logps/chosen": -58.15385818481445,
      "logps/rejected": -140.89617919921875,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3009430170059204,
      "rewards/margins": 8.949872970581055,
      "rewards/rejected": -9.250816345214844,
      "step": 5030
    },
    {
      "epoch": 2.0124,
      "grad_norm": 0.06286031752824783,
      "learning_rate": 3.293333333333333e-07,
      "logits/chosen": -2.837665557861328,
      "logits/rejected": -2.6441733837127686,
      "logps/chosen": -59.848388671875,
      "logps/rejected": -121.1898422241211,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0782819986343384,
      "rewards/margins": 9.087749481201172,
      "rewards/rejected": -8.009468078613281,
      "step": 5031
    },
    {
      "epoch": 2.0128,
      "grad_norm": 0.05201203376054764,
      "learning_rate": 3.2919999999999996e-07,
      "logits/chosen": -2.658799648284912,
      "logits/rejected": -2.066005229949951,
      "logps/chosen": -122.24136352539062,
      "logps/rejected": -156.48580932617188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.07848626375198364,
      "rewards/margins": 8.793845176696777,
      "rewards/rejected": -8.872331619262695,
      "step": 5032
    },
    {
      "epoch": 2.0132,
      "grad_norm": 0.03831387683749199,
      "learning_rate": 3.2906666666666665e-07,
      "logits/chosen": -2.633100986480713,
      "logits/rejected": -2.049868583679199,
      "logps/chosen": -174.09877014160156,
      "logps/rejected": -179.04722595214844,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.22667771577835083,
      "rewards/margins": 9.987028121948242,
      "rewards/rejected": -10.213706970214844,
      "step": 5033
    },
    {
      "epoch": 2.0136,
      "grad_norm": 0.0003317532246001065,
      "learning_rate": 3.2893333333333334e-07,
      "logits/chosen": -2.6681771278381348,
      "logits/rejected": -2.190857410430908,
      "logps/chosen": -75.51417541503906,
      "logps/rejected": -223.4044189453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1333789825439453,
      "rewards/margins": 15.924646377563477,
      "rewards/rejected": -14.791267395019531,
      "step": 5034
    },
    {
      "epoch": 2.014,
      "grad_norm": 122.39541625976562,
      "learning_rate": 3.288e-07,
      "logits/chosen": -2.6353962421417236,
      "logits/rejected": -2.4705076217651367,
      "logps/chosen": -173.7911834716797,
      "logps/rejected": -179.479736328125,
      "loss": 0.8258,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -8.631007194519043,
      "rewards/margins": 3.761176109313965,
      "rewards/rejected": -12.392183303833008,
      "step": 5035
    },
    {
      "epoch": 2.0144,
      "grad_norm": 0.33032017946243286,
      "learning_rate": 3.2866666666666667e-07,
      "logits/chosen": -2.9361557960510254,
      "logits/rejected": -2.6246190071105957,
      "logps/chosen": -61.53358840942383,
      "logps/rejected": -86.06036376953125,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5985641479492188,
      "rewards/margins": 6.183083534240723,
      "rewards/rejected": -5.584519386291504,
      "step": 5036
    },
    {
      "epoch": 2.0148,
      "grad_norm": 8.715003059478477e-05,
      "learning_rate": 3.285333333333333e-07,
      "logits/chosen": -2.4554734230041504,
      "logits/rejected": -1.6345899105072021,
      "logps/chosen": -92.20864868164062,
      "logps/rejected": -260.4974670410156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8371937274932861,
      "rewards/margins": 15.88587760925293,
      "rewards/rejected": -14.048684120178223,
      "step": 5037
    },
    {
      "epoch": 2.0152,
      "grad_norm": 0.005067481659352779,
      "learning_rate": 3.284e-07,
      "logits/chosen": -3.1291754245758057,
      "logits/rejected": -2.5134034156799316,
      "logps/chosen": -71.91334533691406,
      "logps/rejected": -205.4624481201172,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0799267292022705,
      "rewards/margins": 14.776103973388672,
      "rewards/rejected": -13.696176528930664,
      "step": 5038
    },
    {
      "epoch": 2.0156,
      "grad_norm": 0.07679358869791031,
      "learning_rate": 3.2826666666666664e-07,
      "logits/chosen": -2.9667482376098633,
      "logits/rejected": -2.825666904449463,
      "logps/chosen": -74.73649597167969,
      "logps/rejected": -120.14254760742188,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31408578157424927,
      "rewards/margins": 7.869211196899414,
      "rewards/rejected": -7.555125713348389,
      "step": 5039
    },
    {
      "epoch": 2.016,
      "grad_norm": 0.0013193658087402582,
      "learning_rate": 3.2813333333333333e-07,
      "logits/chosen": -2.3179426193237305,
      "logits/rejected": -1.393252968788147,
      "logps/chosen": -110.66056823730469,
      "logps/rejected": -300.320556640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.006641149520874,
      "rewards/margins": 13.414706230163574,
      "rewards/rejected": -11.408064842224121,
      "step": 5040
    },
    {
      "epoch": 2.0164,
      "grad_norm": 0.5673644542694092,
      "learning_rate": 3.28e-07,
      "logits/chosen": -2.946690559387207,
      "logits/rejected": -2.239875316619873,
      "logps/chosen": -66.99385070800781,
      "logps/rejected": -163.26522827148438,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6139219403266907,
      "rewards/margins": 10.619482040405273,
      "rewards/rejected": -10.005559921264648,
      "step": 5041
    },
    {
      "epoch": 2.0168,
      "grad_norm": 0.11432868242263794,
      "learning_rate": 3.278666666666666e-07,
      "logits/chosen": -2.6785292625427246,
      "logits/rejected": -2.389802932739258,
      "logps/chosen": -155.68136596679688,
      "logps/rejected": -195.52659606933594,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.0789923667907715,
      "rewards/margins": 8.625747680664062,
      "rewards/rejected": -12.704740524291992,
      "step": 5042
    },
    {
      "epoch": 2.0172,
      "grad_norm": 0.021741198375821114,
      "learning_rate": 3.277333333333333e-07,
      "logits/chosen": -2.8167386054992676,
      "logits/rejected": -1.926790475845337,
      "logps/chosen": -111.61665344238281,
      "logps/rejected": -159.28292846679688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3206375241279602,
      "rewards/margins": 10.764669418334961,
      "rewards/rejected": -10.444031715393066,
      "step": 5043
    },
    {
      "epoch": 2.0176,
      "grad_norm": 0.062332216650247574,
      "learning_rate": 3.276e-07,
      "logits/chosen": -2.4878649711608887,
      "logits/rejected": -1.971038579940796,
      "logps/chosen": -123.68077087402344,
      "logps/rejected": -159.49444580078125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.04256591200828552,
      "rewards/margins": 9.724686622619629,
      "rewards/rejected": -9.767252922058105,
      "step": 5044
    },
    {
      "epoch": 2.018,
      "grad_norm": 0.0006003809976391494,
      "learning_rate": 3.274666666666667e-07,
      "logits/chosen": -2.8048605918884277,
      "logits/rejected": -2.0374350547790527,
      "logps/chosen": -135.91525268554688,
      "logps/rejected": -202.62661743164062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6667636632919312,
      "rewards/margins": 13.826769828796387,
      "rewards/rejected": -13.160006523132324,
      "step": 5045
    },
    {
      "epoch": 2.0184,
      "grad_norm": 0.0049353307113051414,
      "learning_rate": 3.2733333333333327e-07,
      "logits/chosen": -2.630664825439453,
      "logits/rejected": -2.305159568786621,
      "logps/chosen": -99.37452697753906,
      "logps/rejected": -211.16244506835938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.093616008758545,
      "rewards/margins": 13.75086498260498,
      "rewards/rejected": -11.657249450683594,
      "step": 5046
    },
    {
      "epoch": 2.0188,
      "grad_norm": 0.05105944350361824,
      "learning_rate": 3.2719999999999997e-07,
      "logits/chosen": -2.9706673622131348,
      "logits/rejected": -2.712217330932617,
      "logps/chosen": -63.690086364746094,
      "logps/rejected": -163.38919067382812,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1386206150054932,
      "rewards/margins": 9.119661331176758,
      "rewards/rejected": -10.258281707763672,
      "step": 5047
    },
    {
      "epoch": 2.0192,
      "grad_norm": 0.002955041592940688,
      "learning_rate": 3.2706666666666666e-07,
      "logits/chosen": -2.551809787750244,
      "logits/rejected": -1.9234588146209717,
      "logps/chosen": -163.92372131347656,
      "logps/rejected": -167.2103271484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3990590572357178,
      "rewards/margins": 11.236987113952637,
      "rewards/rejected": -11.636046409606934,
      "step": 5048
    },
    {
      "epoch": 2.0196,
      "grad_norm": 0.002091823611408472,
      "learning_rate": 3.2693333333333335e-07,
      "logits/chosen": -2.6313838958740234,
      "logits/rejected": -2.089916944503784,
      "logps/chosen": -97.78997039794922,
      "logps/rejected": -164.96302795410156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2851948738098145,
      "rewards/margins": 11.842339515686035,
      "rewards/rejected": -10.557144165039062,
      "step": 5049
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.05734658241271973,
      "learning_rate": 3.268e-07,
      "logits/chosen": -2.57763934135437,
      "logits/rejected": -1.9980138540267944,
      "logps/chosen": -86.09373474121094,
      "logps/rejected": -153.86480712890625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8923977613449097,
      "rewards/margins": 10.005853652954102,
      "rewards/rejected": -8.113456726074219,
      "step": 5050
    },
    {
      "epoch": 2.0204,
      "grad_norm": 0.1269979178905487,
      "learning_rate": 3.2666666666666663e-07,
      "logits/chosen": -2.6628739833831787,
      "logits/rejected": -1.9369890689849854,
      "logps/chosen": -73.11801147460938,
      "logps/rejected": -179.32005310058594,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9789583683013916,
      "rewards/margins": 10.963302612304688,
      "rewards/rejected": -8.984344482421875,
      "step": 5051
    },
    {
      "epoch": 2.0208,
      "grad_norm": 1.7625410556793213,
      "learning_rate": 3.265333333333333e-07,
      "logits/chosen": -2.4099209308624268,
      "logits/rejected": -2.2754359245300293,
      "logps/chosen": -173.17958068847656,
      "logps/rejected": -130.4039306640625,
      "loss": 0.0064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0218114852905273,
      "rewards/margins": 5.6060261726379395,
      "rewards/rejected": -7.627837657928467,
      "step": 5052
    },
    {
      "epoch": 2.0212,
      "grad_norm": 0.9101059436798096,
      "learning_rate": 3.264e-07,
      "logits/chosen": -2.529118061065674,
      "logits/rejected": -2.290602207183838,
      "logps/chosen": -93.14525604248047,
      "logps/rejected": -156.366943359375,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8185842633247375,
      "rewards/margins": 10.038244247436523,
      "rewards/rejected": -9.219659805297852,
      "step": 5053
    },
    {
      "epoch": 2.0216,
      "grad_norm": 0.006822633557021618,
      "learning_rate": 3.2626666666666665e-07,
      "logits/chosen": -2.911031723022461,
      "logits/rejected": -2.47172212600708,
      "logps/chosen": -49.86612319946289,
      "logps/rejected": -145.04013061523438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45598143339157104,
      "rewards/margins": 10.532112121582031,
      "rewards/rejected": -10.076131820678711,
      "step": 5054
    },
    {
      "epoch": 2.022,
      "grad_norm": 0.0010037380270659924,
      "learning_rate": 3.2613333333333334e-07,
      "logits/chosen": -2.947744369506836,
      "logits/rejected": -2.6632022857666016,
      "logps/chosen": -85.50332641601562,
      "logps/rejected": -154.15769958496094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7842743396759033,
      "rewards/margins": 12.360428810119629,
      "rewards/rejected": -10.576154708862305,
      "step": 5055
    },
    {
      "epoch": 2.0224,
      "grad_norm": 7.769752119202167e-05,
      "learning_rate": 3.26e-07,
      "logits/chosen": -2.8428120613098145,
      "logits/rejected": -2.3325955867767334,
      "logps/chosen": -91.31944274902344,
      "logps/rejected": -210.54049682617188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14089277386665344,
      "rewards/margins": 15.635862350463867,
      "rewards/rejected": -15.494969367980957,
      "step": 5056
    },
    {
      "epoch": 2.0228,
      "grad_norm": 0.2436056137084961,
      "learning_rate": 3.2586666666666667e-07,
      "logits/chosen": -2.651139259338379,
      "logits/rejected": -2.6111912727355957,
      "logps/chosen": -114.81089782714844,
      "logps/rejected": -120.87759399414062,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3200758099555969,
      "rewards/margins": 6.290243148803711,
      "rewards/rejected": -6.610319137573242,
      "step": 5057
    },
    {
      "epoch": 2.0232,
      "grad_norm": 0.0019767109770327806,
      "learning_rate": 3.257333333333333e-07,
      "logits/chosen": -2.973393678665161,
      "logits/rejected": -2.6620006561279297,
      "logps/chosen": -140.20855712890625,
      "logps/rejected": -197.41098022460938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.41662275791168213,
      "rewards/margins": 11.878862380981445,
      "rewards/rejected": -12.295485496520996,
      "step": 5058
    },
    {
      "epoch": 2.0236,
      "grad_norm": 4.939547061920166,
      "learning_rate": 3.256e-07,
      "logits/chosen": -2.5591883659362793,
      "logits/rejected": -2.327979803085327,
      "logps/chosen": -241.06088256835938,
      "logps/rejected": -138.72610473632812,
      "loss": 0.03,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.371760368347168,
      "rewards/margins": 3.650986671447754,
      "rewards/rejected": -10.022747039794922,
      "step": 5059
    },
    {
      "epoch": 2.024,
      "grad_norm": 0.0075901588425040245,
      "learning_rate": 3.2546666666666664e-07,
      "logits/chosen": -2.801419258117676,
      "logits/rejected": -2.0615265369415283,
      "logps/chosen": -123.93449401855469,
      "logps/rejected": -202.73045349121094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2808975279331207,
      "rewards/margins": 11.549999237060547,
      "rewards/rejected": -11.830896377563477,
      "step": 5060
    },
    {
      "epoch": 2.0244,
      "grad_norm": 3.7014620304107666,
      "learning_rate": 3.253333333333333e-07,
      "logits/chosen": -2.623049259185791,
      "logits/rejected": -2.231895685195923,
      "logps/chosen": -87.97332000732422,
      "logps/rejected": -148.96603393554688,
      "loss": 0.0351,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6598455905914307,
      "rewards/margins": 8.907611846923828,
      "rewards/rejected": -8.247766494750977,
      "step": 5061
    },
    {
      "epoch": 2.0248,
      "grad_norm": 0.0020234270486980677,
      "learning_rate": 3.252e-07,
      "logits/chosen": -2.860637664794922,
      "logits/rejected": -3.032987594604492,
      "logps/chosen": -109.22469329833984,
      "logps/rejected": -183.77188110351562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3240394592285156,
      "rewards/margins": 11.878000259399414,
      "rewards/rejected": -10.553960800170898,
      "step": 5062
    },
    {
      "epoch": 2.0252,
      "grad_norm": 0.43616339564323425,
      "learning_rate": 3.2506666666666667e-07,
      "logits/chosen": -2.726905345916748,
      "logits/rejected": -2.648047924041748,
      "logps/chosen": -122.93794250488281,
      "logps/rejected": -118.07923889160156,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.539910078048706,
      "rewards/margins": 5.853480815887451,
      "rewards/rejected": -7.393390655517578,
      "step": 5063
    },
    {
      "epoch": 2.0256,
      "grad_norm": 0.01573537103831768,
      "learning_rate": 3.2493333333333336e-07,
      "logits/chosen": -3.201658248901367,
      "logits/rejected": -2.375791072845459,
      "logps/chosen": -75.20764923095703,
      "logps/rejected": -194.06744384765625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5507627725601196,
      "rewards/margins": 12.620460510253906,
      "rewards/rejected": -13.171222686767578,
      "step": 5064
    },
    {
      "epoch": 2.026,
      "grad_norm": 0.3516416549682617,
      "learning_rate": 3.2479999999999994e-07,
      "logits/chosen": -2.3743133544921875,
      "logits/rejected": -1.9776535034179688,
      "logps/chosen": -108.23272705078125,
      "logps/rejected": -170.3310546875,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0733723640441895,
      "rewards/margins": 7.983369827270508,
      "rewards/rejected": -10.056741714477539,
      "step": 5065
    },
    {
      "epoch": 2.0264,
      "grad_norm": 0.5286329388618469,
      "learning_rate": 3.2466666666666664e-07,
      "logits/chosen": -2.8083600997924805,
      "logits/rejected": -2.4914391040802,
      "logps/chosen": -59.11468505859375,
      "logps/rejected": -157.41860961914062,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0527260303497314,
      "rewards/margins": 8.21857738494873,
      "rewards/rejected": -9.271303176879883,
      "step": 5066
    },
    {
      "epoch": 2.0268,
      "grad_norm": 10.233269691467285,
      "learning_rate": 3.2453333333333333e-07,
      "logits/chosen": -2.5071749687194824,
      "logits/rejected": -1.9353036880493164,
      "logps/chosen": -147.6529541015625,
      "logps/rejected": -125.52082824707031,
      "loss": 0.0319,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.810667037963867,
      "rewards/margins": 5.85565185546875,
      "rewards/rejected": -8.666318893432617,
      "step": 5067
    },
    {
      "epoch": 2.0272,
      "grad_norm": 0.000491156242787838,
      "learning_rate": 3.244e-07,
      "logits/chosen": -2.8418145179748535,
      "logits/rejected": -1.995499849319458,
      "logps/chosen": -78.47797393798828,
      "logps/rejected": -188.13104248046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7227320075035095,
      "rewards/margins": 13.496562957763672,
      "rewards/rejected": -12.77383041381836,
      "step": 5068
    },
    {
      "epoch": 2.0276,
      "grad_norm": 0.004907518159598112,
      "learning_rate": 3.2426666666666666e-07,
      "logits/chosen": -2.5973362922668457,
      "logits/rejected": -1.6247811317443848,
      "logps/chosen": -106.59326171875,
      "logps/rejected": -190.59402465820312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7272804379463196,
      "rewards/margins": 12.185201644897461,
      "rewards/rejected": -11.457921028137207,
      "step": 5069
    },
    {
      "epoch": 2.028,
      "grad_norm": 0.007369686383754015,
      "learning_rate": 3.241333333333333e-07,
      "logits/chosen": -2.650364875793457,
      "logits/rejected": -1.7382986545562744,
      "logps/chosen": -133.87518310546875,
      "logps/rejected": -201.858642578125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3423171639442444,
      "rewards/margins": 11.012394905090332,
      "rewards/rejected": -10.67007827758789,
      "step": 5070
    },
    {
      "epoch": 2.0284,
      "grad_norm": 0.0033974554389715195,
      "learning_rate": 3.24e-07,
      "logits/chosen": -2.8479771614074707,
      "logits/rejected": -2.251255750656128,
      "logps/chosen": -94.77824401855469,
      "logps/rejected": -206.89132690429688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.09566421806812286,
      "rewards/margins": 13.433662414550781,
      "rewards/rejected": -13.529325485229492,
      "step": 5071
    },
    {
      "epoch": 2.0288,
      "grad_norm": 0.013659085147082806,
      "learning_rate": 3.238666666666667e-07,
      "logits/chosen": -2.8728601932525635,
      "logits/rejected": -2.3570423126220703,
      "logps/chosen": -63.0390510559082,
      "logps/rejected": -189.9801483154297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.47490620613098145,
      "rewards/margins": 12.40423583984375,
      "rewards/rejected": -12.879142761230469,
      "step": 5072
    },
    {
      "epoch": 2.0292,
      "grad_norm": 0.00014623602328356355,
      "learning_rate": 3.237333333333333e-07,
      "logits/chosen": -2.490407705307007,
      "logits/rejected": -1.8217626810073853,
      "logps/chosen": -150.20066833496094,
      "logps/rejected": -319.4127502441406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.13715440034866333,
      "rewards/margins": 16.20404052734375,
      "rewards/rejected": -16.34119415283203,
      "step": 5073
    },
    {
      "epoch": 2.0296,
      "grad_norm": 0.002188979648053646,
      "learning_rate": 3.2359999999999996e-07,
      "logits/chosen": -2.2567195892333984,
      "logits/rejected": -1.7377129793167114,
      "logps/chosen": -134.82896423339844,
      "logps/rejected": -200.08067321777344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.817592978477478,
      "rewards/margins": 11.842365264892578,
      "rewards/rejected": -11.024771690368652,
      "step": 5074
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.10278266668319702,
      "learning_rate": 3.2346666666666665e-07,
      "logits/chosen": -2.5515472888946533,
      "logits/rejected": -1.8354926109313965,
      "logps/chosen": -159.11322021484375,
      "logps/rejected": -129.67684936523438,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.730194091796875,
      "rewards/margins": 8.071775436401367,
      "rewards/rejected": -8.801969528198242,
      "step": 5075
    },
    {
      "epoch": 2.0304,
      "grad_norm": 0.013097597286105156,
      "learning_rate": 3.233333333333333e-07,
      "logits/chosen": -2.2634387016296387,
      "logits/rejected": -1.6851305961608887,
      "logps/chosen": -108.91087341308594,
      "logps/rejected": -202.90126037597656,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8279949426651001,
      "rewards/margins": 11.266221046447754,
      "rewards/rejected": -10.438226699829102,
      "step": 5076
    },
    {
      "epoch": 2.0308,
      "grad_norm": 5.832391616422683e-05,
      "learning_rate": 3.232e-07,
      "logits/chosen": -3.148914337158203,
      "logits/rejected": -2.256704330444336,
      "logps/chosen": -41.98447036743164,
      "logps/rejected": -205.7105255126953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6840678453445435,
      "rewards/margins": 15.466184616088867,
      "rewards/rejected": -14.782116889953613,
      "step": 5077
    },
    {
      "epoch": 2.0312,
      "grad_norm": 1.1478112936019897,
      "learning_rate": 3.230666666666667e-07,
      "logits/chosen": -2.9884300231933594,
      "logits/rejected": -2.844670295715332,
      "logps/chosen": -68.39649963378906,
      "logps/rejected": -99.1794662475586,
      "loss": 0.0097,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5487751364707947,
      "rewards/margins": 5.1045331954956055,
      "rewards/rejected": -5.653308868408203,
      "step": 5078
    },
    {
      "epoch": 2.0316,
      "grad_norm": 0.0032033284660428762,
      "learning_rate": 3.229333333333333e-07,
      "logits/chosen": -2.9305129051208496,
      "logits/rejected": -2.527866840362549,
      "logps/chosen": -111.88130187988281,
      "logps/rejected": -167.84762573242188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.47777366638183594,
      "rewards/margins": 11.188282012939453,
      "rewards/rejected": -10.710508346557617,
      "step": 5079
    },
    {
      "epoch": 2.032,
      "grad_norm": 0.0017740818439051509,
      "learning_rate": 3.2279999999999995e-07,
      "logits/chosen": -2.809837818145752,
      "logits/rejected": -2.2671151161193848,
      "logps/chosen": -126.88207244873047,
      "logps/rejected": -169.6644287109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.04545477032661438,
      "rewards/margins": 11.727716445922852,
      "rewards/rejected": -11.773170471191406,
      "step": 5080
    },
    {
      "epoch": 2.0324,
      "grad_norm": 4.997570514678955,
      "learning_rate": 3.2266666666666664e-07,
      "logits/chosen": -2.828660488128662,
      "logits/rejected": -2.951969623565674,
      "logps/chosen": -84.98542022705078,
      "logps/rejected": -82.39049530029297,
      "loss": 0.0535,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3141037225723267,
      "rewards/margins": 3.591217041015625,
      "rewards/rejected": -4.905320644378662,
      "step": 5081
    },
    {
      "epoch": 2.0328,
      "grad_norm": 0.7351415753364563,
      "learning_rate": 3.2253333333333334e-07,
      "logits/chosen": -2.891653537750244,
      "logits/rejected": -2.5623130798339844,
      "logps/chosen": -40.727699279785156,
      "logps/rejected": -96.59326171875,
      "loss": 0.0048,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.026892662048339844,
      "rewards/margins": 6.154825210571289,
      "rewards/rejected": -6.181717872619629,
      "step": 5082
    },
    {
      "epoch": 2.0332,
      "grad_norm": 0.2410483956336975,
      "learning_rate": 3.2240000000000003e-07,
      "logits/chosen": -2.7250657081604004,
      "logits/rejected": -1.9387497901916504,
      "logps/chosen": -140.7919464111328,
      "logps/rejected": -155.2184600830078,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.645846962928772,
      "rewards/margins": 10.777047157287598,
      "rewards/rejected": -11.422894477844238,
      "step": 5083
    },
    {
      "epoch": 2.0336,
      "grad_norm": 1.1573388576507568,
      "learning_rate": 3.222666666666666e-07,
      "logits/chosen": -2.8629438877105713,
      "logits/rejected": -2.755070209503174,
      "logps/chosen": -97.98147583007812,
      "logps/rejected": -126.93560028076172,
      "loss": 0.0079,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05360066890716553,
      "rewards/margins": 7.7804059982299805,
      "rewards/rejected": -7.726805686950684,
      "step": 5084
    },
    {
      "epoch": 2.034,
      "grad_norm": 2.40283465385437,
      "learning_rate": 3.221333333333333e-07,
      "logits/chosen": -2.4532082080841064,
      "logits/rejected": -2.150860548019409,
      "logps/chosen": -120.84465026855469,
      "logps/rejected": -131.57113647460938,
      "loss": 0.0139,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9538570642471313,
      "rewards/margins": 8.145567893981934,
      "rewards/rejected": -9.099425315856934,
      "step": 5085
    },
    {
      "epoch": 2.0344,
      "grad_norm": 0.0034585969988256693,
      "learning_rate": 3.22e-07,
      "logits/chosen": -2.5515213012695312,
      "logits/rejected": -1.9769172668457031,
      "logps/chosen": -79.8663330078125,
      "logps/rejected": -189.19070434570312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1364220380783081,
      "rewards/margins": 13.553430557250977,
      "rewards/rejected": -13.417007446289062,
      "step": 5086
    },
    {
      "epoch": 2.0348,
      "grad_norm": 0.0008659568848088384,
      "learning_rate": 3.218666666666667e-07,
      "logits/chosen": -2.3567581176757812,
      "logits/rejected": -1.438999056816101,
      "logps/chosen": -121.6224136352539,
      "logps/rejected": -205.50802612304688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2475074678659439,
      "rewards/margins": 13.059669494628906,
      "rewards/rejected": -12.812162399291992,
      "step": 5087
    },
    {
      "epoch": 2.0352,
      "grad_norm": 0.025976475328207016,
      "learning_rate": 3.217333333333333e-07,
      "logits/chosen": -2.799556255340576,
      "logits/rejected": -2.5109877586364746,
      "logps/chosen": -67.16036987304688,
      "logps/rejected": -170.19223022460938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.11945152282714844,
      "rewards/margins": 10.905717849731445,
      "rewards/rejected": -11.025169372558594,
      "step": 5088
    },
    {
      "epoch": 2.0356,
      "grad_norm": 0.010318493470549583,
      "learning_rate": 3.2159999999999997e-07,
      "logits/chosen": -2.7648072242736816,
      "logits/rejected": -2.099597930908203,
      "logps/chosen": -155.29856872558594,
      "logps/rejected": -209.2654266357422,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9408193826675415,
      "rewards/margins": 10.63024616241455,
      "rewards/rejected": -12.571065902709961,
      "step": 5089
    },
    {
      "epoch": 2.036,
      "grad_norm": 0.00036914137308485806,
      "learning_rate": 3.2146666666666666e-07,
      "logits/chosen": -2.5553359985351562,
      "logits/rejected": -1.8862924575805664,
      "logps/chosen": -123.02713775634766,
      "logps/rejected": -211.45022583007812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9634109735488892,
      "rewards/margins": 13.472043991088867,
      "rewards/rejected": -14.435454368591309,
      "step": 5090
    },
    {
      "epoch": 2.0364,
      "grad_norm": 0.0021475704852491617,
      "learning_rate": 3.2133333333333335e-07,
      "logits/chosen": -2.9056339263916016,
      "logits/rejected": -2.470811367034912,
      "logps/chosen": -86.19377136230469,
      "logps/rejected": -201.0814208984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9612648487091064,
      "rewards/margins": 11.888769149780273,
      "rewards/rejected": -13.8500337600708,
      "step": 5091
    },
    {
      "epoch": 2.0368,
      "grad_norm": 0.4334491789340973,
      "learning_rate": 3.212e-07,
      "logits/chosen": -2.746725559234619,
      "logits/rejected": -2.5529422760009766,
      "logps/chosen": -51.12692642211914,
      "logps/rejected": -74.7442398071289,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9939963817596436,
      "rewards/margins": 6.118314266204834,
      "rewards/rejected": -5.1243181228637695,
      "step": 5092
    },
    {
      "epoch": 2.0372,
      "grad_norm": 0.1972152590751648,
      "learning_rate": 3.2106666666666663e-07,
      "logits/chosen": -2.809225082397461,
      "logits/rejected": -2.5408549308776855,
      "logps/chosen": -107.96661376953125,
      "logps/rejected": -143.0357666015625,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.21373403072357178,
      "rewards/margins": 8.745408058166504,
      "rewards/rejected": -8.959141731262207,
      "step": 5093
    },
    {
      "epoch": 2.0376,
      "grad_norm": 45.98031234741211,
      "learning_rate": 3.209333333333333e-07,
      "logits/chosen": -2.7723302841186523,
      "logits/rejected": -2.6940245628356934,
      "logps/chosen": -168.45481872558594,
      "logps/rejected": -131.65780639648438,
      "loss": 0.1528,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.391012668609619,
      "rewards/margins": 5.68731689453125,
      "rewards/rejected": -9.078330039978027,
      "step": 5094
    },
    {
      "epoch": 2.038,
      "grad_norm": 2.842783212661743,
      "learning_rate": 3.2079999999999996e-07,
      "logits/chosen": -2.379070281982422,
      "logits/rejected": -2.270057439804077,
      "logps/chosen": -75.40845489501953,
      "logps/rejected": -118.31539916992188,
      "loss": 0.0122,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9504740238189697,
      "rewards/margins": 5.731878757476807,
      "rewards/rejected": -7.6823530197143555,
      "step": 5095
    },
    {
      "epoch": 2.0384,
      "grad_norm": 1.7332035303115845,
      "learning_rate": 3.2066666666666665e-07,
      "logits/chosen": -2.8058485984802246,
      "logits/rejected": -2.5999391078948975,
      "logps/chosen": -67.49105072021484,
      "logps/rejected": -156.067138671875,
      "loss": 0.0092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8800253868103027,
      "rewards/margins": 8.474579811096191,
      "rewards/rejected": -10.354605674743652,
      "step": 5096
    },
    {
      "epoch": 2.0388,
      "grad_norm": 0.030892174690961838,
      "learning_rate": 3.2053333333333334e-07,
      "logits/chosen": -2.9109108448028564,
      "logits/rejected": -2.501387119293213,
      "logps/chosen": -79.54732513427734,
      "logps/rejected": -139.43418884277344,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6932525634765625,
      "rewards/margins": 9.230142593383789,
      "rewards/rejected": -9.923395156860352,
      "step": 5097
    },
    {
      "epoch": 2.0392,
      "grad_norm": 0.010217479430139065,
      "learning_rate": 3.204e-07,
      "logits/chosen": -3.072201728820801,
      "logits/rejected": -2.385769844055176,
      "logps/chosen": -36.936344146728516,
      "logps/rejected": -164.52926635742188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8730587959289551,
      "rewards/margins": 10.742679595947266,
      "rewards/rejected": -9.869621276855469,
      "step": 5098
    },
    {
      "epoch": 2.0396,
      "grad_norm": 0.4054246246814728,
      "learning_rate": 3.202666666666666e-07,
      "logits/chosen": -2.8998031616210938,
      "logits/rejected": -2.6528944969177246,
      "logps/chosen": -65.26626586914062,
      "logps/rejected": -125.44157409667969,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7013667821884155,
      "rewards/margins": 8.82672119140625,
      "rewards/rejected": -8.125353813171387,
      "step": 5099
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.0076936776749789715,
      "learning_rate": 3.201333333333333e-07,
      "logits/chosen": -2.5217766761779785,
      "logits/rejected": -2.2874362468719482,
      "logps/chosen": -53.285057067871094,
      "logps/rejected": -154.935302734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6450515985488892,
      "rewards/margins": 10.365409851074219,
      "rewards/rejected": -9.720357894897461,
      "step": 5100
    },
    {
      "epoch": 2.0404,
      "grad_norm": 0.22135503590106964,
      "learning_rate": 3.2e-07,
      "logits/chosen": -2.4556517601013184,
      "logits/rejected": -1.855651617050171,
      "logps/chosen": -127.90341186523438,
      "logps/rejected": -201.82095336914062,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.894038736820221,
      "rewards/margins": 10.698541641235352,
      "rewards/rejected": -11.592580795288086,
      "step": 5101
    },
    {
      "epoch": 2.0408,
      "grad_norm": 0.03582247719168663,
      "learning_rate": 3.198666666666667e-07,
      "logits/chosen": -3.052795886993408,
      "logits/rejected": -2.62450909614563,
      "logps/chosen": -42.99552917480469,
      "logps/rejected": -142.4462890625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.663119912147522,
      "rewards/margins": 10.992521286010742,
      "rewards/rejected": -9.329401969909668,
      "step": 5102
    },
    {
      "epoch": 2.0412,
      "grad_norm": 1.5479649305343628,
      "learning_rate": 3.197333333333333e-07,
      "logits/chosen": -2.448491096496582,
      "logits/rejected": -2.2515928745269775,
      "logps/chosen": -139.301513671875,
      "logps/rejected": -147.76901245117188,
      "loss": 0.0072,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.3783085346221924,
      "rewards/margins": 6.456902027130127,
      "rewards/rejected": -8.835210800170898,
      "step": 5103
    },
    {
      "epoch": 2.0416,
      "grad_norm": 0.04001624137163162,
      "learning_rate": 3.196e-07,
      "logits/chosen": -2.6287925243377686,
      "logits/rejected": -1.8273556232452393,
      "logps/chosen": -55.170143127441406,
      "logps/rejected": -154.44351196289062,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22733384370803833,
      "rewards/margins": 11.318746566772461,
      "rewards/rejected": -11.091412544250488,
      "step": 5104
    },
    {
      "epoch": 2.042,
      "grad_norm": 0.12788404524326324,
      "learning_rate": 3.1946666666666667e-07,
      "logits/chosen": -2.867448329925537,
      "logits/rejected": -2.423434019088745,
      "logps/chosen": -67.8189926147461,
      "logps/rejected": -135.40835571289062,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.48253917694091797,
      "rewards/margins": 9.209670066833496,
      "rewards/rejected": -9.692209243774414,
      "step": 5105
    },
    {
      "epoch": 2.0424,
      "grad_norm": 72.9097671508789,
      "learning_rate": 3.1933333333333336e-07,
      "logits/chosen": -2.211380958557129,
      "logits/rejected": -1.49994957447052,
      "logps/chosen": -293.0246887207031,
      "logps/rejected": -196.13314819335938,
      "loss": 0.3049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.381598472595215,
      "rewards/margins": 6.354911804199219,
      "rewards/rejected": -13.736510276794434,
      "step": 5106
    },
    {
      "epoch": 2.0428,
      "grad_norm": 0.0050697834230959415,
      "learning_rate": 3.1919999999999995e-07,
      "logits/chosen": -2.446059465408325,
      "logits/rejected": -1.9849836826324463,
      "logps/chosen": -135.30845642089844,
      "logps/rejected": -182.52413940429688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.29055407643318176,
      "rewards/margins": 12.011272430419922,
      "rewards/rejected": -12.301826477050781,
      "step": 5107
    },
    {
      "epoch": 2.0432,
      "grad_norm": 0.04821905866265297,
      "learning_rate": 3.1906666666666664e-07,
      "logits/chosen": -2.680860996246338,
      "logits/rejected": -1.869674563407898,
      "logps/chosen": -34.938934326171875,
      "logps/rejected": -176.59127807617188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.317495346069336,
      "rewards/margins": 13.408595085144043,
      "rewards/rejected": -11.091099739074707,
      "step": 5108
    },
    {
      "epoch": 2.0436,
      "grad_norm": 0.22686201333999634,
      "learning_rate": 3.1893333333333333e-07,
      "logits/chosen": -2.6730704307556152,
      "logits/rejected": -2.443054676055908,
      "logps/chosen": -114.03116607666016,
      "logps/rejected": -122.95077514648438,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.1431057453155518,
      "rewards/margins": 6.704651832580566,
      "rewards/rejected": -8.847757339477539,
      "step": 5109
    },
    {
      "epoch": 2.044,
      "grad_norm": 0.004912335891276598,
      "learning_rate": 3.1879999999999997e-07,
      "logits/chosen": -2.6236181259155273,
      "logits/rejected": -1.7317581176757812,
      "logps/chosen": -118.00799560546875,
      "logps/rejected": -247.91604614257812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5228298306465149,
      "rewards/margins": 15.377103805541992,
      "rewards/rejected": -14.854272842407227,
      "step": 5110
    },
    {
      "epoch": 2.0444,
      "grad_norm": 0.00022006362269166857,
      "learning_rate": 3.1866666666666666e-07,
      "logits/chosen": -2.3683056831359863,
      "logits/rejected": -1.4872595071792603,
      "logps/chosen": -107.48928833007812,
      "logps/rejected": -232.94615173339844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9881840348243713,
      "rewards/margins": 14.966239929199219,
      "rewards/rejected": -13.978055953979492,
      "step": 5111
    },
    {
      "epoch": 2.0448,
      "grad_norm": 0.02314124070107937,
      "learning_rate": 3.185333333333333e-07,
      "logits/chosen": -2.338890552520752,
      "logits/rejected": -2.064159393310547,
      "logps/chosen": -73.73433685302734,
      "logps/rejected": -157.0631103515625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15553294122219086,
      "rewards/margins": 9.87338924407959,
      "rewards/rejected": -9.717856407165527,
      "step": 5112
    },
    {
      "epoch": 2.0452,
      "grad_norm": 0.5383418202400208,
      "learning_rate": 3.184e-07,
      "logits/chosen": -2.689764976501465,
      "logits/rejected": -2.251800060272217,
      "logps/chosen": -80.39854431152344,
      "logps/rejected": -210.6027069091797,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2857681214809418,
      "rewards/margins": 8.998273849487305,
      "rewards/rejected": -9.284041404724121,
      "step": 5113
    },
    {
      "epoch": 2.0456,
      "grad_norm": 0.011417846195399761,
      "learning_rate": 3.1826666666666663e-07,
      "logits/chosen": -2.523516893386841,
      "logits/rejected": -2.107731819152832,
      "logps/chosen": -77.84397888183594,
      "logps/rejected": -167.98446655273438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3057198524475098,
      "rewards/margins": 11.872442245483398,
      "rewards/rejected": -10.566722869873047,
      "step": 5114
    },
    {
      "epoch": 2.046,
      "grad_norm": 0.004734891001135111,
      "learning_rate": 3.181333333333333e-07,
      "logits/chosen": -2.4200687408447266,
      "logits/rejected": -1.7898794412612915,
      "logps/chosen": -127.95328521728516,
      "logps/rejected": -259.6577453613281,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5025001764297485,
      "rewards/margins": 14.248981475830078,
      "rewards/rejected": -13.746480941772461,
      "step": 5115
    },
    {
      "epoch": 2.0464,
      "grad_norm": 0.0918906033039093,
      "learning_rate": 3.18e-07,
      "logits/chosen": -2.1241302490234375,
      "logits/rejected": -1.339186429977417,
      "logps/chosen": -177.56475830078125,
      "logps/rejected": -182.79835510253906,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.941396713256836,
      "rewards/margins": 9.958047866821289,
      "rewards/rejected": -11.899444580078125,
      "step": 5116
    },
    {
      "epoch": 2.0468,
      "grad_norm": 0.16838380694389343,
      "learning_rate": 3.1786666666666665e-07,
      "logits/chosen": -2.8319811820983887,
      "logits/rejected": -2.504086971282959,
      "logps/chosen": -61.37401580810547,
      "logps/rejected": -117.81124114990234,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8014307022094727,
      "rewards/margins": 7.961508274078369,
      "rewards/rejected": -7.1600775718688965,
      "step": 5117
    },
    {
      "epoch": 2.0472,
      "grad_norm": 0.43641093373298645,
      "learning_rate": 3.177333333333333e-07,
      "logits/chosen": -2.98481822013855,
      "logits/rejected": -2.6217703819274902,
      "logps/chosen": -75.38716888427734,
      "logps/rejected": -123.31837463378906,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0526354312896729,
      "rewards/margins": 7.682410717010498,
      "rewards/rejected": -8.73504638671875,
      "step": 5118
    },
    {
      "epoch": 2.0476,
      "grad_norm": 0.0008923285640776157,
      "learning_rate": 3.176e-07,
      "logits/chosen": -2.500192642211914,
      "logits/rejected": -1.740116834640503,
      "logps/chosen": -79.68157958984375,
      "logps/rejected": -208.40513610839844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8878692984580994,
      "rewards/margins": 14.144569396972656,
      "rewards/rejected": -13.25670051574707,
      "step": 5119
    },
    {
      "epoch": 2.048,
      "grad_norm": 18.866863250732422,
      "learning_rate": 3.174666666666667e-07,
      "logits/chosen": -2.840610980987549,
      "logits/rejected": -2.610785961151123,
      "logps/chosen": -75.08731079101562,
      "logps/rejected": -105.93817901611328,
      "loss": 0.1155,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5203027725219727,
      "rewards/margins": 5.306248664855957,
      "rewards/rejected": -6.82655143737793,
      "step": 5120
    },
    {
      "epoch": 2.0484,
      "grad_norm": 20.205114364624023,
      "learning_rate": 3.173333333333333e-07,
      "logits/chosen": -2.576012134552002,
      "logits/rejected": -2.45674204826355,
      "logps/chosen": -171.5076141357422,
      "logps/rejected": -111.47718811035156,
      "loss": 0.0754,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.8017101287841797,
      "rewards/margins": 4.820666313171387,
      "rewards/rejected": -7.622375965118408,
      "step": 5121
    },
    {
      "epoch": 2.0488,
      "grad_norm": 0.0018744741100817919,
      "learning_rate": 3.1719999999999996e-07,
      "logits/chosen": -2.6162500381469727,
      "logits/rejected": -2.1057910919189453,
      "logps/chosen": -152.6001739501953,
      "logps/rejected": -210.13327026367188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2797825336456299,
      "rewards/margins": 12.162172317504883,
      "rewards/rejected": -13.44195556640625,
      "step": 5122
    },
    {
      "epoch": 2.0492,
      "grad_norm": 0.047231514006853104,
      "learning_rate": 3.1706666666666665e-07,
      "logits/chosen": -2.9462318420410156,
      "logits/rejected": -2.6300406455993652,
      "logps/chosen": -52.63527297973633,
      "logps/rejected": -123.01573181152344,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5047489404678345,
      "rewards/margins": 9.673980712890625,
      "rewards/rejected": -8.169232368469238,
      "step": 5123
    },
    {
      "epoch": 2.0496,
      "grad_norm": 0.0018576219445094466,
      "learning_rate": 3.1693333333333334e-07,
      "logits/chosen": -2.648466110229492,
      "logits/rejected": -1.7789431810379028,
      "logps/chosen": -49.711769104003906,
      "logps/rejected": -220.88548278808594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9076200723648071,
      "rewards/margins": 12.751045227050781,
      "rewards/rejected": -11.843424797058105,
      "step": 5124
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.02363092079758644,
      "learning_rate": 3.1680000000000003e-07,
      "logits/chosen": -2.265477180480957,
      "logits/rejected": -1.648054599761963,
      "logps/chosen": -197.41021728515625,
      "logps/rejected": -275.13031005859375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.09611356258392334,
      "rewards/margins": 10.184637069702148,
      "rewards/rejected": -10.280750274658203,
      "step": 5125
    },
    {
      "epoch": 2.0504,
      "grad_norm": 0.05310319364070892,
      "learning_rate": 3.166666666666666e-07,
      "logits/chosen": -2.8861606121063232,
      "logits/rejected": -2.419485569000244,
      "logps/chosen": -64.16771697998047,
      "logps/rejected": -144.6695556640625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7185295224189758,
      "rewards/margins": 10.017999649047852,
      "rewards/rejected": -9.299470901489258,
      "step": 5126
    },
    {
      "epoch": 2.0508,
      "grad_norm": 0.03273310139775276,
      "learning_rate": 3.165333333333333e-07,
      "logits/chosen": -2.4333202838897705,
      "logits/rejected": -1.9172248840332031,
      "logps/chosen": -117.4015121459961,
      "logps/rejected": -170.189697265625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1284058094024658,
      "rewards/margins": 9.025701522827148,
      "rewards/rejected": -10.154108047485352,
      "step": 5127
    },
    {
      "epoch": 2.0512,
      "grad_norm": 0.001718872576020658,
      "learning_rate": 3.164e-07,
      "logits/chosen": -2.624025821685791,
      "logits/rejected": -2.1609315872192383,
      "logps/chosen": -92.71533203125,
      "logps/rejected": -151.71258544921875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5084564685821533,
      "rewards/margins": 12.250646591186523,
      "rewards/rejected": -10.742191314697266,
      "step": 5128
    },
    {
      "epoch": 2.0516,
      "grad_norm": 0.20322754979133606,
      "learning_rate": 3.1626666666666664e-07,
      "logits/chosen": -2.5980029106140137,
      "logits/rejected": -2.2501583099365234,
      "logps/chosen": -81.56647491455078,
      "logps/rejected": -191.01019287109375,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.041742146015167236,
      "rewards/margins": 10.664451599121094,
      "rewards/rejected": -10.706193923950195,
      "step": 5129
    },
    {
      "epoch": 2.052,
      "grad_norm": 0.02547500841319561,
      "learning_rate": 3.1613333333333333e-07,
      "logits/chosen": -2.9878110885620117,
      "logits/rejected": -2.20485520362854,
      "logps/chosen": -108.42688751220703,
      "logps/rejected": -143.05209350585938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3857284486293793,
      "rewards/margins": 9.953630447387695,
      "rewards/rejected": -9.567901611328125,
      "step": 5130
    },
    {
      "epoch": 2.0524,
      "grad_norm": 0.0010020353365689516,
      "learning_rate": 3.1599999999999997e-07,
      "logits/chosen": -2.4166934490203857,
      "logits/rejected": -1.7314203977584839,
      "logps/chosen": -153.8052215576172,
      "logps/rejected": -209.71917724609375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4013000428676605,
      "rewards/margins": 13.11578369140625,
      "rewards/rejected": -12.714483261108398,
      "step": 5131
    },
    {
      "epoch": 2.0528,
      "grad_norm": 27.0550594329834,
      "learning_rate": 3.1586666666666666e-07,
      "logits/chosen": -2.4613828659057617,
      "logits/rejected": -2.681253433227539,
      "logps/chosen": -130.13763427734375,
      "logps/rejected": -124.02912902832031,
      "loss": 0.1262,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9441959857940674,
      "rewards/margins": 6.565612316131592,
      "rewards/rejected": -8.509808540344238,
      "step": 5132
    },
    {
      "epoch": 2.0532,
      "grad_norm": 3.4523017406463623,
      "learning_rate": 3.157333333333333e-07,
      "logits/chosen": -2.504157543182373,
      "logits/rejected": -2.1446361541748047,
      "logps/chosen": -249.71414184570312,
      "logps/rejected": -203.9679412841797,
      "loss": 0.0155,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.915452003479004,
      "rewards/margins": 7.526299476623535,
      "rewards/rejected": -11.441751480102539,
      "step": 5133
    },
    {
      "epoch": 2.0536,
      "grad_norm": 0.9257113337516785,
      "learning_rate": 3.156e-07,
      "logits/chosen": -2.435844898223877,
      "logits/rejected": -2.027047634124756,
      "logps/chosen": -156.36270141601562,
      "logps/rejected": -129.43875122070312,
      "loss": 0.0065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.2175397872924805,
      "rewards/margins": 5.02923583984375,
      "rewards/rejected": -8.24677562713623,
      "step": 5134
    },
    {
      "epoch": 2.054,
      "grad_norm": 0.5857873558998108,
      "learning_rate": 3.1546666666666663e-07,
      "logits/chosen": -3.019678831100464,
      "logits/rejected": -2.760037899017334,
      "logps/chosen": -74.06875610351562,
      "logps/rejected": -103.57911682128906,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7211855053901672,
      "rewards/margins": 7.2063822746276855,
      "rewards/rejected": -6.485197067260742,
      "step": 5135
    },
    {
      "epoch": 2.0544,
      "grad_norm": 1.0528113842010498,
      "learning_rate": 3.153333333333333e-07,
      "logits/chosen": -2.553468704223633,
      "logits/rejected": -2.3548426628112793,
      "logps/chosen": -121.91856384277344,
      "logps/rejected": -160.9169921875,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1014680862426758,
      "rewards/margins": 8.672196388244629,
      "rewards/rejected": -9.773664474487305,
      "step": 5136
    },
    {
      "epoch": 2.0548,
      "grad_norm": 0.05301709473133087,
      "learning_rate": 3.1519999999999996e-07,
      "logits/chosen": -3.04982852935791,
      "logits/rejected": -2.8306350708007812,
      "logps/chosen": -62.96235275268555,
      "logps/rejected": -129.39537048339844,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5625631809234619,
      "rewards/margins": 8.54870891571045,
      "rewards/rejected": -9.111271858215332,
      "step": 5137
    },
    {
      "epoch": 2.0552,
      "grad_norm": 0.8260596990585327,
      "learning_rate": 3.1506666666666666e-07,
      "logits/chosen": -2.6911416053771973,
      "logits/rejected": -2.1608805656433105,
      "logps/chosen": -59.33890914916992,
      "logps/rejected": -139.95938110351562,
      "loss": 0.0063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7149899005889893,
      "rewards/margins": 9.478606224060059,
      "rewards/rejected": -8.763616561889648,
      "step": 5138
    },
    {
      "epoch": 2.0556,
      "grad_norm": 1.676377360126935e-05,
      "learning_rate": 3.1493333333333335e-07,
      "logits/chosen": -2.617002010345459,
      "logits/rejected": -1.755618691444397,
      "logps/chosen": -91.01710510253906,
      "logps/rejected": -245.78497314453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7172540426254272,
      "rewards/margins": 17.599002838134766,
      "rewards/rejected": -15.881750106811523,
      "step": 5139
    },
    {
      "epoch": 2.056,
      "grad_norm": 0.004747111815959215,
      "learning_rate": 3.148e-07,
      "logits/chosen": -2.791043281555176,
      "logits/rejected": -1.6834242343902588,
      "logps/chosen": -106.30886840820312,
      "logps/rejected": -223.73114013671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7522026300430298,
      "rewards/margins": 14.920896530151367,
      "rewards/rejected": -14.168693542480469,
      "step": 5140
    },
    {
      "epoch": 2.0564,
      "grad_norm": 0.0015433661174029112,
      "learning_rate": 3.146666666666666e-07,
      "logits/chosen": -2.9304981231689453,
      "logits/rejected": -2.3611536026000977,
      "logps/chosen": -89.56939697265625,
      "logps/rejected": -178.5570068359375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06563910841941833,
      "rewards/margins": 12.297189712524414,
      "rewards/rejected": -12.231550216674805,
      "step": 5141
    },
    {
      "epoch": 2.0568,
      "grad_norm": 0.0005020875832997262,
      "learning_rate": 3.145333333333333e-07,
      "logits/chosen": -2.6879727840423584,
      "logits/rejected": -1.9338525533676147,
      "logps/chosen": -84.32584381103516,
      "logps/rejected": -230.59812927246094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0646440982818604,
      "rewards/margins": 15.837638854980469,
      "rewards/rejected": -14.772994995117188,
      "step": 5142
    },
    {
      "epoch": 2.0572,
      "grad_norm": 2.5261058807373047,
      "learning_rate": 3.144e-07,
      "logits/chosen": -2.6654839515686035,
      "logits/rejected": -2.3925061225891113,
      "logps/chosen": -93.29578399658203,
      "logps/rejected": -99.77265930175781,
      "loss": 0.0212,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6022266745567322,
      "rewards/margins": 5.514229774475098,
      "rewards/rejected": -6.116456031799316,
      "step": 5143
    },
    {
      "epoch": 2.0576,
      "grad_norm": 0.11553148180246353,
      "learning_rate": 3.142666666666667e-07,
      "logits/chosen": -2.8190760612487793,
      "logits/rejected": -2.112074375152588,
      "logps/chosen": -84.53582000732422,
      "logps/rejected": -157.66668701171875,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1674447059631348,
      "rewards/margins": 10.452754974365234,
      "rewards/rejected": -9.285310745239258,
      "step": 5144
    },
    {
      "epoch": 2.058,
      "grad_norm": 1.6940956115722656,
      "learning_rate": 3.141333333333333e-07,
      "logits/chosen": -2.4050450325012207,
      "logits/rejected": -2.2198104858398438,
      "logps/chosen": -203.10829162597656,
      "logps/rejected": -204.35301208496094,
      "loss": 0.0059,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -5.40177059173584,
      "rewards/margins": 6.255582809448242,
      "rewards/rejected": -11.657353401184082,
      "step": 5145
    },
    {
      "epoch": 2.0584,
      "grad_norm": 0.06312789767980576,
      "learning_rate": 3.14e-07,
      "logits/chosen": -2.5810189247131348,
      "logits/rejected": -2.1460373401641846,
      "logps/chosen": -171.054931640625,
      "logps/rejected": -172.2417755126953,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5789378881454468,
      "rewards/margins": 8.135546684265137,
      "rewards/rejected": -9.714485168457031,
      "step": 5146
    },
    {
      "epoch": 2.0588,
      "grad_norm": 0.36606013774871826,
      "learning_rate": 3.1386666666666667e-07,
      "logits/chosen": -2.393171787261963,
      "logits/rejected": -1.8940536975860596,
      "logps/chosen": -105.32743835449219,
      "logps/rejected": -114.09272766113281,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5872272849082947,
      "rewards/margins": 7.522248268127441,
      "rewards/rejected": -6.935020923614502,
      "step": 5147
    },
    {
      "epoch": 2.0592,
      "grad_norm": 0.0033667278476059437,
      "learning_rate": 3.137333333333333e-07,
      "logits/chosen": -2.579463481903076,
      "logits/rejected": -1.8560233116149902,
      "logps/chosen": -81.10633087158203,
      "logps/rejected": -184.07774353027344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.03739297389984131,
      "rewards/margins": 12.187601089477539,
      "rewards/rejected": -12.224994659423828,
      "step": 5148
    },
    {
      "epoch": 2.0596,
      "grad_norm": 0.003139520063996315,
      "learning_rate": 3.1359999999999995e-07,
      "logits/chosen": -2.666321277618408,
      "logits/rejected": -1.6999647617340088,
      "logps/chosen": -123.23951721191406,
      "logps/rejected": -244.0152130126953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7479820251464844,
      "rewards/margins": 15.892681121826172,
      "rewards/rejected": -15.144699096679688,
      "step": 5149
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.03029395081102848,
      "learning_rate": 3.1346666666666664e-07,
      "logits/chosen": -2.9414167404174805,
      "logits/rejected": -2.7328057289123535,
      "logps/chosen": -72.28426361083984,
      "logps/rejected": -145.5772247314453,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.15164794027805328,
      "rewards/margins": 9.446144104003906,
      "rewards/rejected": -9.59779167175293,
      "step": 5150
    },
    {
      "epoch": 2.0604,
      "grad_norm": 0.012928221374750137,
      "learning_rate": 3.1333333333333333e-07,
      "logits/chosen": -2.5509607791900635,
      "logits/rejected": -2.0959324836730957,
      "logps/chosen": -116.55766296386719,
      "logps/rejected": -166.89181518554688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2582605481147766,
      "rewards/margins": 11.05712604522705,
      "rewards/rejected": -10.798866271972656,
      "step": 5151
    },
    {
      "epoch": 2.0608,
      "grad_norm": 0.020756613463163376,
      "learning_rate": 3.1319999999999997e-07,
      "logits/chosen": -2.5282845497131348,
      "logits/rejected": -1.7777472734451294,
      "logps/chosen": -70.1978759765625,
      "logps/rejected": -152.1952362060547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.938974142074585,
      "rewards/margins": 10.682653427124023,
      "rewards/rejected": -7.743679523468018,
      "step": 5152
    },
    {
      "epoch": 2.0612,
      "grad_norm": 0.03406607732176781,
      "learning_rate": 3.1306666666666666e-07,
      "logits/chosen": -2.52237606048584,
      "logits/rejected": -2.061957836151123,
      "logps/chosen": -223.15084838867188,
      "logps/rejected": -191.5994415283203,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.003188371658325,
      "rewards/margins": 9.99535083770752,
      "rewards/rejected": -11.998538970947266,
      "step": 5153
    },
    {
      "epoch": 2.0616,
      "grad_norm": 0.0025684211868792772,
      "learning_rate": 3.129333333333333e-07,
      "logits/chosen": -2.8363866806030273,
      "logits/rejected": -2.7035865783691406,
      "logps/chosen": -71.49388122558594,
      "logps/rejected": -176.2884521484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2203383445739746,
      "rewards/margins": 11.432645797729492,
      "rewards/rejected": -12.652983665466309,
      "step": 5154
    },
    {
      "epoch": 2.062,
      "grad_norm": 148.86363220214844,
      "learning_rate": 3.128e-07,
      "logits/chosen": -2.283336639404297,
      "logits/rejected": -2.0314717292785645,
      "logps/chosen": -260.123779296875,
      "logps/rejected": -179.8660888671875,
      "loss": 0.5454,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -5.235376834869385,
      "rewards/margins": 5.7513628005981445,
      "rewards/rejected": -10.986740112304688,
      "step": 5155
    },
    {
      "epoch": 2.0624,
      "grad_norm": 0.005629254970699549,
      "learning_rate": 3.1266666666666663e-07,
      "logits/chosen": -2.35434627532959,
      "logits/rejected": -1.7467823028564453,
      "logps/chosen": -115.38253784179688,
      "logps/rejected": -212.27166748046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3837055563926697,
      "rewards/margins": 12.392976760864258,
      "rewards/rejected": -12.009271621704102,
      "step": 5156
    },
    {
      "epoch": 2.0628,
      "grad_norm": 0.1145809218287468,
      "learning_rate": 3.125333333333333e-07,
      "logits/chosen": -2.585620880126953,
      "logits/rejected": -2.230802059173584,
      "logps/chosen": -166.22584533691406,
      "logps/rejected": -177.29244995117188,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5499305725097656,
      "rewards/margins": 8.28384780883789,
      "rewards/rejected": -8.833778381347656,
      "step": 5157
    },
    {
      "epoch": 2.0632,
      "grad_norm": 0.15460556745529175,
      "learning_rate": 3.124e-07,
      "logits/chosen": -2.410261631011963,
      "logits/rejected": -2.0332043170928955,
      "logps/chosen": -102.93419647216797,
      "logps/rejected": -168.6075897216797,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4813169538974762,
      "rewards/margins": 9.647544860839844,
      "rewards/rejected": -9.166227340698242,
      "step": 5158
    },
    {
      "epoch": 2.0636,
      "grad_norm": 0.1991676390171051,
      "learning_rate": 3.1226666666666666e-07,
      "logits/chosen": -2.6939377784729004,
      "logits/rejected": -2.2213544845581055,
      "logps/chosen": -83.49859619140625,
      "logps/rejected": -162.36256408691406,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32464903593063354,
      "rewards/margins": 9.956353187561035,
      "rewards/rejected": -9.631704330444336,
      "step": 5159
    },
    {
      "epoch": 2.064,
      "grad_norm": 4.190045356750488,
      "learning_rate": 3.121333333333333e-07,
      "logits/chosen": -2.6794304847717285,
      "logits/rejected": -2.025937557220459,
      "logps/chosen": -117.08749389648438,
      "logps/rejected": -142.10369873046875,
      "loss": 0.0349,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7864547967910767,
      "rewards/margins": 8.125436782836914,
      "rewards/rejected": -8.911890983581543,
      "step": 5160
    },
    {
      "epoch": 2.0644,
      "grad_norm": 0.009213533252477646,
      "learning_rate": 3.12e-07,
      "logits/chosen": -2.719007968902588,
      "logits/rejected": -2.292191982269287,
      "logps/chosen": -72.81195068359375,
      "logps/rejected": -193.17767333984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.483277291059494,
      "rewards/margins": 12.715649604797363,
      "rewards/rejected": -12.232372283935547,
      "step": 5161
    },
    {
      "epoch": 2.0648,
      "grad_norm": 0.03266655653715134,
      "learning_rate": 3.118666666666667e-07,
      "logits/chosen": -2.356534719467163,
      "logits/rejected": -1.7808434963226318,
      "logps/chosen": -82.96853637695312,
      "logps/rejected": -182.62478637695312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.1127102375030518,
      "rewards/margins": 9.25770378112793,
      "rewards/rejected": -11.370412826538086,
      "step": 5162
    },
    {
      "epoch": 2.0652,
      "grad_norm": 0.23423504829406738,
      "learning_rate": 3.117333333333333e-07,
      "logits/chosen": -2.596464157104492,
      "logits/rejected": -2.0599584579467773,
      "logps/chosen": -57.715660095214844,
      "logps/rejected": -168.72850036621094,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2365466356277466,
      "rewards/margins": 11.130874633789062,
      "rewards/rejected": -9.894328117370605,
      "step": 5163
    },
    {
      "epoch": 2.0656,
      "grad_norm": 0.01559954322874546,
      "learning_rate": 3.1159999999999996e-07,
      "logits/chosen": -2.9628148078918457,
      "logits/rejected": -2.3513312339782715,
      "logps/chosen": -94.81402587890625,
      "logps/rejected": -180.37966918945312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2759822905063629,
      "rewards/margins": 12.329700469970703,
      "rewards/rejected": -12.053718566894531,
      "step": 5164
    },
    {
      "epoch": 2.066,
      "grad_norm": 0.012713712640106678,
      "learning_rate": 3.1146666666666665e-07,
      "logits/chosen": -2.391324043273926,
      "logits/rejected": -2.324392795562744,
      "logps/chosen": -165.51402282714844,
      "logps/rejected": -265.3887939453125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8156783580780029,
      "rewards/margins": 9.566301345825195,
      "rewards/rejected": -10.381979942321777,
      "step": 5165
    },
    {
      "epoch": 2.0664,
      "grad_norm": 0.007557482924312353,
      "learning_rate": 3.1133333333333334e-07,
      "logits/chosen": -2.8404881954193115,
      "logits/rejected": -2.709841728210449,
      "logps/chosen": -100.67167663574219,
      "logps/rejected": -167.50929260253906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.19997179508209229,
      "rewards/margins": 10.801681518554688,
      "rewards/rejected": -11.001653671264648,
      "step": 5166
    },
    {
      "epoch": 2.0668,
      "grad_norm": 0.02957979589700699,
      "learning_rate": 3.112e-07,
      "logits/chosen": -2.3619513511657715,
      "logits/rejected": -1.7405550479888916,
      "logps/chosen": -164.6596221923828,
      "logps/rejected": -184.22743225097656,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.49805909395217896,
      "rewards/margins": 10.686016082763672,
      "rewards/rejected": -11.184076309204102,
      "step": 5167
    },
    {
      "epoch": 2.0672,
      "grad_norm": 0.0002209360827691853,
      "learning_rate": 3.110666666666666e-07,
      "logits/chosen": -2.398338794708252,
      "logits/rejected": -1.4987785816192627,
      "logps/chosen": -157.926025390625,
      "logps/rejected": -203.01739501953125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.047605887055397034,
      "rewards/margins": 14.28686237335205,
      "rewards/rejected": -14.239255905151367,
      "step": 5168
    },
    {
      "epoch": 2.0676,
      "grad_norm": 0.032569520175457,
      "learning_rate": 3.109333333333333e-07,
      "logits/chosen": -2.9710679054260254,
      "logits/rejected": -2.4687979221343994,
      "logps/chosen": -60.031402587890625,
      "logps/rejected": -116.60792541503906,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7718873023986816,
      "rewards/margins": 10.435537338256836,
      "rewards/rejected": -7.663649559020996,
      "step": 5169
    },
    {
      "epoch": 2.068,
      "grad_norm": 1.4616492986679077,
      "learning_rate": 3.108e-07,
      "logits/chosen": -2.8004746437072754,
      "logits/rejected": -2.2288272380828857,
      "logps/chosen": -107.33560180664062,
      "logps/rejected": -118.23371887207031,
      "loss": 0.006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2036834955215454,
      "rewards/margins": 8.001649856567383,
      "rewards/rejected": -6.797966003417969,
      "step": 5170
    },
    {
      "epoch": 2.0684,
      "grad_norm": 0.009251315146684647,
      "learning_rate": 3.1066666666666664e-07,
      "logits/chosen": -2.6837289333343506,
      "logits/rejected": -2.2971348762512207,
      "logps/chosen": -116.31938934326172,
      "logps/rejected": -155.07675170898438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1485217809677124,
      "rewards/margins": 10.645563125610352,
      "rewards/rejected": -10.497041702270508,
      "step": 5171
    },
    {
      "epoch": 2.0688,
      "grad_norm": 1.7357412576675415,
      "learning_rate": 3.1053333333333333e-07,
      "logits/chosen": -3.041167736053467,
      "logits/rejected": -2.8923778533935547,
      "logps/chosen": -74.22113037109375,
      "logps/rejected": -113.44743347167969,
      "loss": 0.0139,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.1110174655914307,
      "rewards/margins": 4.541790008544922,
      "rewards/rejected": -6.652807712554932,
      "step": 5172
    },
    {
      "epoch": 2.0692,
      "grad_norm": 0.12652528285980225,
      "learning_rate": 3.104e-07,
      "logits/chosen": -2.711620569229126,
      "logits/rejected": -2.4877736568450928,
      "logps/chosen": -65.93346405029297,
      "logps/rejected": -122.02120971679688,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.49121859669685364,
      "rewards/margins": 8.724298477172852,
      "rewards/rejected": -8.23307991027832,
      "step": 5173
    },
    {
      "epoch": 2.0696,
      "grad_norm": 1.318490743637085,
      "learning_rate": 3.1026666666666667e-07,
      "logits/chosen": -2.6962578296661377,
      "logits/rejected": -2.7559585571289062,
      "logps/chosen": -51.33233642578125,
      "logps/rejected": -125.07682800292969,
      "loss": 0.0072,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7412412166595459,
      "rewards/margins": 7.0345540046691895,
      "rewards/rejected": -7.775794982910156,
      "step": 5174
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.9897327423095703,
      "learning_rate": 3.101333333333333e-07,
      "logits/chosen": -2.3228864669799805,
      "logits/rejected": -1.9046151638031006,
      "logps/chosen": -221.96031188964844,
      "logps/rejected": -209.54302978515625,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.077533721923828,
      "rewards/margins": 5.703530788421631,
      "rewards/rejected": -11.781064987182617,
      "step": 5175
    },
    {
      "epoch": 2.0704,
      "grad_norm": 0.2134149670600891,
      "learning_rate": 3.1e-07,
      "logits/chosen": -2.85294246673584,
      "logits/rejected": -2.4949445724487305,
      "logps/chosen": -81.83709716796875,
      "logps/rejected": -126.1877212524414,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4500724673271179,
      "rewards/margins": 7.235245704650879,
      "rewards/rejected": -7.6853179931640625,
      "step": 5176
    },
    {
      "epoch": 2.0708,
      "grad_norm": 0.044969089329242706,
      "learning_rate": 3.098666666666667e-07,
      "logits/chosen": -2.638990640640259,
      "logits/rejected": -2.192920446395874,
      "logps/chosen": -84.18627166748047,
      "logps/rejected": -139.35250854492188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3408230543136597,
      "rewards/margins": 10.037575721740723,
      "rewards/rejected": -8.696752548217773,
      "step": 5177
    },
    {
      "epoch": 2.0712,
      "grad_norm": 0.7351195216178894,
      "learning_rate": 3.0973333333333333e-07,
      "logits/chosen": -2.7363905906677246,
      "logits/rejected": -2.393914222717285,
      "logps/chosen": -127.66831970214844,
      "logps/rejected": -149.5605926513672,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9283123016357422,
      "rewards/margins": 8.576330184936523,
      "rewards/rejected": -9.504642486572266,
      "step": 5178
    },
    {
      "epoch": 2.0716,
      "grad_norm": 0.007004233077168465,
      "learning_rate": 3.0959999999999997e-07,
      "logits/chosen": -2.933086395263672,
      "logits/rejected": -2.3553059101104736,
      "logps/chosen": -102.8653564453125,
      "logps/rejected": -197.45130920410156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.7657837867736816,
      "rewards/margins": 10.791532516479492,
      "rewards/rejected": -13.557316780090332,
      "step": 5179
    },
    {
      "epoch": 2.072,
      "grad_norm": 0.004003582522273064,
      "learning_rate": 3.0946666666666666e-07,
      "logits/chosen": -2.3654699325561523,
      "logits/rejected": -1.4623831510543823,
      "logps/chosen": -140.19398498535156,
      "logps/rejected": -210.97369384765625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.042307734489441,
      "rewards/margins": 11.894207000732422,
      "rewards/rejected": -10.851898193359375,
      "step": 5180
    },
    {
      "epoch": 2.0724,
      "grad_norm": 0.020756222307682037,
      "learning_rate": 3.0933333333333335e-07,
      "logits/chosen": -2.488564968109131,
      "logits/rejected": -1.9030227661132812,
      "logps/chosen": -143.0206298828125,
      "logps/rejected": -153.28213500976562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1713097095489502,
      "rewards/margins": 9.054061889648438,
      "rewards/rejected": -10.225370407104492,
      "step": 5181
    },
    {
      "epoch": 2.0728,
      "grad_norm": 0.013234253972768784,
      "learning_rate": 3.0919999999999994e-07,
      "logits/chosen": -2.6574859619140625,
      "logits/rejected": -1.874544382095337,
      "logps/chosen": -107.32850646972656,
      "logps/rejected": -205.75587463378906,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.11335545778274536,
      "rewards/margins": 9.979400634765625,
      "rewards/rejected": -10.092756271362305,
      "step": 5182
    },
    {
      "epoch": 2.0732,
      "grad_norm": 0.028401339426636696,
      "learning_rate": 3.0906666666666663e-07,
      "logits/chosen": -2.5579566955566406,
      "logits/rejected": -1.8770856857299805,
      "logps/chosen": -117.17218780517578,
      "logps/rejected": -203.04476928710938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9157276153564453,
      "rewards/margins": 10.441343307495117,
      "rewards/rejected": -9.525614738464355,
      "step": 5183
    },
    {
      "epoch": 2.0736,
      "grad_norm": 0.0028273763600736856,
      "learning_rate": 3.089333333333333e-07,
      "logits/chosen": -2.45090389251709,
      "logits/rejected": -1.8413169384002686,
      "logps/chosen": -86.67687225341797,
      "logps/rejected": -184.708251953125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8486963510513306,
      "rewards/margins": 11.531475067138672,
      "rewards/rejected": -10.682779312133789,
      "step": 5184
    },
    {
      "epoch": 2.074,
      "grad_norm": 0.004489273298531771,
      "learning_rate": 3.088e-07,
      "logits/chosen": -2.6180672645568848,
      "logits/rejected": -1.8476873636245728,
      "logps/chosen": -48.48384094238281,
      "logps/rejected": -173.81195068359375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3048100471496582,
      "rewards/margins": 11.044282913208008,
      "rewards/rejected": -9.739473342895508,
      "step": 5185
    },
    {
      "epoch": 2.0744,
      "grad_norm": 0.0004940771614201367,
      "learning_rate": 3.0866666666666665e-07,
      "logits/chosen": -2.431382656097412,
      "logits/rejected": -1.7794432640075684,
      "logps/chosen": -100.0767822265625,
      "logps/rejected": -228.18736267089844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12338408827781677,
      "rewards/margins": 14.692951202392578,
      "rewards/rejected": -14.569567680358887,
      "step": 5186
    },
    {
      "epoch": 2.0748,
      "grad_norm": 0.011017031036317348,
      "learning_rate": 3.085333333333333e-07,
      "logits/chosen": -2.686701774597168,
      "logits/rejected": -2.0671820640563965,
      "logps/chosen": -67.0553970336914,
      "logps/rejected": -181.99349975585938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8593267202377319,
      "rewards/margins": 13.005508422851562,
      "rewards/rejected": -12.146181106567383,
      "step": 5187
    },
    {
      "epoch": 2.0752,
      "grad_norm": 0.041687313467264175,
      "learning_rate": 3.084e-07,
      "logits/chosen": -2.9947545528411865,
      "logits/rejected": -2.507038116455078,
      "logps/chosen": -73.48756408691406,
      "logps/rejected": -191.2569122314453,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.04873046278953552,
      "rewards/margins": 12.259258270263672,
      "rewards/rejected": -12.307989120483398,
      "step": 5188
    },
    {
      "epoch": 2.0756,
      "grad_norm": 0.38828587532043457,
      "learning_rate": 3.082666666666667e-07,
      "logits/chosen": -2.721226692199707,
      "logits/rejected": -2.383108615875244,
      "logps/chosen": -147.1600341796875,
      "logps/rejected": -196.7652587890625,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.4064102172851562,
      "rewards/margins": 9.553418159484863,
      "rewards/rejected": -11.95982837677002,
      "step": 5189
    },
    {
      "epoch": 2.076,
      "grad_norm": 0.013753692619502544,
      "learning_rate": 3.081333333333333e-07,
      "logits/chosen": -2.7539777755737305,
      "logits/rejected": -2.251251220703125,
      "logps/chosen": -85.63289642333984,
      "logps/rejected": -180.92263793945312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8791824579238892,
      "rewards/margins": 11.751325607299805,
      "rewards/rejected": -10.872142791748047,
      "step": 5190
    },
    {
      "epoch": 2.0764,
      "grad_norm": 0.39585310220718384,
      "learning_rate": 3.08e-07,
      "logits/chosen": -2.5472402572631836,
      "logits/rejected": -1.8887990713119507,
      "logps/chosen": -102.5055923461914,
      "logps/rejected": -227.34625244140625,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8617250919342041,
      "rewards/margins": 11.919065475463867,
      "rewards/rejected": -12.780790328979492,
      "step": 5191
    },
    {
      "epoch": 2.0768,
      "grad_norm": 29.92218017578125,
      "learning_rate": 3.0786666666666664e-07,
      "logits/chosen": -2.1021182537078857,
      "logits/rejected": -1.8939801454544067,
      "logps/chosen": -309.4012756347656,
      "logps/rejected": -192.76527404785156,
      "loss": 0.12,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.152009010314941,
      "rewards/margins": 6.545742988586426,
      "rewards/rejected": -10.697751998901367,
      "step": 5192
    },
    {
      "epoch": 2.0772,
      "grad_norm": 3.897022247314453,
      "learning_rate": 3.0773333333333334e-07,
      "logits/chosen": -2.8437068462371826,
      "logits/rejected": -2.5542988777160645,
      "logps/chosen": -104.8693618774414,
      "logps/rejected": -144.8184814453125,
      "loss": 0.0205,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3722870349884033,
      "rewards/margins": 7.115082740783691,
      "rewards/rejected": -8.487369537353516,
      "step": 5193
    },
    {
      "epoch": 2.0776,
      "grad_norm": 0.0009923065081238747,
      "learning_rate": 3.076e-07,
      "logits/chosen": -2.8944382667541504,
      "logits/rejected": -2.2704076766967773,
      "logps/chosen": -98.45510864257812,
      "logps/rejected": -166.56759643554688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1052329540252686,
      "rewards/margins": 12.260766983032227,
      "rewards/rejected": -11.155534744262695,
      "step": 5194
    },
    {
      "epoch": 2.078,
      "grad_norm": 0.04029947891831398,
      "learning_rate": 3.0746666666666667e-07,
      "logits/chosen": -2.70155668258667,
      "logits/rejected": -2.3089191913604736,
      "logps/chosen": -91.36961364746094,
      "logps/rejected": -112.38288879394531,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1287771463394165,
      "rewards/margins": 8.614654541015625,
      "rewards/rejected": -7.48587703704834,
      "step": 5195
    },
    {
      "epoch": 2.0784,
      "grad_norm": 0.03761574253439903,
      "learning_rate": 3.0733333333333336e-07,
      "logits/chosen": -2.819578170776367,
      "logits/rejected": -2.3729639053344727,
      "logps/chosen": -122.43513488769531,
      "logps/rejected": -171.2149200439453,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3819587826728821,
      "rewards/margins": 10.522882461547852,
      "rewards/rejected": -10.140922546386719,
      "step": 5196
    },
    {
      "epoch": 2.0788,
      "grad_norm": 0.000303028296912089,
      "learning_rate": 3.0719999999999995e-07,
      "logits/chosen": -2.509441375732422,
      "logits/rejected": -1.865990161895752,
      "logps/chosen": -140.11451721191406,
      "logps/rejected": -216.7656707763672,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4320075809955597,
      "rewards/margins": 14.167781829833984,
      "rewards/rejected": -13.735774993896484,
      "step": 5197
    },
    {
      "epoch": 2.0792,
      "grad_norm": 0.031187964603304863,
      "learning_rate": 3.0706666666666664e-07,
      "logits/chosen": -2.6071009635925293,
      "logits/rejected": -2.218421697616577,
      "logps/chosen": -209.47146606445312,
      "logps/rejected": -196.61659240722656,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.2540385723114014,
      "rewards/margins": 9.209999084472656,
      "rewards/rejected": -11.46403694152832,
      "step": 5198
    },
    {
      "epoch": 2.0796,
      "grad_norm": 6.440154552459717,
      "learning_rate": 3.0693333333333333e-07,
      "logits/chosen": -2.268855571746826,
      "logits/rejected": -2.11566424369812,
      "logps/chosen": -99.04850006103516,
      "logps/rejected": -100.36209106445312,
      "loss": 0.0272,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3392291069030762,
      "rewards/margins": 4.627745628356934,
      "rewards/rejected": -5.96697473526001,
      "step": 5199
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.1781000941991806,
      "learning_rate": 3.068e-07,
      "logits/chosen": -2.220930576324463,
      "logits/rejected": -1.6453224420547485,
      "logps/chosen": -150.11947631835938,
      "logps/rejected": -202.73153686523438,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2227817177772522,
      "rewards/margins": 10.983139038085938,
      "rewards/rejected": -11.205920219421387,
      "step": 5200
    },
    {
      "epoch": 2.0804,
      "grad_norm": 0.01093245204538107,
      "learning_rate": 3.066666666666666e-07,
      "logits/chosen": -2.482640027999878,
      "logits/rejected": -1.8096458911895752,
      "logps/chosen": -264.1946716308594,
      "logps/rejected": -267.132568359375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.8882713317871094,
      "rewards/margins": 13.841238021850586,
      "rewards/rejected": -16.729509353637695,
      "step": 5201
    },
    {
      "epoch": 2.0808,
      "grad_norm": 0.4859324097633362,
      "learning_rate": 3.065333333333333e-07,
      "logits/chosen": -2.7729849815368652,
      "logits/rejected": -2.3850274085998535,
      "logps/chosen": -147.10581970214844,
      "logps/rejected": -129.58734130859375,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6186577081680298,
      "rewards/margins": 7.865072250366211,
      "rewards/rejected": -7.2464141845703125,
      "step": 5202
    },
    {
      "epoch": 2.0812,
      "grad_norm": 0.005479317158460617,
      "learning_rate": 3.064e-07,
      "logits/chosen": -2.462617874145508,
      "logits/rejected": -2.097963333129883,
      "logps/chosen": -122.3910140991211,
      "logps/rejected": -160.20083618164062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.198466494679451,
      "rewards/margins": 12.02885627746582,
      "rewards/rejected": -11.830389976501465,
      "step": 5203
    },
    {
      "epoch": 2.0816,
      "grad_norm": 0.8070278167724609,
      "learning_rate": 3.062666666666667e-07,
      "logits/chosen": -2.954343318939209,
      "logits/rejected": -2.8596863746643066,
      "logps/chosen": -102.46731567382812,
      "logps/rejected": -115.305908203125,
      "loss": 0.007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4570069909095764,
      "rewards/margins": 4.962141036987305,
      "rewards/rejected": -4.505134582519531,
      "step": 5204
    },
    {
      "epoch": 2.082,
      "grad_norm": 1.617562174797058,
      "learning_rate": 3.061333333333333e-07,
      "logits/chosen": -2.5800561904907227,
      "logits/rejected": -2.1864280700683594,
      "logps/chosen": -95.79585266113281,
      "logps/rejected": -127.89244842529297,
      "loss": 0.009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1401420533657074,
      "rewards/margins": 8.002608299255371,
      "rewards/rejected": -8.14275074005127,
      "step": 5205
    },
    {
      "epoch": 2.0824,
      "grad_norm": 0.006134237628430128,
      "learning_rate": 3.0599999999999996e-07,
      "logits/chosen": -2.3730525970458984,
      "logits/rejected": -1.59090256690979,
      "logps/chosen": -141.8822479248047,
      "logps/rejected": -186.36471557617188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6845337152481079,
      "rewards/margins": 12.672630310058594,
      "rewards/rejected": -11.988097190856934,
      "step": 5206
    },
    {
      "epoch": 2.0828,
      "grad_norm": 0.03679707646369934,
      "learning_rate": 3.0586666666666665e-07,
      "logits/chosen": -2.577068567276001,
      "logits/rejected": -2.167436122894287,
      "logps/chosen": -124.24425506591797,
      "logps/rejected": -124.05342864990234,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2568855285644531,
      "rewards/margins": 8.749887466430664,
      "rewards/rejected": -7.493001937866211,
      "step": 5207
    },
    {
      "epoch": 2.0832,
      "grad_norm": 0.04939686134457588,
      "learning_rate": 3.0573333333333334e-07,
      "logits/chosen": -2.2864089012145996,
      "logits/rejected": -1.4728045463562012,
      "logps/chosen": -156.6685028076172,
      "logps/rejected": -151.2959747314453,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6282417178153992,
      "rewards/margins": 9.298937797546387,
      "rewards/rejected": -9.927179336547852,
      "step": 5208
    },
    {
      "epoch": 2.0836,
      "grad_norm": 0.00039703023503534496,
      "learning_rate": 3.056e-07,
      "logits/chosen": -2.833620071411133,
      "logits/rejected": -2.067996025085449,
      "logps/chosen": -79.1987533569336,
      "logps/rejected": -184.57794189453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3490760326385498,
      "rewards/margins": 13.549589157104492,
      "rewards/rejected": -12.200512886047363,
      "step": 5209
    },
    {
      "epoch": 2.084,
      "grad_norm": 0.017767850309610367,
      "learning_rate": 3.054666666666667e-07,
      "logits/chosen": -2.899667739868164,
      "logits/rejected": -2.444174289703369,
      "logps/chosen": -57.8919563293457,
      "logps/rejected": -139.76780700683594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5169540643692017,
      "rewards/margins": 9.636387825012207,
      "rewards/rejected": -9.119434356689453,
      "step": 5210
    },
    {
      "epoch": 2.0844,
      "grad_norm": 0.312905877828598,
      "learning_rate": 3.053333333333333e-07,
      "logits/chosen": -2.632477283477783,
      "logits/rejected": -2.3619284629821777,
      "logps/chosen": -99.01400756835938,
      "logps/rejected": -205.19973754882812,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5455611944198608,
      "rewards/margins": 12.531951904296875,
      "rewards/rejected": -10.986390113830566,
      "step": 5211
    },
    {
      "epoch": 2.0848,
      "grad_norm": 0.11609438061714172,
      "learning_rate": 3.052e-07,
      "logits/chosen": -2.7509353160858154,
      "logits/rejected": -2.297065019607544,
      "logps/chosen": -45.42546463012695,
      "logps/rejected": -173.92538452148438,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.070529580116272,
      "rewards/margins": 10.280939102172852,
      "rewards/rejected": -9.210409164428711,
      "step": 5212
    },
    {
      "epoch": 2.0852,
      "grad_norm": 0.11373121291399002,
      "learning_rate": 3.0506666666666665e-07,
      "logits/chosen": -2.6485018730163574,
      "logits/rejected": -2.271444320678711,
      "logps/chosen": -66.30758666992188,
      "logps/rejected": -141.06771850585938,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16390153765678406,
      "rewards/margins": 9.996896743774414,
      "rewards/rejected": -9.832995414733887,
      "step": 5213
    },
    {
      "epoch": 2.0856,
      "grad_norm": 0.006598937790840864,
      "learning_rate": 3.0493333333333334e-07,
      "logits/chosen": -2.7464165687561035,
      "logits/rejected": -1.8003408908843994,
      "logps/chosen": -76.31649780273438,
      "logps/rejected": -143.4680633544922,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.409200668334961,
      "rewards/margins": 10.62147331237793,
      "rewards/rejected": -9.212272644042969,
      "step": 5214
    },
    {
      "epoch": 2.086,
      "grad_norm": 0.3540215790271759,
      "learning_rate": 3.048e-07,
      "logits/chosen": -2.374567985534668,
      "logits/rejected": -2.036079168319702,
      "logps/chosen": -128.7868194580078,
      "logps/rejected": -151.45614624023438,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.722193479537964,
      "rewards/margins": 8.161721229553223,
      "rewards/rejected": -10.883914947509766,
      "step": 5215
    },
    {
      "epoch": 2.0864,
      "grad_norm": 0.04653523489832878,
      "learning_rate": 3.046666666666666e-07,
      "logits/chosen": -2.5911312103271484,
      "logits/rejected": -1.6399967670440674,
      "logps/chosen": -65.21880340576172,
      "logps/rejected": -150.5550994873047,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9650167226791382,
      "rewards/margins": 10.115681648254395,
      "rewards/rejected": -9.150664329528809,
      "step": 5216
    },
    {
      "epoch": 2.0868,
      "grad_norm": 0.4818437397480011,
      "learning_rate": 3.045333333333333e-07,
      "logits/chosen": -2.7287797927856445,
      "logits/rejected": -2.3353705406188965,
      "logps/chosen": -99.36027526855469,
      "logps/rejected": -130.1577606201172,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9196071624755859,
      "rewards/margins": 6.299252986907959,
      "rewards/rejected": -7.218860149383545,
      "step": 5217
    },
    {
      "epoch": 2.0872,
      "grad_norm": 0.08309977501630783,
      "learning_rate": 3.044e-07,
      "logits/chosen": -2.7608656883239746,
      "logits/rejected": -2.539177179336548,
      "logps/chosen": -85.41407775878906,
      "logps/rejected": -170.69879150390625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7977205514907837,
      "rewards/margins": 7.821767807006836,
      "rewards/rejected": -9.619487762451172,
      "step": 5218
    },
    {
      "epoch": 2.0876,
      "grad_norm": 0.0111941397190094,
      "learning_rate": 3.042666666666667e-07,
      "logits/chosen": -2.678394317626953,
      "logits/rejected": -1.860168218612671,
      "logps/chosen": -33.33927917480469,
      "logps/rejected": -153.38607788085938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0473827123641968,
      "rewards/margins": 10.079864501953125,
      "rewards/rejected": -9.032482147216797,
      "step": 5219
    },
    {
      "epoch": 2.088,
      "grad_norm": 0.002350075636059046,
      "learning_rate": 3.041333333333333e-07,
      "logits/chosen": -2.2432217597961426,
      "logits/rejected": -1.4161663055419922,
      "logps/chosen": -164.40870666503906,
      "logps/rejected": -231.95535278320312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9023315906524658,
      "rewards/margins": 14.997495651245117,
      "rewards/rejected": -15.89982795715332,
      "step": 5220
    },
    {
      "epoch": 2.0884,
      "grad_norm": 0.5262414216995239,
      "learning_rate": 3.0399999999999997e-07,
      "logits/chosen": -2.4327664375305176,
      "logits/rejected": -1.980769157409668,
      "logps/chosen": -161.01866149902344,
      "logps/rejected": -137.13510131835938,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9062843322753906,
      "rewards/margins": 8.050675392150879,
      "rewards/rejected": -8.95695972442627,
      "step": 5221
    },
    {
      "epoch": 2.0888,
      "grad_norm": 0.002595278201624751,
      "learning_rate": 3.0386666666666666e-07,
      "logits/chosen": -2.358159065246582,
      "logits/rejected": -1.6597754955291748,
      "logps/chosen": -158.97467041015625,
      "logps/rejected": -178.59036254882812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.027255237102508545,
      "rewards/margins": 11.711904525756836,
      "rewards/rejected": -11.73915958404541,
      "step": 5222
    },
    {
      "epoch": 2.0892,
      "grad_norm": 0.12060118466615677,
      "learning_rate": 3.0373333333333335e-07,
      "logits/chosen": -2.735926628112793,
      "logits/rejected": -2.43734073638916,
      "logps/chosen": -74.6722640991211,
      "logps/rejected": -126.202880859375,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.44792118668556213,
      "rewards/margins": 8.340895652770996,
      "rewards/rejected": -7.892974853515625,
      "step": 5223
    },
    {
      "epoch": 2.0896,
      "grad_norm": 6.405430793762207,
      "learning_rate": 3.036e-07,
      "logits/chosen": -3.028543472290039,
      "logits/rejected": -2.4359161853790283,
      "logps/chosen": -118.52836608886719,
      "logps/rejected": -133.36453247070312,
      "loss": 0.0281,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1223881244659424,
      "rewards/margins": 6.745050430297852,
      "rewards/rejected": -7.867438793182373,
      "step": 5224
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.3777616322040558,
      "learning_rate": 3.0346666666666663e-07,
      "logits/chosen": -2.624390125274658,
      "logits/rejected": -2.2537879943847656,
      "logps/chosen": -95.67304229736328,
      "logps/rejected": -173.77992248535156,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.31149327754974365,
      "rewards/margins": 10.859557151794434,
      "rewards/rejected": -11.171050071716309,
      "step": 5225
    },
    {
      "epoch": 2.0904,
      "grad_norm": 0.18115729093551636,
      "learning_rate": 3.033333333333333e-07,
      "logits/chosen": -2.6732020378112793,
      "logits/rejected": -2.5486531257629395,
      "logps/chosen": -87.103759765625,
      "logps/rejected": -121.68082427978516,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6822555661201477,
      "rewards/margins": 7.071558952331543,
      "rewards/rejected": -7.753814697265625,
      "step": 5226
    },
    {
      "epoch": 2.0908,
      "grad_norm": 0.6122106909751892,
      "learning_rate": 3.032e-07,
      "logits/chosen": -2.6049070358276367,
      "logits/rejected": -2.4479827880859375,
      "logps/chosen": -110.79703521728516,
      "logps/rejected": -181.71914672851562,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6079864501953125,
      "rewards/margins": 11.091713905334473,
      "rewards/rejected": -12.699699401855469,
      "step": 5227
    },
    {
      "epoch": 2.0912,
      "grad_norm": 0.007358020171523094,
      "learning_rate": 3.0306666666666665e-07,
      "logits/chosen": -2.593088388442993,
      "logits/rejected": -1.993692398071289,
      "logps/chosen": -73.922119140625,
      "logps/rejected": -172.89512634277344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7651071548461914,
      "rewards/margins": 10.813138961791992,
      "rewards/rejected": -10.048030853271484,
      "step": 5228
    },
    {
      "epoch": 2.0916,
      "grad_norm": 0.02173835225403309,
      "learning_rate": 3.029333333333333e-07,
      "logits/chosen": -2.4924912452697754,
      "logits/rejected": -1.8182156085968018,
      "logps/chosen": -139.9376220703125,
      "logps/rejected": -167.63238525390625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9063858389854431,
      "rewards/margins": 9.509944915771484,
      "rewards/rejected": -8.603558540344238,
      "step": 5229
    },
    {
      "epoch": 2.092,
      "grad_norm": 0.05992788076400757,
      "learning_rate": 3.028e-07,
      "logits/chosen": -2.485759735107422,
      "logits/rejected": -2.079908847808838,
      "logps/chosen": -61.358375549316406,
      "logps/rejected": -156.2967071533203,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.148277997970581,
      "rewards/margins": 9.583551406860352,
      "rewards/rejected": -10.731828689575195,
      "step": 5230
    },
    {
      "epoch": 2.0924,
      "grad_norm": 0.0025786617770791054,
      "learning_rate": 3.026666666666666e-07,
      "logits/chosen": -2.424813747406006,
      "logits/rejected": -2.3452839851379395,
      "logps/chosen": -184.20748901367188,
      "logps/rejected": -274.25848388671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5848366022109985,
      "rewards/margins": 11.529321670532227,
      "rewards/rejected": -10.94448471069336,
      "step": 5231
    },
    {
      "epoch": 2.0928,
      "grad_norm": 0.11149360984563828,
      "learning_rate": 3.025333333333333e-07,
      "logits/chosen": -2.6110105514526367,
      "logits/rejected": -2.346994161605835,
      "logps/chosen": -169.07252502441406,
      "logps/rejected": -187.2002410888672,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7852542400360107,
      "rewards/margins": 8.203021049499512,
      "rewards/rejected": -9.988275527954102,
      "step": 5232
    },
    {
      "epoch": 2.0932,
      "grad_norm": 1.2553664445877075,
      "learning_rate": 3.024e-07,
      "logits/chosen": -3.2133727073669434,
      "logits/rejected": -2.863478183746338,
      "logps/chosen": -44.918304443359375,
      "logps/rejected": -125.18196868896484,
      "loss": 0.0081,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7034313678741455,
      "rewards/margins": 8.834046363830566,
      "rewards/rejected": -8.130615234375,
      "step": 5233
    },
    {
      "epoch": 2.0936,
      "grad_norm": 4.423542022705078,
      "learning_rate": 3.0226666666666665e-07,
      "logits/chosen": -2.6874794960021973,
      "logits/rejected": -2.7293992042541504,
      "logps/chosen": -64.47868347167969,
      "logps/rejected": -112.42437744140625,
      "loss": 0.0246,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.922930359840393,
      "rewards/margins": 4.582357406616211,
      "rewards/rejected": -6.505288124084473,
      "step": 5234
    },
    {
      "epoch": 2.094,
      "grad_norm": 0.00023765998776070774,
      "learning_rate": 3.021333333333333e-07,
      "logits/chosen": -2.2488980293273926,
      "logits/rejected": -1.5451586246490479,
      "logps/chosen": -132.30621337890625,
      "logps/rejected": -302.7121276855469,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39671170711517334,
      "rewards/margins": 17.615922927856445,
      "rewards/rejected": -17.21921157836914,
      "step": 5235
    },
    {
      "epoch": 2.0944,
      "grad_norm": 0.0011752174468711019,
      "learning_rate": 3.02e-07,
      "logits/chosen": -2.5897183418273926,
      "logits/rejected": -2.0686140060424805,
      "logps/chosen": -104.62593078613281,
      "logps/rejected": -273.90069580078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7792496085166931,
      "rewards/margins": 13.813921928405762,
      "rewards/rejected": -14.593171119689941,
      "step": 5236
    },
    {
      "epoch": 2.0948,
      "grad_norm": 0.004796644207090139,
      "learning_rate": 3.0186666666666667e-07,
      "logits/chosen": -2.38881778717041,
      "logits/rejected": -1.488304615020752,
      "logps/chosen": -105.46000671386719,
      "logps/rejected": -171.39117431640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.454977422952652,
      "rewards/margins": 11.474241256713867,
      "rewards/rejected": -11.019264221191406,
      "step": 5237
    },
    {
      "epoch": 2.0952,
      "grad_norm": 0.03995702788233757,
      "learning_rate": 3.0173333333333336e-07,
      "logits/chosen": -2.8104984760284424,
      "logits/rejected": -2.0714282989501953,
      "logps/chosen": -116.77821350097656,
      "logps/rejected": -175.44625854492188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4112277925014496,
      "rewards/margins": 9.890419006347656,
      "rewards/rejected": -10.301647186279297,
      "step": 5238
    },
    {
      "epoch": 2.0956,
      "grad_norm": 0.10369701683521271,
      "learning_rate": 3.0159999999999995e-07,
      "logits/chosen": -2.841911792755127,
      "logits/rejected": -2.381666421890259,
      "logps/chosen": -110.2948226928711,
      "logps/rejected": -182.1767578125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5624315142631531,
      "rewards/margins": 11.676506042480469,
      "rewards/rejected": -11.11407470703125,
      "step": 5239
    },
    {
      "epoch": 2.096,
      "grad_norm": 0.04535042494535446,
      "learning_rate": 3.0146666666666664e-07,
      "logits/chosen": -3.0907411575317383,
      "logits/rejected": -2.65171480178833,
      "logps/chosen": -69.06413269042969,
      "logps/rejected": -154.0418243408203,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5859091281890869,
      "rewards/margins": 11.150344848632812,
      "rewards/rejected": -10.564435958862305,
      "step": 5240
    },
    {
      "epoch": 2.0964,
      "grad_norm": 9.378049850463867,
      "learning_rate": 3.0133333333333333e-07,
      "logits/chosen": -2.877634286880493,
      "logits/rejected": -2.728745460510254,
      "logps/chosen": -82.06639099121094,
      "logps/rejected": -98.44231414794922,
      "loss": 0.0606,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8114816546440125,
      "rewards/margins": 3.8368265628814697,
      "rewards/rejected": -4.648308277130127,
      "step": 5241
    },
    {
      "epoch": 2.0968,
      "grad_norm": 19.137746810913086,
      "learning_rate": 3.012e-07,
      "logits/chosen": -2.6922802925109863,
      "logits/rejected": -2.830049753189087,
      "logps/chosen": -123.55119323730469,
      "logps/rejected": -94.4132308959961,
      "loss": 0.0901,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.25549578666687,
      "rewards/margins": 3.026228427886963,
      "rewards/rejected": -5.281724452972412,
      "step": 5242
    },
    {
      "epoch": 2.0972,
      "grad_norm": 0.001875486341305077,
      "learning_rate": 3.010666666666666e-07,
      "logits/chosen": -2.5210518836975098,
      "logits/rejected": -1.9941580295562744,
      "logps/chosen": -145.7567596435547,
      "logps/rejected": -196.40280151367188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7561042904853821,
      "rewards/margins": 12.437454223632812,
      "rewards/rejected": -11.681349754333496,
      "step": 5243
    },
    {
      "epoch": 2.0976,
      "grad_norm": 0.037686657160520554,
      "learning_rate": 3.009333333333333e-07,
      "logits/chosen": -3.1059417724609375,
      "logits/rejected": -2.5230071544647217,
      "logps/chosen": -78.00798034667969,
      "logps/rejected": -162.50509643554688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08494260907173157,
      "rewards/margins": 11.041598320007324,
      "rewards/rejected": -10.956655502319336,
      "step": 5244
    },
    {
      "epoch": 2.098,
      "grad_norm": 0.05488668754696846,
      "learning_rate": 3.008e-07,
      "logits/chosen": -2.474249839782715,
      "logits/rejected": -1.8033106327056885,
      "logps/chosen": -82.58688354492188,
      "logps/rejected": -113.08453369140625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.068120002746582,
      "rewards/margins": 9.109136581420898,
      "rewards/rejected": -7.041016578674316,
      "step": 5245
    },
    {
      "epoch": 2.0984,
      "grad_norm": 0.01799944043159485,
      "learning_rate": 3.006666666666667e-07,
      "logits/chosen": -2.5819125175476074,
      "logits/rejected": -2.031059741973877,
      "logps/chosen": -102.82328033447266,
      "logps/rejected": -160.56927490234375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4826633334159851,
      "rewards/margins": 10.569862365722656,
      "rewards/rejected": -10.087200164794922,
      "step": 5246
    },
    {
      "epoch": 2.0987999999999998,
      "grad_norm": 0.0049544391222298145,
      "learning_rate": 3.005333333333333e-07,
      "logits/chosen": -2.655916690826416,
      "logits/rejected": -1.8490028381347656,
      "logps/chosen": -68.65599822998047,
      "logps/rejected": -161.18414306640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.60776686668396,
      "rewards/margins": 14.071060180664062,
      "rewards/rejected": -11.463293075561523,
      "step": 5247
    },
    {
      "epoch": 2.0992,
      "grad_norm": 0.011350227519869804,
      "learning_rate": 3.0039999999999996e-07,
      "logits/chosen": -2.4598727226257324,
      "logits/rejected": -2.083341598510742,
      "logps/chosen": -100.10551452636719,
      "logps/rejected": -165.95162963867188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2715293765068054,
      "rewards/margins": 10.333925247192383,
      "rewards/rejected": -10.605454444885254,
      "step": 5248
    },
    {
      "epoch": 2.0996,
      "grad_norm": 0.0009753478807397187,
      "learning_rate": 3.0026666666666666e-07,
      "logits/chosen": -2.8056998252868652,
      "logits/rejected": -2.373026132583618,
      "logps/chosen": -86.66804504394531,
      "logps/rejected": -156.79019165039062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1749935150146484,
      "rewards/margins": 12.12092113494873,
      "rewards/rejected": -10.945926666259766,
      "step": 5249
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.14559228718280792,
      "learning_rate": 3.001333333333333e-07,
      "logits/chosen": -2.8337621688842773,
      "logits/rejected": -2.4146666526794434,
      "logps/chosen": -117.95637512207031,
      "logps/rejected": -141.26239013671875,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5034000277519226,
      "rewards/margins": 8.31900691986084,
      "rewards/rejected": -8.822406768798828,
      "step": 5250
    },
    {
      "epoch": 2.1004,
      "grad_norm": 0.01894277334213257,
      "learning_rate": 3e-07,
      "logits/chosen": -2.744337558746338,
      "logits/rejected": -2.246342182159424,
      "logps/chosen": -142.65135192871094,
      "logps/rejected": -168.63916015625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.968441367149353,
      "rewards/margins": 9.90787124633789,
      "rewards/rejected": -11.876312255859375,
      "step": 5251
    },
    {
      "epoch": 2.1008,
      "grad_norm": 0.006589898839592934,
      "learning_rate": 2.998666666666667e-07,
      "logits/chosen": -2.6544618606567383,
      "logits/rejected": -1.9527512788772583,
      "logps/chosen": -100.23847198486328,
      "logps/rejected": -179.64010620117188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6204477548599243,
      "rewards/margins": 10.83358097076416,
      "rewards/rejected": -10.213132858276367,
      "step": 5252
    },
    {
      "epoch": 2.1012,
      "grad_norm": 0.5534579753875732,
      "learning_rate": 2.997333333333333e-07,
      "logits/chosen": -2.7789363861083984,
      "logits/rejected": -3.0000219345092773,
      "logps/chosen": -86.73206329345703,
      "logps/rejected": -95.98289489746094,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0016286969184875488,
      "rewards/margins": 5.485235214233398,
      "rewards/rejected": -5.483606338500977,
      "step": 5253
    },
    {
      "epoch": 2.1016,
      "grad_norm": 0.0013383392943069339,
      "learning_rate": 2.9959999999999996e-07,
      "logits/chosen": -2.378599166870117,
      "logits/rejected": -1.7466206550598145,
      "logps/chosen": -99.69703674316406,
      "logps/rejected": -223.7389373779297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02856960892677307,
      "rewards/margins": 13.225641250610352,
      "rewards/rejected": -13.197071075439453,
      "step": 5254
    },
    {
      "epoch": 2.102,
      "grad_norm": 0.06089954823255539,
      "learning_rate": 2.9946666666666665e-07,
      "logits/chosen": -2.812060594558716,
      "logits/rejected": -2.642148494720459,
      "logps/chosen": -87.0069580078125,
      "logps/rejected": -127.36090087890625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2349342107772827,
      "rewards/margins": 9.379264831542969,
      "rewards/rejected": -8.144330978393555,
      "step": 5255
    },
    {
      "epoch": 2.1024,
      "grad_norm": 0.03568250313401222,
      "learning_rate": 2.9933333333333334e-07,
      "logits/chosen": -2.6703999042510986,
      "logits/rejected": -2.0732524394989014,
      "logps/chosen": -96.7281723022461,
      "logps/rejected": -175.8584442138672,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9008199572563171,
      "rewards/margins": 12.856439590454102,
      "rewards/rejected": -11.955619812011719,
      "step": 5256
    },
    {
      "epoch": 2.1028000000000002,
      "grad_norm": 0.0014921586262062192,
      "learning_rate": 2.9920000000000003e-07,
      "logits/chosen": -2.6900453567504883,
      "logits/rejected": -1.7814640998840332,
      "logps/chosen": -40.784423828125,
      "logps/rejected": -221.22113037109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41298770904541016,
      "rewards/margins": 14.486357688903809,
      "rewards/rejected": -14.073369979858398,
      "step": 5257
    },
    {
      "epoch": 2.1032,
      "grad_norm": 4.00066614151001,
      "learning_rate": 2.990666666666666e-07,
      "logits/chosen": -2.808361053466797,
      "logits/rejected": -2.5664825439453125,
      "logps/chosen": -57.42737579345703,
      "logps/rejected": -99.36795806884766,
      "loss": 0.0237,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7508577108383179,
      "rewards/margins": 7.435310363769531,
      "rewards/rejected": -6.684453010559082,
      "step": 5258
    },
    {
      "epoch": 2.1036,
      "grad_norm": 0.18123503029346466,
      "learning_rate": 2.989333333333333e-07,
      "logits/chosen": -2.7105941772460938,
      "logits/rejected": -2.790987968444824,
      "logps/chosen": -46.77585220336914,
      "logps/rejected": -133.032958984375,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15263938903808594,
      "rewards/margins": 7.383058547973633,
      "rewards/rejected": -7.230419635772705,
      "step": 5259
    },
    {
      "epoch": 2.104,
      "grad_norm": 0.9467653632164001,
      "learning_rate": 2.988e-07,
      "logits/chosen": -2.6921653747558594,
      "logits/rejected": -2.290306568145752,
      "logps/chosen": -109.9239730834961,
      "logps/rejected": -177.58920288085938,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.878441572189331,
      "rewards/margins": 9.198165893554688,
      "rewards/rejected": -12.076607704162598,
      "step": 5260
    },
    {
      "epoch": 2.1044,
      "grad_norm": 0.2192727029323578,
      "learning_rate": 2.986666666666667e-07,
      "logits/chosen": -2.8619604110717773,
      "logits/rejected": -2.5011231899261475,
      "logps/chosen": -73.72237396240234,
      "logps/rejected": -136.9348602294922,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1624066829681396,
      "rewards/margins": 7.9777021408081055,
      "rewards/rejected": -9.140109062194824,
      "step": 5261
    },
    {
      "epoch": 2.1048,
      "grad_norm": 0.007798172067850828,
      "learning_rate": 2.985333333333333e-07,
      "logits/chosen": -2.483222723007202,
      "logits/rejected": -1.6390221118927002,
      "logps/chosen": -170.72930908203125,
      "logps/rejected": -190.02081298828125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.26774734258651733,
      "rewards/margins": 12.62639331817627,
      "rewards/rejected": -12.894140243530273,
      "step": 5262
    },
    {
      "epoch": 2.1052,
      "grad_norm": 8.092004281934351e-05,
      "learning_rate": 2.9839999999999997e-07,
      "logits/chosen": -2.3959124088287354,
      "logits/rejected": -1.609757423400879,
      "logps/chosen": -127.95347595214844,
      "logps/rejected": -217.81668090820312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4544929265975952,
      "rewards/margins": 15.61156940460205,
      "rewards/rejected": -14.157075881958008,
      "step": 5263
    },
    {
      "epoch": 2.1056,
      "grad_norm": 44.967857360839844,
      "learning_rate": 2.9826666666666666e-07,
      "logits/chosen": -2.518174648284912,
      "logits/rejected": -1.977683663368225,
      "logps/chosen": -237.39208984375,
      "logps/rejected": -139.11318969726562,
      "loss": 0.2341,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.282476902008057,
      "rewards/margins": 2.8616271018981934,
      "rewards/rejected": -9.14410400390625,
      "step": 5264
    },
    {
      "epoch": 2.106,
      "grad_norm": 0.0030301313381642103,
      "learning_rate": 2.981333333333333e-07,
      "logits/chosen": -2.7770519256591797,
      "logits/rejected": -2.411180019378662,
      "logps/chosen": -43.86122512817383,
      "logps/rejected": -178.35670471191406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5948099493980408,
      "rewards/margins": 12.995575904846191,
      "rewards/rejected": -12.400766372680664,
      "step": 5265
    },
    {
      "epoch": 2.1064,
      "grad_norm": 0.015203822404146194,
      "learning_rate": 2.98e-07,
      "logits/chosen": -2.9529972076416016,
      "logits/rejected": -2.6379144191741943,
      "logps/chosen": -65.49187469482422,
      "logps/rejected": -135.27622985839844,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7441490292549133,
      "rewards/margins": 9.750911712646484,
      "rewards/rejected": -9.006762504577637,
      "step": 5266
    },
    {
      "epoch": 2.1068,
      "grad_norm": 0.017222361639142036,
      "learning_rate": 2.9786666666666663e-07,
      "logits/chosen": -2.7853240966796875,
      "logits/rejected": -2.2506399154663086,
      "logps/chosen": -64.4510726928711,
      "logps/rejected": -167.55526733398438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3019275665283203,
      "rewards/margins": 12.122941970825195,
      "rewards/rejected": -10.821014404296875,
      "step": 5267
    },
    {
      "epoch": 2.1072,
      "grad_norm": 0.0006323441630229354,
      "learning_rate": 2.977333333333333e-07,
      "logits/chosen": -2.722198724746704,
      "logits/rejected": -2.1989800930023193,
      "logps/chosen": -82.24957275390625,
      "logps/rejected": -216.0557403564453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.34953346848487854,
      "rewards/margins": 13.802556991577148,
      "rewards/rejected": -14.152090072631836,
      "step": 5268
    },
    {
      "epoch": 2.1076,
      "grad_norm": 0.001040357630699873,
      "learning_rate": 2.9759999999999996e-07,
      "logits/chosen": -2.1737513542175293,
      "logits/rejected": -1.4759526252746582,
      "logps/chosen": -104.03305053710938,
      "logps/rejected": -201.75833129882812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3937580585479736,
      "rewards/margins": 13.453828811645508,
      "rewards/rejected": -12.060070037841797,
      "step": 5269
    },
    {
      "epoch": 2.108,
      "grad_norm": 0.010353075340390205,
      "learning_rate": 2.9746666666666666e-07,
      "logits/chosen": -2.784454345703125,
      "logits/rejected": -2.4383578300476074,
      "logps/chosen": -58.13094711303711,
      "logps/rejected": -161.05848693847656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3970285654067993,
      "rewards/margins": 10.461973190307617,
      "rewards/rejected": -10.06494426727295,
      "step": 5270
    },
    {
      "epoch": 2.1084,
      "grad_norm": 0.0009829358896240592,
      "learning_rate": 2.9733333333333335e-07,
      "logits/chosen": -2.7985830307006836,
      "logits/rejected": -2.161992073059082,
      "logps/chosen": -91.11003875732422,
      "logps/rejected": -192.6536865234375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1939401775598526,
      "rewards/margins": 12.585060119628906,
      "rewards/rejected": -12.391120910644531,
      "step": 5271
    },
    {
      "epoch": 2.1088,
      "grad_norm": 0.019098736345767975,
      "learning_rate": 2.972e-07,
      "logits/chosen": -2.882251501083374,
      "logits/rejected": -2.3603172302246094,
      "logps/chosen": -41.26367950439453,
      "logps/rejected": -179.43701171875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3376510441303253,
      "rewards/margins": 13.913631439208984,
      "rewards/rejected": -13.575981140136719,
      "step": 5272
    },
    {
      "epoch": 2.1092,
      "grad_norm": 0.0037761381827294827,
      "learning_rate": 2.9706666666666663e-07,
      "logits/chosen": -2.5059502124786377,
      "logits/rejected": -2.2435801029205322,
      "logps/chosen": -124.95066833496094,
      "logps/rejected": -230.03604125976562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8793172836303711,
      "rewards/margins": 12.461455345153809,
      "rewards/rejected": -13.34077262878418,
      "step": 5273
    },
    {
      "epoch": 2.1096,
      "grad_norm": 0.5930591821670532,
      "learning_rate": 2.969333333333333e-07,
      "logits/chosen": -2.503788471221924,
      "logits/rejected": -2.173966407775879,
      "logps/chosen": -70.49107360839844,
      "logps/rejected": -135.140625,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6948549151420593,
      "rewards/margins": 9.77925968170166,
      "rewards/rejected": -9.084404945373535,
      "step": 5274
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.3934577405452728,
      "learning_rate": 2.968e-07,
      "logits/chosen": -2.83194637298584,
      "logits/rejected": -2.9840798377990723,
      "logps/chosen": -64.96467590332031,
      "logps/rejected": -82.23870849609375,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20164796710014343,
      "rewards/margins": 5.8924665451049805,
      "rewards/rejected": -5.690818786621094,
      "step": 5275
    },
    {
      "epoch": 2.1104,
      "grad_norm": 0.2632158100605011,
      "learning_rate": 2.966666666666667e-07,
      "logits/chosen": -2.838772773742676,
      "logits/rejected": -2.7474942207336426,
      "logps/chosen": -52.36970520019531,
      "logps/rejected": -119.07787322998047,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.147311806678772,
      "rewards/margins": 8.026627540588379,
      "rewards/rejected": -6.879315376281738,
      "step": 5276
    },
    {
      "epoch": 2.1108,
      "grad_norm": 0.5291703939437866,
      "learning_rate": 2.965333333333333e-07,
      "logits/chosen": -2.52675199508667,
      "logits/rejected": -2.434443712234497,
      "logps/chosen": -90.27632141113281,
      "logps/rejected": -94.77161407470703,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7077156901359558,
      "rewards/margins": 5.512810230255127,
      "rewards/rejected": -6.220525741577148,
      "step": 5277
    },
    {
      "epoch": 2.1112,
      "grad_norm": 0.04314080998301506,
      "learning_rate": 2.964e-07,
      "logits/chosen": -2.864628314971924,
      "logits/rejected": -2.3748114109039307,
      "logps/chosen": -45.326377868652344,
      "logps/rejected": -156.35330200195312,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3067829608917236,
      "rewards/margins": 12.95592975616455,
      "rewards/rejected": -11.649147033691406,
      "step": 5278
    },
    {
      "epoch": 2.1116,
      "grad_norm": 2.2944278717041016,
      "learning_rate": 2.9626666666666667e-07,
      "logits/chosen": -2.7683939933776855,
      "logits/rejected": -2.15881609916687,
      "logps/chosen": -98.24014282226562,
      "logps/rejected": -125.69017791748047,
      "loss": 0.0135,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.879927158355713,
      "rewards/margins": 9.985771179199219,
      "rewards/rejected": -8.105844497680664,
      "step": 5279
    },
    {
      "epoch": 2.112,
      "grad_norm": 0.0033314984757453203,
      "learning_rate": 2.9613333333333336e-07,
      "logits/chosen": -2.697253942489624,
      "logits/rejected": -2.0887084007263184,
      "logps/chosen": -55.70418167114258,
      "logps/rejected": -176.56295776367188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0384671688079834,
      "rewards/margins": 13.78020191192627,
      "rewards/rejected": -11.741735458374023,
      "step": 5280
    },
    {
      "epoch": 2.1124,
      "grad_norm": 0.3371797502040863,
      "learning_rate": 2.9599999999999995e-07,
      "logits/chosen": -2.7224926948547363,
      "logits/rejected": -2.3538687229156494,
      "logps/chosen": -89.49200439453125,
      "logps/rejected": -109.35098266601562,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.47353842854499817,
      "rewards/margins": 6.698467254638672,
      "rewards/rejected": -7.172006130218506,
      "step": 5281
    },
    {
      "epoch": 2.1128,
      "grad_norm": 1.5722749594715424e-05,
      "learning_rate": 2.9586666666666664e-07,
      "logits/chosen": -2.612497091293335,
      "logits/rejected": -1.7697237730026245,
      "logps/chosen": -133.15541076660156,
      "logps/rejected": -235.3040771484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.21894419193267822,
      "rewards/margins": 16.843307495117188,
      "rewards/rejected": -17.062252044677734,
      "step": 5282
    },
    {
      "epoch": 2.1132,
      "grad_norm": 0.00467307586222887,
      "learning_rate": 2.9573333333333333e-07,
      "logits/chosen": -2.6722097396850586,
      "logits/rejected": -2.3771233558654785,
      "logps/chosen": -58.83820343017578,
      "logps/rejected": -187.55496215820312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7543367147445679,
      "rewards/margins": 12.49505615234375,
      "rewards/rejected": -11.740718841552734,
      "step": 5283
    },
    {
      "epoch": 2.1136,
      "grad_norm": 0.028034131973981857,
      "learning_rate": 2.9559999999999997e-07,
      "logits/chosen": -2.4751510620117188,
      "logits/rejected": -2.100735664367676,
      "logps/chosen": -110.2939453125,
      "logps/rejected": -145.4239959716797,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7341609597206116,
      "rewards/margins": 8.823352813720703,
      "rewards/rejected": -8.089192390441895,
      "step": 5284
    },
    {
      "epoch": 2.114,
      "grad_norm": 0.008903644047677517,
      "learning_rate": 2.9546666666666667e-07,
      "logits/chosen": -2.6952097415924072,
      "logits/rejected": -2.310976982116699,
      "logps/chosen": -117.33531951904297,
      "logps/rejected": -209.73483276367188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5308059453964233,
      "rewards/margins": 12.526323318481445,
      "rewards/rejected": -13.05712890625,
      "step": 5285
    },
    {
      "epoch": 2.1144,
      "grad_norm": 0.029406167566776276,
      "learning_rate": 2.953333333333333e-07,
      "logits/chosen": -2.6766672134399414,
      "logits/rejected": -2.249516725540161,
      "logps/chosen": -107.92163848876953,
      "logps/rejected": -193.2918701171875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.055025339126587,
      "rewards/margins": 11.994781494140625,
      "rewards/rejected": -13.049806594848633,
      "step": 5286
    },
    {
      "epoch": 2.1148,
      "grad_norm": 0.00010173601185670123,
      "learning_rate": 2.952e-07,
      "logits/chosen": -2.7439193725585938,
      "logits/rejected": -1.7375893592834473,
      "logps/chosen": -101.62324523925781,
      "logps/rejected": -230.89031982421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.290388822555542,
      "rewards/margins": 16.603374481201172,
      "rewards/rejected": -15.312986373901367,
      "step": 5287
    },
    {
      "epoch": 2.1152,
      "grad_norm": 0.049488551914691925,
      "learning_rate": 2.9506666666666664e-07,
      "logits/chosen": -2.9774012565612793,
      "logits/rejected": -2.563451051712036,
      "logps/chosen": -68.8438949584961,
      "logps/rejected": -144.6275634765625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09309157729148865,
      "rewards/margins": 9.497085571289062,
      "rewards/rejected": -9.403993606567383,
      "step": 5288
    },
    {
      "epoch": 2.1156,
      "grad_norm": 65.9539794921875,
      "learning_rate": 2.9493333333333333e-07,
      "logits/chosen": -2.9124507904052734,
      "logits/rejected": -2.625505208969116,
      "logps/chosen": -90.65959167480469,
      "logps/rejected": -80.10576629638672,
      "loss": 0.4538,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -2.6126561164855957,
      "rewards/margins": 2.130066394805908,
      "rewards/rejected": -4.742722511291504,
      "step": 5289
    },
    {
      "epoch": 2.116,
      "grad_norm": 0.0006875370745547116,
      "learning_rate": 2.948e-07,
      "logits/chosen": -2.2314772605895996,
      "logits/rejected": -1.394006609916687,
      "logps/chosen": -136.2827606201172,
      "logps/rejected": -211.16912841796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3999381959438324,
      "rewards/margins": 14.004968643188477,
      "rewards/rejected": -13.605030059814453,
      "step": 5290
    },
    {
      "epoch": 2.1164,
      "grad_norm": 0.016431454569101334,
      "learning_rate": 2.9466666666666666e-07,
      "logits/chosen": -2.492854595184326,
      "logits/rejected": -1.8416438102722168,
      "logps/chosen": -80.61184692382812,
      "logps/rejected": -155.36138916015625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2949676513671875,
      "rewards/margins": 10.602463722229004,
      "rewards/rejected": -9.307496070861816,
      "step": 5291
    },
    {
      "epoch": 2.1168,
      "grad_norm": 0.14672237634658813,
      "learning_rate": 2.945333333333333e-07,
      "logits/chosen": -2.3559656143188477,
      "logits/rejected": -1.759380578994751,
      "logps/chosen": -150.38568115234375,
      "logps/rejected": -190.89273071289062,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0287353992462158,
      "rewards/margins": 9.41177749633789,
      "rewards/rejected": -10.440512657165527,
      "step": 5292
    },
    {
      "epoch": 2.1172,
      "grad_norm": 0.4387383759021759,
      "learning_rate": 2.944e-07,
      "logits/chosen": -2.535226345062256,
      "logits/rejected": -2.2191734313964844,
      "logps/chosen": -96.00767517089844,
      "logps/rejected": -154.54327392578125,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.721278190612793,
      "rewards/margins": 9.94780445098877,
      "rewards/rejected": -10.669082641601562,
      "step": 5293
    },
    {
      "epoch": 2.1176,
      "grad_norm": 0.3629961907863617,
      "learning_rate": 2.942666666666667e-07,
      "logits/chosen": -2.9400103092193604,
      "logits/rejected": -2.528244733810425,
      "logps/chosen": -73.48439025878906,
      "logps/rejected": -128.7681121826172,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9202747941017151,
      "rewards/margins": 7.2325005531311035,
      "rewards/rejected": -8.152775764465332,
      "step": 5294
    },
    {
      "epoch": 2.118,
      "grad_norm": 0.0021304981783032417,
      "learning_rate": 2.941333333333333e-07,
      "logits/chosen": -2.4522557258605957,
      "logits/rejected": -2.412644863128662,
      "logps/chosen": -153.7586669921875,
      "logps/rejected": -208.20083618164062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.22189562022686005,
      "rewards/margins": 12.141193389892578,
      "rewards/rejected": -12.363088607788086,
      "step": 5295
    },
    {
      "epoch": 2.1184,
      "grad_norm": 0.0013143878895789385,
      "learning_rate": 2.9399999999999996e-07,
      "logits/chosen": -2.47631573677063,
      "logits/rejected": -1.661719560623169,
      "logps/chosen": -91.47410583496094,
      "logps/rejected": -272.41571044921875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6297726035118103,
      "rewards/margins": 17.810192108154297,
      "rewards/rejected": -17.180419921875,
      "step": 5296
    },
    {
      "epoch": 2.1188,
      "grad_norm": 0.017238689586520195,
      "learning_rate": 2.9386666666666665e-07,
      "logits/chosen": -2.8989980220794678,
      "logits/rejected": -1.95326566696167,
      "logps/chosen": -69.6042251586914,
      "logps/rejected": -227.3212127685547,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3204691410064697,
      "rewards/margins": 15.051433563232422,
      "rewards/rejected": -13.730964660644531,
      "step": 5297
    },
    {
      "epoch": 2.1192,
      "grad_norm": 0.21625927090644836,
      "learning_rate": 2.9373333333333334e-07,
      "logits/chosen": -2.4443013668060303,
      "logits/rejected": -2.23016095161438,
      "logps/chosen": -118.70970153808594,
      "logps/rejected": -137.16458129882812,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32208290696144104,
      "rewards/margins": 9.725603103637695,
      "rewards/rejected": -9.403520584106445,
      "step": 5298
    },
    {
      "epoch": 2.1196,
      "grad_norm": 0.8868535161018372,
      "learning_rate": 2.9360000000000003e-07,
      "logits/chosen": -2.711599826812744,
      "logits/rejected": -2.530294895172119,
      "logps/chosen": -128.7757568359375,
      "logps/rejected": -124.71395874023438,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1839261054992676,
      "rewards/margins": 6.754707336425781,
      "rewards/rejected": -7.938633441925049,
      "step": 5299
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.45309439301490784,
      "learning_rate": 2.934666666666666e-07,
      "logits/chosen": -2.533519983291626,
      "logits/rejected": -2.305321455001831,
      "logps/chosen": -66.4386978149414,
      "logps/rejected": -114.7540054321289,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8600926399230957,
      "rewards/margins": 9.229429244995117,
      "rewards/rejected": -7.36933708190918,
      "step": 5300
    },
    {
      "epoch": 2.1204,
      "grad_norm": 0.09664872288703918,
      "learning_rate": 2.933333333333333e-07,
      "logits/chosen": -2.9597535133361816,
      "logits/rejected": -2.7830071449279785,
      "logps/chosen": -60.11693572998047,
      "logps/rejected": -128.60328674316406,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4402666091918945,
      "rewards/margins": 9.329285621643066,
      "rewards/rejected": -7.889019012451172,
      "step": 5301
    },
    {
      "epoch": 2.1208,
      "grad_norm": 0.008768201805651188,
      "learning_rate": 2.932e-07,
      "logits/chosen": -2.605440139770508,
      "logits/rejected": -2.2497777938842773,
      "logps/chosen": -110.0667724609375,
      "logps/rejected": -162.2519989013672,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45558395981788635,
      "rewards/margins": 10.97321891784668,
      "rewards/rejected": -10.517635345458984,
      "step": 5302
    },
    {
      "epoch": 2.1212,
      "grad_norm": 0.057118065655231476,
      "learning_rate": 2.9306666666666664e-07,
      "logits/chosen": -2.6114282608032227,
      "logits/rejected": -2.2598023414611816,
      "logps/chosen": -95.24008178710938,
      "logps/rejected": -165.15509033203125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.347009301185608,
      "rewards/margins": 11.683601379394531,
      "rewards/rejected": -10.336591720581055,
      "step": 5303
    },
    {
      "epoch": 2.1216,
      "grad_norm": 0.005902642384171486,
      "learning_rate": 2.9293333333333334e-07,
      "logits/chosen": -2.260122299194336,
      "logits/rejected": -1.6621806621551514,
      "logps/chosen": -161.7646484375,
      "logps/rejected": -154.88812255859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.717760443687439,
      "rewards/margins": 10.586431503295898,
      "rewards/rejected": -8.868671417236328,
      "step": 5304
    },
    {
      "epoch": 2.122,
      "grad_norm": 0.0152426203712821,
      "learning_rate": 2.928e-07,
      "logits/chosen": -2.626183271408081,
      "logits/rejected": -1.8646398782730103,
      "logps/chosen": -110.90582275390625,
      "logps/rejected": -210.38516235351562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7663814425468445,
      "rewards/margins": 13.195125579833984,
      "rewards/rejected": -13.961505889892578,
      "step": 5305
    },
    {
      "epoch": 2.1224,
      "grad_norm": 0.0004590969765558839,
      "learning_rate": 2.9266666666666667e-07,
      "logits/chosen": -2.569809913635254,
      "logits/rejected": -1.783290147781372,
      "logps/chosen": -152.43313598632812,
      "logps/rejected": -231.55030822753906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5832363367080688,
      "rewards/margins": 14.059558868408203,
      "rewards/rejected": -14.64279556274414,
      "step": 5306
    },
    {
      "epoch": 2.1228,
      "grad_norm": 29.12245750427246,
      "learning_rate": 2.925333333333333e-07,
      "logits/chosen": -2.616328239440918,
      "logits/rejected": -2.217714548110962,
      "logps/chosen": -123.26903533935547,
      "logps/rejected": -113.05240631103516,
      "loss": 0.1167,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.29995059967041,
      "rewards/margins": 4.2329816818237305,
      "rewards/rejected": -7.532932281494141,
      "step": 5307
    },
    {
      "epoch": 2.1232,
      "grad_norm": 4.816304683685303,
      "learning_rate": 2.924e-07,
      "logits/chosen": -2.640824317932129,
      "logits/rejected": -2.1281983852386475,
      "logps/chosen": -145.56387329101562,
      "logps/rejected": -154.9415283203125,
      "loss": 0.0167,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9979133605957031,
      "rewards/margins": 9.200593948364258,
      "rewards/rejected": -10.198508262634277,
      "step": 5308
    },
    {
      "epoch": 2.1236,
      "grad_norm": 0.0028752493672072887,
      "learning_rate": 2.9226666666666664e-07,
      "logits/chosen": -2.456982135772705,
      "logits/rejected": -2.0275142192840576,
      "logps/chosen": -99.50286865234375,
      "logps/rejected": -185.33299255371094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.06741338968276978,
      "rewards/margins": 11.57314395904541,
      "rewards/rejected": -11.640557289123535,
      "step": 5309
    },
    {
      "epoch": 2.124,
      "grad_norm": 0.001272302703000605,
      "learning_rate": 2.9213333333333333e-07,
      "logits/chosen": -2.660919427871704,
      "logits/rejected": -1.9992671012878418,
      "logps/chosen": -95.96928405761719,
      "logps/rejected": -208.1624755859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1274557113647461,
      "rewards/margins": 13.058048248291016,
      "rewards/rejected": -13.185503959655762,
      "step": 5310
    },
    {
      "epoch": 2.1244,
      "grad_norm": 0.008472972549498081,
      "learning_rate": 2.9199999999999997e-07,
      "logits/chosen": -2.948153018951416,
      "logits/rejected": -2.2446253299713135,
      "logps/chosen": -63.435298919677734,
      "logps/rejected": -146.51388549804688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8697021007537842,
      "rewards/margins": 12.371509552001953,
      "rewards/rejected": -10.501808166503906,
      "step": 5311
    },
    {
      "epoch": 2.1248,
      "grad_norm": 216.71994018554688,
      "learning_rate": 2.9186666666666666e-07,
      "logits/chosen": -1.996234655380249,
      "logits/rejected": -1.345581293106079,
      "logps/chosen": -244.386474609375,
      "logps/rejected": -209.91317749023438,
      "loss": 1.7913,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -8.128671646118164,
      "rewards/margins": 5.444683074951172,
      "rewards/rejected": -13.573354721069336,
      "step": 5312
    },
    {
      "epoch": 2.1252,
      "grad_norm": 2.668630599975586,
      "learning_rate": 2.9173333333333335e-07,
      "logits/chosen": -2.649477005004883,
      "logits/rejected": -2.443100929260254,
      "logps/chosen": -127.01483154296875,
      "logps/rejected": -188.71347045898438,
      "loss": 0.0117,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1426013708114624,
      "rewards/margins": 11.281933784484863,
      "rewards/rejected": -12.424535751342773,
      "step": 5313
    },
    {
      "epoch": 2.1256,
      "grad_norm": 1.436397910118103,
      "learning_rate": 2.916e-07,
      "logits/chosen": -2.4360954761505127,
      "logits/rejected": -2.2128028869628906,
      "logps/chosen": -142.1148681640625,
      "logps/rejected": -142.80081176757812,
      "loss": 0.0068,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.4454221725463867,
      "rewards/margins": 6.664344787597656,
      "rewards/rejected": -9.109766960144043,
      "step": 5314
    },
    {
      "epoch": 2.126,
      "grad_norm": 0.025427015498280525,
      "learning_rate": 2.9146666666666663e-07,
      "logits/chosen": -2.1368660926818848,
      "logits/rejected": -1.432524561882019,
      "logps/chosen": -167.16329956054688,
      "logps/rejected": -197.01390075683594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.021654605865478516,
      "rewards/margins": 12.691740989685059,
      "rewards/rejected": -12.713396072387695,
      "step": 5315
    },
    {
      "epoch": 2.1264,
      "grad_norm": 0.11677612364292145,
      "learning_rate": 2.913333333333333e-07,
      "logits/chosen": -2.292412757873535,
      "logits/rejected": -1.9872150421142578,
      "logps/chosen": -143.678955078125,
      "logps/rejected": -133.15606689453125,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8614425659179688,
      "rewards/margins": 8.396675109863281,
      "rewards/rejected": -9.25811767578125,
      "step": 5316
    },
    {
      "epoch": 2.1268,
      "grad_norm": 0.8988160490989685,
      "learning_rate": 2.912e-07,
      "logits/chosen": -2.453782558441162,
      "logits/rejected": -1.8992048501968384,
      "logps/chosen": -137.47479248046875,
      "logps/rejected": -159.5438690185547,
      "loss": 0.0048,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10314631462097168,
      "rewards/margins": 9.999783515930176,
      "rewards/rejected": -9.896636962890625,
      "step": 5317
    },
    {
      "epoch": 2.1272,
      "grad_norm": 0.0002487187157385051,
      "learning_rate": 2.9106666666666665e-07,
      "logits/chosen": -2.399975538253784,
      "logits/rejected": -1.5867280960083008,
      "logps/chosen": -97.86625671386719,
      "logps/rejected": -230.1634521484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4396690130233765,
      "rewards/margins": 15.388763427734375,
      "rewards/rejected": -13.949094772338867,
      "step": 5318
    },
    {
      "epoch": 2.1276,
      "grad_norm": 0.3325287997722626,
      "learning_rate": 2.909333333333333e-07,
      "logits/chosen": -2.891538619995117,
      "logits/rejected": -2.384798765182495,
      "logps/chosen": -79.83665466308594,
      "logps/rejected": -168.6771240234375,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5823940634727478,
      "rewards/margins": 10.753105163574219,
      "rewards/rejected": -11.335498809814453,
      "step": 5319
    },
    {
      "epoch": 2.128,
      "grad_norm": 0.015881823375821114,
      "learning_rate": 2.908e-07,
      "logits/chosen": -2.535940408706665,
      "logits/rejected": -2.023664712905884,
      "logps/chosen": -123.72392272949219,
      "logps/rejected": -165.90859985351562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4737342894077301,
      "rewards/margins": 9.721749305725098,
      "rewards/rejected": -10.195484161376953,
      "step": 5320
    },
    {
      "epoch": 2.1284,
      "grad_norm": 0.0016453940188512206,
      "learning_rate": 2.906666666666667e-07,
      "logits/chosen": -2.8631677627563477,
      "logits/rejected": -2.292318344116211,
      "logps/chosen": -75.85945129394531,
      "logps/rejected": -181.904052734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2821727693080902,
      "rewards/margins": 12.198169708251953,
      "rewards/rejected": -11.915996551513672,
      "step": 5321
    },
    {
      "epoch": 2.1288,
      "grad_norm": 0.05909410119056702,
      "learning_rate": 2.905333333333333e-07,
      "logits/chosen": -3.1247897148132324,
      "logits/rejected": -2.58187198638916,
      "logps/chosen": -110.56805419921875,
      "logps/rejected": -226.98348999023438,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2323681116104126,
      "rewards/margins": 14.657366752624512,
      "rewards/rejected": -15.889734268188477,
      "step": 5322
    },
    {
      "epoch": 2.1292,
      "grad_norm": 0.003024569945409894,
      "learning_rate": 2.9039999999999995e-07,
      "logits/chosen": -2.270353317260742,
      "logits/rejected": -1.4081735610961914,
      "logps/chosen": -146.47891235351562,
      "logps/rejected": -213.50399780273438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.20624084770679474,
      "rewards/margins": 11.768588066101074,
      "rewards/rejected": -11.974828720092773,
      "step": 5323
    },
    {
      "epoch": 2.1296,
      "grad_norm": 0.0016513920854777098,
      "learning_rate": 2.9026666666666665e-07,
      "logits/chosen": -2.5479512214660645,
      "logits/rejected": -1.6659162044525146,
      "logps/chosen": -93.2926025390625,
      "logps/rejected": -175.60902404785156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3266346454620361,
      "rewards/margins": 13.747556686401367,
      "rewards/rejected": -12.42092227935791,
      "step": 5324
    },
    {
      "epoch": 2.13,
      "grad_norm": 1.911932122311555e-05,
      "learning_rate": 2.9013333333333334e-07,
      "logits/chosen": -2.3279776573181152,
      "logits/rejected": -1.5422799587249756,
      "logps/chosen": -101.72117614746094,
      "logps/rejected": -250.46295166015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.094015598297119,
      "rewards/margins": 17.064586639404297,
      "rewards/rejected": -14.970571517944336,
      "step": 5325
    },
    {
      "epoch": 2.1304,
      "grad_norm": 0.7238101363182068,
      "learning_rate": 2.9e-07,
      "logits/chosen": -2.779047966003418,
      "logits/rejected": -2.291947841644287,
      "logps/chosen": -65.03789520263672,
      "logps/rejected": -135.85183715820312,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3456623554229736,
      "rewards/margins": 9.632312774658203,
      "rewards/rejected": -8.286650657653809,
      "step": 5326
    },
    {
      "epoch": 2.1308,
      "grad_norm": 0.00023149201297201216,
      "learning_rate": 2.8986666666666667e-07,
      "logits/chosen": -2.6668734550476074,
      "logits/rejected": -1.9832227230072021,
      "logps/chosen": -118.89027404785156,
      "logps/rejected": -333.78289794921875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8030228018760681,
      "rewards/margins": 14.389397621154785,
      "rewards/rejected": -13.586374282836914,
      "step": 5327
    },
    {
      "epoch": 2.1312,
      "grad_norm": 0.002093741437420249,
      "learning_rate": 2.897333333333333e-07,
      "logits/chosen": -2.3041183948516846,
      "logits/rejected": -1.5221517086029053,
      "logps/chosen": -101.02272033691406,
      "logps/rejected": -172.95437622070312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9280411005020142,
      "rewards/margins": 11.96787166595459,
      "rewards/rejected": -10.039831161499023,
      "step": 5328
    },
    {
      "epoch": 2.1316,
      "grad_norm": 0.2319866567850113,
      "learning_rate": 2.896e-07,
      "logits/chosen": -2.2077369689941406,
      "logits/rejected": -1.3041000366210938,
      "logps/chosen": -163.99301147460938,
      "logps/rejected": -177.00772094726562,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5435100793838501,
      "rewards/margins": 9.24350357055664,
      "rewards/rejected": -9.787013053894043,
      "step": 5329
    },
    {
      "epoch": 2.132,
      "grad_norm": 0.2654300034046173,
      "learning_rate": 2.8946666666666664e-07,
      "logits/chosen": -2.611964225769043,
      "logits/rejected": -1.9290920495986938,
      "logps/chosen": -106.27494049072266,
      "logps/rejected": -142.5464324951172,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7864158749580383,
      "rewards/margins": 8.061266899108887,
      "rewards/rejected": -7.274850845336914,
      "step": 5330
    },
    {
      "epoch": 2.1324,
      "grad_norm": 0.07353948056697845,
      "learning_rate": 2.8933333333333333e-07,
      "logits/chosen": -2.834469795227051,
      "logits/rejected": -2.3391897678375244,
      "logps/chosen": -114.44374084472656,
      "logps/rejected": -132.06082153320312,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5940631628036499,
      "rewards/margins": 8.474000930786133,
      "rewards/rejected": -7.879938125610352,
      "step": 5331
    },
    {
      "epoch": 2.1328,
      "grad_norm": 0.010841102339327335,
      "learning_rate": 2.892e-07,
      "logits/chosen": -2.672929286956787,
      "logits/rejected": -1.91923987865448,
      "logps/chosen": -48.16596221923828,
      "logps/rejected": -153.35763549804688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2912715673446655,
      "rewards/margins": 11.663846969604492,
      "rewards/rejected": -10.372575759887695,
      "step": 5332
    },
    {
      "epoch": 2.1332,
      "grad_norm": 0.0027455443050712347,
      "learning_rate": 2.8906666666666666e-07,
      "logits/chosen": -2.8038463592529297,
      "logits/rejected": -2.433483123779297,
      "logps/chosen": -113.47754669189453,
      "logps/rejected": -225.34613037109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.28780174255371094,
      "rewards/margins": 12.890157699584961,
      "rewards/rejected": -12.60235595703125,
      "step": 5333
    },
    {
      "epoch": 2.1336,
      "grad_norm": 0.68597412109375,
      "learning_rate": 2.889333333333333e-07,
      "logits/chosen": -2.552448272705078,
      "logits/rejected": -2.3207366466522217,
      "logps/chosen": -145.52284240722656,
      "logps/rejected": -187.48199462890625,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5031135678291321,
      "rewards/margins": 8.973186492919922,
      "rewards/rejected": -9.476299285888672,
      "step": 5334
    },
    {
      "epoch": 2.134,
      "grad_norm": 32.103092193603516,
      "learning_rate": 2.888e-07,
      "logits/chosen": -2.7916812896728516,
      "logits/rejected": -2.436221122741699,
      "logps/chosen": -145.08544921875,
      "logps/rejected": -182.2760009765625,
      "loss": 0.178,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.8242650032043457,
      "rewards/margins": 6.30557107925415,
      "rewards/rejected": -9.129836082458496,
      "step": 5335
    },
    {
      "epoch": 2.1344,
      "grad_norm": 0.019692152738571167,
      "learning_rate": 2.886666666666667e-07,
      "logits/chosen": -2.710409164428711,
      "logits/rejected": -1.9952385425567627,
      "logps/chosen": -83.70890808105469,
      "logps/rejected": -166.03146362304688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5244770050048828,
      "rewards/margins": 10.996397972106934,
      "rewards/rejected": -10.47192096710205,
      "step": 5336
    },
    {
      "epoch": 2.1348,
      "grad_norm": 0.02596600539982319,
      "learning_rate": 2.8853333333333327e-07,
      "logits/chosen": -2.8604378700256348,
      "logits/rejected": -2.2780704498291016,
      "logps/chosen": -70.60066223144531,
      "logps/rejected": -126.35576629638672,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.614201307296753,
      "rewards/margins": 10.156310081481934,
      "rewards/rejected": -8.542108535766602,
      "step": 5337
    },
    {
      "epoch": 2.1352,
      "grad_norm": 0.0009511957759968936,
      "learning_rate": 2.8839999999999996e-07,
      "logits/chosen": -2.7262706756591797,
      "logits/rejected": -2.1347126960754395,
      "logps/chosen": -96.64952850341797,
      "logps/rejected": -168.40719604492188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6623691320419312,
      "rewards/margins": 12.774016380310059,
      "rewards/rejected": -11.11164665222168,
      "step": 5338
    },
    {
      "epoch": 2.1356,
      "grad_norm": 0.025520846247673035,
      "learning_rate": 2.8826666666666665e-07,
      "logits/chosen": -3.001918077468872,
      "logits/rejected": -2.5671892166137695,
      "logps/chosen": -40.361045837402344,
      "logps/rejected": -167.83392333984375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3960332870483398,
      "rewards/margins": 12.549535751342773,
      "rewards/rejected": -11.153502464294434,
      "step": 5339
    },
    {
      "epoch": 2.136,
      "grad_norm": 0.02541230246424675,
      "learning_rate": 2.8813333333333335e-07,
      "logits/chosen": -2.6350107192993164,
      "logits/rejected": -2.361640453338623,
      "logps/chosen": -100.39049530029297,
      "logps/rejected": -142.90757751464844,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1254584789276123,
      "rewards/margins": 9.058845520019531,
      "rewards/rejected": -9.184304237365723,
      "step": 5340
    },
    {
      "epoch": 2.1364,
      "grad_norm": 0.6084585189819336,
      "learning_rate": 2.88e-07,
      "logits/chosen": -3.0057570934295654,
      "logits/rejected": -2.7569379806518555,
      "logps/chosen": -95.44003295898438,
      "logps/rejected": -147.38375854492188,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5004101395606995,
      "rewards/margins": 10.027884483337402,
      "rewards/rejected": -9.527474403381348,
      "step": 5341
    },
    {
      "epoch": 2.1368,
      "grad_norm": 0.03094598837196827,
      "learning_rate": 2.878666666666666e-07,
      "logits/chosen": -2.630156993865967,
      "logits/rejected": -1.7933944463729858,
      "logps/chosen": -115.6623306274414,
      "logps/rejected": -162.952880859375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2109851837158203,
      "rewards/margins": 8.89283561706543,
      "rewards/rejected": -10.10382080078125,
      "step": 5342
    },
    {
      "epoch": 2.1372,
      "grad_norm": 0.1294466108083725,
      "learning_rate": 2.877333333333333e-07,
      "logits/chosen": -2.7741169929504395,
      "logits/rejected": -2.604431390762329,
      "logps/chosen": -55.00208282470703,
      "logps/rejected": -104.79042053222656,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7789981961250305,
      "rewards/margins": 7.341593265533447,
      "rewards/rejected": -6.562595367431641,
      "step": 5343
    },
    {
      "epoch": 2.1376,
      "grad_norm": 0.018450595438480377,
      "learning_rate": 2.876e-07,
      "logits/chosen": -3.0520036220550537,
      "logits/rejected": -2.583465576171875,
      "logps/chosen": -60.820220947265625,
      "logps/rejected": -131.8463134765625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.01786327362060547,
      "rewards/margins": 8.98957633972168,
      "rewards/rejected": -9.007440567016602,
      "step": 5344
    },
    {
      "epoch": 2.138,
      "grad_norm": 0.023606108501553535,
      "learning_rate": 2.8746666666666665e-07,
      "logits/chosen": -2.759373664855957,
      "logits/rejected": -2.3874990940093994,
      "logps/chosen": -172.1925048828125,
      "logps/rejected": -188.6705780029297,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.230934977531433,
      "rewards/margins": 12.083995819091797,
      "rewards/rejected": -13.31493091583252,
      "step": 5345
    },
    {
      "epoch": 2.1384,
      "grad_norm": 0.303085058927536,
      "learning_rate": 2.8733333333333334e-07,
      "logits/chosen": -2.368643045425415,
      "logits/rejected": -1.8914599418640137,
      "logps/chosen": -180.2694549560547,
      "logps/rejected": -173.87991333007812,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5955703258514404,
      "rewards/margins": 9.151451110839844,
      "rewards/rejected": -10.747021675109863,
      "step": 5346
    },
    {
      "epoch": 2.1388,
      "grad_norm": 0.022847576066851616,
      "learning_rate": 2.872e-07,
      "logits/chosen": -2.79618239402771,
      "logits/rejected": -2.4664957523345947,
      "logps/chosen": -61.4912109375,
      "logps/rejected": -172.5777130126953,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.46919211745262146,
      "rewards/margins": 10.787696838378906,
      "rewards/rejected": -11.256889343261719,
      "step": 5347
    },
    {
      "epoch": 2.1391999999999998,
      "grad_norm": 1.0880922079086304,
      "learning_rate": 2.8706666666666667e-07,
      "logits/chosen": -2.4136452674865723,
      "logits/rejected": -2.294933319091797,
      "logps/chosen": -112.371826171875,
      "logps/rejected": -151.8654022216797,
      "loss": 0.007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.46466100215911865,
      "rewards/margins": 8.839366912841797,
      "rewards/rejected": -9.304027557373047,
      "step": 5348
    },
    {
      "epoch": 2.1396,
      "grad_norm": 0.004248186945915222,
      "learning_rate": 2.869333333333333e-07,
      "logits/chosen": -2.7535481452941895,
      "logits/rejected": -2.0047874450683594,
      "logps/chosen": -116.7677001953125,
      "logps/rejected": -236.89419555664062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42455291748046875,
      "rewards/margins": 13.622851371765137,
      "rewards/rejected": -13.198299407958984,
      "step": 5349
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.04206594079732895,
      "learning_rate": 2.868e-07,
      "logits/chosen": -2.882727861404419,
      "logits/rejected": -2.6240339279174805,
      "logps/chosen": -74.22311401367188,
      "logps/rejected": -127.52935028076172,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2250382900238037,
      "rewards/margins": 10.332763671875,
      "rewards/rejected": -8.107726097106934,
      "step": 5350
    },
    {
      "epoch": 2.1404,
      "grad_norm": 0.16606640815734863,
      "learning_rate": 2.866666666666667e-07,
      "logits/chosen": -2.779599189758301,
      "logits/rejected": -2.141812324523926,
      "logps/chosen": -104.82771301269531,
      "logps/rejected": -152.3195037841797,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6477859616279602,
      "rewards/margins": 8.371698379516602,
      "rewards/rejected": -9.01948356628418,
      "step": 5351
    },
    {
      "epoch": 2.1408,
      "grad_norm": 0.014745967462658882,
      "learning_rate": 2.865333333333333e-07,
      "logits/chosen": -2.5180559158325195,
      "logits/rejected": -2.7016782760620117,
      "logps/chosen": -130.59466552734375,
      "logps/rejected": -137.41848754882812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2931419014930725,
      "rewards/margins": 9.659241676330566,
      "rewards/rejected": -9.366100311279297,
      "step": 5352
    },
    {
      "epoch": 2.1412,
      "grad_norm": 0.07216407358646393,
      "learning_rate": 2.8639999999999997e-07,
      "logits/chosen": -3.0694122314453125,
      "logits/rejected": -2.7642736434936523,
      "logps/chosen": -55.40809631347656,
      "logps/rejected": -88.33369445800781,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.897871971130371,
      "rewards/margins": 8.179647445678711,
      "rewards/rejected": -6.28177547454834,
      "step": 5353
    },
    {
      "epoch": 2.1416,
      "grad_norm": 30.352603912353516,
      "learning_rate": 2.8626666666666666e-07,
      "logits/chosen": -2.6493642330169678,
      "logits/rejected": -2.577538013458252,
      "logps/chosen": -160.2962646484375,
      "logps/rejected": -94.09796142578125,
      "loss": 0.1448,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7605786323547363,
      "rewards/margins": 2.7186169624328613,
      "rewards/rejected": -4.479195594787598,
      "step": 5354
    },
    {
      "epoch": 2.142,
      "grad_norm": 0.00156600889749825,
      "learning_rate": 2.8613333333333335e-07,
      "logits/chosen": -2.350886821746826,
      "logits/rejected": -1.6446245908737183,
      "logps/chosen": -150.18186950683594,
      "logps/rejected": -176.72869873046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5458595752716064,
      "rewards/margins": 12.272045135498047,
      "rewards/rejected": -10.726184844970703,
      "step": 5355
    },
    {
      "epoch": 2.1424,
      "grad_norm": 0.024640308693051338,
      "learning_rate": 2.8599999999999994e-07,
      "logits/chosen": -2.79740571975708,
      "logits/rejected": -2.3461480140686035,
      "logps/chosen": -89.35038757324219,
      "logps/rejected": -169.38790893554688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5526145696640015,
      "rewards/margins": 12.17284107208252,
      "rewards/rejected": -11.62022590637207,
      "step": 5356
    },
    {
      "epoch": 2.1428,
      "grad_norm": 0.3561863303184509,
      "learning_rate": 2.8586666666666663e-07,
      "logits/chosen": -2.9734551906585693,
      "logits/rejected": -2.6338629722595215,
      "logps/chosen": -71.84297180175781,
      "logps/rejected": -91.38656616210938,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7460548281669617,
      "rewards/margins": 5.83902645111084,
      "rewards/rejected": -6.585081100463867,
      "step": 5357
    },
    {
      "epoch": 2.1432,
      "grad_norm": 0.003082181792706251,
      "learning_rate": 2.857333333333333e-07,
      "logits/chosen": -2.682032585144043,
      "logits/rejected": -2.2020699977874756,
      "logps/chosen": -54.65955352783203,
      "logps/rejected": -206.1844024658203,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.268170714378357,
      "rewards/margins": 11.941301345825195,
      "rewards/rejected": -10.67313003540039,
      "step": 5358
    },
    {
      "epoch": 2.1436,
      "grad_norm": 4.5959858894348145,
      "learning_rate": 2.856e-07,
      "logits/chosen": -2.620634078979492,
      "logits/rejected": -2.1125669479370117,
      "logps/chosen": -122.60675048828125,
      "logps/rejected": -123.72962188720703,
      "loss": 0.0205,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5207347869873047,
      "rewards/margins": 7.446599960327148,
      "rewards/rejected": -7.967334747314453,
      "step": 5359
    },
    {
      "epoch": 2.144,
      "grad_norm": 0.824140191078186,
      "learning_rate": 2.8546666666666666e-07,
      "logits/chosen": -3.0100951194763184,
      "logits/rejected": -2.655294179916382,
      "logps/chosen": -65.43226623535156,
      "logps/rejected": -148.54388427734375,
      "loss": 0.0093,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11377894878387451,
      "rewards/margins": 8.816937446594238,
      "rewards/rejected": -8.703158378601074,
      "step": 5360
    },
    {
      "epoch": 2.1444,
      "grad_norm": 0.006263823714107275,
      "learning_rate": 2.853333333333333e-07,
      "logits/chosen": -2.8417301177978516,
      "logits/rejected": -2.457045555114746,
      "logps/chosen": -65.13790893554688,
      "logps/rejected": -141.91912841796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5926952362060547,
      "rewards/margins": 10.546649932861328,
      "rewards/rejected": -9.953954696655273,
      "step": 5361
    },
    {
      "epoch": 2.1448,
      "grad_norm": 0.0025117925833910704,
      "learning_rate": 2.852e-07,
      "logits/chosen": -2.4197254180908203,
      "logits/rejected": -1.3007371425628662,
      "logps/chosen": -85.04547119140625,
      "logps/rejected": -170.81736755371094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3721165657043457,
      "rewards/margins": 13.155405044555664,
      "rewards/rejected": -10.783288955688477,
      "step": 5362
    },
    {
      "epoch": 2.1452,
      "grad_norm": 0.00013131467858329415,
      "learning_rate": 2.850666666666667e-07,
      "logits/chosen": -2.729226589202881,
      "logits/rejected": -2.177882432937622,
      "logps/chosen": -76.55841064453125,
      "logps/rejected": -192.84996032714844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5912685394287109,
      "rewards/margins": 14.74062442779541,
      "rewards/rejected": -14.1493558883667,
      "step": 5363
    },
    {
      "epoch": 2.1456,
      "grad_norm": 0.28284719586372375,
      "learning_rate": 2.849333333333333e-07,
      "logits/chosen": -2.904017925262451,
      "logits/rejected": -2.7518982887268066,
      "logps/chosen": -125.08207702636719,
      "logps/rejected": -127.70582580566406,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8287179470062256,
      "rewards/margins": 6.336852073669434,
      "rewards/rejected": -8.165570259094238,
      "step": 5364
    },
    {
      "epoch": 2.146,
      "grad_norm": 54.310638427734375,
      "learning_rate": 2.848e-07,
      "logits/chosen": -2.8619155883789062,
      "logits/rejected": -3.090414524078369,
      "logps/chosen": -118.85211181640625,
      "logps/rejected": -129.21087646484375,
      "loss": 0.2769,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5164356231689453,
      "rewards/margins": 6.39890193939209,
      "rewards/rejected": -7.915337562561035,
      "step": 5365
    },
    {
      "epoch": 2.1464,
      "grad_norm": 4.718873023986816,
      "learning_rate": 2.8466666666666665e-07,
      "logits/chosen": -2.5331130027770996,
      "logits/rejected": -2.0211658477783203,
      "logps/chosen": -73.13526916503906,
      "logps/rejected": -120.53045654296875,
      "loss": 0.0222,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8966895937919617,
      "rewards/margins": 9.326375961303711,
      "rewards/rejected": -8.429686546325684,
      "step": 5366
    },
    {
      "epoch": 2.1468,
      "grad_norm": 0.029333077371120453,
      "learning_rate": 2.8453333333333334e-07,
      "logits/chosen": -2.8926703929901123,
      "logits/rejected": -3.0357871055603027,
      "logps/chosen": -91.78296661376953,
      "logps/rejected": -146.5670166015625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5834312438964844,
      "rewards/margins": 10.921564102172852,
      "rewards/rejected": -9.338132858276367,
      "step": 5367
    },
    {
      "epoch": 2.1471999999999998,
      "grad_norm": 0.010372248478233814,
      "learning_rate": 2.844e-07,
      "logits/chosen": -2.3582863807678223,
      "logits/rejected": -1.9583934545516968,
      "logps/chosen": -154.735595703125,
      "logps/rejected": -132.70506286621094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4701324701309204,
      "rewards/margins": 10.242502212524414,
      "rewards/rejected": -8.772369384765625,
      "step": 5368
    },
    {
      "epoch": 2.1476,
      "grad_norm": 0.0006891605444252491,
      "learning_rate": 2.8426666666666667e-07,
      "logits/chosen": -2.5236310958862305,
      "logits/rejected": -1.9013087749481201,
      "logps/chosen": -123.82559967041016,
      "logps/rejected": -178.07594299316406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2137863636016846,
      "rewards/margins": 12.966293334960938,
      "rewards/rejected": -11.752507209777832,
      "step": 5369
    },
    {
      "epoch": 2.148,
      "grad_norm": 0.03797130659222603,
      "learning_rate": 2.841333333333333e-07,
      "logits/chosen": -2.248460292816162,
      "logits/rejected": -1.362802505493164,
      "logps/chosen": -170.71658325195312,
      "logps/rejected": -225.83901977539062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6020501852035522,
      "rewards/margins": 12.048680305480957,
      "rewards/rejected": -13.65073013305664,
      "step": 5370
    },
    {
      "epoch": 2.1484,
      "grad_norm": 0.40982916951179504,
      "learning_rate": 2.8399999999999995e-07,
      "logits/chosen": -2.866786003112793,
      "logits/rejected": -2.714940071105957,
      "logps/chosen": -99.07997131347656,
      "logps/rejected": -157.05569458007812,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4978126585483551,
      "rewards/margins": 9.338920593261719,
      "rewards/rejected": -9.8367338180542,
      "step": 5371
    },
    {
      "epoch": 2.1488,
      "grad_norm": 0.02564757876098156,
      "learning_rate": 2.8386666666666664e-07,
      "logits/chosen": -2.462494373321533,
      "logits/rejected": -1.8720321655273438,
      "logps/chosen": -165.17999267578125,
      "logps/rejected": -208.43545532226562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.9080238342285156,
      "rewards/margins": 12.311744689941406,
      "rewards/rejected": -15.219768524169922,
      "step": 5372
    },
    {
      "epoch": 2.1492,
      "grad_norm": 0.00172135210596025,
      "learning_rate": 2.8373333333333333e-07,
      "logits/chosen": -2.667837619781494,
      "logits/rejected": -1.819960117340088,
      "logps/chosen": -74.02184295654297,
      "logps/rejected": -152.156494140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0543570518493652,
      "rewards/margins": 12.51974105834961,
      "rewards/rejected": -10.465383529663086,
      "step": 5373
    },
    {
      "epoch": 2.1496,
      "grad_norm": 0.01322403084486723,
      "learning_rate": 2.836e-07,
      "logits/chosen": -2.3263862133026123,
      "logits/rejected": -1.471104383468628,
      "logps/chosen": -80.89373779296875,
      "logps/rejected": -162.2881622314453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.031375885009765625,
      "rewards/margins": 10.78032112121582,
      "rewards/rejected": -10.811697006225586,
      "step": 5374
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.18012374639511108,
      "learning_rate": 2.834666666666666e-07,
      "logits/chosen": -2.8495125770568848,
      "logits/rejected": -2.7218070030212402,
      "logps/chosen": -88.96326446533203,
      "logps/rejected": -122.87553405761719,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4758545160293579,
      "rewards/margins": 9.696392059326172,
      "rewards/rejected": -9.220537185668945,
      "step": 5375
    },
    {
      "epoch": 2.1504,
      "grad_norm": 7.606852159369737e-05,
      "learning_rate": 2.833333333333333e-07,
      "logits/chosen": -2.7781291007995605,
      "logits/rejected": -1.8723822832107544,
      "logps/chosen": -57.17338943481445,
      "logps/rejected": -218.314208984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.283576011657715,
      "rewards/margins": 15.691851615905762,
      "rewards/rejected": -13.408275604248047,
      "step": 5376
    },
    {
      "epoch": 2.1508,
      "grad_norm": 213.09530639648438,
      "learning_rate": 2.832e-07,
      "logits/chosen": -2.5060946941375732,
      "logits/rejected": -2.181760787963867,
      "logps/chosen": -195.65728759765625,
      "logps/rejected": -188.80813598632812,
      "loss": 0.6516,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -4.194436550140381,
      "rewards/margins": 7.585691452026367,
      "rewards/rejected": -11.780128479003906,
      "step": 5377
    },
    {
      "epoch": 2.1512000000000002,
      "grad_norm": 0.0019380440935492516,
      "learning_rate": 2.830666666666667e-07,
      "logits/chosen": -2.602736473083496,
      "logits/rejected": -1.7525150775909424,
      "logps/chosen": -130.54702758789062,
      "logps/rejected": -179.27728271484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9913967251777649,
      "rewards/margins": 13.267169952392578,
      "rewards/rejected": -12.275773048400879,
      "step": 5378
    },
    {
      "epoch": 2.1516,
      "grad_norm": 0.0432640016078949,
      "learning_rate": 2.829333333333333e-07,
      "logits/chosen": -2.8348121643066406,
      "logits/rejected": -2.1301162242889404,
      "logps/chosen": -78.8615951538086,
      "logps/rejected": -140.4053192138672,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6379959583282471,
      "rewards/margins": 9.101388931274414,
      "rewards/rejected": -8.463393211364746,
      "step": 5379
    },
    {
      "epoch": 2.152,
      "grad_norm": 0.08855339884757996,
      "learning_rate": 2.8279999999999996e-07,
      "logits/chosen": -2.442826747894287,
      "logits/rejected": -2.1720376014709473,
      "logps/chosen": -113.08277893066406,
      "logps/rejected": -151.01971435546875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1461433172225952,
      "rewards/margins": 8.958638191223145,
      "rewards/rejected": -10.104782104492188,
      "step": 5380
    },
    {
      "epoch": 2.1524,
      "grad_norm": 0.02974112331867218,
      "learning_rate": 2.8266666666666666e-07,
      "logits/chosen": -2.2006468772888184,
      "logits/rejected": -1.7613483667373657,
      "logps/chosen": -135.37942504882812,
      "logps/rejected": -226.35995483398438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.3033196926116943,
      "rewards/margins": 10.562348365783691,
      "rewards/rejected": -12.865668296813965,
      "step": 5381
    },
    {
      "epoch": 2.1528,
      "grad_norm": 0.003928382880985737,
      "learning_rate": 2.8253333333333335e-07,
      "logits/chosen": -2.973977565765381,
      "logits/rejected": -2.5046284198760986,
      "logps/chosen": -65.21040344238281,
      "logps/rejected": -150.3194122314453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5110031366348267,
      "rewards/margins": 10.571847915649414,
      "rewards/rejected": -10.060844421386719,
      "step": 5382
    },
    {
      "epoch": 2.1532,
      "grad_norm": 0.03021872229874134,
      "learning_rate": 2.824e-07,
      "logits/chosen": -2.7975287437438965,
      "logits/rejected": -2.397519111633301,
      "logps/chosen": -104.04866027832031,
      "logps/rejected": -124.24435424804688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3371819257736206,
      "rewards/margins": 8.931395530700684,
      "rewards/rejected": -7.594213485717773,
      "step": 5383
    },
    {
      "epoch": 2.1536,
      "grad_norm": 0.034087564796209335,
      "learning_rate": 2.8226666666666663e-07,
      "logits/chosen": -2.4605183601379395,
      "logits/rejected": -1.752896785736084,
      "logps/chosen": -141.68394470214844,
      "logps/rejected": -243.274169921875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04534304141998291,
      "rewards/margins": 14.032013893127441,
      "rewards/rejected": -13.986671447753906,
      "step": 5384
    },
    {
      "epoch": 2.154,
      "grad_norm": 0.027550864964723587,
      "learning_rate": 2.821333333333333e-07,
      "logits/chosen": -2.795548915863037,
      "logits/rejected": -2.503260850906372,
      "logps/chosen": -121.81163787841797,
      "logps/rejected": -173.41506958007812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2836430072784424,
      "rewards/margins": 9.487018585205078,
      "rewards/rejected": -10.770660400390625,
      "step": 5385
    },
    {
      "epoch": 2.1544,
      "grad_norm": 0.006806451361626387,
      "learning_rate": 2.8199999999999996e-07,
      "logits/chosen": -2.3992528915405273,
      "logits/rejected": -1.4417943954467773,
      "logps/chosen": -110.97261047363281,
      "logps/rejected": -162.7130584716797,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2139030694961548,
      "rewards/margins": 10.870683670043945,
      "rewards/rejected": -9.656781196594238,
      "step": 5386
    },
    {
      "epoch": 2.1548,
      "grad_norm": 0.010895295068621635,
      "learning_rate": 2.8186666666666665e-07,
      "logits/chosen": -2.8610026836395264,
      "logits/rejected": -2.4308700561523438,
      "logps/chosen": -110.98991394042969,
      "logps/rejected": -188.11654663085938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5790146589279175,
      "rewards/margins": 12.233134269714355,
      "rewards/rejected": -12.812149047851562,
      "step": 5387
    },
    {
      "epoch": 2.1552,
      "grad_norm": 21.380346298217773,
      "learning_rate": 2.8173333333333334e-07,
      "logits/chosen": -2.292604446411133,
      "logits/rejected": -1.9723644256591797,
      "logps/chosen": -171.30714416503906,
      "logps/rejected": -195.18594360351562,
      "loss": 0.103,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -5.730335712432861,
      "rewards/margins": 5.509664535522461,
      "rewards/rejected": -11.239999771118164,
      "step": 5388
    },
    {
      "epoch": 2.1556,
      "grad_norm": 6.620997737627476e-05,
      "learning_rate": 2.816e-07,
      "logits/chosen": -2.4397263526916504,
      "logits/rejected": -1.565929651260376,
      "logps/chosen": -98.06672668457031,
      "logps/rejected": -220.46499633789062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3600215911865234,
      "rewards/margins": 16.193103790283203,
      "rewards/rejected": -14.83308219909668,
      "step": 5389
    },
    {
      "epoch": 2.156,
      "grad_norm": 0.004455634392797947,
      "learning_rate": 2.814666666666666e-07,
      "logits/chosen": -2.6425137519836426,
      "logits/rejected": -1.924556016921997,
      "logps/chosen": -100.88577270507812,
      "logps/rejected": -165.04144287109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.818899929523468,
      "rewards/margins": 11.690412521362305,
      "rewards/rejected": -10.871513366699219,
      "step": 5390
    },
    {
      "epoch": 2.1564,
      "grad_norm": 0.01080547459423542,
      "learning_rate": 2.813333333333333e-07,
      "logits/chosen": -2.7867062091827393,
      "logits/rejected": -2.3378725051879883,
      "logps/chosen": -96.84608459472656,
      "logps/rejected": -177.8565673828125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.896487832069397,
      "rewards/margins": 13.494546890258789,
      "rewards/rejected": -12.598058700561523,
      "step": 5391
    },
    {
      "epoch": 2.1568,
      "grad_norm": 0.03255162388086319,
      "learning_rate": 2.812e-07,
      "logits/chosen": -2.466489315032959,
      "logits/rejected": -1.9938573837280273,
      "logps/chosen": -67.31383514404297,
      "logps/rejected": -160.57086181640625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0011348724365234375,
      "rewards/margins": 10.702914237976074,
      "rewards/rejected": -10.704049110412598,
      "step": 5392
    },
    {
      "epoch": 2.1572,
      "grad_norm": 0.0007553884061053395,
      "learning_rate": 2.810666666666667e-07,
      "logits/chosen": -2.7313764095306396,
      "logits/rejected": -1.9679850339889526,
      "logps/chosen": -91.73897552490234,
      "logps/rejected": -206.71897888183594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5965354442596436,
      "rewards/margins": 13.166204452514648,
      "rewards/rejected": -11.569669723510742,
      "step": 5393
    },
    {
      "epoch": 2.1576,
      "grad_norm": 0.1490013152360916,
      "learning_rate": 2.809333333333333e-07,
      "logits/chosen": -2.6271839141845703,
      "logits/rejected": -1.9882696866989136,
      "logps/chosen": -86.57904815673828,
      "logps/rejected": -140.8527069091797,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8529605865478516,
      "rewards/margins": 9.980119705200195,
      "rewards/rejected": -9.127159118652344,
      "step": 5394
    },
    {
      "epoch": 2.158,
      "grad_norm": 0.2561033070087433,
      "learning_rate": 2.8079999999999997e-07,
      "logits/chosen": -2.690403461456299,
      "logits/rejected": -2.098973512649536,
      "logps/chosen": -91.13282012939453,
      "logps/rejected": -183.3350372314453,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2966003715991974,
      "rewards/margins": 12.466002464294434,
      "rewards/rejected": -12.762602806091309,
      "step": 5395
    },
    {
      "epoch": 2.1584,
      "grad_norm": 0.0007583043188787997,
      "learning_rate": 2.8066666666666667e-07,
      "logits/chosen": -2.587517738342285,
      "logits/rejected": -1.9777380228042603,
      "logps/chosen": -124.47795104980469,
      "logps/rejected": -215.90411376953125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.35359326004981995,
      "rewards/margins": 12.89232063293457,
      "rewards/rejected": -13.245914459228516,
      "step": 5396
    },
    {
      "epoch": 2.1588,
      "grad_norm": 0.002130120526999235,
      "learning_rate": 2.8053333333333336e-07,
      "logits/chosen": -2.527569055557251,
      "logits/rejected": -1.8871550559997559,
      "logps/chosen": -112.38552856445312,
      "logps/rejected": -192.37603759765625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5453174710273743,
      "rewards/margins": 11.788848876953125,
      "rewards/rejected": -11.243532180786133,
      "step": 5397
    },
    {
      "epoch": 2.1592000000000002,
      "grad_norm": 0.0011798734776675701,
      "learning_rate": 2.804e-07,
      "logits/chosen": -2.610332489013672,
      "logits/rejected": -2.168172836303711,
      "logps/chosen": -82.78868103027344,
      "logps/rejected": -204.931640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5829257965087891,
      "rewards/margins": 13.00128173828125,
      "rewards/rejected": -13.584207534790039,
      "step": 5398
    },
    {
      "epoch": 2.1596,
      "grad_norm": 0.029695186764001846,
      "learning_rate": 2.8026666666666664e-07,
      "logits/chosen": -2.5329346656799316,
      "logits/rejected": -1.8697844743728638,
      "logps/chosen": -44.25563049316406,
      "logps/rejected": -139.57662963867188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.027814507484436,
      "rewards/margins": 9.244133949279785,
      "rewards/rejected": -8.21631908416748,
      "step": 5399
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.00413485337048769,
      "learning_rate": 2.8013333333333333e-07,
      "logits/chosen": -2.563946485519409,
      "logits/rejected": -2.4640111923217773,
      "logps/chosen": -132.23281860351562,
      "logps/rejected": -212.63523864746094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.852277398109436,
      "rewards/margins": 12.536291122436523,
      "rewards/rejected": -13.388567924499512,
      "step": 5400
    },
    {
      "epoch": 2.1604,
      "grad_norm": 0.005572841502726078,
      "learning_rate": 2.8e-07,
      "logits/chosen": -2.910334825515747,
      "logits/rejected": -2.5153980255126953,
      "logps/chosen": -68.02679443359375,
      "logps/rejected": -191.331787109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6762189865112305,
      "rewards/margins": 12.259820938110352,
      "rewards/rejected": -12.936038970947266,
      "step": 5401
    },
    {
      "epoch": 2.1608,
      "grad_norm": 0.07031657546758652,
      "learning_rate": 2.7986666666666666e-07,
      "logits/chosen": -2.792304277420044,
      "logits/rejected": -2.3029885292053223,
      "logps/chosen": -122.71434020996094,
      "logps/rejected": -184.71212768554688,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3502933382987976,
      "rewards/margins": 10.850329399108887,
      "rewards/rejected": -11.20062255859375,
      "step": 5402
    },
    {
      "epoch": 2.1612,
      "grad_norm": 0.00018445005116518587,
      "learning_rate": 2.797333333333333e-07,
      "logits/chosen": -2.407484531402588,
      "logits/rejected": -1.4992272853851318,
      "logps/chosen": -116.4351577758789,
      "logps/rejected": -225.50668334960938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2673252820968628,
      "rewards/margins": 14.78553295135498,
      "rewards/rejected": -13.518207550048828,
      "step": 5403
    },
    {
      "epoch": 2.1616,
      "grad_norm": 0.0010587505530565977,
      "learning_rate": 2.796e-07,
      "logits/chosen": -2.6304142475128174,
      "logits/rejected": -1.9155124425888062,
      "logps/chosen": -139.91244506835938,
      "logps/rejected": -196.29092407226562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7370361685752869,
      "rewards/margins": 14.132816314697266,
      "rewards/rejected": -13.395780563354492,
      "step": 5404
    },
    {
      "epoch": 2.162,
      "grad_norm": 0.18924522399902344,
      "learning_rate": 2.7946666666666663e-07,
      "logits/chosen": -2.868764638900757,
      "logits/rejected": -2.5161101818084717,
      "logps/chosen": -41.79755401611328,
      "logps/rejected": -102.21142578125,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0053372383117676,
      "rewards/margins": 7.954963684082031,
      "rewards/rejected": -6.949626445770264,
      "step": 5405
    },
    {
      "epoch": 2.1624,
      "grad_norm": 0.06797240674495697,
      "learning_rate": 2.793333333333333e-07,
      "logits/chosen": -2.4560904502868652,
      "logits/rejected": -1.7670459747314453,
      "logps/chosen": -95.29092407226562,
      "logps/rejected": -160.63182067871094,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5786423683166504,
      "rewards/margins": 11.434280395507812,
      "rewards/rejected": -9.855637550354004,
      "step": 5406
    },
    {
      "epoch": 2.1628,
      "grad_norm": 0.00140853738412261,
      "learning_rate": 2.792e-07,
      "logits/chosen": -2.3907957077026367,
      "logits/rejected": -1.4307849407196045,
      "logps/chosen": -75.16026306152344,
      "logps/rejected": -159.80740356445312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9367666244506836,
      "rewards/margins": 12.763593673706055,
      "rewards/rejected": -9.826826095581055,
      "step": 5407
    },
    {
      "epoch": 2.1632,
      "grad_norm": 1.240673542022705,
      "learning_rate": 2.7906666666666665e-07,
      "logits/chosen": -2.3126485347747803,
      "logits/rejected": -1.8181771039962769,
      "logps/chosen": -143.46218872070312,
      "logps/rejected": -164.4247589111328,
      "loss": 0.0055,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3766958713531494,
      "rewards/margins": 9.775031089782715,
      "rewards/rejected": -11.151727676391602,
      "step": 5408
    },
    {
      "epoch": 2.1636,
      "grad_norm": 0.011128968559205532,
      "learning_rate": 2.789333333333333e-07,
      "logits/chosen": -2.529735803604126,
      "logits/rejected": -2.0102407932281494,
      "logps/chosen": -66.13320922851562,
      "logps/rejected": -163.70120239257812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5763394832611084,
      "rewards/margins": 10.880599975585938,
      "rewards/rejected": -10.30426025390625,
      "step": 5409
    },
    {
      "epoch": 2.164,
      "grad_norm": 0.5465964078903198,
      "learning_rate": 2.788e-07,
      "logits/chosen": -2.4965906143188477,
      "logits/rejected": -2.358583688735962,
      "logps/chosen": -164.1686248779297,
      "logps/rejected": -159.13632202148438,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.4600696563720703,
      "rewards/margins": 7.661761283874512,
      "rewards/rejected": -11.121829986572266,
      "step": 5410
    },
    {
      "epoch": 2.1644,
      "grad_norm": 1.8891125917434692,
      "learning_rate": 2.786666666666667e-07,
      "logits/chosen": -2.1234865188598633,
      "logits/rejected": -1.3389127254486084,
      "logps/chosen": -161.91859436035156,
      "logps/rejected": -177.4805145263672,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7680038213729858,
      "rewards/margins": 10.778091430664062,
      "rewards/rejected": -11.54609489440918,
      "step": 5411
    },
    {
      "epoch": 2.1648,
      "grad_norm": 0.03507152199745178,
      "learning_rate": 2.7853333333333337e-07,
      "logits/chosen": -2.858522891998291,
      "logits/rejected": -2.4497053623199463,
      "logps/chosen": -80.28872680664062,
      "logps/rejected": -149.87625122070312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2656311094760895,
      "rewards/margins": 9.22681999206543,
      "rewards/rejected": -9.492450714111328,
      "step": 5412
    },
    {
      "epoch": 2.1652,
      "grad_norm": 0.12529923021793365,
      "learning_rate": 2.7839999999999995e-07,
      "logits/chosen": -2.498414993286133,
      "logits/rejected": -1.9492945671081543,
      "logps/chosen": -101.09829711914062,
      "logps/rejected": -140.38040161132812,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.20205917954444885,
      "rewards/margins": 8.047714233398438,
      "rewards/rejected": -8.249773025512695,
      "step": 5413
    },
    {
      "epoch": 2.1656,
      "grad_norm": 0.002789880847558379,
      "learning_rate": 2.7826666666666664e-07,
      "logits/chosen": -2.218578338623047,
      "logits/rejected": -1.5015761852264404,
      "logps/chosen": -130.6839599609375,
      "logps/rejected": -196.97689819335938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7970619201660156,
      "rewards/margins": 11.509967803955078,
      "rewards/rejected": -10.712905883789062,
      "step": 5414
    },
    {
      "epoch": 2.166,
      "grad_norm": 0.2507968246936798,
      "learning_rate": 2.7813333333333334e-07,
      "logits/chosen": -2.5484094619750977,
      "logits/rejected": -2.072031021118164,
      "logps/chosen": -139.11094665527344,
      "logps/rejected": -204.7643585205078,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5285515189170837,
      "rewards/margins": 10.940696716308594,
      "rewards/rejected": -10.412145614624023,
      "step": 5415
    },
    {
      "epoch": 2.1664,
      "grad_norm": 14.221441268920898,
      "learning_rate": 2.7800000000000003e-07,
      "logits/chosen": -1.9685336351394653,
      "logits/rejected": -1.4085612297058105,
      "logps/chosen": -265.4963684082031,
      "logps/rejected": -203.58139038085938,
      "loss": 0.0469,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.508741855621338,
      "rewards/margins": 7.363485813140869,
      "rewards/rejected": -10.872227668762207,
      "step": 5416
    },
    {
      "epoch": 2.1668,
      "grad_norm": 0.9440172910690308,
      "learning_rate": 2.778666666666666e-07,
      "logits/chosen": -2.7970361709594727,
      "logits/rejected": -2.4807703495025635,
      "logps/chosen": -89.392822265625,
      "logps/rejected": -160.25140380859375,
      "loss": 0.0049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5393962860107422,
      "rewards/margins": 6.614160060882568,
      "rewards/rejected": -7.153555870056152,
      "step": 5417
    },
    {
      "epoch": 2.1672,
      "grad_norm": 0.01693052425980568,
      "learning_rate": 2.777333333333333e-07,
      "logits/chosen": -2.389697551727295,
      "logits/rejected": -2.122248649597168,
      "logps/chosen": -96.0906982421875,
      "logps/rejected": -192.48733520507812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8723961114883423,
      "rewards/margins": 13.191210746765137,
      "rewards/rejected": -11.318815231323242,
      "step": 5418
    },
    {
      "epoch": 2.1676,
      "grad_norm": 0.0008299473556689918,
      "learning_rate": 2.776e-07,
      "logits/chosen": -2.3664937019348145,
      "logits/rejected": -2.017319440841675,
      "logps/chosen": -64.69197082519531,
      "logps/rejected": -222.25897216796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.059898853302002,
      "rewards/margins": 13.572211265563965,
      "rewards/rejected": -11.512311935424805,
      "step": 5419
    },
    {
      "epoch": 2.168,
      "grad_norm": 0.9783434867858887,
      "learning_rate": 2.7746666666666664e-07,
      "logits/chosen": -2.2565550804138184,
      "logits/rejected": -2.2916340827941895,
      "logps/chosen": -124.72232055664062,
      "logps/rejected": -101.06082916259766,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3578956127166748,
      "rewards/margins": 5.183051586151123,
      "rewards/rejected": -4.825156211853027,
      "step": 5420
    },
    {
      "epoch": 2.1684,
      "grad_norm": 0.02229207195341587,
      "learning_rate": 2.7733333333333333e-07,
      "logits/chosen": -2.494748592376709,
      "logits/rejected": -1.8882719278335571,
      "logps/chosen": -168.04110717773438,
      "logps/rejected": -148.21408081054688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.11127166450023651,
      "rewards/margins": 9.125303268432617,
      "rewards/rejected": -9.236574172973633,
      "step": 5421
    },
    {
      "epoch": 2.1688,
      "grad_norm": 0.016092538833618164,
      "learning_rate": 2.7719999999999997e-07,
      "logits/chosen": -2.6717605590820312,
      "logits/rejected": -2.244168281555176,
      "logps/chosen": -73.72450256347656,
      "logps/rejected": -173.86083984375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.543002128601074,
      "rewards/margins": 12.142389297485352,
      "rewards/rejected": -9.599387168884277,
      "step": 5422
    },
    {
      "epoch": 2.1692,
      "grad_norm": 0.001372922328300774,
      "learning_rate": 2.7706666666666666e-07,
      "logits/chosen": -2.4691381454467773,
      "logits/rejected": -1.8669058084487915,
      "logps/chosen": -55.30406951904297,
      "logps/rejected": -183.43133544921875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2709619998931885,
      "rewards/margins": 13.455314636230469,
      "rewards/rejected": -11.18435287475586,
      "step": 5423
    },
    {
      "epoch": 2.1696,
      "grad_norm": 0.0025321105495095253,
      "learning_rate": 2.769333333333333e-07,
      "logits/chosen": -2.197378158569336,
      "logits/rejected": -1.202625036239624,
      "logps/chosen": -94.24563598632812,
      "logps/rejected": -187.88690185546875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4642982482910156,
      "rewards/margins": 13.359371185302734,
      "rewards/rejected": -10.895072937011719,
      "step": 5424
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.05151950940489769,
      "learning_rate": 2.768e-07,
      "logits/chosen": -2.7456133365631104,
      "logits/rejected": -1.9524399042129517,
      "logps/chosen": -88.62229919433594,
      "logps/rejected": -157.93948364257812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6048340201377869,
      "rewards/margins": 9.555686950683594,
      "rewards/rejected": -8.950852394104004,
      "step": 5425
    },
    {
      "epoch": 2.1704,
      "grad_norm": 0.6254967451095581,
      "learning_rate": 2.766666666666667e-07,
      "logits/chosen": -2.738387107849121,
      "logits/rejected": -2.605356216430664,
      "logps/chosen": -104.57942962646484,
      "logps/rejected": -91.07937622070312,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5539187788963318,
      "rewards/margins": 5.244718551635742,
      "rewards/rejected": -5.798637390136719,
      "step": 5426
    },
    {
      "epoch": 2.1708,
      "grad_norm": 0.007196592632681131,
      "learning_rate": 2.765333333333333e-07,
      "logits/chosen": -2.718386173248291,
      "logits/rejected": -2.240326404571533,
      "logps/chosen": -86.51373291015625,
      "logps/rejected": -186.59634399414062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.026961088180542,
      "rewards/margins": 12.997182846069336,
      "rewards/rejected": -11.970221519470215,
      "step": 5427
    },
    {
      "epoch": 2.1712,
      "grad_norm": 0.05300411209464073,
      "learning_rate": 2.7639999999999996e-07,
      "logits/chosen": -2.770984649658203,
      "logits/rejected": -2.099172353744507,
      "logps/chosen": -91.9590835571289,
      "logps/rejected": -133.19761657714844,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6349672675132751,
      "rewards/margins": 8.866228103637695,
      "rewards/rejected": -8.231260299682617,
      "step": 5428
    },
    {
      "epoch": 2.1716,
      "grad_norm": 0.0007653668872080743,
      "learning_rate": 2.7626666666666665e-07,
      "logits/chosen": -2.5742104053497314,
      "logits/rejected": -2.2413368225097656,
      "logps/chosen": -144.05874633789062,
      "logps/rejected": -256.1094970703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.44545021653175354,
      "rewards/margins": 14.720041275024414,
      "rewards/rejected": -14.274591445922852,
      "step": 5429
    },
    {
      "epoch": 2.172,
      "grad_norm": 0.0021396921947598457,
      "learning_rate": 2.7613333333333334e-07,
      "logits/chosen": -2.8102803230285645,
      "logits/rejected": -2.047107696533203,
      "logps/chosen": -81.2772445678711,
      "logps/rejected": -161.39120483398438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6836811304092407,
      "rewards/margins": 11.899887084960938,
      "rewards/rejected": -11.216206550598145,
      "step": 5430
    },
    {
      "epoch": 2.1724,
      "grad_norm": 0.0005840493249706924,
      "learning_rate": 2.7600000000000004e-07,
      "logits/chosen": -2.2625622749328613,
      "logits/rejected": -1.6986252069473267,
      "logps/chosen": -172.6708984375,
      "logps/rejected": -216.39674377441406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0758514404296875,
      "rewards/margins": 13.81022834777832,
      "rewards/rejected": -13.886079788208008,
      "step": 5431
    },
    {
      "epoch": 2.1728,
      "grad_norm": 0.0005641448660753667,
      "learning_rate": 2.758666666666666e-07,
      "logits/chosen": -2.708709955215454,
      "logits/rejected": -2.0319619178771973,
      "logps/chosen": -126.6932601928711,
      "logps/rejected": -221.47312927246094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.470990777015686,
      "rewards/margins": 14.71448040008545,
      "rewards/rejected": -13.243489265441895,
      "step": 5432
    },
    {
      "epoch": 2.1732,
      "grad_norm": 1.3164846897125244,
      "learning_rate": 2.757333333333333e-07,
      "logits/chosen": -2.7024986743927,
      "logits/rejected": -2.502530097961426,
      "logps/chosen": -175.06021118164062,
      "logps/rejected": -189.87371826171875,
      "loss": 0.0057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -5.109924793243408,
      "rewards/margins": 7.253048419952393,
      "rewards/rejected": -12.3629732131958,
      "step": 5433
    },
    {
      "epoch": 2.1736,
      "grad_norm": 0.0029430531430989504,
      "learning_rate": 2.756e-07,
      "logits/chosen": -2.3277273178100586,
      "logits/rejected": -1.3991742134094238,
      "logps/chosen": -132.675048828125,
      "logps/rejected": -199.71617126464844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01293182373046875,
      "rewards/margins": 12.248757362365723,
      "rewards/rejected": -12.235825538635254,
      "step": 5434
    },
    {
      "epoch": 2.174,
      "grad_norm": 0.43289047479629517,
      "learning_rate": 2.754666666666667e-07,
      "logits/chosen": -2.7174224853515625,
      "logits/rejected": -2.9321353435516357,
      "logps/chosen": -92.11367797851562,
      "logps/rejected": -126.45986938476562,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7891889810562134,
      "rewards/margins": 7.079973220825195,
      "rewards/rejected": -8.869162559509277,
      "step": 5435
    },
    {
      "epoch": 2.1744,
      "grad_norm": 0.7204901576042175,
      "learning_rate": 2.753333333333333e-07,
      "logits/chosen": -2.907987356185913,
      "logits/rejected": -2.736748218536377,
      "logps/chosen": -130.21241760253906,
      "logps/rejected": -141.07052612304688,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4865963459014893,
      "rewards/margins": 8.375097274780273,
      "rewards/rejected": -9.8616943359375,
      "step": 5436
    },
    {
      "epoch": 2.1748,
      "grad_norm": 0.19539976119995117,
      "learning_rate": 2.752e-07,
      "logits/chosen": -2.6062264442443848,
      "logits/rejected": -1.8607637882232666,
      "logps/chosen": -81.23896789550781,
      "logps/rejected": -167.20919799804688,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2935833930969238,
      "rewards/margins": 10.010458946228027,
      "rewards/rejected": -11.304041862487793,
      "step": 5437
    },
    {
      "epoch": 2.1752,
      "grad_norm": 0.3478466868400574,
      "learning_rate": 2.7506666666666667e-07,
      "logits/chosen": -2.846656084060669,
      "logits/rejected": -2.0512304306030273,
      "logps/chosen": -91.68342590332031,
      "logps/rejected": -132.27391052246094,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23664723336696625,
      "rewards/margins": 8.215213775634766,
      "rewards/rejected": -7.9785661697387695,
      "step": 5438
    },
    {
      "epoch": 2.1756,
      "grad_norm": 1.4021371603012085,
      "learning_rate": 2.749333333333333e-07,
      "logits/chosen": -2.8757851123809814,
      "logits/rejected": -2.8631787300109863,
      "logps/chosen": -48.894203186035156,
      "logps/rejected": -113.56632995605469,
      "loss": 0.0108,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6092628836631775,
      "rewards/margins": 7.263453006744385,
      "rewards/rejected": -6.6541900634765625,
      "step": 5439
    },
    {
      "epoch": 2.176,
      "grad_norm": 0.002390091773122549,
      "learning_rate": 2.748e-07,
      "logits/chosen": -2.526421546936035,
      "logits/rejected": -2.0026257038116455,
      "logps/chosen": -91.1639404296875,
      "logps/rejected": -157.78829956054688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.730928897857666,
      "rewards/margins": 12.349637985229492,
      "rewards/rejected": -10.618709564208984,
      "step": 5440
    },
    {
      "epoch": 2.1764,
      "grad_norm": 4.757623672485352,
      "learning_rate": 2.7466666666666664e-07,
      "logits/chosen": -2.5544166564941406,
      "logits/rejected": -2.497011184692383,
      "logps/chosen": -108.14374542236328,
      "logps/rejected": -193.25680541992188,
      "loss": 0.0402,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1324734091758728,
      "rewards/margins": 9.032759666442871,
      "rewards/rejected": -8.900286674499512,
      "step": 5441
    },
    {
      "epoch": 2.1768,
      "grad_norm": 0.010900828056037426,
      "learning_rate": 2.7453333333333333e-07,
      "logits/chosen": -2.7513227462768555,
      "logits/rejected": -2.168613910675049,
      "logps/chosen": -109.47185516357422,
      "logps/rejected": -173.43629455566406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.09470558166503906,
      "rewards/margins": 11.679278373718262,
      "rewards/rejected": -11.7739839553833,
      "step": 5442
    },
    {
      "epoch": 2.1772,
      "grad_norm": 0.5151495337486267,
      "learning_rate": 2.7439999999999997e-07,
      "logits/chosen": -2.8300552368164062,
      "logits/rejected": -2.530850887298584,
      "logps/chosen": -115.77479553222656,
      "logps/rejected": -131.12307739257812,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09125328063964844,
      "rewards/margins": 7.1974029541015625,
      "rewards/rejected": -7.106149673461914,
      "step": 5443
    },
    {
      "epoch": 2.1776,
      "grad_norm": 6.427513289963827e-05,
      "learning_rate": 2.7426666666666666e-07,
      "logits/chosen": -2.4716484546661377,
      "logits/rejected": -1.5290297269821167,
      "logps/chosen": -85.28242492675781,
      "logps/rejected": -211.10198974609375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0800278186798096,
      "rewards/margins": 15.718323707580566,
      "rewards/rejected": -13.638296127319336,
      "step": 5444
    },
    {
      "epoch": 2.178,
      "grad_norm": 0.24403439462184906,
      "learning_rate": 2.7413333333333335e-07,
      "logits/chosen": -2.741673469543457,
      "logits/rejected": -2.037052631378174,
      "logps/chosen": -97.24349212646484,
      "logps/rejected": -144.29678344726562,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9005042314529419,
      "rewards/margins": 8.216682434082031,
      "rewards/rejected": -9.1171875,
      "step": 5445
    },
    {
      "epoch": 2.1784,
      "grad_norm": 0.0005581036675721407,
      "learning_rate": 2.74e-07,
      "logits/chosen": -2.6094918251037598,
      "logits/rejected": -1.717602252960205,
      "logps/chosen": -60.20587158203125,
      "logps/rejected": -213.83627319335938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7830063104629517,
      "rewards/margins": 14.362207412719727,
      "rewards/rejected": -12.579201698303223,
      "step": 5446
    },
    {
      "epoch": 2.1788,
      "grad_norm": 1.4101635217666626,
      "learning_rate": 2.7386666666666663e-07,
      "logits/chosen": -2.7960283756256104,
      "logits/rejected": -2.693229913711548,
      "logps/chosen": -67.41633605957031,
      "logps/rejected": -87.1209716796875,
      "loss": 0.0078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3546827435493469,
      "rewards/margins": 5.454833984375,
      "rewards/rejected": -5.100151062011719,
      "step": 5447
    },
    {
      "epoch": 2.1792,
      "grad_norm": 0.027574818581342697,
      "learning_rate": 2.737333333333333e-07,
      "logits/chosen": -2.9086830615997314,
      "logits/rejected": -2.56571888923645,
      "logps/chosen": -80.53282165527344,
      "logps/rejected": -162.6762237548828,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8048332333564758,
      "rewards/margins": 12.331148147583008,
      "rewards/rejected": -11.526315689086914,
      "step": 5448
    },
    {
      "epoch": 2.1796,
      "grad_norm": 0.04128032550215721,
      "learning_rate": 2.736e-07,
      "logits/chosen": -2.875516653060913,
      "logits/rejected": -2.44861102104187,
      "logps/chosen": -93.394775390625,
      "logps/rejected": -169.03790283203125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7524266242980957,
      "rewards/margins": 11.598249435424805,
      "rewards/rejected": -10.845823287963867,
      "step": 5449
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.00209323619492352,
      "learning_rate": 2.7346666666666665e-07,
      "logits/chosen": -2.5626418590545654,
      "logits/rejected": -2.1955325603485107,
      "logps/chosen": -167.73544311523438,
      "logps/rejected": -193.28952026367188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5666767358779907,
      "rewards/margins": 12.075891494750977,
      "rewards/rejected": -12.64256763458252,
      "step": 5450
    },
    {
      "epoch": 2.1804,
      "grad_norm": 0.00023260801390279084,
      "learning_rate": 2.733333333333333e-07,
      "logits/chosen": -2.6650609970092773,
      "logits/rejected": -1.767392635345459,
      "logps/chosen": -104.65928649902344,
      "logps/rejected": -214.19747924804688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4939892292022705,
      "rewards/margins": 14.979793548583984,
      "rewards/rejected": -14.48580551147461,
      "step": 5451
    },
    {
      "epoch": 2.1808,
      "grad_norm": 3.57828426361084,
      "learning_rate": 2.732e-07,
      "logits/chosen": -2.994641065597534,
      "logits/rejected": -2.972179889678955,
      "logps/chosen": -52.834476470947266,
      "logps/rejected": -91.67282104492188,
      "loss": 0.0262,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5525293350219727,
      "rewards/margins": 5.014955520629883,
      "rewards/rejected": -5.5674848556518555,
      "step": 5452
    },
    {
      "epoch": 2.1812,
      "grad_norm": 0.1311841756105423,
      "learning_rate": 2.730666666666667e-07,
      "logits/chosen": -2.7201175689697266,
      "logits/rejected": -2.6011338233947754,
      "logps/chosen": -55.768463134765625,
      "logps/rejected": -118.92179870605469,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1134967803955078,
      "rewards/margins": 9.61819839477539,
      "rewards/rejected": -8.504701614379883,
      "step": 5453
    },
    {
      "epoch": 2.1816,
      "grad_norm": 0.8881336450576782,
      "learning_rate": 2.729333333333333e-07,
      "logits/chosen": -2.851092576980591,
      "logits/rejected": -2.5950584411621094,
      "logps/chosen": -114.03169250488281,
      "logps/rejected": -150.6814727783203,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42760467529296875,
      "rewards/margins": 8.404932975769043,
      "rewards/rejected": -7.977328777313232,
      "step": 5454
    },
    {
      "epoch": 2.182,
      "grad_norm": 0.0007844324572943151,
      "learning_rate": 2.7279999999999995e-07,
      "logits/chosen": -2.3584251403808594,
      "logits/rejected": -2.0001955032348633,
      "logps/chosen": -132.70480346679688,
      "logps/rejected": -244.9185791015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.256768822669983,
      "rewards/margins": 12.977506637573242,
      "rewards/rejected": -11.72073745727539,
      "step": 5455
    },
    {
      "epoch": 2.1824,
      "grad_norm": 0.0009335673530586064,
      "learning_rate": 2.7266666666666665e-07,
      "logits/chosen": -2.7250633239746094,
      "logits/rejected": -2.200448513031006,
      "logps/chosen": -97.07415771484375,
      "logps/rejected": -191.49903869628906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8408454656600952,
      "rewards/margins": 12.693503379821777,
      "rewards/rejected": -13.53434944152832,
      "step": 5456
    },
    {
      "epoch": 2.1828,
      "grad_norm": 0.12279479950666428,
      "learning_rate": 2.7253333333333334e-07,
      "logits/chosen": -2.7526321411132812,
      "logits/rejected": -2.2765355110168457,
      "logps/chosen": -83.00384521484375,
      "logps/rejected": -136.91323852539062,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1373245269060135,
      "rewards/margins": 8.641106605529785,
      "rewards/rejected": -8.778430938720703,
      "step": 5457
    },
    {
      "epoch": 2.1832,
      "grad_norm": 0.021102357655763626,
      "learning_rate": 2.724e-07,
      "logits/chosen": -2.543386459350586,
      "logits/rejected": -1.8720290660858154,
      "logps/chosen": -121.00697326660156,
      "logps/rejected": -177.52487182617188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.31986773014068604,
      "rewards/margins": 10.825891494750977,
      "rewards/rejected": -11.145759582519531,
      "step": 5458
    },
    {
      "epoch": 2.1836,
      "grad_norm": 0.0007035979651845992,
      "learning_rate": 2.7226666666666667e-07,
      "logits/chosen": -2.5694124698638916,
      "logits/rejected": -2.5528812408447266,
      "logps/chosen": -64.3315658569336,
      "logps/rejected": -200.0189208984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4216462969779968,
      "rewards/margins": 13.313761711120605,
      "rewards/rejected": -12.892115592956543,
      "step": 5459
    },
    {
      "epoch": 2.184,
      "grad_norm": 1.6013894081115723,
      "learning_rate": 2.721333333333333e-07,
      "logits/chosen": -2.141890048980713,
      "logits/rejected": -1.6666252613067627,
      "logps/chosen": -205.4500732421875,
      "logps/rejected": -155.21493530273438,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6233298778533936,
      "rewards/margins": 6.762073993682861,
      "rewards/rejected": -8.385403633117676,
      "step": 5460
    },
    {
      "epoch": 2.1844,
      "grad_norm": 1.5757185220718384,
      "learning_rate": 2.72e-07,
      "logits/chosen": -2.8898911476135254,
      "logits/rejected": -2.4226725101470947,
      "logps/chosen": -89.69818115234375,
      "logps/rejected": -122.15036010742188,
      "loss": 0.0094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9466041326522827,
      "rewards/margins": 6.941776275634766,
      "rewards/rejected": -7.888380527496338,
      "step": 5461
    },
    {
      "epoch": 2.1848,
      "grad_norm": 0.0023114257492125034,
      "learning_rate": 2.7186666666666664e-07,
      "logits/chosen": -2.5310115814208984,
      "logits/rejected": -1.882399559020996,
      "logps/chosen": -114.47926330566406,
      "logps/rejected": -182.84329223632812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3679091930389404,
      "rewards/margins": 13.470775604248047,
      "rewards/rejected": -11.102865219116211,
      "step": 5462
    },
    {
      "epoch": 2.1852,
      "grad_norm": 0.014352821744978428,
      "learning_rate": 2.7173333333333333e-07,
      "logits/chosen": -2.1144258975982666,
      "logits/rejected": -1.2797675132751465,
      "logps/chosen": -173.03610229492188,
      "logps/rejected": -239.4674530029297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7266014218330383,
      "rewards/margins": 10.461557388305664,
      "rewards/rejected": -11.188159942626953,
      "step": 5463
    },
    {
      "epoch": 2.1856,
      "grad_norm": 0.17160536348819733,
      "learning_rate": 2.7159999999999997e-07,
      "logits/chosen": -3.0092244148254395,
      "logits/rejected": -2.376328229904175,
      "logps/chosen": -38.27973175048828,
      "logps/rejected": -191.9070281982422,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4594303369522095,
      "rewards/margins": 12.083815574645996,
      "rewards/rejected": -11.624384880065918,
      "step": 5464
    },
    {
      "epoch": 2.186,
      "grad_norm": 0.18125444650650024,
      "learning_rate": 2.7146666666666666e-07,
      "logits/chosen": -2.7864770889282227,
      "logits/rejected": -2.6300415992736816,
      "logps/chosen": -68.82604217529297,
      "logps/rejected": -164.03775024414062,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7859428524971008,
      "rewards/margins": 11.368681907653809,
      "rewards/rejected": -10.582738876342773,
      "step": 5465
    },
    {
      "epoch": 2.1864,
      "grad_norm": 1.1862947940826416,
      "learning_rate": 2.713333333333333e-07,
      "logits/chosen": -2.8439152240753174,
      "logits/rejected": -2.6236014366149902,
      "logps/chosen": -80.29381561279297,
      "logps/rejected": -88.50074768066406,
      "loss": 0.0065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5365139245986938,
      "rewards/margins": 6.142486095428467,
      "rewards/rejected": -5.6059722900390625,
      "step": 5466
    },
    {
      "epoch": 2.1868,
      "grad_norm": 0.05759422481060028,
      "learning_rate": 2.712e-07,
      "logits/chosen": -2.789109230041504,
      "logits/rejected": -2.592834234237671,
      "logps/chosen": -119.01168823242188,
      "logps/rejected": -153.5518798828125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6540668606758118,
      "rewards/margins": 9.00601577758789,
      "rewards/rejected": -9.66008186340332,
      "step": 5467
    },
    {
      "epoch": 2.1872,
      "grad_norm": 0.03631291538476944,
      "learning_rate": 2.710666666666667e-07,
      "logits/chosen": -2.8442800045013428,
      "logits/rejected": -2.5199851989746094,
      "logps/chosen": -105.52154541015625,
      "logps/rejected": -138.36697387695312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.153659462928772,
      "rewards/margins": 9.609676361083984,
      "rewards/rejected": -8.456016540527344,
      "step": 5468
    },
    {
      "epoch": 2.1875999999999998,
      "grad_norm": 0.0271983090788126,
      "learning_rate": 2.709333333333333e-07,
      "logits/chosen": -2.5190155506134033,
      "logits/rejected": -1.792529582977295,
      "logps/chosen": -144.44058227539062,
      "logps/rejected": -206.717529296875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3943687379360199,
      "rewards/margins": 12.272446632385254,
      "rewards/rejected": -11.87807846069336,
      "step": 5469
    },
    {
      "epoch": 2.188,
      "grad_norm": 0.0001847759122028947,
      "learning_rate": 2.7079999999999996e-07,
      "logits/chosen": -2.929600715637207,
      "logits/rejected": -2.3410520553588867,
      "logps/chosen": -75.18301391601562,
      "logps/rejected": -196.53143310546875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4817196130752563,
      "rewards/margins": 15.344501495361328,
      "rewards/rejected": -13.862781524658203,
      "step": 5470
    },
    {
      "epoch": 2.1884,
      "grad_norm": 0.3569503724575043,
      "learning_rate": 2.7066666666666666e-07,
      "logits/chosen": -2.896894931793213,
      "logits/rejected": -2.597761869430542,
      "logps/chosen": -123.11878204345703,
      "logps/rejected": -162.52041625976562,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.490556240081787,
      "rewards/margins": 8.893976211547852,
      "rewards/rejected": -11.384532928466797,
      "step": 5471
    },
    {
      "epoch": 2.1888,
      "grad_norm": 0.2275385707616806,
      "learning_rate": 2.7053333333333335e-07,
      "logits/chosen": -2.5106658935546875,
      "logits/rejected": -2.276244640350342,
      "logps/chosen": -116.94923400878906,
      "logps/rejected": -139.97650146484375,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.24497002363204956,
      "rewards/margins": 8.393442153930664,
      "rewards/rejected": -8.638412475585938,
      "step": 5472
    },
    {
      "epoch": 2.1892,
      "grad_norm": 0.0005520801059901714,
      "learning_rate": 2.704e-07,
      "logits/chosen": -2.8363137245178223,
      "logits/rejected": -2.437049388885498,
      "logps/chosen": -94.42658996582031,
      "logps/rejected": -299.02880859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3204677700996399,
      "rewards/margins": 14.430991172790527,
      "rewards/rejected": -14.110523223876953,
      "step": 5473
    },
    {
      "epoch": 2.1896,
      "grad_norm": 0.0003077166620641947,
      "learning_rate": 2.702666666666666e-07,
      "logits/chosen": -2.700613498687744,
      "logits/rejected": -1.8058940172195435,
      "logps/chosen": -91.15563201904297,
      "logps/rejected": -202.08901977539062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1887422800064087,
      "rewards/margins": 13.889802932739258,
      "rewards/rejected": -12.70106029510498,
      "step": 5474
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.00128939189016819,
      "learning_rate": 2.701333333333333e-07,
      "logits/chosen": -2.360175609588623,
      "logits/rejected": -1.4308717250823975,
      "logps/chosen": -114.86959838867188,
      "logps/rejected": -181.74081420898438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10202980041503906,
      "rewards/margins": 12.378562927246094,
      "rewards/rejected": -12.276533126831055,
      "step": 5475
    },
    {
      "epoch": 2.1904,
      "grad_norm": 0.05944983661174774,
      "learning_rate": 2.7e-07,
      "logits/chosen": -2.8250527381896973,
      "logits/rejected": -2.4577748775482178,
      "logps/chosen": -107.40570068359375,
      "logps/rejected": -170.26309204101562,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0381377935409546,
      "rewards/margins": 9.617830276489258,
      "rewards/rejected": -10.655967712402344,
      "step": 5476
    },
    {
      "epoch": 2.1908,
      "grad_norm": 0.030662184581160545,
      "learning_rate": 2.6986666666666665e-07,
      "logits/chosen": -2.47654390335083,
      "logits/rejected": -2.5487990379333496,
      "logps/chosen": -85.68351745605469,
      "logps/rejected": -152.0814208984375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.034590482711792,
      "rewards/margins": 9.063858032226562,
      "rewards/rejected": -8.029267311096191,
      "step": 5477
    },
    {
      "epoch": 2.1912,
      "grad_norm": 0.011052646674215794,
      "learning_rate": 2.697333333333333e-07,
      "logits/chosen": -2.152022361755371,
      "logits/rejected": -1.1786887645721436,
      "logps/chosen": -161.64492797851562,
      "logps/rejected": -249.6572723388672,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.998772382736206,
      "rewards/margins": 16.47858428955078,
      "rewards/rejected": -15.479812622070312,
      "step": 5478
    },
    {
      "epoch": 2.1916,
      "grad_norm": 0.029452573508024216,
      "learning_rate": 2.696e-07,
      "logits/chosen": -2.3737127780914307,
      "logits/rejected": -1.7920026779174805,
      "logps/chosen": -151.36419677734375,
      "logps/rejected": -156.50979614257812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.44445300102233887,
      "rewards/margins": 11.276063919067383,
      "rewards/rejected": -11.7205171585083,
      "step": 5479
    },
    {
      "epoch": 2.192,
      "grad_norm": 0.08071459829807281,
      "learning_rate": 2.6946666666666667e-07,
      "logits/chosen": -2.369485855102539,
      "logits/rejected": -2.1054837703704834,
      "logps/chosen": -173.20492553710938,
      "logps/rejected": -179.08291625976562,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.33125001192092896,
      "rewards/margins": 11.126335144042969,
      "rewards/rejected": -11.457585334777832,
      "step": 5480
    },
    {
      "epoch": 2.1924,
      "grad_norm": 2.1569371223449707,
      "learning_rate": 2.693333333333333e-07,
      "logits/chosen": -2.972295045852661,
      "logits/rejected": -2.511646270751953,
      "logps/chosen": -79.96800231933594,
      "logps/rejected": -178.2445068359375,
      "loss": 0.0144,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.22173500061035156,
      "rewards/margins": 11.593493461608887,
      "rewards/rejected": -11.815227508544922,
      "step": 5481
    },
    {
      "epoch": 2.1928,
      "grad_norm": 0.020495465025305748,
      "learning_rate": 2.692e-07,
      "logits/chosen": -2.5684213638305664,
      "logits/rejected": -2.3121376037597656,
      "logps/chosen": -95.34046936035156,
      "logps/rejected": -141.44342041015625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6921868324279785,
      "rewards/margins": 9.19215202331543,
      "rewards/rejected": -7.499965667724609,
      "step": 5482
    },
    {
      "epoch": 2.1932,
      "grad_norm": 0.0002788853016681969,
      "learning_rate": 2.6906666666666664e-07,
      "logits/chosen": -2.341704845428467,
      "logits/rejected": -1.8312392234802246,
      "logps/chosen": -121.49393463134766,
      "logps/rejected": -231.46353149414062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6204471588134766,
      "rewards/margins": 14.263248443603516,
      "rewards/rejected": -12.642801284790039,
      "step": 5483
    },
    {
      "epoch": 2.1936,
      "grad_norm": 0.42922377586364746,
      "learning_rate": 2.6893333333333333e-07,
      "logits/chosen": -2.582695722579956,
      "logits/rejected": -2.0677106380462646,
      "logps/chosen": -184.8578643798828,
      "logps/rejected": -213.42327880859375,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0264512300491333,
      "rewards/margins": 10.57414436340332,
      "rewards/rejected": -11.600595474243164,
      "step": 5484
    },
    {
      "epoch": 2.194,
      "grad_norm": 0.8048219084739685,
      "learning_rate": 2.6879999999999997e-07,
      "logits/chosen": -3.083474636077881,
      "logits/rejected": -2.309164047241211,
      "logps/chosen": -56.484596252441406,
      "logps/rejected": -138.76657104492188,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.047602891921997,
      "rewards/margins": 9.022024154663086,
      "rewards/rejected": -10.069626808166504,
      "step": 5485
    },
    {
      "epoch": 2.1944,
      "grad_norm": 0.000751101179048419,
      "learning_rate": 2.6866666666666666e-07,
      "logits/chosen": -2.428419589996338,
      "logits/rejected": -1.3591597080230713,
      "logps/chosen": -149.63070678710938,
      "logps/rejected": -197.3800506591797,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.295021891593933,
      "rewards/margins": 13.584390640258789,
      "rewards/rejected": -12.28936767578125,
      "step": 5486
    },
    {
      "epoch": 2.1948,
      "grad_norm": 0.015711765736341476,
      "learning_rate": 2.6853333333333336e-07,
      "logits/chosen": -2.3036160469055176,
      "logits/rejected": -1.4379308223724365,
      "logps/chosen": -115.28564453125,
      "logps/rejected": -178.40924072265625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5284595489501953,
      "rewards/margins": 11.879105567932129,
      "rewards/rejected": -11.350646018981934,
      "step": 5487
    },
    {
      "epoch": 2.1952,
      "grad_norm": 0.008541202172636986,
      "learning_rate": 2.684e-07,
      "logits/chosen": -2.400986671447754,
      "logits/rejected": -1.9446804523468018,
      "logps/chosen": -98.17867279052734,
      "logps/rejected": -188.60548400878906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8293253183364868,
      "rewards/margins": 10.695162773132324,
      "rewards/rejected": -11.52448844909668,
      "step": 5488
    },
    {
      "epoch": 2.1955999999999998,
      "grad_norm": 2.564640522003174,
      "learning_rate": 2.6826666666666663e-07,
      "logits/chosen": -2.2089385986328125,
      "logits/rejected": -1.522972583770752,
      "logps/chosen": -196.62327575683594,
      "logps/rejected": -203.65170288085938,
      "loss": 0.0106,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9605827331542969,
      "rewards/margins": 9.667095184326172,
      "rewards/rejected": -10.627677917480469,
      "step": 5489
    },
    {
      "epoch": 2.196,
      "grad_norm": 0.00020989887707401067,
      "learning_rate": 2.681333333333333e-07,
      "logits/chosen": -2.437701940536499,
      "logits/rejected": -1.6893335580825806,
      "logps/chosen": -81.89274597167969,
      "logps/rejected": -198.84568786621094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.957932710647583,
      "rewards/margins": 14.245229721069336,
      "rewards/rejected": -12.287298202514648,
      "step": 5490
    },
    {
      "epoch": 2.1964,
      "grad_norm": 0.13195466995239258,
      "learning_rate": 2.68e-07,
      "logits/chosen": -2.618586540222168,
      "logits/rejected": -2.1837174892425537,
      "logps/chosen": -99.58755493164062,
      "logps/rejected": -140.53323364257812,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5492057800292969,
      "rewards/margins": 10.484918594360352,
      "rewards/rejected": -8.935712814331055,
      "step": 5491
    },
    {
      "epoch": 2.1968,
      "grad_norm": 1.6625981330871582,
      "learning_rate": 2.678666666666666e-07,
      "logits/chosen": -2.6776015758514404,
      "logits/rejected": -2.116760015487671,
      "logps/chosen": -95.26449584960938,
      "logps/rejected": -109.09486389160156,
      "loss": 0.009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4230095148086548,
      "rewards/margins": 7.105000019073486,
      "rewards/rejected": -7.528009414672852,
      "step": 5492
    },
    {
      "epoch": 2.1972,
      "grad_norm": 0.00016012006381060928,
      "learning_rate": 2.677333333333333e-07,
      "logits/chosen": -2.489898681640625,
      "logits/rejected": -1.7488640546798706,
      "logps/chosen": -97.63941955566406,
      "logps/rejected": -309.2904052734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5812183022499084,
      "rewards/margins": 15.984306335449219,
      "rewards/rejected": -15.403087615966797,
      "step": 5493
    },
    {
      "epoch": 2.1976,
      "grad_norm": 0.02176920510828495,
      "learning_rate": 2.676e-07,
      "logits/chosen": -2.5894227027893066,
      "logits/rejected": -2.665130615234375,
      "logps/chosen": -102.69351959228516,
      "logps/rejected": -136.02191162109375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4023716151714325,
      "rewards/margins": 9.49473762512207,
      "rewards/rejected": -9.092366218566895,
      "step": 5494
    },
    {
      "epoch": 2.198,
      "grad_norm": 0.0020033754408359528,
      "learning_rate": 2.674666666666667e-07,
      "logits/chosen": -2.6554670333862305,
      "logits/rejected": -1.881137728691101,
      "logps/chosen": -91.82228088378906,
      "logps/rejected": -192.67807006835938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.715773105621338,
      "rewards/margins": 13.544364929199219,
      "rewards/rejected": -11.828592300415039,
      "step": 5495
    },
    {
      "epoch": 2.1984,
      "grad_norm": 0.05165844410657883,
      "learning_rate": 2.673333333333333e-07,
      "logits/chosen": -2.960705518722534,
      "logits/rejected": -2.6904072761535645,
      "logps/chosen": -44.97539520263672,
      "logps/rejected": -115.69699096679688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6985530853271484,
      "rewards/margins": 8.740987777709961,
      "rewards/rejected": -8.042434692382812,
      "step": 5496
    },
    {
      "epoch": 2.1988,
      "grad_norm": 0.08156000077724457,
      "learning_rate": 2.6719999999999996e-07,
      "logits/chosen": -2.510759115219116,
      "logits/rejected": -1.7291789054870605,
      "logps/chosen": -123.56187438964844,
      "logps/rejected": -175.59278869628906,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9923938512802124,
      "rewards/margins": 10.915017127990723,
      "rewards/rejected": -11.907410621643066,
      "step": 5497
    },
    {
      "epoch": 2.1992,
      "grad_norm": 1.417723615304567e-05,
      "learning_rate": 2.6706666666666665e-07,
      "logits/chosen": -2.9909143447875977,
      "logits/rejected": -2.2276034355163574,
      "logps/chosen": -48.91267395019531,
      "logps/rejected": -240.30520629882812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4573196172714233,
      "rewards/margins": 17.762928009033203,
      "rewards/rejected": -16.30561065673828,
      "step": 5498
    },
    {
      "epoch": 2.1996,
      "grad_norm": 0.0004457092145457864,
      "learning_rate": 2.6693333333333334e-07,
      "logits/chosen": -3.0064425468444824,
      "logits/rejected": -2.466337203979492,
      "logps/chosen": -69.17791748046875,
      "logps/rejected": -207.4521026611328,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40332335233688354,
      "rewards/margins": 13.912697792053223,
      "rewards/rejected": -13.509374618530273,
      "step": 5499
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.4283294379711151,
      "learning_rate": 2.668e-07,
      "logits/chosen": -2.928363084793091,
      "logits/rejected": -2.5488271713256836,
      "logps/chosen": -115.31031799316406,
      "logps/rejected": -105.75839233398438,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3607547879219055,
      "rewards/margins": 6.2734198570251465,
      "rewards/rejected": -6.634174823760986,
      "step": 5500
    },
    {
      "epoch": 2.2004,
      "grad_norm": 0.0011110357008874416,
      "learning_rate": 2.6666666666666667e-07,
      "logits/chosen": -2.7777299880981445,
      "logits/rejected": -2.084700107574463,
      "logps/chosen": -102.07455444335938,
      "logps/rejected": -252.9497528076172,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9165385961532593,
      "rewards/margins": 12.85787582397461,
      "rewards/rejected": -10.941336631774902,
      "step": 5501
    },
    {
      "epoch": 2.2008,
      "grad_norm": 0.06711030006408691,
      "learning_rate": 2.665333333333333e-07,
      "logits/chosen": -2.2983102798461914,
      "logits/rejected": -1.7311559915542603,
      "logps/chosen": -183.64004516601562,
      "logps/rejected": -193.5519256591797,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1016807556152344,
      "rewards/margins": 9.687888145446777,
      "rewards/rejected": -10.789568901062012,
      "step": 5502
    },
    {
      "epoch": 2.2012,
      "grad_norm": 0.004936042241752148,
      "learning_rate": 2.664e-07,
      "logits/chosen": -2.2509517669677734,
      "logits/rejected": -1.503226399421692,
      "logps/chosen": -109.77884674072266,
      "logps/rejected": -184.90057373046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.42186659574508667,
      "rewards/margins": 11.850715637207031,
      "rewards/rejected": -12.272581100463867,
      "step": 5503
    },
    {
      "epoch": 2.2016,
      "grad_norm": 0.751800000667572,
      "learning_rate": 2.6626666666666664e-07,
      "logits/chosen": -2.863098382949829,
      "logits/rejected": -2.6535773277282715,
      "logps/chosen": -67.78278350830078,
      "logps/rejected": -111.89430236816406,
      "loss": 0.0059,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5164863467216492,
      "rewards/margins": 8.436445236206055,
      "rewards/rejected": -7.919958114624023,
      "step": 5504
    },
    {
      "epoch": 2.202,
      "grad_norm": 0.2970151901245117,
      "learning_rate": 2.6613333333333333e-07,
      "logits/chosen": -2.6043179035186768,
      "logits/rejected": -2.3902435302734375,
      "logps/chosen": -111.763427734375,
      "logps/rejected": -101.08280944824219,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.44926148653030396,
      "rewards/margins": 7.0476603507995605,
      "rewards/rejected": -6.5983991622924805,
      "step": 5505
    },
    {
      "epoch": 2.2024,
      "grad_norm": 0.2502298355102539,
      "learning_rate": 2.66e-07,
      "logits/chosen": -2.9136033058166504,
      "logits/rejected": -2.8515737056732178,
      "logps/chosen": -77.63131713867188,
      "logps/rejected": -94.2555923461914,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7461429834365845,
      "rewards/margins": 6.400534152984619,
      "rewards/rejected": -5.654391288757324,
      "step": 5506
    },
    {
      "epoch": 2.2028,
      "grad_norm": 0.00836288183927536,
      "learning_rate": 2.658666666666666e-07,
      "logits/chosen": -2.6232540607452393,
      "logits/rejected": -2.0645792484283447,
      "logps/chosen": -221.4607696533203,
      "logps/rejected": -179.0977783203125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6754654049873352,
      "rewards/margins": 10.564580917358398,
      "rewards/rejected": -11.240046501159668,
      "step": 5507
    },
    {
      "epoch": 2.2032,
      "grad_norm": 5.147103309631348,
      "learning_rate": 2.657333333333333e-07,
      "logits/chosen": -2.5886497497558594,
      "logits/rejected": -2.60996675491333,
      "logps/chosen": -106.21096801757812,
      "logps/rejected": -171.73574829101562,
      "loss": 0.0242,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8858726024627686,
      "rewards/margins": 6.980917930603027,
      "rewards/rejected": -8.866790771484375,
      "step": 5508
    },
    {
      "epoch": 2.2036,
      "grad_norm": 0.027785280719399452,
      "learning_rate": 2.656e-07,
      "logits/chosen": -2.139983654022217,
      "logits/rejected": -1.5475571155548096,
      "logps/chosen": -102.54290008544922,
      "logps/rejected": -131.83395385742188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5541627407073975,
      "rewards/margins": 9.986160278320312,
      "rewards/rejected": -7.431997299194336,
      "step": 5509
    },
    {
      "epoch": 2.204,
      "grad_norm": 0.1462762951850891,
      "learning_rate": 2.654666666666667e-07,
      "logits/chosen": -2.5749762058258057,
      "logits/rejected": -2.4258008003234863,
      "logps/chosen": -67.2777328491211,
      "logps/rejected": -170.9286651611328,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5355408191680908,
      "rewards/margins": 8.991682052612305,
      "rewards/rejected": -8.456141471862793,
      "step": 5510
    },
    {
      "epoch": 2.2044,
      "grad_norm": 0.003769729984924197,
      "learning_rate": 2.653333333333333e-07,
      "logits/chosen": -2.872300148010254,
      "logits/rejected": -1.8705142736434937,
      "logps/chosen": -73.25448608398438,
      "logps/rejected": -177.44927978515625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.757402777671814,
      "rewards/margins": 11.619058609008789,
      "rewards/rejected": -10.861655235290527,
      "step": 5511
    },
    {
      "epoch": 2.2048,
      "grad_norm": 0.07067816704511642,
      "learning_rate": 2.6519999999999997e-07,
      "logits/chosen": -2.9645395278930664,
      "logits/rejected": -2.574276924133301,
      "logps/chosen": -59.262229919433594,
      "logps/rejected": -105.17817687988281,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3891487121582031,
      "rewards/margins": 7.8041090965271,
      "rewards/rejected": -7.4149603843688965,
      "step": 5512
    },
    {
      "epoch": 2.2052,
      "grad_norm": 0.5156912207603455,
      "learning_rate": 2.6506666666666666e-07,
      "logits/chosen": -2.7342545986175537,
      "logits/rejected": -2.338118076324463,
      "logps/chosen": -112.1902084350586,
      "logps/rejected": -250.02072143554688,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5539137125015259,
      "rewards/margins": 12.992659568786621,
      "rewards/rejected": -13.546573638916016,
      "step": 5513
    },
    {
      "epoch": 2.2056,
      "grad_norm": 0.18101297318935394,
      "learning_rate": 2.6493333333333335e-07,
      "logits/chosen": -2.6190848350524902,
      "logits/rejected": -2.0379698276519775,
      "logps/chosen": -113.56718444824219,
      "logps/rejected": -156.59811401367188,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7997669577598572,
      "rewards/margins": 9.055845260620117,
      "rewards/rejected": -9.855611801147461,
      "step": 5514
    },
    {
      "epoch": 2.206,
      "grad_norm": 0.014077550731599331,
      "learning_rate": 2.648e-07,
      "logits/chosen": -3.099025011062622,
      "logits/rejected": -2.485017776489258,
      "logps/chosen": -52.68633270263672,
      "logps/rejected": -159.74832153320312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6005765795707703,
      "rewards/margins": 11.05023193359375,
      "rewards/rejected": -11.650808334350586,
      "step": 5515
    },
    {
      "epoch": 2.2064,
      "grad_norm": 0.03190505504608154,
      "learning_rate": 2.6466666666666663e-07,
      "logits/chosen": -2.6068215370178223,
      "logits/rejected": -2.270129680633545,
      "logps/chosen": -127.00969696044922,
      "logps/rejected": -155.51901245117188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1047554016113281,
      "rewards/margins": 8.810667037963867,
      "rewards/rejected": -9.915422439575195,
      "step": 5516
    },
    {
      "epoch": 2.2068,
      "grad_norm": 0.10026969015598297,
      "learning_rate": 2.645333333333333e-07,
      "logits/chosen": -2.6673336029052734,
      "logits/rejected": -2.5896530151367188,
      "logps/chosen": -70.82722473144531,
      "logps/rejected": -143.76116943359375,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9913492202758789,
      "rewards/margins": 11.144266128540039,
      "rewards/rejected": -10.152915954589844,
      "step": 5517
    },
    {
      "epoch": 2.2072,
      "grad_norm": 0.12052814662456512,
      "learning_rate": 2.644e-07,
      "logits/chosen": -2.469045400619507,
      "logits/rejected": -2.0868096351623535,
      "logps/chosen": -211.30783081054688,
      "logps/rejected": -148.0947723388672,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.237764835357666,
      "rewards/margins": 7.748906135559082,
      "rewards/rejected": -9.986671447753906,
      "step": 5518
    },
    {
      "epoch": 2.2076000000000002,
      "grad_norm": 5.983723163604736,
      "learning_rate": 2.6426666666666665e-07,
      "logits/chosen": -2.7452621459960938,
      "logits/rejected": -2.7461514472961426,
      "logps/chosen": -69.52127075195312,
      "logps/rejected": -89.31346893310547,
      "loss": 0.0523,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7742996215820312,
      "rewards/margins": 3.8830366134643555,
      "rewards/rejected": -5.657336235046387,
      "step": 5519
    },
    {
      "epoch": 2.208,
      "grad_norm": 0.4325682520866394,
      "learning_rate": 2.6413333333333334e-07,
      "logits/chosen": -2.2904226779937744,
      "logits/rejected": -1.811119794845581,
      "logps/chosen": -164.109619140625,
      "logps/rejected": -220.30076599121094,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5983299612998962,
      "rewards/margins": 8.984319686889648,
      "rewards/rejected": -9.582649230957031,
      "step": 5520
    },
    {
      "epoch": 2.2084,
      "grad_norm": 0.7063376307487488,
      "learning_rate": 2.64e-07,
      "logits/chosen": -2.6513195037841797,
      "logits/rejected": -2.378337860107422,
      "logps/chosen": -58.23186492919922,
      "logps/rejected": -213.2009735107422,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.44979095458984375,
      "rewards/margins": 12.514022827148438,
      "rewards/rejected": -12.963813781738281,
      "step": 5521
    },
    {
      "epoch": 2.2088,
      "grad_norm": 0.009616670198738575,
      "learning_rate": 2.638666666666667e-07,
      "logits/chosen": -2.823046922683716,
      "logits/rejected": -2.6295602321624756,
      "logps/chosen": -121.03244018554688,
      "logps/rejected": -204.09120178222656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7050457000732422,
      "rewards/margins": 14.611455917358398,
      "rewards/rejected": -13.906410217285156,
      "step": 5522
    },
    {
      "epoch": 2.2092,
      "grad_norm": 0.001291535678319633,
      "learning_rate": 2.637333333333333e-07,
      "logits/chosen": -2.4230165481567383,
      "logits/rejected": -1.6709421873092651,
      "logps/chosen": -197.04078674316406,
      "logps/rejected": -239.64682006835938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.5606446266174316,
      "rewards/margins": 13.041221618652344,
      "rewards/rejected": -15.601866722106934,
      "step": 5523
    },
    {
      "epoch": 2.2096,
      "grad_norm": 0.03225460276007652,
      "learning_rate": 2.636e-07,
      "logits/chosen": -2.735419273376465,
      "logits/rejected": -2.1274170875549316,
      "logps/chosen": -69.52700805664062,
      "logps/rejected": -117.04293823242188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0997467041015625,
      "rewards/margins": 8.749198913574219,
      "rewards/rejected": -8.649452209472656,
      "step": 5524
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.0016793066170066595,
      "learning_rate": 2.634666666666667e-07,
      "logits/chosen": -2.934814214706421,
      "logits/rejected": -2.5011987686157227,
      "logps/chosen": -58.21174621582031,
      "logps/rejected": -153.55870056152344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3674072325229645,
      "rewards/margins": 11.989445686340332,
      "rewards/rejected": -11.622037887573242,
      "step": 5525
    },
    {
      "epoch": 2.2104,
      "grad_norm": 0.0005047306185588241,
      "learning_rate": 2.633333333333333e-07,
      "logits/chosen": -2.5968174934387207,
      "logits/rejected": -1.9691241979599,
      "logps/chosen": -110.37549591064453,
      "logps/rejected": -180.587890625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2288379669189453,
      "rewards/margins": 13.592559814453125,
      "rewards/rejected": -12.36372184753418,
      "step": 5526
    },
    {
      "epoch": 2.2108,
      "grad_norm": 0.00898014660924673,
      "learning_rate": 2.632e-07,
      "logits/chosen": -3.0020675659179688,
      "logits/rejected": -2.436102867126465,
      "logps/chosen": -79.91096496582031,
      "logps/rejected": -148.36582946777344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39216041564941406,
      "rewards/margins": 10.122251510620117,
      "rewards/rejected": -9.730091094970703,
      "step": 5527
    },
    {
      "epoch": 2.2112,
      "grad_norm": 0.0003605952369980514,
      "learning_rate": 2.6306666666666667e-07,
      "logits/chosen": -2.6622776985168457,
      "logits/rejected": -2.08132004737854,
      "logps/chosen": -132.39035034179688,
      "logps/rejected": -248.6626739501953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8977871537208557,
      "rewards/margins": 13.896682739257812,
      "rewards/rejected": -14.794469833374023,
      "step": 5528
    },
    {
      "epoch": 2.2116,
      "grad_norm": 3.6423325538635254,
      "learning_rate": 2.6293333333333336e-07,
      "logits/chosen": -2.439587116241455,
      "logits/rejected": -2.336446762084961,
      "logps/chosen": -126.28515625,
      "logps/rejected": -161.99566650390625,
      "loss": 0.0145,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.3705644607543945,
      "rewards/margins": 8.10099983215332,
      "rewards/rejected": -12.471563339233398,
      "step": 5529
    },
    {
      "epoch": 2.212,
      "grad_norm": 0.08521198481321335,
      "learning_rate": 2.6279999999999994e-07,
      "logits/chosen": -2.694035768508911,
      "logits/rejected": -2.449115753173828,
      "logps/chosen": -79.35774230957031,
      "logps/rejected": -156.10348510742188,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5989063382148743,
      "rewards/margins": 10.032781600952148,
      "rewards/rejected": -10.631688117980957,
      "step": 5530
    },
    {
      "epoch": 2.2124,
      "grad_norm": 0.0002586136688478291,
      "learning_rate": 2.6266666666666664e-07,
      "logits/chosen": -2.5204763412475586,
      "logits/rejected": -1.7253204584121704,
      "logps/chosen": -76.038818359375,
      "logps/rejected": -198.17041015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25867295265197754,
      "rewards/margins": 14.490177154541016,
      "rewards/rejected": -14.2315034866333,
      "step": 5531
    },
    {
      "epoch": 2.2128,
      "grad_norm": 0.07382962852716446,
      "learning_rate": 2.6253333333333333e-07,
      "logits/chosen": -2.6038694381713867,
      "logits/rejected": -2.2123775482177734,
      "logps/chosen": -83.74671936035156,
      "logps/rejected": -119.98046112060547,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16970595717430115,
      "rewards/margins": 7.725848197937012,
      "rewards/rejected": -7.5561418533325195,
      "step": 5532
    },
    {
      "epoch": 2.2132,
      "grad_norm": 0.024759428575634956,
      "learning_rate": 2.624e-07,
      "logits/chosen": -2.8673291206359863,
      "logits/rejected": -2.475116729736328,
      "logps/chosen": -88.30579376220703,
      "logps/rejected": -214.38516235351562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8082423210144043,
      "rewards/margins": 11.642539978027344,
      "rewards/rejected": -13.450782775878906,
      "step": 5533
    },
    {
      "epoch": 2.2136,
      "grad_norm": 0.3005799949169159,
      "learning_rate": 2.6226666666666666e-07,
      "logits/chosen": -2.7891945838928223,
      "logits/rejected": -2.3461802005767822,
      "logps/chosen": -79.24610900878906,
      "logps/rejected": -133.05496215820312,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2319774627685547,
      "rewards/margins": 8.404478073120117,
      "rewards/rejected": -8.636454582214355,
      "step": 5534
    },
    {
      "epoch": 2.214,
      "grad_norm": 0.01723826304078102,
      "learning_rate": 2.621333333333333e-07,
      "logits/chosen": -2.4832205772399902,
      "logits/rejected": -2.378847599029541,
      "logps/chosen": -105.25432586669922,
      "logps/rejected": -149.30807495117188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.421194076538086,
      "rewards/margins": 9.720317840576172,
      "rewards/rejected": -8.299123764038086,
      "step": 5535
    },
    {
      "epoch": 2.2144,
      "grad_norm": 0.0043124970979988575,
      "learning_rate": 2.62e-07,
      "logits/chosen": -2.2505831718444824,
      "logits/rejected": -1.53141188621521,
      "logps/chosen": -96.7379150390625,
      "logps/rejected": -191.99139404296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1418064832687378,
      "rewards/margins": 13.495828628540039,
      "rewards/rejected": -12.354022979736328,
      "step": 5536
    },
    {
      "epoch": 2.2148,
      "grad_norm": 3.103309392929077,
      "learning_rate": 2.618666666666667e-07,
      "logits/chosen": -2.742560386657715,
      "logits/rejected": -2.1236090660095215,
      "logps/chosen": -92.33246612548828,
      "logps/rejected": -149.23623657226562,
      "loss": 0.0191,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.8726930618286133,
      "rewards/margins": 7.065495491027832,
      "rewards/rejected": -9.938188552856445,
      "step": 5537
    },
    {
      "epoch": 2.2152,
      "grad_norm": 0.04226534068584442,
      "learning_rate": 2.617333333333333e-07,
      "logits/chosen": -2.9876797199249268,
      "logits/rejected": -2.7124977111816406,
      "logps/chosen": -56.996612548828125,
      "logps/rejected": -141.4719696044922,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7683208584785461,
      "rewards/margins": 9.907153129577637,
      "rewards/rejected": -9.138832092285156,
      "step": 5538
    },
    {
      "epoch": 2.2156000000000002,
      "grad_norm": 0.06151080131530762,
      "learning_rate": 2.616e-07,
      "logits/chosen": -2.7669119834899902,
      "logits/rejected": -2.3851218223571777,
      "logps/chosen": -74.58386993408203,
      "logps/rejected": -153.79168701171875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3288007974624634,
      "rewards/margins": 12.286569595336914,
      "rewards/rejected": -10.957768440246582,
      "step": 5539
    },
    {
      "epoch": 2.216,
      "grad_norm": 0.517230749130249,
      "learning_rate": 2.6146666666666665e-07,
      "logits/chosen": -2.9270541667938232,
      "logits/rejected": -2.625497817993164,
      "logps/chosen": -92.17781066894531,
      "logps/rejected": -105.90241241455078,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5363392233848572,
      "rewards/margins": 5.525517463684082,
      "rewards/rejected": -6.061856269836426,
      "step": 5540
    },
    {
      "epoch": 2.2164,
      "grad_norm": 0.006583930924534798,
      "learning_rate": 2.613333333333333e-07,
      "logits/chosen": -2.500925064086914,
      "logits/rejected": -2.171333074569702,
      "logps/chosen": -121.91230773925781,
      "logps/rejected": -183.05421447753906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.200994610786438,
      "rewards/margins": 10.95107650756836,
      "rewards/rejected": -12.152070999145508,
      "step": 5541
    },
    {
      "epoch": 2.2168,
      "grad_norm": 0.0038389209657907486,
      "learning_rate": 2.612e-07,
      "logits/chosen": -2.4527924060821533,
      "logits/rejected": -2.160938262939453,
      "logps/chosen": -69.21678161621094,
      "logps/rejected": -179.05911254882812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8896607160568237,
      "rewards/margins": 13.603065490722656,
      "rewards/rejected": -12.713404655456543,
      "step": 5542
    },
    {
      "epoch": 2.2172,
      "grad_norm": 0.07063991576433182,
      "learning_rate": 2.610666666666667e-07,
      "logits/chosen": -2.500913619995117,
      "logits/rejected": -1.761339545249939,
      "logps/chosen": -120.56891632080078,
      "logps/rejected": -159.55093383789062,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.31706732511520386,
      "rewards/margins": 8.595710754394531,
      "rewards/rejected": -8.912778854370117,
      "step": 5543
    },
    {
      "epoch": 2.2176,
      "grad_norm": 0.01376896072179079,
      "learning_rate": 2.609333333333333e-07,
      "logits/chosen": -3.0089633464813232,
      "logits/rejected": -2.5361478328704834,
      "logps/chosen": -41.73635482788086,
      "logps/rejected": -158.8121337890625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7767602205276489,
      "rewards/margins": 10.567770004272461,
      "rewards/rejected": -9.791009902954102,
      "step": 5544
    },
    {
      "epoch": 2.218,
      "grad_norm": 0.30627328157424927,
      "learning_rate": 2.6079999999999995e-07,
      "logits/chosen": -2.841083288192749,
      "logits/rejected": -2.747154474258423,
      "logps/chosen": -85.24171447753906,
      "logps/rejected": -132.32025146484375,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2427181601524353,
      "rewards/margins": 8.636749267578125,
      "rewards/rejected": -8.394030570983887,
      "step": 5545
    },
    {
      "epoch": 2.2184,
      "grad_norm": 1.3363457918167114,
      "learning_rate": 2.6066666666666664e-07,
      "logits/chosen": -2.8696718215942383,
      "logits/rejected": -2.5025768280029297,
      "logps/chosen": -70.8327407836914,
      "logps/rejected": -134.45272827148438,
      "loss": 0.01,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3063236474990845,
      "rewards/margins": 6.661909103393555,
      "rewards/rejected": -7.968233108520508,
      "step": 5546
    },
    {
      "epoch": 2.2188,
      "grad_norm": 1.3248982429504395,
      "learning_rate": 2.6053333333333334e-07,
      "logits/chosen": -2.871540069580078,
      "logits/rejected": -3.013291835784912,
      "logps/chosen": -54.95207977294922,
      "logps/rejected": -91.5822525024414,
      "loss": 0.0103,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5471529364585876,
      "rewards/margins": 6.420355796813965,
      "rewards/rejected": -5.873202800750732,
      "step": 5547
    },
    {
      "epoch": 2.2192,
      "grad_norm": 0.0009227076079696417,
      "learning_rate": 2.6040000000000003e-07,
      "logits/chosen": -2.3857483863830566,
      "logits/rejected": -1.5714638233184814,
      "logps/chosen": -109.12837219238281,
      "logps/rejected": -236.271484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5986263751983643,
      "rewards/margins": 12.852888107299805,
      "rewards/rejected": -11.25426197052002,
      "step": 5548
    },
    {
      "epoch": 2.2196,
      "grad_norm": 0.03355514630675316,
      "learning_rate": 2.602666666666666e-07,
      "logits/chosen": -2.569054126739502,
      "logits/rejected": -2.426727056503296,
      "logps/chosen": -172.37948608398438,
      "logps/rejected": -192.18051147460938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4546371698379517,
      "rewards/margins": 11.446796417236328,
      "rewards/rejected": -12.901433944702148,
      "step": 5549
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.0005907093873247504,
      "learning_rate": 2.601333333333333e-07,
      "logits/chosen": -2.6338210105895996,
      "logits/rejected": -1.9361145496368408,
      "logps/chosen": -89.7922134399414,
      "logps/rejected": -209.27886962890625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7912250757217407,
      "rewards/margins": 13.908485412597656,
      "rewards/rejected": -13.117259979248047,
      "step": 5550
    },
    {
      "epoch": 2.2204,
      "grad_norm": 0.038003671914339066,
      "learning_rate": 2.6e-07,
      "logits/chosen": -2.518872022628784,
      "logits/rejected": -2.1436820030212402,
      "logps/chosen": -125.01651763916016,
      "logps/rejected": -168.1771240234375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8846675753593445,
      "rewards/margins": 11.337408065795898,
      "rewards/rejected": -10.452740669250488,
      "step": 5551
    },
    {
      "epoch": 2.2208,
      "grad_norm": 0.018916776403784752,
      "learning_rate": 2.598666666666667e-07,
      "logits/chosen": -2.685591220855713,
      "logits/rejected": -2.101609468460083,
      "logps/chosen": -97.27120971679688,
      "logps/rejected": -176.0259246826172,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.662955105304718,
      "rewards/margins": 10.462432861328125,
      "rewards/rejected": -11.125387191772461,
      "step": 5552
    },
    {
      "epoch": 2.2212,
      "grad_norm": 0.01671324484050274,
      "learning_rate": 2.5973333333333333e-07,
      "logits/chosen": -2.7651686668395996,
      "logits/rejected": -2.3266658782958984,
      "logps/chosen": -51.62287902832031,
      "logps/rejected": -132.39071655273438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3926281929016113,
      "rewards/margins": 9.393611907958984,
      "rewards/rejected": -8.000984191894531,
      "step": 5553
    },
    {
      "epoch": 2.2216,
      "grad_norm": 0.1002507284283638,
      "learning_rate": 2.5959999999999997e-07,
      "logits/chosen": -2.8012378215789795,
      "logits/rejected": -2.527229070663452,
      "logps/chosen": -62.908607482910156,
      "logps/rejected": -110.27027893066406,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6083520650863647,
      "rewards/margins": 8.166390419006348,
      "rewards/rejected": -7.558037757873535,
      "step": 5554
    },
    {
      "epoch": 2.222,
      "grad_norm": 0.10474711656570435,
      "learning_rate": 2.5946666666666666e-07,
      "logits/chosen": -2.893617630004883,
      "logits/rejected": -2.449840784072876,
      "logps/chosen": -75.93708038330078,
      "logps/rejected": -120.34684753417969,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10648059844970703,
      "rewards/margins": 8.174076080322266,
      "rewards/rejected": -8.280557632446289,
      "step": 5555
    },
    {
      "epoch": 2.2224,
      "grad_norm": 0.0070239463821053505,
      "learning_rate": 2.5933333333333335e-07,
      "logits/chosen": -2.5015530586242676,
      "logits/rejected": -2.2809524536132812,
      "logps/chosen": -152.70004272460938,
      "logps/rejected": -211.74667358398438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8627570867538452,
      "rewards/margins": 12.26845645904541,
      "rewards/rejected": -14.131214141845703,
      "step": 5556
    },
    {
      "epoch": 2.2228,
      "grad_norm": 0.0021490168292075396,
      "learning_rate": 2.592e-07,
      "logits/chosen": -2.433030128479004,
      "logits/rejected": -1.79874587059021,
      "logps/chosen": -169.30694580078125,
      "logps/rejected": -302.34893798828125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.765860080718994,
      "rewards/margins": 12.696610450744629,
      "rewards/rejected": -15.462471008300781,
      "step": 5557
    },
    {
      "epoch": 2.2232,
      "grad_norm": 0.0003647154080681503,
      "learning_rate": 2.5906666666666663e-07,
      "logits/chosen": -2.607309341430664,
      "logits/rejected": -1.9594206809997559,
      "logps/chosen": -82.8512954711914,
      "logps/rejected": -215.23736572265625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.327501505613327,
      "rewards/margins": 13.917125701904297,
      "rewards/rejected": -13.589624404907227,
      "step": 5558
    },
    {
      "epoch": 2.2236,
      "grad_norm": 0.003575944807380438,
      "learning_rate": 2.589333333333333e-07,
      "logits/chosen": -2.6016592979431152,
      "logits/rejected": -2.0108284950256348,
      "logps/chosen": -105.78242492675781,
      "logps/rejected": -169.64743041992188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5240345001220703,
      "rewards/margins": 11.201173782348633,
      "rewards/rejected": -10.677139282226562,
      "step": 5559
    },
    {
      "epoch": 2.224,
      "grad_norm": 0.0007939910283312201,
      "learning_rate": 2.5879999999999996e-07,
      "logits/chosen": -2.407881259918213,
      "logits/rejected": -1.7672817707061768,
      "logps/chosen": -103.84337615966797,
      "logps/rejected": -183.46173095703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3145530223846436,
      "rewards/margins": 14.595973014831543,
      "rewards/rejected": -12.28141975402832,
      "step": 5560
    },
    {
      "epoch": 2.2244,
      "grad_norm": 4.786363206221722e-05,
      "learning_rate": 2.5866666666666665e-07,
      "logits/chosen": -2.7435808181762695,
      "logits/rejected": -2.253715991973877,
      "logps/chosen": -62.90747833251953,
      "logps/rejected": -229.29473876953125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.638633370399475,
      "rewards/margins": 16.616275787353516,
      "rewards/rejected": -14.977642059326172,
      "step": 5561
    },
    {
      "epoch": 2.2248,
      "grad_norm": 0.00011488353629829362,
      "learning_rate": 2.5853333333333335e-07,
      "logits/chosen": -2.2930028438568115,
      "logits/rejected": -1.5087987184524536,
      "logps/chosen": -165.73147583007812,
      "logps/rejected": -227.39083862304688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.454925537109375,
      "rewards/margins": 16.352563858032227,
      "rewards/rejected": -14.897638320922852,
      "step": 5562
    },
    {
      "epoch": 2.2252,
      "grad_norm": 0.0015899762511253357,
      "learning_rate": 2.584e-07,
      "logits/chosen": -2.9379019737243652,
      "logits/rejected": -2.6937363147735596,
      "logps/chosen": -33.47206115722656,
      "logps/rejected": -153.99681091308594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2279129028320312,
      "rewards/margins": 12.180821418762207,
      "rewards/rejected": -9.952908515930176,
      "step": 5563
    },
    {
      "epoch": 2.2256,
      "grad_norm": 0.0024623556528240442,
      "learning_rate": 2.582666666666666e-07,
      "logits/chosen": -2.8488688468933105,
      "logits/rejected": -2.287631034851074,
      "logps/chosen": -40.18779754638672,
      "logps/rejected": -161.29971313476562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.37008941173553467,
      "rewards/margins": 11.618326187133789,
      "rewards/rejected": -11.248237609863281,
      "step": 5564
    },
    {
      "epoch": 2.226,
      "grad_norm": 0.0023737638257443905,
      "learning_rate": 2.581333333333333e-07,
      "logits/chosen": -2.5169715881347656,
      "logits/rejected": -1.9653925895690918,
      "logps/chosen": -96.4073486328125,
      "logps/rejected": -181.73483276367188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7435985207557678,
      "rewards/margins": 11.866561889648438,
      "rewards/rejected": -11.122962951660156,
      "step": 5565
    },
    {
      "epoch": 2.2264,
      "grad_norm": 0.013880571350455284,
      "learning_rate": 2.58e-07,
      "logits/chosen": -2.536330223083496,
      "logits/rejected": -2.1860525608062744,
      "logps/chosen": -98.72581481933594,
      "logps/rejected": -128.1955108642578,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0211613178253174,
      "rewards/margins": 10.184873580932617,
      "rewards/rejected": -8.163711547851562,
      "step": 5566
    },
    {
      "epoch": 2.2268,
      "grad_norm": 0.0028760412242263556,
      "learning_rate": 2.578666666666667e-07,
      "logits/chosen": -2.648860454559326,
      "logits/rejected": -2.155332326889038,
      "logps/chosen": -56.544166564941406,
      "logps/rejected": -187.9352264404297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2584816217422485,
      "rewards/margins": 12.011369705200195,
      "rewards/rejected": -10.752887725830078,
      "step": 5567
    },
    {
      "epoch": 2.2272,
      "grad_norm": 20.992076873779297,
      "learning_rate": 2.577333333333333e-07,
      "logits/chosen": -2.723989486694336,
      "logits/rejected": -2.596994400024414,
      "logps/chosen": -86.86467742919922,
      "logps/rejected": -92.30552673339844,
      "loss": 0.0929,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3216301202774048,
      "rewards/margins": 6.022232532501221,
      "rewards/rejected": -6.343862533569336,
      "step": 5568
    },
    {
      "epoch": 2.2276,
      "grad_norm": 0.04892981797456741,
      "learning_rate": 2.576e-07,
      "logits/chosen": -2.539050579071045,
      "logits/rejected": -1.8493716716766357,
      "logps/chosen": -143.83297729492188,
      "logps/rejected": -143.5311737060547,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5476185083389282,
      "rewards/margins": 9.371111869812012,
      "rewards/rejected": -7.823493003845215,
      "step": 5569
    },
    {
      "epoch": 2.228,
      "grad_norm": 0.0011071576736867428,
      "learning_rate": 2.5746666666666667e-07,
      "logits/chosen": -2.2120132446289062,
      "logits/rejected": -1.6123600006103516,
      "logps/chosen": -134.25518798828125,
      "logps/rejected": -226.5487823486328,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5265156030654907,
      "rewards/margins": 15.630794525146484,
      "rewards/rejected": -14.104278564453125,
      "step": 5570
    },
    {
      "epoch": 2.2284,
      "grad_norm": 0.045729901641607285,
      "learning_rate": 2.5733333333333336e-07,
      "logits/chosen": -2.8273253440856934,
      "logits/rejected": -2.310385227203369,
      "logps/chosen": -82.99008178710938,
      "logps/rejected": -131.95948791503906,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.304692029953003,
      "rewards/margins": 11.047739028930664,
      "rewards/rejected": -9.743046760559082,
      "step": 5571
    },
    {
      "epoch": 2.2288,
      "grad_norm": 0.2856679856777191,
      "learning_rate": 2.5719999999999995e-07,
      "logits/chosen": -2.415849208831787,
      "logits/rejected": -2.1067581176757812,
      "logps/chosen": -97.23727416992188,
      "logps/rejected": -167.43482971191406,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20818711817264557,
      "rewards/margins": 8.99057388305664,
      "rewards/rejected": -8.782386779785156,
      "step": 5572
    },
    {
      "epoch": 2.2292,
      "grad_norm": 0.049287207424640656,
      "learning_rate": 2.5706666666666664e-07,
      "logits/chosen": -2.4912238121032715,
      "logits/rejected": -2.0380191802978516,
      "logps/chosen": -78.52749633789062,
      "logps/rejected": -129.27035522460938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7291970252990723,
      "rewards/margins": 9.211228370666504,
      "rewards/rejected": -7.482030868530273,
      "step": 5573
    },
    {
      "epoch": 2.2296,
      "grad_norm": 2.8788630962371826,
      "learning_rate": 2.5693333333333333e-07,
      "logits/chosen": -2.9085726737976074,
      "logits/rejected": -2.60752010345459,
      "logps/chosen": -68.34233856201172,
      "logps/rejected": -109.06692504882812,
      "loss": 0.0181,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3219802975654602,
      "rewards/margins": 6.184994697570801,
      "rewards/rejected": -6.506975173950195,
      "step": 5574
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.0854383260011673,
      "learning_rate": 2.5679999999999997e-07,
      "logits/chosen": -2.5850510597229004,
      "logits/rejected": -2.0289082527160645,
      "logps/chosen": -117.93077087402344,
      "logps/rejected": -192.96498107910156,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8913745880126953,
      "rewards/margins": 8.875897407531738,
      "rewards/rejected": -9.76727294921875,
      "step": 5575
    },
    {
      "epoch": 2.2304,
      "grad_norm": 0.00011198064748896286,
      "learning_rate": 2.5666666666666666e-07,
      "logits/chosen": -2.653765916824341,
      "logits/rejected": -2.059399127960205,
      "logps/chosen": -68.53221130371094,
      "logps/rejected": -193.76617431640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1489310264587402,
      "rewards/margins": 14.996023178100586,
      "rewards/rejected": -12.847091674804688,
      "step": 5576
    },
    {
      "epoch": 2.2308,
      "grad_norm": 0.06097709387540817,
      "learning_rate": 2.565333333333333e-07,
      "logits/chosen": -2.9075469970703125,
      "logits/rejected": -2.7181105613708496,
      "logps/chosen": -72.25602722167969,
      "logps/rejected": -120.46119689941406,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0784615278244019,
      "rewards/margins": 9.009224891662598,
      "rewards/rejected": -7.9307637214660645,
      "step": 5577
    },
    {
      "epoch": 2.2312,
      "grad_norm": 2.6695189476013184,
      "learning_rate": 2.564e-07,
      "logits/chosen": -2.536630630493164,
      "logits/rejected": -2.5585458278656006,
      "logps/chosen": -129.70361328125,
      "logps/rejected": -119.49383544921875,
      "loss": 0.021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.113480567932129,
      "rewards/margins": 3.8955910205841064,
      "rewards/rejected": -7.009071350097656,
      "step": 5578
    },
    {
      "epoch": 2.2316,
      "grad_norm": 0.0002114276576321572,
      "learning_rate": 2.5626666666666663e-07,
      "logits/chosen": -2.9367384910583496,
      "logits/rejected": -2.3489232063293457,
      "logps/chosen": -72.82340240478516,
      "logps/rejected": -196.67684936523438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3679296672344208,
      "rewards/margins": 14.170721054077148,
      "rewards/rejected": -13.802791595458984,
      "step": 5579
    },
    {
      "epoch": 2.232,
      "grad_norm": 0.012793159112334251,
      "learning_rate": 2.561333333333333e-07,
      "logits/chosen": -2.5812597274780273,
      "logits/rejected": -1.8921946287155151,
      "logps/chosen": -95.12715148925781,
      "logps/rejected": -217.06552124023438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4545513391494751,
      "rewards/margins": 12.612103462219238,
      "rewards/rejected": -13.066655158996582,
      "step": 5580
    },
    {
      "epoch": 2.2324,
      "grad_norm": 4.553499698638916,
      "learning_rate": 2.56e-07,
      "logits/chosen": -2.180548667907715,
      "logits/rejected": -1.9496560096740723,
      "logps/chosen": -245.75942993164062,
      "logps/rejected": -211.88363647460938,
      "loss": 0.0122,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -5.52443790435791,
      "rewards/margins": 5.417190074920654,
      "rewards/rejected": -10.941627502441406,
      "step": 5581
    },
    {
      "epoch": 2.2328,
      "grad_norm": 0.9123950600624084,
      "learning_rate": 2.5586666666666665e-07,
      "logits/chosen": -2.917541742324829,
      "logits/rejected": -2.6294822692871094,
      "logps/chosen": -63.88520050048828,
      "logps/rejected": -92.09585571289062,
      "loss": 0.0052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.25272274017333984,
      "rewards/margins": 5.877236366271973,
      "rewards/rejected": -6.1299591064453125,
      "step": 5582
    },
    {
      "epoch": 2.2332,
      "grad_norm": 0.007740195374935865,
      "learning_rate": 2.557333333333333e-07,
      "logits/chosen": -2.5703840255737305,
      "logits/rejected": -1.971811056137085,
      "logps/chosen": -191.31390380859375,
      "logps/rejected": -220.23294067382812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0892722606658936,
      "rewards/margins": 12.627931594848633,
      "rewards/rejected": -13.717205047607422,
      "step": 5583
    },
    {
      "epoch": 2.2336,
      "grad_norm": 0.01590648479759693,
      "learning_rate": 2.556e-07,
      "logits/chosen": -2.3983030319213867,
      "logits/rejected": -1.873295545578003,
      "logps/chosen": -126.50177001953125,
      "logps/rejected": -167.53855895996094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3170795440673828,
      "rewards/margins": 10.248973846435547,
      "rewards/rejected": -10.56605339050293,
      "step": 5584
    },
    {
      "epoch": 2.234,
      "grad_norm": 0.009731385856866837,
      "learning_rate": 2.554666666666667e-07,
      "logits/chosen": -2.292556047439575,
      "logits/rejected": -1.6099157333374023,
      "logps/chosen": -232.29031372070312,
      "logps/rejected": -158.46377563476562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7713837027549744,
      "rewards/margins": 9.929742813110352,
      "rewards/rejected": -9.15835952758789,
      "step": 5585
    },
    {
      "epoch": 2.2344,
      "grad_norm": 0.03015531785786152,
      "learning_rate": 2.5533333333333337e-07,
      "logits/chosen": -2.5391080379486084,
      "logits/rejected": -2.0379433631896973,
      "logps/chosen": -159.5767822265625,
      "logps/rejected": -204.72216796875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8691311478614807,
      "rewards/margins": 12.117751121520996,
      "rewards/rejected": -12.986882209777832,
      "step": 5586
    },
    {
      "epoch": 2.2348,
      "grad_norm": 0.0041723186150193214,
      "learning_rate": 2.5519999999999996e-07,
      "logits/chosen": -2.885680675506592,
      "logits/rejected": -2.390153169631958,
      "logps/chosen": -94.81551361083984,
      "logps/rejected": -180.53790283203125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9086803793907166,
      "rewards/margins": 11.056608200073242,
      "rewards/rejected": -11.965288162231445,
      "step": 5587
    },
    {
      "epoch": 2.2352,
      "grad_norm": 0.031649839133024216,
      "learning_rate": 2.5506666666666665e-07,
      "logits/chosen": -2.4962663650512695,
      "logits/rejected": -2.0376882553100586,
      "logps/chosen": -53.72823715209961,
      "logps/rejected": -140.616455078125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.910325825214386,
      "rewards/margins": 9.631591796875,
      "rewards/rejected": -8.72126579284668,
      "step": 5588
    },
    {
      "epoch": 2.2356,
      "grad_norm": 1.5587271451950073,
      "learning_rate": 2.5493333333333334e-07,
      "logits/chosen": -2.652820587158203,
      "logits/rejected": -2.4509167671203613,
      "logps/chosen": -87.79619598388672,
      "logps/rejected": -105.4451904296875,
      "loss": 0.0087,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08235204219818115,
      "rewards/margins": 5.291740894317627,
      "rewards/rejected": -5.209388732910156,
      "step": 5589
    },
    {
      "epoch": 2.2359999999999998,
      "grad_norm": 0.6860510110855103,
      "learning_rate": 2.5480000000000003e-07,
      "logits/chosen": -2.7406888008117676,
      "logits/rejected": -2.323427677154541,
      "logps/chosen": -85.0824203491211,
      "logps/rejected": -193.01214599609375,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6889272332191467,
      "rewards/margins": 13.102422714233398,
      "rewards/rejected": -13.791349411010742,
      "step": 5590
    },
    {
      "epoch": 2.2364,
      "grad_norm": 0.5439770817756653,
      "learning_rate": 2.546666666666666e-07,
      "logits/chosen": -2.6151139736175537,
      "logits/rejected": -2.340038299560547,
      "logps/chosen": -111.05455017089844,
      "logps/rejected": -136.33143615722656,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.24618303775787354,
      "rewards/margins": 8.033897399902344,
      "rewards/rejected": -8.280080795288086,
      "step": 5591
    },
    {
      "epoch": 2.2368,
      "grad_norm": 0.6149371266365051,
      "learning_rate": 2.545333333333333e-07,
      "logits/chosen": -2.6985650062561035,
      "logits/rejected": -2.487964391708374,
      "logps/chosen": -113.63125610351562,
      "logps/rejected": -107.38851165771484,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.599522352218628,
      "rewards/margins": 6.392549991607666,
      "rewards/rejected": -7.992072105407715,
      "step": 5592
    },
    {
      "epoch": 2.2372,
      "grad_norm": 0.0005285959923639894,
      "learning_rate": 2.544e-07,
      "logits/chosen": -2.7296528816223145,
      "logits/rejected": -1.8743870258331299,
      "logps/chosen": -77.09034729003906,
      "logps/rejected": -180.78622436523438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5402686595916748,
      "rewards/margins": 13.997543334960938,
      "rewards/rejected": -12.457273483276367,
      "step": 5593
    },
    {
      "epoch": 2.2376,
      "grad_norm": 0.007042428012937307,
      "learning_rate": 2.5426666666666664e-07,
      "logits/chosen": -2.376929759979248,
      "logits/rejected": -1.3893094062805176,
      "logps/chosen": -93.86802673339844,
      "logps/rejected": -264.9759826660156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4719223976135254,
      "rewards/margins": 13.962162971496582,
      "rewards/rejected": -12.490240097045898,
      "step": 5594
    },
    {
      "epoch": 2.238,
      "grad_norm": 0.10119771212339401,
      "learning_rate": 2.5413333333333333e-07,
      "logits/chosen": -2.866102457046509,
      "logits/rejected": -2.4409618377685547,
      "logps/chosen": -67.87872314453125,
      "logps/rejected": -166.27142333984375,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9227283596992493,
      "rewards/margins": 11.098165512084961,
      "rewards/rejected": -10.175436019897461,
      "step": 5595
    },
    {
      "epoch": 2.2384,
      "grad_norm": 0.0010307197226211429,
      "learning_rate": 2.5399999999999997e-07,
      "logits/chosen": -3.056891441345215,
      "logits/rejected": -2.683030605316162,
      "logps/chosen": -51.743656158447266,
      "logps/rejected": -154.7980499267578,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3168375492095947,
      "rewards/margins": 12.588974952697754,
      "rewards/rejected": -11.272137641906738,
      "step": 5596
    },
    {
      "epoch": 2.2388,
      "grad_norm": 25.119247436523438,
      "learning_rate": 2.5386666666666666e-07,
      "logits/chosen": -2.429790496826172,
      "logits/rejected": -2.1392080783843994,
      "logps/chosen": -241.64028930664062,
      "logps/rejected": -126.0816650390625,
      "loss": 0.198,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.7767467498779297,
      "rewards/margins": 4.097284317016602,
      "rewards/rejected": -7.874031066894531,
      "step": 5597
    },
    {
      "epoch": 2.2392,
      "grad_norm": 11.206887245178223,
      "learning_rate": 2.537333333333333e-07,
      "logits/chosen": -2.3373842239379883,
      "logits/rejected": -2.2635509967803955,
      "logps/chosen": -71.34430694580078,
      "logps/rejected": -140.88943481445312,
      "loss": 0.0608,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.852823495864868,
      "rewards/margins": 5.630008697509766,
      "rewards/rejected": -8.482831954956055,
      "step": 5598
    },
    {
      "epoch": 2.2396,
      "grad_norm": 0.04525868594646454,
      "learning_rate": 2.536e-07,
      "logits/chosen": -2.577073574066162,
      "logits/rejected": -2.178396701812744,
      "logps/chosen": -79.87614440917969,
      "logps/rejected": -161.3614959716797,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8563953042030334,
      "rewards/margins": 10.05929946899414,
      "rewards/rejected": -10.915694236755371,
      "step": 5599
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.29380500316619873,
      "learning_rate": 2.534666666666667e-07,
      "logits/chosen": -2.4845147132873535,
      "logits/rejected": -2.098397970199585,
      "logps/chosen": -186.06607055664062,
      "logps/rejected": -229.39283752441406,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.451937675476074,
      "rewards/margins": 7.031689643859863,
      "rewards/rejected": -11.483627319335938,
      "step": 5600
    },
    {
      "epoch": 2.2404,
      "grad_norm": 0.003753121942281723,
      "learning_rate": 2.533333333333333e-07,
      "logits/chosen": -2.691938638687134,
      "logits/rejected": -1.8136992454528809,
      "logps/chosen": -106.13589477539062,
      "logps/rejected": -167.05758666992188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.021532773971557617,
      "rewards/margins": 11.078804016113281,
      "rewards/rejected": -11.100336074829102,
      "step": 5601
    },
    {
      "epoch": 2.2408,
      "grad_norm": 0.0009047662024386227,
      "learning_rate": 2.5319999999999996e-07,
      "logits/chosen": -2.280057668685913,
      "logits/rejected": -1.583858609199524,
      "logps/chosen": -235.1845703125,
      "logps/rejected": -251.93170166015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17245179414749146,
      "rewards/margins": 13.597127914428711,
      "rewards/rejected": -13.424674987792969,
      "step": 5602
    },
    {
      "epoch": 2.2412,
      "grad_norm": 0.025035709142684937,
      "learning_rate": 2.5306666666666666e-07,
      "logits/chosen": -2.5074472427368164,
      "logits/rejected": -2.0460188388824463,
      "logps/chosen": -39.48939514160156,
      "logps/rejected": -158.10601806640625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6423543691635132,
      "rewards/margins": 11.64437484741211,
      "rewards/rejected": -10.002020835876465,
      "step": 5603
    },
    {
      "epoch": 2.2416,
      "grad_norm": 0.5638987421989441,
      "learning_rate": 2.5293333333333335e-07,
      "logits/chosen": -2.661457061767578,
      "logits/rejected": -2.087434768676758,
      "logps/chosen": -90.13233947753906,
      "logps/rejected": -142.66136169433594,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.702252209186554,
      "rewards/margins": 9.819777488708496,
      "rewards/rejected": -9.117525100708008,
      "step": 5604
    },
    {
      "epoch": 2.242,
      "grad_norm": 0.7969247102737427,
      "learning_rate": 2.528e-07,
      "logits/chosen": -2.672826051712036,
      "logits/rejected": -2.5825448036193848,
      "logps/chosen": -66.05987548828125,
      "logps/rejected": -100.40787506103516,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6821334958076477,
      "rewards/margins": 6.281038284301758,
      "rewards/rejected": -6.96317195892334,
      "step": 5605
    },
    {
      "epoch": 2.2424,
      "grad_norm": 0.016707390546798706,
      "learning_rate": 2.526666666666666e-07,
      "logits/chosen": -2.5829880237579346,
      "logits/rejected": -2.1007938385009766,
      "logps/chosen": -88.81224822998047,
      "logps/rejected": -151.93310546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.37109375,
      "rewards/margins": 9.386101722717285,
      "rewards/rejected": -9.015007972717285,
      "step": 5606
    },
    {
      "epoch": 2.2428,
      "grad_norm": 0.3266545236110687,
      "learning_rate": 2.525333333333333e-07,
      "logits/chosen": -2.943131446838379,
      "logits/rejected": -2.663808822631836,
      "logps/chosen": -51.55770492553711,
      "logps/rejected": -103.72183227539062,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.03174474835395813,
      "rewards/margins": 6.239290237426758,
      "rewards/rejected": -6.271035194396973,
      "step": 5607
    },
    {
      "epoch": 2.2432,
      "grad_norm": 0.002969649387523532,
      "learning_rate": 2.524e-07,
      "logits/chosen": -2.606572151184082,
      "logits/rejected": -2.2250962257385254,
      "logps/chosen": -81.28724670410156,
      "logps/rejected": -166.30404663085938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2250332832336426,
      "rewards/margins": 11.677173614501953,
      "rewards/rejected": -9.452140808105469,
      "step": 5608
    },
    {
      "epoch": 2.2436,
      "grad_norm": 0.00042067974573001266,
      "learning_rate": 2.5226666666666665e-07,
      "logits/chosen": -2.4779341220855713,
      "logits/rejected": -1.807175874710083,
      "logps/chosen": -119.88127136230469,
      "logps/rejected": -197.8512725830078,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0547218322753906,
      "rewards/margins": 13.635089874267578,
      "rewards/rejected": -12.580368041992188,
      "step": 5609
    },
    {
      "epoch": 2.2439999999999998,
      "grad_norm": 1.366306185722351,
      "learning_rate": 2.521333333333333e-07,
      "logits/chosen": -2.710875988006592,
      "logits/rejected": -2.5952160358428955,
      "logps/chosen": -61.67750549316406,
      "logps/rejected": -120.38471984863281,
      "loss": 0.01,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35992223024368286,
      "rewards/margins": 7.474566459655762,
      "rewards/rejected": -7.1146440505981445,
      "step": 5610
    },
    {
      "epoch": 2.2444,
      "grad_norm": 0.035794928669929504,
      "learning_rate": 2.52e-07,
      "logits/chosen": -3.046645164489746,
      "logits/rejected": -2.5070509910583496,
      "logps/chosen": -74.95404815673828,
      "logps/rejected": -193.13633728027344,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5850803256034851,
      "rewards/margins": 11.678082466125488,
      "rewards/rejected": -12.263162612915039,
      "step": 5611
    },
    {
      "epoch": 2.2448,
      "grad_norm": 0.004371228627860546,
      "learning_rate": 2.5186666666666667e-07,
      "logits/chosen": -2.7780086994171143,
      "logits/rejected": -2.3969836235046387,
      "logps/chosen": -100.32994842529297,
      "logps/rejected": -169.65908813476562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.680743932723999,
      "rewards/margins": 12.462140083312988,
      "rewards/rejected": -10.78139591217041,
      "step": 5612
    },
    {
      "epoch": 2.2452,
      "grad_norm": 0.38968804478645325,
      "learning_rate": 2.517333333333333e-07,
      "logits/chosen": -2.386505603790283,
      "logits/rejected": -2.141550064086914,
      "logps/chosen": -123.26029968261719,
      "logps/rejected": -147.3720703125,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0545612573623657,
      "rewards/margins": 8.5130033493042,
      "rewards/rejected": -9.567564964294434,
      "step": 5613
    },
    {
      "epoch": 2.2456,
      "grad_norm": 0.09342394024133682,
      "learning_rate": 2.516e-07,
      "logits/chosen": -2.7872605323791504,
      "logits/rejected": -2.3319337368011475,
      "logps/chosen": -74.23332214355469,
      "logps/rejected": -138.99745178222656,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.43489933013916016,
      "rewards/margins": 9.331343650817871,
      "rewards/rejected": -9.766242980957031,
      "step": 5614
    },
    {
      "epoch": 2.246,
      "grad_norm": 4.015133380889893,
      "learning_rate": 2.5146666666666664e-07,
      "logits/chosen": -2.5223419666290283,
      "logits/rejected": -1.941895604133606,
      "logps/chosen": -102.12195587158203,
      "logps/rejected": -173.09869384765625,
      "loss": 0.0294,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5622478723526001,
      "rewards/margins": 9.310397148132324,
      "rewards/rejected": -9.872645378112793,
      "step": 5615
    },
    {
      "epoch": 2.2464,
      "grad_norm": 0.0004558633081614971,
      "learning_rate": 2.5133333333333333e-07,
      "logits/chosen": -2.72104549407959,
      "logits/rejected": -2.035081148147583,
      "logps/chosen": -78.41964721679688,
      "logps/rejected": -235.4903106689453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1698538064956665,
      "rewards/margins": 13.690048217773438,
      "rewards/rejected": -12.520194053649902,
      "step": 5616
    },
    {
      "epoch": 2.2468,
      "grad_norm": 0.01585838384926319,
      "learning_rate": 2.5119999999999997e-07,
      "logits/chosen": -2.6362128257751465,
      "logits/rejected": -1.7677760124206543,
      "logps/chosen": -127.1790542602539,
      "logps/rejected": -158.2408447265625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14300651848316193,
      "rewards/margins": 10.013187408447266,
      "rewards/rejected": -9.8701810836792,
      "step": 5617
    },
    {
      "epoch": 2.2472,
      "grad_norm": 24.214088439941406,
      "learning_rate": 2.5106666666666666e-07,
      "logits/chosen": -2.9636166095733643,
      "logits/rejected": -2.7625584602355957,
      "logps/chosen": -83.53009033203125,
      "logps/rejected": -142.79989624023438,
      "loss": 0.139,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3836199045181274,
      "rewards/margins": 8.184060096740723,
      "rewards/rejected": -9.567680358886719,
      "step": 5618
    },
    {
      "epoch": 2.2476,
      "grad_norm": 0.0008884848211891949,
      "learning_rate": 2.509333333333333e-07,
      "logits/chosen": -2.9037132263183594,
      "logits/rejected": -2.3758127689361572,
      "logps/chosen": -55.552879333496094,
      "logps/rejected": -223.9940948486328,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.34413471817970276,
      "rewards/margins": 14.020261764526367,
      "rewards/rejected": -14.364397048950195,
      "step": 5619
    },
    {
      "epoch": 2.248,
      "grad_norm": 0.0030894901137799025,
      "learning_rate": 2.508e-07,
      "logits/chosen": -2.673614978790283,
      "logits/rejected": -2.5336217880249023,
      "logps/chosen": -93.6777114868164,
      "logps/rejected": -165.5218963623047,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7335807681083679,
      "rewards/margins": 11.16872787475586,
      "rewards/rejected": -10.435147285461426,
      "step": 5620
    },
    {
      "epoch": 2.2484,
      "grad_norm": 0.03934992849826813,
      "learning_rate": 2.5066666666666663e-07,
      "logits/chosen": -2.485072612762451,
      "logits/rejected": -1.8255449533462524,
      "logps/chosen": -84.74542999267578,
      "logps/rejected": -168.62478637695312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2702016830444336,
      "rewards/margins": 11.245401382446289,
      "rewards/rejected": -11.515604019165039,
      "step": 5621
    },
    {
      "epoch": 2.2488,
      "grad_norm": 0.09183727204799652,
      "learning_rate": 2.5053333333333333e-07,
      "logits/chosen": -2.9145383834838867,
      "logits/rejected": -2.643704891204834,
      "logps/chosen": -74.4352035522461,
      "logps/rejected": -116.09122467041016,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6194839477539062,
      "rewards/margins": 7.7047343254089355,
      "rewards/rejected": -8.32421875,
      "step": 5622
    },
    {
      "epoch": 2.2492,
      "grad_norm": 0.2513195872306824,
      "learning_rate": 2.504e-07,
      "logits/chosen": -2.924499988555908,
      "logits/rejected": -2.3164148330688477,
      "logps/chosen": -46.21295928955078,
      "logps/rejected": -156.25323486328125,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3246135413646698,
      "rewards/margins": 9.934452056884766,
      "rewards/rejected": -9.609838485717773,
      "step": 5623
    },
    {
      "epoch": 2.2496,
      "grad_norm": 4.9972405433654785,
      "learning_rate": 2.5026666666666666e-07,
      "logits/chosen": -2.9662299156188965,
      "logits/rejected": -2.540924072265625,
      "logps/chosen": -103.24380493164062,
      "logps/rejected": -95.6679916381836,
      "loss": 0.0224,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.073055386543274,
      "rewards/margins": 5.6634955406188965,
      "rewards/rejected": -6.736550807952881,
      "step": 5624
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.014796970412135124,
      "learning_rate": 2.501333333333333e-07,
      "logits/chosen": -2.2987046241760254,
      "logits/rejected": -2.1042301654815674,
      "logps/chosen": -98.8666763305664,
      "logps/rejected": -231.2725830078125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.148380994796753,
      "rewards/margins": 13.233186721801758,
      "rewards/rejected": -11.084806442260742,
      "step": 5625
    },
    {
      "epoch": 2.2504,
      "grad_norm": 0.011151337996125221,
      "learning_rate": 2.5e-07,
      "logits/chosen": -2.5951008796691895,
      "logits/rejected": -2.116000175476074,
      "logps/chosen": -105.92300415039062,
      "logps/rejected": -151.8619384765625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9440261721611023,
      "rewards/margins": 11.67636489868164,
      "rewards/rejected": -10.732337951660156,
      "step": 5626
    },
    {
      "epoch": 2.2508,
      "grad_norm": 4.1719238652149215e-05,
      "learning_rate": 2.4986666666666663e-07,
      "logits/chosen": -2.47481107711792,
      "logits/rejected": -1.8359613418579102,
      "logps/chosen": -137.39035034179688,
      "logps/rejected": -305.1717529296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5274966955184937,
      "rewards/margins": 17.02810287475586,
      "rewards/rejected": -18.555599212646484,
      "step": 5627
    },
    {
      "epoch": 2.2512,
      "grad_norm": 0.03593923896551132,
      "learning_rate": 2.497333333333333e-07,
      "logits/chosen": -2.8534154891967773,
      "logits/rejected": -2.369670867919922,
      "logps/chosen": -95.25118255615234,
      "logps/rejected": -182.87493896484375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4832136631011963,
      "rewards/margins": 11.053366661071777,
      "rewards/rejected": -12.536580085754395,
      "step": 5628
    },
    {
      "epoch": 2.2516,
      "grad_norm": 0.1351422816514969,
      "learning_rate": 2.4959999999999996e-07,
      "logits/chosen": -2.6960175037384033,
      "logits/rejected": -2.3356034755706787,
      "logps/chosen": -108.62136840820312,
      "logps/rejected": -151.00726318359375,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5225673317909241,
      "rewards/margins": 8.205362319946289,
      "rewards/rejected": -8.72792911529541,
      "step": 5629
    },
    {
      "epoch": 2.252,
      "grad_norm": 0.006529227830469608,
      "learning_rate": 2.4946666666666665e-07,
      "logits/chosen": -2.268728733062744,
      "logits/rejected": -1.5606462955474854,
      "logps/chosen": -164.91522216796875,
      "logps/rejected": -228.6263427734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7320953607559204,
      "rewards/margins": 12.919621467590332,
      "rewards/rejected": -14.651716232299805,
      "step": 5630
    },
    {
      "epoch": 2.2524,
      "grad_norm": 0.004084132146090269,
      "learning_rate": 2.493333333333333e-07,
      "logits/chosen": -2.6071407794952393,
      "logits/rejected": -2.0134096145629883,
      "logps/chosen": -78.02784729003906,
      "logps/rejected": -240.09085083007812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6912006139755249,
      "rewards/margins": 15.483394622802734,
      "rewards/rejected": -14.792194366455078,
      "step": 5631
    },
    {
      "epoch": 2.2528,
      "grad_norm": 5.3657422540709376e-05,
      "learning_rate": 2.492e-07,
      "logits/chosen": -2.5101418495178223,
      "logits/rejected": -2.0200037956237793,
      "logps/chosen": -120.7261962890625,
      "logps/rejected": -262.49639892578125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.19460904598236084,
      "rewards/margins": 15.942282676696777,
      "rewards/rejected": -16.136890411376953,
      "step": 5632
    },
    {
      "epoch": 2.2532,
      "grad_norm": 0.003534839954227209,
      "learning_rate": 2.4906666666666667e-07,
      "logits/chosen": -2.537527084350586,
      "logits/rejected": -1.7521406412124634,
      "logps/chosen": -109.1641616821289,
      "logps/rejected": -193.840087890625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18301749229431152,
      "rewards/margins": 11.914384841918945,
      "rewards/rejected": -11.731367111206055,
      "step": 5633
    },
    {
      "epoch": 2.2536,
      "grad_norm": 3.030691385269165,
      "learning_rate": 2.489333333333333e-07,
      "logits/chosen": -2.5383849143981934,
      "logits/rejected": -2.311898708343506,
      "logps/chosen": -145.78155517578125,
      "logps/rejected": -198.653076171875,
      "loss": 0.0125,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.52110755443573,
      "rewards/margins": 9.230022430419922,
      "rewards/rejected": -10.751130104064941,
      "step": 5634
    },
    {
      "epoch": 2.254,
      "grad_norm": 0.0004742133605759591,
      "learning_rate": 2.488e-07,
      "logits/chosen": -2.4852843284606934,
      "logits/rejected": -1.8533260822296143,
      "logps/chosen": -109.70310974121094,
      "logps/rejected": -173.0792236328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1181560754776,
      "rewards/margins": 13.748788833618164,
      "rewards/rejected": -12.630632400512695,
      "step": 5635
    },
    {
      "epoch": 2.2544,
      "grad_norm": 0.41702237725257874,
      "learning_rate": 2.4866666666666664e-07,
      "logits/chosen": -2.6721901893615723,
      "logits/rejected": -2.474134922027588,
      "logps/chosen": -91.11229705810547,
      "logps/rejected": -131.96630859375,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.42421990633010864,
      "rewards/margins": 8.288281440734863,
      "rewards/rejected": -8.712501525878906,
      "step": 5636
    },
    {
      "epoch": 2.2548,
      "grad_norm": 0.07315775007009506,
      "learning_rate": 2.4853333333333334e-07,
      "logits/chosen": -2.810356616973877,
      "logits/rejected": -2.35970401763916,
      "logps/chosen": -117.95381164550781,
      "logps/rejected": -153.95677185058594,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4526863098144531,
      "rewards/margins": 11.090392112731934,
      "rewards/rejected": -10.63770580291748,
      "step": 5637
    },
    {
      "epoch": 2.2552,
      "grad_norm": 0.0044740187004208565,
      "learning_rate": 2.484e-07,
      "logits/chosen": -2.800109624862671,
      "logits/rejected": -2.368175506591797,
      "logps/chosen": -64.54280090332031,
      "logps/rejected": -142.18563842773438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.301161527633667,
      "rewards/margins": 10.858135223388672,
      "rewards/rejected": -9.55697250366211,
      "step": 5638
    },
    {
      "epoch": 2.2556,
      "grad_norm": 0.2882854640483856,
      "learning_rate": 2.4826666666666667e-07,
      "logits/chosen": -2.663863182067871,
      "logits/rejected": -2.395991325378418,
      "logps/chosen": -147.81044006347656,
      "logps/rejected": -184.89553833007812,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.5975558757781982,
      "rewards/margins": 10.145027160644531,
      "rewards/rejected": -13.742582321166992,
      "step": 5639
    },
    {
      "epoch": 2.2560000000000002,
      "grad_norm": 0.049149949103593826,
      "learning_rate": 2.4813333333333336e-07,
      "logits/chosen": -2.9896934032440186,
      "logits/rejected": -2.666114330291748,
      "logps/chosen": -65.91456604003906,
      "logps/rejected": -144.39291381835938,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5863201022148132,
      "rewards/margins": 9.650996208190918,
      "rewards/rejected": -9.064676284790039,
      "step": 5640
    },
    {
      "epoch": 2.2564,
      "grad_norm": 0.05017892271280289,
      "learning_rate": 2.48e-07,
      "logits/chosen": -3.0250210762023926,
      "logits/rejected": -2.6015625,
      "logps/chosen": -48.54659652709961,
      "logps/rejected": -108.3064193725586,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2794891595840454,
      "rewards/margins": 8.204916000366211,
      "rewards/rejected": -6.925427436828613,
      "step": 5641
    },
    {
      "epoch": 2.2568,
      "grad_norm": 10.700161933898926,
      "learning_rate": 2.478666666666667e-07,
      "logits/chosen": -3.349443197250366,
      "logits/rejected": -3.2842493057250977,
      "logps/chosen": -61.79498291015625,
      "logps/rejected": -112.74703216552734,
      "loss": 0.0517,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12524503469467163,
      "rewards/margins": 6.972413063049316,
      "rewards/rejected": -6.84716796875,
      "step": 5642
    },
    {
      "epoch": 2.2572,
      "grad_norm": 0.0032772717531770468,
      "learning_rate": 2.4773333333333333e-07,
      "logits/chosen": -2.1965179443359375,
      "logits/rejected": -1.4630341529846191,
      "logps/chosen": -96.49276733398438,
      "logps/rejected": -169.12115478515625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6487941741943359,
      "rewards/margins": 11.524911880493164,
      "rewards/rejected": -10.876117706298828,
      "step": 5643
    },
    {
      "epoch": 2.2576,
      "grad_norm": 0.037164364010095596,
      "learning_rate": 2.4759999999999997e-07,
      "logits/chosen": -2.7080607414245605,
      "logits/rejected": -1.9513578414916992,
      "logps/chosen": -107.81590270996094,
      "logps/rejected": -159.53192138671875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1318730115890503,
      "rewards/margins": 10.69221305847168,
      "rewards/rejected": -10.560340881347656,
      "step": 5644
    },
    {
      "epoch": 2.258,
      "grad_norm": 0.01945246383547783,
      "learning_rate": 2.4746666666666666e-07,
      "logits/chosen": -2.7747669219970703,
      "logits/rejected": -2.179332733154297,
      "logps/chosen": -149.22918701171875,
      "logps/rejected": -171.44956970214844,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9375251531600952,
      "rewards/margins": 9.639963150024414,
      "rewards/rejected": -10.57748794555664,
      "step": 5645
    },
    {
      "epoch": 2.2584,
      "grad_norm": 0.4403890073299408,
      "learning_rate": 2.473333333333333e-07,
      "logits/chosen": -2.774688720703125,
      "logits/rejected": -2.489328384399414,
      "logps/chosen": -175.88287353515625,
      "logps/rejected": -131.9805450439453,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9540756940841675,
      "rewards/margins": 6.668185710906982,
      "rewards/rejected": -8.622261047363281,
      "step": 5646
    },
    {
      "epoch": 2.2588,
      "grad_norm": 0.04346936196088791,
      "learning_rate": 2.472e-07,
      "logits/chosen": -2.245811939239502,
      "logits/rejected": -1.8213417530059814,
      "logps/chosen": -186.42955017089844,
      "logps/rejected": -186.38491821289062,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7417266368865967,
      "rewards/margins": 8.815985679626465,
      "rewards/rejected": -10.55771255493164,
      "step": 5647
    },
    {
      "epoch": 2.2592,
      "grad_norm": 0.04134610295295715,
      "learning_rate": 2.4706666666666663e-07,
      "logits/chosen": -2.2326440811157227,
      "logits/rejected": -1.6068902015686035,
      "logps/chosen": -129.1363525390625,
      "logps/rejected": -208.95310974121094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1190593242645264,
      "rewards/margins": 11.922135353088379,
      "rewards/rejected": -13.041194915771484,
      "step": 5648
    },
    {
      "epoch": 2.2596,
      "grad_norm": 0.12421409040689468,
      "learning_rate": 2.469333333333333e-07,
      "logits/chosen": -2.2867655754089355,
      "logits/rejected": -1.8849079608917236,
      "logps/chosen": -277.80340576171875,
      "logps/rejected": -186.87863159179688,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.683875322341919,
      "rewards/margins": 9.071227073669434,
      "rewards/rejected": -11.755102157592773,
      "step": 5649
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.041329704225063324,
      "learning_rate": 2.4679999999999996e-07,
      "logits/chosen": -2.499483585357666,
      "logits/rejected": -2.3491945266723633,
      "logps/chosen": -117.0339584350586,
      "logps/rejected": -233.4237060546875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4514617323875427,
      "rewards/margins": 12.976175308227539,
      "rewards/rejected": -12.524713516235352,
      "step": 5650
    },
    {
      "epoch": 2.2604,
      "grad_norm": 0.5100144147872925,
      "learning_rate": 2.4666666666666665e-07,
      "logits/chosen": -2.2313036918640137,
      "logits/rejected": -1.4603643417358398,
      "logps/chosen": -128.35537719726562,
      "logps/rejected": -195.92628479003906,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.6955032348632812,
      "rewards/margins": 10.112545013427734,
      "rewards/rejected": -12.808048248291016,
      "step": 5651
    },
    {
      "epoch": 2.2608,
      "grad_norm": 0.053510632365942,
      "learning_rate": 2.465333333333333e-07,
      "logits/chosen": -2.3217267990112305,
      "logits/rejected": -2.2467641830444336,
      "logps/chosen": -235.43731689453125,
      "logps/rejected": -197.19354248046875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.6138229370117188,
      "rewards/margins": 9.726907730102539,
      "rewards/rejected": -12.340730667114258,
      "step": 5652
    },
    {
      "epoch": 2.2612,
      "grad_norm": 0.010298692621290684,
      "learning_rate": 2.464e-07,
      "logits/chosen": -2.8327813148498535,
      "logits/rejected": -2.4255881309509277,
      "logps/chosen": -63.81194305419922,
      "logps/rejected": -162.26937866210938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5560251474380493,
      "rewards/margins": 10.63553524017334,
      "rewards/rejected": -11.191560745239258,
      "step": 5653
    },
    {
      "epoch": 2.2616,
      "grad_norm": 0.0006710899178870022,
      "learning_rate": 2.462666666666667e-07,
      "logits/chosen": -2.4208567142486572,
      "logits/rejected": -1.4499804973602295,
      "logps/chosen": -95.99675750732422,
      "logps/rejected": -173.16513061523438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4185795783996582,
      "rewards/margins": 13.15363597869873,
      "rewards/rejected": -11.73505687713623,
      "step": 5654
    },
    {
      "epoch": 2.262,
      "grad_norm": 0.052851416170597076,
      "learning_rate": 2.461333333333333e-07,
      "logits/chosen": -2.616504669189453,
      "logits/rejected": -2.3058714866638184,
      "logps/chosen": -121.90707397460938,
      "logps/rejected": -177.20071411132812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.231675863265991,
      "rewards/margins": 10.09919548034668,
      "rewards/rejected": -12.33087158203125,
      "step": 5655
    },
    {
      "epoch": 2.2624,
      "grad_norm": 0.008195031434297562,
      "learning_rate": 2.46e-07,
      "logits/chosen": -2.5534634590148926,
      "logits/rejected": -1.9820976257324219,
      "logps/chosen": -96.27970886230469,
      "logps/rejected": -147.6757049560547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11069011688232422,
      "rewards/margins": 10.23196792602539,
      "rewards/rejected": -10.12127685546875,
      "step": 5656
    },
    {
      "epoch": 2.2628,
      "grad_norm": 0.0012651946162804961,
      "learning_rate": 2.4586666666666664e-07,
      "logits/chosen": -2.9475529193878174,
      "logits/rejected": -2.433365821838379,
      "logps/chosen": -60.17201614379883,
      "logps/rejected": -173.11810302734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3137097358703613,
      "rewards/margins": 13.407861709594727,
      "rewards/rejected": -12.094152450561523,
      "step": 5657
    },
    {
      "epoch": 2.2632,
      "grad_norm": 0.11070302873849869,
      "learning_rate": 2.4573333333333334e-07,
      "logits/chosen": -2.627187728881836,
      "logits/rejected": -2.4003829956054688,
      "logps/chosen": -76.11227416992188,
      "logps/rejected": -132.38844299316406,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2945024967193604,
      "rewards/margins": 7.912539482116699,
      "rewards/rejected": -9.207042694091797,
      "step": 5658
    },
    {
      "epoch": 2.2636,
      "grad_norm": 0.009338445961475372,
      "learning_rate": 2.456e-07,
      "logits/chosen": -2.581263303756714,
      "logits/rejected": -1.6625661849975586,
      "logps/chosen": -93.58890533447266,
      "logps/rejected": -157.62197875976562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6593614816665649,
      "rewards/margins": 10.140995025634766,
      "rewards/rejected": -9.481634140014648,
      "step": 5659
    },
    {
      "epoch": 2.2640000000000002,
      "grad_norm": 0.00045221400796435773,
      "learning_rate": 2.4546666666666667e-07,
      "logits/chosen": -2.2599987983703613,
      "logits/rejected": -1.2637932300567627,
      "logps/chosen": -116.41507720947266,
      "logps/rejected": -213.87789916992188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5343369245529175,
      "rewards/margins": 14.422331809997559,
      "rewards/rejected": -12.887994766235352,
      "step": 5660
    },
    {
      "epoch": 2.2644,
      "grad_norm": 0.7207353115081787,
      "learning_rate": 2.453333333333333e-07,
      "logits/chosen": -3.0169882774353027,
      "logits/rejected": -2.7671384811401367,
      "logps/chosen": -82.7435073852539,
      "logps/rejected": -107.2811050415039,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.19150352478027344,
      "rewards/margins": 6.197382926940918,
      "rewards/rejected": -6.388886451721191,
      "step": 5661
    },
    {
      "epoch": 2.2648,
      "grad_norm": 0.006026793736964464,
      "learning_rate": 2.452e-07,
      "logits/chosen": -2.3931736946105957,
      "logits/rejected": -1.5570242404937744,
      "logps/chosen": -147.88632202148438,
      "logps/rejected": -197.61749267578125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8113899230957031,
      "rewards/margins": 11.613554000854492,
      "rewards/rejected": -12.424943923950195,
      "step": 5662
    },
    {
      "epoch": 2.2652,
      "grad_norm": 0.019532179459929466,
      "learning_rate": 2.4506666666666664e-07,
      "logits/chosen": -2.2948436737060547,
      "logits/rejected": -1.3545970916748047,
      "logps/chosen": -122.560791015625,
      "logps/rejected": -165.61962890625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6978596448898315,
      "rewards/margins": 12.305315971374512,
      "rewards/rejected": -10.60745620727539,
      "step": 5663
    },
    {
      "epoch": 2.2656,
      "grad_norm": 0.0002171072701457888,
      "learning_rate": 2.4493333333333333e-07,
      "logits/chosen": -2.1830410957336426,
      "logits/rejected": -1.54801607131958,
      "logps/chosen": -59.222511291503906,
      "logps/rejected": -230.33120727539062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2056092023849487,
      "rewards/margins": 15.05059814453125,
      "rewards/rejected": -13.844989776611328,
      "step": 5664
    },
    {
      "epoch": 2.266,
      "grad_norm": 0.2832341194152832,
      "learning_rate": 2.4479999999999997e-07,
      "logits/chosen": -2.660581350326538,
      "logits/rejected": -2.4352219104766846,
      "logps/chosen": -67.15351867675781,
      "logps/rejected": -135.13125610351562,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2261960506439209,
      "rewards/margins": 8.856830596923828,
      "rewards/rejected": -9.083026885986328,
      "step": 5665
    },
    {
      "epoch": 2.2664,
      "grad_norm": 0.05513710156083107,
      "learning_rate": 2.4466666666666666e-07,
      "logits/chosen": -2.78558349609375,
      "logits/rejected": -2.3828635215759277,
      "logps/chosen": -128.51052856445312,
      "logps/rejected": -152.31491088867188,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3553584814071655,
      "rewards/margins": 8.07225227355957,
      "rewards/rejected": -9.427610397338867,
      "step": 5666
    },
    {
      "epoch": 2.2668,
      "grad_norm": 0.2298584133386612,
      "learning_rate": 2.445333333333333e-07,
      "logits/chosen": -2.777423858642578,
      "logits/rejected": -2.2384703159332275,
      "logps/chosen": -136.5127410888672,
      "logps/rejected": -145.55133056640625,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.563153862953186,
      "rewards/margins": 8.384082794189453,
      "rewards/rejected": -8.947237014770508,
      "step": 5667
    },
    {
      "epoch": 2.2672,
      "grad_norm": 0.05683152750134468,
      "learning_rate": 2.444e-07,
      "logits/chosen": -2.866154432296753,
      "logits/rejected": -2.5127081871032715,
      "logps/chosen": -83.76829528808594,
      "logps/rejected": -153.8061065673828,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5865055322647095,
      "rewards/margins": 7.8320441246032715,
      "rewards/rejected": -8.418549537658691,
      "step": 5668
    },
    {
      "epoch": 2.2676,
      "grad_norm": 0.031155094504356384,
      "learning_rate": 2.4426666666666663e-07,
      "logits/chosen": -2.745307445526123,
      "logits/rejected": -2.574398994445801,
      "logps/chosen": -83.99005126953125,
      "logps/rejected": -145.2512969970703,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.027861475944519,
      "rewards/margins": 11.346614837646484,
      "rewards/rejected": -10.318754196166992,
      "step": 5669
    },
    {
      "epoch": 2.268,
      "grad_norm": 0.007854906842112541,
      "learning_rate": 2.441333333333333e-07,
      "logits/chosen": -2.520411729812622,
      "logits/rejected": -1.980185627937317,
      "logps/chosen": -73.90685272216797,
      "logps/rejected": -203.4454345703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0033295154571533,
      "rewards/margins": 12.651873588562012,
      "rewards/rejected": -11.648544311523438,
      "step": 5670
    },
    {
      "epoch": 2.2684,
      "grad_norm": 0.000471554376417771,
      "learning_rate": 2.4399999999999996e-07,
      "logits/chosen": -2.1583492755889893,
      "logits/rejected": -1.7623119354248047,
      "logps/chosen": -140.38172912597656,
      "logps/rejected": -262.1486511230469,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2522006928920746,
      "rewards/margins": 14.643840789794922,
      "rewards/rejected": -14.896040916442871,
      "step": 5671
    },
    {
      "epoch": 2.2688,
      "grad_norm": 0.2995763123035431,
      "learning_rate": 2.4386666666666665e-07,
      "logits/chosen": -2.8664934635162354,
      "logits/rejected": -2.7152881622314453,
      "logps/chosen": -105.65989685058594,
      "logps/rejected": -94.99441528320312,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.04487687349319458,
      "rewards/margins": 7.217712879180908,
      "rewards/rejected": -7.262589454650879,
      "step": 5672
    },
    {
      "epoch": 2.2692,
      "grad_norm": 0.01634277030825615,
      "learning_rate": 2.437333333333333e-07,
      "logits/chosen": -3.0082249641418457,
      "logits/rejected": -2.716750383377075,
      "logps/chosen": -58.228973388671875,
      "logps/rejected": -121.39303588867188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.054232120513916,
      "rewards/margins": 9.32581901550293,
      "rewards/rejected": -8.271587371826172,
      "step": 5673
    },
    {
      "epoch": 2.2696,
      "grad_norm": 0.058042075484991074,
      "learning_rate": 2.436e-07,
      "logits/chosen": -2.030071973800659,
      "logits/rejected": -1.239358901977539,
      "logps/chosen": -215.5899200439453,
      "logps/rejected": -227.73818969726562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.465231418609619,
      "rewards/margins": 8.579317092895508,
      "rewards/rejected": -12.044548034667969,
      "step": 5674
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.8364083766937256,
      "learning_rate": 2.434666666666667e-07,
      "logits/chosen": -2.769279718399048,
      "logits/rejected": -2.573561429977417,
      "logps/chosen": -111.92070007324219,
      "logps/rejected": -101.93415832519531,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.335252046585083,
      "rewards/margins": 5.377654075622559,
      "rewards/rejected": -6.7129058837890625,
      "step": 5675
    },
    {
      "epoch": 2.2704,
      "grad_norm": 0.023379338905215263,
      "learning_rate": 2.433333333333333e-07,
      "logits/chosen": -2.374431610107422,
      "logits/rejected": -2.0286765098571777,
      "logps/chosen": -116.61580657958984,
      "logps/rejected": -177.81597900390625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9450125098228455,
      "rewards/margins": 10.446771621704102,
      "rewards/rejected": -11.39178466796875,
      "step": 5676
    },
    {
      "epoch": 2.2708,
      "grad_norm": 0.12812447547912598,
      "learning_rate": 2.432e-07,
      "logits/chosen": -2.8031067848205566,
      "logits/rejected": -2.3384337425231934,
      "logps/chosen": -126.40847778320312,
      "logps/rejected": -141.62582397460938,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2890392243862152,
      "rewards/margins": 7.809937000274658,
      "rewards/rejected": -8.098976135253906,
      "step": 5677
    },
    {
      "epoch": 2.2712,
      "grad_norm": 0.02222817949950695,
      "learning_rate": 2.4306666666666665e-07,
      "logits/chosen": -2.4625625610351562,
      "logits/rejected": -1.9255523681640625,
      "logps/chosen": -190.48825073242188,
      "logps/rejected": -214.4413299560547,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.414407968521118,
      "rewards/margins": 9.552153587341309,
      "rewards/rejected": -11.966561317443848,
      "step": 5678
    },
    {
      "epoch": 2.2716,
      "grad_norm": 0.007642481941729784,
      "learning_rate": 2.4293333333333334e-07,
      "logits/chosen": -2.4459409713745117,
      "logits/rejected": -2.055048942565918,
      "logps/chosen": -60.104400634765625,
      "logps/rejected": -243.16744995117188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5417699813842773,
      "rewards/margins": 12.08356761932373,
      "rewards/rejected": -11.541797637939453,
      "step": 5679
    },
    {
      "epoch": 2.2720000000000002,
      "grad_norm": 0.26661747694015503,
      "learning_rate": 2.428e-07,
      "logits/chosen": -2.6332719326019287,
      "logits/rejected": -2.444324493408203,
      "logps/chosen": -55.05954360961914,
      "logps/rejected": -124.5520248413086,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.587394118309021,
      "rewards/margins": 7.620364189147949,
      "rewards/rejected": -8.207758903503418,
      "step": 5680
    },
    {
      "epoch": 2.2724,
      "grad_norm": 0.003093827050179243,
      "learning_rate": 2.4266666666666667e-07,
      "logits/chosen": -2.3001675605773926,
      "logits/rejected": -1.4777028560638428,
      "logps/chosen": -185.55972290039062,
      "logps/rejected": -167.73374938964844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41859742999076843,
      "rewards/margins": 11.406633377075195,
      "rewards/rejected": -10.988035202026367,
      "step": 5681
    },
    {
      "epoch": 2.2728,
      "grad_norm": 0.09335756301879883,
      "learning_rate": 2.425333333333333e-07,
      "logits/chosen": -2.6583645343780518,
      "logits/rejected": -1.9858009815216064,
      "logps/chosen": -84.95661926269531,
      "logps/rejected": -125.19036102294922,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1924431324005127,
      "rewards/margins": 9.583525657653809,
      "rewards/rejected": -8.391082763671875,
      "step": 5682
    },
    {
      "epoch": 2.2732,
      "grad_norm": 0.05800747126340866,
      "learning_rate": 2.424e-07,
      "logits/chosen": -2.7502148151397705,
      "logits/rejected": -2.4827816486358643,
      "logps/chosen": -55.785037994384766,
      "logps/rejected": -188.25059509277344,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33624401688575745,
      "rewards/margins": 12.761812210083008,
      "rewards/rejected": -12.425568580627441,
      "step": 5683
    },
    {
      "epoch": 2.2736,
      "grad_norm": 22.891441345214844,
      "learning_rate": 2.4226666666666664e-07,
      "logits/chosen": -2.5336570739746094,
      "logits/rejected": -2.4884727001190186,
      "logps/chosen": -113.36117553710938,
      "logps/rejected": -119.18028259277344,
      "loss": 0.1044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.4564309120178223,
      "rewards/margins": 5.283130168914795,
      "rewards/rejected": -7.739561080932617,
      "step": 5684
    },
    {
      "epoch": 2.274,
      "grad_norm": 3.071001992793754e-05,
      "learning_rate": 2.4213333333333333e-07,
      "logits/chosen": -2.7497291564941406,
      "logits/rejected": -1.8647539615631104,
      "logps/chosen": -64.96903228759766,
      "logps/rejected": -209.8594970703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.89248526096344,
      "rewards/margins": 16.333694458007812,
      "rewards/rejected": -14.44120979309082,
      "step": 5685
    },
    {
      "epoch": 2.2744,
      "grad_norm": 0.00045855503412894905,
      "learning_rate": 2.4199999999999997e-07,
      "logits/chosen": -2.2281932830810547,
      "logits/rejected": -1.3467957973480225,
      "logps/chosen": -110.53937530517578,
      "logps/rejected": -202.43374633789062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5929691791534424,
      "rewards/margins": 13.704532623291016,
      "rewards/rejected": -14.297500610351562,
      "step": 5686
    },
    {
      "epoch": 2.2748,
      "grad_norm": 0.10187023878097534,
      "learning_rate": 2.4186666666666666e-07,
      "logits/chosen": -2.6917495727539062,
      "logits/rejected": -1.98514986038208,
      "logps/chosen": -99.66275024414062,
      "logps/rejected": -163.4138641357422,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09048309922218323,
      "rewards/margins": 9.819403648376465,
      "rewards/rejected": -9.728919982910156,
      "step": 5687
    },
    {
      "epoch": 2.2752,
      "grad_norm": 0.002326292684301734,
      "learning_rate": 2.417333333333333e-07,
      "logits/chosen": -2.6311233043670654,
      "logits/rejected": -2.210153102874756,
      "logps/chosen": -72.36077880859375,
      "logps/rejected": -153.37417602539062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0285507440567017,
      "rewards/margins": 11.623174667358398,
      "rewards/rejected": -10.594624519348145,
      "step": 5688
    },
    {
      "epoch": 2.2756,
      "grad_norm": 0.04016987979412079,
      "learning_rate": 2.416e-07,
      "logits/chosen": -2.5016300678253174,
      "logits/rejected": -2.181964635848999,
      "logps/chosen": -161.25645446777344,
      "logps/rejected": -178.3350372314453,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6384118795394897,
      "rewards/margins": 9.843294143676758,
      "rewards/rejected": -11.481705665588379,
      "step": 5689
    },
    {
      "epoch": 2.276,
      "grad_norm": 0.06322052329778671,
      "learning_rate": 2.4146666666666663e-07,
      "logits/chosen": -2.600065231323242,
      "logits/rejected": -2.322523593902588,
      "logps/chosen": -131.02703857421875,
      "logps/rejected": -163.49452209472656,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08254621922969818,
      "rewards/margins": 10.268427848815918,
      "rewards/rejected": -10.185881614685059,
      "step": 5690
    },
    {
      "epoch": 2.2763999999999998,
      "grad_norm": 0.0024413587525486946,
      "learning_rate": 2.413333333333333e-07,
      "logits/chosen": -2.6470932960510254,
      "logits/rejected": -1.9349300861358643,
      "logps/chosen": -118.18431091308594,
      "logps/rejected": -191.24600219726562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04239237308502197,
      "rewards/margins": 12.76472282409668,
      "rewards/rejected": -12.722330093383789,
      "step": 5691
    },
    {
      "epoch": 2.2768,
      "grad_norm": 0.02580588310956955,
      "learning_rate": 2.4119999999999996e-07,
      "logits/chosen": -2.93044376373291,
      "logits/rejected": -2.431018352508545,
      "logps/chosen": -129.30581665039062,
      "logps/rejected": -177.97564697265625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.3754680156707764,
      "rewards/margins": 9.946321487426758,
      "rewards/rejected": -12.32179069519043,
      "step": 5692
    },
    {
      "epoch": 2.2772,
      "grad_norm": 3.318642120575532e-05,
      "learning_rate": 2.4106666666666665e-07,
      "logits/chosen": -2.2696995735168457,
      "logits/rejected": -1.3639142513275146,
      "logps/chosen": -87.63140869140625,
      "logps/rejected": -258.5577697753906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0796494483947754,
      "rewards/margins": 18.12978172302246,
      "rewards/rejected": -17.050132751464844,
      "step": 5693
    },
    {
      "epoch": 2.2776,
      "grad_norm": 2.3519670963287354,
      "learning_rate": 2.4093333333333335e-07,
      "logits/chosen": -2.491727828979492,
      "logits/rejected": -2.3951921463012695,
      "logps/chosen": -95.82807922363281,
      "logps/rejected": -141.18218994140625,
      "loss": 0.0133,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3227680921554565,
      "rewards/margins": 7.109278202056885,
      "rewards/rejected": -8.432045936584473,
      "step": 5694
    },
    {
      "epoch": 2.278,
      "grad_norm": 0.9162452816963196,
      "learning_rate": 2.408e-07,
      "logits/chosen": -2.7622556686401367,
      "logits/rejected": -2.458599090576172,
      "logps/chosen": -133.0330352783203,
      "logps/rejected": -103.15316772460938,
      "loss": 0.006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7577080130577087,
      "rewards/margins": 5.110773086547852,
      "rewards/rejected": -5.868480682373047,
      "step": 5695
    },
    {
      "epoch": 2.2784,
      "grad_norm": 0.06807077676057816,
      "learning_rate": 2.406666666666667e-07,
      "logits/chosen": -2.7310104370117188,
      "logits/rejected": -2.0077672004699707,
      "logps/chosen": -82.06600189208984,
      "logps/rejected": -148.57420349121094,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2360571026802063,
      "rewards/margins": 10.58061408996582,
      "rewards/rejected": -10.34455680847168,
      "step": 5696
    },
    {
      "epoch": 2.2788,
      "grad_norm": 0.015249645337462425,
      "learning_rate": 2.405333333333333e-07,
      "logits/chosen": -2.8543009757995605,
      "logits/rejected": -2.3396244049072266,
      "logps/chosen": -62.56593322753906,
      "logps/rejected": -194.04544067382812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9295806884765625,
      "rewards/margins": 12.336823463439941,
      "rewards/rejected": -13.266404151916504,
      "step": 5697
    },
    {
      "epoch": 2.2792,
      "grad_norm": 0.010824352502822876,
      "learning_rate": 2.404e-07,
      "logits/chosen": -2.85794997215271,
      "logits/rejected": -2.6153931617736816,
      "logps/chosen": -66.41815185546875,
      "logps/rejected": -138.805908203125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.603949785232544,
      "rewards/margins": 10.189003944396973,
      "rewards/rejected": -9.585054397583008,
      "step": 5698
    },
    {
      "epoch": 2.2796,
      "grad_norm": 0.0073755644261837006,
      "learning_rate": 2.4026666666666665e-07,
      "logits/chosen": -2.408047676086426,
      "logits/rejected": -1.4699381589889526,
      "logps/chosen": -175.59228515625,
      "logps/rejected": -202.27783203125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2508113384246826,
      "rewards/margins": 13.686515808105469,
      "rewards/rejected": -13.937326431274414,
      "step": 5699
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 0.06931328028440475,
      "learning_rate": 2.4013333333333334e-07,
      "logits/chosen": -2.7399559020996094,
      "logits/rejected": -2.292044162750244,
      "logps/chosen": -103.22383117675781,
      "logps/rejected": -142.2386474609375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9750034809112549,
      "rewards/margins": 9.233226776123047,
      "rewards/rejected": -10.208230018615723,
      "step": 5700
    },
    {
      "epoch": 2.2804,
      "grad_norm": 0.47966268658638,
      "learning_rate": 2.4e-07,
      "logits/chosen": -2.3849937915802,
      "logits/rejected": -1.9848899841308594,
      "logps/chosen": -129.2421875,
      "logps/rejected": -145.65728759765625,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.751538872718811,
      "rewards/margins": 7.818421363830566,
      "rewards/rejected": -7.066882610321045,
      "step": 5701
    },
    {
      "epoch": 2.2808,
      "grad_norm": 0.4589289426803589,
      "learning_rate": 2.3986666666666667e-07,
      "logits/chosen": -2.3984622955322266,
      "logits/rejected": -1.9261806011199951,
      "logps/chosen": -85.23454284667969,
      "logps/rejected": -128.6380615234375,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9772182703018188,
      "rewards/margins": 9.419340133666992,
      "rewards/rejected": -8.442122459411621,
      "step": 5702
    },
    {
      "epoch": 2.2812,
      "grad_norm": 0.0008864706032909453,
      "learning_rate": 2.397333333333333e-07,
      "logits/chosen": -2.5770058631896973,
      "logits/rejected": -2.136204957962036,
      "logps/chosen": -69.22247314453125,
      "logps/rejected": -167.32037353515625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3853721618652344,
      "rewards/margins": 12.301905632019043,
      "rewards/rejected": -10.916533470153809,
      "step": 5703
    },
    {
      "epoch": 2.2816,
      "grad_norm": 0.09726045280694962,
      "learning_rate": 2.396e-07,
      "logits/chosen": -2.457172393798828,
      "logits/rejected": -1.9280979633331299,
      "logps/chosen": -105.5411376953125,
      "logps/rejected": -273.5810241699219,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5319297313690186,
      "rewards/margins": 11.372197151184082,
      "rewards/rejected": -10.8402681350708,
      "step": 5704
    },
    {
      "epoch": 2.282,
      "grad_norm": 0.007735916413366795,
      "learning_rate": 2.3946666666666664e-07,
      "logits/chosen": -2.6323957443237305,
      "logits/rejected": -2.1722798347473145,
      "logps/chosen": -113.50428009033203,
      "logps/rejected": -155.599853515625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3845748901367188,
      "rewards/margins": 10.44953727722168,
      "rewards/rejected": -9.064962387084961,
      "step": 5705
    },
    {
      "epoch": 2.2824,
      "grad_norm": 0.08138810098171234,
      "learning_rate": 2.3933333333333333e-07,
      "logits/chosen": -2.4339728355407715,
      "logits/rejected": -1.806666374206543,
      "logps/chosen": -154.2236785888672,
      "logps/rejected": -192.60122680664062,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3662173748016357,
      "rewards/margins": 10.282880783081055,
      "rewards/rejected": -11.64909839630127,
      "step": 5706
    },
    {
      "epoch": 2.2828,
      "grad_norm": 0.0026162932626903057,
      "learning_rate": 2.3919999999999997e-07,
      "logits/chosen": -2.808462619781494,
      "logits/rejected": -2.449024200439453,
      "logps/chosen": -77.68527221679688,
      "logps/rejected": -172.76669311523438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8418846130371094,
      "rewards/margins": 11.999246597290039,
      "rewards/rejected": -11.15736198425293,
      "step": 5707
    },
    {
      "epoch": 2.2832,
      "grad_norm": 16.666946411132812,
      "learning_rate": 2.3906666666666666e-07,
      "logits/chosen": -3.129756450653076,
      "logits/rejected": -3.26131010055542,
      "logps/chosen": -44.509490966796875,
      "logps/rejected": -59.435829162597656,
      "loss": 0.1636,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8245716094970703,
      "rewards/margins": 3.2227845191955566,
      "rewards/rejected": -4.047356128692627,
      "step": 5708
    },
    {
      "epoch": 2.2836,
      "grad_norm": 0.21674476563930511,
      "learning_rate": 2.389333333333333e-07,
      "logits/chosen": -2.923776149749756,
      "logits/rejected": -2.8628034591674805,
      "logps/chosen": -79.90415954589844,
      "logps/rejected": -100.54551696777344,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6422538757324219,
      "rewards/margins": 7.060744762420654,
      "rewards/rejected": -5.418490409851074,
      "step": 5709
    },
    {
      "epoch": 2.284,
      "grad_norm": 0.1499207764863968,
      "learning_rate": 2.388e-07,
      "logits/chosen": -2.9864907264709473,
      "logits/rejected": -2.618758201599121,
      "logps/chosen": -75.90573120117188,
      "logps/rejected": -105.19393157958984,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.42709505558013916,
      "rewards/margins": 6.951380729675293,
      "rewards/rejected": -7.378476142883301,
      "step": 5710
    },
    {
      "epoch": 2.2843999999999998,
      "grad_norm": 2.3168232440948486,
      "learning_rate": 2.3866666666666663e-07,
      "logits/chosen": -3.0249195098876953,
      "logits/rejected": -3.0783424377441406,
      "logps/chosen": -131.8322296142578,
      "logps/rejected": -101.39828491210938,
      "loss": 0.0138,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6543662548065186,
      "rewards/margins": 4.433230876922607,
      "rewards/rejected": -6.087596893310547,
      "step": 5711
    },
    {
      "epoch": 2.2848,
      "grad_norm": 0.0013591081369668245,
      "learning_rate": 2.385333333333333e-07,
      "logits/chosen": -2.7707316875457764,
      "logits/rejected": -2.2128701210021973,
      "logps/chosen": -59.777713775634766,
      "logps/rejected": -173.98509216308594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5438648462295532,
      "rewards/margins": 13.246500015258789,
      "rewards/rejected": -11.702634811401367,
      "step": 5712
    },
    {
      "epoch": 2.2852,
      "grad_norm": 0.020914852619171143,
      "learning_rate": 2.384e-07,
      "logits/chosen": -2.582953453063965,
      "logits/rejected": -1.8828998804092407,
      "logps/chosen": -99.32633972167969,
      "logps/rejected": -193.2158660888672,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6171023845672607,
      "rewards/margins": 12.504181861877441,
      "rewards/rejected": -13.121284484863281,
      "step": 5713
    },
    {
      "epoch": 2.2856,
      "grad_norm": 0.09796319156885147,
      "learning_rate": 2.3826666666666666e-07,
      "logits/chosen": -2.4914846420288086,
      "logits/rejected": -2.3149611949920654,
      "logps/chosen": -75.29122161865234,
      "logps/rejected": -212.37094116210938,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42880669236183167,
      "rewards/margins": 11.517573356628418,
      "rewards/rejected": -11.088766098022461,
      "step": 5714
    },
    {
      "epoch": 2.286,
      "grad_norm": 0.07815510034561157,
      "learning_rate": 2.3813333333333332e-07,
      "logits/chosen": -2.9278461933135986,
      "logits/rejected": -2.4564390182495117,
      "logps/chosen": -147.70809936523438,
      "logps/rejected": -171.0921630859375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.546992540359497,
      "rewards/margins": 9.227128982543945,
      "rewards/rejected": -10.774121284484863,
      "step": 5715
    },
    {
      "epoch": 2.2864,
      "grad_norm": 0.2577120363712311,
      "learning_rate": 2.38e-07,
      "logits/chosen": -2.769622802734375,
      "logits/rejected": -2.26383113861084,
      "logps/chosen": -72.00082397460938,
      "logps/rejected": -134.4041748046875,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.28832703828811646,
      "rewards/margins": 8.020040512084961,
      "rewards/rejected": -7.73171329498291,
      "step": 5716
    },
    {
      "epoch": 2.2868,
      "grad_norm": 0.0003483522159513086,
      "learning_rate": 2.3786666666666665e-07,
      "logits/chosen": -2.0535898208618164,
      "logits/rejected": -1.398158311843872,
      "logps/chosen": -142.6075439453125,
      "logps/rejected": -233.721435546875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8545029163360596,
      "rewards/margins": 13.717061996459961,
      "rewards/rejected": -12.862558364868164,
      "step": 5717
    },
    {
      "epoch": 2.2872,
      "grad_norm": 0.12868328392505646,
      "learning_rate": 2.3773333333333332e-07,
      "logits/chosen": -2.8454155921936035,
      "logits/rejected": -2.4229581356048584,
      "logps/chosen": -110.1049575805664,
      "logps/rejected": -129.11331176757812,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2370903491973877,
      "rewards/margins": 7.197810649871826,
      "rewards/rejected": -8.434901237487793,
      "step": 5718
    },
    {
      "epoch": 2.2876,
      "grad_norm": 39.58403015136719,
      "learning_rate": 2.3759999999999998e-07,
      "logits/chosen": -2.3456668853759766,
      "logits/rejected": -2.1524362564086914,
      "logps/chosen": -186.70657348632812,
      "logps/rejected": -160.9774169921875,
      "loss": 0.3804,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -4.97646951675415,
      "rewards/margins": 4.324524879455566,
      "rewards/rejected": -9.300993919372559,
      "step": 5719
    },
    {
      "epoch": 2.288,
      "grad_norm": 0.24928352236747742,
      "learning_rate": 2.3746666666666665e-07,
      "logits/chosen": -2.9494309425354004,
      "logits/rejected": -2.6570024490356445,
      "logps/chosen": -66.50050354003906,
      "logps/rejected": -154.1497039794922,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5924810171127319,
      "rewards/margins": 9.973276138305664,
      "rewards/rejected": -10.565756797790527,
      "step": 5720
    },
    {
      "epoch": 2.2884,
      "grad_norm": 0.0196272861212492,
      "learning_rate": 2.3733333333333334e-07,
      "logits/chosen": -2.7163586616516113,
      "logits/rejected": -1.9772632122039795,
      "logps/chosen": -147.6311492919922,
      "logps/rejected": -154.37075805664062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7422300577163696,
      "rewards/margins": 9.945169448852539,
      "rewards/rejected": -10.687399864196777,
      "step": 5721
    },
    {
      "epoch": 2.2888,
      "grad_norm": 0.006021047942340374,
      "learning_rate": 2.3719999999999998e-07,
      "logits/chosen": -2.3675272464752197,
      "logits/rejected": -1.8096212148666382,
      "logps/chosen": -146.47679138183594,
      "logps/rejected": -240.61940002441406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5935074090957642,
      "rewards/margins": 12.897382736206055,
      "rewards/rejected": -13.490890502929688,
      "step": 5722
    },
    {
      "epoch": 2.2892,
      "grad_norm": 0.12433549761772156,
      "learning_rate": 2.3706666666666667e-07,
      "logits/chosen": -2.903660535812378,
      "logits/rejected": -2.3607146739959717,
      "logps/chosen": -107.67316436767578,
      "logps/rejected": -138.09930419921875,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5908094644546509,
      "rewards/margins": 8.802709579467773,
      "rewards/rejected": -9.393518447875977,
      "step": 5723
    },
    {
      "epoch": 2.2896,
      "grad_norm": 0.027981702238321304,
      "learning_rate": 2.369333333333333e-07,
      "logits/chosen": -2.5119857788085938,
      "logits/rejected": -1.8742709159851074,
      "logps/chosen": -105.70848083496094,
      "logps/rejected": -137.1714630126953,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01200256496667862,
      "rewards/margins": 9.639396667480469,
      "rewards/rejected": -9.62739372253418,
      "step": 5724
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.07219761610031128,
      "learning_rate": 2.368e-07,
      "logits/chosen": -2.629521131515503,
      "logits/rejected": -2.2556352615356445,
      "logps/chosen": -88.66924285888672,
      "logps/rejected": -195.21827697753906,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1456371545791626,
      "rewards/margins": 12.801660537719727,
      "rewards/rejected": -13.947298049926758,
      "step": 5725
    },
    {
      "epoch": 2.2904,
      "grad_norm": 0.057457804679870605,
      "learning_rate": 2.3666666666666664e-07,
      "logits/chosen": -2.3232338428497314,
      "logits/rejected": -2.175929069519043,
      "logps/chosen": -162.4034423828125,
      "logps/rejected": -162.27432250976562,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.730664849281311,
      "rewards/margins": 9.052694320678711,
      "rewards/rejected": -10.78335952758789,
      "step": 5726
    },
    {
      "epoch": 2.2908,
      "grad_norm": 0.0005461674882099032,
      "learning_rate": 2.3653333333333333e-07,
      "logits/chosen": -2.73530912399292,
      "logits/rejected": -2.531628131866455,
      "logps/chosen": -131.4524688720703,
      "logps/rejected": -197.47064208984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4356708526611328,
      "rewards/margins": 13.159822463989258,
      "rewards/rejected": -13.59549331665039,
      "step": 5727
    },
    {
      "epoch": 2.2912,
      "grad_norm": 6.787175607314566e-06,
      "learning_rate": 2.364e-07,
      "logits/chosen": -2.632072687149048,
      "logits/rejected": -1.7532603740692139,
      "logps/chosen": -77.76465606689453,
      "logps/rejected": -239.06182861328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1745938062667847,
      "rewards/margins": 18.326457977294922,
      "rewards/rejected": -17.15186309814453,
      "step": 5728
    },
    {
      "epoch": 2.2916,
      "grad_norm": 73.28060913085938,
      "learning_rate": 2.3626666666666666e-07,
      "logits/chosen": -2.278386354446411,
      "logits/rejected": -1.757559061050415,
      "logps/chosen": -156.4864044189453,
      "logps/rejected": -174.82073974609375,
      "loss": 0.2316,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.5317702293396,
      "rewards/margins": 7.97569465637207,
      "rewards/rejected": -12.507465362548828,
      "step": 5729
    },
    {
      "epoch": 2.292,
      "grad_norm": 0.15358199179172516,
      "learning_rate": 2.3613333333333333e-07,
      "logits/chosen": -2.672703742980957,
      "logits/rejected": -2.310899019241333,
      "logps/chosen": -88.04443359375,
      "logps/rejected": -152.63946533203125,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.20755654573440552,
      "rewards/margins": 9.874610900878906,
      "rewards/rejected": -10.082167625427246,
      "step": 5730
    },
    {
      "epoch": 2.2923999999999998,
      "grad_norm": 0.005428562872111797,
      "learning_rate": 2.3599999999999997e-07,
      "logits/chosen": -2.410019874572754,
      "logits/rejected": -1.9167051315307617,
      "logps/chosen": -126.67292785644531,
      "logps/rejected": -140.7731170654297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9394996166229248,
      "rewards/margins": 11.107124328613281,
      "rewards/rejected": -9.167624473571777,
      "step": 5731
    },
    {
      "epoch": 2.2928,
      "grad_norm": 0.011400801129639149,
      "learning_rate": 2.3586666666666666e-07,
      "logits/chosen": -2.5120954513549805,
      "logits/rejected": -2.0959291458129883,
      "logps/chosen": -162.41111755371094,
      "logps/rejected": -192.82583618164062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5996688604354858,
      "rewards/margins": 11.800312995910645,
      "rewards/rejected": -12.399982452392578,
      "step": 5732
    },
    {
      "epoch": 2.2932,
      "grad_norm": 0.02070382423698902,
      "learning_rate": 2.357333333333333e-07,
      "logits/chosen": -2.5051236152648926,
      "logits/rejected": -2.18271541595459,
      "logps/chosen": -140.88377380371094,
      "logps/rejected": -215.66351318359375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0718276500701904,
      "rewards/margins": 13.216123580932617,
      "rewards/rejected": -14.287951469421387,
      "step": 5733
    },
    {
      "epoch": 2.2936,
      "grad_norm": 0.013866132125258446,
      "learning_rate": 2.356e-07,
      "logits/chosen": -2.6783883571624756,
      "logits/rejected": -2.312551498413086,
      "logps/chosen": -107.14299011230469,
      "logps/rejected": -162.75717163085938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.28427544236183167,
      "rewards/margins": 10.76066780090332,
      "rewards/rejected": -11.044942855834961,
      "step": 5734
    },
    {
      "epoch": 2.294,
      "grad_norm": 0.00241254735738039,
      "learning_rate": 2.3546666666666666e-07,
      "logits/chosen": -2.67830491065979,
      "logits/rejected": -1.7692465782165527,
      "logps/chosen": -143.19947814941406,
      "logps/rejected": -301.1746826171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1413078010082245,
      "rewards/margins": 16.311582565307617,
      "rewards/rejected": -16.452890396118164,
      "step": 5735
    },
    {
      "epoch": 2.2944,
      "grad_norm": 0.004233960527926683,
      "learning_rate": 2.3533333333333332e-07,
      "logits/chosen": -2.315713405609131,
      "logits/rejected": -1.2805407047271729,
      "logps/chosen": -169.39303588867188,
      "logps/rejected": -188.10459899902344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15299110114574432,
      "rewards/margins": 11.834726333618164,
      "rewards/rejected": -11.68173599243164,
      "step": 5736
    },
    {
      "epoch": 2.2948,
      "grad_norm": 0.0033962493762373924,
      "learning_rate": 2.352e-07,
      "logits/chosen": -2.5878448486328125,
      "logits/rejected": -1.9626846313476562,
      "logps/chosen": -83.11930084228516,
      "logps/rejected": -153.83349609375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1349389553070068,
      "rewards/margins": 11.485008239746094,
      "rewards/rejected": -10.350069046020508,
      "step": 5737
    },
    {
      "epoch": 2.2952,
      "grad_norm": 0.03168584406375885,
      "learning_rate": 2.3506666666666665e-07,
      "logits/chosen": -2.4692625999450684,
      "logits/rejected": -1.8265093564987183,
      "logps/chosen": -95.07919311523438,
      "logps/rejected": -217.1262664794922,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8044281005859375,
      "rewards/margins": 10.036123275756836,
      "rewards/rejected": -11.840551376342773,
      "step": 5738
    },
    {
      "epoch": 2.2956,
      "grad_norm": 0.24543771147727966,
      "learning_rate": 2.3493333333333332e-07,
      "logits/chosen": -2.5208678245544434,
      "logits/rejected": -2.278879165649414,
      "logps/chosen": -57.84841537475586,
      "logps/rejected": -139.3256378173828,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6785640716552734,
      "rewards/margins": 10.293875694274902,
      "rewards/rejected": -9.615311622619629,
      "step": 5739
    },
    {
      "epoch": 2.296,
      "grad_norm": 0.006636830046772957,
      "learning_rate": 2.3479999999999998e-07,
      "logits/chosen": -2.57401180267334,
      "logits/rejected": -1.8304083347320557,
      "logps/chosen": -147.93714904785156,
      "logps/rejected": -158.46694946289062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.16896039247512817,
      "rewards/margins": 10.242462158203125,
      "rewards/rejected": -10.411422729492188,
      "step": 5740
    },
    {
      "epoch": 2.2964,
      "grad_norm": 4.194853318040259e-05,
      "learning_rate": 2.3466666666666665e-07,
      "logits/chosen": -2.471330165863037,
      "logits/rejected": -1.6985783576965332,
      "logps/chosen": -91.51097869873047,
      "logps/rejected": -224.0731201171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8491311073303223,
      "rewards/margins": 16.28500747680664,
      "rewards/rejected": -14.435876846313477,
      "step": 5741
    },
    {
      "epoch": 2.2968,
      "grad_norm": 6.623356603085995e-05,
      "learning_rate": 2.3453333333333334e-07,
      "logits/chosen": -2.9241857528686523,
      "logits/rejected": -2.178694248199463,
      "logps/chosen": -85.6806411743164,
      "logps/rejected": -208.93310546875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4516617059707642,
      "rewards/margins": 15.970144271850586,
      "rewards/rejected": -14.518482208251953,
      "step": 5742
    },
    {
      "epoch": 2.2972,
      "grad_norm": 0.33438360691070557,
      "learning_rate": 2.3439999999999998e-07,
      "logits/chosen": -2.627659320831299,
      "logits/rejected": -2.080634593963623,
      "logps/chosen": -202.4426727294922,
      "logps/rejected": -197.67684936523438,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.02678918838501,
      "rewards/margins": 6.441143989562988,
      "rewards/rejected": -10.467933654785156,
      "step": 5743
    },
    {
      "epoch": 2.2976,
      "grad_norm": 0.0018899044953286648,
      "learning_rate": 2.3426666666666667e-07,
      "logits/chosen": -2.9039812088012695,
      "logits/rejected": -2.212489604949951,
      "logps/chosen": -96.33853149414062,
      "logps/rejected": -184.1548309326172,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10983777046203613,
      "rewards/margins": 12.277471542358398,
      "rewards/rejected": -12.387310028076172,
      "step": 5744
    },
    {
      "epoch": 2.298,
      "grad_norm": 0.009447766467928886,
      "learning_rate": 2.341333333333333e-07,
      "logits/chosen": -3.100261688232422,
      "logits/rejected": -2.6985249519348145,
      "logps/chosen": -59.388427734375,
      "logps/rejected": -129.44903564453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7049551010131836,
      "rewards/margins": 10.084981918334961,
      "rewards/rejected": -9.380025863647461,
      "step": 5745
    },
    {
      "epoch": 2.2984,
      "grad_norm": 0.003836758201941848,
      "learning_rate": 2.34e-07,
      "logits/chosen": -2.506282329559326,
      "logits/rejected": -1.8790961503982544,
      "logps/chosen": -172.31326293945312,
      "logps/rejected": -190.86903381347656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1835479736328125,
      "rewards/margins": 12.010160446166992,
      "rewards/rejected": -12.193708419799805,
      "step": 5746
    },
    {
      "epoch": 2.2988,
      "grad_norm": 0.0513017363846302,
      "learning_rate": 2.3386666666666667e-07,
      "logits/chosen": -2.5230205059051514,
      "logits/rejected": -1.9174753427505493,
      "logps/chosen": -167.06292724609375,
      "logps/rejected": -130.69065856933594,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12141001224517822,
      "rewards/margins": 8.554889678955078,
      "rewards/rejected": -8.433480262756348,
      "step": 5747
    },
    {
      "epoch": 2.2992,
      "grad_norm": 1.2877211570739746,
      "learning_rate": 2.337333333333333e-07,
      "logits/chosen": -2.9680685997009277,
      "logits/rejected": -2.5594005584716797,
      "logps/chosen": -61.01957321166992,
      "logps/rejected": -113.99053192138672,
      "loss": 0.0079,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.535617470741272,
      "rewards/margins": 7.651119232177734,
      "rewards/rejected": -8.186737060546875,
      "step": 5748
    },
    {
      "epoch": 2.2996,
      "grad_norm": 111.54365539550781,
      "learning_rate": 2.336e-07,
      "logits/chosen": -2.3605666160583496,
      "logits/rejected": -1.923021674156189,
      "logps/chosen": -132.86911010742188,
      "logps/rejected": -162.64669799804688,
      "loss": 1.4431,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -5.122598648071289,
      "rewards/margins": 5.426547050476074,
      "rewards/rejected": -10.549145698547363,
      "step": 5749
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.01740315742790699,
      "learning_rate": 2.3346666666666664e-07,
      "logits/chosen": -2.759657382965088,
      "logits/rejected": -2.3257930278778076,
      "logps/chosen": -80.73235321044922,
      "logps/rejected": -121.22862243652344,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1862406730651855,
      "rewards/margins": 9.634106636047363,
      "rewards/rejected": -7.447865962982178,
      "step": 5750
    },
    {
      "epoch": 2.3004,
      "grad_norm": 0.0009107574005611241,
      "learning_rate": 2.3333333333333333e-07,
      "logits/chosen": -2.330946445465088,
      "logits/rejected": -1.3286020755767822,
      "logps/chosen": -80.89979553222656,
      "logps/rejected": -228.4707489013672,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1819000244140625,
      "rewards/margins": 14.391849517822266,
      "rewards/rejected": -12.209948539733887,
      "step": 5751
    },
    {
      "epoch": 2.3008,
      "grad_norm": 0.05031830444931984,
      "learning_rate": 2.3319999999999997e-07,
      "logits/chosen": -2.823273181915283,
      "logits/rejected": -2.2938809394836426,
      "logps/chosen": -56.539154052734375,
      "logps/rejected": -148.859375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8622143268585205,
      "rewards/margins": 8.474111557006836,
      "rewards/rejected": -9.336326599121094,
      "step": 5752
    },
    {
      "epoch": 2.3012,
      "grad_norm": 0.004466624930500984,
      "learning_rate": 2.3306666666666666e-07,
      "logits/chosen": -2.416142463684082,
      "logits/rejected": -2.0359113216400146,
      "logps/chosen": -102.8249740600586,
      "logps/rejected": -168.64695739746094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9470203518867493,
      "rewards/margins": 11.153350830078125,
      "rewards/rejected": -10.206329345703125,
      "step": 5753
    },
    {
      "epoch": 2.3016,
      "grad_norm": 0.07564593106508255,
      "learning_rate": 2.3293333333333333e-07,
      "logits/chosen": -2.9609227180480957,
      "logits/rejected": -2.1932742595672607,
      "logps/chosen": -59.6816520690918,
      "logps/rejected": -185.86734008789062,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.150346040725708,
      "rewards/margins": 9.893329620361328,
      "rewards/rejected": -11.043675422668457,
      "step": 5754
    },
    {
      "epoch": 2.302,
      "grad_norm": 0.04076848924160004,
      "learning_rate": 2.328e-07,
      "logits/chosen": -2.551671028137207,
      "logits/rejected": -1.9075167179107666,
      "logps/chosen": -148.52224731445312,
      "logps/rejected": -133.7650146484375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8171871304512024,
      "rewards/margins": 9.64680290222168,
      "rewards/rejected": -8.82961654663086,
      "step": 5755
    },
    {
      "epoch": 2.3024,
      "grad_norm": 0.020365968346595764,
      "learning_rate": 2.3266666666666666e-07,
      "logits/chosen": -2.4229073524475098,
      "logits/rejected": -2.3636512756347656,
      "logps/chosen": -126.29231262207031,
      "logps/rejected": -190.4355926513672,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5162088871002197,
      "rewards/margins": 11.418006896972656,
      "rewards/rejected": -10.901798248291016,
      "step": 5756
    },
    {
      "epoch": 2.3028,
      "grad_norm": 0.45053666830062866,
      "learning_rate": 2.3253333333333332e-07,
      "logits/chosen": -2.4995017051696777,
      "logits/rejected": -1.9534324407577515,
      "logps/chosen": -176.28758239746094,
      "logps/rejected": -178.49534606933594,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6207528114318848,
      "rewards/margins": 8.899599075317383,
      "rewards/rejected": -10.52035140991211,
      "step": 5757
    },
    {
      "epoch": 2.3032,
      "grad_norm": 0.023048175498843193,
      "learning_rate": 2.324e-07,
      "logits/chosen": -2.959247589111328,
      "logits/rejected": -2.609267234802246,
      "logps/chosen": -59.530479431152344,
      "logps/rejected": -129.4232940673828,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6883722543716431,
      "rewards/margins": 9.801172256469727,
      "rewards/rejected": -9.112800598144531,
      "step": 5758
    },
    {
      "epoch": 2.3036,
      "grad_norm": 4.698543548583984,
      "learning_rate": 2.3226666666666666e-07,
      "logits/chosen": -2.6411759853363037,
      "logits/rejected": -2.5088653564453125,
      "logps/chosen": -48.031402587890625,
      "logps/rejected": -122.26258850097656,
      "loss": 0.0199,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.44009095430374146,
      "rewards/margins": 7.678926467895508,
      "rewards/rejected": -8.119017601013184,
      "step": 5759
    },
    {
      "epoch": 2.304,
      "grad_norm": 0.049859512597322464,
      "learning_rate": 2.3213333333333332e-07,
      "logits/chosen": -2.8605377674102783,
      "logits/rejected": -2.4259400367736816,
      "logps/chosen": -81.22452545166016,
      "logps/rejected": -127.11724090576172,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6939483880996704,
      "rewards/margins": 7.987897872924805,
      "rewards/rejected": -8.681846618652344,
      "step": 5760
    },
    {
      "epoch": 2.3044000000000002,
      "grad_norm": 0.13297952711582184,
      "learning_rate": 2.32e-07,
      "logits/chosen": -2.692829132080078,
      "logits/rejected": -2.4325430393218994,
      "logps/chosen": -89.35354614257812,
      "logps/rejected": -137.7190704345703,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1131480932235718,
      "rewards/margins": 8.115257263183594,
      "rewards/rejected": -9.228404998779297,
      "step": 5761
    },
    {
      "epoch": 2.3048,
      "grad_norm": 0.762412965297699,
      "learning_rate": 2.3186666666666665e-07,
      "logits/chosen": -2.9298152923583984,
      "logits/rejected": -2.4158976078033447,
      "logps/chosen": -62.874141693115234,
      "logps/rejected": -103.45254516601562,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23446273803710938,
      "rewards/margins": 7.271642684936523,
      "rewards/rejected": -7.037179946899414,
      "step": 5762
    },
    {
      "epoch": 2.3052,
      "grad_norm": 0.1300382912158966,
      "learning_rate": 2.3173333333333334e-07,
      "logits/chosen": -2.9718737602233887,
      "logits/rejected": -2.553699493408203,
      "logps/chosen": -68.1752700805664,
      "logps/rejected": -139.64414978027344,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6721432209014893,
      "rewards/margins": 10.61810302734375,
      "rewards/rejected": -9.945959091186523,
      "step": 5763
    },
    {
      "epoch": 2.3056,
      "grad_norm": 0.001411142060533166,
      "learning_rate": 2.3159999999999998e-07,
      "logits/chosen": -2.5244393348693848,
      "logits/rejected": -1.8991179466247559,
      "logps/chosen": -63.313941955566406,
      "logps/rejected": -161.21426391601562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.162111520767212,
      "rewards/margins": 13.472881317138672,
      "rewards/rejected": -11.310770034790039,
      "step": 5764
    },
    {
      "epoch": 2.306,
      "grad_norm": 0.0020218549761921167,
      "learning_rate": 2.3146666666666665e-07,
      "logits/chosen": -2.890122890472412,
      "logits/rejected": -2.020623207092285,
      "logps/chosen": -159.7451934814453,
      "logps/rejected": -218.4131622314453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7534980773925781,
      "rewards/margins": 12.828980445861816,
      "rewards/rejected": -14.582478523254395,
      "step": 5765
    },
    {
      "epoch": 2.3064,
      "grad_norm": 0.12147108465433121,
      "learning_rate": 2.3133333333333331e-07,
      "logits/chosen": -2.439000129699707,
      "logits/rejected": -1.9823198318481445,
      "logps/chosen": -100.09848022460938,
      "logps/rejected": -174.21343994140625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5921735763549805,
      "rewards/margins": 11.25263786315918,
      "rewards/rejected": -10.6604642868042,
      "step": 5766
    },
    {
      "epoch": 2.3068,
      "grad_norm": 0.04821477085351944,
      "learning_rate": 2.3119999999999998e-07,
      "logits/chosen": -2.4064533710479736,
      "logits/rejected": -2.146703004837036,
      "logps/chosen": -91.42181396484375,
      "logps/rejected": -145.08273315429688,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02799147367477417,
      "rewards/margins": 8.159708023071289,
      "rewards/rejected": -8.13171672821045,
      "step": 5767
    },
    {
      "epoch": 2.3072,
      "grad_norm": 0.003975878935307264,
      "learning_rate": 2.3106666666666667e-07,
      "logits/chosen": -2.8376121520996094,
      "logits/rejected": -1.9311649799346924,
      "logps/chosen": -55.401466369628906,
      "logps/rejected": -168.3379364013672,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5026543140411377,
      "rewards/margins": 11.29071044921875,
      "rewards/rejected": -9.788055419921875,
      "step": 5768
    },
    {
      "epoch": 2.3076,
      "grad_norm": 0.1425725519657135,
      "learning_rate": 2.309333333333333e-07,
      "logits/chosen": -2.915761709213257,
      "logits/rejected": -2.6543056964874268,
      "logps/chosen": -69.00120544433594,
      "logps/rejected": -155.17361450195312,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0285872220993042,
      "rewards/margins": 8.653923034667969,
      "rewards/rejected": -9.682510375976562,
      "step": 5769
    },
    {
      "epoch": 2.308,
      "grad_norm": 12.126023292541504,
      "learning_rate": 2.308e-07,
      "logits/chosen": -2.4159154891967773,
      "logits/rejected": -2.086580753326416,
      "logps/chosen": -123.9278564453125,
      "logps/rejected": -159.34213256835938,
      "loss": 0.075,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5958821773529053,
      "rewards/margins": 8.442229270935059,
      "rewards/rejected": -10.038110733032227,
      "step": 5770
    },
    {
      "epoch": 2.3084,
      "grad_norm": 0.005317946430295706,
      "learning_rate": 2.3066666666666664e-07,
      "logits/chosen": -2.3829095363616943,
      "logits/rejected": -1.915010690689087,
      "logps/chosen": -155.96482849121094,
      "logps/rejected": -196.80673217773438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7321960926055908,
      "rewards/margins": 10.80905532836914,
      "rewards/rejected": -12.541252136230469,
      "step": 5771
    },
    {
      "epoch": 2.3088,
      "grad_norm": 1.2752186059951782,
      "learning_rate": 2.3053333333333333e-07,
      "logits/chosen": -2.819838762283325,
      "logits/rejected": -2.66318941116333,
      "logps/chosen": -104.25556945800781,
      "logps/rejected": -95.91959381103516,
      "loss": 0.0084,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8491848111152649,
      "rewards/margins": 5.5561604499816895,
      "rewards/rejected": -6.4053449630737305,
      "step": 5772
    },
    {
      "epoch": 2.3092,
      "grad_norm": 0.09030955284833908,
      "learning_rate": 2.3039999999999997e-07,
      "logits/chosen": -2.86887788772583,
      "logits/rejected": -2.6503958702087402,
      "logps/chosen": -75.89067840576172,
      "logps/rejected": -117.41921997070312,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10315322875976562,
      "rewards/margins": 7.961341381072998,
      "rewards/rejected": -8.064495086669922,
      "step": 5773
    },
    {
      "epoch": 2.3096,
      "grad_norm": 0.0010715917451307178,
      "learning_rate": 2.3026666666666666e-07,
      "logits/chosen": -2.595147132873535,
      "logits/rejected": -1.7150179147720337,
      "logps/chosen": -107.81056213378906,
      "logps/rejected": -202.1126251220703,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3323274552822113,
      "rewards/margins": 13.215208053588867,
      "rewards/rejected": -12.882880210876465,
      "step": 5774
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.09623430669307709,
      "learning_rate": 2.3013333333333333e-07,
      "logits/chosen": -2.614896774291992,
      "logits/rejected": -2.308461904525757,
      "logps/chosen": -161.89248657226562,
      "logps/rejected": -119.86872863769531,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1631889343261719,
      "rewards/margins": 9.034368515014648,
      "rewards/rejected": -7.871179580688477,
      "step": 5775
    },
    {
      "epoch": 2.3104,
      "grad_norm": 0.28896602988243103,
      "learning_rate": 2.3e-07,
      "logits/chosen": -2.761157512664795,
      "logits/rejected": -2.299715518951416,
      "logps/chosen": -65.4859619140625,
      "logps/rejected": -117.2518081665039,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9557621479034424,
      "rewards/margins": 7.150456428527832,
      "rewards/rejected": -8.106218338012695,
      "step": 5776
    },
    {
      "epoch": 2.3108,
      "grad_norm": 0.10340177267789841,
      "learning_rate": 2.2986666666666666e-07,
      "logits/chosen": -2.5568628311157227,
      "logits/rejected": -2.317861795425415,
      "logps/chosen": -135.85665893554688,
      "logps/rejected": -160.51939392089844,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6463409662246704,
      "rewards/margins": 8.865743637084961,
      "rewards/rejected": -10.512084007263184,
      "step": 5777
    },
    {
      "epoch": 2.3112,
      "grad_norm": 95.69107055664062,
      "learning_rate": 2.2973333333333333e-07,
      "logits/chosen": -2.939389228820801,
      "logits/rejected": -2.6630101203918457,
      "logps/chosen": -114.88571166992188,
      "logps/rejected": -133.4012451171875,
      "loss": 1.3918,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -5.199406623840332,
      "rewards/margins": 3.7653656005859375,
      "rewards/rejected": -8.96477222442627,
      "step": 5778
    },
    {
      "epoch": 2.3116,
      "grad_norm": 1.3104791641235352,
      "learning_rate": 2.296e-07,
      "logits/chosen": -2.7286300659179688,
      "logits/rejected": -2.7636680603027344,
      "logps/chosen": -106.0136489868164,
      "logps/rejected": -105.1274185180664,
      "loss": 0.0119,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.3592848777770996,
      "rewards/margins": 4.488020420074463,
      "rewards/rejected": -6.8473052978515625,
      "step": 5779
    },
    {
      "epoch": 2.312,
      "grad_norm": 0.0013587052235379815,
      "learning_rate": 2.2946666666666666e-07,
      "logits/chosen": -2.5818874835968018,
      "logits/rejected": -1.8123325109481812,
      "logps/chosen": -63.93537521362305,
      "logps/rejected": -203.5829620361328,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08209800720214844,
      "rewards/margins": 12.867294311523438,
      "rewards/rejected": -12.785196304321289,
      "step": 5780
    },
    {
      "epoch": 2.3124000000000002,
      "grad_norm": 0.03771895170211792,
      "learning_rate": 2.2933333333333332e-07,
      "logits/chosen": -3.0392351150512695,
      "logits/rejected": -2.606348991394043,
      "logps/chosen": -48.646484375,
      "logps/rejected": -101.71881103515625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4772100448608398,
      "rewards/margins": 8.423948287963867,
      "rewards/rejected": -6.946737766265869,
      "step": 5781
    },
    {
      "epoch": 2.3128,
      "grad_norm": 0.014789888635277748,
      "learning_rate": 2.292e-07,
      "logits/chosen": -2.956268548965454,
      "logits/rejected": -2.406829595565796,
      "logps/chosen": -70.35234069824219,
      "logps/rejected": -167.82672119140625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1187212467193604,
      "rewards/margins": 10.72926139831543,
      "rewards/rejected": -11.847982406616211,
      "step": 5782
    },
    {
      "epoch": 2.3132,
      "grad_norm": 0.004972351249307394,
      "learning_rate": 2.2906666666666665e-07,
      "logits/chosen": -2.6525678634643555,
      "logits/rejected": -2.619739532470703,
      "logps/chosen": -101.5451889038086,
      "logps/rejected": -170.94801330566406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7476745843887329,
      "rewards/margins": 11.527104377746582,
      "rewards/rejected": -10.779430389404297,
      "step": 5783
    },
    {
      "epoch": 2.3136,
      "grad_norm": 0.09095024317502975,
      "learning_rate": 2.2893333333333332e-07,
      "logits/chosen": -2.3541784286499023,
      "logits/rejected": -1.8925743103027344,
      "logps/chosen": -100.00495147705078,
      "logps/rejected": -149.49029541015625,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.263888120651245,
      "rewards/margins": 7.708493232727051,
      "rewards/rejected": -9.972381591796875,
      "step": 5784
    },
    {
      "epoch": 2.314,
      "grad_norm": 0.419672429561615,
      "learning_rate": 2.2879999999999998e-07,
      "logits/chosen": -2.9958362579345703,
      "logits/rejected": -2.3846731185913086,
      "logps/chosen": -55.13792037963867,
      "logps/rejected": -134.89450073242188,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.19838076829910278,
      "rewards/margins": 8.666893005371094,
      "rewards/rejected": -8.865273475646973,
      "step": 5785
    },
    {
      "epoch": 2.3144,
      "grad_norm": 0.24871370196342468,
      "learning_rate": 2.2866666666666665e-07,
      "logits/chosen": -2.7054800987243652,
      "logits/rejected": -2.641421318054199,
      "logps/chosen": -45.92359161376953,
      "logps/rejected": -163.3689422607422,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4922988712787628,
      "rewards/margins": 10.988842010498047,
      "rewards/rejected": -11.481141090393066,
      "step": 5786
    },
    {
      "epoch": 2.3148,
      "grad_norm": 0.005276679992675781,
      "learning_rate": 2.2853333333333332e-07,
      "logits/chosen": -2.6513023376464844,
      "logits/rejected": -2.1312448978424072,
      "logps/chosen": -98.23055267333984,
      "logps/rejected": -169.58596801757812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0058249235153198,
      "rewards/margins": 10.793050765991211,
      "rewards/rejected": -11.79887580871582,
      "step": 5787
    },
    {
      "epoch": 2.3152,
      "grad_norm": 0.11665324121713638,
      "learning_rate": 2.2839999999999998e-07,
      "logits/chosen": -2.509212017059326,
      "logits/rejected": -2.1053266525268555,
      "logps/chosen": -67.14837646484375,
      "logps/rejected": -135.07135009765625,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5912151336669922,
      "rewards/margins": 8.066163063049316,
      "rewards/rejected": -7.474947929382324,
      "step": 5788
    },
    {
      "epoch": 2.3156,
      "grad_norm": 0.16865405440330505,
      "learning_rate": 2.2826666666666667e-07,
      "logits/chosen": -2.608309745788574,
      "logits/rejected": -1.8762116432189941,
      "logps/chosen": -98.73765563964844,
      "logps/rejected": -157.5789794921875,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4022748470306396,
      "rewards/margins": 8.548343658447266,
      "rewards/rejected": -9.950618743896484,
      "step": 5789
    },
    {
      "epoch": 2.316,
      "grad_norm": 1.1856149435043335,
      "learning_rate": 2.281333333333333e-07,
      "logits/chosen": -2.4016664028167725,
      "logits/rejected": -2.391639232635498,
      "logps/chosen": -72.45050811767578,
      "logps/rejected": -116.55767059326172,
      "loss": 0.0073,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7734501361846924,
      "rewards/margins": 5.59440803527832,
      "rewards/rejected": -7.367857933044434,
      "step": 5790
    },
    {
      "epoch": 2.3164,
      "grad_norm": 0.4463355243206024,
      "learning_rate": 2.28e-07,
      "logits/chosen": -2.5073628425598145,
      "logits/rejected": -1.9448814392089844,
      "logps/chosen": -235.59304809570312,
      "logps/rejected": -176.2498016357422,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.214240312576294,
      "rewards/margins": 9.984033584594727,
      "rewards/rejected": -11.198274612426758,
      "step": 5791
    },
    {
      "epoch": 2.3168,
      "grad_norm": 0.18250086903572083,
      "learning_rate": 2.2786666666666664e-07,
      "logits/chosen": -2.7855138778686523,
      "logits/rejected": -2.4262773990631104,
      "logps/chosen": -94.1329345703125,
      "logps/rejected": -173.149169921875,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.21579456329345703,
      "rewards/margins": 10.983569145202637,
      "rewards/rejected": -11.199363708496094,
      "step": 5792
    },
    {
      "epoch": 2.3172,
      "grad_norm": 0.043017733842134476,
      "learning_rate": 2.2773333333333333e-07,
      "logits/chosen": -2.5230648517608643,
      "logits/rejected": -2.1459126472473145,
      "logps/chosen": -95.42770385742188,
      "logps/rejected": -140.10377502441406,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.818734049797058,
      "rewards/margins": 10.007384300231934,
      "rewards/rejected": -8.188650131225586,
      "step": 5793
    },
    {
      "epoch": 2.3176,
      "grad_norm": 0.958984911441803,
      "learning_rate": 2.2759999999999997e-07,
      "logits/chosen": -2.761843681335449,
      "logits/rejected": -2.5326623916625977,
      "logps/chosen": -70.36830139160156,
      "logps/rejected": -182.0804443359375,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4496269226074219,
      "rewards/margins": 11.819976806640625,
      "rewards/rejected": -13.269603729248047,
      "step": 5794
    },
    {
      "epoch": 2.318,
      "grad_norm": 0.00011389546125428751,
      "learning_rate": 2.2746666666666667e-07,
      "logits/chosen": -2.3783013820648193,
      "logits/rejected": -1.897322416305542,
      "logps/chosen": -107.90966033935547,
      "logps/rejected": -197.18588256835938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.062856674194336,
      "rewards/margins": 14.983158111572266,
      "rewards/rejected": -13.92030143737793,
      "step": 5795
    },
    {
      "epoch": 2.3184,
      "grad_norm": 0.004854691214859486,
      "learning_rate": 2.2733333333333333e-07,
      "logits/chosen": -2.9439761638641357,
      "logits/rejected": -2.231318473815918,
      "logps/chosen": -58.49380874633789,
      "logps/rejected": -160.25161743164062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2961349487304688,
      "rewards/margins": 11.186616897583008,
      "rewards/rejected": -9.890481948852539,
      "step": 5796
    },
    {
      "epoch": 2.3188,
      "grad_norm": 0.033563029021024704,
      "learning_rate": 2.272e-07,
      "logits/chosen": -2.619884967803955,
      "logits/rejected": -2.166987419128418,
      "logps/chosen": -90.94949340820312,
      "logps/rejected": -152.28237915039062,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3032577633857727,
      "rewards/margins": 9.734704971313477,
      "rewards/rejected": -9.431447982788086,
      "step": 5797
    },
    {
      "epoch": 2.3192,
      "grad_norm": 0.13508498668670654,
      "learning_rate": 2.2706666666666666e-07,
      "logits/chosen": -2.8903722763061523,
      "logits/rejected": -2.4051342010498047,
      "logps/chosen": -38.085609436035156,
      "logps/rejected": -158.63516235351562,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7785074710845947,
      "rewards/margins": 11.514080047607422,
      "rewards/rejected": -9.735572814941406,
      "step": 5798
    },
    {
      "epoch": 2.3196,
      "grad_norm": 0.004399396944791079,
      "learning_rate": 2.269333333333333e-07,
      "logits/chosen": -2.8574795722961426,
      "logits/rejected": -2.4622645378112793,
      "logps/chosen": -80.67684936523438,
      "logps/rejected": -164.34536743164062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4171176850795746,
      "rewards/margins": 10.840313911437988,
      "rewards/rejected": -11.257431030273438,
      "step": 5799
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.08842664211988449,
      "learning_rate": 2.268e-07,
      "logits/chosen": -2.9114651679992676,
      "logits/rejected": -2.5278220176696777,
      "logps/chosen": -50.897483825683594,
      "logps/rejected": -134.22630310058594,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5959571599960327,
      "rewards/margins": 9.119523048400879,
      "rewards/rejected": -8.523565292358398,
      "step": 5800
    },
    {
      "epoch": 2.3204000000000002,
      "grad_norm": 0.399554044008255,
      "learning_rate": 2.2666666666666663e-07,
      "logits/chosen": -2.8091845512390137,
      "logits/rejected": -2.332099199295044,
      "logps/chosen": -104.40760803222656,
      "logps/rejected": -168.17977905273438,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7305832505226135,
      "rewards/margins": 10.474238395690918,
      "rewards/rejected": -11.204821586608887,
      "step": 5801
    },
    {
      "epoch": 2.3208,
      "grad_norm": 3.1310704798670486e-05,
      "learning_rate": 2.2653333333333332e-07,
      "logits/chosen": -2.8740057945251465,
      "logits/rejected": -2.1948161125183105,
      "logps/chosen": -74.95133972167969,
      "logps/rejected": -247.24627685546875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5508316159248352,
      "rewards/margins": 16.87397003173828,
      "rewards/rejected": -16.323137283325195,
      "step": 5802
    },
    {
      "epoch": 2.3212,
      "grad_norm": 0.0017900151433423162,
      "learning_rate": 2.264e-07,
      "logits/chosen": -2.8730294704437256,
      "logits/rejected": -2.3478643894195557,
      "logps/chosen": -95.61004638671875,
      "logps/rejected": -191.39663696289062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0943702682852745,
      "rewards/margins": 12.885202407836914,
      "rewards/rejected": -12.79083251953125,
      "step": 5803
    },
    {
      "epoch": 2.3216,
      "grad_norm": 0.000566760019864887,
      "learning_rate": 2.2626666666666665e-07,
      "logits/chosen": -2.80794620513916,
      "logits/rejected": -2.258021116256714,
      "logps/chosen": -85.50567626953125,
      "logps/rejected": -181.82058715820312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7572921514511108,
      "rewards/margins": 13.537229537963867,
      "rewards/rejected": -12.779937744140625,
      "step": 5804
    },
    {
      "epoch": 2.322,
      "grad_norm": 0.08554521948099136,
      "learning_rate": 2.2613333333333332e-07,
      "logits/chosen": -2.5774102210998535,
      "logits/rejected": -2.0917720794677734,
      "logps/chosen": -82.00260925292969,
      "logps/rejected": -156.70388793945312,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9396488666534424,
      "rewards/margins": 10.427661895751953,
      "rewards/rejected": -9.48801326751709,
      "step": 5805
    },
    {
      "epoch": 2.3224,
      "grad_norm": 0.44676080346107483,
      "learning_rate": 2.2599999999999999e-07,
      "logits/chosen": -2.701817750930786,
      "logits/rejected": -2.1874730587005615,
      "logps/chosen": -133.88540649414062,
      "logps/rejected": -127.73062133789062,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2001739740371704,
      "rewards/margins": 8.986929893493652,
      "rewards/rejected": -7.786755561828613,
      "step": 5806
    },
    {
      "epoch": 2.3228,
      "grad_norm": 7.516712188720703,
      "learning_rate": 2.2586666666666665e-07,
      "logits/chosen": -2.4476308822631836,
      "logits/rejected": -2.181551218032837,
      "logps/chosen": -89.78689575195312,
      "logps/rejected": -110.12002563476562,
      "loss": 0.0305,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0832778811454773,
      "rewards/margins": 5.695850372314453,
      "rewards/rejected": -5.779128551483154,
      "step": 5807
    },
    {
      "epoch": 2.3232,
      "grad_norm": 0.13935668766498566,
      "learning_rate": 2.2573333333333334e-07,
      "logits/chosen": -3.0385546684265137,
      "logits/rejected": -2.5512847900390625,
      "logps/chosen": -58.732635498046875,
      "logps/rejected": -127.46099090576172,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0775102376937866,
      "rewards/margins": 9.194461822509766,
      "rewards/rejected": -8.116951942443848,
      "step": 5808
    },
    {
      "epoch": 2.3236,
      "grad_norm": 0.05973414331674576,
      "learning_rate": 2.2559999999999998e-07,
      "logits/chosen": -2.84240984916687,
      "logits/rejected": -2.2689504623413086,
      "logps/chosen": -57.95283508300781,
      "logps/rejected": -113.7929916381836,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6026067733764648,
      "rewards/margins": 8.112626075744629,
      "rewards/rejected": -6.510019302368164,
      "step": 5809
    },
    {
      "epoch": 2.324,
      "grad_norm": 0.34904706478118896,
      "learning_rate": 2.2546666666666667e-07,
      "logits/chosen": -2.8389291763305664,
      "logits/rejected": -2.5865674018859863,
      "logps/chosen": -76.22651672363281,
      "logps/rejected": -95.8587875366211,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3197883665561676,
      "rewards/margins": 6.405589580535889,
      "rewards/rejected": -6.085801124572754,
      "step": 5810
    },
    {
      "epoch": 2.3244,
      "grad_norm": 0.0045749833807349205,
      "learning_rate": 2.253333333333333e-07,
      "logits/chosen": -2.4954452514648438,
      "logits/rejected": -2.097264051437378,
      "logps/chosen": -101.92207336425781,
      "logps/rejected": -197.87057495117188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2604801654815674,
      "rewards/margins": 12.688032150268555,
      "rewards/rejected": -12.42755126953125,
      "step": 5811
    },
    {
      "epoch": 2.3247999999999998,
      "grad_norm": 2.1558077335357666,
      "learning_rate": 2.252e-07,
      "logits/chosen": -2.6705310344696045,
      "logits/rejected": -2.0862202644348145,
      "logps/chosen": -178.72195434570312,
      "logps/rejected": -155.7838897705078,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.207667112350464,
      "rewards/margins": 7.082642555236816,
      "rewards/rejected": -9.29030990600586,
      "step": 5812
    },
    {
      "epoch": 2.3252,
      "grad_norm": 0.000600753235630691,
      "learning_rate": 2.2506666666666664e-07,
      "logits/chosen": -2.5882036685943604,
      "logits/rejected": -1.8116867542266846,
      "logps/chosen": -96.41079711914062,
      "logps/rejected": -174.71566772460938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.663658618927002,
      "rewards/margins": 12.893058776855469,
      "rewards/rejected": -10.229400634765625,
      "step": 5813
    },
    {
      "epoch": 2.3256,
      "grad_norm": 0.0012768974993377924,
      "learning_rate": 2.2493333333333334e-07,
      "logits/chosen": -2.543555974960327,
      "logits/rejected": -2.0427005290985107,
      "logps/chosen": -119.62376403808594,
      "logps/rejected": -217.51889038085938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6972931027412415,
      "rewards/margins": 12.738262176513672,
      "rewards/rejected": -13.435554504394531,
      "step": 5814
    },
    {
      "epoch": 2.326,
      "grad_norm": 0.013701758347451687,
      "learning_rate": 2.248e-07,
      "logits/chosen": -2.777883291244507,
      "logits/rejected": -2.5037479400634766,
      "logps/chosen": -111.52493286132812,
      "logps/rejected": -152.3359375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3848690390586853,
      "rewards/margins": 10.174703598022461,
      "rewards/rejected": -9.789834022521973,
      "step": 5815
    },
    {
      "epoch": 2.3264,
      "grad_norm": 0.07046367228031158,
      "learning_rate": 2.2466666666666664e-07,
      "logits/chosen": -3.017073154449463,
      "logits/rejected": -2.594456434249878,
      "logps/chosen": -43.42228698730469,
      "logps/rejected": -136.48219299316406,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7916780710220337,
      "rewards/margins": 9.507791519165039,
      "rewards/rejected": -8.716114044189453,
      "step": 5816
    },
    {
      "epoch": 2.3268,
      "grad_norm": 0.00446808896958828,
      "learning_rate": 2.2453333333333333e-07,
      "logits/chosen": -2.6761178970336914,
      "logits/rejected": -1.924323320388794,
      "logps/chosen": -128.05075073242188,
      "logps/rejected": -187.04669189453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9359962940216064,
      "rewards/margins": 13.676424980163574,
      "rewards/rejected": -12.740428924560547,
      "step": 5817
    },
    {
      "epoch": 2.3272,
      "grad_norm": 0.002707864623516798,
      "learning_rate": 2.2439999999999997e-07,
      "logits/chosen": -2.866461753845215,
      "logits/rejected": -2.529613971710205,
      "logps/chosen": -114.08094787597656,
      "logps/rejected": -225.71083068847656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4561122953891754,
      "rewards/margins": 13.147631645202637,
      "rewards/rejected": -12.691518783569336,
      "step": 5818
    },
    {
      "epoch": 2.3276,
      "grad_norm": 0.4013534188270569,
      "learning_rate": 2.2426666666666666e-07,
      "logits/chosen": -2.697394609451294,
      "logits/rejected": -2.462721347808838,
      "logps/chosen": -95.4113540649414,
      "logps/rejected": -130.12774658203125,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.685630202293396,
      "rewards/margins": 8.895780563354492,
      "rewards/rejected": -9.58141040802002,
      "step": 5819
    },
    {
      "epoch": 2.328,
      "grad_norm": 0.005109870806336403,
      "learning_rate": 2.241333333333333e-07,
      "logits/chosen": -2.8943638801574707,
      "logits/rejected": -2.459022045135498,
      "logps/chosen": -56.753421783447266,
      "logps/rejected": -197.7744598388672,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9950352311134338,
      "rewards/margins": 13.541159629821777,
      "rewards/rejected": -12.546124458312988,
      "step": 5820
    },
    {
      "epoch": 2.3284000000000002,
      "grad_norm": 82.08847045898438,
      "learning_rate": 2.24e-07,
      "logits/chosen": -2.719449996948242,
      "logits/rejected": -2.5891542434692383,
      "logps/chosen": -235.86537170410156,
      "logps/rejected": -73.92046356201172,
      "loss": 0.4849,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -4.2605133056640625,
      "rewards/margins": 0.7876812219619751,
      "rewards/rejected": -5.048194408416748,
      "step": 5821
    },
    {
      "epoch": 2.3288,
      "grad_norm": 0.036846742033958435,
      "learning_rate": 2.2386666666666666e-07,
      "logits/chosen": -2.908442497253418,
      "logits/rejected": -2.4376344680786133,
      "logps/chosen": -102.3531494140625,
      "logps/rejected": -149.82540893554688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.023081183433532715,
      "rewards/margins": 8.984960556030273,
      "rewards/rejected": -8.96187973022461,
      "step": 5822
    },
    {
      "epoch": 2.3292,
      "grad_norm": 0.0003410496865399182,
      "learning_rate": 2.2373333333333333e-07,
      "logits/chosen": -2.745328426361084,
      "logits/rejected": -2.1761224269866943,
      "logps/chosen": -104.48580169677734,
      "logps/rejected": -212.7198944091797,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9012959003448486,
      "rewards/margins": 14.023998260498047,
      "rewards/rejected": -13.122702598571777,
      "step": 5823
    },
    {
      "epoch": 2.3296,
      "grad_norm": 0.01370178535580635,
      "learning_rate": 2.236e-07,
      "logits/chosen": -2.9515368938446045,
      "logits/rejected": -2.4756064414978027,
      "logps/chosen": -68.48567199707031,
      "logps/rejected": -144.60293579101562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7160711288452148,
      "rewards/margins": 9.919343948364258,
      "rewards/rejected": -9.203271865844727,
      "step": 5824
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.0017583672888576984,
      "learning_rate": 2.2346666666666666e-07,
      "logits/chosen": -2.502458095550537,
      "logits/rejected": -2.01236629486084,
      "logps/chosen": -141.12564086914062,
      "logps/rejected": -188.2421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2160232663154602,
      "rewards/margins": 12.33309555053711,
      "rewards/rejected": -12.549118041992188,
      "step": 5825
    },
    {
      "epoch": 2.3304,
      "grad_norm": 0.0054004439152777195,
      "learning_rate": 2.2333333333333332e-07,
      "logits/chosen": -2.472438335418701,
      "logits/rejected": -1.719963550567627,
      "logps/chosen": -118.83334350585938,
      "logps/rejected": -153.70396423339844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.413913369178772,
      "rewards/margins": 11.309869766235352,
      "rewards/rejected": -9.895956039428711,
      "step": 5826
    },
    {
      "epoch": 2.3308,
      "grad_norm": 0.04593656212091446,
      "learning_rate": 2.232e-07,
      "logits/chosen": -2.8235926628112793,
      "logits/rejected": -2.393141746520996,
      "logps/chosen": -94.06409454345703,
      "logps/rejected": -214.82623291015625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7870754599571228,
      "rewards/margins": 12.326444625854492,
      "rewards/rejected": -13.113519668579102,
      "step": 5827
    },
    {
      "epoch": 2.3312,
      "grad_norm": 0.022880572825670242,
      "learning_rate": 2.2306666666666665e-07,
      "logits/chosen": -2.788672685623169,
      "logits/rejected": -2.5729355812072754,
      "logps/chosen": -124.84611511230469,
      "logps/rejected": -165.45083618164062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5705513954162598,
      "rewards/margins": 9.532526969909668,
      "rewards/rejected": -11.103078842163086,
      "step": 5828
    },
    {
      "epoch": 2.3316,
      "grad_norm": 0.017544422298669815,
      "learning_rate": 2.2293333333333334e-07,
      "logits/chosen": -2.4479434490203857,
      "logits/rejected": -1.8757038116455078,
      "logps/chosen": -253.20660400390625,
      "logps/rejected": -178.9244384765625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8810272216796875,
      "rewards/margins": 9.431892395019531,
      "rewards/rejected": -10.312919616699219,
      "step": 5829
    },
    {
      "epoch": 2.332,
      "grad_norm": 0.12649349868297577,
      "learning_rate": 2.2279999999999998e-07,
      "logits/chosen": -2.597107172012329,
      "logits/rejected": -2.040717601776123,
      "logps/chosen": -173.69842529296875,
      "logps/rejected": -132.9693603515625,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.05274486541748047,
      "rewards/margins": 9.421262741088867,
      "rewards/rejected": -9.474007606506348,
      "step": 5830
    },
    {
      "epoch": 2.3324,
      "grad_norm": 0.013169776648283005,
      "learning_rate": 2.2266666666666668e-07,
      "logits/chosen": -2.844583034515381,
      "logits/rejected": -2.7599592208862305,
      "logps/chosen": -49.03809356689453,
      "logps/rejected": -150.12945556640625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2155027389526367,
      "rewards/margins": 10.69843864440918,
      "rewards/rejected": -9.482934951782227,
      "step": 5831
    },
    {
      "epoch": 2.3327999999999998,
      "grad_norm": 0.005136278923600912,
      "learning_rate": 2.2253333333333331e-07,
      "logits/chosen": -2.450657367706299,
      "logits/rejected": -1.7858779430389404,
      "logps/chosen": -141.52952575683594,
      "logps/rejected": -240.3621826171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0521141290664673,
      "rewards/margins": 17.351511001586914,
      "rewards/rejected": -16.29939842224121,
      "step": 5832
    },
    {
      "epoch": 2.3332,
      "grad_norm": 0.09024850279092789,
      "learning_rate": 2.2239999999999998e-07,
      "logits/chosen": -2.8031764030456543,
      "logits/rejected": -2.3433382511138916,
      "logps/chosen": -92.33575439453125,
      "logps/rejected": -140.0979766845703,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9419040679931641,
      "rewards/margins": 8.36494255065918,
      "rewards/rejected": -9.306846618652344,
      "step": 5833
    },
    {
      "epoch": 2.3336,
      "grad_norm": 0.003301735268905759,
      "learning_rate": 2.2226666666666665e-07,
      "logits/chosen": -2.599928379058838,
      "logits/rejected": -1.6644246578216553,
      "logps/chosen": -76.00640869140625,
      "logps/rejected": -183.541015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0809558629989624,
      "rewards/margins": 12.156370162963867,
      "rewards/rejected": -11.075414657592773,
      "step": 5834
    },
    {
      "epoch": 2.334,
      "grad_norm": 0.6100400686264038,
      "learning_rate": 2.221333333333333e-07,
      "logits/chosen": -2.8718302249908447,
      "logits/rejected": -2.743159770965576,
      "logps/chosen": -124.60726928710938,
      "logps/rejected": -128.6175994873047,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6947933435440063,
      "rewards/margins": 8.790071487426758,
      "rewards/rejected": -9.484865188598633,
      "step": 5835
    },
    {
      "epoch": 2.3344,
      "grad_norm": 0.03565804660320282,
      "learning_rate": 2.22e-07,
      "logits/chosen": -2.312897205352783,
      "logits/rejected": -1.533250093460083,
      "logps/chosen": -125.4700698852539,
      "logps/rejected": -182.78961181640625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.06147038936615,
      "rewards/margins": 13.491756439208984,
      "rewards/rejected": -12.430286407470703,
      "step": 5836
    },
    {
      "epoch": 2.3348,
      "grad_norm": 0.0007950005820021033,
      "learning_rate": 2.2186666666666664e-07,
      "logits/chosen": -2.5193028450012207,
      "logits/rejected": -1.773608922958374,
      "logps/chosen": -115.41361236572266,
      "logps/rejected": -202.7921905517578,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5566818714141846,
      "rewards/margins": 13.40787124633789,
      "rewards/rejected": -12.851188659667969,
      "step": 5837
    },
    {
      "epoch": 2.3352,
      "grad_norm": 2.3990038243937306e-05,
      "learning_rate": 2.2173333333333333e-07,
      "logits/chosen": -2.694507598876953,
      "logits/rejected": -2.3832502365112305,
      "logps/chosen": -98.95266723632812,
      "logps/rejected": -219.82774353027344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.940146267414093,
      "rewards/margins": 16.979461669921875,
      "rewards/rejected": -16.03931427001953,
      "step": 5838
    },
    {
      "epoch": 2.3356,
      "grad_norm": 0.5686696171760559,
      "learning_rate": 2.2159999999999997e-07,
      "logits/chosen": -2.9049320220947266,
      "logits/rejected": -2.4662230014801025,
      "logps/chosen": -102.44591522216797,
      "logps/rejected": -137.2748565673828,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2016586065292358,
      "rewards/margins": 7.700972557067871,
      "rewards/rejected": -8.902631759643555,
      "step": 5839
    },
    {
      "epoch": 2.336,
      "grad_norm": 18.079877853393555,
      "learning_rate": 2.2146666666666666e-07,
      "logits/chosen": -2.5894622802734375,
      "logits/rejected": -2.669386386871338,
      "logps/chosen": -75.95636749267578,
      "logps/rejected": -133.52928161621094,
      "loss": 0.1095,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2648452520370483,
      "rewards/margins": 7.282217502593994,
      "rewards/rejected": -8.547062873840332,
      "step": 5840
    },
    {
      "epoch": 2.3364,
      "grad_norm": 9.63319034781307e-05,
      "learning_rate": 2.213333333333333e-07,
      "logits/chosen": -2.7463040351867676,
      "logits/rejected": -1.690487265586853,
      "logps/chosen": -74.69844818115234,
      "logps/rejected": -219.27835083007812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9438285827636719,
      "rewards/margins": 16.402326583862305,
      "rewards/rejected": -14.458498001098633,
      "step": 5841
    },
    {
      "epoch": 2.3368,
      "grad_norm": 4.503872871398926,
      "learning_rate": 2.212e-07,
      "logits/chosen": -2.494227886199951,
      "logits/rejected": -1.8841564655303955,
      "logps/chosen": -188.94139099121094,
      "logps/rejected": -181.02883911132812,
      "loss": 0.0191,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.359433650970459,
      "rewards/margins": 7.838125705718994,
      "rewards/rejected": -12.197559356689453,
      "step": 5842
    },
    {
      "epoch": 2.3372,
      "grad_norm": 0.06956648081541061,
      "learning_rate": 2.2106666666666666e-07,
      "logits/chosen": -2.6646153926849365,
      "logits/rejected": -1.8821840286254883,
      "logps/chosen": -74.61871337890625,
      "logps/rejected": -154.11282348632812,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32486075162887573,
      "rewards/margins": 9.47818374633789,
      "rewards/rejected": -9.15332317352295,
      "step": 5843
    },
    {
      "epoch": 2.3376,
      "grad_norm": 0.3724101781845093,
      "learning_rate": 2.2093333333333333e-07,
      "logits/chosen": -2.559933662414551,
      "logits/rejected": -1.8801721334457397,
      "logps/chosen": -77.49990844726562,
      "logps/rejected": -137.48817443847656,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0586121082305908,
      "rewards/margins": 8.912948608398438,
      "rewards/rejected": -7.854336738586426,
      "step": 5844
    },
    {
      "epoch": 2.338,
      "grad_norm": 12.306121826171875,
      "learning_rate": 2.208e-07,
      "logits/chosen": -2.8161416053771973,
      "logits/rejected": -2.620213031768799,
      "logps/chosen": -119.5356216430664,
      "logps/rejected": -83.26863098144531,
      "loss": 0.0674,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8410277366638184,
      "rewards/margins": 3.1062734127044678,
      "rewards/rejected": -4.947300910949707,
      "step": 5845
    },
    {
      "epoch": 2.3384,
      "grad_norm": 0.01806989125907421,
      "learning_rate": 2.2066666666666666e-07,
      "logits/chosen": -2.217156410217285,
      "logits/rejected": -1.3944950103759766,
      "logps/chosen": -114.94503784179688,
      "logps/rejected": -174.67950439453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9020488858222961,
      "rewards/margins": 10.752376556396484,
      "rewards/rejected": -9.850326538085938,
      "step": 5846
    },
    {
      "epoch": 2.3388,
      "grad_norm": 0.0229914803057909,
      "learning_rate": 2.2053333333333332e-07,
      "logits/chosen": -2.749943733215332,
      "logits/rejected": -2.2431163787841797,
      "logps/chosen": -207.68405151367188,
      "logps/rejected": -204.7097930908203,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6020538806915283,
      "rewards/margins": 10.002541542053223,
      "rewards/rejected": -11.604595184326172,
      "step": 5847
    },
    {
      "epoch": 2.3392,
      "grad_norm": 0.0347476601600647,
      "learning_rate": 2.2040000000000001e-07,
      "logits/chosen": -2.261256217956543,
      "logits/rejected": -1.90696382522583,
      "logps/chosen": -183.02615356445312,
      "logps/rejected": -171.02874755859375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.906407356262207,
      "rewards/margins": 9.009698867797852,
      "rewards/rejected": -11.916105270385742,
      "step": 5848
    },
    {
      "epoch": 2.3396,
      "grad_norm": 0.0879640281200409,
      "learning_rate": 2.2026666666666665e-07,
      "logits/chosen": -2.578714370727539,
      "logits/rejected": -2.034619092941284,
      "logps/chosen": -86.23980712890625,
      "logps/rejected": -173.70782470703125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.270255446434021,
      "rewards/margins": 10.402891159057617,
      "rewards/rejected": -10.132635116577148,
      "step": 5849
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.03850099816918373,
      "learning_rate": 2.2013333333333332e-07,
      "logits/chosen": -2.583251476287842,
      "logits/rejected": -2.033008575439453,
      "logps/chosen": -108.34806823730469,
      "logps/rejected": -166.4465789794922,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6285443305969238,
      "rewards/margins": 9.884736061096191,
      "rewards/rejected": -11.513280868530273,
      "step": 5850
    },
    {
      "epoch": 2.3404,
      "grad_norm": 0.001511018956080079,
      "learning_rate": 2.1999999999999998e-07,
      "logits/chosen": -2.7928571701049805,
      "logits/rejected": -1.8439395427703857,
      "logps/chosen": -65.96682739257812,
      "logps/rejected": -259.4615478515625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6726465821266174,
      "rewards/margins": 14.737190246582031,
      "rewards/rejected": -14.064544677734375,
      "step": 5851
    },
    {
      "epoch": 2.3407999999999998,
      "grad_norm": 6.836625107098371e-05,
      "learning_rate": 2.1986666666666665e-07,
      "logits/chosen": -2.6617941856384277,
      "logits/rejected": -2.1803369522094727,
      "logps/chosen": -116.41790771484375,
      "logps/rejected": -232.02975463867188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2325845956802368,
      "rewards/margins": 15.340658187866211,
      "rewards/rejected": -16.573244094848633,
      "step": 5852
    },
    {
      "epoch": 2.3412,
      "grad_norm": 0.004803486168384552,
      "learning_rate": 2.1973333333333332e-07,
      "logits/chosen": -2.4542346000671387,
      "logits/rejected": -1.6124216318130493,
      "logps/chosen": -110.29115295410156,
      "logps/rejected": -207.0016326904297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.631500244140625,
      "rewards/margins": 11.369173049926758,
      "rewards/rejected": -12.000673294067383,
      "step": 5853
    },
    {
      "epoch": 2.3416,
      "grad_norm": 0.0008796182810328901,
      "learning_rate": 2.1959999999999998e-07,
      "logits/chosen": -2.3567633628845215,
      "logits/rejected": -1.462984323501587,
      "logps/chosen": -164.118896484375,
      "logps/rejected": -214.55780029296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9082584977149963,
      "rewards/margins": 14.277722358703613,
      "rewards/rejected": -13.369464874267578,
      "step": 5854
    },
    {
      "epoch": 2.342,
      "grad_norm": 0.01495099812746048,
      "learning_rate": 2.1946666666666667e-07,
      "logits/chosen": -2.5789732933044434,
      "logits/rejected": -2.1289377212524414,
      "logps/chosen": -107.09742736816406,
      "logps/rejected": -122.08169555664062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8519864082336426,
      "rewards/margins": 10.302705764770508,
      "rewards/rejected": -8.450718879699707,
      "step": 5855
    },
    {
      "epoch": 2.3424,
      "grad_norm": 0.005382101517170668,
      "learning_rate": 2.193333333333333e-07,
      "logits/chosen": -2.2195894718170166,
      "logits/rejected": -1.7237038612365723,
      "logps/chosen": -111.12646484375,
      "logps/rejected": -151.9955596923828,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7518284320831299,
      "rewards/margins": 10.939413070678711,
      "rewards/rejected": -9.187583923339844,
      "step": 5856
    },
    {
      "epoch": 2.3428,
      "grad_norm": 5.603859244729392e-05,
      "learning_rate": 2.192e-07,
      "logits/chosen": -2.4354701042175293,
      "logits/rejected": -1.9968243837356567,
      "logps/chosen": -182.546142578125,
      "logps/rejected": -256.15960693359375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2741661071777344,
      "rewards/margins": 15.718536376953125,
      "rewards/rejected": -16.99270248413086,
      "step": 5857
    },
    {
      "epoch": 2.3432,
      "grad_norm": 0.022303767502307892,
      "learning_rate": 2.1906666666666664e-07,
      "logits/chosen": -2.056074857711792,
      "logits/rejected": -1.8370468616485596,
      "logps/chosen": -164.021728515625,
      "logps/rejected": -140.08421325683594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0180373191833496,
      "rewards/margins": 9.715194702148438,
      "rewards/rejected": -8.69715690612793,
      "step": 5858
    },
    {
      "epoch": 2.3436,
      "grad_norm": 0.008038979955017567,
      "learning_rate": 2.1893333333333334e-07,
      "logits/chosen": -2.634943962097168,
      "logits/rejected": -2.1034746170043945,
      "logps/chosen": -52.94602966308594,
      "logps/rejected": -173.03683471679688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0482382774353027,
      "rewards/margins": 12.706012725830078,
      "rewards/rejected": -10.65777587890625,
      "step": 5859
    },
    {
      "epoch": 2.344,
      "grad_norm": 0.2923606038093567,
      "learning_rate": 2.1879999999999997e-07,
      "logits/chosen": -2.3280587196350098,
      "logits/rejected": -1.771073579788208,
      "logps/chosen": -102.72826385498047,
      "logps/rejected": -128.60391235351562,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2338041067123413,
      "rewards/margins": 6.6060895919799805,
      "rewards/rejected": -7.839893341064453,
      "step": 5860
    },
    {
      "epoch": 2.3444,
      "grad_norm": 0.0004986188723705709,
      "learning_rate": 2.1866666666666667e-07,
      "logits/chosen": -2.3899712562561035,
      "logits/rejected": -1.3569386005401611,
      "logps/chosen": -112.54230499267578,
      "logps/rejected": -220.0441436767578,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0978012084960938,
      "rewards/margins": 15.523472785949707,
      "rewards/rejected": -13.425671577453613,
      "step": 5861
    },
    {
      "epoch": 2.3448,
      "grad_norm": 0.2656617760658264,
      "learning_rate": 2.1853333333333333e-07,
      "logits/chosen": -2.5354108810424805,
      "logits/rejected": -1.7036943435668945,
      "logps/chosen": -100.24710845947266,
      "logps/rejected": -159.16477966308594,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5263391733169556,
      "rewards/margins": 9.1942138671875,
      "rewards/rejected": -9.720552444458008,
      "step": 5862
    },
    {
      "epoch": 2.3452,
      "grad_norm": 0.015912126749753952,
      "learning_rate": 2.184e-07,
      "logits/chosen": -2.7254133224487305,
      "logits/rejected": -2.4807534217834473,
      "logps/chosen": -101.07904052734375,
      "logps/rejected": -172.6595458984375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3129669427871704,
      "rewards/margins": 12.264532089233398,
      "rewards/rejected": -11.95156478881836,
      "step": 5863
    },
    {
      "epoch": 2.3456,
      "grad_norm": 0.015192179009318352,
      "learning_rate": 2.1826666666666666e-07,
      "logits/chosen": -2.651193618774414,
      "logits/rejected": -2.2793877124786377,
      "logps/chosen": -99.27072143554688,
      "logps/rejected": -184.96217346191406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4604568481445312,
      "rewards/margins": 9.874542236328125,
      "rewards/rejected": -11.334999084472656,
      "step": 5864
    },
    {
      "epoch": 2.346,
      "grad_norm": 6.37948905932717e-05,
      "learning_rate": 2.1813333333333333e-07,
      "logits/chosen": -2.282439708709717,
      "logits/rejected": -1.417599081993103,
      "logps/chosen": -93.84425354003906,
      "logps/rejected": -213.19110107421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.217995047569275,
      "rewards/margins": 16.042757034301758,
      "rewards/rejected": -14.824762344360352,
      "step": 5865
    },
    {
      "epoch": 2.3464,
      "grad_norm": 0.2795184254646301,
      "learning_rate": 2.18e-07,
      "logits/chosen": -2.1632273197174072,
      "logits/rejected": -1.8902318477630615,
      "logps/chosen": -182.61175537109375,
      "logps/rejected": -167.95767211914062,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6953620910644531,
      "rewards/margins": 8.624950408935547,
      "rewards/rejected": -9.3203125,
      "step": 5866
    },
    {
      "epoch": 2.3468,
      "grad_norm": 0.24887017905712128,
      "learning_rate": 2.1786666666666663e-07,
      "logits/chosen": -2.487335681915283,
      "logits/rejected": -1.8480029106140137,
      "logps/chosen": -118.26180267333984,
      "logps/rejected": -155.63890075683594,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.242381289601326,
      "rewards/margins": 9.376047134399414,
      "rewards/rejected": -9.618428230285645,
      "step": 5867
    },
    {
      "epoch": 2.3472,
      "grad_norm": 0.005696939770132303,
      "learning_rate": 2.1773333333333332e-07,
      "logits/chosen": -2.4835972785949707,
      "logits/rejected": -2.0171585083007812,
      "logps/chosen": -77.608642578125,
      "logps/rejected": -191.80447387695312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08160629868507385,
      "rewards/margins": 12.511626243591309,
      "rewards/rejected": -12.43001937866211,
      "step": 5868
    },
    {
      "epoch": 2.3476,
      "grad_norm": 0.4636397063732147,
      "learning_rate": 2.176e-07,
      "logits/chosen": -3.02114200592041,
      "logits/rejected": -2.7897841930389404,
      "logps/chosen": -87.4136962890625,
      "logps/rejected": -204.39329528808594,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7040109634399414,
      "rewards/margins": 12.69158935546875,
      "rewards/rejected": -13.395599365234375,
      "step": 5869
    },
    {
      "epoch": 2.348,
      "grad_norm": 0.0330553874373436,
      "learning_rate": 2.1746666666666666e-07,
      "logits/chosen": -2.221238136291504,
      "logits/rejected": -1.6456682682037354,
      "logps/chosen": -131.44064331054688,
      "logps/rejected": -208.05010986328125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.730508029460907,
      "rewards/margins": 10.514120101928711,
      "rewards/rejected": -9.783612251281738,
      "step": 5870
    },
    {
      "epoch": 2.3484,
      "grad_norm": 0.01918957382440567,
      "learning_rate": 2.1733333333333332e-07,
      "logits/chosen": -2.547081470489502,
      "logits/rejected": -2.1099023818969727,
      "logps/chosen": -71.31796264648438,
      "logps/rejected": -157.56146240234375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2974386215209961,
      "rewards/margins": 9.875150680541992,
      "rewards/rejected": -9.577712059020996,
      "step": 5871
    },
    {
      "epoch": 2.3487999999999998,
      "grad_norm": 0.12031456083059311,
      "learning_rate": 2.1719999999999999e-07,
      "logits/chosen": -2.6171927452087402,
      "logits/rejected": -2.187138557434082,
      "logps/chosen": -85.0718765258789,
      "logps/rejected": -148.00238037109375,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8151319622993469,
      "rewards/margins": 10.69806957244873,
      "rewards/rejected": -9.88293743133545,
      "step": 5872
    },
    {
      "epoch": 2.3492,
      "grad_norm": 0.25340813398361206,
      "learning_rate": 2.1706666666666665e-07,
      "logits/chosen": -2.4388716220855713,
      "logits/rejected": -2.4833860397338867,
      "logps/chosen": -100.36356353759766,
      "logps/rejected": -98.01263427734375,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0325918197631836,
      "rewards/margins": 7.540314674377441,
      "rewards/rejected": -6.507722854614258,
      "step": 5873
    },
    {
      "epoch": 2.3496,
      "grad_norm": 0.13898877799510956,
      "learning_rate": 2.1693333333333332e-07,
      "logits/chosen": -2.504185199737549,
      "logits/rejected": -2.0739970207214355,
      "logps/chosen": -148.0641632080078,
      "logps/rejected": -134.89761352539062,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.194648027420044,
      "rewards/margins": 7.654220104217529,
      "rewards/rejected": -8.848868370056152,
      "step": 5874
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.6234474182128906,
      "learning_rate": 2.1679999999999998e-07,
      "logits/chosen": -2.702813148498535,
      "logits/rejected": -2.827667236328125,
      "logps/chosen": -56.36855697631836,
      "logps/rejected": -118.93209838867188,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2195237874984741,
      "rewards/margins": 7.3502888679504395,
      "rewards/rejected": -6.130764961242676,
      "step": 5875
    },
    {
      "epoch": 2.3504,
      "grad_norm": 0.004260615911334753,
      "learning_rate": 2.1666666666666667e-07,
      "logits/chosen": -2.6757829189300537,
      "logits/rejected": -1.680912971496582,
      "logps/chosen": -137.84568786621094,
      "logps/rejected": -198.3988800048828,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9095901846885681,
      "rewards/margins": 11.662822723388672,
      "rewards/rejected": -10.753232955932617,
      "step": 5876
    },
    {
      "epoch": 2.3508,
      "grad_norm": 98.20108795166016,
      "learning_rate": 2.1653333333333331e-07,
      "logits/chosen": -1.771751880645752,
      "logits/rejected": -1.424006462097168,
      "logps/chosen": -324.6980285644531,
      "logps/rejected": -147.3271026611328,
      "loss": 0.6343,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -9.225625038146973,
      "rewards/margins": 0.47440552711486816,
      "rewards/rejected": -9.700030326843262,
      "step": 5877
    },
    {
      "epoch": 2.3512,
      "grad_norm": 0.06005354970693588,
      "learning_rate": 2.164e-07,
      "logits/chosen": -2.463481903076172,
      "logits/rejected": -2.0964818000793457,
      "logps/chosen": -55.81550216674805,
      "logps/rejected": -214.37179565429688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20450395345687866,
      "rewards/margins": 12.750139236450195,
      "rewards/rejected": -12.545635223388672,
      "step": 5878
    },
    {
      "epoch": 2.3516,
      "grad_norm": 0.001914394786581397,
      "learning_rate": 2.1626666666666664e-07,
      "logits/chosen": -2.511256217956543,
      "logits/rejected": -1.975799798965454,
      "logps/chosen": -59.28249740600586,
      "logps/rejected": -229.9052734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.30208510160446167,
      "rewards/margins": 14.889705657958984,
      "rewards/rejected": -14.587621688842773,
      "step": 5879
    },
    {
      "epoch": 2.352,
      "grad_norm": 0.0018400608096271753,
      "learning_rate": 2.1613333333333334e-07,
      "logits/chosen": -2.699948787689209,
      "logits/rejected": -2.3695902824401855,
      "logps/chosen": -93.03684997558594,
      "logps/rejected": -218.7513885498047,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1130573749542236,
      "rewards/margins": 13.871282577514648,
      "rewards/rejected": -14.98434066772461,
      "step": 5880
    },
    {
      "epoch": 2.3524,
      "grad_norm": 0.0823286697268486,
      "learning_rate": 2.1599999999999998e-07,
      "logits/chosen": -2.651865005493164,
      "logits/rejected": -2.03005313873291,
      "logps/chosen": -109.71495056152344,
      "logps/rejected": -157.4859619140625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0562405586242676,
      "rewards/margins": 12.345663070678711,
      "rewards/rejected": -11.289422035217285,
      "step": 5881
    },
    {
      "epoch": 2.3528000000000002,
      "grad_norm": 1.9675956964492798,
      "learning_rate": 2.1586666666666667e-07,
      "logits/chosen": -2.8920845985412598,
      "logits/rejected": -3.128852367401123,
      "logps/chosen": -75.56314086914062,
      "logps/rejected": -72.8204345703125,
      "loss": 0.0172,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.41403427720069885,
      "rewards/margins": 4.202580451965332,
      "rewards/rejected": -4.616614818572998,
      "step": 5882
    },
    {
      "epoch": 2.3532,
      "grad_norm": 0.0003692985337693244,
      "learning_rate": 2.1573333333333333e-07,
      "logits/chosen": -2.682028293609619,
      "logits/rejected": -1.986496925354004,
      "logps/chosen": -89.46249389648438,
      "logps/rejected": -186.5388641357422,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3973941802978516,
      "rewards/margins": 13.675880432128906,
      "rewards/rejected": -12.278486251831055,
      "step": 5883
    },
    {
      "epoch": 2.3536,
      "grad_norm": 0.04966161772608757,
      "learning_rate": 2.156e-07,
      "logits/chosen": -2.421508312225342,
      "logits/rejected": -2.169637441635132,
      "logps/chosen": -74.54125213623047,
      "logps/rejected": -146.02772521972656,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4722133874893188,
      "rewards/margins": 9.832786560058594,
      "rewards/rejected": -8.360572814941406,
      "step": 5884
    },
    {
      "epoch": 2.354,
      "grad_norm": 0.0031291414052248,
      "learning_rate": 2.1546666666666666e-07,
      "logits/chosen": -2.4126973152160645,
      "logits/rejected": -1.7987070083618164,
      "logps/chosen": -102.13404846191406,
      "logps/rejected": -176.11050415039062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7789887189865112,
      "rewards/margins": 11.807947158813477,
      "rewards/rejected": -10.028959274291992,
      "step": 5885
    },
    {
      "epoch": 2.3544,
      "grad_norm": 4.174286365509033,
      "learning_rate": 2.153333333333333e-07,
      "logits/chosen": -3.0041255950927734,
      "logits/rejected": -2.6984241008758545,
      "logps/chosen": -73.78311157226562,
      "logps/rejected": -84.89241027832031,
      "loss": 0.0216,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08008420467376709,
      "rewards/margins": 5.470929145812988,
      "rewards/rejected": -5.551012992858887,
      "step": 5886
    },
    {
      "epoch": 2.3548,
      "grad_norm": 0.09144477546215057,
      "learning_rate": 2.152e-07,
      "logits/chosen": -2.7501578330993652,
      "logits/rejected": -2.2898340225219727,
      "logps/chosen": -38.35148620605469,
      "logps/rejected": -110.02365112304688,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9170265197753906,
      "rewards/margins": 8.155194282531738,
      "rewards/rejected": -7.238167762756348,
      "step": 5887
    },
    {
      "epoch": 2.3552,
      "grad_norm": 0.00226631760597229,
      "learning_rate": 2.1506666666666663e-07,
      "logits/chosen": -2.7203125953674316,
      "logits/rejected": -2.0659406185150146,
      "logps/chosen": -94.21678924560547,
      "logps/rejected": -229.25372314453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9304531812667847,
      "rewards/margins": 13.856424331665039,
      "rewards/rejected": -12.925971984863281,
      "step": 5888
    },
    {
      "epoch": 2.3556,
      "grad_norm": 0.06922279298305511,
      "learning_rate": 2.1493333333333333e-07,
      "logits/chosen": -2.676553726196289,
      "logits/rejected": -2.422767162322998,
      "logps/chosen": -74.61436462402344,
      "logps/rejected": -121.38752746582031,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08587570488452911,
      "rewards/margins": 8.213502883911133,
      "rewards/rejected": -8.1276273727417,
      "step": 5889
    },
    {
      "epoch": 2.356,
      "grad_norm": 0.3257693946361542,
      "learning_rate": 2.148e-07,
      "logits/chosen": -2.7633426189422607,
      "logits/rejected": -2.733595371246338,
      "logps/chosen": -77.00801086425781,
      "logps/rejected": -106.15730285644531,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0668294429779053,
      "rewards/margins": 6.233878135681152,
      "rewards/rejected": -7.3007073402404785,
      "step": 5890
    },
    {
      "epoch": 2.3564,
      "grad_norm": 0.0030057490803301334,
      "learning_rate": 2.1466666666666666e-07,
      "logits/chosen": -2.9045958518981934,
      "logits/rejected": -2.23742938041687,
      "logps/chosen": -82.02639770507812,
      "logps/rejected": -169.094970703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0804237127304077,
      "rewards/margins": 12.54638385772705,
      "rewards/rejected": -11.465959548950195,
      "step": 5891
    },
    {
      "epoch": 2.3568,
      "grad_norm": 0.7866794466972351,
      "learning_rate": 2.1453333333333332e-07,
      "logits/chosen": -2.911147117614746,
      "logits/rejected": -3.080012321472168,
      "logps/chosen": -62.691734313964844,
      "logps/rejected": -155.59011840820312,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0609476566314697,
      "rewards/margins": 9.272262573242188,
      "rewards/rejected": -8.211315155029297,
      "step": 5892
    },
    {
      "epoch": 2.3572,
      "grad_norm": 0.0005796070909127593,
      "learning_rate": 2.144e-07,
      "logits/chosen": -3.146146297454834,
      "logits/rejected": -2.7411608695983887,
      "logps/chosen": -64.64482116699219,
      "logps/rejected": -198.47512817382812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8411834836006165,
      "rewards/margins": 13.3799409866333,
      "rewards/rejected": -12.53875732421875,
      "step": 5893
    },
    {
      "epoch": 2.3576,
      "grad_norm": 9.125092037720606e-05,
      "learning_rate": 2.1426666666666665e-07,
      "logits/chosen": -2.536005735397339,
      "logits/rejected": -1.7999622821807861,
      "logps/chosen": -138.47293090820312,
      "logps/rejected": -305.1026611328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6046669483184814,
      "rewards/margins": 17.05660629272461,
      "rewards/rejected": -18.661273956298828,
      "step": 5894
    },
    {
      "epoch": 2.358,
      "grad_norm": 8.338062798429746e-06,
      "learning_rate": 2.1413333333333334e-07,
      "logits/chosen": -2.2390317916870117,
      "logits/rejected": -1.2380914688110352,
      "logps/chosen": -89.30387878417969,
      "logps/rejected": -255.6049041748047,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6215388774871826,
      "rewards/margins": 17.988739013671875,
      "rewards/rejected": -15.36720085144043,
      "step": 5895
    },
    {
      "epoch": 2.3584,
      "grad_norm": 0.0002057749079540372,
      "learning_rate": 2.1399999999999998e-07,
      "logits/chosen": -2.567451000213623,
      "logits/rejected": -1.8233615159988403,
      "logps/chosen": -104.75570678710938,
      "logps/rejected": -224.5836639404297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7580966949462891,
      "rewards/margins": 14.390035629272461,
      "rewards/rejected": -15.14813232421875,
      "step": 5896
    },
    {
      "epoch": 2.3588,
      "grad_norm": 14.042425155639648,
      "learning_rate": 2.1386666666666668e-07,
      "logits/chosen": -2.473055362701416,
      "logits/rejected": -2.081752300262451,
      "logps/chosen": -168.8915557861328,
      "logps/rejected": -210.67657470703125,
      "loss": 0.046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4836376905441284,
      "rewards/margins": 9.6376371383667,
      "rewards/rejected": -11.121274948120117,
      "step": 5897
    },
    {
      "epoch": 2.3592,
      "grad_norm": 0.0008067238377407193,
      "learning_rate": 2.1373333333333331e-07,
      "logits/chosen": -2.736534595489502,
      "logits/rejected": -2.2385621070861816,
      "logps/chosen": -41.97980499267578,
      "logps/rejected": -188.23724365234375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5521268844604492,
      "rewards/margins": 13.860686302185059,
      "rewards/rejected": -13.30855941772461,
      "step": 5898
    },
    {
      "epoch": 2.3596,
      "grad_norm": 0.33331775665283203,
      "learning_rate": 2.136e-07,
      "logits/chosen": -2.800938367843628,
      "logits/rejected": -2.2920405864715576,
      "logps/chosen": -104.8461685180664,
      "logps/rejected": -167.23602294921875,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4706573486328125,
      "rewards/margins": 9.769014358520508,
      "rewards/rejected": -11.23967170715332,
      "step": 5899
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.29994481801986694,
      "learning_rate": 2.1346666666666665e-07,
      "logits/chosen": -2.693063259124756,
      "logits/rejected": -2.289501190185547,
      "logps/chosen": -152.6494598388672,
      "logps/rejected": -140.88111877441406,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10548248887062073,
      "rewards/margins": 8.525594711303711,
      "rewards/rejected": -8.63107681274414,
      "step": 5900
    },
    {
      "epoch": 2.3604,
      "grad_norm": 0.5152265429496765,
      "learning_rate": 2.1333333333333334e-07,
      "logits/chosen": -2.664189100265503,
      "logits/rejected": -2.330292224884033,
      "logps/chosen": -130.3550567626953,
      "logps/rejected": -130.05026245117188,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2749733924865723,
      "rewards/margins": 7.381828308105469,
      "rewards/rejected": -8.6568021774292,
      "step": 5901
    },
    {
      "epoch": 2.3608000000000002,
      "grad_norm": 0.03569359704852104,
      "learning_rate": 2.132e-07,
      "logits/chosen": -2.7972488403320312,
      "logits/rejected": -2.456721782684326,
      "logps/chosen": -72.19866180419922,
      "logps/rejected": -158.07913208007812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.497732937335968,
      "rewards/margins": 10.18328857421875,
      "rewards/rejected": -10.681021690368652,
      "step": 5902
    },
    {
      "epoch": 2.3612,
      "grad_norm": 0.014494753442704678,
      "learning_rate": 2.1306666666666664e-07,
      "logits/chosen": -2.5243186950683594,
      "logits/rejected": -1.939739465713501,
      "logps/chosen": -102.98924255371094,
      "logps/rejected": -177.72433471679688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4906978607177734,
      "rewards/margins": 10.440146446228027,
      "rewards/rejected": -11.930845260620117,
      "step": 5903
    },
    {
      "epoch": 2.3616,
      "grad_norm": 2.2336912155151367,
      "learning_rate": 2.1293333333333333e-07,
      "logits/chosen": -2.6644206047058105,
      "logits/rejected": -2.3853402137756348,
      "logps/chosen": -56.07750701904297,
      "logps/rejected": -144.75897216796875,
      "loss": 0.0191,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6347033977508545,
      "rewards/margins": 9.674145698547363,
      "rewards/rejected": -10.308849334716797,
      "step": 5904
    },
    {
      "epoch": 2.362,
      "grad_norm": 0.014838701114058495,
      "learning_rate": 2.1279999999999997e-07,
      "logits/chosen": -2.7219555377960205,
      "logits/rejected": -2.2490055561065674,
      "logps/chosen": -40.497188568115234,
      "logps/rejected": -152.47915649414062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.773484230041504,
      "rewards/margins": 11.242500305175781,
      "rewards/rejected": -9.469017028808594,
      "step": 5905
    },
    {
      "epoch": 2.3624,
      "grad_norm": 0.0017850111471489072,
      "learning_rate": 2.1266666666666667e-07,
      "logits/chosen": -2.128929615020752,
      "logits/rejected": -1.6076130867004395,
      "logps/chosen": -112.13541412353516,
      "logps/rejected": -258.9255676269531,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2449466586112976,
      "rewards/margins": 14.272018432617188,
      "rewards/rejected": -14.51696491241455,
      "step": 5906
    },
    {
      "epoch": 2.3628,
      "grad_norm": 0.8290599584579468,
      "learning_rate": 2.125333333333333e-07,
      "logits/chosen": -2.9272186756134033,
      "logits/rejected": -2.5326285362243652,
      "logps/chosen": -50.31403732299805,
      "logps/rejected": -134.3810272216797,
      "loss": 0.0056,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14906978607177734,
      "rewards/margins": 8.877823829650879,
      "rewards/rejected": -8.728754043579102,
      "step": 5907
    },
    {
      "epoch": 2.3632,
      "grad_norm": 0.015308383852243423,
      "learning_rate": 2.124e-07,
      "logits/chosen": -2.6012330055236816,
      "logits/rejected": -2.281550407409668,
      "logps/chosen": -125.11659240722656,
      "logps/rejected": -234.64695739746094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06460342556238174,
      "rewards/margins": 10.645559310913086,
      "rewards/rejected": -10.58095645904541,
      "step": 5908
    },
    {
      "epoch": 2.3636,
      "grad_norm": 0.005584107246249914,
      "learning_rate": 2.1226666666666666e-07,
      "logits/chosen": -2.551642894744873,
      "logits/rejected": -1.8646049499511719,
      "logps/chosen": -104.12224578857422,
      "logps/rejected": -166.21978759765625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2107851207256317,
      "rewards/margins": 10.60306167602539,
      "rewards/rejected": -10.3922758102417,
      "step": 5909
    },
    {
      "epoch": 2.364,
      "grad_norm": 0.0023244365584105253,
      "learning_rate": 2.1213333333333333e-07,
      "logits/chosen": -2.7648634910583496,
      "logits/rejected": -2.3990113735198975,
      "logps/chosen": -143.3896942138672,
      "logps/rejected": -212.63894653320312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3807159662246704,
      "rewards/margins": 12.045271873474121,
      "rewards/rejected": -13.425987243652344,
      "step": 5910
    },
    {
      "epoch": 2.3644,
      "grad_norm": 0.040022119879722595,
      "learning_rate": 2.12e-07,
      "logits/chosen": -2.6567859649658203,
      "logits/rejected": -2.067244529724121,
      "logps/chosen": -81.83857727050781,
      "logps/rejected": -163.1288299560547,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25495147705078125,
      "rewards/margins": 11.170320510864258,
      "rewards/rejected": -10.915369033813477,
      "step": 5911
    },
    {
      "epoch": 2.3648,
      "grad_norm": 1.2308844327926636,
      "learning_rate": 2.1186666666666666e-07,
      "logits/chosen": -2.5371291637420654,
      "logits/rejected": -2.1462273597717285,
      "logps/chosen": -73.21870422363281,
      "logps/rejected": -206.37730407714844,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9869411587715149,
      "rewards/margins": 10.44166374206543,
      "rewards/rejected": -9.45472240447998,
      "step": 5912
    },
    {
      "epoch": 2.3652,
      "grad_norm": 0.03787537291646004,
      "learning_rate": 2.1173333333333332e-07,
      "logits/chosen": -2.658909797668457,
      "logits/rejected": -2.5855872631073,
      "logps/chosen": -64.21711730957031,
      "logps/rejected": -133.10971069335938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.055801019072532654,
      "rewards/margins": 9.418373107910156,
      "rewards/rejected": -9.474174499511719,
      "step": 5913
    },
    {
      "epoch": 2.3656,
      "grad_norm": 0.27604541182518005,
      "learning_rate": 2.116e-07,
      "logits/chosen": -2.764448404312134,
      "logits/rejected": -2.019155263900757,
      "logps/chosen": -94.78759002685547,
      "logps/rejected": -149.57806396484375,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3877620697021484,
      "rewards/margins": 9.534107208251953,
      "rewards/rejected": -10.921869277954102,
      "step": 5914
    },
    {
      "epoch": 2.366,
      "grad_norm": 1.148603081703186,
      "learning_rate": 2.1146666666666665e-07,
      "logits/chosen": -2.7117676734924316,
      "logits/rejected": -2.632690668106079,
      "logps/chosen": -103.3760757446289,
      "logps/rejected": -177.98681640625,
      "loss": 0.0048,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4469581842422485,
      "rewards/margins": 7.999436378479004,
      "rewards/rejected": -9.446393966674805,
      "step": 5915
    },
    {
      "epoch": 2.3664,
      "grad_norm": 0.025845756754279137,
      "learning_rate": 2.1133333333333335e-07,
      "logits/chosen": -2.2588772773742676,
      "logits/rejected": -1.9578642845153809,
      "logps/chosen": -140.73565673828125,
      "logps/rejected": -143.64085388183594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2772457599639893,
      "rewards/margins": 10.423042297363281,
      "rewards/rejected": -9.145795822143555,
      "step": 5916
    },
    {
      "epoch": 2.3668,
      "grad_norm": 0.0034638296347111464,
      "learning_rate": 2.1119999999999999e-07,
      "logits/chosen": -2.738407850265503,
      "logits/rejected": -2.275289535522461,
      "logps/chosen": -80.96800994873047,
      "logps/rejected": -177.77235412597656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0758060216903687,
      "rewards/margins": 11.464834213256836,
      "rewards/rejected": -12.540640830993652,
      "step": 5917
    },
    {
      "epoch": 2.3672,
      "grad_norm": 9.622931480407715,
      "learning_rate": 2.1106666666666668e-07,
      "logits/chosen": -2.9509806632995605,
      "logits/rejected": -2.4135265350341797,
      "logps/chosen": -61.23445510864258,
      "logps/rejected": -148.0132598876953,
      "loss": 0.0577,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3637539148330688,
      "rewards/margins": 9.082681655883789,
      "rewards/rejected": -10.44643497467041,
      "step": 5918
    },
    {
      "epoch": 2.3676,
      "grad_norm": 0.0014188933419063687,
      "learning_rate": 2.1093333333333332e-07,
      "logits/chosen": -2.4330925941467285,
      "logits/rejected": -2.1664981842041016,
      "logps/chosen": -107.22738647460938,
      "logps/rejected": -192.45333862304688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.44317859411239624,
      "rewards/margins": 13.186742782592773,
      "rewards/rejected": -13.629921913146973,
      "step": 5919
    },
    {
      "epoch": 2.368,
      "grad_norm": 0.18383875489234924,
      "learning_rate": 2.1079999999999998e-07,
      "logits/chosen": -2.699645519256592,
      "logits/rejected": -2.5012307167053223,
      "logps/chosen": -131.8140411376953,
      "logps/rejected": -152.6171112060547,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3188099265098572,
      "rewards/margins": 8.948258399963379,
      "rewards/rejected": -9.267067909240723,
      "step": 5920
    },
    {
      "epoch": 2.3684,
      "grad_norm": 0.05656734108924866,
      "learning_rate": 2.1066666666666665e-07,
      "logits/chosen": -2.593109369277954,
      "logits/rejected": -1.9051542282104492,
      "logps/chosen": -80.96772003173828,
      "logps/rejected": -137.88363647460938,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4582816362380981,
      "rewards/margins": 10.194272994995117,
      "rewards/rejected": -8.735991477966309,
      "step": 5921
    },
    {
      "epoch": 2.3688000000000002,
      "grad_norm": 0.6696794629096985,
      "learning_rate": 2.105333333333333e-07,
      "logits/chosen": -2.2948012351989746,
      "logits/rejected": -1.8609668016433716,
      "logps/chosen": -192.78712463378906,
      "logps/rejected": -176.68984985351562,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.4818010330200195,
      "rewards/margins": 7.174782752990723,
      "rewards/rejected": -11.656583786010742,
      "step": 5922
    },
    {
      "epoch": 2.3692,
      "grad_norm": 0.1330188661813736,
      "learning_rate": 2.104e-07,
      "logits/chosen": -2.8839943408966064,
      "logits/rejected": -2.326658010482788,
      "logps/chosen": -37.112548828125,
      "logps/rejected": -144.53150939941406,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2635183334350586,
      "rewards/margins": 10.595430374145508,
      "rewards/rejected": -10.33191204071045,
      "step": 5923
    },
    {
      "epoch": 2.3696,
      "grad_norm": 115.96562957763672,
      "learning_rate": 2.1026666666666664e-07,
      "logits/chosen": -2.250056028366089,
      "logits/rejected": -2.230634927749634,
      "logps/chosen": -260.71197509765625,
      "logps/rejected": -93.24259948730469,
      "loss": 1.1086,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -5.979870796203613,
      "rewards/margins": -0.3745434284210205,
      "rewards/rejected": -5.605327129364014,
      "step": 5924
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.030534982681274414,
      "learning_rate": 2.1013333333333334e-07,
      "logits/chosen": -2.9470505714416504,
      "logits/rejected": -2.520688533782959,
      "logps/chosen": -44.535621643066406,
      "logps/rejected": -133.09567260742188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09269064664840698,
      "rewards/margins": 9.042186737060547,
      "rewards/rejected": -8.949496269226074,
      "step": 5925
    },
    {
      "epoch": 2.3704,
      "grad_norm": 0.027234522625803947,
      "learning_rate": 2.0999999999999997e-07,
      "logits/chosen": -2.5026278495788574,
      "logits/rejected": -2.169048309326172,
      "logps/chosen": -129.63441467285156,
      "logps/rejected": -124.54986572265625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6166999936103821,
      "rewards/margins": 9.129721641540527,
      "rewards/rejected": -8.513021469116211,
      "step": 5926
    },
    {
      "epoch": 2.3708,
      "grad_norm": 0.43490472435951233,
      "learning_rate": 2.0986666666666667e-07,
      "logits/chosen": -2.5527610778808594,
      "logits/rejected": -2.361022472381592,
      "logps/chosen": -68.46324157714844,
      "logps/rejected": -271.1451721191406,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7857919335365295,
      "rewards/margins": 9.227482795715332,
      "rewards/rejected": -8.441690444946289,
      "step": 5927
    },
    {
      "epoch": 2.3712,
      "grad_norm": 0.221268892288208,
      "learning_rate": 2.097333333333333e-07,
      "logits/chosen": -2.5161807537078857,
      "logits/rejected": -2.0949690341949463,
      "logps/chosen": -118.34236145019531,
      "logps/rejected": -139.97654724121094,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9883159399032593,
      "rewards/margins": 10.499197959899902,
      "rewards/rejected": -9.510881423950195,
      "step": 5928
    },
    {
      "epoch": 2.3716,
      "grad_norm": 4.666153907775879,
      "learning_rate": 2.096e-07,
      "logits/chosen": -2.6293187141418457,
      "logits/rejected": -2.253221035003662,
      "logps/chosen": -91.47694396972656,
      "logps/rejected": -94.92411804199219,
      "loss": 0.0249,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6347034573554993,
      "rewards/margins": 5.735710144042969,
      "rewards/rejected": -6.370413780212402,
      "step": 5929
    },
    {
      "epoch": 2.372,
      "grad_norm": 0.03469286486506462,
      "learning_rate": 2.0946666666666666e-07,
      "logits/chosen": -2.8981575965881348,
      "logits/rejected": -2.4341249465942383,
      "logps/chosen": -60.25361633300781,
      "logps/rejected": -126.20774841308594,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2577875852584839,
      "rewards/margins": 8.826971054077148,
      "rewards/rejected": -7.569183349609375,
      "step": 5930
    },
    {
      "epoch": 2.3724,
      "grad_norm": 0.3199477195739746,
      "learning_rate": 2.0933333333333333e-07,
      "logits/chosen": -2.528693675994873,
      "logits/rejected": -2.437392473220825,
      "logps/chosen": -135.54315185546875,
      "logps/rejected": -190.39260864257812,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.608588457107544,
      "rewards/margins": 11.189138412475586,
      "rewards/rejected": -11.797727584838867,
      "step": 5931
    },
    {
      "epoch": 2.3728,
      "grad_norm": 0.07132352888584137,
      "learning_rate": 2.092e-07,
      "logits/chosen": -2.6261696815490723,
      "logits/rejected": -2.533538818359375,
      "logps/chosen": -86.03292846679688,
      "logps/rejected": -138.59552001953125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8864784240722656,
      "rewards/margins": 8.046778678894043,
      "rewards/rejected": -9.933257102966309,
      "step": 5932
    },
    {
      "epoch": 2.3731999999999998,
      "grad_norm": 0.05739809572696686,
      "learning_rate": 2.0906666666666666e-07,
      "logits/chosen": -3.1137213706970215,
      "logits/rejected": -2.5905957221984863,
      "logps/chosen": -24.056716918945312,
      "logps/rejected": -104.8355712890625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2691879272460938,
      "rewards/margins": 8.18521499633789,
      "rewards/rejected": -6.916027069091797,
      "step": 5933
    },
    {
      "epoch": 2.3736,
      "grad_norm": 0.010984948836266994,
      "learning_rate": 2.0893333333333332e-07,
      "logits/chosen": -2.548072576522827,
      "logits/rejected": -1.9970449209213257,
      "logps/chosen": -174.26072692871094,
      "logps/rejected": -169.73818969726562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06554335355758667,
      "rewards/margins": 11.835918426513672,
      "rewards/rejected": -11.77037525177002,
      "step": 5934
    },
    {
      "epoch": 2.374,
      "grad_norm": 0.06950755417346954,
      "learning_rate": 2.0880000000000002e-07,
      "logits/chosen": -2.4895708560943604,
      "logits/rejected": -2.008183717727661,
      "logps/chosen": -116.23442077636719,
      "logps/rejected": -232.9384765625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6498711109161377,
      "rewards/margins": 12.512548446655273,
      "rewards/rejected": -13.162418365478516,
      "step": 5935
    },
    {
      "epoch": 2.3744,
      "grad_norm": 0.06323760002851486,
      "learning_rate": 2.0866666666666666e-07,
      "logits/chosen": -2.509077548980713,
      "logits/rejected": -2.1233816146850586,
      "logps/chosen": -115.39016723632812,
      "logps/rejected": -243.3624725341797,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14177533984184265,
      "rewards/margins": 11.623397827148438,
      "rewards/rejected": -11.481621742248535,
      "step": 5936
    },
    {
      "epoch": 2.3748,
      "grad_norm": 3.1109189987182617,
      "learning_rate": 2.0853333333333332e-07,
      "logits/chosen": -2.43898606300354,
      "logits/rejected": -2.0512731075286865,
      "logps/chosen": -169.37237548828125,
      "logps/rejected": -128.6335906982422,
      "loss": 0.0139,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1716965436935425,
      "rewards/margins": 8.0962495803833,
      "rewards/rejected": -9.267946243286133,
      "step": 5937
    },
    {
      "epoch": 2.3752,
      "grad_norm": 0.3020736277103424,
      "learning_rate": 2.0839999999999999e-07,
      "logits/chosen": -2.8454232215881348,
      "logits/rejected": -2.8729023933410645,
      "logps/chosen": -56.860504150390625,
      "logps/rejected": -130.71636962890625,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4608402252197266,
      "rewards/margins": 6.367889404296875,
      "rewards/rejected": -7.828729629516602,
      "step": 5938
    },
    {
      "epoch": 2.3756,
      "grad_norm": 0.005369104910641909,
      "learning_rate": 2.0826666666666665e-07,
      "logits/chosen": -2.8403379917144775,
      "logits/rejected": -2.3979125022888184,
      "logps/chosen": -85.84092712402344,
      "logps/rejected": -182.29135131835938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7384792566299438,
      "rewards/margins": 14.017318725585938,
      "rewards/rejected": -13.278841018676758,
      "step": 5939
    },
    {
      "epoch": 2.376,
      "grad_norm": 0.000505773990880698,
      "learning_rate": 2.0813333333333332e-07,
      "logits/chosen": -2.6262574195861816,
      "logits/rejected": -1.7936837673187256,
      "logps/chosen": -81.23941802978516,
      "logps/rejected": -233.62179565429688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.22493058443069458,
      "rewards/margins": 13.58462142944336,
      "rewards/rejected": -13.809553146362305,
      "step": 5940
    },
    {
      "epoch": 2.3764,
      "grad_norm": 0.04377291351556778,
      "learning_rate": 2.0799999999999998e-07,
      "logits/chosen": -3.1410350799560547,
      "logits/rejected": -2.5649733543395996,
      "logps/chosen": -36.343345642089844,
      "logps/rejected": -119.89115142822266,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5448825359344482,
      "rewards/margins": 9.082090377807617,
      "rewards/rejected": -8.53720760345459,
      "step": 5941
    },
    {
      "epoch": 2.3768000000000002,
      "grad_norm": 0.005171669647097588,
      "learning_rate": 2.0786666666666668e-07,
      "logits/chosen": -2.4521896839141846,
      "logits/rejected": -1.8842730522155762,
      "logps/chosen": -111.43434143066406,
      "logps/rejected": -183.35858154296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.15403249859809875,
      "rewards/margins": 11.607452392578125,
      "rewards/rejected": -11.761484146118164,
      "step": 5942
    },
    {
      "epoch": 2.3772,
      "grad_norm": 0.03104352578520775,
      "learning_rate": 2.0773333333333331e-07,
      "logits/chosen": -2.689469337463379,
      "logits/rejected": -2.093168258666992,
      "logps/chosen": -99.72349548339844,
      "logps/rejected": -177.45860290527344,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.502554714679718,
      "rewards/margins": 10.88458251953125,
      "rewards/rejected": -11.387136459350586,
      "step": 5943
    },
    {
      "epoch": 2.3776,
      "grad_norm": 0.024926315993070602,
      "learning_rate": 2.076e-07,
      "logits/chosen": -2.811005115509033,
      "logits/rejected": -2.184309959411621,
      "logps/chosen": -60.06200408935547,
      "logps/rejected": -170.46466064453125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1331474781036377,
      "rewards/margins": 12.83202075958252,
      "rewards/rejected": -10.698873519897461,
      "step": 5944
    },
    {
      "epoch": 2.378,
      "grad_norm": 0.06455089151859283,
      "learning_rate": 2.0746666666666665e-07,
      "logits/chosen": -2.5355224609375,
      "logits/rejected": -2.0161538124084473,
      "logps/chosen": -93.60379791259766,
      "logps/rejected": -141.64697265625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45531120896339417,
      "rewards/margins": 9.354965209960938,
      "rewards/rejected": -8.899653434753418,
      "step": 5945
    },
    {
      "epoch": 2.3784,
      "grad_norm": 0.002370985923334956,
      "learning_rate": 2.0733333333333334e-07,
      "logits/chosen": -2.586118698120117,
      "logits/rejected": -2.072873115539551,
      "logps/chosen": -86.8740005493164,
      "logps/rejected": -171.9345703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.323621392250061,
      "rewards/margins": 12.178092956542969,
      "rewards/rejected": -10.854472160339355,
      "step": 5946
    },
    {
      "epoch": 2.3788,
      "grad_norm": 0.05070926249027252,
      "learning_rate": 2.0719999999999998e-07,
      "logits/chosen": -2.778470993041992,
      "logits/rejected": -2.234926223754883,
      "logps/chosen": -101.45889282226562,
      "logps/rejected": -181.9441680908203,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3547065854072571,
      "rewards/margins": 12.066865921020508,
      "rewards/rejected": -12.4215726852417,
      "step": 5947
    },
    {
      "epoch": 2.3792,
      "grad_norm": 0.0007471981225535274,
      "learning_rate": 2.0706666666666667e-07,
      "logits/chosen": -2.6416454315185547,
      "logits/rejected": -2.2706127166748047,
      "logps/chosen": -75.21257019042969,
      "logps/rejected": -223.86630249023438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.018601607531309128,
      "rewards/margins": 15.377723693847656,
      "rewards/rejected": -15.359121322631836,
      "step": 5948
    },
    {
      "epoch": 2.3796,
      "grad_norm": 0.6935192346572876,
      "learning_rate": 2.0693333333333333e-07,
      "logits/chosen": -2.983150005340576,
      "logits/rejected": -2.8476991653442383,
      "logps/chosen": -66.39024353027344,
      "logps/rejected": -93.42436218261719,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6254188418388367,
      "rewards/margins": 5.521313190460205,
      "rewards/rejected": -4.895894527435303,
      "step": 5949
    },
    {
      "epoch": 2.38,
      "grad_norm": 5.676636219024658,
      "learning_rate": 2.068e-07,
      "logits/chosen": -2.7962265014648438,
      "logits/rejected": -2.683544158935547,
      "logps/chosen": -111.55430603027344,
      "logps/rejected": -152.2338409423828,
      "loss": 0.0393,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.470445990562439,
      "rewards/margins": 8.479098320007324,
      "rewards/rejected": -9.949544906616211,
      "step": 5950
    },
    {
      "epoch": 2.3804,
      "grad_norm": 0.008179199881851673,
      "learning_rate": 2.0666666666666666e-07,
      "logits/chosen": -2.6551320552825928,
      "logits/rejected": -1.9737423658370972,
      "logps/chosen": -110.26325988769531,
      "logps/rejected": -170.06358337402344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4975988566875458,
      "rewards/margins": 10.539436340332031,
      "rewards/rejected": -11.037035942077637,
      "step": 5951
    },
    {
      "epoch": 2.3808,
      "grad_norm": 0.4584589898586273,
      "learning_rate": 2.0653333333333333e-07,
      "logits/chosen": -2.712923526763916,
      "logits/rejected": -2.6323559284210205,
      "logps/chosen": -86.88894653320312,
      "logps/rejected": -144.01528930664062,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1340900659561157,
      "rewards/margins": 10.029601097106934,
      "rewards/rejected": -8.895511627197266,
      "step": 5952
    },
    {
      "epoch": 2.3811999999999998,
      "grad_norm": 0.001180785009637475,
      "learning_rate": 2.064e-07,
      "logits/chosen": -2.8342933654785156,
      "logits/rejected": -2.3436803817749023,
      "logps/chosen": -47.144744873046875,
      "logps/rejected": -212.48599243164062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1761224269866943,
      "rewards/margins": 15.559078216552734,
      "rewards/rejected": -14.382955551147461,
      "step": 5953
    },
    {
      "epoch": 2.3816,
      "grad_norm": 7.380858898162842,
      "learning_rate": 2.0626666666666663e-07,
      "logits/chosen": -2.8067827224731445,
      "logits/rejected": -2.534635543823242,
      "logps/chosen": -97.01390075683594,
      "logps/rejected": -83.47003173828125,
      "loss": 0.0529,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6769767999649048,
      "rewards/margins": 3.1924729347229004,
      "rewards/rejected": -4.869449615478516,
      "step": 5954
    },
    {
      "epoch": 2.382,
      "grad_norm": 0.022841574624180794,
      "learning_rate": 2.0613333333333333e-07,
      "logits/chosen": -2.9143199920654297,
      "logits/rejected": -2.497774600982666,
      "logps/chosen": -67.61152648925781,
      "logps/rejected": -170.1804656982422,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5127944946289062,
      "rewards/margins": 10.998434066772461,
      "rewards/rejected": -11.511228561401367,
      "step": 5955
    },
    {
      "epoch": 2.3824,
      "grad_norm": 0.0002912995114456862,
      "learning_rate": 2.06e-07,
      "logits/chosen": -2.800363302230835,
      "logits/rejected": -1.8720674514770508,
      "logps/chosen": -74.6029052734375,
      "logps/rejected": -213.14828491210938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3623943328857422,
      "rewards/margins": 13.981372833251953,
      "rewards/rejected": -13.618978500366211,
      "step": 5956
    },
    {
      "epoch": 2.3828,
      "grad_norm": 0.17413946986198425,
      "learning_rate": 2.0586666666666666e-07,
      "logits/chosen": -2.55375337600708,
      "logits/rejected": -2.3165788650512695,
      "logps/chosen": -95.08805084228516,
      "logps/rejected": -139.86151123046875,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6105888485908508,
      "rewards/margins": 9.59599781036377,
      "rewards/rejected": -10.206586837768555,
      "step": 5957
    },
    {
      "epoch": 2.3832,
      "grad_norm": 0.4515308439731598,
      "learning_rate": 2.0573333333333332e-07,
      "logits/chosen": -2.5051863193511963,
      "logits/rejected": -2.1283156871795654,
      "logps/chosen": -124.52091979980469,
      "logps/rejected": -141.13604736328125,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03765641152858734,
      "rewards/margins": 9.540030479431152,
      "rewards/rejected": -9.502373695373535,
      "step": 5958
    },
    {
      "epoch": 2.3836,
      "grad_norm": 0.0024885404855012894,
      "learning_rate": 2.056e-07,
      "logits/chosen": -2.1424143314361572,
      "logits/rejected": -1.3421344757080078,
      "logps/chosen": -163.49935913085938,
      "logps/rejected": -270.73797607421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8099372982978821,
      "rewards/margins": 17.911481857299805,
      "rewards/rejected": -17.101545333862305,
      "step": 5959
    },
    {
      "epoch": 2.384,
      "grad_norm": 0.1877230554819107,
      "learning_rate": 2.0546666666666665e-07,
      "logits/chosen": -2.6028661727905273,
      "logits/rejected": -2.1209001541137695,
      "logps/chosen": -150.33749389648438,
      "logps/rejected": -137.8392333984375,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.956909418106079,
      "rewards/margins": 7.355578422546387,
      "rewards/rejected": -9.312487602233887,
      "step": 5960
    },
    {
      "epoch": 2.3844,
      "grad_norm": 0.06544172018766403,
      "learning_rate": 2.0533333333333332e-07,
      "logits/chosen": -2.637122869491577,
      "logits/rejected": -2.305554151535034,
      "logps/chosen": -90.62928771972656,
      "logps/rejected": -163.87973022460938,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1284503936767578,
      "rewards/margins": 8.69599437713623,
      "rewards/rejected": -9.824443817138672,
      "step": 5961
    },
    {
      "epoch": 2.3848,
      "grad_norm": 0.0003459908766672015,
      "learning_rate": 2.0519999999999998e-07,
      "logits/chosen": -2.166928291320801,
      "logits/rejected": -1.5140007734298706,
      "logps/chosen": -183.072998046875,
      "logps/rejected": -308.38916015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8973000049591064,
      "rewards/margins": 14.292854309082031,
      "rewards/rejected": -15.190154075622559,
      "step": 5962
    },
    {
      "epoch": 2.3852,
      "grad_norm": 0.4950903356075287,
      "learning_rate": 2.0506666666666668e-07,
      "logits/chosen": -2.82482647895813,
      "logits/rejected": -2.599015951156616,
      "logps/chosen": -98.34736633300781,
      "logps/rejected": -98.5820541381836,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5775882601737976,
      "rewards/margins": 6.204404830932617,
      "rewards/rejected": -5.626816749572754,
      "step": 5963
    },
    {
      "epoch": 2.3856,
      "grad_norm": 0.15865309536457062,
      "learning_rate": 2.0493333333333332e-07,
      "logits/chosen": -2.5327234268188477,
      "logits/rejected": -1.9470456838607788,
      "logps/chosen": -161.44796752929688,
      "logps/rejected": -200.03713989257812,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.292299747467041,
      "rewards/margins": 9.539989471435547,
      "rewards/rejected": -12.832289695739746,
      "step": 5964
    },
    {
      "epoch": 2.386,
      "grad_norm": 0.0166927482932806,
      "learning_rate": 2.048e-07,
      "logits/chosen": -2.888741970062256,
      "logits/rejected": -2.445680856704712,
      "logps/chosen": -50.32719039916992,
      "logps/rejected": -145.93692016601562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.347077488899231,
      "rewards/margins": 10.357746124267578,
      "rewards/rejected": -9.010669708251953,
      "step": 5965
    },
    {
      "epoch": 2.3864,
      "grad_norm": 0.007103428710252047,
      "learning_rate": 2.0466666666666665e-07,
      "logits/chosen": -2.6372504234313965,
      "logits/rejected": -2.1102311611175537,
      "logps/chosen": -104.68782043457031,
      "logps/rejected": -168.99114990234375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.703940749168396,
      "rewards/margins": 10.333673477172852,
      "rewards/rejected": -11.037613868713379,
      "step": 5966
    },
    {
      "epoch": 2.3868,
      "grad_norm": 0.001733633573167026,
      "learning_rate": 2.0453333333333334e-07,
      "logits/chosen": -2.806640625,
      "logits/rejected": -2.1897077560424805,
      "logps/chosen": -94.02863311767578,
      "logps/rejected": -208.2419891357422,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2771787643432617,
      "rewards/margins": 13.424768447875977,
      "rewards/rejected": -12.147590637207031,
      "step": 5967
    },
    {
      "epoch": 2.3872,
      "grad_norm": 0.02313394658267498,
      "learning_rate": 2.0439999999999998e-07,
      "logits/chosen": -2.8169093132019043,
      "logits/rejected": -2.4653360843658447,
      "logps/chosen": -52.27214813232422,
      "logps/rejected": -125.14840698242188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4767456352710724,
      "rewards/margins": 8.741597175598145,
      "rewards/rejected": -8.264851570129395,
      "step": 5968
    },
    {
      "epoch": 2.3876,
      "grad_norm": 0.0020388427656143904,
      "learning_rate": 2.0426666666666667e-07,
      "logits/chosen": -2.85506534576416,
      "logits/rejected": -2.3550572395324707,
      "logps/chosen": -62.571468353271484,
      "logps/rejected": -207.03167724609375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39733201265335083,
      "rewards/margins": 14.998417854309082,
      "rewards/rejected": -14.601085662841797,
      "step": 5969
    },
    {
      "epoch": 2.388,
      "grad_norm": 0.0011857127537950873,
      "learning_rate": 2.0413333333333333e-07,
      "logits/chosen": -2.7767786979675293,
      "logits/rejected": -2.345409870147705,
      "logps/chosen": -99.02938842773438,
      "logps/rejected": -152.7679443359375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8861549496650696,
      "rewards/margins": 12.089524269104004,
      "rewards/rejected": -11.203369140625,
      "step": 5970
    },
    {
      "epoch": 2.3884,
      "grad_norm": 0.0008836285560391843,
      "learning_rate": 2.0399999999999997e-07,
      "logits/chosen": -2.916383743286133,
      "logits/rejected": -2.4181790351867676,
      "logps/chosen": -110.78538513183594,
      "logps/rejected": -210.36846923828125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.03564262390136719,
      "rewards/margins": 14.316957473754883,
      "rewards/rejected": -14.35260009765625,
      "step": 5971
    },
    {
      "epoch": 2.3888,
      "grad_norm": 0.0025859905872493982,
      "learning_rate": 2.0386666666666667e-07,
      "logits/chosen": -2.380457878112793,
      "logits/rejected": -1.8456225395202637,
      "logps/chosen": -186.8819580078125,
      "logps/rejected": -182.21658325195312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3285018801689148,
      "rewards/margins": 11.685534477233887,
      "rewards/rejected": -11.357032775878906,
      "step": 5972
    },
    {
      "epoch": 2.3891999999999998,
      "grad_norm": 0.0031156481709331274,
      "learning_rate": 2.037333333333333e-07,
      "logits/chosen": -2.45410418510437,
      "logits/rejected": -2.073963165283203,
      "logps/chosen": -93.58602905273438,
      "logps/rejected": -180.3187713623047,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5055023431777954,
      "rewards/margins": 12.233857154846191,
      "rewards/rejected": -11.728355407714844,
      "step": 5973
    },
    {
      "epoch": 2.3896,
      "grad_norm": 0.22338241338729858,
      "learning_rate": 2.036e-07,
      "logits/chosen": -2.97638201713562,
      "logits/rejected": -2.436018466949463,
      "logps/chosen": -80.537841796875,
      "logps/rejected": -115.68531036376953,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1289314329624176,
      "rewards/margins": 8.083580017089844,
      "rewards/rejected": -7.954648971557617,
      "step": 5974
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.0010699237463995814,
      "learning_rate": 2.0346666666666664e-07,
      "logits/chosen": -2.54915714263916,
      "logits/rejected": -2.1925249099731445,
      "logps/chosen": -130.7294921875,
      "logps/rejected": -259.89794921875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.163757085800171,
      "rewards/margins": 12.897216796875,
      "rewards/rejected": -16.06097412109375,
      "step": 5975
    },
    {
      "epoch": 2.3904,
      "grad_norm": 39.865638732910156,
      "learning_rate": 2.0333333333333333e-07,
      "logits/chosen": -2.0918588638305664,
      "logits/rejected": -1.6608107089996338,
      "logps/chosen": -190.95089721679688,
      "logps/rejected": -209.6454315185547,
      "loss": 0.169,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.2659595012664795,
      "rewards/margins": 6.865445137023926,
      "rewards/rejected": -10.131404876708984,
      "step": 5976
    },
    {
      "epoch": 2.3908,
      "grad_norm": 0.04487041011452675,
      "learning_rate": 2.032e-07,
      "logits/chosen": -2.757223129272461,
      "logits/rejected": -2.282712459564209,
      "logps/chosen": -117.38619995117188,
      "logps/rejected": -163.06765747070312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0094070434570312,
      "rewards/margins": 10.478754043579102,
      "rewards/rejected": -11.488161087036133,
      "step": 5977
    },
    {
      "epoch": 2.3912,
      "grad_norm": 4.5220371248433366e-05,
      "learning_rate": 2.0306666666666666e-07,
      "logits/chosen": -2.491332530975342,
      "logits/rejected": -1.3001017570495605,
      "logps/chosen": -107.94464874267578,
      "logps/rejected": -230.6658172607422,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.80411958694458,
      "rewards/margins": 17.0593204498291,
      "rewards/rejected": -15.255199432373047,
      "step": 5978
    },
    {
      "epoch": 2.3916,
      "grad_norm": 0.0007227582973428071,
      "learning_rate": 2.0293333333333332e-07,
      "logits/chosen": -2.772310733795166,
      "logits/rejected": -2.1684212684631348,
      "logps/chosen": -63.243751525878906,
      "logps/rejected": -234.75726318359375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7085787057876587,
      "rewards/margins": 16.109304428100586,
      "rewards/rejected": -15.400725364685059,
      "step": 5979
    },
    {
      "epoch": 2.392,
      "grad_norm": 0.0015818998217582703,
      "learning_rate": 2.028e-07,
      "logits/chosen": -2.652923583984375,
      "logits/rejected": -2.292741537094116,
      "logps/chosen": -110.28688049316406,
      "logps/rejected": -185.353515625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5362918972969055,
      "rewards/margins": 12.597820281982422,
      "rewards/rejected": -12.061529159545898,
      "step": 5980
    },
    {
      "epoch": 2.3924,
      "grad_norm": 1.3089778423309326,
      "learning_rate": 2.0266666666666666e-07,
      "logits/chosen": -2.391195058822632,
      "logits/rejected": -2.213331699371338,
      "logps/chosen": -50.3629150390625,
      "logps/rejected": -129.0756378173828,
      "loss": 0.0127,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08728200197219849,
      "rewards/margins": 7.697719573974609,
      "rewards/rejected": -7.785001754760742,
      "step": 5981
    },
    {
      "epoch": 2.3928,
      "grad_norm": 0.002122378209605813,
      "learning_rate": 2.0253333333333335e-07,
      "logits/chosen": -2.2840657234191895,
      "logits/rejected": -1.433171272277832,
      "logps/chosen": -69.13568115234375,
      "logps/rejected": -225.8102569580078,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.621159315109253,
      "rewards/margins": 17.18604278564453,
      "rewards/rejected": -15.564882278442383,
      "step": 5982
    },
    {
      "epoch": 2.3932,
      "grad_norm": 0.6944065690040588,
      "learning_rate": 2.0239999999999999e-07,
      "logits/chosen": -2.4834494590759277,
      "logits/rejected": -2.180819511413574,
      "logps/chosen": -84.29991149902344,
      "logps/rejected": -281.3028869628906,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0431346893310547,
      "rewards/margins": 8.810144424438477,
      "rewards/rejected": -7.767009258270264,
      "step": 5983
    },
    {
      "epoch": 2.3936,
      "grad_norm": 0.03568197414278984,
      "learning_rate": 2.0226666666666668e-07,
      "logits/chosen": -2.4574408531188965,
      "logits/rejected": -2.0229649543762207,
      "logps/chosen": -247.19390869140625,
      "logps/rejected": -208.00291442871094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15355300903320312,
      "rewards/margins": 11.779407501220703,
      "rewards/rejected": -11.6258544921875,
      "step": 5984
    },
    {
      "epoch": 2.394,
      "grad_norm": 2.7944107055664062,
      "learning_rate": 2.0213333333333332e-07,
      "logits/chosen": -2.442883253097534,
      "logits/rejected": -1.849008321762085,
      "logps/chosen": -116.01639556884766,
      "logps/rejected": -177.94424438476562,
      "loss": 0.0201,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7725898623466492,
      "rewards/margins": 12.29936408996582,
      "rewards/rejected": -11.526773452758789,
      "step": 5985
    },
    {
      "epoch": 2.3944,
      "grad_norm": 0.7563164234161377,
      "learning_rate": 2.02e-07,
      "logits/chosen": -2.911336898803711,
      "logits/rejected": -2.602736234664917,
      "logps/chosen": -61.696449279785156,
      "logps/rejected": -81.8002700805664,
      "loss": 0.0049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1641459465026855,
      "rewards/margins": 5.837597846984863,
      "rewards/rejected": -4.6734514236450195,
      "step": 5986
    },
    {
      "epoch": 2.3948,
      "grad_norm": 0.008258583024144173,
      "learning_rate": 2.0186666666666665e-07,
      "logits/chosen": -2.384035348892212,
      "logits/rejected": -1.8190157413482666,
      "logps/chosen": -141.26171875,
      "logps/rejected": -172.0614471435547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3424724340438843,
      "rewards/margins": 12.189510345458984,
      "rewards/rejected": -11.847037315368652,
      "step": 5987
    },
    {
      "epoch": 2.3952,
      "grad_norm": 0.25793302059173584,
      "learning_rate": 2.0173333333333331e-07,
      "logits/chosen": -2.7446913719177246,
      "logits/rejected": -2.3565285205841064,
      "logps/chosen": -135.1698760986328,
      "logps/rejected": -148.82281494140625,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.242788791656494,
      "rewards/margins": 7.470860481262207,
      "rewards/rejected": -9.713648796081543,
      "step": 5988
    },
    {
      "epoch": 2.3956,
      "grad_norm": 0.0031657968647778034,
      "learning_rate": 2.016e-07,
      "logits/chosen": -2.286525249481201,
      "logits/rejected": -1.783447504043579,
      "logps/chosen": -75.2432861328125,
      "logps/rejected": -190.6480712890625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.265407681465149,
      "rewards/margins": 11.827743530273438,
      "rewards/rejected": -10.562335968017578,
      "step": 5989
    },
    {
      "epoch": 2.396,
      "grad_norm": 0.06616280227899551,
      "learning_rate": 2.0146666666666664e-07,
      "logits/chosen": -2.7854697704315186,
      "logits/rejected": -2.0549514293670654,
      "logps/chosen": -58.98851776123047,
      "logps/rejected": -169.065673828125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0100256204605103,
      "rewards/margins": 12.031554222106934,
      "rewards/rejected": -11.021529197692871,
      "step": 5990
    },
    {
      "epoch": 2.3964,
      "grad_norm": 1.323858380317688,
      "learning_rate": 2.0133333333333334e-07,
      "logits/chosen": -2.8614609241485596,
      "logits/rejected": -2.5143165588378906,
      "logps/chosen": -75.53187561035156,
      "logps/rejected": -101.49705505371094,
      "loss": 0.0078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4721620082855225,
      "rewards/margins": 5.52821159362793,
      "rewards/rejected": -7.000373840332031,
      "step": 5991
    },
    {
      "epoch": 2.3968,
      "grad_norm": 0.6941697597503662,
      "learning_rate": 2.0119999999999998e-07,
      "logits/chosen": -2.856201410293579,
      "logits/rejected": -2.4327898025512695,
      "logps/chosen": -90.10076904296875,
      "logps/rejected": -174.818603515625,
      "loss": 0.0055,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5960254669189453,
      "rewards/margins": 10.71899700164795,
      "rewards/rejected": -11.315022468566895,
      "step": 5992
    },
    {
      "epoch": 2.3971999999999998,
      "grad_norm": 0.008935991674661636,
      "learning_rate": 2.0106666666666667e-07,
      "logits/chosen": -2.7740557193756104,
      "logits/rejected": -2.2937068939208984,
      "logps/chosen": -84.15635681152344,
      "logps/rejected": -141.58737182617188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.28241923451423645,
      "rewards/margins": 10.658443450927734,
      "rewards/rejected": -10.37602424621582,
      "step": 5993
    },
    {
      "epoch": 2.3976,
      "grad_norm": 4.258562088012695,
      "learning_rate": 2.009333333333333e-07,
      "logits/chosen": -2.577249526977539,
      "logits/rejected": -2.094808340072632,
      "logps/chosen": -97.47500610351562,
      "logps/rejected": -188.08984375,
      "loss": 0.0232,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1727752685546875,
      "rewards/margins": 11.74415397644043,
      "rewards/rejected": -12.916929244995117,
      "step": 5994
    },
    {
      "epoch": 2.398,
      "grad_norm": 0.2867564857006073,
      "learning_rate": 2.008e-07,
      "logits/chosen": -2.734626293182373,
      "logits/rejected": -2.5743978023529053,
      "logps/chosen": -106.8943099975586,
      "logps/rejected": -106.57656860351562,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6811012625694275,
      "rewards/margins": 6.37441349029541,
      "rewards/rejected": -5.693312168121338,
      "step": 5995
    },
    {
      "epoch": 2.3984,
      "grad_norm": 0.14527881145477295,
      "learning_rate": 2.0066666666666666e-07,
      "logits/chosen": -2.2421562671661377,
      "logits/rejected": -1.5572254657745361,
      "logps/chosen": -159.18080139160156,
      "logps/rejected": -187.5202178955078,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6351195573806763,
      "rewards/margins": 9.89314079284668,
      "rewards/rejected": -11.528260231018066,
      "step": 5996
    },
    {
      "epoch": 2.3988,
      "grad_norm": 0.21260221302509308,
      "learning_rate": 2.0053333333333333e-07,
      "logits/chosen": -2.3984341621398926,
      "logits/rejected": -1.9184584617614746,
      "logps/chosen": -112.12042236328125,
      "logps/rejected": -149.57350158691406,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.664546251296997,
      "rewards/margins": 8.219026565551758,
      "rewards/rejected": -9.88357162475586,
      "step": 5997
    },
    {
      "epoch": 2.3992,
      "grad_norm": 0.0025512457359582186,
      "learning_rate": 2.004e-07,
      "logits/chosen": -2.673611640930176,
      "logits/rejected": -2.1606316566467285,
      "logps/chosen": -90.53392028808594,
      "logps/rejected": -164.5118865966797,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2148230075836182,
      "rewards/margins": 12.04842758178711,
      "rewards/rejected": -10.83360481262207,
      "step": 5998
    },
    {
      "epoch": 2.3996,
      "grad_norm": 0.0017301208572462201,
      "learning_rate": 2.0026666666666666e-07,
      "logits/chosen": -2.3661112785339355,
      "logits/rejected": -1.2831525802612305,
      "logps/chosen": -180.4808349609375,
      "logps/rejected": -183.52259826660156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6991764307022095,
      "rewards/margins": 11.923737525939941,
      "rewards/rejected": -12.62291431427002,
      "step": 5999
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.047165099531412125,
      "learning_rate": 2.0013333333333333e-07,
      "logits/chosen": -2.860746145248413,
      "logits/rejected": -2.3600409030914307,
      "logps/chosen": -51.655540466308594,
      "logps/rejected": -168.38262939453125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4766063690185547,
      "rewards/margins": 11.373068809509277,
      "rewards/rejected": -10.896462440490723,
      "step": 6000
    },
    {
      "epoch": 2.4004,
      "grad_norm": 0.02766905352473259,
      "learning_rate": 2e-07,
      "logits/chosen": -2.9865686893463135,
      "logits/rejected": -2.2133169174194336,
      "logps/chosen": -53.888545989990234,
      "logps/rejected": -158.12103271484375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3265289068222046,
      "rewards/margins": 10.473858833312988,
      "rewards/rejected": -10.147330284118652,
      "step": 6001
    },
    {
      "epoch": 2.4008,
      "grad_norm": 0.0009992342675104737,
      "learning_rate": 1.9986666666666666e-07,
      "logits/chosen": -2.325028896331787,
      "logits/rejected": -1.4546632766723633,
      "logps/chosen": -108.10362243652344,
      "logps/rejected": -271.79913330078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.251285195350647,
      "rewards/margins": 13.118881225585938,
      "rewards/rejected": -11.867595672607422,
      "step": 6002
    },
    {
      "epoch": 2.4012000000000002,
      "grad_norm": 1.428128719329834,
      "learning_rate": 1.9973333333333335e-07,
      "logits/chosen": -2.7640066146850586,
      "logits/rejected": -2.497593641281128,
      "logps/chosen": -58.49262237548828,
      "logps/rejected": -131.9590301513672,
      "loss": 0.0106,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.06223595142364502,
      "rewards/margins": 8.71942138671875,
      "rewards/rejected": -8.781657218933105,
      "step": 6003
    },
    {
      "epoch": 2.4016,
      "grad_norm": 0.05492250993847847,
      "learning_rate": 1.996e-07,
      "logits/chosen": -2.9588661193847656,
      "logits/rejected": -2.7837722301483154,
      "logps/chosen": -97.88267517089844,
      "logps/rejected": -128.12228393554688,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3566833734512329,
      "rewards/margins": 8.207003593444824,
      "rewards/rejected": -8.563687324523926,
      "step": 6004
    },
    {
      "epoch": 2.402,
      "grad_norm": 0.0017734316643327475,
      "learning_rate": 1.9946666666666665e-07,
      "logits/chosen": -2.352137565612793,
      "logits/rejected": -1.8840583562850952,
      "logps/chosen": -133.81591796875,
      "logps/rejected": -216.5185546875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24559175968170166,
      "rewards/margins": 14.401927947998047,
      "rewards/rejected": -14.156335830688477,
      "step": 6005
    },
    {
      "epoch": 2.4024,
      "grad_norm": 0.9788125157356262,
      "learning_rate": 1.9933333333333332e-07,
      "logits/chosen": -2.96140456199646,
      "logits/rejected": -2.7442989349365234,
      "logps/chosen": -45.6568717956543,
      "logps/rejected": -91.06132507324219,
      "loss": 0.007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1168239563703537,
      "rewards/margins": 6.191056251525879,
      "rewards/rejected": -6.07423210144043,
      "step": 6006
    },
    {
      "epoch": 2.4028,
      "grad_norm": 0.00011318420001771301,
      "learning_rate": 1.9919999999999998e-07,
      "logits/chosen": -2.4530529975891113,
      "logits/rejected": -1.7560651302337646,
      "logps/chosen": -97.48460388183594,
      "logps/rejected": -208.9063720703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20414352416992188,
      "rewards/margins": 14.995986938476562,
      "rewards/rejected": -14.79184341430664,
      "step": 6007
    },
    {
      "epoch": 2.4032,
      "grad_norm": 4.245820045471191,
      "learning_rate": 1.9906666666666665e-07,
      "logits/chosen": -2.6040334701538086,
      "logits/rejected": -1.9981101751327515,
      "logps/chosen": -134.73211669921875,
      "logps/rejected": -190.56884765625,
      "loss": 0.0237,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.13599056005477905,
      "rewards/margins": 11.357343673706055,
      "rewards/rejected": -11.49333381652832,
      "step": 6008
    },
    {
      "epoch": 2.4036,
      "grad_norm": 0.007259045261889696,
      "learning_rate": 1.9893333333333331e-07,
      "logits/chosen": -2.966236114501953,
      "logits/rejected": -2.5133516788482666,
      "logps/chosen": -69.48445129394531,
      "logps/rejected": -191.17288208007812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0603456497192383,
      "rewards/margins": 11.879581451416016,
      "rewards/rejected": -12.93992805480957,
      "step": 6009
    },
    {
      "epoch": 2.404,
      "grad_norm": 0.00914281327277422,
      "learning_rate": 1.988e-07,
      "logits/chosen": -2.710020065307617,
      "logits/rejected": -2.526047945022583,
      "logps/chosen": -51.595237731933594,
      "logps/rejected": -220.25201416015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.711603581905365,
      "rewards/margins": 15.219667434692383,
      "rewards/rejected": -15.931270599365234,
      "step": 6010
    },
    {
      "epoch": 2.4044,
      "grad_norm": 0.005585768725723028,
      "learning_rate": 1.9866666666666665e-07,
      "logits/chosen": -2.6790482997894287,
      "logits/rejected": -1.8564622402191162,
      "logps/chosen": -52.37897491455078,
      "logps/rejected": -173.32472229003906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0928494930267334,
      "rewards/margins": 14.269918441772461,
      "rewards/rejected": -12.177069664001465,
      "step": 6011
    },
    {
      "epoch": 2.4048,
      "grad_norm": 0.00019050983246415854,
      "learning_rate": 1.9853333333333334e-07,
      "logits/chosen": -2.7425854206085205,
      "logits/rejected": -1.8603891134262085,
      "logps/chosen": -75.81828308105469,
      "logps/rejected": -195.84764099121094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0066579580307007,
      "rewards/margins": 14.800761222839355,
      "rewards/rejected": -13.794103622436523,
      "step": 6012
    },
    {
      "epoch": 2.4052,
      "grad_norm": 0.023433886468410492,
      "learning_rate": 1.9839999999999998e-07,
      "logits/chosen": -2.776899814605713,
      "logits/rejected": -2.454439878463745,
      "logps/chosen": -76.90412139892578,
      "logps/rejected": -169.44544982910156,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2661140561103821,
      "rewards/margins": 9.759178161621094,
      "rewards/rejected": -10.02529239654541,
      "step": 6013
    },
    {
      "epoch": 2.4056,
      "grad_norm": 0.002913736505433917,
      "learning_rate": 1.9826666666666667e-07,
      "logits/chosen": -2.4423012733459473,
      "logits/rejected": -1.763789176940918,
      "logps/chosen": -176.59046936035156,
      "logps/rejected": -222.70558166503906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8489898443222046,
      "rewards/margins": 12.559205055236816,
      "rewards/rejected": -14.408195495605469,
      "step": 6014
    },
    {
      "epoch": 2.406,
      "grad_norm": 0.021731149405241013,
      "learning_rate": 1.981333333333333e-07,
      "logits/chosen": -2.404752254486084,
      "logits/rejected": -1.8521240949630737,
      "logps/chosen": -124.82052612304688,
      "logps/rejected": -178.42291259765625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4120597839355469,
      "rewards/margins": 10.540735244750977,
      "rewards/rejected": -10.952795028686523,
      "step": 6015
    },
    {
      "epoch": 2.4064,
      "grad_norm": 0.0018068196950480342,
      "learning_rate": 1.98e-07,
      "logits/chosen": -2.5233302116394043,
      "logits/rejected": -2.1653571128845215,
      "logps/chosen": -86.83843994140625,
      "logps/rejected": -251.1167755126953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.47632867097854614,
      "rewards/margins": 12.12158203125,
      "rewards/rejected": -12.597909927368164,
      "step": 6016
    },
    {
      "epoch": 2.4068,
      "grad_norm": 4.764542579650879,
      "learning_rate": 1.9786666666666666e-07,
      "logits/chosen": -2.3718008995056152,
      "logits/rejected": -1.7159385681152344,
      "logps/chosen": -178.3203125,
      "logps/rejected": -188.21286010742188,
      "loss": 0.02,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.325768232345581,
      "rewards/margins": 9.21880054473877,
      "rewards/rejected": -10.54456901550293,
      "step": 6017
    },
    {
      "epoch": 2.4072,
      "grad_norm": 0.18937338888645172,
      "learning_rate": 1.9773333333333333e-07,
      "logits/chosen": -2.8455116748809814,
      "logits/rejected": -2.441878318786621,
      "logps/chosen": -54.89040756225586,
      "logps/rejected": -137.49612426757812,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4361182451248169,
      "rewards/margins": 8.11473274230957,
      "rewards/rejected": -8.550851821899414,
      "step": 6018
    },
    {
      "epoch": 2.4076,
      "grad_norm": 0.0009447021293453872,
      "learning_rate": 1.976e-07,
      "logits/chosen": -2.268540859222412,
      "logits/rejected": -1.3218965530395508,
      "logps/chosen": -124.31355285644531,
      "logps/rejected": -171.91830444335938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9294540882110596,
      "rewards/margins": 12.745431900024414,
      "rewards/rejected": -11.815977096557617,
      "step": 6019
    },
    {
      "epoch": 2.408,
      "grad_norm": 14.077961921691895,
      "learning_rate": 1.9746666666666666e-07,
      "logits/chosen": -2.678842544555664,
      "logits/rejected": -2.03718638420105,
      "logps/chosen": -117.41665649414062,
      "logps/rejected": -137.01138305664062,
      "loss": 0.0722,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.22273634374141693,
      "rewards/margins": 6.831427574157715,
      "rewards/rejected": -7.054163932800293,
      "step": 6020
    },
    {
      "epoch": 2.4084,
      "grad_norm": 0.058246858417987823,
      "learning_rate": 1.9733333333333333e-07,
      "logits/chosen": -3.024700164794922,
      "logits/rejected": -2.7371163368225098,
      "logps/chosen": -96.07743072509766,
      "logps/rejected": -160.76632690429688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.009531199932098389,
      "rewards/margins": 10.725552558898926,
      "rewards/rejected": -10.716021537780762,
      "step": 6021
    },
    {
      "epoch": 2.4088,
      "grad_norm": 0.002115556737408042,
      "learning_rate": 1.9719999999999997e-07,
      "logits/chosen": -2.6413846015930176,
      "logits/rejected": -2.250871181488037,
      "logps/chosen": -92.85787963867188,
      "logps/rejected": -192.09844970703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08623199164867401,
      "rewards/margins": 12.516297340393066,
      "rewards/rejected": -12.602529525756836,
      "step": 6022
    },
    {
      "epoch": 2.4092000000000002,
      "grad_norm": 0.04148692637681961,
      "learning_rate": 1.9706666666666666e-07,
      "logits/chosen": -2.162397861480713,
      "logits/rejected": -1.4504915475845337,
      "logps/chosen": -195.70285034179688,
      "logps/rejected": -218.58541870117188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.290163516998291,
      "rewards/margins": 12.053478240966797,
      "rewards/rejected": -13.34364128112793,
      "step": 6023
    },
    {
      "epoch": 2.4096,
      "grad_norm": 0.15972597897052765,
      "learning_rate": 1.9693333333333332e-07,
      "logits/chosen": -2.3596155643463135,
      "logits/rejected": -2.1546778678894043,
      "logps/chosen": -241.82904052734375,
      "logps/rejected": -220.98736572265625,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.066030263900757,
      "rewards/margins": 7.7937726974487305,
      "rewards/rejected": -9.859803199768066,
      "step": 6024
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.3067440986633301,
      "learning_rate": 1.968e-07,
      "logits/chosen": -2.8962879180908203,
      "logits/rejected": -2.547201633453369,
      "logps/chosen": -69.80208587646484,
      "logps/rejected": -103.00701141357422,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.23755912482738495,
      "rewards/margins": 6.058141708374023,
      "rewards/rejected": -6.295701026916504,
      "step": 6025
    },
    {
      "epoch": 2.4104,
      "grad_norm": 0.005111816804856062,
      "learning_rate": 1.9666666666666665e-07,
      "logits/chosen": -2.2488417625427246,
      "logits/rejected": -1.3783724308013916,
      "logps/chosen": -105.57772827148438,
      "logps/rejected": -171.93661499023438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1249504089355469,
      "rewards/margins": 11.72372817993164,
      "rewards/rejected": -10.598777770996094,
      "step": 6026
    },
    {
      "epoch": 2.4108,
      "grad_norm": 0.523629903793335,
      "learning_rate": 1.9653333333333332e-07,
      "logits/chosen": -2.565131425857544,
      "logits/rejected": -2.421361207962036,
      "logps/chosen": -118.67517852783203,
      "logps/rejected": -152.9161376953125,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9453461170196533,
      "rewards/margins": 11.99150562286377,
      "rewards/rejected": -11.046159744262695,
      "step": 6027
    },
    {
      "epoch": 2.4112,
      "grad_norm": 0.5530111789703369,
      "learning_rate": 1.9639999999999999e-07,
      "logits/chosen": -2.762425422668457,
      "logits/rejected": -2.2445669174194336,
      "logps/chosen": -78.62905883789062,
      "logps/rejected": -135.1974639892578,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6409012079238892,
      "rewards/margins": 7.90529727935791,
      "rewards/rejected": -8.546198844909668,
      "step": 6028
    },
    {
      "epoch": 2.4116,
      "grad_norm": 2.5499887466430664,
      "learning_rate": 1.9626666666666665e-07,
      "logits/chosen": -3.0198254585266113,
      "logits/rejected": -2.8022239208221436,
      "logps/chosen": -52.56166458129883,
      "logps/rejected": -125.77825927734375,
      "loss": 0.0162,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7387866973876953,
      "rewards/margins": 7.252701759338379,
      "rewards/rejected": -6.513915061950684,
      "step": 6029
    },
    {
      "epoch": 2.412,
      "grad_norm": 0.0008521242998540401,
      "learning_rate": 1.9613333333333332e-07,
      "logits/chosen": -2.6535117626190186,
      "logits/rejected": -1.8557472229003906,
      "logps/chosen": -50.45307159423828,
      "logps/rejected": -206.71539306640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4281070828437805,
      "rewards/margins": 14.263079643249512,
      "rewards/rejected": -13.834972381591797,
      "step": 6030
    },
    {
      "epoch": 2.4124,
      "grad_norm": 0.9718289971351624,
      "learning_rate": 1.96e-07,
      "logits/chosen": -2.6898961067199707,
      "logits/rejected": -2.2060048580169678,
      "logps/chosen": -53.84010696411133,
      "logps/rejected": -109.39937591552734,
      "loss": 0.0072,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07008001208305359,
      "rewards/margins": 6.4463114738464355,
      "rewards/rejected": -6.3762311935424805,
      "step": 6031
    },
    {
      "epoch": 2.4128,
      "grad_norm": 0.0003646457917056978,
      "learning_rate": 1.9586666666666665e-07,
      "logits/chosen": -2.8601222038269043,
      "logits/rejected": -2.4039993286132812,
      "logps/chosen": -70.39373016357422,
      "logps/rejected": -181.8558349609375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.043447732925415,
      "rewards/margins": 13.610288619995117,
      "rewards/rejected": -12.566841125488281,
      "step": 6032
    },
    {
      "epoch": 2.4132,
      "grad_norm": 3.732135534286499,
      "learning_rate": 1.9573333333333334e-07,
      "logits/chosen": -2.5790162086486816,
      "logits/rejected": -2.751473903656006,
      "logps/chosen": -232.74752807617188,
      "logps/rejected": -171.67062377929688,
      "loss": 0.0136,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.2735700607299805,
      "rewards/margins": 4.407441139221191,
      "rewards/rejected": -10.681011199951172,
      "step": 6033
    },
    {
      "epoch": 2.4136,
      "grad_norm": 0.042986735701560974,
      "learning_rate": 1.9559999999999998e-07,
      "logits/chosen": -2.6281981468200684,
      "logits/rejected": -2.0998897552490234,
      "logps/chosen": -90.01312255859375,
      "logps/rejected": -133.55194091796875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03916281461715698,
      "rewards/margins": 9.04450798034668,
      "rewards/rejected": -9.005345344543457,
      "step": 6034
    },
    {
      "epoch": 2.414,
      "grad_norm": 2.9275052547454834,
      "learning_rate": 1.9546666666666667e-07,
      "logits/chosen": -2.6278929710388184,
      "logits/rejected": -2.0553736686706543,
      "logps/chosen": -134.07928466796875,
      "logps/rejected": -254.00244140625,
      "loss": 0.0124,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.982049465179443,
      "rewards/margins": 8.178694725036621,
      "rewards/rejected": -13.160743713378906,
      "step": 6035
    },
    {
      "epoch": 2.4144,
      "grad_norm": 0.002481322269886732,
      "learning_rate": 1.953333333333333e-07,
      "logits/chosen": -2.856123685836792,
      "logits/rejected": -2.3055472373962402,
      "logps/chosen": -48.35494613647461,
      "logps/rejected": -261.30377197265625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8176473379135132,
      "rewards/margins": 18.59148597717285,
      "rewards/rejected": -17.77383804321289,
      "step": 6036
    },
    {
      "epoch": 2.4148,
      "grad_norm": 0.01928028091788292,
      "learning_rate": 1.952e-07,
      "logits/chosen": -2.5151596069335938,
      "logits/rejected": -1.9825341701507568,
      "logps/chosen": -142.15969848632812,
      "logps/rejected": -176.94618225097656,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10109961032867432,
      "rewards/margins": 12.644152641296387,
      "rewards/rejected": -12.54305362701416,
      "step": 6037
    },
    {
      "epoch": 2.4152,
      "grad_norm": 0.041604481637477875,
      "learning_rate": 1.9506666666666667e-07,
      "logits/chosen": -2.7416341304779053,
      "logits/rejected": -2.5453085899353027,
      "logps/chosen": -93.33055877685547,
      "logps/rejected": -151.72337341308594,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3312618136405945,
      "rewards/margins": 8.94927978515625,
      "rewards/rejected": -8.61801815032959,
      "step": 6038
    },
    {
      "epoch": 2.4156,
      "grad_norm": 0.0011910520261153579,
      "learning_rate": 1.949333333333333e-07,
      "logits/chosen": -2.097870349884033,
      "logits/rejected": -1.7343597412109375,
      "logps/chosen": -87.44236755371094,
      "logps/rejected": -191.09002685546875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.755820870399475,
      "rewards/margins": 14.482988357543945,
      "rewards/rejected": -12.727167129516602,
      "step": 6039
    },
    {
      "epoch": 2.416,
      "grad_norm": 0.001406166236847639,
      "learning_rate": 1.948e-07,
      "logits/chosen": -2.778355836868286,
      "logits/rejected": -2.4280149936676025,
      "logps/chosen": -99.76335144042969,
      "logps/rejected": -226.5052490234375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.480894923210144,
      "rewards/margins": 13.873494148254395,
      "rewards/rejected": -15.354389190673828,
      "step": 6040
    },
    {
      "epoch": 2.4164,
      "grad_norm": 0.0013754151295870543,
      "learning_rate": 1.9466666666666664e-07,
      "logits/chosen": -2.1831588745117188,
      "logits/rejected": -1.4878969192504883,
      "logps/chosen": -114.15159606933594,
      "logps/rejected": -215.66529846191406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0049644410610198975,
      "rewards/margins": 12.567695617675781,
      "rewards/rejected": -12.56273078918457,
      "step": 6041
    },
    {
      "epoch": 2.4168,
      "grad_norm": 0.010435543954372406,
      "learning_rate": 1.9453333333333333e-07,
      "logits/chosen": -2.9578208923339844,
      "logits/rejected": -2.3219566345214844,
      "logps/chosen": -67.55587768554688,
      "logps/rejected": -184.54949951171875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9735143184661865,
      "rewards/margins": 14.634725570678711,
      "rewards/rejected": -12.661211013793945,
      "step": 6042
    },
    {
      "epoch": 2.4172000000000002,
      "grad_norm": 0.09906107187271118,
      "learning_rate": 1.944e-07,
      "logits/chosen": -2.562852144241333,
      "logits/rejected": -1.8150334358215332,
      "logps/chosen": -106.16917419433594,
      "logps/rejected": -239.4209747314453,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1990203708410263,
      "rewards/margins": 11.779205322265625,
      "rewards/rejected": -11.580184936523438,
      "step": 6043
    },
    {
      "epoch": 2.4176,
      "grad_norm": 55.807098388671875,
      "learning_rate": 1.9426666666666666e-07,
      "logits/chosen": -2.479768753051758,
      "logits/rejected": -1.9464658498764038,
      "logps/chosen": -109.99150085449219,
      "logps/rejected": -142.2347869873047,
      "loss": 0.3289,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2983779907226562,
      "rewards/margins": 7.767021656036377,
      "rewards/rejected": -9.065399169921875,
      "step": 6044
    },
    {
      "epoch": 2.418,
      "grad_norm": 0.08686568588018417,
      "learning_rate": 1.9413333333333332e-07,
      "logits/chosen": -2.762028694152832,
      "logits/rejected": -2.322206497192383,
      "logps/chosen": -65.68560791015625,
      "logps/rejected": -141.3049774169922,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0361248254776001,
      "rewards/margins": 9.945832252502441,
      "rewards/rejected": -9.909707069396973,
      "step": 6045
    },
    {
      "epoch": 2.4184,
      "grad_norm": 0.31112557649612427,
      "learning_rate": 1.94e-07,
      "logits/chosen": -2.8724801540374756,
      "logits/rejected": -2.698667526245117,
      "logps/chosen": -111.8345947265625,
      "logps/rejected": -153.67385864257812,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6625118255615234,
      "rewards/margins": 8.891109466552734,
      "rewards/rejected": -9.553621292114258,
      "step": 6046
    },
    {
      "epoch": 2.4188,
      "grad_norm": 0.013861620798707008,
      "learning_rate": 1.9386666666666666e-07,
      "logits/chosen": -2.8287224769592285,
      "logits/rejected": -2.4558706283569336,
      "logps/chosen": -53.37584686279297,
      "logps/rejected": -148.49131774902344,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9063324332237244,
      "rewards/margins": 10.135940551757812,
      "rewards/rejected": -9.229607582092285,
      "step": 6047
    },
    {
      "epoch": 2.4192,
      "grad_norm": 0.05087469890713692,
      "learning_rate": 1.9373333333333332e-07,
      "logits/chosen": -2.7197346687316895,
      "logits/rejected": -2.231403350830078,
      "logps/chosen": -59.27970504760742,
      "logps/rejected": -199.927978515625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5053380727767944,
      "rewards/margins": 11.222825050354004,
      "rewards/rejected": -10.717486381530762,
      "step": 6048
    },
    {
      "epoch": 2.4196,
      "grad_norm": 0.013868623413145542,
      "learning_rate": 1.9359999999999999e-07,
      "logits/chosen": -2.604644775390625,
      "logits/rejected": -2.2883141040802,
      "logps/chosen": -116.9280014038086,
      "logps/rejected": -164.3450927734375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.532809853553772,
      "rewards/margins": 9.539325714111328,
      "rewards/rejected": -11.072135925292969,
      "step": 6049
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.014237421564757824,
      "learning_rate": 1.9346666666666668e-07,
      "logits/chosen": -2.2335939407348633,
      "logits/rejected": -1.1963385343551636,
      "logps/chosen": -129.13497924804688,
      "logps/rejected": -167.38815307617188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.439475178718567,
      "rewards/margins": 10.623062133789062,
      "rewards/rejected": -9.183586120605469,
      "step": 6050
    },
    {
      "epoch": 2.4204,
      "grad_norm": 0.7974026799201965,
      "learning_rate": 1.9333333333333332e-07,
      "logits/chosen": -3.0393319129943848,
      "logits/rejected": -2.666079521179199,
      "logps/chosen": -73.0040283203125,
      "logps/rejected": -106.88924407958984,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08915863186120987,
      "rewards/margins": 6.429027557373047,
      "rewards/rejected": -6.339869022369385,
      "step": 6051
    },
    {
      "epoch": 2.4208,
      "grad_norm": 0.18611092865467072,
      "learning_rate": 1.932e-07,
      "logits/chosen": -2.810171604156494,
      "logits/rejected": -2.530301570892334,
      "logps/chosen": -94.85647583007812,
      "logps/rejected": -155.21646118164062,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1460593938827515,
      "rewards/margins": 8.269376754760742,
      "rewards/rejected": -9.415436744689941,
      "step": 6052
    },
    {
      "epoch": 2.4212,
      "grad_norm": 0.005208722781389952,
      "learning_rate": 1.9306666666666665e-07,
      "logits/chosen": -2.879873037338257,
      "logits/rejected": -1.8860478401184082,
      "logps/chosen": -56.838783264160156,
      "logps/rejected": -184.50033569335938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.282766342163086,
      "rewards/margins": 11.535794258117676,
      "rewards/rejected": -10.25302791595459,
      "step": 6053
    },
    {
      "epoch": 2.4215999999999998,
      "grad_norm": 0.007407105062156916,
      "learning_rate": 1.9293333333333334e-07,
      "logits/chosen": -2.459360122680664,
      "logits/rejected": -2.2124593257904053,
      "logps/chosen": -125.24950408935547,
      "logps/rejected": -197.71893310546875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41211622953414917,
      "rewards/margins": 10.21599006652832,
      "rewards/rejected": -9.803873062133789,
      "step": 6054
    },
    {
      "epoch": 2.422,
      "grad_norm": 0.023838333785533905,
      "learning_rate": 1.9279999999999998e-07,
      "logits/chosen": -2.914177894592285,
      "logits/rejected": -2.4467825889587402,
      "logps/chosen": -53.927711486816406,
      "logps/rejected": -160.94659423828125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7767465114593506,
      "rewards/margins": 10.513345718383789,
      "rewards/rejected": -8.736598014831543,
      "step": 6055
    },
    {
      "epoch": 2.4224,
      "grad_norm": 0.0110344672575593,
      "learning_rate": 1.9266666666666667e-07,
      "logits/chosen": -3.0223121643066406,
      "logits/rejected": -2.801870107650757,
      "logps/chosen": -65.72209930419922,
      "logps/rejected": -141.75477600097656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7197974920272827,
      "rewards/margins": 10.152679443359375,
      "rewards/rejected": -9.432882308959961,
      "step": 6056
    },
    {
      "epoch": 2.4228,
      "grad_norm": 0.8173765540122986,
      "learning_rate": 1.9253333333333334e-07,
      "logits/chosen": -2.5069661140441895,
      "logits/rejected": -2.1817307472229004,
      "logps/chosen": -135.94195556640625,
      "logps/rejected": -137.71376037597656,
      "loss": 0.0071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10490646958351135,
      "rewards/margins": 8.620878219604492,
      "rewards/rejected": -8.515972137451172,
      "step": 6057
    },
    {
      "epoch": 2.4232,
      "grad_norm": 0.013959744945168495,
      "learning_rate": 1.9239999999999998e-07,
      "logits/chosen": -2.888427257537842,
      "logits/rejected": -2.386117458343506,
      "logps/chosen": -96.62550354003906,
      "logps/rejected": -211.3814697265625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.07391852140426636,
      "rewards/margins": 14.388689041137695,
      "rewards/rejected": -14.462608337402344,
      "step": 6058
    },
    {
      "epoch": 2.4236,
      "grad_norm": 0.1118183508515358,
      "learning_rate": 1.9226666666666667e-07,
      "logits/chosen": -2.1842637062072754,
      "logits/rejected": -1.3564248085021973,
      "logps/chosen": -186.5612335205078,
      "logps/rejected": -201.1171875,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0560810565948486,
      "rewards/margins": 11.240768432617188,
      "rewards/rejected": -13.296849250793457,
      "step": 6059
    },
    {
      "epoch": 2.424,
      "grad_norm": 0.48794782161712646,
      "learning_rate": 1.921333333333333e-07,
      "logits/chosen": -2.3134572505950928,
      "logits/rejected": -1.8825453519821167,
      "logps/chosen": -174.40200805664062,
      "logps/rejected": -176.37002563476562,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0998367071151733,
      "rewards/margins": 9.421674728393555,
      "rewards/rejected": -10.521512031555176,
      "step": 6060
    },
    {
      "epoch": 2.4244,
      "grad_norm": 0.12244921922683716,
      "learning_rate": 1.92e-07,
      "logits/chosen": -2.509117603302002,
      "logits/rejected": -1.885603427886963,
      "logps/chosen": -131.26272583007812,
      "logps/rejected": -185.80838012695312,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31998711824417114,
      "rewards/margins": 9.609125137329102,
      "rewards/rejected": -9.289138793945312,
      "step": 6061
    },
    {
      "epoch": 2.4248,
      "grad_norm": 0.003892475040629506,
      "learning_rate": 1.9186666666666664e-07,
      "logits/chosen": -2.51930570602417,
      "logits/rejected": -2.396453857421875,
      "logps/chosen": -86.31351470947266,
      "logps/rejected": -166.2520751953125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7124409675598145,
      "rewards/margins": 11.44285774230957,
      "rewards/rejected": -10.730417251586914,
      "step": 6062
    },
    {
      "epoch": 2.4252000000000002,
      "grad_norm": 0.19287942349910736,
      "learning_rate": 1.9173333333333333e-07,
      "logits/chosen": -2.738901138305664,
      "logits/rejected": -2.25457763671875,
      "logps/chosen": -108.18385314941406,
      "logps/rejected": -145.40228271484375,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9988950490951538,
      "rewards/margins": 9.923933029174805,
      "rewards/rejected": -8.925037384033203,
      "step": 6063
    },
    {
      "epoch": 2.4256,
      "grad_norm": 0.044532157480716705,
      "learning_rate": 1.916e-07,
      "logits/chosen": -2.698866844177246,
      "logits/rejected": -1.9795308113098145,
      "logps/chosen": -107.10710906982422,
      "logps/rejected": -138.5601043701172,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1307594776153564,
      "rewards/margins": 10.118017196655273,
      "rewards/rejected": -8.987257957458496,
      "step": 6064
    },
    {
      "epoch": 2.426,
      "grad_norm": 0.0021235232707113028,
      "learning_rate": 1.9146666666666666e-07,
      "logits/chosen": -2.592874050140381,
      "logits/rejected": -1.7762749195098877,
      "logps/chosen": -90.29979705810547,
      "logps/rejected": -211.60084533691406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45626869797706604,
      "rewards/margins": 14.13183307647705,
      "rewards/rejected": -13.67556381225586,
      "step": 6065
    },
    {
      "epoch": 2.4264,
      "grad_norm": 22.49819564819336,
      "learning_rate": 1.9133333333333333e-07,
      "logits/chosen": -2.576624870300293,
      "logits/rejected": -2.1849093437194824,
      "logps/chosen": -202.6324920654297,
      "logps/rejected": -201.48809814453125,
      "loss": 0.0765,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.862242221832275,
      "rewards/margins": 7.37715482711792,
      "rewards/rejected": -12.239397048950195,
      "step": 6066
    },
    {
      "epoch": 2.4268,
      "grad_norm": 0.018195003271102905,
      "learning_rate": 1.912e-07,
      "logits/chosen": -2.6931257247924805,
      "logits/rejected": -1.8140400648117065,
      "logps/chosen": -72.4552230834961,
      "logps/rejected": -170.69219970703125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8608075976371765,
      "rewards/margins": 11.599550247192383,
      "rewards/rejected": -10.73874282836914,
      "step": 6067
    },
    {
      "epoch": 2.4272,
      "grad_norm": 0.000634922063909471,
      "learning_rate": 1.9106666666666666e-07,
      "logits/chosen": -2.559821844100952,
      "logits/rejected": -2.0613436698913574,
      "logps/chosen": -60.54819107055664,
      "logps/rejected": -164.75851440429688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7340710163116455,
      "rewards/margins": 13.224874496459961,
      "rewards/rejected": -11.490803718566895,
      "step": 6068
    },
    {
      "epoch": 2.4276,
      "grad_norm": 0.018096424639225006,
      "learning_rate": 1.9093333333333332e-07,
      "logits/chosen": -2.5664732456207275,
      "logits/rejected": -2.2780044078826904,
      "logps/chosen": -65.95960998535156,
      "logps/rejected": -136.35983276367188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.944340169429779,
      "rewards/margins": 9.601085662841797,
      "rewards/rejected": -8.656744956970215,
      "step": 6069
    },
    {
      "epoch": 2.428,
      "grad_norm": 0.0001343404728686437,
      "learning_rate": 1.908e-07,
      "logits/chosen": -2.6340909004211426,
      "logits/rejected": -1.8561229705810547,
      "logps/chosen": -88.39116668701172,
      "logps/rejected": -214.45040893554688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9938217401504517,
      "rewards/margins": 15.517802238464355,
      "rewards/rejected": -14.523980140686035,
      "step": 6070
    },
    {
      "epoch": 2.4284,
      "grad_norm": 0.03172650188207626,
      "learning_rate": 1.9066666666666668e-07,
      "logits/chosen": -2.4449117183685303,
      "logits/rejected": -2.0889453887939453,
      "logps/chosen": -124.59516143798828,
      "logps/rejected": -147.31243896484375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6476768851280212,
      "rewards/margins": 8.883216857910156,
      "rewards/rejected": -8.235540390014648,
      "step": 6071
    },
    {
      "epoch": 2.4288,
      "grad_norm": 0.00016731662617530674,
      "learning_rate": 1.9053333333333332e-07,
      "logits/chosen": -2.1966140270233154,
      "logits/rejected": -1.3735377788543701,
      "logps/chosen": -106.94325256347656,
      "logps/rejected": -234.46583557128906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.273525595664978,
      "rewards/margins": 15.139503479003906,
      "rewards/rejected": -14.865976333618164,
      "step": 6072
    },
    {
      "epoch": 2.4292,
      "grad_norm": 0.0005664576892741024,
      "learning_rate": 1.904e-07,
      "logits/chosen": -2.3657889366149902,
      "logits/rejected": -1.8592655658721924,
      "logps/chosen": -98.94132232666016,
      "logps/rejected": -249.55172729492188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0840004682540894,
      "rewards/margins": 15.547600746154785,
      "rewards/rejected": -14.463600158691406,
      "step": 6073
    },
    {
      "epoch": 2.4295999999999998,
      "grad_norm": 9.701423645019531,
      "learning_rate": 1.9026666666666665e-07,
      "logits/chosen": -2.793675422668457,
      "logits/rejected": -2.6345553398132324,
      "logps/chosen": -85.75186157226562,
      "logps/rejected": -99.93952178955078,
      "loss": 0.0672,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16182823479175568,
      "rewards/margins": 6.4625983238220215,
      "rewards/rejected": -6.300770282745361,
      "step": 6074
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.0010119080543518066,
      "learning_rate": 1.9013333333333332e-07,
      "logits/chosen": -2.3650436401367188,
      "logits/rejected": -1.812903881072998,
      "logps/chosen": -132.41006469726562,
      "logps/rejected": -177.19570922851562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1651097536087036,
      "rewards/margins": 12.886733055114746,
      "rewards/rejected": -11.721623420715332,
      "step": 6075
    },
    {
      "epoch": 2.4304,
      "grad_norm": 3.885719195295678e-07,
      "learning_rate": 1.8999999999999998e-07,
      "logits/chosen": -2.905247211456299,
      "logits/rejected": -1.9041650295257568,
      "logps/chosen": -97.73861694335938,
      "logps/rejected": -386.5954284667969,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9489948153495789,
      "rewards/margins": 21.861248016357422,
      "rewards/rejected": -20.912254333496094,
      "step": 6076
    },
    {
      "epoch": 2.4308,
      "grad_norm": 0.07111010700464249,
      "learning_rate": 1.8986666666666665e-07,
      "logits/chosen": -2.4465067386627197,
      "logits/rejected": -1.7605830430984497,
      "logps/chosen": -118.546142578125,
      "logps/rejected": -200.79379272460938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3438587188720703,
      "rewards/margins": 12.531362533569336,
      "rewards/rejected": -13.875221252441406,
      "step": 6077
    },
    {
      "epoch": 2.4312,
      "grad_norm": 0.008029629476368427,
      "learning_rate": 1.8973333333333334e-07,
      "logits/chosen": -2.3402061462402344,
      "logits/rejected": -1.7052414417266846,
      "logps/chosen": -138.80409240722656,
      "logps/rejected": -209.11390686035156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6236310005187988,
      "rewards/margins": 13.229970932006836,
      "rewards/rejected": -13.853602409362793,
      "step": 6078
    },
    {
      "epoch": 2.4316,
      "grad_norm": 1.2981561422348022,
      "learning_rate": 1.8959999999999998e-07,
      "logits/chosen": -2.526577949523926,
      "logits/rejected": -2.3342599868774414,
      "logps/chosen": -152.45700073242188,
      "logps/rejected": -180.68911743164062,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.5273425579071045,
      "rewards/margins": 8.703689575195312,
      "rewards/rejected": -11.23103141784668,
      "step": 6079
    },
    {
      "epoch": 2.432,
      "grad_norm": 0.00043645978439599276,
      "learning_rate": 1.8946666666666667e-07,
      "logits/chosen": -2.5654594898223877,
      "logits/rejected": -1.605168342590332,
      "logps/chosen": -101.44869995117188,
      "logps/rejected": -187.82965087890625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1598930358886719,
      "rewards/margins": 13.6437406539917,
      "rewards/rejected": -12.483847618103027,
      "step": 6080
    },
    {
      "epoch": 2.4324,
      "grad_norm": 0.07641234248876572,
      "learning_rate": 1.893333333333333e-07,
      "logits/chosen": -2.7281551361083984,
      "logits/rejected": -2.5570459365844727,
      "logps/chosen": -39.013248443603516,
      "logps/rejected": -139.71730041503906,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2713470458984375,
      "rewards/margins": 9.090279579162598,
      "rewards/rejected": -9.361626625061035,
      "step": 6081
    },
    {
      "epoch": 2.4328,
      "grad_norm": 4.327078819274902,
      "learning_rate": 1.892e-07,
      "logits/chosen": -2.0416576862335205,
      "logits/rejected": -1.6520099639892578,
      "logps/chosen": -189.47894287109375,
      "logps/rejected": -199.86148071289062,
      "loss": 0.0157,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.537461042404175,
      "rewards/margins": 8.89406967163086,
      "rewards/rejected": -11.431529998779297,
      "step": 6082
    },
    {
      "epoch": 2.4332,
      "grad_norm": 0.23965893685817719,
      "learning_rate": 1.8906666666666664e-07,
      "logits/chosen": -2.642040252685547,
      "logits/rejected": -2.1944730281829834,
      "logps/chosen": -154.36337280273438,
      "logps/rejected": -172.07241821289062,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.983924150466919,
      "rewards/margins": 12.028913497924805,
      "rewards/rejected": -13.012837409973145,
      "step": 6083
    },
    {
      "epoch": 2.4336,
      "grad_norm": 0.10768043249845505,
      "learning_rate": 1.8893333333333333e-07,
      "logits/chosen": -2.6275081634521484,
      "logits/rejected": -2.002534866333008,
      "logps/chosen": -81.43466186523438,
      "logps/rejected": -219.40939331054688,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7919452786445618,
      "rewards/margins": 10.91586685180664,
      "rewards/rejected": -10.123921394348145,
      "step": 6084
    },
    {
      "epoch": 2.434,
      "grad_norm": 0.01690441183745861,
      "learning_rate": 1.888e-07,
      "logits/chosen": -2.400423526763916,
      "logits/rejected": -1.7611545324325562,
      "logps/chosen": -47.71234893798828,
      "logps/rejected": -173.37332153320312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.04863333702087402,
      "rewards/margins": 9.731159210205078,
      "rewards/rejected": -9.779792785644531,
      "step": 6085
    },
    {
      "epoch": 2.4344,
      "grad_norm": 5.803321838378906,
      "learning_rate": 1.8866666666666666e-07,
      "logits/chosen": -2.7295989990234375,
      "logits/rejected": -2.4381842613220215,
      "logps/chosen": -154.54713439941406,
      "logps/rejected": -183.04971313476562,
      "loss": 0.0287,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.92378044128418,
      "rewards/margins": 6.4814043045043945,
      "rewards/rejected": -11.405184745788574,
      "step": 6086
    },
    {
      "epoch": 2.4348,
      "grad_norm": 0.036263469606637955,
      "learning_rate": 1.8853333333333333e-07,
      "logits/chosen": -2.7036004066467285,
      "logits/rejected": -2.328752040863037,
      "logps/chosen": -111.42300415039062,
      "logps/rejected": -179.12957763671875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4189525842666626,
      "rewards/margins": 10.855822563171387,
      "rewards/rejected": -11.274774551391602,
      "step": 6087
    },
    {
      "epoch": 2.4352,
      "grad_norm": 0.0023905178532004356,
      "learning_rate": 1.884e-07,
      "logits/chosen": -2.7076077461242676,
      "logits/rejected": -2.3398261070251465,
      "logps/chosen": -87.2547836303711,
      "logps/rejected": -187.57766723632812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5710254311561584,
      "rewards/margins": 12.231260299682617,
      "rewards/rejected": -11.660234451293945,
      "step": 6088
    },
    {
      "epoch": 2.4356,
      "grad_norm": 0.6007197499275208,
      "learning_rate": 1.8826666666666666e-07,
      "logits/chosen": -2.8659071922302246,
      "logits/rejected": -2.4994313716888428,
      "logps/chosen": -57.832252502441406,
      "logps/rejected": -98.96469116210938,
      "loss": 0.0052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0340012311935425,
      "rewards/margins": 6.6602277755737305,
      "rewards/rejected": -5.626226902008057,
      "step": 6089
    },
    {
      "epoch": 2.436,
      "grad_norm": 5.854963302612305,
      "learning_rate": 1.8813333333333335e-07,
      "logits/chosen": -2.4183568954467773,
      "logits/rejected": -2.296841621398926,
      "logps/chosen": -164.67486572265625,
      "logps/rejected": -180.31729125976562,
      "loss": 0.0241,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.987987518310547,
      "rewards/margins": 7.390881538391113,
      "rewards/rejected": -11.378868103027344,
      "step": 6090
    },
    {
      "epoch": 2.4364,
      "grad_norm": 0.006242124363780022,
      "learning_rate": 1.88e-07,
      "logits/chosen": -2.8092823028564453,
      "logits/rejected": -2.217189073562622,
      "logps/chosen": -70.0028076171875,
      "logps/rejected": -172.8092041015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.37425464391708374,
      "rewards/margins": 11.447218894958496,
      "rewards/rejected": -11.821474075317383,
      "step": 6091
    },
    {
      "epoch": 2.4368,
      "grad_norm": 0.02880445122718811,
      "learning_rate": 1.8786666666666665e-07,
      "logits/chosen": -2.747194766998291,
      "logits/rejected": -2.5118062496185303,
      "logps/chosen": -72.87447357177734,
      "logps/rejected": -129.04534912109375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.23827266693115234,
      "rewards/margins": 8.900801658630371,
      "rewards/rejected": -9.139074325561523,
      "step": 6092
    },
    {
      "epoch": 2.4372,
      "grad_norm": 0.008619683794677258,
      "learning_rate": 1.8773333333333332e-07,
      "logits/chosen": -2.700530767440796,
      "logits/rejected": -2.226609706878662,
      "logps/chosen": -94.35824584960938,
      "logps/rejected": -192.80047607421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1731563806533813,
      "rewards/margins": 12.289114952087402,
      "rewards/rejected": -11.115958213806152,
      "step": 6093
    },
    {
      "epoch": 2.4375999999999998,
      "grad_norm": 0.32999640703201294,
      "learning_rate": 1.8759999999999999e-07,
      "logits/chosen": -2.167121171951294,
      "logits/rejected": -1.377257227897644,
      "logps/chosen": -201.30252075195312,
      "logps/rejected": -213.87277221679688,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.8506462574005127,
      "rewards/margins": 11.3242826461792,
      "rewards/rejected": -14.174928665161133,
      "step": 6094
    },
    {
      "epoch": 2.438,
      "grad_norm": 0.26702722907066345,
      "learning_rate": 1.8746666666666665e-07,
      "logits/chosen": -2.4355010986328125,
      "logits/rejected": -1.858071208000183,
      "logps/chosen": -109.03683471679688,
      "logps/rejected": -253.62753295898438,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3057987689971924,
      "rewards/margins": 11.784416198730469,
      "rewards/rejected": -12.090215682983398,
      "step": 6095
    },
    {
      "epoch": 2.4384,
      "grad_norm": 5.8317484855651855,
      "learning_rate": 1.8733333333333332e-07,
      "logits/chosen": -2.8244786262512207,
      "logits/rejected": -2.7122530937194824,
      "logps/chosen": -74.75823974609375,
      "logps/rejected": -98.7802734375,
      "loss": 0.0391,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2766942977905273,
      "rewards/margins": 4.881927490234375,
      "rewards/rejected": -6.158621788024902,
      "step": 6096
    },
    {
      "epoch": 2.4388,
      "grad_norm": 0.030621416866779327,
      "learning_rate": 1.872e-07,
      "logits/chosen": -2.5431885719299316,
      "logits/rejected": -2.060150384902954,
      "logps/chosen": -189.37005615234375,
      "logps/rejected": -140.12615966796875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.49534153938293457,
      "rewards/margins": 8.721490859985352,
      "rewards/rejected": -9.216833114624023,
      "step": 6097
    },
    {
      "epoch": 2.4392,
      "grad_norm": 104.221435546875,
      "learning_rate": 1.8706666666666665e-07,
      "logits/chosen": -2.4531145095825195,
      "logits/rejected": -2.3478169441223145,
      "logps/chosen": -207.9010009765625,
      "logps/rejected": -158.7430419921875,
      "loss": 0.5254,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -6.690500736236572,
      "rewards/margins": 4.3726582527160645,
      "rewards/rejected": -11.063158988952637,
      "step": 6098
    },
    {
      "epoch": 2.4396,
      "grad_norm": 0.021771831437945366,
      "learning_rate": 1.8693333333333334e-07,
      "logits/chosen": -2.321951389312744,
      "logits/rejected": -1.7791800498962402,
      "logps/chosen": -122.04796600341797,
      "logps/rejected": -180.521240234375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0708366632461548,
      "rewards/margins": 11.362824440002441,
      "rewards/rejected": -12.433660507202148,
      "step": 6099
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.10772857069969177,
      "learning_rate": 1.8679999999999998e-07,
      "logits/chosen": -2.8726844787597656,
      "logits/rejected": -2.2092573642730713,
      "logps/chosen": -74.53250122070312,
      "logps/rejected": -148.16310119628906,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9898933172225952,
      "rewards/margins": 12.620462417602539,
      "rewards/rejected": -10.630568504333496,
      "step": 6100
    },
    {
      "epoch": 2.4404,
      "grad_norm": 0.7618544697761536,
      "learning_rate": 1.8666666666666667e-07,
      "logits/chosen": -2.849945068359375,
      "logits/rejected": -2.5588645935058594,
      "logps/chosen": -59.17396545410156,
      "logps/rejected": -97.47779846191406,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3029099702835083,
      "rewards/margins": 7.394105911254883,
      "rewards/rejected": -6.091196060180664,
      "step": 6101
    },
    {
      "epoch": 2.4408,
      "grad_norm": 0.0015717520145699382,
      "learning_rate": 1.865333333333333e-07,
      "logits/chosen": -2.782226085662842,
      "logits/rejected": -2.0134339332580566,
      "logps/chosen": -79.80414581298828,
      "logps/rejected": -233.6421661376953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6179714202880859,
      "rewards/margins": 15.59027099609375,
      "rewards/rejected": -14.972299575805664,
      "step": 6102
    },
    {
      "epoch": 2.4412,
      "grad_norm": 0.0011189704528078437,
      "learning_rate": 1.864e-07,
      "logits/chosen": -2.9916629791259766,
      "logits/rejected": -2.6212148666381836,
      "logps/chosen": -89.65042877197266,
      "logps/rejected": -189.72573852539062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.813067615032196,
      "rewards/margins": 12.450312614440918,
      "rewards/rejected": -11.637245178222656,
      "step": 6103
    },
    {
      "epoch": 2.4416,
      "grad_norm": 7.659887313842773,
      "learning_rate": 1.8626666666666667e-07,
      "logits/chosen": -2.5767316818237305,
      "logits/rejected": -2.0115861892700195,
      "logps/chosen": -144.9150390625,
      "logps/rejected": -113.87863159179688,
      "loss": 0.0388,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5869560241699219,
      "rewards/margins": 7.089235305786133,
      "rewards/rejected": -6.502279281616211,
      "step": 6104
    },
    {
      "epoch": 2.442,
      "grad_norm": 0.007548530586063862,
      "learning_rate": 1.8613333333333333e-07,
      "logits/chosen": -2.704068660736084,
      "logits/rejected": -2.2156221866607666,
      "logps/chosen": -70.54507446289062,
      "logps/rejected": -140.82786560058594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.117568016052246,
      "rewards/margins": 10.422359466552734,
      "rewards/rejected": -9.304791450500488,
      "step": 6105
    },
    {
      "epoch": 2.4424,
      "grad_norm": 0.6172615885734558,
      "learning_rate": 1.86e-07,
      "logits/chosen": -2.3542661666870117,
      "logits/rejected": -2.260002374649048,
      "logps/chosen": -64.43755340576172,
      "logps/rejected": -147.60032653808594,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.13464033603668213,
      "rewards/margins": 9.042723655700684,
      "rewards/rejected": -9.177364349365234,
      "step": 6106
    },
    {
      "epoch": 2.4428,
      "grad_norm": 0.013155710883438587,
      "learning_rate": 1.8586666666666666e-07,
      "logits/chosen": -2.086617946624756,
      "logits/rejected": -1.262430191040039,
      "logps/chosen": -152.8765869140625,
      "logps/rejected": -224.57081604003906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8584697246551514,
      "rewards/margins": 13.55994987487793,
      "rewards/rejected": -15.41841983795166,
      "step": 6107
    },
    {
      "epoch": 2.4432,
      "grad_norm": 0.0005272197886370122,
      "learning_rate": 1.8573333333333333e-07,
      "logits/chosen": -2.6020660400390625,
      "logits/rejected": -2.330549716949463,
      "logps/chosen": -60.63381576538086,
      "logps/rejected": -203.5509033203125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.169089913368225,
      "rewards/margins": 13.52794075012207,
      "rewards/rejected": -12.358851432800293,
      "step": 6108
    },
    {
      "epoch": 2.4436,
      "grad_norm": 0.16495001316070557,
      "learning_rate": 1.8559999999999997e-07,
      "logits/chosen": -2.0589849948883057,
      "logits/rejected": -1.4064717292785645,
      "logps/chosen": -177.62252807617188,
      "logps/rejected": -225.650146484375,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.63573157787323,
      "rewards/margins": 10.784561157226562,
      "rewards/rejected": -12.420293807983398,
      "step": 6109
    },
    {
      "epoch": 2.444,
      "grad_norm": 0.408725380897522,
      "learning_rate": 1.8546666666666666e-07,
      "logits/chosen": -2.6285030841827393,
      "logits/rejected": -2.3940041065216064,
      "logps/chosen": -120.74333953857422,
      "logps/rejected": -138.74705505371094,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5872020721435547,
      "rewards/margins": 7.530604839324951,
      "rewards/rejected": -9.117807388305664,
      "step": 6110
    },
    {
      "epoch": 2.4444,
      "grad_norm": 4.949172019958496,
      "learning_rate": 1.8533333333333333e-07,
      "logits/chosen": -3.0414180755615234,
      "logits/rejected": -2.7842137813568115,
      "logps/chosen": -81.49360656738281,
      "logps/rejected": -107.49049377441406,
      "loss": 0.0291,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7674671411514282,
      "rewards/margins": 5.110215187072754,
      "rewards/rejected": -6.877682209014893,
      "step": 6111
    },
    {
      "epoch": 2.4448,
      "grad_norm": 0.014017543755471706,
      "learning_rate": 1.852e-07,
      "logits/chosen": -2.6209566593170166,
      "logits/rejected": -2.4013471603393555,
      "logps/chosen": -65.47184753417969,
      "logps/rejected": -199.2345733642578,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.11917328834533691,
      "rewards/margins": 9.907724380493164,
      "rewards/rejected": -10.026897430419922,
      "step": 6112
    },
    {
      "epoch": 2.4452,
      "grad_norm": 91.23313903808594,
      "learning_rate": 1.8506666666666666e-07,
      "logits/chosen": -2.6633501052856445,
      "logits/rejected": -2.5245118141174316,
      "logps/chosen": -155.13165283203125,
      "logps/rejected": -132.8223114013672,
      "loss": 0.4345,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -3.9134931564331055,
      "rewards/margins": 5.775680065155029,
      "rewards/rejected": -9.689172744750977,
      "step": 6113
    },
    {
      "epoch": 2.4455999999999998,
      "grad_norm": 2.664149284362793,
      "learning_rate": 1.8493333333333332e-07,
      "logits/chosen": -2.6723744869232178,
      "logits/rejected": -2.544403553009033,
      "logps/chosen": -96.74006652832031,
      "logps/rejected": -160.72085571289062,
      "loss": 0.0141,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.947608470916748,
      "rewards/margins": 5.941071033477783,
      "rewards/rejected": -9.888679504394531,
      "step": 6114
    },
    {
      "epoch": 2.446,
      "grad_norm": 0.019157394766807556,
      "learning_rate": 1.848e-07,
      "logits/chosen": -2.167387008666992,
      "logits/rejected": -2.1743602752685547,
      "logps/chosen": -181.823486328125,
      "logps/rejected": -181.14990234375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.182796001434326,
      "rewards/margins": 9.802688598632812,
      "rewards/rejected": -11.985485076904297,
      "step": 6115
    },
    {
      "epoch": 2.4464,
      "grad_norm": 0.0009179026819765568,
      "learning_rate": 1.8466666666666665e-07,
      "logits/chosen": -2.6473798751831055,
      "logits/rejected": -2.133848190307617,
      "logps/chosen": -123.12825012207031,
      "logps/rejected": -187.27291870117188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1124773025512695,
      "rewards/margins": 13.117164611816406,
      "rewards/rejected": -11.004688262939453,
      "step": 6116
    },
    {
      "epoch": 2.4468,
      "grad_norm": 0.30613791942596436,
      "learning_rate": 1.8453333333333332e-07,
      "logits/chosen": -2.9595894813537598,
      "logits/rejected": -2.4356701374053955,
      "logps/chosen": -70.45089721679688,
      "logps/rejected": -115.55384826660156,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22761917114257812,
      "rewards/margins": 6.901951789855957,
      "rewards/rejected": -6.674332618713379,
      "step": 6117
    },
    {
      "epoch": 2.4472,
      "grad_norm": 0.3483435809612274,
      "learning_rate": 1.844e-07,
      "logits/chosen": -2.2759156227111816,
      "logits/rejected": -1.9239580631256104,
      "logps/chosen": -219.72750854492188,
      "logps/rejected": -169.38426208496094,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.163687229156494,
      "rewards/margins": 7.367632865905762,
      "rewards/rejected": -10.531319618225098,
      "step": 6118
    },
    {
      "epoch": 2.4476,
      "grad_norm": 0.02403055876493454,
      "learning_rate": 1.8426666666666665e-07,
      "logits/chosen": -2.8076529502868652,
      "logits/rejected": -2.4425759315490723,
      "logps/chosen": -126.76861572265625,
      "logps/rejected": -132.67071533203125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5678516626358032,
      "rewards/margins": 8.685823440551758,
      "rewards/rejected": -8.117971420288086,
      "step": 6119
    },
    {
      "epoch": 2.448,
      "grad_norm": 0.02838623896241188,
      "learning_rate": 1.8413333333333334e-07,
      "logits/chosen": -2.6468310356140137,
      "logits/rejected": -2.0165634155273438,
      "logps/chosen": -100.14930725097656,
      "logps/rejected": -198.81924438476562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.24927091598510742,
      "rewards/margins": 12.678241729736328,
      "rewards/rejected": -12.927513122558594,
      "step": 6120
    },
    {
      "epoch": 2.4484,
      "grad_norm": 0.0006254615145735443,
      "learning_rate": 1.8399999999999998e-07,
      "logits/chosen": -2.7357819080352783,
      "logits/rejected": -2.1666879653930664,
      "logps/chosen": -103.51008605957031,
      "logps/rejected": -222.64669799804688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3427108526229858,
      "rewards/margins": 14.228571891784668,
      "rewards/rejected": -15.571282386779785,
      "step": 6121
    },
    {
      "epoch": 2.4488,
      "grad_norm": 0.01579456776380539,
      "learning_rate": 1.8386666666666667e-07,
      "logits/chosen": -2.7579352855682373,
      "logits/rejected": -2.5867323875427246,
      "logps/chosen": -66.38009643554688,
      "logps/rejected": -126.24505615234375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6504722833633423,
      "rewards/margins": 10.05479907989502,
      "rewards/rejected": -8.404327392578125,
      "step": 6122
    },
    {
      "epoch": 2.4492,
      "grad_norm": 0.0067974780686199665,
      "learning_rate": 1.837333333333333e-07,
      "logits/chosen": -2.710526943206787,
      "logits/rejected": -2.4363930225372314,
      "logps/chosen": -111.74449157714844,
      "logps/rejected": -155.60301208496094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3412727415561676,
      "rewards/margins": 10.832545280456543,
      "rewards/rejected": -10.491272926330566,
      "step": 6123
    },
    {
      "epoch": 2.4496,
      "grad_norm": 0.4858885705471039,
      "learning_rate": 1.836e-07,
      "logits/chosen": -2.6721949577331543,
      "logits/rejected": -2.4036130905151367,
      "logps/chosen": -95.20777893066406,
      "logps/rejected": -181.94873046875,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.854524612426758,
      "rewards/margins": 9.48682689666748,
      "rewards/rejected": -12.341352462768555,
      "step": 6124
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.21095608174800873,
      "learning_rate": 1.8346666666666667e-07,
      "logits/chosen": -2.3466217517852783,
      "logits/rejected": -1.8052895069122314,
      "logps/chosen": -116.03123474121094,
      "logps/rejected": -179.11904907226562,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8924663066864014,
      "rewards/margins": 11.689081192016602,
      "rewards/rejected": -12.581548690795898,
      "step": 6125
    },
    {
      "epoch": 2.4504,
      "grad_norm": 0.00017412961460649967,
      "learning_rate": 1.833333333333333e-07,
      "logits/chosen": -2.596022129058838,
      "logits/rejected": -1.8929294347763062,
      "logps/chosen": -113.78266143798828,
      "logps/rejected": -251.45497131347656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.43141257762908936,
      "rewards/margins": 15.179651260375977,
      "rewards/rejected": -15.611063957214355,
      "step": 6126
    },
    {
      "epoch": 2.4508,
      "grad_norm": 0.0016985539114102721,
      "learning_rate": 1.832e-07,
      "logits/chosen": -2.468686103820801,
      "logits/rejected": -1.9918529987335205,
      "logps/chosen": -85.20204162597656,
      "logps/rejected": -231.30943298339844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3294124603271484,
      "rewards/margins": 12.323493957519531,
      "rewards/rejected": -10.994081497192383,
      "step": 6127
    },
    {
      "epoch": 2.4512,
      "grad_norm": 0.00347388768568635,
      "learning_rate": 1.8306666666666664e-07,
      "logits/chosen": -2.622562885284424,
      "logits/rejected": -1.9867606163024902,
      "logps/chosen": -125.78790283203125,
      "logps/rejected": -214.53150939941406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8862788677215576,
      "rewards/margins": 12.773636817932129,
      "rewards/rejected": -14.659915924072266,
      "step": 6128
    },
    {
      "epoch": 2.4516,
      "grad_norm": 2.3430378437042236,
      "learning_rate": 1.8293333333333333e-07,
      "logits/chosen": -2.9761037826538086,
      "logits/rejected": -2.5606977939605713,
      "logps/chosen": -77.52983093261719,
      "logps/rejected": -116.28532409667969,
      "loss": 0.0114,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.445914089679718,
      "rewards/margins": 8.335206031799316,
      "rewards/rejected": -7.889291763305664,
      "step": 6129
    },
    {
      "epoch": 2.452,
      "grad_norm": 1.4331153631210327,
      "learning_rate": 1.8279999999999997e-07,
      "logits/chosen": -2.612394332885742,
      "logits/rejected": -2.0241427421569824,
      "logps/chosen": -158.89111328125,
      "logps/rejected": -189.22332763671875,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9591149091720581,
      "rewards/margins": 10.75268840789795,
      "rewards/rejected": -11.71180248260498,
      "step": 6130
    },
    {
      "epoch": 2.4524,
      "grad_norm": 0.03002595715224743,
      "learning_rate": 1.8266666666666666e-07,
      "logits/chosen": -2.8165464401245117,
      "logits/rejected": -2.440446615219116,
      "logps/chosen": -84.20195007324219,
      "logps/rejected": -145.30393981933594,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.828799843788147,
      "rewards/margins": 10.37833023071289,
      "rewards/rejected": -9.549530029296875,
      "step": 6131
    },
    {
      "epoch": 2.4528,
      "grad_norm": 7.80112313805148e-05,
      "learning_rate": 1.8253333333333333e-07,
      "logits/chosen": -2.7349324226379395,
      "logits/rejected": -2.081754446029663,
      "logps/chosen": -79.66947174072266,
      "logps/rejected": -198.0959930419922,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6946358680725098,
      "rewards/margins": 15.25466251373291,
      "rewards/rejected": -13.560026168823242,
      "step": 6132
    },
    {
      "epoch": 2.4532,
      "grad_norm": 0.003754759207367897,
      "learning_rate": 1.824e-07,
      "logits/chosen": -2.4281625747680664,
      "logits/rejected": -1.6641145944595337,
      "logps/chosen": -90.83760070800781,
      "logps/rejected": -184.08102416992188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1559112071990967,
      "rewards/margins": 11.276988983154297,
      "rewards/rejected": -12.432899475097656,
      "step": 6133
    },
    {
      "epoch": 2.4536,
      "grad_norm": 0.01373895164579153,
      "learning_rate": 1.8226666666666666e-07,
      "logits/chosen": -2.7390618324279785,
      "logits/rejected": -2.479158401489258,
      "logps/chosen": -114.57640075683594,
      "logps/rejected": -139.19461059570312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3445442318916321,
      "rewards/margins": 9.224214553833008,
      "rewards/rejected": -8.879670143127441,
      "step": 6134
    },
    {
      "epoch": 2.454,
      "grad_norm": 0.010291555896401405,
      "learning_rate": 1.8213333333333332e-07,
      "logits/chosen": -2.5563454627990723,
      "logits/rejected": -2.1105294227600098,
      "logps/chosen": -76.35751342773438,
      "logps/rejected": -172.40542602539062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5532108545303345,
      "rewards/margins": 10.670427322387695,
      "rewards/rejected": -10.117216110229492,
      "step": 6135
    },
    {
      "epoch": 2.4544,
      "grad_norm": 0.1467631608247757,
      "learning_rate": 1.82e-07,
      "logits/chosen": -2.6589927673339844,
      "logits/rejected": -2.2287306785583496,
      "logps/chosen": -104.55548095703125,
      "logps/rejected": -184.87161254882812,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08296126127243042,
      "rewards/margins": 12.322881698608398,
      "rewards/rejected": -12.239919662475586,
      "step": 6136
    },
    {
      "epoch": 2.4548,
      "grad_norm": 9.241499355994165e-05,
      "learning_rate": 1.8186666666666668e-07,
      "logits/chosen": -2.2690858840942383,
      "logits/rejected": -1.7224671840667725,
      "logps/chosen": -146.7216796875,
      "logps/rejected": -193.2029571533203,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.15825617313385,
      "rewards/margins": 14.925521850585938,
      "rewards/rejected": -13.767265319824219,
      "step": 6137
    },
    {
      "epoch": 2.4552,
      "grad_norm": 11.02541732788086,
      "learning_rate": 1.8173333333333332e-07,
      "logits/chosen": -2.9099063873291016,
      "logits/rejected": -2.7640738487243652,
      "logps/chosen": -105.54695129394531,
      "logps/rejected": -116.42266845703125,
      "loss": 0.0465,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7087427377700806,
      "rewards/margins": 7.030959129333496,
      "rewards/rejected": -7.739702224731445,
      "step": 6138
    },
    {
      "epoch": 2.4556,
      "grad_norm": 0.033674612641334534,
      "learning_rate": 1.816e-07,
      "logits/chosen": -2.6944212913513184,
      "logits/rejected": -2.052405834197998,
      "logps/chosen": -123.49005889892578,
      "logps/rejected": -183.99559020996094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8911791443824768,
      "rewards/margins": 11.290363311767578,
      "rewards/rejected": -12.181541442871094,
      "step": 6139
    },
    {
      "epoch": 2.456,
      "grad_norm": 0.006925890222191811,
      "learning_rate": 1.8146666666666665e-07,
      "logits/chosen": -2.627978563308716,
      "logits/rejected": -2.120964527130127,
      "logps/chosen": -55.87820053100586,
      "logps/rejected": -168.60501098632812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3488714098930359,
      "rewards/margins": 11.877191543579102,
      "rewards/rejected": -12.226062774658203,
      "step": 6140
    },
    {
      "epoch": 2.4564,
      "grad_norm": 0.0002689951506908983,
      "learning_rate": 1.8133333333333334e-07,
      "logits/chosen": -2.39182710647583,
      "logits/rejected": -1.958981990814209,
      "logps/chosen": -141.91519165039062,
      "logps/rejected": -189.10357666015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1631622314453125,
      "rewards/margins": 13.734367370605469,
      "rewards/rejected": -13.897529602050781,
      "step": 6141
    },
    {
      "epoch": 2.4568,
      "grad_norm": 0.0017701196484267712,
      "learning_rate": 1.8119999999999998e-07,
      "logits/chosen": -2.443666458129883,
      "logits/rejected": -2.1131374835968018,
      "logps/chosen": -111.50247192382812,
      "logps/rejected": -205.53134155273438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8282387256622314,
      "rewards/margins": 15.00780963897705,
      "rewards/rejected": -14.179571151733398,
      "step": 6142
    },
    {
      "epoch": 2.4572,
      "grad_norm": 0.05085916817188263,
      "learning_rate": 1.8106666666666665e-07,
      "logits/chosen": -2.3401780128479004,
      "logits/rejected": -1.8030991554260254,
      "logps/chosen": -74.35454559326172,
      "logps/rejected": -139.99008178710938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17877158522605896,
      "rewards/margins": 11.000458717346191,
      "rewards/rejected": -10.821686744689941,
      "step": 6143
    },
    {
      "epoch": 2.4576000000000002,
      "grad_norm": 0.2916077971458435,
      "learning_rate": 1.8093333333333334e-07,
      "logits/chosen": -2.568270444869995,
      "logits/rejected": -1.9530431032180786,
      "logps/chosen": -87.23545837402344,
      "logps/rejected": -138.78216552734375,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8391263484954834,
      "rewards/margins": 10.593421936035156,
      "rewards/rejected": -8.75429630279541,
      "step": 6144
    },
    {
      "epoch": 2.458,
      "grad_norm": 0.7225951552391052,
      "learning_rate": 1.8079999999999998e-07,
      "logits/chosen": -2.6998212337493896,
      "logits/rejected": -2.4425222873687744,
      "logps/chosen": -81.52070617675781,
      "logps/rejected": -200.48446655273438,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4691885709762573,
      "rewards/margins": 10.889785766601562,
      "rewards/rejected": -11.35897445678711,
      "step": 6145
    },
    {
      "epoch": 2.4584,
      "grad_norm": 1.8829281330108643,
      "learning_rate": 1.8066666666666667e-07,
      "logits/chosen": -2.845503807067871,
      "logits/rejected": -2.664412498474121,
      "logps/chosen": -77.51903533935547,
      "logps/rejected": -111.17185974121094,
      "loss": 0.0088,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5678956508636475,
      "rewards/margins": 7.870417594909668,
      "rewards/rejected": -7.302521705627441,
      "step": 6146
    },
    {
      "epoch": 2.4588,
      "grad_norm": 0.022684896364808083,
      "learning_rate": 1.805333333333333e-07,
      "logits/chosen": -2.5062780380249023,
      "logits/rejected": -1.7614104747772217,
      "logps/chosen": -131.8992919921875,
      "logps/rejected": -176.79324340820312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5120643377304077,
      "rewards/margins": 10.094015121459961,
      "rewards/rejected": -10.606080055236816,
      "step": 6147
    },
    {
      "epoch": 2.4592,
      "grad_norm": 35.03139114379883,
      "learning_rate": 1.804e-07,
      "logits/chosen": -2.821991443634033,
      "logits/rejected": -2.6880006790161133,
      "logps/chosen": -79.8756103515625,
      "logps/rejected": -82.04130554199219,
      "loss": 0.2054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5614372491836548,
      "rewards/margins": 4.6018500328063965,
      "rewards/rejected": -5.163287162780762,
      "step": 6148
    },
    {
      "epoch": 2.4596,
      "grad_norm": 0.005085831042379141,
      "learning_rate": 1.8026666666666664e-07,
      "logits/chosen": -2.553497791290283,
      "logits/rejected": -1.8705629110336304,
      "logps/chosen": -125.4888916015625,
      "logps/rejected": -259.68341064453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40547066926956177,
      "rewards/margins": 12.747434616088867,
      "rewards/rejected": -12.341964721679688,
      "step": 6149
    },
    {
      "epoch": 2.46,
      "grad_norm": 5.462892532348633,
      "learning_rate": 1.8013333333333333e-07,
      "logits/chosen": -2.723750114440918,
      "logits/rejected": -2.5026497840881348,
      "logps/chosen": -187.8755340576172,
      "logps/rejected": -178.90469360351562,
      "loss": 0.0145,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.9134533405303955,
      "rewards/margins": 8.523916244506836,
      "rewards/rejected": -11.437370300292969,
      "step": 6150
    },
    {
      "epoch": 2.4604,
      "grad_norm": 0.11595378816127777,
      "learning_rate": 1.8e-07,
      "logits/chosen": -2.1083009243011475,
      "logits/rejected": -1.759795904159546,
      "logps/chosen": -108.6789321899414,
      "logps/rejected": -199.72476196289062,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.21688538789749146,
      "rewards/margins": 10.738719940185547,
      "rewards/rejected": -10.955604553222656,
      "step": 6151
    },
    {
      "epoch": 2.4608,
      "grad_norm": 0.018113907426595688,
      "learning_rate": 1.7986666666666666e-07,
      "logits/chosen": -2.4377315044403076,
      "logits/rejected": -1.8456239700317383,
      "logps/chosen": -107.95260620117188,
      "logps/rejected": -166.4805450439453,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.16641521453857422,
      "rewards/margins": 9.422779083251953,
      "rewards/rejected": -9.589194297790527,
      "step": 6152
    },
    {
      "epoch": 2.4612,
      "grad_norm": 0.07064204663038254,
      "learning_rate": 1.7973333333333333e-07,
      "logits/chosen": -2.866919994354248,
      "logits/rejected": -2.3965888023376465,
      "logps/chosen": -58.52229309082031,
      "logps/rejected": -109.22708129882812,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5585095882415771,
      "rewards/margins": 7.442030906677246,
      "rewards/rejected": -6.88352108001709,
      "step": 6153
    },
    {
      "epoch": 2.4616,
      "grad_norm": 0.0004933724412694573,
      "learning_rate": 1.796e-07,
      "logits/chosen": -2.920771598815918,
      "logits/rejected": -2.372441291809082,
      "logps/chosen": -49.063194274902344,
      "logps/rejected": -195.40093994140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9740999341011047,
      "rewards/margins": 13.888229370117188,
      "rewards/rejected": -12.914130210876465,
      "step": 6154
    },
    {
      "epoch": 2.462,
      "grad_norm": 0.05764854699373245,
      "learning_rate": 1.7946666666666666e-07,
      "logits/chosen": -2.7056968212127686,
      "logits/rejected": -2.3384416103363037,
      "logps/chosen": -55.89606475830078,
      "logps/rejected": -147.93275451660156,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2834932804107666,
      "rewards/margins": 10.364534378051758,
      "rewards/rejected": -9.08104133605957,
      "step": 6155
    },
    {
      "epoch": 2.4624,
      "grad_norm": 0.003707459196448326,
      "learning_rate": 1.7933333333333332e-07,
      "logits/chosen": -2.962752342224121,
      "logits/rejected": -2.4495742321014404,
      "logps/chosen": -75.38168334960938,
      "logps/rejected": -158.962646484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2401164770126343,
      "rewards/margins": 11.27745246887207,
      "rewards/rejected": -10.037336349487305,
      "step": 6156
    },
    {
      "epoch": 2.4628,
      "grad_norm": 6.424575258279219e-05,
      "learning_rate": 1.792e-07,
      "logits/chosen": -2.682236671447754,
      "logits/rejected": -1.8163931369781494,
      "logps/chosen": -80.18775939941406,
      "logps/rejected": -194.32192993164062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.120371103286743,
      "rewards/margins": 15.64156436920166,
      "rewards/rejected": -13.52119255065918,
      "step": 6157
    },
    {
      "epoch": 2.4632,
      "grad_norm": 0.11556889116764069,
      "learning_rate": 1.7906666666666668e-07,
      "logits/chosen": -2.6454195976257324,
      "logits/rejected": -2.1854846477508545,
      "logps/chosen": -69.87945556640625,
      "logps/rejected": -199.4490966796875,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3789993226528168,
      "rewards/margins": 13.983863830566406,
      "rewards/rejected": -13.604864120483398,
      "step": 6158
    },
    {
      "epoch": 2.4636,
      "grad_norm": 0.0033126117195934057,
      "learning_rate": 1.7893333333333332e-07,
      "logits/chosen": -2.8128883838653564,
      "logits/rejected": -2.1707844734191895,
      "logps/chosen": -101.23892211914062,
      "logps/rejected": -182.79800415039062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04622960090637207,
      "rewards/margins": 12.032960891723633,
      "rewards/rejected": -11.98673152923584,
      "step": 6159
    },
    {
      "epoch": 2.464,
      "grad_norm": 0.35899773240089417,
      "learning_rate": 1.7879999999999999e-07,
      "logits/chosen": -2.696918249130249,
      "logits/rejected": -2.2590932846069336,
      "logps/chosen": -60.33164596557617,
      "logps/rejected": -159.94163513183594,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.257805347442627,
      "rewards/margins": 11.370159149169922,
      "rewards/rejected": -10.112353324890137,
      "step": 6160
    },
    {
      "epoch": 2.4644,
      "grad_norm": 0.04890717938542366,
      "learning_rate": 1.7866666666666665e-07,
      "logits/chosen": -2.449828624725342,
      "logits/rejected": -1.8210943937301636,
      "logps/chosen": -160.0694580078125,
      "logps/rejected": -191.3090057373047,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5605136752128601,
      "rewards/margins": 11.92851448059082,
      "rewards/rejected": -12.489027976989746,
      "step": 6161
    },
    {
      "epoch": 2.4648,
      "grad_norm": 0.034615784883499146,
      "learning_rate": 1.7853333333333332e-07,
      "logits/chosen": -2.879967451095581,
      "logits/rejected": -2.442347526550293,
      "logps/chosen": -73.15385437011719,
      "logps/rejected": -133.44552612304688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02420082688331604,
      "rewards/margins": 8.510204315185547,
      "rewards/rejected": -8.486002922058105,
      "step": 6162
    },
    {
      "epoch": 2.4652,
      "grad_norm": 0.003652445040643215,
      "learning_rate": 1.7839999999999998e-07,
      "logits/chosen": -2.6981253623962402,
      "logits/rejected": -2.2433409690856934,
      "logps/chosen": -122.97415161132812,
      "logps/rejected": -167.6671142578125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.24940072000026703,
      "rewards/margins": 11.088733673095703,
      "rewards/rejected": -11.338134765625,
      "step": 6163
    },
    {
      "epoch": 2.4656000000000002,
      "grad_norm": 4.159973621368408,
      "learning_rate": 1.7826666666666665e-07,
      "logits/chosen": -2.7941231727600098,
      "logits/rejected": -2.345032215118408,
      "logps/chosen": -90.36470031738281,
      "logps/rejected": -197.63381958007812,
      "loss": 0.0327,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3616516590118408,
      "rewards/margins": 10.756397247314453,
      "rewards/rejected": -12.118048667907715,
      "step": 6164
    },
    {
      "epoch": 2.466,
      "grad_norm": 0.0003997384919784963,
      "learning_rate": 1.7813333333333334e-07,
      "logits/chosen": -2.484579086303711,
      "logits/rejected": -1.8762190341949463,
      "logps/chosen": -109.88282012939453,
      "logps/rejected": -246.6092987060547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5181000232696533,
      "rewards/margins": 16.375152587890625,
      "rewards/rejected": -14.857053756713867,
      "step": 6165
    },
    {
      "epoch": 2.4664,
      "grad_norm": 0.00010886068048421293,
      "learning_rate": 1.7799999999999998e-07,
      "logits/chosen": -2.403409004211426,
      "logits/rejected": -1.4766566753387451,
      "logps/chosen": -116.70516967773438,
      "logps/rejected": -201.34564208984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0796314477920532,
      "rewards/margins": 15.153993606567383,
      "rewards/rejected": -14.074361801147461,
      "step": 6166
    },
    {
      "epoch": 2.4668,
      "grad_norm": 0.013914423063397408,
      "learning_rate": 1.7786666666666667e-07,
      "logits/chosen": -2.6802315711975098,
      "logits/rejected": -1.8651857376098633,
      "logps/chosen": -176.17796325683594,
      "logps/rejected": -178.34292602539062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8376610279083252,
      "rewards/margins": 10.03571891784668,
      "rewards/rejected": -10.87337875366211,
      "step": 6167
    },
    {
      "epoch": 2.4672,
      "grad_norm": 0.003707914613187313,
      "learning_rate": 1.777333333333333e-07,
      "logits/chosen": -2.8678159713745117,
      "logits/rejected": -2.3237643241882324,
      "logps/chosen": -71.66366577148438,
      "logps/rejected": -174.6963653564453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1284420490264893,
      "rewards/margins": 13.134539604187012,
      "rewards/rejected": -12.006097793579102,
      "step": 6168
    },
    {
      "epoch": 2.4676,
      "grad_norm": 0.30628547072410583,
      "learning_rate": 1.776e-07,
      "logits/chosen": -2.680469036102295,
      "logits/rejected": -2.259277820587158,
      "logps/chosen": -67.24481964111328,
      "logps/rejected": -137.49673461914062,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5269836783409119,
      "rewards/margins": 8.305288314819336,
      "rewards/rejected": -8.83227252960205,
      "step": 6169
    },
    {
      "epoch": 2.468,
      "grad_norm": 0.11536956578493118,
      "learning_rate": 1.7746666666666664e-07,
      "logits/chosen": -2.3230581283569336,
      "logits/rejected": -1.6882823705673218,
      "logps/chosen": -61.17929458618164,
      "logps/rejected": -106.1392822265625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1125385761260986,
      "rewards/margins": 8.51301383972168,
      "rewards/rejected": -6.40047550201416,
      "step": 6170
    },
    {
      "epoch": 2.4684,
      "grad_norm": 1.1748323440551758,
      "learning_rate": 1.7733333333333333e-07,
      "logits/chosen": -2.790318489074707,
      "logits/rejected": -2.2857701778411865,
      "logps/chosen": -74.49663543701172,
      "logps/rejected": -170.3834686279297,
      "loss": 0.0091,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.26996156573295593,
      "rewards/margins": 11.720335006713867,
      "rewards/rejected": -11.990297317504883,
      "step": 6171
    },
    {
      "epoch": 2.4688,
      "grad_norm": 0.007606490049511194,
      "learning_rate": 1.772e-07,
      "logits/chosen": -2.618025779724121,
      "logits/rejected": -1.8893380165100098,
      "logps/chosen": -199.8777618408203,
      "logps/rejected": -239.19955444335938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.427668809890747,
      "rewards/margins": 12.050049781799316,
      "rewards/rejected": -14.477718353271484,
      "step": 6172
    },
    {
      "epoch": 2.4692,
      "grad_norm": 0.0005236133001744747,
      "learning_rate": 1.7706666666666666e-07,
      "logits/chosen": -2.808241844177246,
      "logits/rejected": -2.242428779602051,
      "logps/chosen": -85.97634887695312,
      "logps/rejected": -199.48834228515625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17799624800682068,
      "rewards/margins": 13.218938827514648,
      "rewards/rejected": -13.040943145751953,
      "step": 6173
    },
    {
      "epoch": 2.4696,
      "grad_norm": 24.631696701049805,
      "learning_rate": 1.7693333333333333e-07,
      "logits/chosen": -2.471571922302246,
      "logits/rejected": -2.3193764686584473,
      "logps/chosen": -122.42450714111328,
      "logps/rejected": -176.18148803710938,
      "loss": 0.1228,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3864947557449341,
      "rewards/margins": 8.757867813110352,
      "rewards/rejected": -9.144362449645996,
      "step": 6174
    },
    {
      "epoch": 2.4699999999999998,
      "grad_norm": 0.9601830840110779,
      "learning_rate": 1.768e-07,
      "logits/chosen": -2.368208408355713,
      "logits/rejected": -2.4874048233032227,
      "logps/chosen": -94.8030014038086,
      "logps/rejected": -110.28675842285156,
      "loss": 0.0056,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2047828733921051,
      "rewards/margins": 6.468496799468994,
      "rewards/rejected": -6.673279762268066,
      "step": 6175
    },
    {
      "epoch": 2.4704,
      "grad_norm": 0.03895391896367073,
      "learning_rate": 1.7666666666666666e-07,
      "logits/chosen": -2.821998119354248,
      "logits/rejected": -2.4357471466064453,
      "logps/chosen": -118.009033203125,
      "logps/rejected": -160.73248291015625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9480571746826172,
      "rewards/margins": 9.12720775604248,
      "rewards/rejected": -10.075264930725098,
      "step": 6176
    },
    {
      "epoch": 2.4708,
      "grad_norm": 0.03395918756723404,
      "learning_rate": 1.765333333333333e-07,
      "logits/chosen": -2.4279587268829346,
      "logits/rejected": -2.106295347213745,
      "logps/chosen": -81.92196655273438,
      "logps/rejected": -182.7591552734375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7056102752685547,
      "rewards/margins": 8.980255126953125,
      "rewards/rejected": -8.27464485168457,
      "step": 6177
    },
    {
      "epoch": 2.4712,
      "grad_norm": 0.6259584426879883,
      "learning_rate": 1.764e-07,
      "logits/chosen": -2.7260446548461914,
      "logits/rejected": -2.321467876434326,
      "logps/chosen": -85.33747863769531,
      "logps/rejected": -125.24342346191406,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6256564855575562,
      "rewards/margins": 9.870068550109863,
      "rewards/rejected": -8.244412422180176,
      "step": 6178
    },
    {
      "epoch": 2.4716,
      "grad_norm": 0.04821131378412247,
      "learning_rate": 1.7626666666666666e-07,
      "logits/chosen": -2.7177939414978027,
      "logits/rejected": -2.494765281677246,
      "logps/chosen": -152.45339965820312,
      "logps/rejected": -135.22042846679688,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0950569212436676,
      "rewards/margins": 8.16445255279541,
      "rewards/rejected": -8.259509086608887,
      "step": 6179
    },
    {
      "epoch": 2.472,
      "grad_norm": 0.3521164655685425,
      "learning_rate": 1.7613333333333332e-07,
      "logits/chosen": -2.7609405517578125,
      "logits/rejected": -2.611680269241333,
      "logps/chosen": -79.58948516845703,
      "logps/rejected": -95.16668701171875,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5698879361152649,
      "rewards/margins": 6.062711715698242,
      "rewards/rejected": -6.632599830627441,
      "step": 6180
    },
    {
      "epoch": 2.4724,
      "grad_norm": 0.015134595334529877,
      "learning_rate": 1.76e-07,
      "logits/chosen": -2.819042205810547,
      "logits/rejected": -2.588728666305542,
      "logps/chosen": -59.12159729003906,
      "logps/rejected": -134.21847534179688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22941184043884277,
      "rewards/margins": 9.629034996032715,
      "rewards/rejected": -9.399622917175293,
      "step": 6181
    },
    {
      "epoch": 2.4728,
      "grad_norm": 0.029099352657794952,
      "learning_rate": 1.7586666666666665e-07,
      "logits/chosen": -2.8940179347991943,
      "logits/rejected": -2.3313324451446533,
      "logps/chosen": -56.059505462646484,
      "logps/rejected": -155.92144775390625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04134407639503479,
      "rewards/margins": 10.264442443847656,
      "rewards/rejected": -10.223097801208496,
      "step": 6182
    },
    {
      "epoch": 2.4732,
      "grad_norm": 0.14627769589424133,
      "learning_rate": 1.7573333333333332e-07,
      "logits/chosen": -2.6765551567077637,
      "logits/rejected": -2.0633697509765625,
      "logps/chosen": -115.05896759033203,
      "logps/rejected": -149.1445770263672,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.36763185262680054,
      "rewards/margins": 9.853998184204102,
      "rewards/rejected": -9.486366271972656,
      "step": 6183
    },
    {
      "epoch": 2.4736000000000002,
      "grad_norm": 0.014499824494123459,
      "learning_rate": 1.756e-07,
      "logits/chosen": -2.3777763843536377,
      "logits/rejected": -1.9679163694381714,
      "logps/chosen": -185.54986572265625,
      "logps/rejected": -159.59503173828125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.955340564250946,
      "rewards/margins": 10.967143058776855,
      "rewards/rejected": -11.922483444213867,
      "step": 6184
    },
    {
      "epoch": 2.474,
      "grad_norm": 0.0008891617762856185,
      "learning_rate": 1.7546666666666665e-07,
      "logits/chosen": -2.3264174461364746,
      "logits/rejected": -1.7825262546539307,
      "logps/chosen": -84.6204833984375,
      "logps/rejected": -183.55873107910156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0015422701835632324,
      "rewards/margins": 12.62631607055664,
      "rewards/rejected": -12.62785816192627,
      "step": 6185
    },
    {
      "epoch": 2.4744,
      "grad_norm": 0.06570936739444733,
      "learning_rate": 1.7533333333333334e-07,
      "logits/chosen": -2.8506059646606445,
      "logits/rejected": -3.002255916595459,
      "logps/chosen": -105.57945251464844,
      "logps/rejected": -117.50446319580078,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.18699872493743896,
      "rewards/margins": 8.117782592773438,
      "rewards/rejected": -8.304781913757324,
      "step": 6186
    },
    {
      "epoch": 2.4748,
      "grad_norm": 0.017629796639084816,
      "learning_rate": 1.7519999999999998e-07,
      "logits/chosen": -2.615328311920166,
      "logits/rejected": -1.905254602432251,
      "logps/chosen": -96.89376831054688,
      "logps/rejected": -148.09271240234375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5655903816223145,
      "rewards/margins": 9.727799415588379,
      "rewards/rejected": -8.162208557128906,
      "step": 6187
    },
    {
      "epoch": 2.4752,
      "grad_norm": 3.6867291927337646,
      "learning_rate": 1.7506666666666667e-07,
      "logits/chosen": -2.8868649005889893,
      "logits/rejected": -2.594066619873047,
      "logps/chosen": -112.44302368164062,
      "logps/rejected": -122.897705078125,
      "loss": 0.0168,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6017460227012634,
      "rewards/margins": 6.873154640197754,
      "rewards/rejected": -7.474900245666504,
      "step": 6188
    },
    {
      "epoch": 2.4756,
      "grad_norm": 1.9878040552139282,
      "learning_rate": 1.749333333333333e-07,
      "logits/chosen": -2.09909987449646,
      "logits/rejected": -2.0125701427459717,
      "logps/chosen": -80.84461975097656,
      "logps/rejected": -162.786865234375,
      "loss": 0.0111,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.13879279792308807,
      "rewards/margins": 10.083019256591797,
      "rewards/rejected": -10.22181224822998,
      "step": 6189
    },
    {
      "epoch": 2.476,
      "grad_norm": 0.0186914149671793,
      "learning_rate": 1.748e-07,
      "logits/chosen": -2.816190004348755,
      "logits/rejected": -2.286062717437744,
      "logps/chosen": -99.05389404296875,
      "logps/rejected": -137.6058349609375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0879108905792236,
      "rewards/margins": 10.198802947998047,
      "rewards/rejected": -9.110891342163086,
      "step": 6190
    },
    {
      "epoch": 2.4764,
      "grad_norm": 1.4329180717468262,
      "learning_rate": 1.7466666666666667e-07,
      "logits/chosen": -2.928143262863159,
      "logits/rejected": -2.4126524925231934,
      "logps/chosen": -55.802635192871094,
      "logps/rejected": -159.31414794921875,
      "loss": 0.0072,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14104843139648438,
      "rewards/margins": 10.603667259216309,
      "rewards/rejected": -10.462618827819824,
      "step": 6191
    },
    {
      "epoch": 2.4768,
      "grad_norm": 1.4680163860321045,
      "learning_rate": 1.7453333333333333e-07,
      "logits/chosen": -2.43674898147583,
      "logits/rejected": -1.834257960319519,
      "logps/chosen": -242.96641540527344,
      "logps/rejected": -153.0469207763672,
      "loss": 0.0062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.8908486366271973,
      "rewards/margins": 6.999782562255859,
      "rewards/rejected": -10.890631675720215,
      "step": 6192
    },
    {
      "epoch": 2.4772,
      "grad_norm": 0.012599505484104156,
      "learning_rate": 1.744e-07,
      "logits/chosen": -2.2412257194519043,
      "logits/rejected": -1.4858736991882324,
      "logps/chosen": -144.53524780273438,
      "logps/rejected": -258.64715576171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.055652618408203125,
      "rewards/margins": 11.829151153564453,
      "rewards/rejected": -11.884803771972656,
      "step": 6193
    },
    {
      "epoch": 2.4776,
      "grad_norm": 0.17650367319583893,
      "learning_rate": 1.7426666666666664e-07,
      "logits/chosen": -2.9118432998657227,
      "logits/rejected": -2.6086511611938477,
      "logps/chosen": -103.49716186523438,
      "logps/rejected": -146.201416015625,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3820184469223022,
      "rewards/margins": 7.88043737411499,
      "rewards/rejected": -9.262455940246582,
      "step": 6194
    },
    {
      "epoch": 2.4779999999999998,
      "grad_norm": 0.055233184248209,
      "learning_rate": 1.7413333333333333e-07,
      "logits/chosen": -2.4895355701446533,
      "logits/rejected": -1.7706382274627686,
      "logps/chosen": -103.06842041015625,
      "logps/rejected": -172.11761474609375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8201764822006226,
      "rewards/margins": 11.475790023803711,
      "rewards/rejected": -12.295966148376465,
      "step": 6195
    },
    {
      "epoch": 2.4784,
      "grad_norm": 0.007982221432030201,
      "learning_rate": 1.7399999999999997e-07,
      "logits/chosen": -2.289182186126709,
      "logits/rejected": -1.6814289093017578,
      "logps/chosen": -157.60841369628906,
      "logps/rejected": -160.99993896484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3329641819000244,
      "rewards/margins": 10.544485092163086,
      "rewards/rejected": -10.21152114868164,
      "step": 6196
    },
    {
      "epoch": 2.4788,
      "grad_norm": 0.0018569721141830087,
      "learning_rate": 1.7386666666666666e-07,
      "logits/chosen": -2.5659353733062744,
      "logits/rejected": -2.0456058979034424,
      "logps/chosen": -81.02130889892578,
      "logps/rejected": -202.22479248046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9311466813087463,
      "rewards/margins": 13.309975624084473,
      "rewards/rejected": -12.378829002380371,
      "step": 6197
    },
    {
      "epoch": 2.4792,
      "grad_norm": 0.35596001148223877,
      "learning_rate": 1.7373333333333333e-07,
      "logits/chosen": -2.2112603187561035,
      "logits/rejected": -1.5760133266448975,
      "logps/chosen": -158.9800262451172,
      "logps/rejected": -209.84841918945312,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.2594056129455566,
      "rewards/margins": 12.408058166503906,
      "rewards/rejected": -15.667463302612305,
      "step": 6198
    },
    {
      "epoch": 2.4796,
      "grad_norm": 0.0012748092412948608,
      "learning_rate": 1.736e-07,
      "logits/chosen": -2.635500431060791,
      "logits/rejected": -1.9241950511932373,
      "logps/chosen": -145.19076538085938,
      "logps/rejected": -234.25448608398438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.2158141136169434,
      "rewards/margins": 12.573811531066895,
      "rewards/rejected": -14.78962516784668,
      "step": 6199
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.0001386671356158331,
      "learning_rate": 1.7346666666666666e-07,
      "logits/chosen": -2.2432479858398438,
      "logits/rejected": -1.7687824964523315,
      "logps/chosen": -71.21455383300781,
      "logps/rejected": -294.5196533203125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.467372179031372,
      "rewards/margins": 19.010295867919922,
      "rewards/rejected": -17.542922973632812,
      "step": 6200
    },
    {
      "epoch": 2.4804,
      "grad_norm": 0.019261833280324936,
      "learning_rate": 1.7333333333333332e-07,
      "logits/chosen": -2.885953664779663,
      "logits/rejected": -2.3099236488342285,
      "logps/chosen": -79.79212951660156,
      "logps/rejected": -138.854248046875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.12030735611915588,
      "rewards/margins": 9.479412078857422,
      "rewards/rejected": -9.599719047546387,
      "step": 6201
    },
    {
      "epoch": 2.4808,
      "grad_norm": 0.37738919258117676,
      "learning_rate": 1.732e-07,
      "logits/chosen": -2.9615182876586914,
      "logits/rejected": -2.490394353866577,
      "logps/chosen": -46.578250885009766,
      "logps/rejected": -153.87506103515625,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5509293675422668,
      "rewards/margins": 10.172586441040039,
      "rewards/rejected": -10.723516464233398,
      "step": 6202
    },
    {
      "epoch": 2.4812,
      "grad_norm": 0.389456182718277,
      "learning_rate": 1.7306666666666665e-07,
      "logits/chosen": -2.698822498321533,
      "logits/rejected": -1.8292639255523682,
      "logps/chosen": -146.29124450683594,
      "logps/rejected": -183.95977783203125,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.5606226921081543,
      "rewards/margins": 10.259404182434082,
      "rewards/rejected": -13.820026397705078,
      "step": 6203
    },
    {
      "epoch": 2.4816,
      "grad_norm": 0.15302355587482452,
      "learning_rate": 1.7293333333333332e-07,
      "logits/chosen": -2.4819111824035645,
      "logits/rejected": -2.575312614440918,
      "logps/chosen": -117.1653823852539,
      "logps/rejected": -164.8631591796875,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8451874256134033,
      "rewards/margins": 10.201828956604004,
      "rewards/rejected": -11.047016143798828,
      "step": 6204
    },
    {
      "epoch": 2.482,
      "grad_norm": 0.0005459504900500178,
      "learning_rate": 1.728e-07,
      "logits/chosen": -2.621105194091797,
      "logits/rejected": -1.8775901794433594,
      "logps/chosen": -126.0030746459961,
      "logps/rejected": -183.7684326171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.30808335542678833,
      "rewards/margins": 13.186333656311035,
      "rewards/rejected": -12.878250122070312,
      "step": 6205
    },
    {
      "epoch": 2.4824,
      "grad_norm": 0.014922479167580605,
      "learning_rate": 1.7266666666666665e-07,
      "logits/chosen": -2.6940720081329346,
      "logits/rejected": -2.4361038208007812,
      "logps/chosen": -79.35370635986328,
      "logps/rejected": -140.16197204589844,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.17026251554489136,
      "rewards/margins": 9.204066276550293,
      "rewards/rejected": -9.37432861328125,
      "step": 6206
    },
    {
      "epoch": 2.4828,
      "grad_norm": 8.296023588627577e-05,
      "learning_rate": 1.7253333333333334e-07,
      "logits/chosen": -2.791271209716797,
      "logits/rejected": -1.9475890398025513,
      "logps/chosen": -77.73130798339844,
      "logps/rejected": -244.69598388671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.47191619873046875,
      "rewards/margins": 15.649909973144531,
      "rewards/rejected": -15.177993774414062,
      "step": 6207
    },
    {
      "epoch": 2.4832,
      "grad_norm": 0.249067023396492,
      "learning_rate": 1.7239999999999998e-07,
      "logits/chosen": -2.979327917098999,
      "logits/rejected": -2.873844623565674,
      "logps/chosen": -39.63974380493164,
      "logps/rejected": -115.3421630859375,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.752403736114502,
      "rewards/margins": 8.498359680175781,
      "rewards/rejected": -7.745955467224121,
      "step": 6208
    },
    {
      "epoch": 2.4836,
      "grad_norm": 0.02847565896809101,
      "learning_rate": 1.7226666666666667e-07,
      "logits/chosen": -2.8157238960266113,
      "logits/rejected": -2.2007107734680176,
      "logps/chosen": -64.22819519042969,
      "logps/rejected": -187.63629150390625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6948335766792297,
      "rewards/margins": 12.597063064575195,
      "rewards/rejected": -11.902230262756348,
      "step": 6209
    },
    {
      "epoch": 2.484,
      "grad_norm": 0.009205839596688747,
      "learning_rate": 1.721333333333333e-07,
      "logits/chosen": -1.9880205392837524,
      "logits/rejected": -1.2992651462554932,
      "logps/chosen": -154.2976531982422,
      "logps/rejected": -184.31088256835938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2726398706436157,
      "rewards/margins": 11.423966407775879,
      "rewards/rejected": -11.151327133178711,
      "step": 6210
    },
    {
      "epoch": 2.4844,
      "grad_norm": 0.028071753680706024,
      "learning_rate": 1.7199999999999998e-07,
      "logits/chosen": -2.5640268325805664,
      "logits/rejected": -2.088709831237793,
      "logps/chosen": -72.28779602050781,
      "logps/rejected": -188.3899383544922,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0791428089141846,
      "rewards/margins": 12.062505722045898,
      "rewards/rejected": -9.983363151550293,
      "step": 6211
    },
    {
      "epoch": 2.4848,
      "grad_norm": 0.009075033478438854,
      "learning_rate": 1.7186666666666667e-07,
      "logits/chosen": -2.7186665534973145,
      "logits/rejected": -2.4495553970336914,
      "logps/chosen": -109.77161407470703,
      "logps/rejected": -156.17495727539062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8360204696655273,
      "rewards/margins": 10.297126770019531,
      "rewards/rejected": -11.133147239685059,
      "step": 6212
    },
    {
      "epoch": 2.4852,
      "grad_norm": 0.1447979211807251,
      "learning_rate": 1.717333333333333e-07,
      "logits/chosen": -2.5678601264953613,
      "logits/rejected": -2.156352996826172,
      "logps/chosen": -144.52984619140625,
      "logps/rejected": -186.77719116210938,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.545064926147461,
      "rewards/margins": 8.223173141479492,
      "rewards/rejected": -9.768238067626953,
      "step": 6213
    },
    {
      "epoch": 2.4856,
      "grad_norm": 0.022639458999037743,
      "learning_rate": 1.716e-07,
      "logits/chosen": -2.498542070388794,
      "logits/rejected": -2.385434150695801,
      "logps/chosen": -53.03605651855469,
      "logps/rejected": -228.24942016601562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9775643348693848,
      "rewards/margins": 12.981026649475098,
      "rewards/rejected": -11.003461837768555,
      "step": 6214
    },
    {
      "epoch": 2.4859999999999998,
      "grad_norm": 0.35964643955230713,
      "learning_rate": 1.7146666666666664e-07,
      "logits/chosen": -2.824331283569336,
      "logits/rejected": -2.558952808380127,
      "logps/chosen": -113.96780395507812,
      "logps/rejected": -118.89730072021484,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8405307531356812,
      "rewards/margins": 8.447864532470703,
      "rewards/rejected": -7.607333183288574,
      "step": 6215
    },
    {
      "epoch": 2.4864,
      "grad_norm": 0.038262102752923965,
      "learning_rate": 1.7133333333333333e-07,
      "logits/chosen": -2.758246898651123,
      "logits/rejected": -2.7271604537963867,
      "logps/chosen": -92.94689178466797,
      "logps/rejected": -135.65780639648438,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7467914819717407,
      "rewards/margins": 9.754085540771484,
      "rewards/rejected": -9.007293701171875,
      "step": 6216
    },
    {
      "epoch": 2.4868,
      "grad_norm": 0.00024088105419650674,
      "learning_rate": 1.7119999999999997e-07,
      "logits/chosen": -2.384213924407959,
      "logits/rejected": -1.6156139373779297,
      "logps/chosen": -90.28033447265625,
      "logps/rejected": -181.55462646484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4640605449676514,
      "rewards/margins": 14.347562789916992,
      "rewards/rejected": -12.883502960205078,
      "step": 6217
    },
    {
      "epoch": 2.4872,
      "grad_norm": 0.01356059405952692,
      "learning_rate": 1.7106666666666666e-07,
      "logits/chosen": -2.688157558441162,
      "logits/rejected": -2.0342319011688232,
      "logps/chosen": -63.053955078125,
      "logps/rejected": -179.96763610839844,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.581530213356018,
      "rewards/margins": 12.199217796325684,
      "rewards/rejected": -10.617687225341797,
      "step": 6218
    },
    {
      "epoch": 2.4876,
      "grad_norm": 0.0006675561890006065,
      "learning_rate": 1.7093333333333333e-07,
      "logits/chosen": -2.443018913269043,
      "logits/rejected": -1.8877071142196655,
      "logps/chosen": -100.62647247314453,
      "logps/rejected": -210.0882568359375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9203704595565796,
      "rewards/margins": 14.649420738220215,
      "rewards/rejected": -13.729049682617188,
      "step": 6219
    },
    {
      "epoch": 2.488,
      "grad_norm": 0.47337087988853455,
      "learning_rate": 1.708e-07,
      "logits/chosen": -2.307666301727295,
      "logits/rejected": -1.8449814319610596,
      "logps/chosen": -146.2470703125,
      "logps/rejected": -162.20838928222656,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0286415815353394,
      "rewards/margins": 9.723006248474121,
      "rewards/rejected": -10.75164794921875,
      "step": 6220
    },
    {
      "epoch": 2.4884,
      "grad_norm": 0.030230194330215454,
      "learning_rate": 1.7066666666666666e-07,
      "logits/chosen": -2.8006556034088135,
      "logits/rejected": -2.720315933227539,
      "logps/chosen": -99.69577026367188,
      "logps/rejected": -147.99803161621094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4476776421070099,
      "rewards/margins": 10.25501823425293,
      "rewards/rejected": -9.807340621948242,
      "step": 6221
    },
    {
      "epoch": 2.4888,
      "grad_norm": 0.23370586335659027,
      "learning_rate": 1.7053333333333333e-07,
      "logits/chosen": -2.752190589904785,
      "logits/rejected": -2.5907669067382812,
      "logps/chosen": -69.46681213378906,
      "logps/rejected": -103.94564819335938,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4103859066963196,
      "rewards/margins": 6.616114616394043,
      "rewards/rejected": -7.026500701904297,
      "step": 6222
    },
    {
      "epoch": 2.4892,
      "grad_norm": 0.02880631946027279,
      "learning_rate": 1.704e-07,
      "logits/chosen": -2.9234628677368164,
      "logits/rejected": -2.3104119300842285,
      "logps/chosen": -35.046295166015625,
      "logps/rejected": -181.1787109375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2855465412139893,
      "rewards/margins": 12.468482971191406,
      "rewards/rejected": -11.182936668395996,
      "step": 6223
    },
    {
      "epoch": 2.4896,
      "grad_norm": 0.033738575875759125,
      "learning_rate": 1.7026666666666668e-07,
      "logits/chosen": -3.0460755825042725,
      "logits/rejected": -2.683042049407959,
      "logps/chosen": -85.47979736328125,
      "logps/rejected": -105.16227722167969,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7522637844085693,
      "rewards/margins": 8.923332214355469,
      "rewards/rejected": -7.1710686683654785,
      "step": 6224
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.013295907527208328,
      "learning_rate": 1.7013333333333332e-07,
      "logits/chosen": -2.8188230991363525,
      "logits/rejected": -2.405569076538086,
      "logps/chosen": -74.66789245605469,
      "logps/rejected": -147.37490844726562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5179979801177979,
      "rewards/margins": 9.800971984863281,
      "rewards/rejected": -9.282974243164062,
      "step": 6225
    },
    {
      "epoch": 2.4904,
      "grad_norm": 0.012670292519032955,
      "learning_rate": 1.7000000000000001e-07,
      "logits/chosen": -2.192655563354492,
      "logits/rejected": -1.4655039310455322,
      "logps/chosen": -87.39988708496094,
      "logps/rejected": -186.91493225097656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0451419353485107,
      "rewards/margins": 11.854530334472656,
      "rewards/rejected": -10.80938720703125,
      "step": 6226
    },
    {
      "epoch": 2.4908,
      "grad_norm": 0.010802424512803555,
      "learning_rate": 1.6986666666666665e-07,
      "logits/chosen": -2.4484643936157227,
      "logits/rejected": -2.0695290565490723,
      "logps/chosen": -158.61819458007812,
      "logps/rejected": -177.22979736328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.03515511751174927,
      "rewards/margins": 11.69222640991211,
      "rewards/rejected": -11.72738265991211,
      "step": 6227
    },
    {
      "epoch": 2.4912,
      "grad_norm": 0.0011078683892264962,
      "learning_rate": 1.6973333333333334e-07,
      "logits/chosen": -2.594144105911255,
      "logits/rejected": -2.389495849609375,
      "logps/chosen": -112.16705322265625,
      "logps/rejected": -227.80368041992188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4141044616699219,
      "rewards/margins": 15.359283447265625,
      "rewards/rejected": -15.773387908935547,
      "step": 6228
    },
    {
      "epoch": 2.4916,
      "grad_norm": 0.18573562800884247,
      "learning_rate": 1.6959999999999998e-07,
      "logits/chosen": -2.5488638877868652,
      "logits/rejected": -1.9111934900283813,
      "logps/chosen": -182.9749755859375,
      "logps/rejected": -185.2758026123047,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0829849243164062,
      "rewards/margins": 9.741514205932617,
      "rewards/rejected": -10.824499130249023,
      "step": 6229
    },
    {
      "epoch": 2.492,
      "grad_norm": 0.007061935029923916,
      "learning_rate": 1.6946666666666665e-07,
      "logits/chosen": -2.5617294311523438,
      "logits/rejected": -1.7520816326141357,
      "logps/chosen": -95.626953125,
      "logps/rejected": -130.47869873046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.225529909133911,
      "rewards/margins": 10.278450965881348,
      "rewards/rejected": -8.052921295166016,
      "step": 6230
    },
    {
      "epoch": 2.4924,
      "grad_norm": 0.04333052411675453,
      "learning_rate": 1.6933333333333334e-07,
      "logits/chosen": -2.8764638900756836,
      "logits/rejected": -2.5015065670013428,
      "logps/chosen": -59.79463195800781,
      "logps/rejected": -141.21414184570312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2625701427459717,
      "rewards/margins": 10.25849723815918,
      "rewards/rejected": -8.995927810668945,
      "step": 6231
    },
    {
      "epoch": 2.4928,
      "grad_norm": 3.90459899790585e-06,
      "learning_rate": 1.6919999999999998e-07,
      "logits/chosen": -2.8187098503112793,
      "logits/rejected": -2.0567049980163574,
      "logps/chosen": -37.59457778930664,
      "logps/rejected": -252.65802001953125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9119706153869629,
      "rewards/margins": 18.630767822265625,
      "rewards/rejected": -17.718795776367188,
      "step": 6232
    },
    {
      "epoch": 2.4932,
      "grad_norm": 0.003073842264711857,
      "learning_rate": 1.6906666666666667e-07,
      "logits/chosen": -2.3860764503479004,
      "logits/rejected": -2.086465835571289,
      "logps/chosen": -147.8645782470703,
      "logps/rejected": -159.45510864257812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.518602728843689,
      "rewards/margins": 11.445388793945312,
      "rewards/rejected": -10.926786422729492,
      "step": 6233
    },
    {
      "epoch": 2.4936,
      "grad_norm": 0.3552064597606659,
      "learning_rate": 1.689333333333333e-07,
      "logits/chosen": -3.1412391662597656,
      "logits/rejected": -2.8160111904144287,
      "logps/chosen": -35.74033737182617,
      "logps/rejected": -80.59852600097656,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4279199838638306,
      "rewards/margins": 6.433134078979492,
      "rewards/rejected": -5.005213737487793,
      "step": 6234
    },
    {
      "epoch": 2.4939999999999998,
      "grad_norm": 0.014723747037351131,
      "learning_rate": 1.688e-07,
      "logits/chosen": -2.8485305309295654,
      "logits/rejected": -2.6963002681732178,
      "logps/chosen": -63.91378402709961,
      "logps/rejected": -146.12722778320312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7646507620811462,
      "rewards/margins": 10.266162872314453,
      "rewards/rejected": -9.50151252746582,
      "step": 6235
    },
    {
      "epoch": 2.4944,
      "grad_norm": 0.030718160793185234,
      "learning_rate": 1.6866666666666664e-07,
      "logits/chosen": -2.4403491020202637,
      "logits/rejected": -1.8389432430267334,
      "logps/chosen": -158.57211303710938,
      "logps/rejected": -183.15267944335938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.06007719039917,
      "rewards/margins": 9.021984100341797,
      "rewards/rejected": -11.082061767578125,
      "step": 6236
    },
    {
      "epoch": 2.4948,
      "grad_norm": 0.0999680832028389,
      "learning_rate": 1.6853333333333333e-07,
      "logits/chosen": -2.6759791374206543,
      "logits/rejected": -2.1093974113464355,
      "logps/chosen": -126.8682861328125,
      "logps/rejected": -154.69410705566406,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6384766101837158,
      "rewards/margins": 9.975737571716309,
      "rewards/rejected": -9.337261199951172,
      "step": 6237
    },
    {
      "epoch": 2.4952,
      "grad_norm": 0.0004980853409506381,
      "learning_rate": 1.684e-07,
      "logits/chosen": -2.470756769180298,
      "logits/rejected": -1.6236549615859985,
      "logps/chosen": -116.21431732177734,
      "logps/rejected": -188.45501708984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5947303771972656,
      "rewards/margins": 13.25238037109375,
      "rewards/rejected": -11.657649993896484,
      "step": 6238
    },
    {
      "epoch": 2.4956,
      "grad_norm": 2.2000186443328857,
      "learning_rate": 1.6826666666666666e-07,
      "logits/chosen": -2.384464740753174,
      "logits/rejected": -1.9833080768585205,
      "logps/chosen": -134.4154052734375,
      "logps/rejected": -125.30430603027344,
      "loss": 0.0091,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4978634119033813,
      "rewards/margins": 5.9559550285339355,
      "rewards/rejected": -7.453818321228027,
      "step": 6239
    },
    {
      "epoch": 2.496,
      "grad_norm": 0.1854943335056305,
      "learning_rate": 1.6813333333333333e-07,
      "logits/chosen": -2.472203493118286,
      "logits/rejected": -2.0841598510742188,
      "logps/chosen": -136.27090454101562,
      "logps/rejected": -297.7583923339844,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.268993854522705,
      "rewards/margins": 10.36556625366211,
      "rewards/rejected": -12.634560585021973,
      "step": 6240
    },
    {
      "epoch": 2.4964,
      "grad_norm": 3.6657345294952393,
      "learning_rate": 1.68e-07,
      "logits/chosen": -3.136622190475464,
      "logits/rejected": -2.6258201599121094,
      "logps/chosen": -59.29230499267578,
      "logps/rejected": -108.7764892578125,
      "loss": 0.0256,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.48073291778564453,
      "rewards/margins": 7.894990921020508,
      "rewards/rejected": -7.414258003234863,
      "step": 6241
    },
    {
      "epoch": 2.4968,
      "grad_norm": 0.9722115397453308,
      "learning_rate": 1.6786666666666666e-07,
      "logits/chosen": -2.7724595069885254,
      "logits/rejected": -2.7813949584960938,
      "logps/chosen": -115.34097290039062,
      "logps/rejected": -97.1600570678711,
      "loss": 0.0062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3930778503417969,
      "rewards/margins": 5.105098724365234,
      "rewards/rejected": -6.498176574707031,
      "step": 6242
    },
    {
      "epoch": 2.4972,
      "grad_norm": 0.22165854275226593,
      "learning_rate": 1.6773333333333333e-07,
      "logits/chosen": -2.9243321418762207,
      "logits/rejected": -2.774914264678955,
      "logps/chosen": -34.35296630859375,
      "logps/rejected": -87.12286376953125,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3079596757888794,
      "rewards/margins": 6.512221336364746,
      "rewards/rejected": -5.204261779785156,
      "step": 6243
    },
    {
      "epoch": 2.4976,
      "grad_norm": 0.015215927734971046,
      "learning_rate": 1.676e-07,
      "logits/chosen": -2.6049933433532715,
      "logits/rejected": -1.8691469430923462,
      "logps/chosen": -103.64170837402344,
      "logps/rejected": -207.7357177734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.48604506254196167,
      "rewards/margins": 13.750722885131836,
      "rewards/rejected": -13.264678001403809,
      "step": 6244
    },
    {
      "epoch": 2.498,
      "grad_norm": 5.438634616439231e-05,
      "learning_rate": 1.6746666666666668e-07,
      "logits/chosen": -2.3594372272491455,
      "logits/rejected": -1.5975842475891113,
      "logps/chosen": -112.44775390625,
      "logps/rejected": -310.58160400390625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.555072009563446,
      "rewards/margins": 16.860109329223633,
      "rewards/rejected": -16.305038452148438,
      "step": 6245
    },
    {
      "epoch": 2.4984,
      "grad_norm": 0.6519687175750732,
      "learning_rate": 1.6733333333333332e-07,
      "logits/chosen": -2.8814806938171387,
      "logits/rejected": -2.2945284843444824,
      "logps/chosen": -83.22917175292969,
      "logps/rejected": -157.79461669921875,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.47012126445770264,
      "rewards/margins": 11.032833099365234,
      "rewards/rejected": -11.50295352935791,
      "step": 6246
    },
    {
      "epoch": 2.4988,
      "grad_norm": 0.3426697850227356,
      "learning_rate": 1.672e-07,
      "logits/chosen": -2.9059085845947266,
      "logits/rejected": -2.8041186332702637,
      "logps/chosen": -71.43701171875,
      "logps/rejected": -71.53315734863281,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8585025072097778,
      "rewards/margins": 5.808844566345215,
      "rewards/rejected": -4.950342178344727,
      "step": 6247
    },
    {
      "epoch": 2.4992,
      "grad_norm": 0.8919467926025391,
      "learning_rate": 1.6706666666666665e-07,
      "logits/chosen": -2.547377109527588,
      "logits/rejected": -2.0128612518310547,
      "logps/chosen": -96.50029754638672,
      "logps/rejected": -161.95657348632812,
      "loss": 0.0052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7371345162391663,
      "rewards/margins": 9.164642333984375,
      "rewards/rejected": -9.901777267456055,
      "step": 6248
    },
    {
      "epoch": 2.4996,
      "grad_norm": 0.24169495701789856,
      "learning_rate": 1.6693333333333332e-07,
      "logits/chosen": -2.4815120697021484,
      "logits/rejected": -2.252464532852173,
      "logps/chosen": -145.53451538085938,
      "logps/rejected": -134.44557189941406,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4117965698242188,
      "rewards/margins": 6.983609199523926,
      "rewards/rejected": -8.395405769348145,
      "step": 6249
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.1612793207168579,
      "learning_rate": 1.6679999999999998e-07,
      "logits/chosen": -2.5626134872436523,
      "logits/rejected": -1.7882393598556519,
      "logps/chosen": -69.2699966430664,
      "logps/rejected": -141.69119262695312,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3315681219100952,
      "rewards/margins": 9.843541145324707,
      "rewards/rejected": -9.511972427368164,
      "step": 6250
    },
    {
      "epoch": 2.5004,
      "grad_norm": 0.004245318938046694,
      "learning_rate": 1.6666666666666665e-07,
      "logits/chosen": -2.403637409210205,
      "logits/rejected": -1.2809925079345703,
      "logps/chosen": -74.37263488769531,
      "logps/rejected": -149.87289428710938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6920852661132812,
      "rewards/margins": 11.790274620056152,
      "rewards/rejected": -9.098188400268555,
      "step": 6251
    },
    {
      "epoch": 2.5008,
      "grad_norm": 0.00011381664808141068,
      "learning_rate": 1.6653333333333334e-07,
      "logits/chosen": -2.366398811340332,
      "logits/rejected": -1.8008084297180176,
      "logps/chosen": -77.50621032714844,
      "logps/rejected": -244.7880859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.014687657356262207,
      "rewards/margins": 15.16377067565918,
      "rewards/rejected": -15.178459167480469,
      "step": 6252
    },
    {
      "epoch": 2.5012,
      "grad_norm": 0.00014380417997017503,
      "learning_rate": 1.6639999999999998e-07,
      "logits/chosen": -2.317424774169922,
      "logits/rejected": -1.5909818410873413,
      "logps/chosen": -53.204933166503906,
      "logps/rejected": -235.99063110351562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1731934547424316,
      "rewards/margins": 15.049053192138672,
      "rewards/rejected": -12.875859260559082,
      "step": 6253
    },
    {
      "epoch": 2.5016,
      "grad_norm": 0.012278878130018711,
      "learning_rate": 1.6626666666666667e-07,
      "logits/chosen": -2.7339701652526855,
      "logits/rejected": -2.228163719177246,
      "logps/chosen": -48.08527374267578,
      "logps/rejected": -168.21990966796875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3419342041015625,
      "rewards/margins": 13.21725082397461,
      "rewards/rejected": -11.875316619873047,
      "step": 6254
    },
    {
      "epoch": 2.502,
      "grad_norm": 0.006339523009955883,
      "learning_rate": 1.661333333333333e-07,
      "logits/chosen": -2.693103790283203,
      "logits/rejected": -1.9440910816192627,
      "logps/chosen": -96.65113067626953,
      "logps/rejected": -134.07843017578125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1444530487060547,
      "rewards/margins": 11.423539161682129,
      "rewards/rejected": -9.279086112976074,
      "step": 6255
    },
    {
      "epoch": 2.5023999999999997,
      "grad_norm": 0.0006623626686632633,
      "learning_rate": 1.66e-07,
      "logits/chosen": -2.735724449157715,
      "logits/rejected": -1.9803812503814697,
      "logps/chosen": -99.59263610839844,
      "logps/rejected": -265.9239501953125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.03157234191894531,
      "rewards/margins": 15.35421371459961,
      "rewards/rejected": -15.385786056518555,
      "step": 6256
    },
    {
      "epoch": 2.5028,
      "grad_norm": 0.00135129876434803,
      "learning_rate": 1.6586666666666664e-07,
      "logits/chosen": -2.6946256160736084,
      "logits/rejected": -2.3597731590270996,
      "logps/chosen": -90.17434692382812,
      "logps/rejected": -202.56771850585938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7508445978164673,
      "rewards/margins": 15.32777214050293,
      "rewards/rejected": -14.576927185058594,
      "step": 6257
    },
    {
      "epoch": 2.5032,
      "grad_norm": 0.04237882047891617,
      "learning_rate": 1.6573333333333334e-07,
      "logits/chosen": -2.5857768058776855,
      "logits/rejected": -2.296285629272461,
      "logps/chosen": -137.58848571777344,
      "logps/rejected": -144.59205627441406,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.14411583542823792,
      "rewards/margins": 8.438828468322754,
      "rewards/rejected": -8.582944869995117,
      "step": 6258
    },
    {
      "epoch": 2.5036,
      "grad_norm": 0.14851824939250946,
      "learning_rate": 1.656e-07,
      "logits/chosen": -2.9707837104797363,
      "logits/rejected": -2.558459758758545,
      "logps/chosen": -67.26713562011719,
      "logps/rejected": -142.04266357421875,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09460657835006714,
      "rewards/margins": 9.653097152709961,
      "rewards/rejected": -9.558490753173828,
      "step": 6259
    },
    {
      "epoch": 2.504,
      "grad_norm": 0.0002484208671376109,
      "learning_rate": 1.6546666666666667e-07,
      "logits/chosen": -2.324638843536377,
      "logits/rejected": -1.5915379524230957,
      "logps/chosen": -95.3089828491211,
      "logps/rejected": -213.21975708007812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.226224184036255,
      "rewards/margins": 16.48674201965332,
      "rewards/rejected": -14.260519027709961,
      "step": 6260
    },
    {
      "epoch": 2.5044,
      "grad_norm": 0.016713695600628853,
      "learning_rate": 1.6533333333333333e-07,
      "logits/chosen": -2.5288333892822266,
      "logits/rejected": -2.1563985347747803,
      "logps/chosen": -88.72412872314453,
      "logps/rejected": -154.7807159423828,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1530230045318604,
      "rewards/margins": 11.06454086303711,
      "rewards/rejected": -9.911518096923828,
      "step": 6261
    },
    {
      "epoch": 2.5048,
      "grad_norm": 0.05348837748169899,
      "learning_rate": 1.652e-07,
      "logits/chosen": -2.5150060653686523,
      "logits/rejected": -1.862663745880127,
      "logps/chosen": -123.34464263916016,
      "logps/rejected": -160.31520080566406,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5664916634559631,
      "rewards/margins": 9.511734008789062,
      "rewards/rejected": -10.078226089477539,
      "step": 6262
    },
    {
      "epoch": 2.5052,
      "grad_norm": 1.043300380842993e-05,
      "learning_rate": 1.6506666666666666e-07,
      "logits/chosen": -2.3264870643615723,
      "logits/rejected": -1.504795789718628,
      "logps/chosen": -104.39848327636719,
      "logps/rejected": -261.0156555175781,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9299674034118652,
      "rewards/margins": 17.91905975341797,
      "rewards/rejected": -15.989091873168945,
      "step": 6263
    },
    {
      "epoch": 2.5056000000000003,
      "grad_norm": 0.9934674501419067,
      "learning_rate": 1.649333333333333e-07,
      "logits/chosen": -2.9137563705444336,
      "logits/rejected": -2.8526740074157715,
      "logps/chosen": -88.40034484863281,
      "logps/rejected": -92.53741455078125,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5632549524307251,
      "rewards/margins": 6.466360092163086,
      "rewards/rejected": -5.903104782104492,
      "step": 6264
    },
    {
      "epoch": 2.5060000000000002,
      "grad_norm": 0.002772117732092738,
      "learning_rate": 1.648e-07,
      "logits/chosen": -2.6644372940063477,
      "logits/rejected": -2.006960868835449,
      "logps/chosen": -51.920867919921875,
      "logps/rejected": -144.96975708007812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.100673198699951,
      "rewards/margins": 11.838342666625977,
      "rewards/rejected": -8.737668991088867,
      "step": 6265
    },
    {
      "epoch": 2.5064,
      "grad_norm": 0.021226420998573303,
      "learning_rate": 1.6466666666666666e-07,
      "logits/chosen": -2.786475419998169,
      "logits/rejected": -2.0533528327941895,
      "logps/chosen": -122.88526916503906,
      "logps/rejected": -185.9472198486328,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.33489686250686646,
      "rewards/margins": 12.230648040771484,
      "rewards/rejected": -12.565545082092285,
      "step": 6266
    },
    {
      "epoch": 2.5068,
      "grad_norm": 14.77332878112793,
      "learning_rate": 1.6453333333333332e-07,
      "logits/chosen": -2.354593276977539,
      "logits/rejected": -2.1858811378479004,
      "logps/chosen": -219.58209228515625,
      "logps/rejected": -151.8727569580078,
      "loss": 0.1077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -5.2497358322143555,
      "rewards/margins": 2.3366994857788086,
      "rewards/rejected": -7.586435317993164,
      "step": 6267
    },
    {
      "epoch": 2.5072,
      "grad_norm": 0.4866032302379608,
      "learning_rate": 1.644e-07,
      "logits/chosen": -2.5389509201049805,
      "logits/rejected": -2.0415139198303223,
      "logps/chosen": -82.54225158691406,
      "logps/rejected": -140.8505859375,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2272697389125824,
      "rewards/margins": 9.238873481750488,
      "rewards/rejected": -9.466143608093262,
      "step": 6268
    },
    {
      "epoch": 2.5076,
      "grad_norm": 0.055966466665267944,
      "learning_rate": 1.6426666666666666e-07,
      "logits/chosen": -2.787667751312256,
      "logits/rejected": -2.365084171295166,
      "logps/chosen": -71.68021392822266,
      "logps/rejected": -138.25140380859375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.238572895526886,
      "rewards/margins": 8.51476001739502,
      "rewards/rejected": -8.276187896728516,
      "step": 6269
    },
    {
      "epoch": 2.508,
      "grad_norm": 0.000267041934421286,
      "learning_rate": 1.6413333333333332e-07,
      "logits/chosen": -2.513202667236328,
      "logits/rejected": -2.115532636642456,
      "logps/chosen": -71.91171264648438,
      "logps/rejected": -233.13668823242188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05288887023925781,
      "rewards/margins": 14.80532169342041,
      "rewards/rejected": -14.752433776855469,
      "step": 6270
    },
    {
      "epoch": 2.5084,
      "grad_norm": 0.42650848627090454,
      "learning_rate": 1.64e-07,
      "logits/chosen": -2.2130229473114014,
      "logits/rejected": -1.3991951942443848,
      "logps/chosen": -204.03970336914062,
      "logps/rejected": -166.0156707763672,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.3189940452575684,
      "rewards/margins": 8.20363998413086,
      "rewards/rejected": -10.522634506225586,
      "step": 6271
    },
    {
      "epoch": 2.5088,
      "grad_norm": 0.00045079391566105187,
      "learning_rate": 1.6386666666666665e-07,
      "logits/chosen": -2.497112512588501,
      "logits/rejected": -2.057752847671509,
      "logps/chosen": -133.77613830566406,
      "logps/rejected": -329.1854553222656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.5336012840270996,
      "rewards/margins": 18.397254943847656,
      "rewards/rejected": -20.930858612060547,
      "step": 6272
    },
    {
      "epoch": 2.5092,
      "grad_norm": 0.0012785932049155235,
      "learning_rate": 1.6373333333333334e-07,
      "logits/chosen": -2.433030366897583,
      "logits/rejected": -1.9818460941314697,
      "logps/chosen": -75.2288818359375,
      "logps/rejected": -172.19554138183594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.456845760345459,
      "rewards/margins": 12.201780319213867,
      "rewards/rejected": -11.74493408203125,
      "step": 6273
    },
    {
      "epoch": 2.5096,
      "grad_norm": 0.009216594509780407,
      "learning_rate": 1.6359999999999998e-07,
      "logits/chosen": -2.764026641845703,
      "logits/rejected": -2.398965358734131,
      "logps/chosen": -81.77371215820312,
      "logps/rejected": -190.64913940429688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3065608739852905,
      "rewards/margins": 12.519636154174805,
      "rewards/rejected": -13.826196670532227,
      "step": 6274
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.00014489461318589747,
      "learning_rate": 1.6346666666666667e-07,
      "logits/chosen": -2.79160213470459,
      "logits/rejected": -1.9842195510864258,
      "logps/chosen": -72.92525482177734,
      "logps/rejected": -200.25770568847656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.887734055519104,
      "rewards/margins": 15.013528823852539,
      "rewards/rejected": -13.125795364379883,
      "step": 6275
    },
    {
      "epoch": 2.5103999999999997,
      "grad_norm": 0.07977490872144699,
      "learning_rate": 1.6333333333333331e-07,
      "logits/chosen": -2.6813645362854004,
      "logits/rejected": -2.0878026485443115,
      "logps/chosen": -136.99618530273438,
      "logps/rejected": -147.1322021484375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.974966824054718,
      "rewards/margins": 8.071951866149902,
      "rewards/rejected": -9.046918869018555,
      "step": 6276
    },
    {
      "epoch": 2.5108,
      "grad_norm": 0.07350090146064758,
      "learning_rate": 1.632e-07,
      "logits/chosen": -2.679743766784668,
      "logits/rejected": -2.3985631465911865,
      "logps/chosen": -64.46884155273438,
      "logps/rejected": -161.67921447753906,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2521328926086426,
      "rewards/margins": 11.220502853393555,
      "rewards/rejected": -9.96837043762207,
      "step": 6277
    },
    {
      "epoch": 2.5112,
      "grad_norm": 0.01712966524064541,
      "learning_rate": 1.6306666666666667e-07,
      "logits/chosen": -2.7731199264526367,
      "logits/rejected": -2.5207531452178955,
      "logps/chosen": -119.11628723144531,
      "logps/rejected": -154.90643310546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9529564380645752,
      "rewards/margins": 9.179231643676758,
      "rewards/rejected": -10.132187843322754,
      "step": 6278
    },
    {
      "epoch": 2.5116,
      "grad_norm": 0.003009076928719878,
      "learning_rate": 1.6293333333333334e-07,
      "logits/chosen": -2.2854785919189453,
      "logits/rejected": -2.1348018646240234,
      "logps/chosen": -87.48091125488281,
      "logps/rejected": -225.48599243164062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.315042108297348,
      "rewards/margins": 13.529630661010742,
      "rewards/rejected": -13.21458911895752,
      "step": 6279
    },
    {
      "epoch": 2.512,
      "grad_norm": 0.5881903171539307,
      "learning_rate": 1.628e-07,
      "logits/chosen": -2.9539191722869873,
      "logits/rejected": -2.5738449096679688,
      "logps/chosen": -60.97831726074219,
      "logps/rejected": -108.8875732421875,
      "loss": 0.0049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.42330339550971985,
      "rewards/margins": 6.500161647796631,
      "rewards/rejected": -6.923464775085449,
      "step": 6280
    },
    {
      "epoch": 2.5124,
      "grad_norm": 0.02451881766319275,
      "learning_rate": 1.6266666666666664e-07,
      "logits/chosen": -2.6573548316955566,
      "logits/rejected": -2.261772632598877,
      "logps/chosen": -54.502685546875,
      "logps/rejected": -140.4248046875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2249617576599121,
      "rewards/margins": 9.762226104736328,
      "rewards/rejected": -9.987188339233398,
      "step": 6281
    },
    {
      "epoch": 2.5128,
      "grad_norm": 0.17329728603363037,
      "learning_rate": 1.6253333333333333e-07,
      "logits/chosen": -2.5977838039398193,
      "logits/rejected": -2.3315699100494385,
      "logps/chosen": -73.47590637207031,
      "logps/rejected": -132.6747283935547,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6341163516044617,
      "rewards/margins": 8.111162185668945,
      "rewards/rejected": -8.745279312133789,
      "step": 6282
    },
    {
      "epoch": 2.5132,
      "grad_norm": 0.5478811264038086,
      "learning_rate": 1.6239999999999997e-07,
      "logits/chosen": -2.6642675399780273,
      "logits/rejected": -2.733883857727051,
      "logps/chosen": -88.82110595703125,
      "logps/rejected": -120.50778198242188,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3177508115768433,
      "rewards/margins": 7.149323463439941,
      "rewards/rejected": -8.467074394226074,
      "step": 6283
    },
    {
      "epoch": 2.5136,
      "grad_norm": 0.018251756206154823,
      "learning_rate": 1.6226666666666666e-07,
      "logits/chosen": -2.848174571990967,
      "logits/rejected": -2.2669992446899414,
      "logps/chosen": -100.33988952636719,
      "logps/rejected": -137.10574340820312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14943274855613708,
      "rewards/margins": 9.73561954498291,
      "rewards/rejected": -9.586187362670898,
      "step": 6284
    },
    {
      "epoch": 2.5140000000000002,
      "grad_norm": 0.031629834324121475,
      "learning_rate": 1.6213333333333333e-07,
      "logits/chosen": -2.6345877647399902,
      "logits/rejected": -2.0110650062561035,
      "logps/chosen": -92.2017593383789,
      "logps/rejected": -141.46920776367188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9537984728813171,
      "rewards/margins": 9.633441925048828,
      "rewards/rejected": -8.679643630981445,
      "step": 6285
    },
    {
      "epoch": 2.5144,
      "grad_norm": 0.0538073293864727,
      "learning_rate": 1.62e-07,
      "logits/chosen": -2.759415626525879,
      "logits/rejected": -2.49086332321167,
      "logps/chosen": -81.20301818847656,
      "logps/rejected": -166.9012451171875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1622841358184814,
      "rewards/margins": 11.81961441040039,
      "rewards/rejected": -10.657330513000488,
      "step": 6286
    },
    {
      "epoch": 2.5148,
      "grad_norm": 0.0007660076371394098,
      "learning_rate": 1.6186666666666666e-07,
      "logits/chosen": -2.6354384422302246,
      "logits/rejected": -1.7809826135635376,
      "logps/chosen": -97.51324462890625,
      "logps/rejected": -165.83480834960938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.14552640914917,
      "rewards/margins": 13.097526550292969,
      "rewards/rejected": -10.95199966430664,
      "step": 6287
    },
    {
      "epoch": 2.5152,
      "grad_norm": 0.024134842678904533,
      "learning_rate": 1.6173333333333333e-07,
      "logits/chosen": -2.840815544128418,
      "logits/rejected": -2.638364791870117,
      "logps/chosen": -60.88435363769531,
      "logps/rejected": -132.8319549560547,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.18666496872901917,
      "rewards/margins": 8.69723892211914,
      "rewards/rejected": -8.883903503417969,
      "step": 6288
    },
    {
      "epoch": 2.5156,
      "grad_norm": 0.0026245368644595146,
      "learning_rate": 1.616e-07,
      "logits/chosen": -2.62773060798645,
      "logits/rejected": -1.732008695602417,
      "logps/chosen": -85.71189880371094,
      "logps/rejected": -171.99148559570312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6318929195404053,
      "rewards/margins": 12.508997917175293,
      "rewards/rejected": -10.877105712890625,
      "step": 6289
    },
    {
      "epoch": 2.516,
      "grad_norm": 16.329448699951172,
      "learning_rate": 1.6146666666666666e-07,
      "logits/chosen": -2.667360305786133,
      "logits/rejected": -2.5024075508117676,
      "logps/chosen": -134.117919921875,
      "logps/rejected": -132.01025390625,
      "loss": 0.0497,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.4376707077026367,
      "rewards/margins": 5.942670822143555,
      "rewards/rejected": -9.380340576171875,
      "step": 6290
    },
    {
      "epoch": 2.5164,
      "grad_norm": 0.004189976025372744,
      "learning_rate": 1.6133333333333332e-07,
      "logits/chosen": -2.7108263969421387,
      "logits/rejected": -2.269840717315674,
      "logps/chosen": -68.2633056640625,
      "logps/rejected": -208.9637451171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3248844146728516,
      "rewards/margins": 11.228361129760742,
      "rewards/rejected": -9.90347671508789,
      "step": 6291
    },
    {
      "epoch": 2.5168,
      "grad_norm": 0.0014194573741406202,
      "learning_rate": 1.6120000000000001e-07,
      "logits/chosen": -2.5419368743896484,
      "logits/rejected": -2.050175666809082,
      "logps/chosen": -89.15995788574219,
      "logps/rejected": -177.5874786376953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1168148517608643,
      "rewards/margins": 13.143966674804688,
      "rewards/rejected": -11.027153015136719,
      "step": 6292
    },
    {
      "epoch": 2.5172,
      "grad_norm": 75.18052673339844,
      "learning_rate": 1.6106666666666665e-07,
      "logits/chosen": -2.024737596511841,
      "logits/rejected": -1.4513399600982666,
      "logps/chosen": -263.55889892578125,
      "logps/rejected": -230.1275634765625,
      "loss": 0.3609,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -2.6022064685821533,
      "rewards/margins": 9.278663635253906,
      "rewards/rejected": -11.88086986541748,
      "step": 6293
    },
    {
      "epoch": 2.5176,
      "grad_norm": 0.13901524245738983,
      "learning_rate": 1.6093333333333335e-07,
      "logits/chosen": -2.5532360076904297,
      "logits/rejected": -2.052499771118164,
      "logps/chosen": -72.95893859863281,
      "logps/rejected": -196.74269104003906,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.576625645160675,
      "rewards/margins": 13.114989280700684,
      "rewards/rejected": -12.538363456726074,
      "step": 6294
    },
    {
      "epoch": 2.518,
      "grad_norm": 6.040009611751884e-05,
      "learning_rate": 1.6079999999999998e-07,
      "logits/chosen": -2.4478933811187744,
      "logits/rejected": -1.5027797222137451,
      "logps/chosen": -124.33855438232422,
      "logps/rejected": -251.71539306640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5045913457870483,
      "rewards/margins": 17.505884170532227,
      "rewards/rejected": -17.001293182373047,
      "step": 6295
    },
    {
      "epoch": 2.5183999999999997,
      "grad_norm": 0.06538255512714386,
      "learning_rate": 1.6066666666666668e-07,
      "logits/chosen": -2.523198127746582,
      "logits/rejected": -2.170886754989624,
      "logps/chosen": -131.21932983398438,
      "logps/rejected": -126.84022521972656,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.078920379281044,
      "rewards/margins": 8.043298721313477,
      "rewards/rejected": -7.964378356933594,
      "step": 6296
    },
    {
      "epoch": 2.5188,
      "grad_norm": 0.03797278180718422,
      "learning_rate": 1.6053333333333331e-07,
      "logits/chosen": -2.449129343032837,
      "logits/rejected": -1.8442109823226929,
      "logps/chosen": -63.075157165527344,
      "logps/rejected": -164.1448974609375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3346748352050781,
      "rewards/margins": 10.507126808166504,
      "rewards/rejected": -10.841800689697266,
      "step": 6297
    },
    {
      "epoch": 2.5192,
      "grad_norm": 0.029694154858589172,
      "learning_rate": 1.6039999999999998e-07,
      "logits/chosen": -2.1237335205078125,
      "logits/rejected": -1.1515703201293945,
      "logps/chosen": -136.3654327392578,
      "logps/rejected": -198.29107666015625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6077988147735596,
      "rewards/margins": 12.346956253051758,
      "rewards/rejected": -11.739157676696777,
      "step": 6298
    },
    {
      "epoch": 2.5196,
      "grad_norm": 0.007871709764003754,
      "learning_rate": 1.6026666666666667e-07,
      "logits/chosen": -2.4817867279052734,
      "logits/rejected": -1.9154387712478638,
      "logps/chosen": -131.77650451660156,
      "logps/rejected": -208.4510955810547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9250576496124268,
      "rewards/margins": 13.400947570800781,
      "rewards/rejected": -12.47589111328125,
      "step": 6299
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.3631877601146698,
      "learning_rate": 1.601333333333333e-07,
      "logits/chosen": -2.7195281982421875,
      "logits/rejected": -2.38238263130188,
      "logps/chosen": -129.68072509765625,
      "logps/rejected": -134.4969024658203,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.21102240681648254,
      "rewards/margins": 8.68783187866211,
      "rewards/rejected": -8.89885425567627,
      "step": 6300
    },
    {
      "epoch": 2.5204,
      "grad_norm": 1.150962233543396,
      "learning_rate": 1.6e-07,
      "logits/chosen": -2.9263577461242676,
      "logits/rejected": -2.676063060760498,
      "logps/chosen": -42.44154357910156,
      "logps/rejected": -88.65878295898438,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.12593668699264526,
      "rewards/margins": 5.826687335968018,
      "rewards/rejected": -5.952624320983887,
      "step": 6301
    },
    {
      "epoch": 2.5208,
      "grad_norm": 11.076086044311523,
      "learning_rate": 1.5986666666666664e-07,
      "logits/chosen": -2.369513511657715,
      "logits/rejected": -1.8428459167480469,
      "logps/chosen": -126.55828857421875,
      "logps/rejected": -149.04437255859375,
      "loss": 0.0512,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.34712374210357666,
      "rewards/margins": 8.289799690246582,
      "rewards/rejected": -8.636923789978027,
      "step": 6302
    },
    {
      "epoch": 2.5212,
      "grad_norm": 0.2196177840232849,
      "learning_rate": 1.5973333333333333e-07,
      "logits/chosen": -2.7151758670806885,
      "logits/rejected": -2.681431293487549,
      "logps/chosen": -126.48727416992188,
      "logps/rejected": -129.59829711914062,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.3460450172424316,
      "rewards/margins": 6.5346784591674805,
      "rewards/rejected": -8.880722999572754,
      "step": 6303
    },
    {
      "epoch": 2.5216,
      "grad_norm": 0.002816258929669857,
      "learning_rate": 1.5959999999999997e-07,
      "logits/chosen": -2.9178528785705566,
      "logits/rejected": -2.2230193614959717,
      "logps/chosen": -80.27091217041016,
      "logps/rejected": -197.97415161132812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1470579206943512,
      "rewards/margins": 14.156084060668945,
      "rewards/rejected": -14.303141593933105,
      "step": 6304
    },
    {
      "epoch": 2.5220000000000002,
      "grad_norm": 0.0230376236140728,
      "learning_rate": 1.5946666666666667e-07,
      "logits/chosen": -2.494797706604004,
      "logits/rejected": -1.7955117225646973,
      "logps/chosen": -86.849853515625,
      "logps/rejected": -187.230224609375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.037999749183654785,
      "rewards/margins": 11.372872352600098,
      "rewards/rejected": -11.33487319946289,
      "step": 6305
    },
    {
      "epoch": 2.5224,
      "grad_norm": 0.02926827408373356,
      "learning_rate": 1.5933333333333333e-07,
      "logits/chosen": -2.5202560424804688,
      "logits/rejected": -2.2881226539611816,
      "logps/chosen": -67.26024627685547,
      "logps/rejected": -188.7091064453125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7183458805084229,
      "rewards/margins": 11.788368225097656,
      "rewards/rejected": -11.070021629333496,
      "step": 6306
    },
    {
      "epoch": 2.5228,
      "grad_norm": 0.013541264459490776,
      "learning_rate": 1.592e-07,
      "logits/chosen": -2.8473682403564453,
      "logits/rejected": -2.348442792892456,
      "logps/chosen": -73.98277282714844,
      "logps/rejected": -234.74012756347656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42369574308395386,
      "rewards/margins": 11.243627548217773,
      "rewards/rejected": -10.819931030273438,
      "step": 6307
    },
    {
      "epoch": 2.5232,
      "grad_norm": 3.013521194458008,
      "learning_rate": 1.5906666666666666e-07,
      "logits/chosen": -2.809910774230957,
      "logits/rejected": -2.4612960815429688,
      "logps/chosen": -89.70970153808594,
      "logps/rejected": -140.33108520507812,
      "loss": 0.015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.28270184993743896,
      "rewards/margins": 10.428893089294434,
      "rewards/rejected": -10.146190643310547,
      "step": 6308
    },
    {
      "epoch": 2.5236,
      "grad_norm": 0.0001991014287341386,
      "learning_rate": 1.5893333333333333e-07,
      "logits/chosen": -2.7418904304504395,
      "logits/rejected": -2.1395962238311768,
      "logps/chosen": -106.44587707519531,
      "logps/rejected": -199.88375854492188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.055688321590423584,
      "rewards/margins": 14.116147994995117,
      "rewards/rejected": -14.171835899353027,
      "step": 6309
    },
    {
      "epoch": 2.524,
      "grad_norm": 0.00032361262128688395,
      "learning_rate": 1.588e-07,
      "logits/chosen": -2.44635009765625,
      "logits/rejected": -1.48238205909729,
      "logps/chosen": -90.09648132324219,
      "logps/rejected": -215.38067626953125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9352786540985107,
      "rewards/margins": 16.055042266845703,
      "rewards/rejected": -14.11976432800293,
      "step": 6310
    },
    {
      "epoch": 2.5244,
      "grad_norm": 0.02800276130437851,
      "learning_rate": 1.5866666666666666e-07,
      "logits/chosen": -2.23872971534729,
      "logits/rejected": -1.8851866722106934,
      "logps/chosen": -143.5095672607422,
      "logps/rejected": -218.93740844726562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0188171863555908,
      "rewards/margins": 11.721687316894531,
      "rewards/rejected": -12.74050521850586,
      "step": 6311
    },
    {
      "epoch": 2.5248,
      "grad_norm": 0.03954975679516792,
      "learning_rate": 1.5853333333333332e-07,
      "logits/chosen": -3.0931620597839355,
      "logits/rejected": -2.6635427474975586,
      "logps/chosen": -84.14752197265625,
      "logps/rejected": -152.85968017578125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3516111373901367,
      "rewards/margins": 9.931297302246094,
      "rewards/rejected": -9.57968521118164,
      "step": 6312
    },
    {
      "epoch": 2.5252,
      "grad_norm": 0.00044037163024768233,
      "learning_rate": 1.5840000000000002e-07,
      "logits/chosen": -2.4074554443359375,
      "logits/rejected": -1.434316635131836,
      "logps/chosen": -76.28581237792969,
      "logps/rejected": -187.287109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0671091079711914,
      "rewards/margins": 13.772968292236328,
      "rewards/rejected": -11.705859184265137,
      "step": 6313
    },
    {
      "epoch": 2.5256,
      "grad_norm": 0.005283127538859844,
      "learning_rate": 1.5826666666666665e-07,
      "logits/chosen": -2.7266640663146973,
      "logits/rejected": -1.9718217849731445,
      "logps/chosen": -160.0864715576172,
      "logps/rejected": -174.74911499023438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3987577557563782,
      "rewards/margins": 11.117124557495117,
      "rewards/rejected": -11.51588249206543,
      "step": 6314
    },
    {
      "epoch": 2.526,
      "grad_norm": 0.011984390206634998,
      "learning_rate": 1.5813333333333332e-07,
      "logits/chosen": -2.640145778656006,
      "logits/rejected": -1.5834085941314697,
      "logps/chosen": -109.17698669433594,
      "logps/rejected": -174.1965789794922,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4491604566574097,
      "rewards/margins": 9.621831893920898,
      "rewards/rejected": -11.070992469787598,
      "step": 6315
    },
    {
      "epoch": 2.5263999999999998,
      "grad_norm": 0.23923547565937042,
      "learning_rate": 1.5799999999999999e-07,
      "logits/chosen": -2.5510222911834717,
      "logits/rejected": -2.222259521484375,
      "logps/chosen": -82.27143859863281,
      "logps/rejected": -121.18209075927734,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7615680694580078,
      "rewards/margins": 8.019731521606445,
      "rewards/rejected": -7.2581634521484375,
      "step": 6316
    },
    {
      "epoch": 2.5268,
      "grad_norm": 1.7577557563781738,
      "learning_rate": 1.5786666666666665e-07,
      "logits/chosen": -2.559177875518799,
      "logits/rejected": -2.0926733016967773,
      "logps/chosen": -73.61028289794922,
      "logps/rejected": -117.44798278808594,
      "loss": 0.0111,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.780591607093811,
      "rewards/margins": 8.489005088806152,
      "rewards/rejected": -6.708413600921631,
      "step": 6317
    },
    {
      "epoch": 2.5272,
      "grad_norm": 1.399744987487793,
      "learning_rate": 1.5773333333333332e-07,
      "logits/chosen": -2.856532573699951,
      "logits/rejected": -2.886197566986084,
      "logps/chosen": -71.74267578125,
      "logps/rejected": -87.65983581542969,
      "loss": 0.0093,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05816763639450073,
      "rewards/margins": 6.3332839012146,
      "rewards/rejected": -6.275115966796875,
      "step": 6318
    },
    {
      "epoch": 2.5276,
      "grad_norm": 0.018301546573638916,
      "learning_rate": 1.5759999999999998e-07,
      "logits/chosen": -2.4412245750427246,
      "logits/rejected": -1.8382513523101807,
      "logps/chosen": -158.7713165283203,
      "logps/rejected": -163.72108459472656,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.676025390625,
      "rewards/margins": 10.676389694213867,
      "rewards/rejected": -11.352415084838867,
      "step": 6319
    },
    {
      "epoch": 2.528,
      "grad_norm": 0.8017888069152832,
      "learning_rate": 1.5746666666666667e-07,
      "logits/chosen": -2.7678754329681396,
      "logits/rejected": -2.6975741386413574,
      "logps/chosen": -51.53490447998047,
      "logps/rejected": -107.72350311279297,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8536905646324158,
      "rewards/margins": 6.756670951843262,
      "rewards/rejected": -7.610361099243164,
      "step": 6320
    },
    {
      "epoch": 2.5284,
      "grad_norm": 0.0055025555193424225,
      "learning_rate": 1.573333333333333e-07,
      "logits/chosen": -2.2680306434631348,
      "logits/rejected": -1.6169272661209106,
      "logps/chosen": -193.22207641601562,
      "logps/rejected": -183.72987365722656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9831870794296265,
      "rewards/margins": 12.19644546508789,
      "rewards/rejected": -13.179632186889648,
      "step": 6321
    },
    {
      "epoch": 2.5288,
      "grad_norm": 0.011708885431289673,
      "learning_rate": 1.572e-07,
      "logits/chosen": -2.627537727355957,
      "logits/rejected": -2.250153064727783,
      "logps/chosen": -73.55397033691406,
      "logps/rejected": -123.42658996582031,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0823605060577393,
      "rewards/margins": 10.094339370727539,
      "rewards/rejected": -9.011980056762695,
      "step": 6322
    },
    {
      "epoch": 2.5292,
      "grad_norm": 17.920984268188477,
      "learning_rate": 1.5706666666666664e-07,
      "logits/chosen": -2.445007801055908,
      "logits/rejected": -2.269474506378174,
      "logps/chosen": -155.9438934326172,
      "logps/rejected": -200.67141723632812,
      "loss": 0.0506,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -5.976105690002441,
      "rewards/margins": 7.4955668449401855,
      "rewards/rejected": -13.471672058105469,
      "step": 6323
    },
    {
      "epoch": 2.5296,
      "grad_norm": 0.9179537892341614,
      "learning_rate": 1.5693333333333334e-07,
      "logits/chosen": -2.5083909034729004,
      "logits/rejected": -1.98012375831604,
      "logps/chosen": -99.8128433227539,
      "logps/rejected": -141.85411071777344,
      "loss": 0.006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.054969415068626404,
      "rewards/margins": 7.177323341369629,
      "rewards/rejected": -7.122353553771973,
      "step": 6324
    },
    {
      "epoch": 2.5300000000000002,
      "grad_norm": 0.061258379369974136,
      "learning_rate": 1.5679999999999997e-07,
      "logits/chosen": -3.3177707195281982,
      "logits/rejected": -2.76859188079834,
      "logps/chosen": -51.683712005615234,
      "logps/rejected": -109.98947143554688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5695915222167969,
      "rewards/margins": 9.588615417480469,
      "rewards/rejected": -8.019023895263672,
      "step": 6325
    },
    {
      "epoch": 2.5304,
      "grad_norm": 0.5481454133987427,
      "learning_rate": 1.5666666666666667e-07,
      "logits/chosen": -2.6695873737335205,
      "logits/rejected": -2.592538833618164,
      "logps/chosen": -109.69268798828125,
      "logps/rejected": -99.65548706054688,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24491122364997864,
      "rewards/margins": 6.2842254638671875,
      "rewards/rejected": -6.039314270019531,
      "step": 6326
    },
    {
      "epoch": 2.5308,
      "grad_norm": 0.03000783361494541,
      "learning_rate": 1.5653333333333333e-07,
      "logits/chosen": -2.42421817779541,
      "logits/rejected": -2.056692123413086,
      "logps/chosen": -141.31390380859375,
      "logps/rejected": -154.76174926757812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2260940074920654,
      "rewards/margins": 8.94365119934082,
      "rewards/rejected": -10.169745445251465,
      "step": 6327
    },
    {
      "epoch": 2.5312,
      "grad_norm": 0.11410294473171234,
      "learning_rate": 1.564e-07,
      "logits/chosen": -2.572634220123291,
      "logits/rejected": -1.9416242837905884,
      "logps/chosen": -70.15644836425781,
      "logps/rejected": -189.64736938476562,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6372768878936768,
      "rewards/margins": 10.188538551330566,
      "rewards/rejected": -10.825815200805664,
      "step": 6328
    },
    {
      "epoch": 2.5316,
      "grad_norm": 0.17975588142871857,
      "learning_rate": 1.5626666666666666e-07,
      "logits/chosen": -2.6562676429748535,
      "logits/rejected": -2.448681354522705,
      "logps/chosen": -96.14157104492188,
      "logps/rejected": -128.67445373535156,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.375169038772583,
      "rewards/margins": 7.824698448181152,
      "rewards/rejected": -8.199867248535156,
      "step": 6329
    },
    {
      "epoch": 2.532,
      "grad_norm": 8.55053513078019e-05,
      "learning_rate": 1.5613333333333333e-07,
      "logits/chosen": -2.343015193939209,
      "logits/rejected": -1.3857214450836182,
      "logps/chosen": -132.06532287597656,
      "logps/rejected": -267.279052734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6016334295272827,
      "rewards/margins": 16.91962242126465,
      "rewards/rejected": -16.317989349365234,
      "step": 6330
    },
    {
      "epoch": 2.5324,
      "grad_norm": 0.002383946441113949,
      "learning_rate": 1.56e-07,
      "logits/chosen": -2.3059136867523193,
      "logits/rejected": -1.8439438343048096,
      "logps/chosen": -106.69606018066406,
      "logps/rejected": -223.3783721923828,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2482486367225647,
      "rewards/margins": 13.276588439941406,
      "rewards/rejected": -13.028339385986328,
      "step": 6331
    },
    {
      "epoch": 2.5328,
      "grad_norm": 0.01120788138359785,
      "learning_rate": 1.5586666666666666e-07,
      "logits/chosen": -3.005016326904297,
      "logits/rejected": -2.177065372467041,
      "logps/chosen": -52.972694396972656,
      "logps/rejected": -207.312744140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.022808656096458435,
      "rewards/margins": 12.567987442016602,
      "rewards/rejected": -12.59079647064209,
      "step": 6332
    },
    {
      "epoch": 2.5332,
      "grad_norm": 2.0149242877960205,
      "learning_rate": 1.5573333333333332e-07,
      "logits/chosen": -2.6983160972595215,
      "logits/rejected": -2.8409829139709473,
      "logps/chosen": -91.46650695800781,
      "logps/rejected": -87.21224212646484,
      "loss": 0.0105,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1024044007062912,
      "rewards/margins": 5.892309188842773,
      "rewards/rejected": -5.789904594421387,
      "step": 6333
    },
    {
      "epoch": 2.5336,
      "grad_norm": 0.9571717977523804,
      "learning_rate": 1.556e-07,
      "logits/chosen": -2.6655681133270264,
      "logits/rejected": -2.5057835578918457,
      "logps/chosen": -63.61335372924805,
      "logps/rejected": -131.16976928710938,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.11755865812301636,
      "rewards/margins": 8.461804389953613,
      "rewards/rejected": -8.579362869262695,
      "step": 6334
    },
    {
      "epoch": 2.534,
      "grad_norm": 0.002865403424948454,
      "learning_rate": 1.5546666666666666e-07,
      "logits/chosen": -2.6043572425842285,
      "logits/rejected": -1.6217020750045776,
      "logps/chosen": -122.28666687011719,
      "logps/rejected": -159.9537353515625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6819359064102173,
      "rewards/margins": 11.843507766723633,
      "rewards/rejected": -10.161571502685547,
      "step": 6335
    },
    {
      "epoch": 2.5343999999999998,
      "grad_norm": 3.7233004570007324,
      "learning_rate": 1.5533333333333332e-07,
      "logits/chosen": -2.8218026161193848,
      "logits/rejected": -2.485273838043213,
      "logps/chosen": -121.28841400146484,
      "logps/rejected": -143.93252563476562,
      "loss": 0.013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13814698159694672,
      "rewards/margins": 7.576628684997559,
      "rewards/rejected": -7.43848180770874,
      "step": 6336
    },
    {
      "epoch": 2.5348,
      "grad_norm": 0.0018844219157472253,
      "learning_rate": 1.552e-07,
      "logits/chosen": -2.855323553085327,
      "logits/rejected": -2.1251277923583984,
      "logps/chosen": -53.66035842895508,
      "logps/rejected": -224.28021240234375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6140270233154297,
      "rewards/margins": 15.710918426513672,
      "rewards/rejected": -14.096891403198242,
      "step": 6337
    },
    {
      "epoch": 2.5352,
      "grad_norm": 0.0006194942397996783,
      "learning_rate": 1.5506666666666665e-07,
      "logits/chosen": -2.4033913612365723,
      "logits/rejected": -1.9489753246307373,
      "logps/chosen": -163.6409454345703,
      "logps/rejected": -225.46800231933594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5174552798271179,
      "rewards/margins": 14.945829391479492,
      "rewards/rejected": -15.46328353881836,
      "step": 6338
    },
    {
      "epoch": 2.5356,
      "grad_norm": 0.006950558163225651,
      "learning_rate": 1.5493333333333334e-07,
      "logits/chosen": -2.265852451324463,
      "logits/rejected": -1.5697100162506104,
      "logps/chosen": -145.29150390625,
      "logps/rejected": -157.67208862304688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.47275280952453613,
      "rewards/margins": 10.994361877441406,
      "rewards/rejected": -10.52160930633545,
      "step": 6339
    },
    {
      "epoch": 2.536,
      "grad_norm": 0.016831837594509125,
      "learning_rate": 1.5479999999999998e-07,
      "logits/chosen": -2.4936137199401855,
      "logits/rejected": -1.7016841173171997,
      "logps/chosen": -132.69708251953125,
      "logps/rejected": -202.38958740234375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2251129150390625,
      "rewards/margins": 10.733699798583984,
      "rewards/rejected": -10.958812713623047,
      "step": 6340
    },
    {
      "epoch": 2.5364,
      "grad_norm": 0.00843568705022335,
      "learning_rate": 1.5466666666666668e-07,
      "logits/chosen": -2.532482624053955,
      "logits/rejected": -2.188807249069214,
      "logps/chosen": -70.57734680175781,
      "logps/rejected": -138.68104553222656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19871404767036438,
      "rewards/margins": 10.782722473144531,
      "rewards/rejected": -10.58400821685791,
      "step": 6341
    },
    {
      "epoch": 2.5368,
      "grad_norm": 0.08914674818515778,
      "learning_rate": 1.5453333333333331e-07,
      "logits/chosen": -2.695387840270996,
      "logits/rejected": -2.189837694168091,
      "logps/chosen": -108.43606567382812,
      "logps/rejected": -140.30889892578125,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7325092554092407,
      "rewards/margins": 7.500114440917969,
      "rewards/rejected": -9.232624053955078,
      "step": 6342
    },
    {
      "epoch": 2.5372,
      "grad_norm": 0.11087894439697266,
      "learning_rate": 1.544e-07,
      "logits/chosen": -1.9627888202667236,
      "logits/rejected": -1.6534192562103271,
      "logps/chosen": -208.0037841796875,
      "logps/rejected": -198.70619201660156,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.483424425125122,
      "rewards/margins": 8.705743789672852,
      "rewards/rejected": -11.189168930053711,
      "step": 6343
    },
    {
      "epoch": 2.5376,
      "grad_norm": 117.12112426757812,
      "learning_rate": 1.5426666666666665e-07,
      "logits/chosen": -2.7024707794189453,
      "logits/rejected": -2.479170083999634,
      "logps/chosen": -171.6619110107422,
      "logps/rejected": -137.74063110351562,
      "loss": 1.4299,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -5.199174404144287,
      "rewards/margins": 4.907743453979492,
      "rewards/rejected": -10.106917381286621,
      "step": 6344
    },
    {
      "epoch": 2.5380000000000003,
      "grad_norm": 0.0019408209482207894,
      "learning_rate": 1.5413333333333334e-07,
      "logits/chosen": -2.13077974319458,
      "logits/rejected": -1.891223669052124,
      "logps/chosen": -114.43669128417969,
      "logps/rejected": -212.7593231201172,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.536737084388733,
      "rewards/margins": 13.474960327148438,
      "rewards/rejected": -11.938222885131836,
      "step": 6345
    },
    {
      "epoch": 2.5384,
      "grad_norm": 0.03667602688074112,
      "learning_rate": 1.54e-07,
      "logits/chosen": -2.6548399925231934,
      "logits/rejected": -2.3881163597106934,
      "logps/chosen": -104.34953308105469,
      "logps/rejected": -199.45626831054688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.07801323384046555,
      "rewards/margins": 14.47623062133789,
      "rewards/rejected": -14.554243087768555,
      "step": 6346
    },
    {
      "epoch": 2.5388,
      "grad_norm": 0.0023781813215464354,
      "learning_rate": 1.5386666666666667e-07,
      "logits/chosen": -2.98807430267334,
      "logits/rejected": -2.4552087783813477,
      "logps/chosen": -38.522438049316406,
      "logps/rejected": -176.12945556640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7220114469528198,
      "rewards/margins": 13.190324783325195,
      "rewards/rejected": -11.468313217163086,
      "step": 6347
    },
    {
      "epoch": 2.5392,
      "grad_norm": 0.17032833397388458,
      "learning_rate": 1.5373333333333333e-07,
      "logits/chosen": -2.10790753364563,
      "logits/rejected": -1.9578557014465332,
      "logps/chosen": -213.77833557128906,
      "logps/rejected": -167.123046875,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.3269128799438477,
      "rewards/margins": 7.5940165519714355,
      "rewards/rejected": -9.920928955078125,
      "step": 6348
    },
    {
      "epoch": 2.5396,
      "grad_norm": 0.02608456462621689,
      "learning_rate": 1.5359999999999997e-07,
      "logits/chosen": -2.574747085571289,
      "logits/rejected": -2.1408917903900146,
      "logps/chosen": -73.26439666748047,
      "logps/rejected": -137.30706787109375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3467876613140106,
      "rewards/margins": 9.223223686218262,
      "rewards/rejected": -9.570011138916016,
      "step": 6349
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.7797832489013672,
      "learning_rate": 1.5346666666666666e-07,
      "logits/chosen": -2.733696937561035,
      "logits/rejected": -2.5531959533691406,
      "logps/chosen": -104.19654846191406,
      "logps/rejected": -144.1458740234375,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8912056684494019,
      "rewards/margins": 8.49931526184082,
      "rewards/rejected": -10.390520095825195,
      "step": 6350
    },
    {
      "epoch": 2.5404,
      "grad_norm": 0.0008528493344783783,
      "learning_rate": 1.533333333333333e-07,
      "logits/chosen": -2.5930252075195312,
      "logits/rejected": -1.8285484313964844,
      "logps/chosen": -102.45536804199219,
      "logps/rejected": -179.87451171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2133185863494873,
      "rewards/margins": 13.867316246032715,
      "rewards/rejected": -12.653997421264648,
      "step": 6351
    },
    {
      "epoch": 2.5408,
      "grad_norm": 0.006631477735936642,
      "learning_rate": 1.532e-07,
      "logits/chosen": -2.2232542037963867,
      "logits/rejected": -1.3656082153320312,
      "logps/chosen": -124.5864028930664,
      "logps/rejected": -187.3609161376953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8090580105781555,
      "rewards/margins": 11.127908706665039,
      "rewards/rejected": -11.936967849731445,
      "step": 6352
    },
    {
      "epoch": 2.5412,
      "grad_norm": 0.10284221172332764,
      "learning_rate": 1.5306666666666666e-07,
      "logits/chosen": -2.6133084297180176,
      "logits/rejected": -1.775763988494873,
      "logps/chosen": -73.39913940429688,
      "logps/rejected": -156.0108184814453,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8107296228408813,
      "rewards/margins": 10.840326309204102,
      "rewards/rejected": -10.029597282409668,
      "step": 6353
    },
    {
      "epoch": 2.5416,
      "grad_norm": 0.02815963886678219,
      "learning_rate": 1.5293333333333333e-07,
      "logits/chosen": -2.9283883571624756,
      "logits/rejected": -2.2584991455078125,
      "logps/chosen": -79.23080444335938,
      "logps/rejected": -128.12689208984375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0642967224121094,
      "rewards/margins": 9.386299133300781,
      "rewards/rejected": -8.322002410888672,
      "step": 6354
    },
    {
      "epoch": 2.542,
      "grad_norm": 1.5961252450942993,
      "learning_rate": 1.528e-07,
      "logits/chosen": -2.78525710105896,
      "logits/rejected": -2.7204909324645996,
      "logps/chosen": -94.05253601074219,
      "logps/rejected": -128.83172607421875,
      "loss": 0.0085,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.891470193862915,
      "rewards/margins": 8.198892593383789,
      "rewards/rejected": -9.090363502502441,
      "step": 6355
    },
    {
      "epoch": 2.5423999999999998,
      "grad_norm": 0.0033165377099066973,
      "learning_rate": 1.5266666666666666e-07,
      "logits/chosen": -2.5227670669555664,
      "logits/rejected": -1.7296943664550781,
      "logps/chosen": -99.69122314453125,
      "logps/rejected": -178.34225463867188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32281726598739624,
      "rewards/margins": 11.658073425292969,
      "rewards/rejected": -11.335256576538086,
      "step": 6356
    },
    {
      "epoch": 2.5427999999999997,
      "grad_norm": 1.0269256830215454,
      "learning_rate": 1.5253333333333332e-07,
      "logits/chosen": -2.8829917907714844,
      "logits/rejected": -2.717830181121826,
      "logps/chosen": -72.57384490966797,
      "logps/rejected": -77.34564971923828,
      "loss": 0.0055,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.072062611579895,
      "rewards/margins": 6.239720821380615,
      "rewards/rejected": -5.16765832901001,
      "step": 6357
    },
    {
      "epoch": 2.5432,
      "grad_norm": 0.4949294924736023,
      "learning_rate": 1.524e-07,
      "logits/chosen": -2.3997249603271484,
      "logits/rejected": -2.3708083629608154,
      "logps/chosen": -115.28204345703125,
      "logps/rejected": -137.57559204101562,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8082119226455688,
      "rewards/margins": 8.437948226928711,
      "rewards/rejected": -9.246160507202148,
      "step": 6358
    },
    {
      "epoch": 2.5436,
      "grad_norm": 0.027070919051766396,
      "learning_rate": 1.5226666666666665e-07,
      "logits/chosen": -2.5022597312927246,
      "logits/rejected": -1.956224799156189,
      "logps/chosen": -158.47772216796875,
      "logps/rejected": -197.37388610839844,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.947364330291748,
      "rewards/margins": 11.294981956481934,
      "rewards/rejected": -13.242345809936523,
      "step": 6359
    },
    {
      "epoch": 2.544,
      "grad_norm": 0.002407878404483199,
      "learning_rate": 1.5213333333333335e-07,
      "logits/chosen": -2.9604172706604004,
      "logits/rejected": -2.2980904579162598,
      "logps/chosen": -49.604400634765625,
      "logps/rejected": -158.13314819335938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7288530468940735,
      "rewards/margins": 11.930355072021484,
      "rewards/rejected": -11.201501846313477,
      "step": 6360
    },
    {
      "epoch": 2.5444,
      "grad_norm": 0.027921628206968307,
      "learning_rate": 1.5199999999999998e-07,
      "logits/chosen": -2.5427567958831787,
      "logits/rejected": -2.040076971054077,
      "logps/chosen": -65.94197082519531,
      "logps/rejected": -172.8921661376953,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.121229887008667,
      "rewards/margins": 13.031404495239258,
      "rewards/rejected": -10.910174369812012,
      "step": 6361
    },
    {
      "epoch": 2.5448,
      "grad_norm": 0.23439010977745056,
      "learning_rate": 1.5186666666666668e-07,
      "logits/chosen": -2.559373378753662,
      "logits/rejected": -2.215829849243164,
      "logps/chosen": -142.18788146972656,
      "logps/rejected": -164.50645446777344,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.3051066398620605,
      "rewards/margins": 8.56047534942627,
      "rewards/rejected": -10.865582466125488,
      "step": 6362
    },
    {
      "epoch": 2.5452,
      "grad_norm": 0.8151572942733765,
      "learning_rate": 1.5173333333333332e-07,
      "logits/chosen": -2.771545648574829,
      "logits/rejected": -2.8345794677734375,
      "logps/chosen": -58.43990707397461,
      "logps/rejected": -87.73072814941406,
      "loss": 0.0063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3359474539756775,
      "rewards/margins": 6.093629837036133,
      "rewards/rejected": -5.757682800292969,
      "step": 6363
    },
    {
      "epoch": 2.5456,
      "grad_norm": 0.003661865834146738,
      "learning_rate": 1.516e-07,
      "logits/chosen": -2.5892891883850098,
      "logits/rejected": -2.306406259536743,
      "logps/chosen": -78.52043914794922,
      "logps/rejected": -210.15823364257812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8507438898086548,
      "rewards/margins": 11.499221801757812,
      "rewards/rejected": -10.648477554321289,
      "step": 6364
    },
    {
      "epoch": 2.5460000000000003,
      "grad_norm": 0.2167588323354721,
      "learning_rate": 1.5146666666666665e-07,
      "logits/chosen": -1.995229959487915,
      "logits/rejected": -1.5372209548950195,
      "logps/chosen": -195.92733764648438,
      "logps/rejected": -204.25222778320312,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.3999016284942627,
      "rewards/margins": 9.562944412231445,
      "rewards/rejected": -12.962845802307129,
      "step": 6365
    },
    {
      "epoch": 2.5464,
      "grad_norm": 0.3084111213684082,
      "learning_rate": 1.513333333333333e-07,
      "logits/chosen": -2.5091392993927,
      "logits/rejected": -2.122957229614258,
      "logps/chosen": -120.430908203125,
      "logps/rejected": -201.51278686523438,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.9864747524261475,
      "rewards/margins": 9.994834899902344,
      "rewards/rejected": -13.98130989074707,
      "step": 6366
    },
    {
      "epoch": 2.5468,
      "grad_norm": 0.029454708099365234,
      "learning_rate": 1.512e-07,
      "logits/chosen": -2.605848789215088,
      "logits/rejected": -2.5385677814483643,
      "logps/chosen": -77.40605926513672,
      "logps/rejected": -111.85752868652344,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.996004343032837,
      "rewards/margins": 9.614371299743652,
      "rewards/rejected": -7.6183671951293945,
      "step": 6367
    },
    {
      "epoch": 2.5472,
      "grad_norm": 1.988584280014038,
      "learning_rate": 1.5106666666666664e-07,
      "logits/chosen": -2.592350959777832,
      "logits/rejected": -2.3517980575561523,
      "logps/chosen": -116.44522094726562,
      "logps/rejected": -108.63328552246094,
      "loss": 0.0121,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8964496850967407,
      "rewards/margins": 6.190693378448486,
      "rewards/rejected": -7.0871429443359375,
      "step": 6368
    },
    {
      "epoch": 2.5476,
      "grad_norm": 0.09315384924411774,
      "learning_rate": 1.5093333333333333e-07,
      "logits/chosen": -2.551083564758301,
      "logits/rejected": -1.9187531471252441,
      "logps/chosen": -65.6772232055664,
      "logps/rejected": -153.6048126220703,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7848028540611267,
      "rewards/margins": 11.287446022033691,
      "rewards/rejected": -10.502643585205078,
      "step": 6369
    },
    {
      "epoch": 2.548,
      "grad_norm": 0.49101758003234863,
      "learning_rate": 1.5079999999999997e-07,
      "logits/chosen": -2.711005210876465,
      "logits/rejected": -2.407461166381836,
      "logps/chosen": -78.39012908935547,
      "logps/rejected": -131.51419067382812,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7629188299179077,
      "rewards/margins": 6.706993579864502,
      "rewards/rejected": -8.4699125289917,
      "step": 6370
    },
    {
      "epoch": 2.5484,
      "grad_norm": 1.3910658359527588,
      "learning_rate": 1.5066666666666667e-07,
      "logits/chosen": -2.7657928466796875,
      "logits/rejected": -2.3011093139648438,
      "logps/chosen": -115.08219909667969,
      "logps/rejected": -141.36151123046875,
      "loss": 0.0052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6854019165039062,
      "rewards/margins": 7.513511657714844,
      "rewards/rejected": -9.19891357421875,
      "step": 6371
    },
    {
      "epoch": 2.5488,
      "grad_norm": 0.1789436638355255,
      "learning_rate": 1.505333333333333e-07,
      "logits/chosen": -2.5570456981658936,
      "logits/rejected": -2.580634117126465,
      "logps/chosen": -53.644752502441406,
      "logps/rejected": -101.95401763916016,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3606497049331665,
      "rewards/margins": 6.649542808532715,
      "rewards/rejected": -7.010191917419434,
      "step": 6372
    },
    {
      "epoch": 2.5492,
      "grad_norm": 0.009124171920120716,
      "learning_rate": 1.504e-07,
      "logits/chosen": -2.794160842895508,
      "logits/rejected": -2.511861801147461,
      "logps/chosen": -139.53976440429688,
      "logps/rejected": -145.0255126953125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20141106843948364,
      "rewards/margins": 10.224088668823242,
      "rewards/rejected": -10.022676467895508,
      "step": 6373
    },
    {
      "epoch": 2.5496,
      "grad_norm": 0.9351392984390259,
      "learning_rate": 1.5026666666666666e-07,
      "logits/chosen": -2.694514751434326,
      "logits/rejected": -2.43436598777771,
      "logps/chosen": -128.60633850097656,
      "logps/rejected": -163.39321899414062,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.6041157245635986,
      "rewards/margins": 9.37710189819336,
      "rewards/rejected": -11.981218338012695,
      "step": 6374
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.08063028752803802,
      "learning_rate": 1.5013333333333333e-07,
      "logits/chosen": -2.4527950286865234,
      "logits/rejected": -2.0314767360687256,
      "logps/chosen": -148.9702911376953,
      "logps/rejected": -226.8758544921875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.6486077308654785,
      "rewards/margins": 9.884376525878906,
      "rewards/rejected": -12.532983779907227,
      "step": 6375
    },
    {
      "epoch": 2.5504,
      "grad_norm": 0.0006740781827829778,
      "learning_rate": 1.5e-07,
      "logits/chosen": -2.671874761581421,
      "logits/rejected": -2.392542600631714,
      "logps/chosen": -88.44231414794922,
      "logps/rejected": -183.89968872070312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4106464087963104,
      "rewards/margins": 14.14586067199707,
      "rewards/rejected": -13.735214233398438,
      "step": 6376
    },
    {
      "epoch": 2.5507999999999997,
      "grad_norm": 0.0005742762004956603,
      "learning_rate": 1.4986666666666666e-07,
      "logits/chosen": -2.4457688331604004,
      "logits/rejected": -1.789949893951416,
      "logps/chosen": -83.22872924804688,
      "logps/rejected": -215.1322784423828,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2115418910980225,
      "rewards/margins": 14.602731704711914,
      "rewards/rejected": -12.391189575195312,
      "step": 6377
    },
    {
      "epoch": 2.5512,
      "grad_norm": 0.16457194089889526,
      "learning_rate": 1.4973333333333332e-07,
      "logits/chosen": -2.872004747390747,
      "logits/rejected": -2.5226216316223145,
      "logps/chosen": -41.64518356323242,
      "logps/rejected": -141.7219696044922,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.755794882774353,
      "rewards/margins": 6.962420463562012,
      "rewards/rejected": -6.206625461578369,
      "step": 6378
    },
    {
      "epoch": 2.5516,
      "grad_norm": 0.0526626892387867,
      "learning_rate": 1.4960000000000002e-07,
      "logits/chosen": -2.818085193634033,
      "logits/rejected": -2.311950206756592,
      "logps/chosen": -62.899986267089844,
      "logps/rejected": -163.61097717285156,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8932289481163025,
      "rewards/margins": 11.774881362915039,
      "rewards/rejected": -10.881651878356934,
      "step": 6379
    },
    {
      "epoch": 2.552,
      "grad_norm": 5.1231368161097635e-06,
      "learning_rate": 1.4946666666666666e-07,
      "logits/chosen": -2.563321113586426,
      "logits/rejected": -2.0208518505096436,
      "logps/chosen": -94.89286041259766,
      "logps/rejected": -232.78958129882812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.926896572113037,
      "rewards/margins": 18.237031936645508,
      "rewards/rejected": -16.310134887695312,
      "step": 6380
    },
    {
      "epoch": 2.5524,
      "grad_norm": 1.1152565479278564,
      "learning_rate": 1.4933333333333335e-07,
      "logits/chosen": -2.637571334838867,
      "logits/rejected": -2.124891996383667,
      "logps/chosen": -63.579612731933594,
      "logps/rejected": -147.8414306640625,
      "loss": 0.0077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9498656988143921,
      "rewards/margins": 10.452156066894531,
      "rewards/rejected": -9.502290725708008,
      "step": 6381
    },
    {
      "epoch": 2.5528,
      "grad_norm": 0.0999823734164238,
      "learning_rate": 1.4919999999999999e-07,
      "logits/chosen": -2.43916654586792,
      "logits/rejected": -1.9883027076721191,
      "logps/chosen": -94.40812683105469,
      "logps/rejected": -153.9798583984375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.47334402799606323,
      "rewards/margins": 10.433126449584961,
      "rewards/rejected": -9.959782600402832,
      "step": 6382
    },
    {
      "epoch": 2.5532,
      "grad_norm": 0.03871865198016167,
      "learning_rate": 1.4906666666666665e-07,
      "logits/chosen": -2.7066073417663574,
      "logits/rejected": -2.1483237743377686,
      "logps/chosen": -138.7757568359375,
      "logps/rejected": -239.13526916503906,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09384232759475708,
      "rewards/margins": 11.141550064086914,
      "rewards/rejected": -11.047707557678223,
      "step": 6383
    },
    {
      "epoch": 2.5536,
      "grad_norm": 0.0027813336346298456,
      "learning_rate": 1.4893333333333332e-07,
      "logits/chosen": -2.896143674850464,
      "logits/rejected": -2.414714813232422,
      "logps/chosen": -73.5582504272461,
      "logps/rejected": -157.16323852539062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.793931245803833,
      "rewards/margins": 11.176614761352539,
      "rewards/rejected": -10.382682800292969,
      "step": 6384
    },
    {
      "epoch": 2.5540000000000003,
      "grad_norm": 0.027213051915168762,
      "learning_rate": 1.4879999999999998e-07,
      "logits/chosen": -2.516317844390869,
      "logits/rejected": -2.413949489593506,
      "logps/chosen": -95.607421875,
      "logps/rejected": -133.58517456054688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4303201735019684,
      "rewards/margins": 9.414825439453125,
      "rewards/rejected": -8.984504699707031,
      "step": 6385
    },
    {
      "epoch": 2.5544000000000002,
      "grad_norm": 0.0008795910398475826,
      "learning_rate": 1.4866666666666667e-07,
      "logits/chosen": -2.4430978298187256,
      "logits/rejected": -1.6785426139831543,
      "logps/chosen": -134.89906311035156,
      "logps/rejected": -225.31692504882812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3284052312374115,
      "rewards/margins": 13.70693588256836,
      "rewards/rejected": -14.035341262817383,
      "step": 6386
    },
    {
      "epoch": 2.5548,
      "grad_norm": 0.09533023834228516,
      "learning_rate": 1.4853333333333331e-07,
      "logits/chosen": -2.1988892555236816,
      "logits/rejected": -1.4993025064468384,
      "logps/chosen": -193.8614959716797,
      "logps/rejected": -194.37863159179688,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0205470323562622,
      "rewards/margins": 10.261017799377441,
      "rewards/rejected": -11.281564712524414,
      "step": 6387
    },
    {
      "epoch": 2.5552,
      "grad_norm": 0.008643466047942638,
      "learning_rate": 1.484e-07,
      "logits/chosen": -2.36698055267334,
      "logits/rejected": -1.8633689880371094,
      "logps/chosen": -111.58906555175781,
      "logps/rejected": -166.73399353027344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2752807140350342,
      "rewards/margins": 10.625921249389648,
      "rewards/rejected": -9.350639343261719,
      "step": 6388
    },
    {
      "epoch": 2.5556,
      "grad_norm": 8.484546661376953,
      "learning_rate": 1.4826666666666664e-07,
      "logits/chosen": -2.665302276611328,
      "logits/rejected": -2.707465887069702,
      "logps/chosen": -106.14901733398438,
      "logps/rejected": -95.78057861328125,
      "loss": 0.0424,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7049133777618408,
      "rewards/margins": 6.08341121673584,
      "rewards/rejected": -6.788324356079102,
      "step": 6389
    },
    {
      "epoch": 2.556,
      "grad_norm": 0.00014874622866045684,
      "learning_rate": 1.4813333333333334e-07,
      "logits/chosen": -2.49330997467041,
      "logits/rejected": -2.0191383361816406,
      "logps/chosen": -106.42887115478516,
      "logps/rejected": -214.9069061279297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.318265676498413,
      "rewards/margins": 14.948699951171875,
      "rewards/rejected": -13.6304349899292,
      "step": 6390
    },
    {
      "epoch": 2.5564,
      "grad_norm": 0.0005214657285250723,
      "learning_rate": 1.4799999999999998e-07,
      "logits/chosen": -2.896209239959717,
      "logits/rejected": -2.059178113937378,
      "logps/chosen": -66.83834838867188,
      "logps/rejected": -180.68357849121094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.283782958984375,
      "rewards/margins": 13.321637153625488,
      "rewards/rejected": -12.037854194641113,
      "step": 6391
    },
    {
      "epoch": 2.5568,
      "grad_norm": 0.008251716382801533,
      "learning_rate": 1.4786666666666667e-07,
      "logits/chosen": -2.5557572841644287,
      "logits/rejected": -2.0584189891815186,
      "logps/chosen": -87.35086059570312,
      "logps/rejected": -156.79046630859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.22779390215873718,
      "rewards/margins": 10.827662467956543,
      "rewards/rejected": -11.055456161499023,
      "step": 6392
    },
    {
      "epoch": 2.5572,
      "grad_norm": 0.37636443972587585,
      "learning_rate": 1.4773333333333333e-07,
      "logits/chosen": -2.551666498184204,
      "logits/rejected": -2.2674388885498047,
      "logps/chosen": -166.09002685546875,
      "logps/rejected": -154.1126708984375,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.9779980182647705,
      "rewards/margins": 7.29449462890625,
      "rewards/rejected": -10.272493362426758,
      "step": 6393
    },
    {
      "epoch": 2.5576,
      "grad_norm": 0.004928399343043566,
      "learning_rate": 1.476e-07,
      "logits/chosen": -2.2840352058410645,
      "logits/rejected": -1.611832857131958,
      "logps/chosen": -139.32369995117188,
      "logps/rejected": -178.61483764648438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1780415177345276,
      "rewards/margins": 10.891754150390625,
      "rewards/rejected": -11.069795608520508,
      "step": 6394
    },
    {
      "epoch": 2.558,
      "grad_norm": 0.07936537265777588,
      "learning_rate": 1.4746666666666666e-07,
      "logits/chosen": -2.544403314590454,
      "logits/rejected": -2.1082592010498047,
      "logps/chosen": -126.40525817871094,
      "logps/rejected": -175.6095733642578,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8335144519805908,
      "rewards/margins": 10.473797798156738,
      "rewards/rejected": -9.64028263092041,
      "step": 6395
    },
    {
      "epoch": 2.5584,
      "grad_norm": 0.011146239005029202,
      "learning_rate": 1.4733333333333333e-07,
      "logits/chosen": -2.3047125339508057,
      "logits/rejected": -2.1438238620758057,
      "logps/chosen": -194.49964904785156,
      "logps/rejected": -205.48162841796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.175120547413826,
      "rewards/margins": 10.18749713897705,
      "rewards/rejected": -10.362617492675781,
      "step": 6396
    },
    {
      "epoch": 2.5587999999999997,
      "grad_norm": 0.7863645553588867,
      "learning_rate": 1.472e-07,
      "logits/chosen": -3.1066696643829346,
      "logits/rejected": -2.6668481826782227,
      "logps/chosen": -71.24520111083984,
      "logps/rejected": -122.50738525390625,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.36161428689956665,
      "rewards/margins": 6.817639350891113,
      "rewards/rejected": -7.179253578186035,
      "step": 6397
    },
    {
      "epoch": 2.5592,
      "grad_norm": 0.04292935132980347,
      "learning_rate": 1.4706666666666666e-07,
      "logits/chosen": -2.3980517387390137,
      "logits/rejected": -2.0686628818511963,
      "logps/chosen": -87.28562927246094,
      "logps/rejected": -142.417724609375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9318145513534546,
      "rewards/margins": 9.642341613769531,
      "rewards/rejected": -8.710527420043945,
      "step": 6398
    },
    {
      "epoch": 2.5596,
      "grad_norm": 0.4609713852405548,
      "learning_rate": 1.4693333333333333e-07,
      "logits/chosen": -2.4843645095825195,
      "logits/rejected": -1.9818658828735352,
      "logps/chosen": -98.93463134765625,
      "logps/rejected": -134.60287475585938,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5060306787490845,
      "rewards/margins": 10.59799861907959,
      "rewards/rejected": -9.091968536376953,
      "step": 6399
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.2382468432188034,
      "learning_rate": 1.4680000000000002e-07,
      "logits/chosen": -2.83229923248291,
      "logits/rejected": -2.3179454803466797,
      "logps/chosen": -93.63804626464844,
      "logps/rejected": -128.92752075195312,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.17655813694000244,
      "rewards/margins": 8.405518531799316,
      "rewards/rejected": -8.582076072692871,
      "step": 6400
    },
    {
      "epoch": 2.5604,
      "grad_norm": 0.004082434345036745,
      "learning_rate": 1.4666666666666666e-07,
      "logits/chosen": -2.5296730995178223,
      "logits/rejected": -2.0669968128204346,
      "logps/chosen": -85.04107666015625,
      "logps/rejected": -188.19419860839844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4772236347198486,
      "rewards/margins": 12.105180740356445,
      "rewards/rejected": -10.62795639038086,
      "step": 6401
    },
    {
      "epoch": 2.5608,
      "grad_norm": 0.06631992757320404,
      "learning_rate": 1.4653333333333332e-07,
      "logits/chosen": -2.4467153549194336,
      "logits/rejected": -2.2362217903137207,
      "logps/chosen": -62.457923889160156,
      "logps/rejected": -146.2767791748047,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8084741830825806,
      "rewards/margins": 8.737691879272461,
      "rewards/rejected": -7.92921781539917,
      "step": 6402
    },
    {
      "epoch": 2.5612,
      "grad_norm": 0.6520674824714661,
      "learning_rate": 1.464e-07,
      "logits/chosen": -2.4334969520568848,
      "logits/rejected": -2.072152614593506,
      "logps/chosen": -117.95075988769531,
      "logps/rejected": -194.17745971679688,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6108852624893188,
      "rewards/margins": 11.861766815185547,
      "rewards/rejected": -13.472651481628418,
      "step": 6403
    },
    {
      "epoch": 2.5616,
      "grad_norm": 0.03331064060330391,
      "learning_rate": 1.4626666666666665e-07,
      "logits/chosen": -2.685577154159546,
      "logits/rejected": -2.132643938064575,
      "logps/chosen": -103.87918090820312,
      "logps/rejected": -161.73590087890625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5019676089286804,
      "rewards/margins": 11.225313186645508,
      "rewards/rejected": -10.723345756530762,
      "step": 6404
    },
    {
      "epoch": 2.5620000000000003,
      "grad_norm": 0.021603738889098167,
      "learning_rate": 1.4613333333333332e-07,
      "logits/chosen": -2.5668134689331055,
      "logits/rejected": -2.177980661392212,
      "logps/chosen": -50.67336654663086,
      "logps/rejected": -136.49203491210938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.35308247804641724,
      "rewards/margins": 9.43803596496582,
      "rewards/rejected": -9.791118621826172,
      "step": 6405
    },
    {
      "epoch": 2.5624000000000002,
      "grad_norm": 0.12202543765306473,
      "learning_rate": 1.4599999999999998e-07,
      "logits/chosen": -2.9545063972473145,
      "logits/rejected": -2.3097712993621826,
      "logps/chosen": -56.89850616455078,
      "logps/rejected": -152.48977661132812,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40049517154693604,
      "rewards/margins": 10.197190284729004,
      "rewards/rejected": -9.796695709228516,
      "step": 6406
    },
    {
      "epoch": 2.5628,
      "grad_norm": 0.012304991483688354,
      "learning_rate": 1.4586666666666668e-07,
      "logits/chosen": -2.682694911956787,
      "logits/rejected": -2.269256114959717,
      "logps/chosen": -80.35774993896484,
      "logps/rejected": -180.98599243164062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21216660737991333,
      "rewards/margins": 10.692218780517578,
      "rewards/rejected": -10.48005199432373,
      "step": 6407
    },
    {
      "epoch": 2.5632,
      "grad_norm": 0.2514919638633728,
      "learning_rate": 1.4573333333333331e-07,
      "logits/chosen": -2.8157949447631836,
      "logits/rejected": -2.5064311027526855,
      "logps/chosen": -53.93170166015625,
      "logps/rejected": -137.7399139404297,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2468717098236084,
      "rewards/margins": 8.017709732055664,
      "rewards/rejected": -6.770838260650635,
      "step": 6408
    },
    {
      "epoch": 2.5636,
      "grad_norm": 0.27207210659980774,
      "learning_rate": 1.456e-07,
      "logits/chosen": -2.772674083709717,
      "logits/rejected": -2.4021999835968018,
      "logps/chosen": -100.49866485595703,
      "logps/rejected": -141.59854125976562,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6931871175765991,
      "rewards/margins": 8.443244934082031,
      "rewards/rejected": -9.136432647705078,
      "step": 6409
    },
    {
      "epoch": 2.564,
      "grad_norm": 0.029455125331878662,
      "learning_rate": 1.4546666666666665e-07,
      "logits/chosen": -2.596332550048828,
      "logits/rejected": -2.0137434005737305,
      "logps/chosen": -74.148681640625,
      "logps/rejected": -186.79736328125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2256832122802734,
      "rewards/margins": 13.007529258728027,
      "rewards/rejected": -11.781846046447754,
      "step": 6410
    },
    {
      "epoch": 2.5644,
      "grad_norm": 0.0009534773416817188,
      "learning_rate": 1.4533333333333334e-07,
      "logits/chosen": -2.200613498687744,
      "logits/rejected": -1.4474420547485352,
      "logps/chosen": -91.45401000976562,
      "logps/rejected": -212.4154052734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0588505268096924,
      "rewards/margins": 15.054912567138672,
      "rewards/rejected": -13.996061325073242,
      "step": 6411
    },
    {
      "epoch": 2.5648,
      "grad_norm": 0.05889542028307915,
      "learning_rate": 1.4519999999999998e-07,
      "logits/chosen": -2.6394340991973877,
      "logits/rejected": -2.0652682781219482,
      "logps/chosen": -77.93882751464844,
      "logps/rejected": -170.08944702148438,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3587372303009033,
      "rewards/margins": 12.453413009643555,
      "rewards/rejected": -10.094676971435547,
      "step": 6412
    },
    {
      "epoch": 2.5652,
      "grad_norm": 0.0032417047768831253,
      "learning_rate": 1.4506666666666667e-07,
      "logits/chosen": -2.3847856521606445,
      "logits/rejected": -2.4041614532470703,
      "logps/chosen": -109.2650146484375,
      "logps/rejected": -207.91293334960938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3629448413848877,
      "rewards/margins": 11.253646850585938,
      "rewards/rejected": -12.616592407226562,
      "step": 6413
    },
    {
      "epoch": 2.5656,
      "grad_norm": 0.004794755019247532,
      "learning_rate": 1.4493333333333333e-07,
      "logits/chosen": -2.42634916305542,
      "logits/rejected": -1.7394647598266602,
      "logps/chosen": -85.45323944091797,
      "logps/rejected": -203.77398681640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.48375195264816284,
      "rewards/margins": 13.660934448242188,
      "rewards/rejected": -13.1771821975708,
      "step": 6414
    },
    {
      "epoch": 2.566,
      "grad_norm": 0.30822038650512695,
      "learning_rate": 1.448e-07,
      "logits/chosen": -2.5186102390289307,
      "logits/rejected": -2.644805431365967,
      "logps/chosen": -95.7696533203125,
      "logps/rejected": -122.77617645263672,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0645115375518799,
      "rewards/margins": 8.45706558227539,
      "rewards/rejected": -7.392554759979248,
      "step": 6415
    },
    {
      "epoch": 2.5664,
      "grad_norm": 0.015226604416966438,
      "learning_rate": 1.4466666666666667e-07,
      "logits/chosen": -2.5105395317077637,
      "logits/rejected": -1.8667871952056885,
      "logps/chosen": -140.21673583984375,
      "logps/rejected": -188.6924285888672,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9582668542861938,
      "rewards/margins": 12.541057586669922,
      "rewards/rejected": -13.499324798583984,
      "step": 6416
    },
    {
      "epoch": 2.5667999999999997,
      "grad_norm": 0.0030671083368360996,
      "learning_rate": 1.4453333333333333e-07,
      "logits/chosen": -2.5179309844970703,
      "logits/rejected": -1.7355918884277344,
      "logps/chosen": -87.05780792236328,
      "logps/rejected": -238.19680786132812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6309990882873535,
      "rewards/margins": 15.467353820800781,
      "rewards/rejected": -13.83635425567627,
      "step": 6417
    },
    {
      "epoch": 2.5672,
      "grad_norm": 0.06204182282090187,
      "learning_rate": 1.444e-07,
      "logits/chosen": -2.5294322967529297,
      "logits/rejected": -2.0741302967071533,
      "logps/chosen": -103.18334197998047,
      "logps/rejected": -136.59088134765625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41664502024650574,
      "rewards/margins": 8.340264320373535,
      "rewards/rejected": -7.923619270324707,
      "step": 6418
    },
    {
      "epoch": 2.5676,
      "grad_norm": 0.01953793317079544,
      "learning_rate": 1.4426666666666664e-07,
      "logits/chosen": -2.321608781814575,
      "logits/rejected": -1.6464065313339233,
      "logps/chosen": -156.4712677001953,
      "logps/rejected": -159.57666015625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4726402461528778,
      "rewards/margins": 10.246381759643555,
      "rewards/rejected": -9.77374267578125,
      "step": 6419
    },
    {
      "epoch": 2.568,
      "grad_norm": 2.759268283843994,
      "learning_rate": 1.4413333333333333e-07,
      "logits/chosen": -2.787442207336426,
      "logits/rejected": -2.7088451385498047,
      "logps/chosen": -83.6463394165039,
      "logps/rejected": -109.79115295410156,
      "loss": 0.013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.17196238040924072,
      "rewards/margins": 5.950575828552246,
      "rewards/rejected": -6.122538089752197,
      "step": 6420
    },
    {
      "epoch": 2.5684,
      "grad_norm": 1.4135507345199585,
      "learning_rate": 1.44e-07,
      "logits/chosen": -2.642233371734619,
      "logits/rejected": -2.4674201011657715,
      "logps/chosen": -53.24787521362305,
      "logps/rejected": -81.31016540527344,
      "loss": 0.0113,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1156120300292969,
      "rewards/margins": 4.525948524475098,
      "rewards/rejected": -5.6415605545043945,
      "step": 6421
    },
    {
      "epoch": 2.5688,
      "grad_norm": 0.31575924158096313,
      "learning_rate": 1.4386666666666666e-07,
      "logits/chosen": -2.4804344177246094,
      "logits/rejected": -1.883994221687317,
      "logps/chosen": -152.7998046875,
      "logps/rejected": -198.44964599609375,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3987998962402344,
      "rewards/margins": 11.594011306762695,
      "rewards/rejected": -11.99281120300293,
      "step": 6422
    },
    {
      "epoch": 2.5692,
      "grad_norm": 0.04622892662882805,
      "learning_rate": 1.4373333333333332e-07,
      "logits/chosen": -2.751129150390625,
      "logits/rejected": -2.57814359664917,
      "logps/chosen": -65.17572021484375,
      "logps/rejected": -151.4275665283203,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4267321527004242,
      "rewards/margins": 9.185840606689453,
      "rewards/rejected": -9.612573623657227,
      "step": 6423
    },
    {
      "epoch": 2.5696,
      "grad_norm": 0.9331283569335938,
      "learning_rate": 1.436e-07,
      "logits/chosen": -2.282607078552246,
      "logits/rejected": -2.0615181922912598,
      "logps/chosen": -170.31179809570312,
      "logps/rejected": -153.29502868652344,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5421524047851562,
      "rewards/margins": 7.291057586669922,
      "rewards/rejected": -7.833209991455078,
      "step": 6424
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.14182212948799133,
      "learning_rate": 1.4346666666666665e-07,
      "logits/chosen": -2.262782096862793,
      "logits/rejected": -1.3092057704925537,
      "logps/chosen": -129.18801879882812,
      "logps/rejected": -198.36151123046875,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.17031633853912354,
      "rewards/margins": 11.549240112304688,
      "rewards/rejected": -11.71955680847168,
      "step": 6425
    },
    {
      "epoch": 2.5704000000000002,
      "grad_norm": 0.020944250747561455,
      "learning_rate": 1.4333333333333335e-07,
      "logits/chosen": -2.8072710037231445,
      "logits/rejected": -2.5045604705810547,
      "logps/chosen": -80.69158172607422,
      "logps/rejected": -144.35714721679688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.445259690284729,
      "rewards/margins": 9.318090438842773,
      "rewards/rejected": -9.763350486755371,
      "step": 6426
    },
    {
      "epoch": 2.5708,
      "grad_norm": 0.9603132009506226,
      "learning_rate": 1.4319999999999999e-07,
      "logits/chosen": -2.6722097396850586,
      "logits/rejected": -2.782735586166382,
      "logps/chosen": -113.56703186035156,
      "logps/rejected": -112.06853485107422,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0995357483625412,
      "rewards/margins": 5.442668437957764,
      "rewards/rejected": -5.542203903198242,
      "step": 6427
    },
    {
      "epoch": 2.5712,
      "grad_norm": 0.10883068293333054,
      "learning_rate": 1.4306666666666668e-07,
      "logits/chosen": -2.4609646797180176,
      "logits/rejected": -1.844602108001709,
      "logps/chosen": -83.60569763183594,
      "logps/rejected": -178.20713806152344,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5849983096122742,
      "rewards/margins": 12.173803329467773,
      "rewards/rejected": -12.75880241394043,
      "step": 6428
    },
    {
      "epoch": 2.5716,
      "grad_norm": 0.045469511300325394,
      "learning_rate": 1.4293333333333332e-07,
      "logits/chosen": -2.197930097579956,
      "logits/rejected": -1.6913433074951172,
      "logps/chosen": -154.55648803710938,
      "logps/rejected": -211.6494140625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7632709741592407,
      "rewards/margins": 9.552938461303711,
      "rewards/rejected": -11.31620979309082,
      "step": 6429
    },
    {
      "epoch": 2.572,
      "grad_norm": 0.243551105260849,
      "learning_rate": 1.428e-07,
      "logits/chosen": -2.6446919441223145,
      "logits/rejected": -2.1863887310028076,
      "logps/chosen": -126.42903900146484,
      "logps/rejected": -156.030517578125,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.20289039611816406,
      "rewards/margins": 9.677207946777344,
      "rewards/rejected": -9.880098342895508,
      "step": 6430
    },
    {
      "epoch": 2.5724,
      "grad_norm": 0.04835938662290573,
      "learning_rate": 1.4266666666666665e-07,
      "logits/chosen": -2.695335626602173,
      "logits/rejected": -2.3221378326416016,
      "logps/chosen": -49.09070587158203,
      "logps/rejected": -111.96626281738281,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9835833311080933,
      "rewards/margins": 9.00286865234375,
      "rewards/rejected": -8.019285202026367,
      "step": 6431
    },
    {
      "epoch": 2.5728,
      "grad_norm": 0.004457178059965372,
      "learning_rate": 1.4253333333333334e-07,
      "logits/chosen": -2.8374481201171875,
      "logits/rejected": -2.295823097229004,
      "logps/chosen": -45.981204986572266,
      "logps/rejected": -141.48684692382812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6844196319580078,
      "rewards/margins": 11.249303817749023,
      "rewards/rejected": -9.564884185791016,
      "step": 6432
    },
    {
      "epoch": 2.5732,
      "grad_norm": 0.0014357721665874124,
      "learning_rate": 1.424e-07,
      "logits/chosen": -2.5575971603393555,
      "logits/rejected": -1.8547663688659668,
      "logps/chosen": -91.40421295166016,
      "logps/rejected": -198.75222778320312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.028761625289917,
      "rewards/margins": 12.579623222351074,
      "rewards/rejected": -13.60838508605957,
      "step": 6433
    },
    {
      "epoch": 2.5736,
      "grad_norm": 0.08497896790504456,
      "learning_rate": 1.4226666666666667e-07,
      "logits/chosen": -2.23854398727417,
      "logits/rejected": -1.7400888204574585,
      "logps/chosen": -113.23478698730469,
      "logps/rejected": -213.94720458984375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13728369772434235,
      "rewards/margins": 11.630176544189453,
      "rewards/rejected": -11.49289321899414,
      "step": 6434
    },
    {
      "epoch": 2.574,
      "grad_norm": 9.215773025061935e-05,
      "learning_rate": 1.4213333333333334e-07,
      "logits/chosen": -2.326666831970215,
      "logits/rejected": -1.8460376262664795,
      "logps/chosen": -98.72056579589844,
      "logps/rejected": -266.28570556640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2362523078918457,
      "rewards/margins": 18.900876998901367,
      "rewards/rejected": -16.66462516784668,
      "step": 6435
    },
    {
      "epoch": 2.5744,
      "grad_norm": 0.05351768806576729,
      "learning_rate": 1.4199999999999997e-07,
      "logits/chosen": -2.384655237197876,
      "logits/rejected": -1.8630998134613037,
      "logps/chosen": -147.25979614257812,
      "logps/rejected": -181.6299591064453,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5067031979560852,
      "rewards/margins": 12.054754257202148,
      "rewards/rejected": -11.548050880432129,
      "step": 6436
    },
    {
      "epoch": 2.5747999999999998,
      "grad_norm": 4.1482468077447265e-05,
      "learning_rate": 1.4186666666666667e-07,
      "logits/chosen": -2.693685293197632,
      "logits/rejected": -1.9974629878997803,
      "logps/chosen": -75.04212951660156,
      "logps/rejected": -219.37677001953125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42462730407714844,
      "rewards/margins": 16.05791664123535,
      "rewards/rejected": -15.633289337158203,
      "step": 6437
    },
    {
      "epoch": 2.5752,
      "grad_norm": 0.0036656248848885298,
      "learning_rate": 1.417333333333333e-07,
      "logits/chosen": -2.6721019744873047,
      "logits/rejected": -1.8215694427490234,
      "logps/chosen": -154.93536376953125,
      "logps/rejected": -193.47743225097656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1932392120361328,
      "rewards/margins": 12.283445358276367,
      "rewards/rejected": -12.090206146240234,
      "step": 6438
    },
    {
      "epoch": 2.5756,
      "grad_norm": 2.241060733795166,
      "learning_rate": 1.416e-07,
      "logits/chosen": -2.5182652473449707,
      "logits/rejected": -2.143048048019409,
      "logps/chosen": -146.98065185546875,
      "logps/rejected": -143.82186889648438,
      "loss": 0.0064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.26666259765625,
      "rewards/margins": 8.784295082092285,
      "rewards/rejected": -10.050957679748535,
      "step": 6439
    },
    {
      "epoch": 2.576,
      "grad_norm": 0.05109560117125511,
      "learning_rate": 1.4146666666666666e-07,
      "logits/chosen": -2.5415823459625244,
      "logits/rejected": -1.949312448501587,
      "logps/chosen": -106.48106384277344,
      "logps/rejected": -181.3623809814453,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1502200961112976,
      "rewards/margins": 11.58286190032959,
      "rewards/rejected": -11.733081817626953,
      "step": 6440
    },
    {
      "epoch": 2.5764,
      "grad_norm": 0.0009507598006166518,
      "learning_rate": 1.4133333333333333e-07,
      "logits/chosen": -2.4453697204589844,
      "logits/rejected": -1.3345563411712646,
      "logps/chosen": -98.08146667480469,
      "logps/rejected": -218.630859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7487305402755737,
      "rewards/margins": 14.104095458984375,
      "rewards/rejected": -13.355365753173828,
      "step": 6441
    },
    {
      "epoch": 2.5768,
      "grad_norm": 4.435118626133772e-06,
      "learning_rate": 1.412e-07,
      "logits/chosen": -2.7329139709472656,
      "logits/rejected": -1.9919317960739136,
      "logps/chosen": -80.07452392578125,
      "logps/rejected": -260.8121337890625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1683403253555298,
      "rewards/margins": 18.58574867248535,
      "rewards/rejected": -17.417407989501953,
      "step": 6442
    },
    {
      "epoch": 2.5772,
      "grad_norm": 2.784882963169366e-05,
      "learning_rate": 1.4106666666666666e-07,
      "logits/chosen": -2.454345703125,
      "logits/rejected": -1.622676134109497,
      "logps/chosen": -84.18577575683594,
      "logps/rejected": -243.86175537109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.791276454925537,
      "rewards/margins": 17.871105194091797,
      "rewards/rejected": -15.079828262329102,
      "step": 6443
    },
    {
      "epoch": 2.5776,
      "grad_norm": 0.22277112305164337,
      "learning_rate": 1.4093333333333332e-07,
      "logits/chosen": -2.519482135772705,
      "logits/rejected": -2.369401693344116,
      "logps/chosen": -43.30859375,
      "logps/rejected": -139.15078735351562,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5301010012626648,
      "rewards/margins": 9.151262283325195,
      "rewards/rejected": -8.621161460876465,
      "step": 6444
    },
    {
      "epoch": 2.578,
      "grad_norm": 0.0013202744303271174,
      "learning_rate": 1.408e-07,
      "logits/chosen": -2.637617588043213,
      "logits/rejected": -1.9764974117279053,
      "logps/chosen": -114.99041748046875,
      "logps/rejected": -262.7758483886719,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0421173572540283,
      "rewards/margins": 14.147647857666016,
      "rewards/rejected": -13.10552978515625,
      "step": 6445
    },
    {
      "epoch": 2.5784000000000002,
      "grad_norm": 42.371482849121094,
      "learning_rate": 1.4066666666666666e-07,
      "logits/chosen": -2.2230472564697266,
      "logits/rejected": -1.6640770435333252,
      "logps/chosen": -208.6033477783203,
      "logps/rejected": -200.5751953125,
      "loss": 0.1986,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -5.3876118659973145,
      "rewards/margins": 7.221865653991699,
      "rewards/rejected": -12.609477996826172,
      "step": 6446
    },
    {
      "epoch": 2.5788,
      "grad_norm": 0.00036600304883904755,
      "learning_rate": 1.4053333333333335e-07,
      "logits/chosen": -2.3204345703125,
      "logits/rejected": -1.298661231994629,
      "logps/chosen": -129.27845764160156,
      "logps/rejected": -211.45037841796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4535965323448181,
      "rewards/margins": 14.282695770263672,
      "rewards/rejected": -13.829099655151367,
      "step": 6447
    },
    {
      "epoch": 2.5792,
      "grad_norm": 0.020208053290843964,
      "learning_rate": 1.4039999999999999e-07,
      "logits/chosen": -2.7757322788238525,
      "logits/rejected": -2.1270716190338135,
      "logps/chosen": -149.95831298828125,
      "logps/rejected": -164.61679077148438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6101791858673096,
      "rewards/margins": 9.62253475189209,
      "rewards/rejected": -10.23271369934082,
      "step": 6448
    },
    {
      "epoch": 2.5796,
      "grad_norm": 163.1944580078125,
      "learning_rate": 1.4026666666666668e-07,
      "logits/chosen": -2.477876663208008,
      "logits/rejected": -2.0771644115448,
      "logps/chosen": -159.4380340576172,
      "logps/rejected": -115.30148315429688,
      "loss": 1.769,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -4.515273571014404,
      "rewards/margins": 3.829467296600342,
      "rewards/rejected": -8.344740867614746,
      "step": 6449
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.025684522464871407,
      "learning_rate": 1.4013333333333332e-07,
      "logits/chosen": -2.4441823959350586,
      "logits/rejected": -1.8494610786437988,
      "logps/chosen": -106.12704467773438,
      "logps/rejected": -167.20587158203125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7638039588928223,
      "rewards/margins": 11.210185050964355,
      "rewards/rejected": -9.446380615234375,
      "step": 6450
    },
    {
      "epoch": 2.5804,
      "grad_norm": 0.7045844197273254,
      "learning_rate": 1.4e-07,
      "logits/chosen": -3.0540614128112793,
      "logits/rejected": -2.577942371368408,
      "logps/chosen": -42.123191833496094,
      "logps/rejected": -152.6501922607422,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7399609088897705,
      "rewards/margins": 9.065174102783203,
      "rewards/rejected": -8.325213432312012,
      "step": 6451
    },
    {
      "epoch": 2.5808,
      "grad_norm": 0.22348077595233917,
      "learning_rate": 1.3986666666666665e-07,
      "logits/chosen": -2.7460193634033203,
      "logits/rejected": -2.5593457221984863,
      "logps/chosen": -74.11298370361328,
      "logps/rejected": -109.38426971435547,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0192556381225586,
      "rewards/margins": 6.550595283508301,
      "rewards/rejected": -7.569850921630859,
      "step": 6452
    },
    {
      "epoch": 2.5812,
      "grad_norm": 0.016684850677847862,
      "learning_rate": 1.3973333333333331e-07,
      "logits/chosen": -2.6764183044433594,
      "logits/rejected": -1.9712917804718018,
      "logps/chosen": -58.86878967285156,
      "logps/rejected": -169.4634246826172,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.305769205093384,
      "rewards/margins": 13.520410537719727,
      "rewards/rejected": -11.214641571044922,
      "step": 6453
    },
    {
      "epoch": 2.5816,
      "grad_norm": 0.9810997843742371,
      "learning_rate": 1.396e-07,
      "logits/chosen": -2.493647575378418,
      "logits/rejected": -2.558504104614258,
      "logps/chosen": -109.2983627319336,
      "logps/rejected": -127.5733642578125,
      "loss": 0.0064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5089560747146606,
      "rewards/margins": 7.095829486846924,
      "rewards/rejected": -8.604785919189453,
      "step": 6454
    },
    {
      "epoch": 2.582,
      "grad_norm": 0.009781303815543652,
      "learning_rate": 1.3946666666666664e-07,
      "logits/chosen": -2.5971341133117676,
      "logits/rejected": -2.0034260749816895,
      "logps/chosen": -110.10879516601562,
      "logps/rejected": -178.3930206298828,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.12685070931911469,
      "rewards/margins": 10.105840682983398,
      "rewards/rejected": -10.232690811157227,
      "step": 6455
    },
    {
      "epoch": 2.5824,
      "grad_norm": 1.4834352731704712,
      "learning_rate": 1.3933333333333334e-07,
      "logits/chosen": -2.6364359855651855,
      "logits/rejected": -2.541604518890381,
      "logps/chosen": -68.75999450683594,
      "logps/rejected": -86.39613342285156,
      "loss": 0.0088,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.17646388709545135,
      "rewards/margins": 5.746306896209717,
      "rewards/rejected": -5.922770977020264,
      "step": 6456
    },
    {
      "epoch": 2.5827999999999998,
      "grad_norm": 0.04207679629325867,
      "learning_rate": 1.3919999999999998e-07,
      "logits/chosen": -2.5798463821411133,
      "logits/rejected": -2.1321849822998047,
      "logps/chosen": -108.1809310913086,
      "logps/rejected": -185.7627716064453,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1028708219528198,
      "rewards/margins": 10.083863258361816,
      "rewards/rejected": -11.186734199523926,
      "step": 6457
    },
    {
      "epoch": 2.5832,
      "grad_norm": 0.006949571892619133,
      "learning_rate": 1.3906666666666667e-07,
      "logits/chosen": -1.855696201324463,
      "logits/rejected": -1.4924087524414062,
      "logps/chosen": -138.03598022460938,
      "logps/rejected": -248.83828735351562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2465256452560425,
      "rewards/margins": 10.71449089050293,
      "rewards/rejected": -11.961016654968262,
      "step": 6458
    },
    {
      "epoch": 2.5836,
      "grad_norm": 0.13811348378658295,
      "learning_rate": 1.389333333333333e-07,
      "logits/chosen": -2.8487024307250977,
      "logits/rejected": -2.451756477355957,
      "logps/chosen": -97.67549896240234,
      "logps/rejected": -169.85980224609375,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8303230404853821,
      "rewards/margins": 10.469407081604004,
      "rewards/rejected": -11.29973030090332,
      "step": 6459
    },
    {
      "epoch": 2.584,
      "grad_norm": 0.015859687700867653,
      "learning_rate": 1.388e-07,
      "logits/chosen": -2.1872482299804688,
      "logits/rejected": -1.3892688751220703,
      "logps/chosen": -160.2095184326172,
      "logps/rejected": -171.69265747070312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.02517545223236084,
      "rewards/margins": 10.593317031860352,
      "rewards/rejected": -10.618492126464844,
      "step": 6460
    },
    {
      "epoch": 2.5844,
      "grad_norm": 0.005891125649213791,
      "learning_rate": 1.3866666666666666e-07,
      "logits/chosen": -2.696751117706299,
      "logits/rejected": -2.172410726547241,
      "logps/chosen": -97.05520629882812,
      "logps/rejected": -181.3600616455078,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6454788446426392,
      "rewards/margins": 11.768610000610352,
      "rewards/rejected": -11.123130798339844,
      "step": 6461
    },
    {
      "epoch": 2.5848,
      "grad_norm": 0.20905515551567078,
      "learning_rate": 1.3853333333333333e-07,
      "logits/chosen": -2.402656316757202,
      "logits/rejected": -2.02593994140625,
      "logps/chosen": -187.4112548828125,
      "logps/rejected": -150.62448120117188,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.12798810005188,
      "rewards/margins": 7.643678665161133,
      "rewards/rejected": -10.77166748046875,
      "step": 6462
    },
    {
      "epoch": 2.5852,
      "grad_norm": 0.6037818789482117,
      "learning_rate": 1.384e-07,
      "logits/chosen": -2.8579447269439697,
      "logits/rejected": -2.455679416656494,
      "logps/chosen": -82.36519622802734,
      "logps/rejected": -182.6675262451172,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1941089630126953,
      "rewards/margins": 8.909521102905273,
      "rewards/rejected": -9.103630065917969,
      "step": 6463
    },
    {
      "epoch": 2.5856,
      "grad_norm": 0.0065610515885055065,
      "learning_rate": 1.3826666666666666e-07,
      "logits/chosen": -2.872408390045166,
      "logits/rejected": -2.112638235092163,
      "logps/chosen": -72.96395874023438,
      "logps/rejected": -163.3038330078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08875275403261185,
      "rewards/margins": 10.582737922668457,
      "rewards/rejected": -10.671490669250488,
      "step": 6464
    },
    {
      "epoch": 2.586,
      "grad_norm": 0.326890766620636,
      "learning_rate": 1.3813333333333333e-07,
      "logits/chosen": -2.5109329223632812,
      "logits/rejected": -2.3546369075775146,
      "logps/chosen": -211.83856201171875,
      "logps/rejected": -182.0488739013672,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.40684700012207,
      "rewards/margins": 8.12271499633789,
      "rewards/rejected": -12.529561996459961,
      "step": 6465
    },
    {
      "epoch": 2.5864000000000003,
      "grad_norm": 0.0014763018116354942,
      "learning_rate": 1.3800000000000002e-07,
      "logits/chosen": -2.691507339477539,
      "logits/rejected": -1.7849538326263428,
      "logps/chosen": -74.29387664794922,
      "logps/rejected": -169.9150390625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4522156715393066,
      "rewards/margins": 14.045557975769043,
      "rewards/rejected": -11.593342781066895,
      "step": 6466
    },
    {
      "epoch": 2.5868,
      "grad_norm": 3.6537930965423584,
      "learning_rate": 1.3786666666666666e-07,
      "logits/chosen": -2.950678825378418,
      "logits/rejected": -2.2862491607666016,
      "logps/chosen": -80.0687255859375,
      "logps/rejected": -166.69732666015625,
      "loss": 0.0156,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2869402170181274,
      "rewards/margins": 9.46931266784668,
      "rewards/rejected": -8.182372093200684,
      "step": 6467
    },
    {
      "epoch": 2.5872,
      "grad_norm": 0.032119471579790115,
      "learning_rate": 1.3773333333333335e-07,
      "logits/chosen": -2.7184019088745117,
      "logits/rejected": -2.263923168182373,
      "logps/chosen": -116.62897491455078,
      "logps/rejected": -160.4555206298828,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.253262519836426,
      "rewards/margins": 8.494242668151855,
      "rewards/rejected": -10.747505187988281,
      "step": 6468
    },
    {
      "epoch": 2.5876,
      "grad_norm": 0.004467529244720936,
      "learning_rate": 1.376e-07,
      "logits/chosen": -2.1992876529693604,
      "logits/rejected": -1.580596685409546,
      "logps/chosen": -145.85658264160156,
      "logps/rejected": -212.89999389648438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.29756394028663635,
      "rewards/margins": 14.717069625854492,
      "rewards/rejected": -15.014633178710938,
      "step": 6469
    },
    {
      "epoch": 2.588,
      "grad_norm": 0.5459527373313904,
      "learning_rate": 1.3746666666666665e-07,
      "logits/chosen": -2.0480704307556152,
      "logits/rejected": -1.4242351055145264,
      "logps/chosen": -249.57717895507812,
      "logps/rejected": -213.57635498046875,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.125505208969116,
      "rewards/margins": 8.356772422790527,
      "rewards/rejected": -10.482277870178223,
      "step": 6470
    },
    {
      "epoch": 2.5884,
      "grad_norm": 120.38682556152344,
      "learning_rate": 1.3733333333333332e-07,
      "logits/chosen": -2.235109329223633,
      "logits/rejected": -1.7134642601013184,
      "logps/chosen": -233.7525177001953,
      "logps/rejected": -191.36181640625,
      "loss": 0.5029,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -5.630734920501709,
      "rewards/margins": 7.423637866973877,
      "rewards/rejected": -13.054372787475586,
      "step": 6471
    },
    {
      "epoch": 2.5888,
      "grad_norm": 6.342235565185547,
      "learning_rate": 1.3719999999999998e-07,
      "logits/chosen": -2.6989612579345703,
      "logits/rejected": -2.3290109634399414,
      "logps/chosen": -140.62620544433594,
      "logps/rejected": -121.9547119140625,
      "loss": 0.022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.30460262298584,
      "rewards/margins": 5.406064033508301,
      "rewards/rejected": -7.710666656494141,
      "step": 6472
    },
    {
      "epoch": 2.5892,
      "grad_norm": 0.0013216928346082568,
      "learning_rate": 1.3706666666666668e-07,
      "logits/chosen": -3.0707345008850098,
      "logits/rejected": -2.38155460357666,
      "logps/chosen": -112.1527099609375,
      "logps/rejected": -205.2704315185547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8674103021621704,
      "rewards/margins": 14.600997924804688,
      "rewards/rejected": -15.468408584594727,
      "step": 6473
    },
    {
      "epoch": 2.5896,
      "grad_norm": 0.0046137054450809956,
      "learning_rate": 1.3693333333333332e-07,
      "logits/chosen": -2.4233500957489014,
      "logits/rejected": -1.807116985321045,
      "logps/chosen": -72.05912017822266,
      "logps/rejected": -248.69992065429688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.65585196018219,
      "rewards/margins": 14.324848175048828,
      "rewards/rejected": -15.980700492858887,
      "step": 6474
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.14987388253211975,
      "learning_rate": 1.368e-07,
      "logits/chosen": -2.5478148460388184,
      "logits/rejected": -2.13832688331604,
      "logps/chosen": -67.382568359375,
      "logps/rejected": -196.06918334960938,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08533783257007599,
      "rewards/margins": 8.950429916381836,
      "rewards/rejected": -9.0357666015625,
      "step": 6475
    },
    {
      "epoch": 2.5904,
      "grad_norm": 2.4860594272613525,
      "learning_rate": 1.3666666666666665e-07,
      "logits/chosen": -1.995224952697754,
      "logits/rejected": -1.3718514442443848,
      "logps/chosen": -122.09406280517578,
      "logps/rejected": -169.6885528564453,
      "loss": 0.0098,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.9045608043670654,
      "rewards/margins": 8.866647720336914,
      "rewards/rejected": -11.771207809448242,
      "step": 6476
    },
    {
      "epoch": 2.5907999999999998,
      "grad_norm": 0.06260084360837936,
      "learning_rate": 1.3653333333333334e-07,
      "logits/chosen": -3.00278377532959,
      "logits/rejected": -2.5487310886383057,
      "logps/chosen": -68.78692626953125,
      "logps/rejected": -156.47012329101562,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5393943786621094,
      "rewards/margins": 11.207456588745117,
      "rewards/rejected": -10.668062210083008,
      "step": 6477
    },
    {
      "epoch": 2.5911999999999997,
      "grad_norm": 0.002538025379180908,
      "learning_rate": 1.3639999999999998e-07,
      "logits/chosen": -2.8712220191955566,
      "logits/rejected": -2.233755588531494,
      "logps/chosen": -100.78889465332031,
      "logps/rejected": -178.48907470703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09124243259429932,
      "rewards/margins": 13.133935928344727,
      "rewards/rejected": -13.042694091796875,
      "step": 6478
    },
    {
      "epoch": 2.5916,
      "grad_norm": 0.0015253853052854538,
      "learning_rate": 1.3626666666666667e-07,
      "logits/chosen": -2.7709789276123047,
      "logits/rejected": -2.344255208969116,
      "logps/chosen": -66.53426361083984,
      "logps/rejected": -179.38198852539062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3894413113594055,
      "rewards/margins": 12.519281387329102,
      "rewards/rejected": -12.129838943481445,
      "step": 6479
    },
    {
      "epoch": 2.592,
      "grad_norm": 6.138423442840576,
      "learning_rate": 1.3613333333333333e-07,
      "logits/chosen": -2.8260135650634766,
      "logits/rejected": -2.3461499214172363,
      "logps/chosen": -73.77989196777344,
      "logps/rejected": -163.34188842773438,
      "loss": 0.0339,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0488017797470093,
      "rewards/margins": 10.244025230407715,
      "rewards/rejected": -9.195222854614258,
      "step": 6480
    },
    {
      "epoch": 2.5924,
      "grad_norm": 0.000658583827316761,
      "learning_rate": 1.36e-07,
      "logits/chosen": -2.7206568717956543,
      "logits/rejected": -1.9239038228988647,
      "logps/chosen": -61.672080993652344,
      "logps/rejected": -208.97479248046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7532495856285095,
      "rewards/margins": 14.865915298461914,
      "rewards/rejected": -14.112665176391602,
      "step": 6481
    },
    {
      "epoch": 2.5928,
      "grad_norm": 8.258906746050343e-05,
      "learning_rate": 1.3586666666666667e-07,
      "logits/chosen": -2.50002384185791,
      "logits/rejected": -1.9908497333526611,
      "logps/chosen": -67.26744079589844,
      "logps/rejected": -257.7078552246094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0366225242614746,
      "rewards/margins": 16.909687042236328,
      "rewards/rejected": -14.873064041137695,
      "step": 6482
    },
    {
      "epoch": 2.5932,
      "grad_norm": 1.9195854663848877,
      "learning_rate": 1.3573333333333333e-07,
      "logits/chosen": -2.604794979095459,
      "logits/rejected": -2.0977370738983154,
      "logps/chosen": -101.1402587890625,
      "logps/rejected": -155.50640869140625,
      "loss": 0.0082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.04353666305542,
      "rewards/margins": 8.908838272094727,
      "rewards/rejected": -9.952374458312988,
      "step": 6483
    },
    {
      "epoch": 2.5936,
      "grad_norm": 0.3036598563194275,
      "learning_rate": 1.356e-07,
      "logits/chosen": -2.5857486724853516,
      "logits/rejected": -2.3589835166931152,
      "logps/chosen": -120.26371002197266,
      "logps/rejected": -181.8800048828125,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4483039975166321,
      "rewards/margins": 11.902565956115723,
      "rewards/rejected": -12.350870132446289,
      "step": 6484
    },
    {
      "epoch": 2.594,
      "grad_norm": 0.03230442851781845,
      "learning_rate": 1.3546666666666666e-07,
      "logits/chosen": -2.477398633956909,
      "logits/rejected": -2.095350980758667,
      "logps/chosen": -175.52578735351562,
      "logps/rejected": -165.59402465820312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.04716956615448,
      "rewards/margins": 8.914264678955078,
      "rewards/rejected": -9.961435317993164,
      "step": 6485
    },
    {
      "epoch": 2.5944000000000003,
      "grad_norm": 0.5718687176704407,
      "learning_rate": 1.3533333333333333e-07,
      "logits/chosen": -2.409083366394043,
      "logits/rejected": -1.7065898180007935,
      "logps/chosen": -144.1295166015625,
      "logps/rejected": -162.39898681640625,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2285957336425781,
      "rewards/margins": 8.52978229522705,
      "rewards/rejected": -9.758378028869629,
      "step": 6486
    },
    {
      "epoch": 2.5948,
      "grad_norm": 0.07093939185142517,
      "learning_rate": 1.352e-07,
      "logits/chosen": -2.3612661361694336,
      "logits/rejected": -1.926681399345398,
      "logps/chosen": -118.77375793457031,
      "logps/rejected": -114.77505493164062,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6484272480010986,
      "rewards/margins": 8.230101585388184,
      "rewards/rejected": -7.581674575805664,
      "step": 6487
    },
    {
      "epoch": 2.5952,
      "grad_norm": 7.157446384429932,
      "learning_rate": 1.3506666666666666e-07,
      "logits/chosen": -2.7265255451202393,
      "logits/rejected": -2.510690689086914,
      "logps/chosen": -101.38302612304688,
      "logps/rejected": -128.533447265625,
      "loss": 0.0681,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.45060768723487854,
      "rewards/margins": 6.4304070472717285,
      "rewards/rejected": -6.881014823913574,
      "step": 6488
    },
    {
      "epoch": 2.5956,
      "grad_norm": 0.0001336134591838345,
      "learning_rate": 1.3493333333333332e-07,
      "logits/chosen": -2.5437045097351074,
      "logits/rejected": -1.915611982345581,
      "logps/chosen": -115.06971740722656,
      "logps/rejected": -199.62158203125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6479473114013672,
      "rewards/margins": 14.797027587890625,
      "rewards/rejected": -14.149080276489258,
      "step": 6489
    },
    {
      "epoch": 2.596,
      "grad_norm": 0.0018823292339220643,
      "learning_rate": 1.348e-07,
      "logits/chosen": -2.207068681716919,
      "logits/rejected": -1.5403964519500732,
      "logps/chosen": -72.60975646972656,
      "logps/rejected": -237.71731567382812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.966047465801239,
      "rewards/margins": 12.786577224731445,
      "rewards/rejected": -11.82052993774414,
      "step": 6490
    },
    {
      "epoch": 2.5964,
      "grad_norm": 0.5221826434135437,
      "learning_rate": 1.3466666666666665e-07,
      "logits/chosen": -2.6547818183898926,
      "logits/rejected": -2.579782247543335,
      "logps/chosen": -67.9562759399414,
      "logps/rejected": -98.27720642089844,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11753064393997192,
      "rewards/margins": 5.998078346252441,
      "rewards/rejected": -5.880548000335693,
      "step": 6491
    },
    {
      "epoch": 2.5968,
      "grad_norm": 0.5865615010261536,
      "learning_rate": 1.3453333333333332e-07,
      "logits/chosen": -2.4561500549316406,
      "logits/rejected": -2.2567310333251953,
      "logps/chosen": -148.29888916015625,
      "logps/rejected": -186.8394775390625,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.7887625694274902,
      "rewards/margins": 8.405380249023438,
      "rewards/rejected": -11.194143295288086,
      "step": 6492
    },
    {
      "epoch": 2.5972,
      "grad_norm": 0.00018603225180413574,
      "learning_rate": 1.3439999999999999e-07,
      "logits/chosen": -2.377825975418091,
      "logits/rejected": -1.605288028717041,
      "logps/chosen": -113.06562042236328,
      "logps/rejected": -247.31759643554688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.338139295578003,
      "rewards/margins": 15.028766632080078,
      "rewards/rejected": -13.690628051757812,
      "step": 6493
    },
    {
      "epoch": 2.5976,
      "grad_norm": 5.0969938456546515e-05,
      "learning_rate": 1.3426666666666668e-07,
      "logits/chosen": -2.5276436805725098,
      "logits/rejected": -1.8441998958587646,
      "logps/chosen": -89.95960235595703,
      "logps/rejected": -276.5296325683594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7586579322814941,
      "rewards/margins": 16.011457443237305,
      "rewards/rejected": -14.252799987792969,
      "step": 6494
    },
    {
      "epoch": 2.598,
      "grad_norm": 4.741722583770752,
      "learning_rate": 1.3413333333333332e-07,
      "logits/chosen": -2.736642360687256,
      "logits/rejected": -2.9336936473846436,
      "logps/chosen": -50.84700012207031,
      "logps/rejected": -64.39266204833984,
      "loss": 0.0367,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5019304156303406,
      "rewards/margins": 3.5290310382843018,
      "rewards/rejected": -4.030961513519287,
      "step": 6495
    },
    {
      "epoch": 2.5984,
      "grad_norm": 0.0002552569203544408,
      "learning_rate": 1.34e-07,
      "logits/chosen": -2.3849265575408936,
      "logits/rejected": -1.659200668334961,
      "logps/chosen": -228.19107055664062,
      "logps/rejected": -278.35467529296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9459800720214844,
      "rewards/margins": 14.602884292602539,
      "rewards/rejected": -16.548864364624023,
      "step": 6496
    },
    {
      "epoch": 2.5987999999999998,
      "grad_norm": 0.0013140866067260504,
      "learning_rate": 1.3386666666666665e-07,
      "logits/chosen": -2.377735137939453,
      "logits/rejected": -1.4940497875213623,
      "logps/chosen": -78.12956237792969,
      "logps/rejected": -218.13296508789062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6501812934875488,
      "rewards/margins": 13.600057601928711,
      "rewards/rejected": -11.949875831604004,
      "step": 6497
    },
    {
      "epoch": 2.5991999999999997,
      "grad_norm": 0.4725344777107239,
      "learning_rate": 1.3373333333333334e-07,
      "logits/chosen": -2.6363232135772705,
      "logits/rejected": -2.0978126525878906,
      "logps/chosen": -66.98159790039062,
      "logps/rejected": -142.16555786132812,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.48981282114982605,
      "rewards/margins": 9.703619003295898,
      "rewards/rejected": -9.21380615234375,
      "step": 6498
    },
    {
      "epoch": 2.5996,
      "grad_norm": 0.35135775804519653,
      "learning_rate": 1.3359999999999998e-07,
      "logits/chosen": -2.60022234916687,
      "logits/rejected": -2.0081000328063965,
      "logps/chosen": -99.15890502929688,
      "logps/rejected": -169.74942016601562,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9945656657218933,
      "rewards/margins": 8.945228576660156,
      "rewards/rejected": -9.939794540405273,
      "step": 6499
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.031902242451906204,
      "learning_rate": 1.3346666666666667e-07,
      "logits/chosen": -2.132493495941162,
      "logits/rejected": -1.6036970615386963,
      "logps/chosen": -188.0264892578125,
      "logps/rejected": -172.26223754882812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.5334179401397705,
      "rewards/margins": 9.571138381958008,
      "rewards/rejected": -12.104557037353516,
      "step": 6500
    },
    {
      "epoch": 2.6004,
      "grad_norm": 0.001567745115607977,
      "learning_rate": 1.3333333333333334e-07,
      "logits/chosen": -2.463615894317627,
      "logits/rejected": -1.909206509590149,
      "logps/chosen": -34.551700592041016,
      "logps/rejected": -179.6296844482422,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7379215359687805,
      "rewards/margins": 12.760024070739746,
      "rewards/rejected": -12.022102355957031,
      "step": 6501
    },
    {
      "epoch": 2.6008,
      "grad_norm": 0.0022751674987375736,
      "learning_rate": 1.332e-07,
      "logits/chosen": -2.3119356632232666,
      "logits/rejected": -2.2356224060058594,
      "logps/chosen": -105.0399169921875,
      "logps/rejected": -249.85858154296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.398306667804718,
      "rewards/margins": 12.33807373046875,
      "rewards/rejected": -11.939767837524414,
      "step": 6502
    },
    {
      "epoch": 2.6012,
      "grad_norm": 0.02745872549712658,
      "learning_rate": 1.3306666666666667e-07,
      "logits/chosen": -2.5271077156066895,
      "logits/rejected": -1.9348464012145996,
      "logps/chosen": -92.98434448242188,
      "logps/rejected": -169.40274047851562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8624495267868042,
      "rewards/margins": 11.911661148071289,
      "rewards/rejected": -11.049211502075195,
      "step": 6503
    },
    {
      "epoch": 2.6016,
      "grad_norm": 0.013713138177990913,
      "learning_rate": 1.329333333333333e-07,
      "logits/chosen": -2.136460304260254,
      "logits/rejected": -1.8350872993469238,
      "logps/chosen": -110.20814514160156,
      "logps/rejected": -192.26388549804688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5712871551513672,
      "rewards/margins": 12.848258972167969,
      "rewards/rejected": -12.276972770690918,
      "step": 6504
    },
    {
      "epoch": 2.602,
      "grad_norm": 0.0009827675530686975,
      "learning_rate": 1.328e-07,
      "logits/chosen": -2.5914969444274902,
      "logits/rejected": -1.7476787567138672,
      "logps/chosen": -60.73705291748047,
      "logps/rejected": -216.1142578125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31361502408981323,
      "rewards/margins": 15.870316505432129,
      "rewards/rejected": -15.55670166015625,
      "step": 6505
    },
    {
      "epoch": 2.6024000000000003,
      "grad_norm": 1.5177757740020752,
      "learning_rate": 1.3266666666666664e-07,
      "logits/chosen": -2.0647921562194824,
      "logits/rejected": -1.4388903379440308,
      "logps/chosen": -169.5121612548828,
      "logps/rejected": -164.51429748535156,
      "loss": 0.0082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9756836891174316,
      "rewards/margins": 8.653592109680176,
      "rewards/rejected": -10.629276275634766,
      "step": 6506
    },
    {
      "epoch": 2.6028000000000002,
      "grad_norm": 0.020692097023129463,
      "learning_rate": 1.3253333333333333e-07,
      "logits/chosen": -2.631640911102295,
      "logits/rejected": -2.3441367149353027,
      "logps/chosen": -52.42357635498047,
      "logps/rejected": -163.462646484375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5461959838867188,
      "rewards/margins": 11.675853729248047,
      "rewards/rejected": -12.222049713134766,
      "step": 6507
    },
    {
      "epoch": 2.6032,
      "grad_norm": 0.0003802010614890605,
      "learning_rate": 1.324e-07,
      "logits/chosen": -2.8984427452087402,
      "logits/rejected": -2.253159523010254,
      "logps/chosen": -94.12525939941406,
      "logps/rejected": -214.78662109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9535220861434937,
      "rewards/margins": 15.722616195678711,
      "rewards/rejected": -14.769094467163086,
      "step": 6508
    },
    {
      "epoch": 2.6036,
      "grad_norm": 0.3906826972961426,
      "learning_rate": 1.3226666666666666e-07,
      "logits/chosen": -2.591826915740967,
      "logits/rejected": -2.280060052871704,
      "logps/chosen": -102.40824890136719,
      "logps/rejected": -114.52859497070312,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9176162481307983,
      "rewards/margins": 5.865387916564941,
      "rewards/rejected": -7.783004283905029,
      "step": 6509
    },
    {
      "epoch": 2.604,
      "grad_norm": 0.07279331982135773,
      "learning_rate": 1.3213333333333333e-07,
      "logits/chosen": -2.4801275730133057,
      "logits/rejected": -1.9143881797790527,
      "logps/chosen": -88.65859985351562,
      "logps/rejected": -177.24981689453125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.33271142840385437,
      "rewards/margins": 11.82741928100586,
      "rewards/rejected": -12.160130500793457,
      "step": 6510
    },
    {
      "epoch": 2.6044,
      "grad_norm": 0.8296314477920532,
      "learning_rate": 1.32e-07,
      "logits/chosen": -2.815016746520996,
      "logits/rejected": -2.595233201980591,
      "logps/chosen": -62.43445587158203,
      "logps/rejected": -106.34176635742188,
      "loss": 0.0077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1527217626571655,
      "rewards/margins": 5.841655254364014,
      "rewards/rejected": -6.994377136230469,
      "step": 6511
    },
    {
      "epoch": 2.6048,
      "grad_norm": 4.609268665313721,
      "learning_rate": 1.3186666666666666e-07,
      "logits/chosen": -2.507066249847412,
      "logits/rejected": -2.2971291542053223,
      "logps/chosen": -119.95323944091797,
      "logps/rejected": -174.6310577392578,
      "loss": 0.0153,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.976637363433838,
      "rewards/margins": 7.828097343444824,
      "rewards/rejected": -11.80473518371582,
      "step": 6512
    },
    {
      "epoch": 2.6052,
      "grad_norm": 0.09586519747972488,
      "learning_rate": 1.3173333333333335e-07,
      "logits/chosen": -2.6032843589782715,
      "logits/rejected": -2.262939214706421,
      "logps/chosen": -63.76522445678711,
      "logps/rejected": -138.98976135253906,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5016416311264038,
      "rewards/margins": 9.85527229309082,
      "rewards/rejected": -9.353631019592285,
      "step": 6513
    },
    {
      "epoch": 2.6056,
      "grad_norm": 0.024066736921668053,
      "learning_rate": 1.316e-07,
      "logits/chosen": -2.3878121376037598,
      "logits/rejected": -1.684603214263916,
      "logps/chosen": -181.9280548095703,
      "logps/rejected": -256.66705322265625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.6803033351898193,
      "rewards/margins": 12.13216781616211,
      "rewards/rejected": -14.812470436096191,
      "step": 6514
    },
    {
      "epoch": 2.606,
      "grad_norm": 0.7477750778198242,
      "learning_rate": 1.3146666666666668e-07,
      "logits/chosen": -2.7899832725524902,
      "logits/rejected": -2.3058724403381348,
      "logps/chosen": -152.28854370117188,
      "logps/rejected": -176.04583740234375,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.9756100177764893,
      "rewards/margins": 9.356061935424805,
      "rewards/rejected": -12.331671714782715,
      "step": 6515
    },
    {
      "epoch": 2.6064,
      "grad_norm": 0.1335993856191635,
      "learning_rate": 1.3133333333333332e-07,
      "logits/chosen": -2.9131288528442383,
      "logits/rejected": -2.6973018646240234,
      "logps/chosen": -89.81558227539062,
      "logps/rejected": -146.41554260253906,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4930845499038696,
      "rewards/margins": 7.8212385177612305,
      "rewards/rejected": -9.314323425292969,
      "step": 6516
    },
    {
      "epoch": 2.6068,
      "grad_norm": 0.15043899416923523,
      "learning_rate": 1.312e-07,
      "logits/chosen": -2.8718748092651367,
      "logits/rejected": -2.587919235229492,
      "logps/chosen": -80.50607299804688,
      "logps/rejected": -136.42327880859375,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6423885226249695,
      "rewards/margins": 8.021839141845703,
      "rewards/rejected": -8.664228439331055,
      "step": 6517
    },
    {
      "epoch": 2.6071999999999997,
      "grad_norm": 0.0030830935575067997,
      "learning_rate": 1.3106666666666665e-07,
      "logits/chosen": -2.2718310356140137,
      "logits/rejected": -1.3450020551681519,
      "logps/chosen": -114.56930541992188,
      "logps/rejected": -249.6014404296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4087814390659332,
      "rewards/margins": 15.557318687438965,
      "rewards/rejected": -15.148536682128906,
      "step": 6518
    },
    {
      "epoch": 2.6076,
      "grad_norm": 4.7067653213161975e-05,
      "learning_rate": 1.3093333333333334e-07,
      "logits/chosen": -2.441131591796875,
      "logits/rejected": -1.5460665225982666,
      "logps/chosen": -148.58612060546875,
      "logps/rejected": -247.1250457763672,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6007915735244751,
      "rewards/margins": 15.827040672302246,
      "rewards/rejected": -16.427831649780273,
      "step": 6519
    },
    {
      "epoch": 2.608,
      "grad_norm": 0.03651317581534386,
      "learning_rate": 1.308e-07,
      "logits/chosen": -2.9737462997436523,
      "logits/rejected": -2.4679081439971924,
      "logps/chosen": -62.281768798828125,
      "logps/rejected": -119.20186614990234,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2165725827217102,
      "rewards/margins": 8.444594383239746,
      "rewards/rejected": -8.66116714477539,
      "step": 6520
    },
    {
      "epoch": 2.6084,
      "grad_norm": 0.059619177132844925,
      "learning_rate": 1.3066666666666665e-07,
      "logits/chosen": -2.3355722427368164,
      "logits/rejected": -1.7921762466430664,
      "logps/chosen": -187.70657348632812,
      "logps/rejected": -184.0298309326172,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8755462765693665,
      "rewards/margins": 10.769603729248047,
      "rewards/rejected": -11.645150184631348,
      "step": 6521
    },
    {
      "epoch": 2.6088,
      "grad_norm": 4.033206939697266,
      "learning_rate": 1.3053333333333334e-07,
      "logits/chosen": -2.2884838581085205,
      "logits/rejected": -1.7812469005584717,
      "logps/chosen": -204.2781982421875,
      "logps/rejected": -228.11318969726562,
      "loss": 0.0134,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.449380874633789,
      "rewards/margins": 8.43890380859375,
      "rewards/rejected": -11.888284683227539,
      "step": 6522
    },
    {
      "epoch": 2.6092,
      "grad_norm": 0.9495583176612854,
      "learning_rate": 1.3039999999999998e-07,
      "logits/chosen": -2.5700020790100098,
      "logits/rejected": -2.57850980758667,
      "logps/chosen": -93.27330017089844,
      "logps/rejected": -197.494140625,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9891036748886108,
      "rewards/margins": 9.377620697021484,
      "rewards/rejected": -10.366724967956543,
      "step": 6523
    },
    {
      "epoch": 2.6096,
      "grad_norm": 0.04653206840157509,
      "learning_rate": 1.3026666666666667e-07,
      "logits/chosen": -2.550480604171753,
      "logits/rejected": -2.563131332397461,
      "logps/chosen": -114.9263687133789,
      "logps/rejected": -123.574462890625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.04017871618270874,
      "rewards/margins": 8.092998504638672,
      "rewards/rejected": -8.133177757263184,
      "step": 6524
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.00025248335441574454,
      "learning_rate": 1.301333333333333e-07,
      "logits/chosen": -2.5929412841796875,
      "logits/rejected": -2.033055305480957,
      "logps/chosen": -99.56526947021484,
      "logps/rejected": -270.300537109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.22698289155960083,
      "rewards/margins": 16.212566375732422,
      "rewards/rejected": -16.43954849243164,
      "step": 6525
    },
    {
      "epoch": 2.6104000000000003,
      "grad_norm": 0.00043239581282250583,
      "learning_rate": 1.3e-07,
      "logits/chosen": -2.288722515106201,
      "logits/rejected": -1.789919376373291,
      "logps/chosen": -134.73216247558594,
      "logps/rejected": -198.25051879882812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15283626317977905,
      "rewards/margins": 13.450428009033203,
      "rewards/rejected": -13.297592163085938,
      "step": 6526
    },
    {
      "epoch": 2.6108000000000002,
      "grad_norm": 2.163649797439575,
      "learning_rate": 1.2986666666666666e-07,
      "logits/chosen": -2.298403263092041,
      "logits/rejected": -2.0179877281188965,
      "logps/chosen": -147.3574676513672,
      "logps/rejected": -164.378173828125,
      "loss": 0.0127,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05174865573644638,
      "rewards/margins": 9.625548362731934,
      "rewards/rejected": -9.573799133300781,
      "step": 6527
    },
    {
      "epoch": 2.6112,
      "grad_norm": 0.003014134708791971,
      "learning_rate": 1.2973333333333333e-07,
      "logits/chosen": -2.4806482791900635,
      "logits/rejected": -1.5935977697372437,
      "logps/chosen": -94.06840515136719,
      "logps/rejected": -248.27853393554688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6733986139297485,
      "rewards/margins": 13.728862762451172,
      "rewards/rejected": -13.055465698242188,
      "step": 6528
    },
    {
      "epoch": 2.6116,
      "grad_norm": 1.2726248502731323,
      "learning_rate": 1.296e-07,
      "logits/chosen": -2.4629111289978027,
      "logits/rejected": -2.2813880443573,
      "logps/chosen": -113.81697082519531,
      "logps/rejected": -104.60797119140625,
      "loss": 0.0062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.3886547088623047,
      "rewards/margins": 5.218427658081055,
      "rewards/rejected": -7.607082366943359,
      "step": 6529
    },
    {
      "epoch": 2.612,
      "grad_norm": 0.04889257624745369,
      "learning_rate": 1.2946666666666666e-07,
      "logits/chosen": -2.6443493366241455,
      "logits/rejected": -2.346186637878418,
      "logps/chosen": -152.1512451171875,
      "logps/rejected": -169.165283203125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.966897964477539,
      "rewards/margins": 9.983896255493164,
      "rewards/rejected": -11.950794219970703,
      "step": 6530
    },
    {
      "epoch": 2.6124,
      "grad_norm": 0.0761229395866394,
      "learning_rate": 1.2933333333333333e-07,
      "logits/chosen": -2.728344440460205,
      "logits/rejected": -2.271742105484009,
      "logps/chosen": -91.50836181640625,
      "logps/rejected": -143.95980834960938,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.44082796573638916,
      "rewards/margins": 7.819601535797119,
      "rewards/rejected": -7.3787736892700195,
      "step": 6531
    },
    {
      "epoch": 2.6128,
      "grad_norm": 0.2016378492116928,
      "learning_rate": 1.292e-07,
      "logits/chosen": -2.9991836547851562,
      "logits/rejected": -2.6940999031066895,
      "logps/chosen": -94.27690124511719,
      "logps/rejected": -109.46826171875,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3086288571357727,
      "rewards/margins": 7.1941986083984375,
      "rewards/rejected": -6.8855695724487305,
      "step": 6532
    },
    {
      "epoch": 2.6132,
      "grad_norm": 0.10593302547931671,
      "learning_rate": 1.2906666666666666e-07,
      "logits/chosen": -2.842285394668579,
      "logits/rejected": -2.530468463897705,
      "logps/chosen": -46.70633316040039,
      "logps/rejected": -121.80097198486328,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3294802904129028,
      "rewards/margins": 9.858665466308594,
      "rewards/rejected": -8.52918529510498,
      "step": 6533
    },
    {
      "epoch": 2.6136,
      "grad_norm": 0.9318680763244629,
      "learning_rate": 1.2893333333333335e-07,
      "logits/chosen": -2.8873848915100098,
      "logits/rejected": -2.513068199157715,
      "logps/chosen": -92.12924194335938,
      "logps/rejected": -180.39910888671875,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.27795958518981934,
      "rewards/margins": 10.599125862121582,
      "rewards/rejected": -10.877086639404297,
      "step": 6534
    },
    {
      "epoch": 2.614,
      "grad_norm": 0.018359631299972534,
      "learning_rate": 1.288e-07,
      "logits/chosen": -2.6040220260620117,
      "logits/rejected": -1.9692379236221313,
      "logps/chosen": -97.17829895019531,
      "logps/rejected": -179.19912719726562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6714752316474915,
      "rewards/margins": 13.209985733032227,
      "rewards/rejected": -12.538511276245117,
      "step": 6535
    },
    {
      "epoch": 2.6144,
      "grad_norm": 0.037714362144470215,
      "learning_rate": 1.2866666666666668e-07,
      "logits/chosen": -2.9629454612731934,
      "logits/rejected": -2.2422308921813965,
      "logps/chosen": -69.1489486694336,
      "logps/rejected": -192.71759033203125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23273715376853943,
      "rewards/margins": 12.735214233398438,
      "rewards/rejected": -12.502476692199707,
      "step": 6536
    },
    {
      "epoch": 2.6148,
      "grad_norm": 0.4858030676841736,
      "learning_rate": 1.2853333333333332e-07,
      "logits/chosen": -2.4784646034240723,
      "logits/rejected": -1.8357990980148315,
      "logps/chosen": -173.83056640625,
      "logps/rejected": -141.32528686523438,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.1017422676086426,
      "rewards/margins": 6.939743995666504,
      "rewards/rejected": -9.041486740112305,
      "step": 6537
    },
    {
      "epoch": 2.6151999999999997,
      "grad_norm": 0.31820443272590637,
      "learning_rate": 1.2839999999999999e-07,
      "logits/chosen": -2.5339698791503906,
      "logits/rejected": -2.222590446472168,
      "logps/chosen": -127.86454772949219,
      "logps/rejected": -142.87847900390625,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2922935485839844,
      "rewards/margins": 8.051769256591797,
      "rewards/rejected": -9.344062805175781,
      "step": 6538
    },
    {
      "epoch": 2.6156,
      "grad_norm": 2.217205047607422,
      "learning_rate": 1.2826666666666665e-07,
      "logits/chosen": -2.457817554473877,
      "logits/rejected": -1.8450720310211182,
      "logps/chosen": -161.42269897460938,
      "logps/rejected": -156.64324951171875,
      "loss": 0.0094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.16217041015625,
      "rewards/margins": 7.036940574645996,
      "rewards/rejected": -9.199110984802246,
      "step": 6539
    },
    {
      "epoch": 2.616,
      "grad_norm": 0.0007885760278441012,
      "learning_rate": 1.2813333333333332e-07,
      "logits/chosen": -2.784188985824585,
      "logits/rejected": -2.297934055328369,
      "logps/chosen": -69.20569610595703,
      "logps/rejected": -171.20819091796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4017466306686401,
      "rewards/margins": 12.797748565673828,
      "rewards/rejected": -11.396001815795898,
      "step": 6540
    },
    {
      "epoch": 2.6164,
      "grad_norm": 0.013933521695435047,
      "learning_rate": 1.28e-07,
      "logits/chosen": -2.6443653106689453,
      "logits/rejected": -1.9948304891586304,
      "logps/chosen": -61.53044891357422,
      "logps/rejected": -164.383056640625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9175335168838501,
      "rewards/margins": 11.915451049804688,
      "rewards/rejected": -10.997918128967285,
      "step": 6541
    },
    {
      "epoch": 2.6168,
      "grad_norm": 0.0004444268997758627,
      "learning_rate": 1.2786666666666665e-07,
      "logits/chosen": -2.6311116218566895,
      "logits/rejected": -1.8129281997680664,
      "logps/chosen": -71.0989990234375,
      "logps/rejected": -206.80514526367188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.09388142824172974,
      "rewards/margins": 14.69749641418457,
      "rewards/rejected": -14.791378021240234,
      "step": 6542
    },
    {
      "epoch": 2.6172,
      "grad_norm": 5.738328763982281e-05,
      "learning_rate": 1.2773333333333334e-07,
      "logits/chosen": -2.5186924934387207,
      "logits/rejected": -1.6443123817443848,
      "logps/chosen": -99.29756164550781,
      "logps/rejected": -201.0025634765625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.187055230140686,
      "rewards/margins": 15.66672420501709,
      "rewards/rejected": -14.479669570922852,
      "step": 6543
    },
    {
      "epoch": 2.6176,
      "grad_norm": 0.0028408172074705362,
      "learning_rate": 1.2759999999999998e-07,
      "logits/chosen": -3.0318984985351562,
      "logits/rejected": -2.1957340240478516,
      "logps/chosen": -45.18055725097656,
      "logps/rejected": -183.07904052734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5170748233795166,
      "rewards/margins": 13.303861618041992,
      "rewards/rejected": -11.786787033081055,
      "step": 6544
    },
    {
      "epoch": 2.618,
      "grad_norm": 0.009049718268215656,
      "learning_rate": 1.2746666666666667e-07,
      "logits/chosen": -2.506937026977539,
      "logits/rejected": -1.9306498765945435,
      "logps/chosen": -100.22335815429688,
      "logps/rejected": -193.01248168945312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.268866777420044,
      "rewards/margins": 13.412372589111328,
      "rewards/rejected": -12.143506050109863,
      "step": 6545
    },
    {
      "epoch": 2.6184,
      "grad_norm": 0.027308519929647446,
      "learning_rate": 1.273333333333333e-07,
      "logits/chosen": -2.8674612045288086,
      "logits/rejected": -2.3970651626586914,
      "logps/chosen": -54.852622985839844,
      "logps/rejected": -169.11358642578125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8976414203643799,
      "rewards/margins": 12.780282974243164,
      "rewards/rejected": -11.882641792297363,
      "step": 6546
    },
    {
      "epoch": 2.6188000000000002,
      "grad_norm": 0.00011592287046369165,
      "learning_rate": 1.272e-07,
      "logits/chosen": -2.445113182067871,
      "logits/rejected": -1.9737582206726074,
      "logps/chosen": -62.17713165283203,
      "logps/rejected": -193.35736083984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.779085636138916,
      "rewards/margins": 14.774079322814941,
      "rewards/rejected": -12.994993209838867,
      "step": 6547
    },
    {
      "epoch": 2.6192,
      "grad_norm": 0.6325079202651978,
      "learning_rate": 1.2706666666666667e-07,
      "logits/chosen": -3.222167491912842,
      "logits/rejected": -2.9849135875701904,
      "logps/chosen": -106.72805786132812,
      "logps/rejected": -114.93098449707031,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8122814297676086,
      "rewards/margins": 5.836840629577637,
      "rewards/rejected": -6.6491217613220215,
      "step": 6548
    },
    {
      "epoch": 2.6196,
      "grad_norm": 0.8092501759529114,
      "learning_rate": 1.2693333333333333e-07,
      "logits/chosen": -2.559833526611328,
      "logits/rejected": -2.290313720703125,
      "logps/chosen": -72.88201141357422,
      "logps/rejected": -140.2308807373047,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40091589093208313,
      "rewards/margins": 9.958219528198242,
      "rewards/rejected": -9.557304382324219,
      "step": 6549
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.2778457999229431,
      "learning_rate": 1.268e-07,
      "logits/chosen": -2.9348530769348145,
      "logits/rejected": -2.6804699897766113,
      "logps/chosen": -68.91584777832031,
      "logps/rejected": -113.5845718383789,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8863321542739868,
      "rewards/margins": 6.71455192565918,
      "rewards/rejected": -7.600883960723877,
      "step": 6550
    },
    {
      "epoch": 2.6204,
      "grad_norm": 0.039664942771196365,
      "learning_rate": 1.2666666666666666e-07,
      "logits/chosen": -3.136460065841675,
      "logits/rejected": -2.5755772590637207,
      "logps/chosen": -63.08984375,
      "logps/rejected": -162.46217346191406,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7477178573608398,
      "rewards/margins": 11.736220359802246,
      "rewards/rejected": -10.988502502441406,
      "step": 6551
    },
    {
      "epoch": 2.6208,
      "grad_norm": 0.0011740510817617178,
      "learning_rate": 1.2653333333333333e-07,
      "logits/chosen": -2.1677470207214355,
      "logits/rejected": -1.3983526229858398,
      "logps/chosen": -114.44866943359375,
      "logps/rejected": -223.02342224121094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7349128723144531,
      "rewards/margins": 13.105307579040527,
      "rewards/rejected": -11.370394706726074,
      "step": 6552
    },
    {
      "epoch": 2.6212,
      "grad_norm": 5.800498962402344,
      "learning_rate": 1.264e-07,
      "logits/chosen": -2.838987350463867,
      "logits/rejected": -2.1627449989318848,
      "logps/chosen": -96.1957778930664,
      "logps/rejected": -169.25257873535156,
      "loss": 0.0148,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.832344889640808,
      "rewards/margins": 9.596782684326172,
      "rewards/rejected": -11.429126739501953,
      "step": 6553
    },
    {
      "epoch": 2.6216,
      "grad_norm": 0.5578923225402832,
      "learning_rate": 1.2626666666666666e-07,
      "logits/chosen": -2.671342134475708,
      "logits/rejected": -2.282998561859131,
      "logps/chosen": -125.7935791015625,
      "logps/rejected": -160.65292358398438,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6744598150253296,
      "rewards/margins": 9.679027557373047,
      "rewards/rejected": -10.353487968444824,
      "step": 6554
    },
    {
      "epoch": 2.622,
      "grad_norm": 0.2858436703681946,
      "learning_rate": 1.2613333333333332e-07,
      "logits/chosen": -2.8597912788391113,
      "logits/rejected": -2.6865007877349854,
      "logps/chosen": -118.61817932128906,
      "logps/rejected": -136.9622802734375,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0147860050201416,
      "rewards/margins": 8.639076232910156,
      "rewards/rejected": -9.653861999511719,
      "step": 6555
    },
    {
      "epoch": 2.6224,
      "grad_norm": 0.0039102607406675816,
      "learning_rate": 1.26e-07,
      "logits/chosen": -2.867992401123047,
      "logits/rejected": -2.516545057296753,
      "logps/chosen": -64.89752960205078,
      "logps/rejected": -138.5576934814453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.576440453529358,
      "rewards/margins": 10.949853897094727,
      "rewards/rejected": -9.373414039611816,
      "step": 6556
    },
    {
      "epoch": 2.6228,
      "grad_norm": 0.4279678761959076,
      "learning_rate": 1.2586666666666666e-07,
      "logits/chosen": -2.6104109287261963,
      "logits/rejected": -2.448472023010254,
      "logps/chosen": -75.11602020263672,
      "logps/rejected": -104.15753936767578,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6940819025039673,
      "rewards/margins": 6.337786674499512,
      "rewards/rejected": -7.031868934631348,
      "step": 6557
    },
    {
      "epoch": 2.6231999999999998,
      "grad_norm": 0.25188499689102173,
      "learning_rate": 1.2573333333333332e-07,
      "logits/chosen": -2.8987998962402344,
      "logits/rejected": -2.643239736557007,
      "logps/chosen": -63.401832580566406,
      "logps/rejected": -127.69078826904297,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.01694774627685547,
      "rewards/margins": 7.449518203735352,
      "rewards/rejected": -7.466465950012207,
      "step": 6558
    },
    {
      "epoch": 2.6236,
      "grad_norm": 0.010497057810425758,
      "learning_rate": 1.2559999999999999e-07,
      "logits/chosen": -2.5749778747558594,
      "logits/rejected": -2.1300196647644043,
      "logps/chosen": -53.14155578613281,
      "logps/rejected": -218.756103515625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.29684978723526,
      "rewards/margins": 15.445422172546387,
      "rewards/rejected": -15.14857292175293,
      "step": 6559
    },
    {
      "epoch": 2.624,
      "grad_norm": 0.0005331027787178755,
      "learning_rate": 1.2546666666666665e-07,
      "logits/chosen": -2.513627052307129,
      "logits/rejected": -2.186964273452759,
      "logps/chosen": -90.57620239257812,
      "logps/rejected": -279.6055908203125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.263605535030365,
      "rewards/margins": 13.644039154052734,
      "rewards/rejected": -13.907644271850586,
      "step": 6560
    },
    {
      "epoch": 2.6244,
      "grad_norm": 3.3538997173309326,
      "learning_rate": 1.2533333333333332e-07,
      "logits/chosen": -2.7040348052978516,
      "logits/rejected": -2.3368115425109863,
      "logps/chosen": -81.77970123291016,
      "logps/rejected": -159.02252197265625,
      "loss": 0.0134,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.473702609539032,
      "rewards/margins": 11.535165786743164,
      "rewards/rejected": -11.061463356018066,
      "step": 6561
    },
    {
      "epoch": 2.6248,
      "grad_norm": 0.22969670593738556,
      "learning_rate": 1.252e-07,
      "logits/chosen": -3.2175228595733643,
      "logits/rejected": -2.730825424194336,
      "logps/chosen": -33.86839294433594,
      "logps/rejected": -92.87562561035156,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3705085813999176,
      "rewards/margins": 6.458881378173828,
      "rewards/rejected": -6.088373184204102,
      "step": 6562
    },
    {
      "epoch": 2.6252,
      "grad_norm": 0.0006052358075976372,
      "learning_rate": 1.2506666666666665e-07,
      "logits/chosen": -2.8162035942077637,
      "logits/rejected": -2.187329053878784,
      "logps/chosen": -54.61452102661133,
      "logps/rejected": -222.64044189453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2752246856689453,
      "rewards/margins": 15.579018592834473,
      "rewards/rejected": -15.854243278503418,
      "step": 6563
    },
    {
      "epoch": 2.6256,
      "grad_norm": 0.01525130495429039,
      "learning_rate": 1.2493333333333331e-07,
      "logits/chosen": -2.755547046661377,
      "logits/rejected": -2.600503921508789,
      "logps/chosen": -81.08610534667969,
      "logps/rejected": -127.26567077636719,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41103899478912354,
      "rewards/margins": 9.368257522583008,
      "rewards/rejected": -8.957218170166016,
      "step": 6564
    },
    {
      "epoch": 2.626,
      "grad_norm": 0.003095403779298067,
      "learning_rate": 1.2479999999999998e-07,
      "logits/chosen": -2.532285690307617,
      "logits/rejected": -2.1053624153137207,
      "logps/chosen": -72.19650268554688,
      "logps/rejected": -175.49539184570312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1853538751602173,
      "rewards/margins": 12.950094223022461,
      "rewards/rejected": -11.764739990234375,
      "step": 6565
    },
    {
      "epoch": 2.6264,
      "grad_norm": 0.18474110960960388,
      "learning_rate": 1.2466666666666664e-07,
      "logits/chosen": -2.211777687072754,
      "logits/rejected": -1.9128711223602295,
      "logps/chosen": -142.5503692626953,
      "logps/rejected": -152.1307830810547,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.06220090389251709,
      "rewards/margins": 8.593720436096191,
      "rewards/rejected": -8.65592098236084,
      "step": 6566
    },
    {
      "epoch": 2.6268000000000002,
      "grad_norm": 0.2867266833782196,
      "learning_rate": 1.2453333333333334e-07,
      "logits/chosen": -2.9302749633789062,
      "logits/rejected": -2.550938606262207,
      "logps/chosen": -110.46068572998047,
      "logps/rejected": -130.37741088867188,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2302066683769226,
      "rewards/margins": 6.7883172035217285,
      "rewards/rejected": -6.558110237121582,
      "step": 6567
    },
    {
      "epoch": 2.6272,
      "grad_norm": 0.07248680293560028,
      "learning_rate": 1.244e-07,
      "logits/chosen": -2.5751328468322754,
      "logits/rejected": -2.2862634658813477,
      "logps/chosen": -157.38299560546875,
      "logps/rejected": -153.18894958496094,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0782113075256348,
      "rewards/margins": 8.739542007446289,
      "rewards/rejected": -10.817752838134766,
      "step": 6568
    },
    {
      "epoch": 2.6276,
      "grad_norm": 0.022598544135689735,
      "learning_rate": 1.2426666666666667e-07,
      "logits/chosen": -2.6060073375701904,
      "logits/rejected": -2.4808034896850586,
      "logps/chosen": -76.44099426269531,
      "logps/rejected": -138.78985595703125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.30095311999320984,
      "rewards/margins": 9.28823471069336,
      "rewards/rejected": -9.589188575744629,
      "step": 6569
    },
    {
      "epoch": 2.628,
      "grad_norm": 0.03205377981066704,
      "learning_rate": 1.2413333333333333e-07,
      "logits/chosen": -2.0083327293395996,
      "logits/rejected": -1.866403579711914,
      "logps/chosen": -134.23175048828125,
      "logps/rejected": -150.9691162109375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6015390157699585,
      "rewards/margins": 8.573406219482422,
      "rewards/rejected": -10.174945831298828,
      "step": 6570
    },
    {
      "epoch": 2.6284,
      "grad_norm": 3.4432430267333984,
      "learning_rate": 1.24e-07,
      "logits/chosen": -2.702758312225342,
      "logits/rejected": -2.4118504524230957,
      "logps/chosen": -130.6168212890625,
      "logps/rejected": -145.77333068847656,
      "loss": 0.0202,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.349968433380127,
      "rewards/margins": 6.535937786102295,
      "rewards/rejected": -8.885906219482422,
      "step": 6571
    },
    {
      "epoch": 2.6288,
      "grad_norm": 0.002489935141056776,
      "learning_rate": 1.2386666666666666e-07,
      "logits/chosen": -2.7696585655212402,
      "logits/rejected": -2.1827902793884277,
      "logps/chosen": -93.58234405517578,
      "logps/rejected": -173.83038330078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7487354278564453,
      "rewards/margins": 13.747869491577148,
      "rewards/rejected": -11.999134063720703,
      "step": 6572
    },
    {
      "epoch": 2.6292,
      "grad_norm": 0.6088117361068726,
      "learning_rate": 1.2373333333333333e-07,
      "logits/chosen": -2.5348734855651855,
      "logits/rejected": -2.0259103775024414,
      "logps/chosen": -203.78628540039062,
      "logps/rejected": -150.30648803710938,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.243924617767334,
      "rewards/margins": 6.579680442810059,
      "rewards/rejected": -7.823605537414551,
      "step": 6573
    },
    {
      "epoch": 2.6296,
      "grad_norm": 0.10272123664617538,
      "learning_rate": 1.236e-07,
      "logits/chosen": -2.5577492713928223,
      "logits/rejected": -2.1420018672943115,
      "logps/chosen": -96.33126831054688,
      "logps/rejected": -211.56468200683594,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7798891067504883,
      "rewards/margins": 11.579206466674805,
      "rewards/rejected": -12.359095573425293,
      "step": 6574
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.00696237338706851,
      "learning_rate": 1.2346666666666666e-07,
      "logits/chosen": -2.706260919570923,
      "logits/rejected": -2.275360584259033,
      "logps/chosen": -38.78963851928711,
      "logps/rejected": -165.42791748046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0877999067306519,
      "rewards/margins": 11.135780334472656,
      "rewards/rejected": -10.047981262207031,
      "step": 6575
    },
    {
      "epoch": 2.6304,
      "grad_norm": 0.12110192328691483,
      "learning_rate": 1.2333333333333333e-07,
      "logits/chosen": -2.6905429363250732,
      "logits/rejected": -2.478851556777954,
      "logps/chosen": -66.35968017578125,
      "logps/rejected": -147.02859497070312,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6317703723907471,
      "rewards/margins": 10.691475868225098,
      "rewards/rejected": -11.323246002197266,
      "step": 6576
    },
    {
      "epoch": 2.6308,
      "grad_norm": 0.12334540486335754,
      "learning_rate": 1.232e-07,
      "logits/chosen": -2.7558302879333496,
      "logits/rejected": -2.6605679988861084,
      "logps/chosen": -103.85377502441406,
      "logps/rejected": -101.83563232421875,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21681711077690125,
      "rewards/margins": 7.564194679260254,
      "rewards/rejected": -7.347377777099609,
      "step": 6577
    },
    {
      "epoch": 2.6311999999999998,
      "grad_norm": 0.020915942266583443,
      "learning_rate": 1.2306666666666666e-07,
      "logits/chosen": -2.559318780899048,
      "logits/rejected": -2.177196979522705,
      "logps/chosen": -157.20285034179688,
      "logps/rejected": -135.57611083984375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.064510703086853,
      "rewards/margins": 10.56330680847168,
      "rewards/rejected": -9.498795509338379,
      "step": 6578
    },
    {
      "epoch": 2.6316,
      "grad_norm": 0.1274762600660324,
      "learning_rate": 1.2293333333333332e-07,
      "logits/chosen": -2.8133530616760254,
      "logits/rejected": -2.5224952697753906,
      "logps/chosen": -61.47559356689453,
      "logps/rejected": -127.60352325439453,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17284315824508667,
      "rewards/margins": 9.430593490600586,
      "rewards/rejected": -9.257750511169434,
      "step": 6579
    },
    {
      "epoch": 2.632,
      "grad_norm": 11.006075859069824,
      "learning_rate": 1.228e-07,
      "logits/chosen": -2.2737202644348145,
      "logits/rejected": -1.8505892753601074,
      "logps/chosen": -200.46728515625,
      "logps/rejected": -146.69808959960938,
      "loss": 0.0324,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.775092601776123,
      "rewards/margins": 5.524515151977539,
      "rewards/rejected": -8.29960823059082,
      "step": 6580
    },
    {
      "epoch": 2.6324,
      "grad_norm": 1.510488748550415,
      "learning_rate": 1.2266666666666665e-07,
      "logits/chosen": -3.0130374431610107,
      "logits/rejected": -2.600170850753784,
      "logps/chosen": -73.59590148925781,
      "logps/rejected": -103.85884094238281,
      "loss": 0.009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4349985122680664,
      "rewards/margins": 6.950740814208984,
      "rewards/rejected": -7.385739326477051,
      "step": 6581
    },
    {
      "epoch": 2.6328,
      "grad_norm": 0.0009898899588733912,
      "learning_rate": 1.2253333333333332e-07,
      "logits/chosen": -2.4506845474243164,
      "logits/rejected": -1.5908361673355103,
      "logps/chosen": -136.82012939453125,
      "logps/rejected": -211.71905517578125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3911689519882202,
      "rewards/margins": 14.537601470947266,
      "rewards/rejected": -14.146432876586914,
      "step": 6582
    },
    {
      "epoch": 2.6332,
      "grad_norm": 0.011025715619325638,
      "learning_rate": 1.2239999999999998e-07,
      "logits/chosen": -2.399407386779785,
      "logits/rejected": -1.9013458490371704,
      "logps/chosen": -111.63052368164062,
      "logps/rejected": -140.1626434326172,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7199127674102783,
      "rewards/margins": 11.054031372070312,
      "rewards/rejected": -9.334117889404297,
      "step": 6583
    },
    {
      "epoch": 2.6336,
      "grad_norm": 2.0294637579354458e-05,
      "learning_rate": 1.2226666666666665e-07,
      "logits/chosen": -2.450010299682617,
      "logits/rejected": -1.6102375984191895,
      "logps/chosen": -77.83757019042969,
      "logps/rejected": -202.6570587158203,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.489962339401245,
      "rewards/margins": 16.862682342529297,
      "rewards/rejected": -14.372718811035156,
      "step": 6584
    },
    {
      "epoch": 2.634,
      "grad_norm": 0.028147412464022636,
      "learning_rate": 1.2213333333333332e-07,
      "logits/chosen": -2.375767230987549,
      "logits/rejected": -2.1154396533966064,
      "logps/chosen": -50.825531005859375,
      "logps/rejected": -117.0820541381836,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1724622249603271,
      "rewards/margins": 9.548458099365234,
      "rewards/rejected": -8.375995635986328,
      "step": 6585
    },
    {
      "epoch": 2.6344,
      "grad_norm": 0.01311304047703743,
      "learning_rate": 1.2199999999999998e-07,
      "logits/chosen": -2.6063759326934814,
      "logits/rejected": -1.8300881385803223,
      "logps/chosen": -70.89862060546875,
      "logps/rejected": -199.40179443359375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0434911251068115,
      "rewards/margins": 12.903609275817871,
      "rewards/rejected": -10.860118865966797,
      "step": 6586
    },
    {
      "epoch": 2.6348000000000003,
      "grad_norm": 2.9370639324188232,
      "learning_rate": 1.2186666666666665e-07,
      "logits/chosen": -2.3346261978149414,
      "logits/rejected": -2.098170757293701,
      "logps/chosen": -175.87777709960938,
      "logps/rejected": -159.78387451171875,
      "loss": 0.0122,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.806692361831665,
      "rewards/margins": 5.4510722160339355,
      "rewards/rejected": -9.25776481628418,
      "step": 6587
    },
    {
      "epoch": 2.6352,
      "grad_norm": 0.18160554766654968,
      "learning_rate": 1.2173333333333334e-07,
      "logits/chosen": -2.8370537757873535,
      "logits/rejected": -2.5913262367248535,
      "logps/chosen": -49.88005447387695,
      "logps/rejected": -133.1351776123047,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4168619215488434,
      "rewards/margins": 8.725831031799316,
      "rewards/rejected": -9.142692565917969,
      "step": 6588
    },
    {
      "epoch": 2.6356,
      "grad_norm": 4.9273271560668945,
      "learning_rate": 1.216e-07,
      "logits/chosen": -2.8781986236572266,
      "logits/rejected": -2.5539097785949707,
      "logps/chosen": -56.780677795410156,
      "logps/rejected": -107.95164489746094,
      "loss": 0.0292,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8901883959770203,
      "rewards/margins": 6.796463489532471,
      "rewards/rejected": -5.906275272369385,
      "step": 6589
    },
    {
      "epoch": 2.636,
      "grad_norm": 0.31802842020988464,
      "learning_rate": 1.2146666666666667e-07,
      "logits/chosen": -2.7486824989318848,
      "logits/rejected": -2.1743226051330566,
      "logps/chosen": -127.4686508178711,
      "logps/rejected": -171.12599182128906,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.352546453475952,
      "rewards/margins": 8.607086181640625,
      "rewards/rejected": -10.959632873535156,
      "step": 6590
    },
    {
      "epoch": 2.6364,
      "grad_norm": 0.039681144058704376,
      "learning_rate": 1.2133333333333333e-07,
      "logits/chosen": -2.709092140197754,
      "logits/rejected": -2.562497138977051,
      "logps/chosen": -107.96812438964844,
      "logps/rejected": -164.6893310546875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9088706374168396,
      "rewards/margins": 11.023416519165039,
      "rewards/rejected": -11.932287216186523,
      "step": 6591
    },
    {
      "epoch": 2.6368,
      "grad_norm": 0.34855344891548157,
      "learning_rate": 1.212e-07,
      "logits/chosen": -2.703805446624756,
      "logits/rejected": -2.5372314453125,
      "logps/chosen": -119.439453125,
      "logps/rejected": -151.1085662841797,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2287864685058594,
      "rewards/margins": 9.537614822387695,
      "rewards/rejected": -10.766401290893555,
      "step": 6592
    },
    {
      "epoch": 2.6372,
      "grad_norm": 0.03306771442294121,
      "learning_rate": 1.2106666666666667e-07,
      "logits/chosen": -2.620302200317383,
      "logits/rejected": -2.0784623622894287,
      "logps/chosen": -110.13027954101562,
      "logps/rejected": -185.0703125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9149106740951538,
      "rewards/margins": 8.839008331298828,
      "rewards/rejected": -9.753918647766113,
      "step": 6593
    },
    {
      "epoch": 2.6376,
      "grad_norm": 8.28467082977295,
      "learning_rate": 1.2093333333333333e-07,
      "logits/chosen": -2.778505563735962,
      "logits/rejected": -2.484025478363037,
      "logps/chosen": -81.15325927734375,
      "logps/rejected": -140.53030395507812,
      "loss": 0.0456,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2276825904846191,
      "rewards/margins": 8.36042308807373,
      "rewards/rejected": -9.588106155395508,
      "step": 6594
    },
    {
      "epoch": 2.638,
      "grad_norm": 0.0069885835982859135,
      "learning_rate": 1.208e-07,
      "logits/chosen": -2.2014923095703125,
      "logits/rejected": -2.015471935272217,
      "logps/chosen": -200.28477478027344,
      "logps/rejected": -292.65887451171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2568691372871399,
      "rewards/margins": 10.853414535522461,
      "rewards/rejected": -10.596545219421387,
      "step": 6595
    },
    {
      "epoch": 2.6384,
      "grad_norm": 0.005618324037641287,
      "learning_rate": 1.2066666666666666e-07,
      "logits/chosen": -2.253324031829834,
      "logits/rejected": -1.534593939781189,
      "logps/chosen": -128.35360717773438,
      "logps/rejected": -177.89071655273438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.199007049202919,
      "rewards/margins": 12.061318397521973,
      "rewards/rejected": -12.26032543182373,
      "step": 6596
    },
    {
      "epoch": 2.6388,
      "grad_norm": 1.1580440998077393,
      "learning_rate": 1.2053333333333333e-07,
      "logits/chosen": -2.9636964797973633,
      "logits/rejected": -2.642058849334717,
      "logps/chosen": -59.71293640136719,
      "logps/rejected": -157.74154663085938,
      "loss": 0.0059,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11993350088596344,
      "rewards/margins": 9.436453819274902,
      "rewards/rejected": -9.316520690917969,
      "step": 6597
    },
    {
      "epoch": 2.6391999999999998,
      "grad_norm": 0.06805630773305893,
      "learning_rate": 1.204e-07,
      "logits/chosen": -2.8820478916168213,
      "logits/rejected": -2.6135387420654297,
      "logps/chosen": -116.22262573242188,
      "logps/rejected": -153.696044921875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3022186756134033,
      "rewards/margins": 10.181236267089844,
      "rewards/rejected": -9.879016876220703,
      "step": 6598
    },
    {
      "epoch": 2.6395999999999997,
      "grad_norm": 0.0001195570221170783,
      "learning_rate": 1.2026666666666666e-07,
      "logits/chosen": -2.938399314880371,
      "logits/rejected": -2.304816246032715,
      "logps/chosen": -82.15145874023438,
      "logps/rejected": -241.39566040039062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39067384600639343,
      "rewards/margins": 17.5106143951416,
      "rewards/rejected": -17.11993980407715,
      "step": 6599
    },
    {
      "epoch": 2.64,
      "grad_norm": 1.5797230005264282,
      "learning_rate": 1.2013333333333332e-07,
      "logits/chosen": -2.9179434776306152,
      "logits/rejected": -2.392009735107422,
      "logps/chosen": -112.56996154785156,
      "logps/rejected": -184.97454833984375,
      "loss": 0.0078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.874476432800293,
      "rewards/margins": 10.580668449401855,
      "rewards/rejected": -12.455144882202148,
      "step": 6600
    },
    {
      "epoch": 2.6404,
      "grad_norm": 0.008280274458229542,
      "learning_rate": 1.2e-07,
      "logits/chosen": -2.8359487056732178,
      "logits/rejected": -2.530956983566284,
      "logps/chosen": -97.85829162597656,
      "logps/rejected": -152.18563842773438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4684906005859375,
      "rewards/margins": 10.580108642578125,
      "rewards/rejected": -9.111618041992188,
      "step": 6601
    },
    {
      "epoch": 2.6408,
      "grad_norm": 1.019161581993103,
      "learning_rate": 1.1986666666666665e-07,
      "logits/chosen": -2.114961862564087,
      "logits/rejected": -1.3204511404037476,
      "logps/chosen": -199.1548614501953,
      "logps/rejected": -180.8130645751953,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.6112968921661377,
      "rewards/margins": 9.216219902038574,
      "rewards/rejected": -12.827516555786133,
      "step": 6602
    },
    {
      "epoch": 2.6412,
      "grad_norm": 0.00027296628104522824,
      "learning_rate": 1.1973333333333332e-07,
      "logits/chosen": -2.611276626586914,
      "logits/rejected": -2.2789926528930664,
      "logps/chosen": -68.91378021240234,
      "logps/rejected": -216.2552947998047,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8880311250686646,
      "rewards/margins": 13.912384033203125,
      "rewards/rejected": -15.8004150390625,
      "step": 6603
    },
    {
      "epoch": 2.6416,
      "grad_norm": 0.03500334173440933,
      "learning_rate": 1.1959999999999999e-07,
      "logits/chosen": -2.6181511878967285,
      "logits/rejected": -2.098470449447632,
      "logps/chosen": -68.46222686767578,
      "logps/rejected": -126.70492553710938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6977196931838989,
      "rewards/margins": 8.910135269165039,
      "rewards/rejected": -8.212414741516113,
      "step": 6604
    },
    {
      "epoch": 2.642,
      "grad_norm": 0.0674799233675003,
      "learning_rate": 1.1946666666666665e-07,
      "logits/chosen": -2.4346299171447754,
      "logits/rejected": -1.895359992980957,
      "logps/chosen": -86.91923522949219,
      "logps/rejected": -167.4004669189453,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3475503921508789,
      "rewards/margins": 9.560892105102539,
      "rewards/rejected": -9.908443450927734,
      "step": 6605
    },
    {
      "epoch": 2.6424,
      "grad_norm": 0.025624295696616173,
      "learning_rate": 1.1933333333333332e-07,
      "logits/chosen": -2.6860344409942627,
      "logits/rejected": -2.2223401069641113,
      "logps/chosen": -59.15456771850586,
      "logps/rejected": -146.39903259277344,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.29472142457962036,
      "rewards/margins": 9.764707565307617,
      "rewards/rejected": -9.469985961914062,
      "step": 6606
    },
    {
      "epoch": 2.6428000000000003,
      "grad_norm": 0.07627572119235992,
      "learning_rate": 1.192e-07,
      "logits/chosen": -2.7375521659851074,
      "logits/rejected": -1.9130257368087769,
      "logps/chosen": -86.52774810791016,
      "logps/rejected": -153.25625610351562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1983947902917862,
      "rewards/margins": 10.099873542785645,
      "rewards/rejected": -9.901477813720703,
      "step": 6607
    },
    {
      "epoch": 2.6432,
      "grad_norm": 0.00034832596429623663,
      "learning_rate": 1.1906666666666666e-07,
      "logits/chosen": -2.2612335681915283,
      "logits/rejected": -1.6496635675430298,
      "logps/chosen": -123.30267333984375,
      "logps/rejected": -213.15576171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08780288696289062,
      "rewards/margins": 13.699039459228516,
      "rewards/rejected": -13.611236572265625,
      "step": 6608
    },
    {
      "epoch": 2.6436,
      "grad_norm": 0.0007139506051316857,
      "learning_rate": 1.1893333333333333e-07,
      "logits/chosen": -2.123410224914551,
      "logits/rejected": -1.1320459842681885,
      "logps/chosen": -205.58958435058594,
      "logps/rejected": -207.90750122070312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.17676925659179688,
      "rewards/margins": 14.328176498413086,
      "rewards/rejected": -14.504945755004883,
      "step": 6609
    },
    {
      "epoch": 2.644,
      "grad_norm": 0.20376960933208466,
      "learning_rate": 1.1879999999999999e-07,
      "logits/chosen": -2.598867893218994,
      "logits/rejected": -2.2363715171813965,
      "logps/chosen": -110.72509765625,
      "logps/rejected": -170.209716796875,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5049422979354858,
      "rewards/margins": 11.212493896484375,
      "rewards/rejected": -10.707551956176758,
      "step": 6610
    },
    {
      "epoch": 2.6444,
      "grad_norm": 0.00026086586876772344,
      "learning_rate": 1.1866666666666667e-07,
      "logits/chosen": -2.408966302871704,
      "logits/rejected": -2.0230283737182617,
      "logps/chosen": -108.6129379272461,
      "logps/rejected": -295.5919189453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.49867767095565796,
      "rewards/margins": 16.595706939697266,
      "rewards/rejected": -17.094385147094727,
      "step": 6611
    },
    {
      "epoch": 2.6448,
      "grad_norm": 0.0012319734087213874,
      "learning_rate": 1.1853333333333334e-07,
      "logits/chosen": -2.3297626972198486,
      "logits/rejected": -1.5329654216766357,
      "logps/chosen": -167.56564331054688,
      "logps/rejected": -167.9569854736328,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.199129581451416,
      "rewards/margins": 12.382682800292969,
      "rewards/rejected": -10.183553695678711,
      "step": 6612
    },
    {
      "epoch": 2.6452,
      "grad_norm": 0.0023217699490487576,
      "learning_rate": 1.184e-07,
      "logits/chosen": -2.159921884536743,
      "logits/rejected": -1.5795680284500122,
      "logps/chosen": -128.21029663085938,
      "logps/rejected": -206.48114013671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5627020001411438,
      "rewards/margins": 12.283060073852539,
      "rewards/rejected": -12.845762252807617,
      "step": 6613
    },
    {
      "epoch": 2.6456,
      "grad_norm": 0.0007139668450690806,
      "learning_rate": 1.1826666666666667e-07,
      "logits/chosen": -2.2392725944519043,
      "logits/rejected": -1.559016466140747,
      "logps/chosen": -149.0695343017578,
      "logps/rejected": -237.19366455078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0864940881729126,
      "rewards/margins": 14.410937309265137,
      "rewards/rejected": -13.324443817138672,
      "step": 6614
    },
    {
      "epoch": 2.646,
      "grad_norm": 0.04864043369889259,
      "learning_rate": 1.1813333333333333e-07,
      "logits/chosen": -2.5100231170654297,
      "logits/rejected": -2.086679220199585,
      "logps/chosen": -126.76588439941406,
      "logps/rejected": -173.59620666503906,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0205268859863281,
      "rewards/margins": 10.508854866027832,
      "rewards/rejected": -11.52938175201416,
      "step": 6615
    },
    {
      "epoch": 2.6464,
      "grad_norm": 0.016377126798033714,
      "learning_rate": 1.1799999999999998e-07,
      "logits/chosen": -2.401139736175537,
      "logits/rejected": -1.7293195724487305,
      "logps/chosen": -87.76140594482422,
      "logps/rejected": -180.459228515625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.228029727935791,
      "rewards/margins": 11.450448989868164,
      "rewards/rejected": -10.222418785095215,
      "step": 6616
    },
    {
      "epoch": 2.6468,
      "grad_norm": 0.013443471863865852,
      "learning_rate": 1.1786666666666665e-07,
      "logits/chosen": -2.96988844871521,
      "logits/rejected": -2.6074090003967285,
      "logps/chosen": -154.9556884765625,
      "logps/rejected": -176.93167114257812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2887253165245056,
      "rewards/margins": 10.907217979431152,
      "rewards/rejected": -11.195943832397461,
      "step": 6617
    },
    {
      "epoch": 2.6471999999999998,
      "grad_norm": 0.00921678077429533,
      "learning_rate": 1.1773333333333333e-07,
      "logits/chosen": -2.467306613922119,
      "logits/rejected": -2.2788820266723633,
      "logps/chosen": -108.82186889648438,
      "logps/rejected": -200.25648498535156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5645771026611328,
      "rewards/margins": 12.87765121459961,
      "rewards/rejected": -13.442228317260742,
      "step": 6618
    },
    {
      "epoch": 2.6475999999999997,
      "grad_norm": 0.000600663770455867,
      "learning_rate": 1.176e-07,
      "logits/chosen": -2.5196361541748047,
      "logits/rejected": -2.2024784088134766,
      "logps/chosen": -142.30380249023438,
      "logps/rejected": -247.9287567138672,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41081082820892334,
      "rewards/margins": 13.29257583618164,
      "rewards/rejected": -12.88176441192627,
      "step": 6619
    },
    {
      "epoch": 2.648,
      "grad_norm": 0.011246878653764725,
      "learning_rate": 1.1746666666666666e-07,
      "logits/chosen": -2.7703027725219727,
      "logits/rejected": -2.1988682746887207,
      "logps/chosen": -87.44731903076172,
      "logps/rejected": -199.72406005859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6022915244102478,
      "rewards/margins": 13.842504501342773,
      "rewards/rejected": -13.240213394165039,
      "step": 6620
    },
    {
      "epoch": 2.6484,
      "grad_norm": 0.0005659242742694914,
      "learning_rate": 1.1733333333333333e-07,
      "logits/chosen": -2.46509051322937,
      "logits/rejected": -2.2575325965881348,
      "logps/chosen": -43.192893981933594,
      "logps/rejected": -186.16241455078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.455037236213684,
      "rewards/margins": 13.422264099121094,
      "rewards/rejected": -11.967226028442383,
      "step": 6621
    },
    {
      "epoch": 2.6488,
      "grad_norm": 0.013342473655939102,
      "learning_rate": 1.1719999999999999e-07,
      "logits/chosen": -2.240288496017456,
      "logits/rejected": -1.4341628551483154,
      "logps/chosen": -140.45364379882812,
      "logps/rejected": -211.18267822265625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.587231457233429,
      "rewards/margins": 11.857549667358398,
      "rewards/rejected": -12.444781303405762,
      "step": 6622
    },
    {
      "epoch": 2.6492,
      "grad_norm": 0.06036430597305298,
      "learning_rate": 1.1706666666666666e-07,
      "logits/chosen": -2.6051316261291504,
      "logits/rejected": -2.062682867050171,
      "logps/chosen": -124.44255065917969,
      "logps/rejected": -173.13670349121094,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4806616008281708,
      "rewards/margins": 13.06185245513916,
      "rewards/rejected": -12.581191062927246,
      "step": 6623
    },
    {
      "epoch": 2.6496,
      "grad_norm": 0.029438814148306847,
      "learning_rate": 1.1693333333333333e-07,
      "logits/chosen": -2.7910633087158203,
      "logits/rejected": -2.5289528369903564,
      "logps/chosen": -70.08042907714844,
      "logps/rejected": -131.33197021484375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3426494598388672,
      "rewards/margins": 10.358345031738281,
      "rewards/rejected": -9.015695571899414,
      "step": 6624
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.03687531128525734,
      "learning_rate": 1.168e-07,
      "logits/chosen": -2.775625705718994,
      "logits/rejected": -2.415369749069214,
      "logps/chosen": -68.66368103027344,
      "logps/rejected": -132.07418823242188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3923841714859009,
      "rewards/margins": 10.31246566772461,
      "rewards/rejected": -9.920082092285156,
      "step": 6625
    },
    {
      "epoch": 2.6504,
      "grad_norm": 0.10697916150093079,
      "learning_rate": 1.1666666666666667e-07,
      "logits/chosen": -2.539484977722168,
      "logits/rejected": -2.125720500946045,
      "logps/chosen": -110.00519561767578,
      "logps/rejected": -134.77798461914062,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.30131208896636963,
      "rewards/margins": 8.042176246643066,
      "rewards/rejected": -7.740863800048828,
      "step": 6626
    },
    {
      "epoch": 2.6508000000000003,
      "grad_norm": 0.3161435127258301,
      "learning_rate": 1.1653333333333333e-07,
      "logits/chosen": -2.734858751296997,
      "logits/rejected": -2.338721752166748,
      "logps/chosen": -103.29885864257812,
      "logps/rejected": -119.86772155761719,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6843154430389404,
      "rewards/margins": 6.402544021606445,
      "rewards/rejected": -8.086859703063965,
      "step": 6627
    },
    {
      "epoch": 2.6512000000000002,
      "grad_norm": 0.00016615491767879575,
      "learning_rate": 1.164e-07,
      "logits/chosen": -2.612474203109741,
      "logits/rejected": -1.9391429424285889,
      "logps/chosen": -88.93113708496094,
      "logps/rejected": -219.181396484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.041165541857481,
      "rewards/margins": 15.35568618774414,
      "rewards/rejected": -15.314521789550781,
      "step": 6628
    },
    {
      "epoch": 2.6516,
      "grad_norm": 339.6156311035156,
      "learning_rate": 1.1626666666666666e-07,
      "logits/chosen": -2.4240810871124268,
      "logits/rejected": -2.262824296951294,
      "logps/chosen": -242.09913635253906,
      "logps/rejected": -138.728515625,
      "loss": 1.5192,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -6.2236738204956055,
      "rewards/margins": 1.147839069366455,
      "rewards/rejected": -7.371513366699219,
      "step": 6629
    },
    {
      "epoch": 2.652,
      "grad_norm": 0.002264639362692833,
      "learning_rate": 1.1613333333333333e-07,
      "logits/chosen": -2.452181816101074,
      "logits/rejected": -2.0160772800445557,
      "logps/chosen": -84.03929901123047,
      "logps/rejected": -199.50701904296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6152364611625671,
      "rewards/margins": 13.703166961669922,
      "rewards/rejected": -13.087930679321289,
      "step": 6630
    },
    {
      "epoch": 2.6524,
      "grad_norm": 0.0011964893201366067,
      "learning_rate": 1.16e-07,
      "logits/chosen": -2.5663557052612305,
      "logits/rejected": -2.0209739208221436,
      "logps/chosen": -91.02973937988281,
      "logps/rejected": -223.54251098632812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7503620386123657,
      "rewards/margins": 13.442347526550293,
      "rewards/rejected": -12.691986083984375,
      "step": 6631
    },
    {
      "epoch": 2.6528,
      "grad_norm": 0.00406790291890502,
      "learning_rate": 1.1586666666666667e-07,
      "logits/chosen": -2.499814987182617,
      "logits/rejected": -1.9047476053237915,
      "logps/chosen": -110.0378189086914,
      "logps/rejected": -210.56820678710938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4819531440734863,
      "rewards/margins": 12.817358016967773,
      "rewards/rejected": -11.335405349731445,
      "step": 6632
    },
    {
      "epoch": 2.6532,
      "grad_norm": 0.006723453756421804,
      "learning_rate": 1.1573333333333332e-07,
      "logits/chosen": -2.381368637084961,
      "logits/rejected": -1.7255518436431885,
      "logps/chosen": -139.66485595703125,
      "logps/rejected": -161.06155395507812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6266025900840759,
      "rewards/margins": 11.600858688354492,
      "rewards/rejected": -10.97425651550293,
      "step": 6633
    },
    {
      "epoch": 2.6536,
      "grad_norm": 0.8091781735420227,
      "learning_rate": 1.1559999999999999e-07,
      "logits/chosen": -2.8453850746154785,
      "logits/rejected": -2.554394245147705,
      "logps/chosen": -54.58808135986328,
      "logps/rejected": -111.29054260253906,
      "loss": 0.0069,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.29038944840431213,
      "rewards/margins": 6.288418769836426,
      "rewards/rejected": -6.578807830810547,
      "step": 6634
    },
    {
      "epoch": 2.654,
      "grad_norm": 0.001083842245861888,
      "learning_rate": 1.1546666666666666e-07,
      "logits/chosen": -2.4660327434539795,
      "logits/rejected": -2.4186463356018066,
      "logps/chosen": -58.9013557434082,
      "logps/rejected": -202.3247833251953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1631345748901367,
      "rewards/margins": 12.538106918334961,
      "rewards/rejected": -13.701242446899414,
      "step": 6635
    },
    {
      "epoch": 2.6544,
      "grad_norm": 0.009976687841117382,
      "learning_rate": 1.1533333333333332e-07,
      "logits/chosen": -2.791680335998535,
      "logits/rejected": -2.4231979846954346,
      "logps/chosen": -69.90296936035156,
      "logps/rejected": -153.52755737304688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1911766231060028,
      "rewards/margins": 9.780420303344727,
      "rewards/rejected": -9.589242935180664,
      "step": 6636
    },
    {
      "epoch": 2.6548,
      "grad_norm": 0.0007181895198300481,
      "learning_rate": 1.1519999999999999e-07,
      "logits/chosen": -3.025291681289673,
      "logits/rejected": -2.4221434593200684,
      "logps/chosen": -64.99118041992188,
      "logps/rejected": -239.11959838867188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5314708948135376,
      "rewards/margins": 16.49297332763672,
      "rewards/rejected": -15.961503028869629,
      "step": 6637
    },
    {
      "epoch": 2.6552,
      "grad_norm": 0.02885592356324196,
      "learning_rate": 1.1506666666666666e-07,
      "logits/chosen": -2.353252410888672,
      "logits/rejected": -2.177738666534424,
      "logps/chosen": -96.04446411132812,
      "logps/rejected": -152.2787628173828,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.744695246219635,
      "rewards/margins": 9.637615203857422,
      "rewards/rejected": -10.38231086730957,
      "step": 6638
    },
    {
      "epoch": 2.6555999999999997,
      "grad_norm": 0.02937932126224041,
      "learning_rate": 1.1493333333333333e-07,
      "logits/chosen": -2.54434871673584,
      "logits/rejected": -2.035444736480713,
      "logps/chosen": -159.11061096191406,
      "logps/rejected": -159.07200622558594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7890613079071045,
      "rewards/margins": 9.166861534118652,
      "rewards/rejected": -10.955923080444336,
      "step": 6639
    },
    {
      "epoch": 2.656,
      "grad_norm": 0.013207091018557549,
      "learning_rate": 1.148e-07,
      "logits/chosen": -2.14835786819458,
      "logits/rejected": -1.5119435787200928,
      "logps/chosen": -131.19815063476562,
      "logps/rejected": -145.01388549804688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.199533462524414,
      "rewards/margins": 9.770771026611328,
      "rewards/rejected": -8.571237564086914,
      "step": 6640
    },
    {
      "epoch": 2.6564,
      "grad_norm": 0.0974648967385292,
      "learning_rate": 1.1466666666666666e-07,
      "logits/chosen": -2.864532947540283,
      "logits/rejected": -2.638284206390381,
      "logps/chosen": -36.588748931884766,
      "logps/rejected": -108.55964660644531,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6809122562408447,
      "rewards/margins": 9.4925537109375,
      "rewards/rejected": -7.811641693115234,
      "step": 6641
    },
    {
      "epoch": 2.6568,
      "grad_norm": 0.026224127039313316,
      "learning_rate": 1.1453333333333333e-07,
      "logits/chosen": -2.5826072692871094,
      "logits/rejected": -1.8342101573944092,
      "logps/chosen": -90.10472869873047,
      "logps/rejected": -177.54608154296875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.948520302772522,
      "rewards/margins": 13.077790260314941,
      "rewards/rejected": -12.12926959991455,
      "step": 6642
    },
    {
      "epoch": 2.6572,
      "grad_norm": 0.05069853737950325,
      "learning_rate": 1.1439999999999999e-07,
      "logits/chosen": -2.8770859241485596,
      "logits/rejected": -2.4581503868103027,
      "logps/chosen": -99.03477478027344,
      "logps/rejected": -157.05990600585938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0666720867156982,
      "rewards/margins": 9.513240814208984,
      "rewards/rejected": -8.44656753540039,
      "step": 6643
    },
    {
      "epoch": 2.6576,
      "grad_norm": 0.7235168814659119,
      "learning_rate": 1.1426666666666666e-07,
      "logits/chosen": -2.937263250350952,
      "logits/rejected": -2.6203205585479736,
      "logps/chosen": -97.17668914794922,
      "logps/rejected": -149.5419921875,
      "loss": 0.005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.058772087097168,
      "rewards/margins": 5.791749954223633,
      "rewards/rejected": -8.8505220413208,
      "step": 6644
    },
    {
      "epoch": 2.658,
      "grad_norm": 1.184346079826355,
      "learning_rate": 1.1413333333333334e-07,
      "logits/chosen": -2.2777552604675293,
      "logits/rejected": -1.3561086654663086,
      "logps/chosen": -187.65757751464844,
      "logps/rejected": -136.92027282714844,
      "loss": 0.0083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8760970830917358,
      "rewards/margins": 5.273067474365234,
      "rewards/rejected": -7.149165153503418,
      "step": 6645
    },
    {
      "epoch": 2.6584,
      "grad_norm": 0.655026912689209,
      "learning_rate": 1.14e-07,
      "logits/chosen": -2.506728172302246,
      "logits/rejected": -2.127506732940674,
      "logps/chosen": -126.49176025390625,
      "logps/rejected": -119.4005126953125,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.403641939163208,
      "rewards/margins": 7.602162837982178,
      "rewards/rejected": -8.005805015563965,
      "step": 6646
    },
    {
      "epoch": 2.6588000000000003,
      "grad_norm": 0.003941154573112726,
      "learning_rate": 1.1386666666666667e-07,
      "logits/chosen": -2.7108852863311768,
      "logits/rejected": -2.3052573204040527,
      "logps/chosen": -68.74732208251953,
      "logps/rejected": -235.58303833007812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6118945479393005,
      "rewards/margins": 16.810253143310547,
      "rewards/rejected": -16.198360443115234,
      "step": 6647
    },
    {
      "epoch": 2.6592000000000002,
      "grad_norm": 0.00030412263004109263,
      "learning_rate": 1.1373333333333333e-07,
      "logits/chosen": -2.709444522857666,
      "logits/rejected": -1.9147417545318604,
      "logps/chosen": -73.03120422363281,
      "logps/rejected": -203.94912719726562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32112884521484375,
      "rewards/margins": 14.30793571472168,
      "rewards/rejected": -13.986806869506836,
      "step": 6648
    },
    {
      "epoch": 2.6596,
      "grad_norm": 0.01356285810470581,
      "learning_rate": 1.136e-07,
      "logits/chosen": -2.9864587783813477,
      "logits/rejected": -2.506883144378662,
      "logps/chosen": -89.25224304199219,
      "logps/rejected": -161.87841796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9020832180976868,
      "rewards/margins": 11.266435623168945,
      "rewards/rejected": -10.364352226257324,
      "step": 6649
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.0003261092642787844,
      "learning_rate": 1.1346666666666665e-07,
      "logits/chosen": -2.0955843925476074,
      "logits/rejected": -1.6223342418670654,
      "logps/chosen": -136.56781005859375,
      "logps/rejected": -307.1167297363281,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9161095023155212,
      "rewards/margins": 14.34682846069336,
      "rewards/rejected": -13.430718421936035,
      "step": 6650
    },
    {
      "epoch": 2.6604,
      "grad_norm": 0.03432004526257515,
      "learning_rate": 1.1333333333333332e-07,
      "logits/chosen": -2.6940765380859375,
      "logits/rejected": -2.0743117332458496,
      "logps/chosen": -119.62876892089844,
      "logps/rejected": -174.46408081054688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8064188957214355,
      "rewards/margins": 8.94091796875,
      "rewards/rejected": -10.747337341308594,
      "step": 6651
    },
    {
      "epoch": 2.6608,
      "grad_norm": 0.007572217844426632,
      "learning_rate": 1.132e-07,
      "logits/chosen": -2.32146954536438,
      "logits/rejected": -1.8223044872283936,
      "logps/chosen": -115.74871826171875,
      "logps/rejected": -171.31349182128906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4959484338760376,
      "rewards/margins": 10.280278205871582,
      "rewards/rejected": -10.776226043701172,
      "step": 6652
    },
    {
      "epoch": 2.6612,
      "grad_norm": 0.0022532627917826176,
      "learning_rate": 1.1306666666666666e-07,
      "logits/chosen": -2.6437478065490723,
      "logits/rejected": -2.0031018257141113,
      "logps/chosen": -118.33355712890625,
      "logps/rejected": -205.06576538085938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.075468897819519,
      "rewards/margins": 13.139089584350586,
      "rewards/rejected": -14.214558601379395,
      "step": 6653
    },
    {
      "epoch": 2.6616,
      "grad_norm": 1.1243996620178223,
      "learning_rate": 1.1293333333333333e-07,
      "logits/chosen": -2.949842929840088,
      "logits/rejected": -2.5762529373168945,
      "logps/chosen": -66.76817321777344,
      "logps/rejected": -160.12680053710938,
      "loss": 0.0057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1778070628643036,
      "rewards/margins": 10.711036682128906,
      "rewards/rejected": -10.88884449005127,
      "step": 6654
    },
    {
      "epoch": 2.662,
      "grad_norm": 0.9621155858039856,
      "learning_rate": 1.1279999999999999e-07,
      "logits/chosen": -2.4966444969177246,
      "logits/rejected": -2.2472894191741943,
      "logps/chosen": -227.89639282226562,
      "logps/rejected": -205.68539428710938,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.885401964187622,
      "rewards/margins": 9.780588150024414,
      "rewards/rejected": -12.665990829467773,
      "step": 6655
    },
    {
      "epoch": 2.6624,
      "grad_norm": 0.0011017293436452746,
      "learning_rate": 1.1266666666666666e-07,
      "logits/chosen": -2.7284326553344727,
      "logits/rejected": -2.261111259460449,
      "logps/chosen": -44.175331115722656,
      "logps/rejected": -192.48886108398438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.06693611294031143,
      "rewards/margins": 12.364082336425781,
      "rewards/rejected": -12.431017875671387,
      "step": 6656
    },
    {
      "epoch": 2.6628,
      "grad_norm": 0.0006540786125697196,
      "learning_rate": 1.1253333333333332e-07,
      "logits/chosen": -2.4019436836242676,
      "logits/rejected": -1.676707148551941,
      "logps/chosen": -115.0470199584961,
      "logps/rejected": -195.8664093017578,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9686603546142578,
      "rewards/margins": 13.272751808166504,
      "rewards/rejected": -12.304091453552246,
      "step": 6657
    },
    {
      "epoch": 2.6632,
      "grad_norm": 1.757391333580017,
      "learning_rate": 1.124e-07,
      "logits/chosen": -2.701263904571533,
      "logits/rejected": -2.561403274536133,
      "logps/chosen": -104.38668060302734,
      "logps/rejected": -131.82838439941406,
      "loss": 0.0092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6390020251274109,
      "rewards/margins": 7.5574798583984375,
      "rewards/rejected": -8.196481704711914,
      "step": 6658
    },
    {
      "epoch": 2.6635999999999997,
      "grad_norm": 0.14794836938381195,
      "learning_rate": 1.1226666666666667e-07,
      "logits/chosen": -2.5948309898376465,
      "logits/rejected": -2.1851625442504883,
      "logps/chosen": -81.26028442382812,
      "logps/rejected": -140.78289794921875,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.017059326171875,
      "rewards/margins": 9.81358528137207,
      "rewards/rejected": -9.830644607543945,
      "step": 6659
    },
    {
      "epoch": 2.664,
      "grad_norm": 1.3029173612594604,
      "learning_rate": 1.1213333333333333e-07,
      "logits/chosen": -2.9236721992492676,
      "logits/rejected": -2.6410913467407227,
      "logps/chosen": -125.27798461914062,
      "logps/rejected": -110.97095489501953,
      "loss": 0.0073,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.873745322227478,
      "rewards/margins": 4.946071624755859,
      "rewards/rejected": -6.819817066192627,
      "step": 6660
    },
    {
      "epoch": 2.6644,
      "grad_norm": 0.08336084336042404,
      "learning_rate": 1.12e-07,
      "logits/chosen": -2.560298442840576,
      "logits/rejected": -1.7695908546447754,
      "logps/chosen": -95.56253814697266,
      "logps/rejected": -143.84922790527344,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2858006954193115,
      "rewards/margins": 9.668672561645508,
      "rewards/rejected": -8.382871627807617,
      "step": 6661
    },
    {
      "epoch": 2.6648,
      "grad_norm": 0.06336403638124466,
      "learning_rate": 1.1186666666666666e-07,
      "logits/chosen": -2.600799798965454,
      "logits/rejected": -1.7988018989562988,
      "logps/chosen": -92.97693634033203,
      "logps/rejected": -157.39785766601562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20482522249221802,
      "rewards/margins": 10.908315658569336,
      "rewards/rejected": -10.703490257263184,
      "step": 6662
    },
    {
      "epoch": 2.6652,
      "grad_norm": 0.03273507580161095,
      "learning_rate": 1.1173333333333333e-07,
      "logits/chosen": -2.619868755340576,
      "logits/rejected": -2.1528830528259277,
      "logps/chosen": -135.09527587890625,
      "logps/rejected": -286.7162780761719,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.17472153902053833,
      "rewards/margins": 18.011913299560547,
      "rewards/rejected": -18.186635971069336,
      "step": 6663
    },
    {
      "epoch": 2.6656,
      "grad_norm": 0.4009758532047272,
      "learning_rate": 1.116e-07,
      "logits/chosen": -2.521984100341797,
      "logits/rejected": -2.388232469558716,
      "logps/chosen": -119.50165557861328,
      "logps/rejected": -195.9416961669922,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4234050512313843,
      "rewards/margins": 9.78935432434082,
      "rewards/rejected": -9.365948677062988,
      "step": 6664
    },
    {
      "epoch": 2.666,
      "grad_norm": 0.1861582249403,
      "learning_rate": 1.1146666666666667e-07,
      "logits/chosen": -2.3937339782714844,
      "logits/rejected": -1.8347985744476318,
      "logps/chosen": -117.65372467041016,
      "logps/rejected": -176.16323852539062,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5454678535461426,
      "rewards/margins": 9.941145896911621,
      "rewards/rejected": -11.486614227294922,
      "step": 6665
    },
    {
      "epoch": 2.6664,
      "grad_norm": 0.013209044001996517,
      "learning_rate": 1.1133333333333334e-07,
      "logits/chosen": -2.4632763862609863,
      "logits/rejected": -1.7721998691558838,
      "logps/chosen": -122.8150863647461,
      "logps/rejected": -229.742431640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.20181989669799805,
      "rewards/margins": 12.412251472473145,
      "rewards/rejected": -12.614070892333984,
      "step": 6666
    },
    {
      "epoch": 2.6668,
      "grad_norm": 0.018383441492915154,
      "learning_rate": 1.1119999999999999e-07,
      "logits/chosen": -2.3248419761657715,
      "logits/rejected": -1.7109295129776,
      "logps/chosen": -99.44216918945312,
      "logps/rejected": -205.91055297851562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.05766487121582031,
      "rewards/margins": 12.593408584594727,
      "rewards/rejected": -12.651073455810547,
      "step": 6667
    },
    {
      "epoch": 2.6672000000000002,
      "grad_norm": 0.13283880054950714,
      "learning_rate": 1.1106666666666666e-07,
      "logits/chosen": -2.422638177871704,
      "logits/rejected": -1.97792649269104,
      "logps/chosen": -103.02627563476562,
      "logps/rejected": -256.94061279296875,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5416759252548218,
      "rewards/margins": 12.861350059509277,
      "rewards/rejected": -14.40302562713623,
      "step": 6668
    },
    {
      "epoch": 2.6676,
      "grad_norm": 0.0034427428618073463,
      "learning_rate": 1.1093333333333332e-07,
      "logits/chosen": -2.453826427459717,
      "logits/rejected": -1.6761988401412964,
      "logps/chosen": -94.97013092041016,
      "logps/rejected": -168.9907989501953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0826637744903564,
      "rewards/margins": 11.560844421386719,
      "rewards/rejected": -10.478179931640625,
      "step": 6669
    },
    {
      "epoch": 2.668,
      "grad_norm": 0.09201385825872421,
      "learning_rate": 1.1079999999999999e-07,
      "logits/chosen": -2.721261501312256,
      "logits/rejected": -2.22603178024292,
      "logps/chosen": -70.16769409179688,
      "logps/rejected": -151.94940185546875,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.29069268703460693,
      "rewards/margins": 9.247069358825684,
      "rewards/rejected": -9.537761688232422,
      "step": 6670
    },
    {
      "epoch": 2.6684,
      "grad_norm": 0.003003421239554882,
      "learning_rate": 1.1066666666666665e-07,
      "logits/chosen": -2.670936107635498,
      "logits/rejected": -2.1705992221832275,
      "logps/chosen": -81.72525787353516,
      "logps/rejected": -245.0606689453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7177017331123352,
      "rewards/margins": 12.090147018432617,
      "rewards/rejected": -11.372446060180664,
      "step": 6671
    },
    {
      "epoch": 2.6688,
      "grad_norm": 250.19073486328125,
      "learning_rate": 1.1053333333333333e-07,
      "logits/chosen": -2.593090057373047,
      "logits/rejected": -2.310527801513672,
      "logps/chosen": -218.6201934814453,
      "logps/rejected": -205.47607421875,
      "loss": 3.8956,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -8.879511833190918,
      "rewards/margins": 5.7175211906433105,
      "rewards/rejected": -14.59703254699707,
      "step": 6672
    },
    {
      "epoch": 2.6692,
      "grad_norm": 0.04398331418633461,
      "learning_rate": 1.104e-07,
      "logits/chosen": -2.9108614921569824,
      "logits/rejected": -2.4688057899475098,
      "logps/chosen": -105.91044616699219,
      "logps/rejected": -158.5682830810547,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19208723306655884,
      "rewards/margins": 11.192341804504395,
      "rewards/rejected": -11.00025463104248,
      "step": 6673
    },
    {
      "epoch": 2.6696,
      "grad_norm": 0.08260985463857651,
      "learning_rate": 1.1026666666666666e-07,
      "logits/chosen": -2.594086170196533,
      "logits/rejected": -2.2724814414978027,
      "logps/chosen": -77.86558532714844,
      "logps/rejected": -180.7099609375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2560449540615082,
      "rewards/margins": 12.554169654846191,
      "rewards/rejected": -12.810214042663574,
      "step": 6674
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.002674001967534423,
      "learning_rate": 1.1013333333333333e-07,
      "logits/chosen": -2.6294102668762207,
      "logits/rejected": -1.8788549900054932,
      "logps/chosen": -93.70042419433594,
      "logps/rejected": -222.74429321289062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6391105651855469,
      "rewards/margins": 15.641193389892578,
      "rewards/rejected": -15.002082824707031,
      "step": 6675
    },
    {
      "epoch": 2.6704,
      "grad_norm": 0.00039645525976084173,
      "learning_rate": 1.0999999999999999e-07,
      "logits/chosen": -2.820058822631836,
      "logits/rejected": -2.3551745414733887,
      "logps/chosen": -95.25714111328125,
      "logps/rejected": -210.87841796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5947769284248352,
      "rewards/margins": 13.463955879211426,
      "rewards/rejected": -12.869178771972656,
      "step": 6676
    },
    {
      "epoch": 2.6708,
      "grad_norm": 1.6186405420303345,
      "learning_rate": 1.0986666666666666e-07,
      "logits/chosen": -2.439255714416504,
      "logits/rejected": -2.264166831970215,
      "logps/chosen": -90.83560180664062,
      "logps/rejected": -150.7584228515625,
      "loss": 0.0105,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8648662567138672,
      "rewards/margins": 7.096561431884766,
      "rewards/rejected": -7.961427688598633,
      "step": 6677
    },
    {
      "epoch": 2.6712,
      "grad_norm": 0.06026891991496086,
      "learning_rate": 1.0973333333333334e-07,
      "logits/chosen": -2.577183961868286,
      "logits/rejected": -1.9528837203979492,
      "logps/chosen": -98.16801452636719,
      "logps/rejected": -163.70143127441406,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7483367919921875,
      "rewards/margins": 10.963459968566895,
      "rewards/rejected": -10.215123176574707,
      "step": 6678
    },
    {
      "epoch": 2.6715999999999998,
      "grad_norm": 0.03221442922949791,
      "learning_rate": 1.096e-07,
      "logits/chosen": -2.4815115928649902,
      "logits/rejected": -2.138366937637329,
      "logps/chosen": -100.55101013183594,
      "logps/rejected": -191.3558349609375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.24377194046974182,
      "rewards/margins": 11.05787467956543,
      "rewards/rejected": -11.301647186279297,
      "step": 6679
    },
    {
      "epoch": 2.672,
      "grad_norm": 0.021137692034244537,
      "learning_rate": 1.0946666666666667e-07,
      "logits/chosen": -2.4931178092956543,
      "logits/rejected": -1.9237781763076782,
      "logps/chosen": -86.61482238769531,
      "logps/rejected": -149.9720458984375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0578885078430176,
      "rewards/margins": 11.189210891723633,
      "rewards/rejected": -10.131322860717773,
      "step": 6680
    },
    {
      "epoch": 2.6724,
      "grad_norm": 0.0018210919806733727,
      "learning_rate": 1.0933333333333333e-07,
      "logits/chosen": -2.2918334007263184,
      "logits/rejected": -1.8474457263946533,
      "logps/chosen": -113.98479461669922,
      "logps/rejected": -267.7588806152344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2763786315917969,
      "rewards/margins": 13.701705932617188,
      "rewards/rejected": -12.42532730102539,
      "step": 6681
    },
    {
      "epoch": 2.6728,
      "grad_norm": 0.30524298548698425,
      "learning_rate": 1.092e-07,
      "logits/chosen": -2.686459541320801,
      "logits/rejected": -2.3059942722320557,
      "logps/chosen": -153.92459106445312,
      "logps/rejected": -179.06146240234375,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1436793804168701,
      "rewards/margins": 11.040853500366211,
      "rewards/rejected": -12.184532165527344,
      "step": 6682
    },
    {
      "epoch": 2.6732,
      "grad_norm": 0.005742763634771109,
      "learning_rate": 1.0906666666666666e-07,
      "logits/chosen": -2.681267738342285,
      "logits/rejected": -2.271146774291992,
      "logps/chosen": -69.16836547851562,
      "logps/rejected": -176.2551727294922,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04599112272262573,
      "rewards/margins": 11.00428581237793,
      "rewards/rejected": -10.958293914794922,
      "step": 6683
    },
    {
      "epoch": 2.6736,
      "grad_norm": 0.10598503798246384,
      "learning_rate": 1.0893333333333332e-07,
      "logits/chosen": -2.931262493133545,
      "logits/rejected": -2.7762961387634277,
      "logps/chosen": -58.51355743408203,
      "logps/rejected": -127.16161346435547,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1373155564069748,
      "rewards/margins": 8.292438507080078,
      "rewards/rejected": -8.155122756958008,
      "step": 6684
    },
    {
      "epoch": 2.674,
      "grad_norm": 11.489154815673828,
      "learning_rate": 1.088e-07,
      "logits/chosen": -2.641223907470703,
      "logits/rejected": -1.952739953994751,
      "logps/chosen": -115.15057373046875,
      "logps/rejected": -126.94666290283203,
      "loss": 0.0789,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1734176874160767,
      "rewards/margins": 6.564735412597656,
      "rewards/rejected": -7.738152980804443,
      "step": 6685
    },
    {
      "epoch": 2.6744,
      "grad_norm": 0.04026322439312935,
      "learning_rate": 1.0866666666666666e-07,
      "logits/chosen": -2.672088623046875,
      "logits/rejected": -2.127147674560547,
      "logps/chosen": -112.39166259765625,
      "logps/rejected": -154.00430297851562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5441704988479614,
      "rewards/margins": 11.531291961669922,
      "rewards/rejected": -9.98712158203125,
      "step": 6686
    },
    {
      "epoch": 2.6748,
      "grad_norm": 0.002035579178482294,
      "learning_rate": 1.0853333333333333e-07,
      "logits/chosen": -2.3428196907043457,
      "logits/rejected": -1.6626445055007935,
      "logps/chosen": -134.62237548828125,
      "logps/rejected": -208.19607543945312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6525871157646179,
      "rewards/margins": 12.843339920043945,
      "rewards/rejected": -13.495926856994629,
      "step": 6687
    },
    {
      "epoch": 2.6752000000000002,
      "grad_norm": 0.24307875335216522,
      "learning_rate": 1.0839999999999999e-07,
      "logits/chosen": -2.9198427200317383,
      "logits/rejected": -2.4883453845977783,
      "logps/chosen": -53.97380828857422,
      "logps/rejected": -95.51966857910156,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8168941736221313,
      "rewards/margins": 7.092354774475098,
      "rewards/rejected": -6.275461196899414,
      "step": 6688
    },
    {
      "epoch": 2.6756,
      "grad_norm": 0.000860271044075489,
      "learning_rate": 1.0826666666666666e-07,
      "logits/chosen": -2.488194704055786,
      "logits/rejected": -1.8315048217773438,
      "logps/chosen": -72.300048828125,
      "logps/rejected": -190.40142822265625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0222328901290894,
      "rewards/margins": 15.179828643798828,
      "rewards/rejected": -14.157596588134766,
      "step": 6689
    },
    {
      "epoch": 2.676,
      "grad_norm": 0.17607060074806213,
      "learning_rate": 1.0813333333333332e-07,
      "logits/chosen": -2.781672239303589,
      "logits/rejected": -2.4415767192840576,
      "logps/chosen": -36.600154876708984,
      "logps/rejected": -162.05897521972656,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3675706088542938,
      "rewards/margins": 11.683403015136719,
      "rewards/rejected": -11.315832138061523,
      "step": 6690
    },
    {
      "epoch": 2.6764,
      "grad_norm": 0.0642637088894844,
      "learning_rate": 1.0799999999999999e-07,
      "logits/chosen": -2.28692626953125,
      "logits/rejected": -1.9334478378295898,
      "logps/chosen": -128.47134399414062,
      "logps/rejected": -185.80552673339844,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7930812239646912,
      "rewards/margins": 11.53576374053955,
      "rewards/rejected": -12.328845024108887,
      "step": 6691
    },
    {
      "epoch": 2.6768,
      "grad_norm": 0.003002873156219721,
      "learning_rate": 1.0786666666666667e-07,
      "logits/chosen": -2.4235334396362305,
      "logits/rejected": -1.8903504610061646,
      "logps/chosen": -101.03343200683594,
      "logps/rejected": -190.47076416015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.198481798171997,
      "rewards/margins": 12.678873062133789,
      "rewards/rejected": -11.480390548706055,
      "step": 6692
    },
    {
      "epoch": 2.6772,
      "grad_norm": 0.004043344873934984,
      "learning_rate": 1.0773333333333333e-07,
      "logits/chosen": -2.2855324745178223,
      "logits/rejected": -1.38375985622406,
      "logps/chosen": -166.839599609375,
      "logps/rejected": -218.9050750732422,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0955482721328735,
      "rewards/margins": 14.809860229492188,
      "rewards/rejected": -13.714313507080078,
      "step": 6693
    },
    {
      "epoch": 2.6776,
      "grad_norm": 0.007290930952876806,
      "learning_rate": 1.076e-07,
      "logits/chosen": -2.5573248863220215,
      "logits/rejected": -2.1142070293426514,
      "logps/chosen": -252.55877685546875,
      "logps/rejected": -191.32679748535156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3846813440322876,
      "rewards/margins": 11.61761474609375,
      "rewards/rejected": -13.002296447753906,
      "step": 6694
    },
    {
      "epoch": 2.678,
      "grad_norm": 0.020937059074640274,
      "learning_rate": 1.0746666666666666e-07,
      "logits/chosen": -3.2340786457061768,
      "logits/rejected": -2.8677353858947754,
      "logps/chosen": -82.35958862304688,
      "logps/rejected": -166.31906127929688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9841146469116211,
      "rewards/margins": 9.724832534790039,
      "rewards/rejected": -10.70894718170166,
      "step": 6695
    },
    {
      "epoch": 2.6784,
      "grad_norm": 0.002781475428491831,
      "learning_rate": 1.0733333333333333e-07,
      "logits/chosen": -2.507173538208008,
      "logits/rejected": -1.636749505996704,
      "logps/chosen": -94.7562255859375,
      "logps/rejected": -271.5307922363281,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9478088021278381,
      "rewards/margins": 16.183612823486328,
      "rewards/rejected": -17.13142204284668,
      "step": 6696
    },
    {
      "epoch": 2.6788,
      "grad_norm": 0.4401018023490906,
      "learning_rate": 1.072e-07,
      "logits/chosen": -2.97023606300354,
      "logits/rejected": -2.530442714691162,
      "logps/chosen": -97.54598999023438,
      "logps/rejected": -187.87692260742188,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.373241901397705,
      "rewards/margins": 13.329360961914062,
      "rewards/rejected": -11.956119537353516,
      "step": 6697
    },
    {
      "epoch": 2.6792,
      "grad_norm": 0.5893238186836243,
      "learning_rate": 1.0706666666666667e-07,
      "logits/chosen": -2.5118067264556885,
      "logits/rejected": -2.0145390033721924,
      "logps/chosen": -111.49118041992188,
      "logps/rejected": -147.87435913085938,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3045727014541626,
      "rewards/margins": 8.41970157623291,
      "rewards/rejected": -8.724273681640625,
      "step": 6698
    },
    {
      "epoch": 2.6795999999999998,
      "grad_norm": 0.22448712587356567,
      "learning_rate": 1.0693333333333334e-07,
      "logits/chosen": -2.7887020111083984,
      "logits/rejected": -2.6025352478027344,
      "logps/chosen": -91.23051452636719,
      "logps/rejected": -96.26518249511719,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5086776614189148,
      "rewards/margins": 6.890624046325684,
      "rewards/rejected": -6.381946086883545,
      "step": 6699
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.005320509895682335,
      "learning_rate": 1.068e-07,
      "logits/chosen": -2.562910795211792,
      "logits/rejected": -1.9176199436187744,
      "logps/chosen": -127.69157409667969,
      "logps/rejected": -216.09112548828125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6887909173965454,
      "rewards/margins": 12.752359390258789,
      "rewards/rejected": -13.441150665283203,
      "step": 6700
    },
    {
      "epoch": 2.6804,
      "grad_norm": 0.2395462989807129,
      "learning_rate": 1.0666666666666667e-07,
      "logits/chosen": -2.9223642349243164,
      "logits/rejected": -2.3625214099884033,
      "logps/chosen": -45.57664489746094,
      "logps/rejected": -134.6906280517578,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.18420526385307312,
      "rewards/margins": 8.161531448364258,
      "rewards/rejected": -8.345736503601074,
      "step": 6701
    },
    {
      "epoch": 2.6808,
      "grad_norm": 0.6729139685630798,
      "learning_rate": 1.0653333333333332e-07,
      "logits/chosen": -2.6017980575561523,
      "logits/rejected": -1.988938331604004,
      "logps/chosen": -117.48825073242188,
      "logps/rejected": -129.51370239257812,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9080978631973267,
      "rewards/margins": 9.131985664367676,
      "rewards/rejected": -8.223888397216797,
      "step": 6702
    },
    {
      "epoch": 2.6812,
      "grad_norm": 0.10225038230419159,
      "learning_rate": 1.0639999999999999e-07,
      "logits/chosen": -2.6451916694641113,
      "logits/rejected": -1.832309603691101,
      "logps/chosen": -105.00112915039062,
      "logps/rejected": -164.78375244140625,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.336879014968872,
      "rewards/margins": 11.307306289672852,
      "rewards/rejected": -9.970427513122559,
      "step": 6703
    },
    {
      "epoch": 2.6816,
      "grad_norm": 1.844664216041565,
      "learning_rate": 1.0626666666666665e-07,
      "logits/chosen": -2.6752097606658936,
      "logits/rejected": -2.6116690635681152,
      "logps/chosen": -110.18569946289062,
      "logps/rejected": -100.66453552246094,
      "loss": 0.01,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4081143140792847,
      "rewards/margins": 5.333312511444092,
      "rewards/rejected": -6.741426944732666,
      "step": 6704
    },
    {
      "epoch": 2.682,
      "grad_norm": 0.1451975554227829,
      "learning_rate": 1.0613333333333333e-07,
      "logits/chosen": -2.792328357696533,
      "logits/rejected": -2.6860620975494385,
      "logps/chosen": -74.18354034423828,
      "logps/rejected": -116.13980102539062,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2851347923278809,
      "rewards/margins": 7.124837875366211,
      "rewards/rejected": -8.40997314453125,
      "step": 6705
    },
    {
      "epoch": 2.6824,
      "grad_norm": 0.09161020815372467,
      "learning_rate": 1.06e-07,
      "logits/chosen": -2.975552558898926,
      "logits/rejected": -2.4164304733276367,
      "logps/chosen": -56.68852233886719,
      "logps/rejected": -129.7010955810547,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.620103657245636,
      "rewards/margins": 9.385309219360352,
      "rewards/rejected": -8.765205383300781,
      "step": 6706
    },
    {
      "epoch": 2.6828,
      "grad_norm": 8.088413596851751e-05,
      "learning_rate": 1.0586666666666666e-07,
      "logits/chosen": -2.497126579284668,
      "logits/rejected": -2.078871011734009,
      "logps/chosen": -81.48764038085938,
      "logps/rejected": -219.43206787109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4042738080024719,
      "rewards/margins": 15.70261001586914,
      "rewards/rejected": -15.29833698272705,
      "step": 6707
    },
    {
      "epoch": 2.6832000000000003,
      "grad_norm": 0.11776331067085266,
      "learning_rate": 1.0573333333333333e-07,
      "logits/chosen": -2.6611523628234863,
      "logits/rejected": -2.2882473468780518,
      "logps/chosen": -68.12893676757812,
      "logps/rejected": -174.74038696289062,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8986251354217529,
      "rewards/margins": 10.675149917602539,
      "rewards/rejected": -9.77652359008789,
      "step": 6708
    },
    {
      "epoch": 2.6836,
      "grad_norm": 0.0334479957818985,
      "learning_rate": 1.0559999999999999e-07,
      "logits/chosen": -2.822053909301758,
      "logits/rejected": -2.2192461490631104,
      "logps/chosen": -106.90892028808594,
      "logps/rejected": -133.66116333007812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11533892154693604,
      "rewards/margins": 8.696495056152344,
      "rewards/rejected": -8.581155776977539,
      "step": 6709
    },
    {
      "epoch": 2.684,
      "grad_norm": 9.421833992004395,
      "learning_rate": 1.0546666666666666e-07,
      "logits/chosen": -2.4264445304870605,
      "logits/rejected": -1.9797217845916748,
      "logps/chosen": -102.24449157714844,
      "logps/rejected": -237.30169677734375,
      "loss": 0.0397,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0150837898254395,
      "rewards/margins": 10.14296817779541,
      "rewards/rejected": -11.158052444458008,
      "step": 6710
    },
    {
      "epoch": 2.6844,
      "grad_norm": 0.927650511264801,
      "learning_rate": 1.0533333333333332e-07,
      "logits/chosen": -2.7749452590942383,
      "logits/rejected": -2.677809953689575,
      "logps/chosen": -130.14382934570312,
      "logps/rejected": -98.61557006835938,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7696548700332642,
      "rewards/margins": 5.932175636291504,
      "rewards/rejected": -6.70182991027832,
      "step": 6711
    },
    {
      "epoch": 2.6848,
      "grad_norm": 0.051253434270620346,
      "learning_rate": 1.052e-07,
      "logits/chosen": -3.008308172225952,
      "logits/rejected": -2.4216084480285645,
      "logps/chosen": -56.72053527832031,
      "logps/rejected": -221.36349487304688,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.013485908508300781,
      "rewards/margins": 15.103837013244629,
      "rewards/rejected": -15.11732292175293,
      "step": 6712
    },
    {
      "epoch": 2.6852,
      "grad_norm": 0.002176746493205428,
      "learning_rate": 1.0506666666666667e-07,
      "logits/chosen": -3.093202590942383,
      "logits/rejected": -2.7112536430358887,
      "logps/chosen": -72.7291030883789,
      "logps/rejected": -153.69332885742188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7695028781890869,
      "rewards/margins": 11.749441146850586,
      "rewards/rejected": -10.979937553405762,
      "step": 6713
    },
    {
      "epoch": 2.6856,
      "grad_norm": 0.011809218674898148,
      "learning_rate": 1.0493333333333333e-07,
      "logits/chosen": -2.321139335632324,
      "logits/rejected": -1.9166133403778076,
      "logps/chosen": -176.06112670898438,
      "logps/rejected": -177.556640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.212289333343506,
      "rewards/margins": 10.031006813049316,
      "rewards/rejected": -12.243295669555664,
      "step": 6714
    },
    {
      "epoch": 2.686,
      "grad_norm": 0.0010036383755505085,
      "learning_rate": 1.048e-07,
      "logits/chosen": -2.6776504516601562,
      "logits/rejected": -2.3288583755493164,
      "logps/chosen": -45.80681610107422,
      "logps/rejected": -207.1374969482422,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.952948808670044,
      "rewards/margins": 14.128997802734375,
      "rewards/rejected": -13.17604923248291,
      "step": 6715
    },
    {
      "epoch": 2.6864,
      "grad_norm": 0.016417648643255234,
      "learning_rate": 1.0466666666666666e-07,
      "logits/chosen": -2.552774429321289,
      "logits/rejected": -2.1618075370788574,
      "logps/chosen": -150.3002166748047,
      "logps/rejected": -154.630126953125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9672424793243408,
      "rewards/margins": 9.561896324157715,
      "rewards/rejected": -11.529138565063477,
      "step": 6716
    },
    {
      "epoch": 2.6868,
      "grad_norm": 0.006977706681936979,
      "learning_rate": 1.0453333333333333e-07,
      "logits/chosen": -2.480106830596924,
      "logits/rejected": -2.1604652404785156,
      "logps/chosen": -107.75308227539062,
      "logps/rejected": -167.60549926757812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015340030193328857,
      "rewards/margins": 10.693878173828125,
      "rewards/rejected": -10.678537368774414,
      "step": 6717
    },
    {
      "epoch": 2.6872,
      "grad_norm": 0.26008838415145874,
      "learning_rate": 1.0440000000000001e-07,
      "logits/chosen": -2.673427104949951,
      "logits/rejected": -2.5074100494384766,
      "logps/chosen": -82.56426239013672,
      "logps/rejected": -112.6387939453125,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.17887574434280396,
      "rewards/margins": 7.211225509643555,
      "rewards/rejected": -7.390100479125977,
      "step": 6718
    },
    {
      "epoch": 2.6875999999999998,
      "grad_norm": 0.10504637658596039,
      "learning_rate": 1.0426666666666666e-07,
      "logits/chosen": -2.8219380378723145,
      "logits/rejected": -2.5385866165161133,
      "logps/chosen": -64.03305053710938,
      "logps/rejected": -109.28319549560547,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3327863812446594,
      "rewards/margins": 7.381712913513184,
      "rewards/rejected": -7.04892635345459,
      "step": 6719
    },
    {
      "epoch": 2.6879999999999997,
      "grad_norm": 0.03735837712883949,
      "learning_rate": 1.0413333333333333e-07,
      "logits/chosen": -2.786604881286621,
      "logits/rejected": -2.484912872314453,
      "logps/chosen": -37.15473937988281,
      "logps/rejected": -206.04542541503906,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5069066882133484,
      "rewards/margins": 14.943046569824219,
      "rewards/rejected": -14.436140060424805,
      "step": 6720
    },
    {
      "epoch": 2.6884,
      "grad_norm": 0.019519075751304626,
      "learning_rate": 1.0399999999999999e-07,
      "logits/chosen": -2.2644405364990234,
      "logits/rejected": -1.7316991090774536,
      "logps/chosen": -105.99517822265625,
      "logps/rejected": -151.25860595703125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.113110303878784,
      "rewards/margins": 12.237367630004883,
      "rewards/rejected": -10.12425708770752,
      "step": 6721
    },
    {
      "epoch": 2.6888,
      "grad_norm": 0.000977622577920556,
      "learning_rate": 1.0386666666666666e-07,
      "logits/chosen": -2.4486823081970215,
      "logits/rejected": -1.6883606910705566,
      "logps/chosen": -165.8861541748047,
      "logps/rejected": -261.5786437988281,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7880203127861023,
      "rewards/margins": 15.121490478515625,
      "rewards/rejected": -15.90951156616211,
      "step": 6722
    },
    {
      "epoch": 2.6892,
      "grad_norm": 2.624242067337036,
      "learning_rate": 1.0373333333333332e-07,
      "logits/chosen": -2.4227237701416016,
      "logits/rejected": -1.6929889917373657,
      "logps/chosen": -85.11724853515625,
      "logps/rejected": -152.57955932617188,
      "loss": 0.0121,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3189055919647217,
      "rewards/margins": 8.454364776611328,
      "rewards/rejected": -8.773270606994629,
      "step": 6723
    },
    {
      "epoch": 2.6896,
      "grad_norm": 0.007814411073923111,
      "learning_rate": 1.0359999999999999e-07,
      "logits/chosen": -2.8676915168762207,
      "logits/rejected": -2.5480902194976807,
      "logps/chosen": -130.79872131347656,
      "logps/rejected": -191.1914520263672,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1761856079101562,
      "rewards/margins": 11.278825759887695,
      "rewards/rejected": -12.455011367797852,
      "step": 6724
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.4021807909011841,
      "learning_rate": 1.0346666666666667e-07,
      "logits/chosen": -2.4691147804260254,
      "logits/rejected": -2.1077728271484375,
      "logps/chosen": -117.92808532714844,
      "logps/rejected": -191.45098876953125,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11906108260154724,
      "rewards/margins": 10.644965171813965,
      "rewards/rejected": -10.525904655456543,
      "step": 6725
    },
    {
      "epoch": 2.6904,
      "grad_norm": 0.001977225998416543,
      "learning_rate": 1.0333333333333333e-07,
      "logits/chosen": -2.473069906234741,
      "logits/rejected": -2.02929425239563,
      "logps/chosen": -105.03258514404297,
      "logps/rejected": -168.4744873046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2701531648635864,
      "rewards/margins": 11.67837142944336,
      "rewards/rejected": -10.408218383789062,
      "step": 6726
    },
    {
      "epoch": 2.6908,
      "grad_norm": 0.06380277127027512,
      "learning_rate": 1.032e-07,
      "logits/chosen": -2.3086397647857666,
      "logits/rejected": -1.6873154640197754,
      "logps/chosen": -171.46914672851562,
      "logps/rejected": -166.38839721679688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8632240295410156,
      "rewards/margins": 10.148709297180176,
      "rewards/rejected": -11.011933326721191,
      "step": 6727
    },
    {
      "epoch": 2.6912000000000003,
      "grad_norm": 0.17240683734416962,
      "learning_rate": 1.0306666666666666e-07,
      "logits/chosen": -2.9018232822418213,
      "logits/rejected": -2.564791202545166,
      "logps/chosen": -65.57420349121094,
      "logps/rejected": -106.7264404296875,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4918873310089111,
      "rewards/margins": 8.134799003601074,
      "rewards/rejected": -6.642911434173584,
      "step": 6728
    },
    {
      "epoch": 2.6916,
      "grad_norm": 0.03303801268339157,
      "learning_rate": 1.0293333333333333e-07,
      "logits/chosen": -2.3064732551574707,
      "logits/rejected": -1.7909703254699707,
      "logps/chosen": -221.69923400878906,
      "logps/rejected": -275.2434997558594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9254486560821533,
      "rewards/margins": 13.577936172485352,
      "rewards/rejected": -14.503385543823242,
      "step": 6729
    },
    {
      "epoch": 2.692,
      "grad_norm": 54.83605194091797,
      "learning_rate": 1.028e-07,
      "logits/chosen": -2.7022204399108887,
      "logits/rejected": -2.3942370414733887,
      "logps/chosen": -136.71072387695312,
      "logps/rejected": -137.1509552001953,
      "loss": 0.249,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -5.38412618637085,
      "rewards/margins": 4.831667423248291,
      "rewards/rejected": -10.21579360961914,
      "step": 6730
    },
    {
      "epoch": 2.6924,
      "grad_norm": 0.013028114102780819,
      "learning_rate": 1.0266666666666666e-07,
      "logits/chosen": -2.438220500946045,
      "logits/rejected": -1.9887871742248535,
      "logps/chosen": -143.64190673828125,
      "logps/rejected": -253.92694091796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5253403186798096,
      "rewards/margins": 11.590341567993164,
      "rewards/rejected": -13.115680694580078,
      "step": 6731
    },
    {
      "epoch": 2.6928,
      "grad_norm": 0.004237563349306583,
      "learning_rate": 1.0253333333333334e-07,
      "logits/chosen": -2.428220748901367,
      "logits/rejected": -1.8066538572311401,
      "logps/chosen": -91.16836547851562,
      "logps/rejected": -187.63111877441406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.33513695001602173,
      "rewards/margins": 11.346431732177734,
      "rewards/rejected": -11.681568145751953,
      "step": 6732
    },
    {
      "epoch": 2.6932,
      "grad_norm": 0.12755413353443146,
      "learning_rate": 1.024e-07,
      "logits/chosen": -2.6322519779205322,
      "logits/rejected": -2.1432151794433594,
      "logps/chosen": -93.05215454101562,
      "logps/rejected": -199.40916442871094,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.487600326538086,
      "rewards/margins": 12.547515869140625,
      "rewards/rejected": -11.059915542602539,
      "step": 6733
    },
    {
      "epoch": 2.6936,
      "grad_norm": 1.0279799699783325,
      "learning_rate": 1.0226666666666667e-07,
      "logits/chosen": -2.7871432304382324,
      "logits/rejected": -2.627537727355957,
      "logps/chosen": -90.1185073852539,
      "logps/rejected": -95.20320129394531,
      "loss": 0.0061,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4765573740005493,
      "rewards/margins": 5.802211761474609,
      "rewards/rejected": -6.278769493103027,
      "step": 6734
    },
    {
      "epoch": 2.694,
      "grad_norm": 52.606807708740234,
      "learning_rate": 1.0213333333333333e-07,
      "logits/chosen": -2.5473687648773193,
      "logits/rejected": -2.4254512786865234,
      "logps/chosen": -163.1811065673828,
      "logps/rejected": -72.0804214477539,
      "loss": 0.3578,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.1173946857452393,
      "rewards/margins": 0.9443039894104004,
      "rewards/rejected": -4.061698913574219,
      "step": 6735
    },
    {
      "epoch": 2.6944,
      "grad_norm": 0.24110205471515656,
      "learning_rate": 1.0199999999999999e-07,
      "logits/chosen": -2.9258415699005127,
      "logits/rejected": -2.4827208518981934,
      "logps/chosen": -43.25898361206055,
      "logps/rejected": -146.85955810546875,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.15155363082885742,
      "rewards/margins": 10.510591506958008,
      "rewards/rejected": -10.662145614624023,
      "step": 6736
    },
    {
      "epoch": 2.6948,
      "grad_norm": 0.0255851149559021,
      "learning_rate": 1.0186666666666665e-07,
      "logits/chosen": -2.6610188484191895,
      "logits/rejected": -2.3703837394714355,
      "logps/chosen": -41.89812469482422,
      "logps/rejected": -113.8770751953125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4487707614898682,
      "rewards/margins": 9.016470909118652,
      "rewards/rejected": -7.567699909210205,
      "step": 6737
    },
    {
      "epoch": 2.6952,
      "grad_norm": 0.04413042590022087,
      "learning_rate": 1.0173333333333332e-07,
      "logits/chosen": -2.6495933532714844,
      "logits/rejected": -2.258208751678467,
      "logps/chosen": -42.037803649902344,
      "logps/rejected": -177.6818084716797,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5944573879241943,
      "rewards/margins": 11.605447769165039,
      "rewards/rejected": -12.199905395507812,
      "step": 6738
    },
    {
      "epoch": 2.6955999999999998,
      "grad_norm": 0.45719870924949646,
      "learning_rate": 1.016e-07,
      "logits/chosen": -3.116201162338257,
      "logits/rejected": -2.74699068069458,
      "logps/chosen": -64.32257080078125,
      "logps/rejected": -129.214599609375,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.28788453340530396,
      "rewards/margins": 7.564550399780273,
      "rewards/rejected": -7.276665687561035,
      "step": 6739
    },
    {
      "epoch": 2.6959999999999997,
      "grad_norm": 0.0046556564047932625,
      "learning_rate": 1.0146666666666666e-07,
      "logits/chosen": -2.751378297805786,
      "logits/rejected": -2.2589926719665527,
      "logps/chosen": -89.0423812866211,
      "logps/rejected": -190.90374755859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2500205934047699,
      "rewards/margins": 13.515981674194336,
      "rewards/rejected": -13.265960693359375,
      "step": 6740
    },
    {
      "epoch": 2.6964,
      "grad_norm": 0.006826280616223812,
      "learning_rate": 1.0133333333333333e-07,
      "logits/chosen": -2.167362689971924,
      "logits/rejected": -1.6864898204803467,
      "logps/chosen": -173.22970581054688,
      "logps/rejected": -190.17001342773438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7134590148925781,
      "rewards/margins": 12.385066986083984,
      "rewards/rejected": -11.671607971191406,
      "step": 6741
    },
    {
      "epoch": 2.6968,
      "grad_norm": 0.16555491089820862,
      "learning_rate": 1.0119999999999999e-07,
      "logits/chosen": -2.6068403720855713,
      "logits/rejected": -1.9691591262817383,
      "logps/chosen": -148.35655212402344,
      "logps/rejected": -164.76815795898438,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1347241997718811,
      "rewards/margins": 8.716166496276855,
      "rewards/rejected": -8.85089111328125,
      "step": 6742
    },
    {
      "epoch": 2.6972,
      "grad_norm": 0.0010513431625440717,
      "learning_rate": 1.0106666666666666e-07,
      "logits/chosen": -2.3794028759002686,
      "logits/rejected": -2.3010568618774414,
      "logps/chosen": -111.00938415527344,
      "logps/rejected": -186.3824462890625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12535744905471802,
      "rewards/margins": 12.593780517578125,
      "rewards/rejected": -12.468421936035156,
      "step": 6743
    },
    {
      "epoch": 2.6976,
      "grad_norm": 0.017196692526340485,
      "learning_rate": 1.0093333333333332e-07,
      "logits/chosen": -2.6221184730529785,
      "logits/rejected": -2.4125423431396484,
      "logps/chosen": -141.978759765625,
      "logps/rejected": -163.29148864746094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8166584372520447,
      "rewards/margins": 11.167313575744629,
      "rewards/rejected": -11.983972549438477,
      "step": 6744
    },
    {
      "epoch": 2.698,
      "grad_norm": 0.002606444526463747,
      "learning_rate": 1.008e-07,
      "logits/chosen": -2.393975257873535,
      "logits/rejected": -2.046133279800415,
      "logps/chosen": -80.408203125,
      "logps/rejected": -200.85707092285156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.041561126708984375,
      "rewards/margins": 12.089841842651367,
      "rewards/rejected": -12.048280715942383,
      "step": 6745
    },
    {
      "epoch": 2.6984,
      "grad_norm": 99.24288940429688,
      "learning_rate": 1.0066666666666667e-07,
      "logits/chosen": -2.478616237640381,
      "logits/rejected": -2.270055055618286,
      "logps/chosen": -147.6414794921875,
      "logps/rejected": -192.96112060546875,
      "loss": 0.5443,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -5.76901388168335,
      "rewards/margins": 6.806952953338623,
      "rewards/rejected": -12.575966835021973,
      "step": 6746
    },
    {
      "epoch": 2.6988,
      "grad_norm": 0.01517927460372448,
      "learning_rate": 1.0053333333333333e-07,
      "logits/chosen": -2.9395627975463867,
      "logits/rejected": -2.449765682220459,
      "logps/chosen": -50.45046615600586,
      "logps/rejected": -152.47586059570312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5334415435791016,
      "rewards/margins": 10.717939376831055,
      "rewards/rejected": -10.184497833251953,
      "step": 6747
    },
    {
      "epoch": 2.6992000000000003,
      "grad_norm": 0.00903329998254776,
      "learning_rate": 1.004e-07,
      "logits/chosen": -2.434399127960205,
      "logits/rejected": -1.7918217182159424,
      "logps/chosen": -142.25527954101562,
      "logps/rejected": -144.74029541015625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1297374963760376,
      "rewards/margins": 11.674236297607422,
      "rewards/rejected": -10.544499397277832,
      "step": 6748
    },
    {
      "epoch": 2.6996,
      "grad_norm": 0.01606731116771698,
      "learning_rate": 1.0026666666666666e-07,
      "logits/chosen": -2.4705963134765625,
      "logits/rejected": -1.9051234722137451,
      "logps/chosen": -96.83565521240234,
      "logps/rejected": -145.67233276367188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7547569274902344,
      "rewards/margins": 10.2147798538208,
      "rewards/rejected": -9.46002197265625,
      "step": 6749
    },
    {
      "epoch": 2.7,
      "grad_norm": 15.941078186035156,
      "learning_rate": 1.0013333333333333e-07,
      "logits/chosen": -2.5563406944274902,
      "logits/rejected": -2.475782871246338,
      "logps/chosen": -123.30014038085938,
      "logps/rejected": -153.2787628173828,
      "loss": 0.0665,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7114845514297485,
      "rewards/margins": 7.967928409576416,
      "rewards/rejected": -9.679412841796875,
      "step": 6750
    },
    {
      "epoch": 2.7004,
      "grad_norm": 0.0030696187168359756,
      "learning_rate": 1e-07,
      "logits/chosen": -2.462449550628662,
      "logits/rejected": -1.8792436122894287,
      "logps/chosen": -75.28504943847656,
      "logps/rejected": -193.57412719726562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.729682445526123,
      "rewards/margins": 14.505210876464844,
      "rewards/rejected": -12.775527954101562,
      "step": 6751
    },
    {
      "epoch": 2.7008,
      "grad_norm": 0.04764288663864136,
      "learning_rate": 9.986666666666667e-08,
      "logits/chosen": -2.7953572273254395,
      "logits/rejected": -2.456803560256958,
      "logps/chosen": -108.2188720703125,
      "logps/rejected": -154.4175567626953,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21479451656341553,
      "rewards/margins": 9.920522689819336,
      "rewards/rejected": -9.705727577209473,
      "step": 6752
    },
    {
      "epoch": 2.7012,
      "grad_norm": 0.06550928950309753,
      "learning_rate": 9.973333333333333e-08,
      "logits/chosen": -2.903430938720703,
      "logits/rejected": -2.5034773349761963,
      "logps/chosen": -79.68109130859375,
      "logps/rejected": -150.5401611328125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6779449582099915,
      "rewards/margins": 9.291437149047852,
      "rewards/rejected": -9.969382286071777,
      "step": 6753
    },
    {
      "epoch": 2.7016,
      "grad_norm": 0.01588834449648857,
      "learning_rate": 9.959999999999999e-08,
      "logits/chosen": -2.790238857269287,
      "logits/rejected": -2.525570869445801,
      "logps/chosen": -121.98135375976562,
      "logps/rejected": -183.56446838378906,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9782860279083252,
      "rewards/margins": 10.40069580078125,
      "rewards/rejected": -12.37898063659668,
      "step": 6754
    },
    {
      "epoch": 2.702,
      "grad_norm": 0.8452465534210205,
      "learning_rate": 9.946666666666666e-08,
      "logits/chosen": -2.7964210510253906,
      "logits/rejected": -2.464231491088867,
      "logps/chosen": -131.593017578125,
      "logps/rejected": -121.15625,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0877156257629395,
      "rewards/margins": 5.778266906738281,
      "rewards/rejected": -7.865983009338379,
      "step": 6755
    },
    {
      "epoch": 2.7024,
      "grad_norm": 0.04824978858232498,
      "learning_rate": 9.933333333333332e-08,
      "logits/chosen": -2.8938539028167725,
      "logits/rejected": -2.0448529720306396,
      "logps/chosen": -85.29317474365234,
      "logps/rejected": -194.97024536132812,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9368851184844971,
      "rewards/margins": 12.476982116699219,
      "rewards/rejected": -13.41386604309082,
      "step": 6756
    },
    {
      "epoch": 2.7028,
      "grad_norm": 0.019273504614830017,
      "learning_rate": 9.919999999999999e-08,
      "logits/chosen": -2.841115713119507,
      "logits/rejected": -2.581493616104126,
      "logps/chosen": -124.9977035522461,
      "logps/rejected": -152.040771484375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4839218854904175,
      "rewards/margins": 9.60069465637207,
      "rewards/rejected": -9.11677360534668,
      "step": 6757
    },
    {
      "epoch": 2.7032,
      "grad_norm": 0.01025347225368023,
      "learning_rate": 9.906666666666665e-08,
      "logits/chosen": -2.8320937156677246,
      "logits/rejected": -2.389890193939209,
      "logps/chosen": -80.00469207763672,
      "logps/rejected": -158.58392333984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.16790923476219177,
      "rewards/margins": 10.631975173950195,
      "rewards/rejected": -10.799884796142578,
      "step": 6758
    },
    {
      "epoch": 2.7036,
      "grad_norm": 0.0007768846116960049,
      "learning_rate": 9.893333333333333e-08,
      "logits/chosen": -2.19526743888855,
      "logits/rejected": -1.5295462608337402,
      "logps/chosen": -142.86184692382812,
      "logps/rejected": -189.5131072998047,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5195888876914978,
      "rewards/margins": 12.910089492797852,
      "rewards/rejected": -12.39050006866455,
      "step": 6759
    },
    {
      "epoch": 2.7039999999999997,
      "grad_norm": 1.278461695619626e-05,
      "learning_rate": 9.88e-08,
      "logits/chosen": -2.292613983154297,
      "logits/rejected": -1.3211596012115479,
      "logps/chosen": -78.67611694335938,
      "logps/rejected": -282.346923828125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4573020935058594,
      "rewards/margins": 18.422924041748047,
      "rewards/rejected": -15.965620994567871,
      "step": 6760
    },
    {
      "epoch": 2.7044,
      "grad_norm": 0.3722972869873047,
      "learning_rate": 9.866666666666666e-08,
      "logits/chosen": -2.0971789360046387,
      "logits/rejected": -1.9300293922424316,
      "logps/chosen": -227.71229553222656,
      "logps/rejected": -229.88729858398438,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3155803680419922,
      "rewards/margins": 10.689982414245605,
      "rewards/rejected": -12.005562782287598,
      "step": 6761
    },
    {
      "epoch": 2.7048,
      "grad_norm": 0.31823107600212097,
      "learning_rate": 9.853333333333333e-08,
      "logits/chosen": -2.620575189590454,
      "logits/rejected": -2.14159893989563,
      "logps/chosen": -102.10487365722656,
      "logps/rejected": -181.41183471679688,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9527696967124939,
      "rewards/margins": 11.510808944702148,
      "rewards/rejected": -12.463579177856445,
      "step": 6762
    },
    {
      "epoch": 2.7052,
      "grad_norm": 2.2515058517456055,
      "learning_rate": 9.84e-08,
      "logits/chosen": -2.831721305847168,
      "logits/rejected": -2.7577245235443115,
      "logps/chosen": -104.12452697753906,
      "logps/rejected": -98.52046203613281,
      "loss": 0.0107,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8698110580444336,
      "rewards/margins": 6.464796543121338,
      "rewards/rejected": -7.334607124328613,
      "step": 6763
    },
    {
      "epoch": 2.7056,
      "grad_norm": 0.01054244115948677,
      "learning_rate": 9.826666666666666e-08,
      "logits/chosen": -2.5893924236297607,
      "logits/rejected": -1.8757373094558716,
      "logps/chosen": -82.161865234375,
      "logps/rejected": -175.51715087890625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8298149108886719,
      "rewards/margins": 12.82878589630127,
      "rewards/rejected": -10.998970985412598,
      "step": 6764
    },
    {
      "epoch": 2.706,
      "grad_norm": 0.003890763968229294,
      "learning_rate": 9.813333333333333e-08,
      "logits/chosen": -3.0814294815063477,
      "logits/rejected": -2.4198389053344727,
      "logps/chosen": -51.77657699584961,
      "logps/rejected": -180.3431396484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0361924171447754,
      "rewards/margins": 14.286066055297852,
      "rewards/rejected": -12.249874114990234,
      "step": 6765
    },
    {
      "epoch": 2.7064,
      "grad_norm": 0.005275193136185408,
      "learning_rate": 9.8e-08,
      "logits/chosen": -2.243231773376465,
      "logits/rejected": -1.4236650466918945,
      "logps/chosen": -105.85319519042969,
      "logps/rejected": -165.45526123046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39078980684280396,
      "rewards/margins": 11.359872817993164,
      "rewards/rejected": -10.96908187866211,
      "step": 6766
    },
    {
      "epoch": 2.7068,
      "grad_norm": 0.0026191293727606535,
      "learning_rate": 9.786666666666667e-08,
      "logits/chosen": -2.368380546569824,
      "logits/rejected": -1.5881664752960205,
      "logps/chosen": -208.62399291992188,
      "logps/rejected": -230.84039306640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.37358707189559937,
      "rewards/margins": 15.683969497680664,
      "rewards/rejected": -15.310382843017578,
      "step": 6767
    },
    {
      "epoch": 2.7072000000000003,
      "grad_norm": 0.0022594411857426167,
      "learning_rate": 9.773333333333333e-08,
      "logits/chosen": -2.1109986305236816,
      "logits/rejected": -1.5731468200683594,
      "logps/chosen": -146.32623291015625,
      "logps/rejected": -198.77931213378906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08379784226417542,
      "rewards/margins": 11.972906112670898,
      "rewards/rejected": -11.889108657836914,
      "step": 6768
    },
    {
      "epoch": 2.7076000000000002,
      "grad_norm": 20.68150520324707,
      "learning_rate": 9.76e-08,
      "logits/chosen": -2.617410182952881,
      "logits/rejected": -2.213564872741699,
      "logps/chosen": -106.09452056884766,
      "logps/rejected": -97.94058227539062,
      "loss": 0.1135,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.19953078031539917,
      "rewards/margins": 6.133528709411621,
      "rewards/rejected": -6.333059310913086,
      "step": 6769
    },
    {
      "epoch": 2.708,
      "grad_norm": 0.0016025969525799155,
      "learning_rate": 9.746666666666665e-08,
      "logits/chosen": -2.6627488136291504,
      "logits/rejected": -2.132762908935547,
      "logps/chosen": -94.25100708007812,
      "logps/rejected": -197.34727478027344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0793911218643188,
      "rewards/margins": 12.078296661376953,
      "rewards/rejected": -13.15768814086914,
      "step": 6770
    },
    {
      "epoch": 2.7084,
      "grad_norm": 0.037602394819259644,
      "learning_rate": 9.733333333333332e-08,
      "logits/chosen": -2.8814809322357178,
      "logits/rejected": -2.2541861534118652,
      "logps/chosen": -98.00836944580078,
      "logps/rejected": -183.4089813232422,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5277817249298096,
      "rewards/margins": 13.137334823608398,
      "rewards/rejected": -13.665116310119629,
      "step": 6771
    },
    {
      "epoch": 2.7088,
      "grad_norm": 0.029923684895038605,
      "learning_rate": 9.72e-08,
      "logits/chosen": -3.0141406059265137,
      "logits/rejected": -2.6019155979156494,
      "logps/chosen": -61.7007942199707,
      "logps/rejected": -158.30096435546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1740802526474,
      "rewards/margins": 9.825666427612305,
      "rewards/rejected": -8.651586532592773,
      "step": 6772
    },
    {
      "epoch": 2.7092,
      "grad_norm": 0.0013262121938169003,
      "learning_rate": 9.706666666666666e-08,
      "logits/chosen": -2.6881842613220215,
      "logits/rejected": -2.4247074127197266,
      "logps/chosen": -102.13546752929688,
      "logps/rejected": -165.97308349609375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.212961196899414,
      "rewards/margins": 12.894021987915039,
      "rewards/rejected": -10.681060791015625,
      "step": 6773
    },
    {
      "epoch": 2.7096,
      "grad_norm": 0.05679866299033165,
      "learning_rate": 9.693333333333333e-08,
      "logits/chosen": -2.9583091735839844,
      "logits/rejected": -2.3869643211364746,
      "logps/chosen": -82.25540161132812,
      "logps/rejected": -121.1526870727539,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1574852466583252,
      "rewards/margins": 9.107897758483887,
      "rewards/rejected": -7.950412750244141,
      "step": 6774
    },
    {
      "epoch": 2.71,
      "grad_norm": 2.025906562805176,
      "learning_rate": 9.679999999999999e-08,
      "logits/chosen": -2.546590566635132,
      "logits/rejected": -1.8680450916290283,
      "logps/chosen": -117.12188720703125,
      "logps/rejected": -135.51046752929688,
      "loss": 0.0093,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.06601294875144958,
      "rewards/margins": 8.442585945129395,
      "rewards/rejected": -8.508598327636719,
      "step": 6775
    },
    {
      "epoch": 2.7104,
      "grad_norm": 0.03083527833223343,
      "learning_rate": 9.666666666666666e-08,
      "logits/chosen": -2.9696950912475586,
      "logits/rejected": -2.7154626846313477,
      "logps/chosen": -63.0892219543457,
      "logps/rejected": -130.150634765625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38771021366119385,
      "rewards/margins": 9.041263580322266,
      "rewards/rejected": -8.653553009033203,
      "step": 6776
    },
    {
      "epoch": 2.7108,
      "grad_norm": 0.0003593340516090393,
      "learning_rate": 9.653333333333332e-08,
      "logits/chosen": -2.5414812564849854,
      "logits/rejected": -1.8233931064605713,
      "logps/chosen": -102.56143951416016,
      "logps/rejected": -201.5085906982422,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9813086986541748,
      "rewards/margins": 15.685002326965332,
      "rewards/rejected": -13.703693389892578,
      "step": 6777
    },
    {
      "epoch": 2.7112,
      "grad_norm": 0.00719463312998414,
      "learning_rate": 9.639999999999999e-08,
      "logits/chosen": -2.6311895847320557,
      "logits/rejected": -2.3105697631835938,
      "logps/chosen": -96.13014221191406,
      "logps/rejected": -141.44842529296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0166141986846924,
      "rewards/margins": 10.664800643920898,
      "rewards/rejected": -9.648185729980469,
      "step": 6778
    },
    {
      "epoch": 2.7116,
      "grad_norm": 0.8193079829216003,
      "learning_rate": 9.626666666666667e-08,
      "logits/chosen": -2.9598159790039062,
      "logits/rejected": -2.5270776748657227,
      "logps/chosen": -114.25321960449219,
      "logps/rejected": -155.21192932128906,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5553531646728516,
      "rewards/margins": 7.15925407409668,
      "rewards/rejected": -8.714607238769531,
      "step": 6779
    },
    {
      "epoch": 2.7119999999999997,
      "grad_norm": 0.0015996616566553712,
      "learning_rate": 9.613333333333333e-08,
      "logits/chosen": -2.6435508728027344,
      "logits/rejected": -2.322829246520996,
      "logps/chosen": -124.33001708984375,
      "logps/rejected": -232.422607421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3583202362060547,
      "rewards/margins": 16.927902221679688,
      "rewards/rejected": -15.56958293914795,
      "step": 6780
    },
    {
      "epoch": 2.7124,
      "grad_norm": 0.028710205107927322,
      "learning_rate": 9.6e-08,
      "logits/chosen": -2.6949095726013184,
      "logits/rejected": -2.529571533203125,
      "logps/chosen": -123.90141296386719,
      "logps/rejected": -145.14483642578125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05005532503128052,
      "rewards/margins": 9.259231567382812,
      "rewards/rejected": -9.209177017211914,
      "step": 6781
    },
    {
      "epoch": 2.7128,
      "grad_norm": 0.043662313371896744,
      "learning_rate": 9.586666666666666e-08,
      "logits/chosen": -2.2687807083129883,
      "logits/rejected": -1.5368903875350952,
      "logps/chosen": -136.60171508789062,
      "logps/rejected": -236.39039611816406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.036653876304626465,
      "rewards/margins": 13.169431686401367,
      "rewards/rejected": -13.132777214050293,
      "step": 6782
    },
    {
      "epoch": 2.7132,
      "grad_norm": 8.361776351928711,
      "learning_rate": 9.573333333333333e-08,
      "logits/chosen": -2.7257728576660156,
      "logits/rejected": -2.6672117710113525,
      "logps/chosen": -68.16128540039062,
      "logps/rejected": -78.24508666992188,
      "loss": 0.0818,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.7173843383789062,
      "rewards/margins": 3.0089049339294434,
      "rewards/rejected": -5.72628927230835,
      "step": 6783
    },
    {
      "epoch": 2.7136,
      "grad_norm": 30.93103790283203,
      "learning_rate": 9.56e-08,
      "logits/chosen": -2.5576562881469727,
      "logits/rejected": -2.16873836517334,
      "logps/chosen": -122.02430725097656,
      "logps/rejected": -111.37579345703125,
      "loss": 0.1823,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.44865307211875916,
      "rewards/margins": 6.687273025512695,
      "rewards/rejected": -7.135926246643066,
      "step": 6784
    },
    {
      "epoch": 2.714,
      "grad_norm": 1.0587519407272339,
      "learning_rate": 9.546666666666666e-08,
      "logits/chosen": -2.8142850399017334,
      "logits/rejected": -2.4481911659240723,
      "logps/chosen": -88.66267395019531,
      "logps/rejected": -103.84342956542969,
      "loss": 0.0048,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0338325500488281,
      "rewards/margins": 7.138429164886475,
      "rewards/rejected": -6.104596138000488,
      "step": 6785
    },
    {
      "epoch": 2.7144,
      "grad_norm": 4.042299747467041,
      "learning_rate": 9.533333333333334e-08,
      "logits/chosen": -2.401095151901245,
      "logits/rejected": -2.003619432449341,
      "logps/chosen": -191.8817138671875,
      "logps/rejected": -163.4551239013672,
      "loss": 0.0135,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9701553583145142,
      "rewards/margins": 7.093597888946533,
      "rewards/rejected": -9.063753128051758,
      "step": 6786
    },
    {
      "epoch": 2.7148,
      "grad_norm": 0.017114803194999695,
      "learning_rate": 9.52e-08,
      "logits/chosen": -2.9280238151550293,
      "logits/rejected": -2.5032715797424316,
      "logps/chosen": -103.24057006835938,
      "logps/rejected": -169.6903076171875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.01481032371521,
      "rewards/margins": 9.871343612670898,
      "rewards/rejected": -8.85653305053711,
      "step": 6787
    },
    {
      "epoch": 2.7152,
      "grad_norm": 0.08446789532899857,
      "learning_rate": 9.506666666666666e-08,
      "logits/chosen": -2.1517691612243652,
      "logits/rejected": -1.984804391860962,
      "logps/chosen": -129.7623291015625,
      "logps/rejected": -168.96824645996094,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.18745309114456177,
      "rewards/margins": 10.678749084472656,
      "rewards/rejected": -10.866202354431152,
      "step": 6788
    },
    {
      "epoch": 2.7156000000000002,
      "grad_norm": 0.0030799629166722298,
      "learning_rate": 9.493333333333332e-08,
      "logits/chosen": -2.6626858711242676,
      "logits/rejected": -2.198540210723877,
      "logps/chosen": -52.03057861328125,
      "logps/rejected": -149.1149444580078,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4567647874355316,
      "rewards/margins": 11.316872596740723,
      "rewards/rejected": -10.860107421875,
      "step": 6789
    },
    {
      "epoch": 2.716,
      "grad_norm": 0.03268587589263916,
      "learning_rate": 9.479999999999999e-08,
      "logits/chosen": -2.341276168823242,
      "logits/rejected": -1.5104098320007324,
      "logps/chosen": -122.78587341308594,
      "logps/rejected": -231.2503662109375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.14367523789405823,
      "rewards/margins": 11.421548843383789,
      "rewards/rejected": -11.565224647521973,
      "step": 6790
    },
    {
      "epoch": 2.7164,
      "grad_norm": 0.007127259857952595,
      "learning_rate": 9.466666666666665e-08,
      "logits/chosen": -2.5383429527282715,
      "logits/rejected": -2.0369198322296143,
      "logps/chosen": -88.21613311767578,
      "logps/rejected": -159.176025390625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1481597423553467,
      "rewards/margins": 12.044893264770508,
      "rewards/rejected": -10.896734237670898,
      "step": 6791
    },
    {
      "epoch": 2.7168,
      "grad_norm": 0.015630917623639107,
      "learning_rate": 9.453333333333332e-08,
      "logits/chosen": -2.652123212814331,
      "logits/rejected": -2.5348563194274902,
      "logps/chosen": -132.85726928710938,
      "logps/rejected": -178.30465698242188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.199078768491745,
      "rewards/margins": 10.994855880737305,
      "rewards/rejected": -10.7957763671875,
      "step": 6792
    },
    {
      "epoch": 2.7172,
      "grad_norm": 2.254090395581443e-05,
      "learning_rate": 9.44e-08,
      "logits/chosen": -2.378804922103882,
      "logits/rejected": -1.3684542179107666,
      "logps/chosen": -104.75357818603516,
      "logps/rejected": -242.84158325195312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9813759326934814,
      "rewards/margins": 16.843830108642578,
      "rewards/rejected": -14.86245346069336,
      "step": 6793
    },
    {
      "epoch": 2.7176,
      "grad_norm": 0.023528732359409332,
      "learning_rate": 9.426666666666666e-08,
      "logits/chosen": -2.737971782684326,
      "logits/rejected": -2.3640222549438477,
      "logps/chosen": -85.66154479980469,
      "logps/rejected": -173.4318389892578,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0003997683525085449,
      "rewards/margins": 10.390944480895996,
      "rewards/rejected": -10.39134407043457,
      "step": 6794
    },
    {
      "epoch": 2.718,
      "grad_norm": 1.7218259572982788,
      "learning_rate": 9.413333333333333e-08,
      "logits/chosen": -2.6535725593566895,
      "logits/rejected": -2.623175859451294,
      "logps/chosen": -51.78095626831055,
      "logps/rejected": -129.36770629882812,
      "loss": 0.0204,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8402292132377625,
      "rewards/margins": 8.223301887512207,
      "rewards/rejected": -9.063530921936035,
      "step": 6795
    },
    {
      "epoch": 2.7184,
      "grad_norm": 0.48814547061920166,
      "learning_rate": 9.4e-08,
      "logits/chosen": -2.4273362159729004,
      "logits/rejected": -1.9492716789245605,
      "logps/chosen": -186.24464416503906,
      "logps/rejected": -162.6265869140625,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.4240882396698,
      "rewards/margins": 8.39928913116455,
      "rewards/rejected": -10.82337760925293,
      "step": 6796
    },
    {
      "epoch": 2.7188,
      "grad_norm": 0.2833060920238495,
      "learning_rate": 9.386666666666666e-08,
      "logits/chosen": -2.956514835357666,
      "logits/rejected": -2.4594788551330566,
      "logps/chosen": -115.307861328125,
      "logps/rejected": -119.11563110351562,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6047469973564148,
      "rewards/margins": 7.812351226806641,
      "rewards/rejected": -7.20760440826416,
      "step": 6797
    },
    {
      "epoch": 2.7192,
      "grad_norm": 0.00037944468203932047,
      "learning_rate": 9.373333333333333e-08,
      "logits/chosen": -2.352077007293701,
      "logits/rejected": -1.424360990524292,
      "logps/chosen": -73.94587707519531,
      "logps/rejected": -248.37893676757812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9915627241134644,
      "rewards/margins": 14.461931228637695,
      "rewards/rejected": -12.470369338989258,
      "step": 6798
    },
    {
      "epoch": 2.7196,
      "grad_norm": 0.008939823135733604,
      "learning_rate": 9.36e-08,
      "logits/chosen": -2.349226951599121,
      "logits/rejected": -1.8622817993164062,
      "logps/chosen": -131.90884399414062,
      "logps/rejected": -165.62893676757812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1761448085308075,
      "rewards/margins": 11.233689308166504,
      "rewards/rejected": -11.409833908081055,
      "step": 6799
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.0007156006176955998,
      "learning_rate": 9.346666666666667e-08,
      "logits/chosen": -2.854217529296875,
      "logits/rejected": -2.2822108268737793,
      "logps/chosen": -110.37026977539062,
      "logps/rejected": -206.0250244140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019326776266098022,
      "rewards/margins": 14.429749488830566,
      "rewards/rejected": -14.410423278808594,
      "step": 6800
    },
    {
      "epoch": 2.7204,
      "grad_norm": 0.024492060765624046,
      "learning_rate": 9.333333333333334e-08,
      "logits/chosen": -2.626398801803589,
      "logits/rejected": -2.2200968265533447,
      "logps/chosen": -59.560935974121094,
      "logps/rejected": -244.4427032470703,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2666994333267212,
      "rewards/margins": 15.208292007446289,
      "rewards/rejected": -13.9415922164917,
      "step": 6801
    },
    {
      "epoch": 2.7208,
      "grad_norm": 0.011006730608642101,
      "learning_rate": 9.32e-08,
      "logits/chosen": -2.700166702270508,
      "logits/rejected": -2.395643949508667,
      "logps/chosen": -34.29655456542969,
      "logps/rejected": -160.89828491210938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7058346271514893,
      "rewards/margins": 12.91285514831543,
      "rewards/rejected": -11.207019805908203,
      "step": 6802
    },
    {
      "epoch": 2.7212,
      "grad_norm": 0.00012207365944050252,
      "learning_rate": 9.306666666666667e-08,
      "logits/chosen": -2.465881824493408,
      "logits/rejected": -1.5879888534545898,
      "logps/chosen": -107.69619750976562,
      "logps/rejected": -214.5392303466797,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9813587069511414,
      "rewards/margins": 15.206937789916992,
      "rewards/rejected": -14.225579261779785,
      "step": 6803
    },
    {
      "epoch": 2.7216,
      "grad_norm": 0.008555842563509941,
      "learning_rate": 9.293333333333333e-08,
      "logits/chosen": -2.510746955871582,
      "logits/rejected": -2.0798919200897217,
      "logps/chosen": -83.97297668457031,
      "logps/rejected": -167.160888671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0744675397872925,
      "rewards/margins": 11.200678825378418,
      "rewards/rejected": -10.126211166381836,
      "step": 6804
    },
    {
      "epoch": 2.722,
      "grad_norm": 0.016203710809350014,
      "learning_rate": 9.279999999999998e-08,
      "logits/chosen": -2.806303024291992,
      "logits/rejected": -2.3873963356018066,
      "logps/chosen": -78.8348388671875,
      "logps/rejected": -164.00479125976562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2552177309989929,
      "rewards/margins": 10.588861465454102,
      "rewards/rejected": -10.333642959594727,
      "step": 6805
    },
    {
      "epoch": 2.7224,
      "grad_norm": 2.0636467933654785,
      "learning_rate": 9.266666666666666e-08,
      "logits/chosen": -3.0085039138793945,
      "logits/rejected": -2.6444344520568848,
      "logps/chosen": -59.963340759277344,
      "logps/rejected": -106.51293182373047,
      "loss": 0.0161,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6558729410171509,
      "rewards/margins": 6.636361122131348,
      "rewards/rejected": -7.292233467102051,
      "step": 6806
    },
    {
      "epoch": 2.7228,
      "grad_norm": 0.0018240581266582012,
      "learning_rate": 9.253333333333333e-08,
      "logits/chosen": -2.513718605041504,
      "logits/rejected": -2.0368847846984863,
      "logps/chosen": -99.05294036865234,
      "logps/rejected": -242.40237426757812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9164507389068604,
      "rewards/margins": 14.340330123901367,
      "rewards/rejected": -12.423879623413086,
      "step": 6807
    },
    {
      "epoch": 2.7232,
      "grad_norm": 0.026471389457583427,
      "learning_rate": 9.24e-08,
      "logits/chosen": -2.071110486984253,
      "logits/rejected": -1.6743378639221191,
      "logps/chosen": -230.2022247314453,
      "logps/rejected": -286.23065185546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2069199085235596,
      "rewards/margins": 12.227909088134766,
      "rewards/rejected": -13.43482780456543,
      "step": 6808
    },
    {
      "epoch": 2.7236000000000002,
      "grad_norm": 21.67298698425293,
      "learning_rate": 9.226666666666666e-08,
      "logits/chosen": -1.9067281484603882,
      "logits/rejected": -1.414235234260559,
      "logps/chosen": -212.28790283203125,
      "logps/rejected": -181.1223602294922,
      "loss": 0.0639,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -5.094916820526123,
      "rewards/margins": 7.2351250648498535,
      "rewards/rejected": -12.330041885375977,
      "step": 6809
    },
    {
      "epoch": 2.724,
      "grad_norm": 0.027406219393014908,
      "learning_rate": 9.213333333333332e-08,
      "logits/chosen": -2.578188896179199,
      "logits/rejected": -2.015547752380371,
      "logps/chosen": -151.82696533203125,
      "logps/rejected": -182.68624877929688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6502051949501038,
      "rewards/margins": 11.234685897827148,
      "rewards/rejected": -11.884891510009766,
      "step": 6810
    },
    {
      "epoch": 2.7244,
      "grad_norm": 0.008154373615980148,
      "learning_rate": 9.199999999999999e-08,
      "logits/chosen": -3.0950708389282227,
      "logits/rejected": -2.5087966918945312,
      "logps/chosen": -45.03230285644531,
      "logps/rejected": -147.45663452148438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21892547607421875,
      "rewards/margins": 10.30550479888916,
      "rewards/rejected": -10.086579322814941,
      "step": 6811
    },
    {
      "epoch": 2.7248,
      "grad_norm": 0.00031261375988833606,
      "learning_rate": 9.186666666666666e-08,
      "logits/chosen": -2.5675573348999023,
      "logits/rejected": -1.876173496246338,
      "logps/chosen": -129.83251953125,
      "logps/rejected": -191.84625244140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6355999112129211,
      "rewards/margins": 14.067590713500977,
      "rewards/rejected": -13.431991577148438,
      "step": 6812
    },
    {
      "epoch": 2.7252,
      "grad_norm": 1.6365787982940674,
      "learning_rate": 9.173333333333333e-08,
      "logits/chosen": -2.4815011024475098,
      "logits/rejected": -2.2350738048553467,
      "logps/chosen": -136.69326782226562,
      "logps/rejected": -142.25210571289062,
      "loss": 0.0137,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.5660593509674072,
      "rewards/margins": 5.27218770980835,
      "rewards/rejected": -7.838247299194336,
      "step": 6813
    },
    {
      "epoch": 2.7256,
      "grad_norm": 0.33540409803390503,
      "learning_rate": 9.16e-08,
      "logits/chosen": -2.3733043670654297,
      "logits/rejected": -1.9312355518341064,
      "logps/chosen": -122.3609390258789,
      "logps/rejected": -213.07809448242188,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.699502944946289,
      "rewards/margins": 10.961915969848633,
      "rewards/rejected": -12.661418914794922,
      "step": 6814
    },
    {
      "epoch": 2.726,
      "grad_norm": 0.30066412687301636,
      "learning_rate": 9.146666666666667e-08,
      "logits/chosen": -2.8870737552642822,
      "logits/rejected": -2.6134307384490967,
      "logps/chosen": -92.82678985595703,
      "logps/rejected": -136.8137969970703,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9675857424736023,
      "rewards/margins": 10.752666473388672,
      "rewards/rejected": -9.785080909729004,
      "step": 6815
    },
    {
      "epoch": 2.7264,
      "grad_norm": 0.004225675482302904,
      "learning_rate": 9.133333333333333e-08,
      "logits/chosen": -2.4770331382751465,
      "logits/rejected": -1.7276923656463623,
      "logps/chosen": -110.08966064453125,
      "logps/rejected": -209.52365112304688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5415183901786804,
      "rewards/margins": 13.388439178466797,
      "rewards/rejected": -13.929957389831543,
      "step": 6816
    },
    {
      "epoch": 2.7268,
      "grad_norm": 0.0014692971017211676,
      "learning_rate": 9.12e-08,
      "logits/chosen": -2.7052700519561768,
      "logits/rejected": -2.183774709701538,
      "logps/chosen": -99.42170715332031,
      "logps/rejected": -154.33126831054688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7286076545715332,
      "rewards/margins": 11.98738956451416,
      "rewards/rejected": -10.258781433105469,
      "step": 6817
    },
    {
      "epoch": 2.7272,
      "grad_norm": 0.007252461742609739,
      "learning_rate": 9.106666666666666e-08,
      "logits/chosen": -2.388679027557373,
      "logits/rejected": -1.9014230966567993,
      "logps/chosen": -105.25338745117188,
      "logps/rejected": -246.8951416015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.427914023399353,
      "rewards/margins": 15.431020736694336,
      "rewards/rejected": -15.003107070922852,
      "step": 6818
    },
    {
      "epoch": 2.7276,
      "grad_norm": 0.010372599586844444,
      "learning_rate": 9.093333333333334e-08,
      "logits/chosen": -2.5349137783050537,
      "logits/rejected": -2.0146827697753906,
      "logps/chosen": -120.10540008544922,
      "logps/rejected": -161.78875732421875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.037192940711975,
      "rewards/margins": 9.745965957641602,
      "rewards/rejected": -10.783158302307129,
      "step": 6819
    },
    {
      "epoch": 2.7279999999999998,
      "grad_norm": 0.28208795189857483,
      "learning_rate": 9.08e-08,
      "logits/chosen": -2.303079128265381,
      "logits/rejected": -1.7719372510910034,
      "logps/chosen": -149.59344482421875,
      "logps/rejected": -221.10450744628906,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.979813098907471,
      "rewards/margins": 9.667420387268066,
      "rewards/rejected": -14.647233963012695,
      "step": 6820
    },
    {
      "epoch": 2.7284,
      "grad_norm": 0.00219100434333086,
      "learning_rate": 9.066666666666667e-08,
      "logits/chosen": -3.1270556449890137,
      "logits/rejected": -2.521420478820801,
      "logps/chosen": -68.14494323730469,
      "logps/rejected": -154.01617431640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42202264070510864,
      "rewards/margins": 11.893077850341797,
      "rewards/rejected": -11.471055030822754,
      "step": 6821
    },
    {
      "epoch": 2.7288,
      "grad_norm": 0.005615494213998318,
      "learning_rate": 9.053333333333332e-08,
      "logits/chosen": -2.4739439487457275,
      "logits/rejected": -1.8985655307769775,
      "logps/chosen": -86.78984069824219,
      "logps/rejected": -218.79592895507812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.022242784500122,
      "rewards/margins": 14.892813682556152,
      "rewards/rejected": -13.87057113647461,
      "step": 6822
    },
    {
      "epoch": 2.7292,
      "grad_norm": 0.00017839322390500456,
      "learning_rate": 9.039999999999999e-08,
      "logits/chosen": -2.446554660797119,
      "logits/rejected": -2.062504768371582,
      "logps/chosen": -84.93965148925781,
      "logps/rejected": -260.71697998046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0370335578918457,
      "rewards/margins": 15.094854354858398,
      "rewards/rejected": -13.057820320129395,
      "step": 6823
    },
    {
      "epoch": 2.7296,
      "grad_norm": 0.014065214432775974,
      "learning_rate": 9.026666666666665e-08,
      "logits/chosen": -2.705075740814209,
      "logits/rejected": -2.1045851707458496,
      "logps/chosen": -159.2084503173828,
      "logps/rejected": -177.77963256835938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8562290668487549,
      "rewards/margins": 9.648544311523438,
      "rewards/rejected": -11.50477409362793,
      "step": 6824
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.0006958022131584585,
      "learning_rate": 9.013333333333332e-08,
      "logits/chosen": -2.085554599761963,
      "logits/rejected": -1.8382573127746582,
      "logps/chosen": -145.05038452148438,
      "logps/rejected": -197.6278076171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3112244606018066,
      "rewards/margins": 13.169918060302734,
      "rewards/rejected": -11.858694076538086,
      "step": 6825
    },
    {
      "epoch": 2.7304,
      "grad_norm": 0.6213076114654541,
      "learning_rate": 9e-08,
      "logits/chosen": -2.5718936920166016,
      "logits/rejected": -2.404388427734375,
      "logps/chosen": -111.54729461669922,
      "logps/rejected": -138.52618408203125,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.3505351543426514,
      "rewards/margins": 6.653688430786133,
      "rewards/rejected": -9.004222869873047,
      "step": 6826
    },
    {
      "epoch": 2.7308,
      "grad_norm": 0.0010581688256934285,
      "learning_rate": 8.986666666666666e-08,
      "logits/chosen": -2.24043607711792,
      "logits/rejected": -1.681903600692749,
      "logps/chosen": -104.70935821533203,
      "logps/rejected": -291.830078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.306649088859558,
      "rewards/margins": 13.09300422668457,
      "rewards/rejected": -11.786355018615723,
      "step": 6827
    },
    {
      "epoch": 2.7312,
      "grad_norm": 1.280962586402893,
      "learning_rate": 8.973333333333333e-08,
      "logits/chosen": -2.7452943325042725,
      "logits/rejected": -2.2645769119262695,
      "logps/chosen": -105.9764633178711,
      "logps/rejected": -141.62376403808594,
      "loss": 0.0077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9139358401298523,
      "rewards/margins": 9.905509948730469,
      "rewards/rejected": -8.99157428741455,
      "step": 6828
    },
    {
      "epoch": 2.7316000000000003,
      "grad_norm": 0.017840968444943428,
      "learning_rate": 8.96e-08,
      "logits/chosen": -2.8517141342163086,
      "logits/rejected": -2.647172212600708,
      "logps/chosen": -62.68585968017578,
      "logps/rejected": -144.26983642578125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.573607325553894,
      "rewards/margins": 9.586612701416016,
      "rewards/rejected": -8.013006210327148,
      "step": 6829
    },
    {
      "epoch": 2.732,
      "grad_norm": 0.09346188604831696,
      "learning_rate": 8.946666666666666e-08,
      "logits/chosen": -2.482771873474121,
      "logits/rejected": -2.1183316707611084,
      "logps/chosen": -86.03758239746094,
      "logps/rejected": -127.36084747314453,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7579193115234375,
      "rewards/margins": 8.51865291595459,
      "rewards/rejected": -9.276572227478027,
      "step": 6830
    },
    {
      "epoch": 2.7324,
      "grad_norm": 0.06837595999240875,
      "learning_rate": 8.933333333333333e-08,
      "logits/chosen": -2.0642359256744385,
      "logits/rejected": -1.4510133266448975,
      "logps/chosen": -185.1357879638672,
      "logps/rejected": -226.63323974609375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.8413963317871094,
      "rewards/margins": 9.693452835083008,
      "rewards/rejected": -12.534849166870117,
      "step": 6831
    },
    {
      "epoch": 2.7328,
      "grad_norm": 44.43536376953125,
      "learning_rate": 8.919999999999999e-08,
      "logits/chosen": -2.3502187728881836,
      "logits/rejected": -2.101861000061035,
      "logps/chosen": -192.17840576171875,
      "logps/rejected": -133.26132202148438,
      "loss": 0.1778,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.250368356704712,
      "rewards/margins": 3.67533016204834,
      "rewards/rejected": -6.925698280334473,
      "step": 6832
    },
    {
      "epoch": 2.7332,
      "grad_norm": 0.032130345702171326,
      "learning_rate": 8.906666666666667e-08,
      "logits/chosen": -2.9120092391967773,
      "logits/rejected": -2.606233596801758,
      "logps/chosen": -60.85153579711914,
      "logps/rejected": -127.27146911621094,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.845140814781189,
      "rewards/margins": 9.13405990600586,
      "rewards/rejected": -8.288919448852539,
      "step": 6833
    },
    {
      "epoch": 2.7336,
      "grad_norm": 0.06324989348649979,
      "learning_rate": 8.893333333333334e-08,
      "logits/chosen": -2.837890386581421,
      "logits/rejected": -2.521402359008789,
      "logps/chosen": -41.258575439453125,
      "logps/rejected": -126.6555404663086,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.035064697265625,
      "rewards/margins": 8.116632461547852,
      "rewards/rejected": -8.151698112487793,
      "step": 6834
    },
    {
      "epoch": 2.734,
      "grad_norm": 0.045049551874399185,
      "learning_rate": 8.88e-08,
      "logits/chosen": -2.530780792236328,
      "logits/rejected": -1.8964526653289795,
      "logps/chosen": -81.48896026611328,
      "logps/rejected": -193.34158325195312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.36899513006210327,
      "rewards/margins": 12.211187362670898,
      "rewards/rejected": -11.842191696166992,
      "step": 6835
    },
    {
      "epoch": 2.7344,
      "grad_norm": 0.002127068117260933,
      "learning_rate": 8.866666666666667e-08,
      "logits/chosen": -2.3556628227233887,
      "logits/rejected": -1.8368151187896729,
      "logps/chosen": -139.6438751220703,
      "logps/rejected": -191.0438232421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.48440250754356384,
      "rewards/margins": 12.47067642211914,
      "rewards/rejected": -11.986273765563965,
      "step": 6836
    },
    {
      "epoch": 2.7348,
      "grad_norm": 0.00013608769222628325,
      "learning_rate": 8.853333333333333e-08,
      "logits/chosen": -2.4289724826812744,
      "logits/rejected": -1.5326176881790161,
      "logps/chosen": -89.43219757080078,
      "logps/rejected": -215.74734497070312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.10215163230896,
      "rewards/margins": 15.221027374267578,
      "rewards/rejected": -14.118875503540039,
      "step": 6837
    },
    {
      "epoch": 2.7352,
      "grad_norm": 0.009682843461632729,
      "learning_rate": 8.84e-08,
      "logits/chosen": -3.006887912750244,
      "logits/rejected": -2.4722278118133545,
      "logps/chosen": -57.29273986816406,
      "logps/rejected": -171.03280639648438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06426846981048584,
      "rewards/margins": 10.957769393920898,
      "rewards/rejected": -10.893501281738281,
      "step": 6838
    },
    {
      "epoch": 2.7356,
      "grad_norm": 0.31882423162460327,
      "learning_rate": 8.826666666666665e-08,
      "logits/chosen": -2.903474807739258,
      "logits/rejected": -2.726504325866699,
      "logps/chosen": -42.4509391784668,
      "logps/rejected": -125.33409881591797,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09948769211769104,
      "rewards/margins": 8.039193153381348,
      "rewards/rejected": -7.939704895019531,
      "step": 6839
    },
    {
      "epoch": 2.7359999999999998,
      "grad_norm": 0.06466018408536911,
      "learning_rate": 8.813333333333333e-08,
      "logits/chosen": -2.4231784343719482,
      "logits/rejected": -1.6469268798828125,
      "logps/chosen": -101.93773651123047,
      "logps/rejected": -133.84408569335938,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3600612878799438,
      "rewards/margins": 10.998077392578125,
      "rewards/rejected": -9.638015747070312,
      "step": 6840
    },
    {
      "epoch": 2.7364,
      "grad_norm": 0.0003156290331389755,
      "learning_rate": 8.8e-08,
      "logits/chosen": -2.377648115158081,
      "logits/rejected": -1.5584986209869385,
      "logps/chosen": -112.68577575683594,
      "logps/rejected": -356.90484619140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.846266508102417,
      "rewards/margins": 16.061527252197266,
      "rewards/rejected": -14.21526050567627,
      "step": 6841
    },
    {
      "epoch": 2.7368,
      "grad_norm": 0.0005684306961484253,
      "learning_rate": 8.786666666666666e-08,
      "logits/chosen": -2.552957534790039,
      "logits/rejected": -1.7371888160705566,
      "logps/chosen": -71.54584503173828,
      "logps/rejected": -202.35549926757812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.279707908630371,
      "rewards/margins": 13.934234619140625,
      "rewards/rejected": -12.65452766418457,
      "step": 6842
    },
    {
      "epoch": 2.7372,
      "grad_norm": 0.0916055291891098,
      "learning_rate": 8.773333333333332e-08,
      "logits/chosen": -2.6995041370391846,
      "logits/rejected": -2.322282552719116,
      "logps/chosen": -116.88491821289062,
      "logps/rejected": -130.48812866210938,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6796581149101257,
      "rewards/margins": 8.242358207702637,
      "rewards/rejected": -8.922016143798828,
      "step": 6843
    },
    {
      "epoch": 2.7376,
      "grad_norm": 0.0005762471701018512,
      "learning_rate": 8.759999999999999e-08,
      "logits/chosen": -2.36978816986084,
      "logits/rejected": -1.6569262742996216,
      "logps/chosen": -94.3226318359375,
      "logps/rejected": -258.63848876953125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6789645552635193,
      "rewards/margins": 15.483694076538086,
      "rewards/rejected": -14.804728507995605,
      "step": 6844
    },
    {
      "epoch": 2.738,
      "grad_norm": 0.14146165549755096,
      "learning_rate": 8.746666666666666e-08,
      "logits/chosen": -2.6882243156433105,
      "logits/rejected": -2.11057448387146,
      "logps/chosen": -84.68074035644531,
      "logps/rejected": -280.3847351074219,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7808201313018799,
      "rewards/margins": 13.753862380981445,
      "rewards/rejected": -11.973042488098145,
      "step": 6845
    },
    {
      "epoch": 2.7384,
      "grad_norm": 0.21779482066631317,
      "learning_rate": 8.733333333333333e-08,
      "logits/chosen": -2.582930564880371,
      "logits/rejected": -2.5667104721069336,
      "logps/chosen": -35.928279876708984,
      "logps/rejected": -104.27425384521484,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5174258351325989,
      "rewards/margins": 7.585929870605469,
      "rewards/rejected": -7.0685038566589355,
      "step": 6846
    },
    {
      "epoch": 2.7388,
      "grad_norm": 0.4124477803707123,
      "learning_rate": 8.72e-08,
      "logits/chosen": -2.7623910903930664,
      "logits/rejected": -2.5582056045532227,
      "logps/chosen": -84.17338562011719,
      "logps/rejected": -107.23353576660156,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7713130712509155,
      "rewards/margins": 5.696730136871338,
      "rewards/rejected": -6.468043327331543,
      "step": 6847
    },
    {
      "epoch": 2.7392,
      "grad_norm": 0.11164020001888275,
      "learning_rate": 8.706666666666667e-08,
      "logits/chosen": -2.7878987789154053,
      "logits/rejected": -2.0031793117523193,
      "logps/chosen": -47.88957977294922,
      "logps/rejected": -153.36160278320312,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2160520553588867,
      "rewards/margins": 12.650042533874512,
      "rewards/rejected": -11.433990478515625,
      "step": 6848
    },
    {
      "epoch": 2.7396000000000003,
      "grad_norm": 0.44594651460647583,
      "learning_rate": 8.693333333333333e-08,
      "logits/chosen": -2.6575746536254883,
      "logits/rejected": -2.4482147693634033,
      "logps/chosen": -156.38616943359375,
      "logps/rejected": -118.96519470214844,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3819512128829956,
      "rewards/margins": 6.031229019165039,
      "rewards/rejected": -7.413180351257324,
      "step": 6849
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.01742185465991497,
      "learning_rate": 8.68e-08,
      "logits/chosen": -2.888972759246826,
      "logits/rejected": -2.488276481628418,
      "logps/chosen": -108.89840698242188,
      "logps/rejected": -153.87765502929688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.040081024169921875,
      "rewards/margins": 9.665298461914062,
      "rewards/rejected": -9.62521743774414,
      "step": 6850
    },
    {
      "epoch": 2.7404,
      "grad_norm": 0.04501523822546005,
      "learning_rate": 8.666666666666666e-08,
      "logits/chosen": -2.330136299133301,
      "logits/rejected": -1.9964263439178467,
      "logps/chosen": -64.46408081054688,
      "logps/rejected": -114.1016845703125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9816467761993408,
      "rewards/margins": 9.532586097717285,
      "rewards/rejected": -7.550939559936523,
      "step": 6851
    },
    {
      "epoch": 2.7408,
      "grad_norm": 2.6713385523180477e-05,
      "learning_rate": 8.653333333333333e-08,
      "logits/chosen": -2.7852671146392822,
      "logits/rejected": -1.930222988128662,
      "logps/chosen": -84.3332748413086,
      "logps/rejected": -215.93392944335938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.872395396232605,
      "rewards/margins": 17.22179412841797,
      "rewards/rejected": -15.34939956665039,
      "step": 6852
    },
    {
      "epoch": 2.7412,
      "grad_norm": 0.3439767062664032,
      "learning_rate": 8.64e-08,
      "logits/chosen": -2.6864354610443115,
      "logits/rejected": -1.9228979349136353,
      "logps/chosen": -57.096946716308594,
      "logps/rejected": -201.58001708984375,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6297193765640259,
      "rewards/margins": 9.12206745147705,
      "rewards/rejected": -9.751786231994629,
      "step": 6853
    },
    {
      "epoch": 2.7416,
      "grad_norm": 0.004428504966199398,
      "learning_rate": 8.626666666666667e-08,
      "logits/chosen": -2.625322103500366,
      "logits/rejected": -2.3979029655456543,
      "logps/chosen": -140.0983123779297,
      "logps/rejected": -201.71531677246094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11726532131433487,
      "rewards/margins": 12.66971492767334,
      "rewards/rejected": -12.552450180053711,
      "step": 6854
    },
    {
      "epoch": 2.742,
      "grad_norm": 0.12940554320812225,
      "learning_rate": 8.613333333333334e-08,
      "logits/chosen": -2.3767518997192383,
      "logits/rejected": -1.9474713802337646,
      "logps/chosen": -154.41299438476562,
      "logps/rejected": -192.09561157226562,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.280667543411255,
      "rewards/margins": 9.676863670349121,
      "rewards/rejected": -11.957530975341797,
      "step": 6855
    },
    {
      "epoch": 2.7424,
      "grad_norm": 0.016680799424648285,
      "learning_rate": 8.599999999999999e-08,
      "logits/chosen": -2.482755661010742,
      "logits/rejected": -1.8647456169128418,
      "logps/chosen": -123.351806640625,
      "logps/rejected": -188.29998779296875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4874660968780518,
      "rewards/margins": 12.222158432006836,
      "rewards/rejected": -10.734691619873047,
      "step": 6856
    },
    {
      "epoch": 2.7428,
      "grad_norm": 0.023352742195129395,
      "learning_rate": 8.586666666666665e-08,
      "logits/chosen": -2.397855758666992,
      "logits/rejected": -1.936065435409546,
      "logps/chosen": -78.46058654785156,
      "logps/rejected": -199.13641357421875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.711286187171936,
      "rewards/margins": 13.57798957824707,
      "rewards/rejected": -11.866703033447266,
      "step": 6857
    },
    {
      "epoch": 2.7432,
      "grad_norm": 0.1443151980638504,
      "learning_rate": 8.573333333333332e-08,
      "logits/chosen": -2.5482585430145264,
      "logits/rejected": -1.7877638339996338,
      "logps/chosen": -144.62109375,
      "logps/rejected": -177.6961669921875,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9757499694824219,
      "rewards/margins": 9.96670913696289,
      "rewards/rejected": -10.942459106445312,
      "step": 6858
    },
    {
      "epoch": 2.7436,
      "grad_norm": 0.19264933466911316,
      "learning_rate": 8.559999999999999e-08,
      "logits/chosen": -2.4684863090515137,
      "logits/rejected": -2.2813122272491455,
      "logps/chosen": -147.99496459960938,
      "logps/rejected": -134.77281188964844,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8880455493927002,
      "rewards/margins": 7.559503555297852,
      "rewards/rejected": -9.447549819946289,
      "step": 6859
    },
    {
      "epoch": 2.7439999999999998,
      "grad_norm": 0.0003610336279962212,
      "learning_rate": 8.546666666666666e-08,
      "logits/chosen": -2.66292142868042,
      "logits/rejected": -2.1758835315704346,
      "logps/chosen": -84.76416015625,
      "logps/rejected": -184.12283325195312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20334701240062714,
      "rewards/margins": 13.564001083374023,
      "rewards/rejected": -13.360654830932617,
      "step": 6860
    },
    {
      "epoch": 2.7443999999999997,
      "grad_norm": 0.001869960455223918,
      "learning_rate": 8.533333333333333e-08,
      "logits/chosen": -2.5765552520751953,
      "logits/rejected": -1.9261486530303955,
      "logps/chosen": -58.82464599609375,
      "logps/rejected": -168.3046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2273495197296143,
      "rewards/margins": 11.992992401123047,
      "rewards/rejected": -9.765642166137695,
      "step": 6861
    },
    {
      "epoch": 2.7448,
      "grad_norm": 0.010781819000840187,
      "learning_rate": 8.52e-08,
      "logits/chosen": -2.7707018852233887,
      "logits/rejected": -2.3815577030181885,
      "logps/chosen": -53.35602951049805,
      "logps/rejected": -155.7256622314453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.38265204429626465,
      "rewards/margins": 10.181611061096191,
      "rewards/rejected": -10.564263343811035,
      "step": 6862
    },
    {
      "epoch": 2.7452,
      "grad_norm": 0.1644962579011917,
      "learning_rate": 8.506666666666666e-08,
      "logits/chosen": -2.384347915649414,
      "logits/rejected": -2.080216884613037,
      "logps/chosen": -114.86805725097656,
      "logps/rejected": -163.3415985107422,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3600410223007202,
      "rewards/margins": 9.092060089111328,
      "rewards/rejected": -10.45210075378418,
      "step": 6863
    },
    {
      "epoch": 2.7456,
      "grad_norm": 0.21097615361213684,
      "learning_rate": 8.493333333333333e-08,
      "logits/chosen": -2.7001490592956543,
      "logits/rejected": -2.448810338973999,
      "logps/chosen": -61.89170455932617,
      "logps/rejected": -87.63874053955078,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6602249145507812,
      "rewards/margins": 6.7190656661987305,
      "rewards/rejected": -6.058840751647949,
      "step": 6864
    },
    {
      "epoch": 2.746,
      "grad_norm": 1.6253180503845215,
      "learning_rate": 8.479999999999999e-08,
      "logits/chosen": -2.458178997039795,
      "logits/rejected": -2.1522183418273926,
      "logps/chosen": -158.73779296875,
      "logps/rejected": -178.1718292236328,
      "loss": 0.0113,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -5.318930149078369,
      "rewards/margins": 4.993576526641846,
      "rewards/rejected": -10.312506675720215,
      "step": 6865
    },
    {
      "epoch": 2.7464,
      "grad_norm": 0.000512900238391012,
      "learning_rate": 8.466666666666667e-08,
      "logits/chosen": -2.6946206092834473,
      "logits/rejected": -1.692256212234497,
      "logps/chosen": -77.51499938964844,
      "logps/rejected": -217.99984741210938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2563488483428955,
      "rewards/margins": 14.256423950195312,
      "rewards/rejected": -13.00007438659668,
      "step": 6866
    },
    {
      "epoch": 2.7468,
      "grad_norm": 0.004003727808594704,
      "learning_rate": 8.453333333333334e-08,
      "logits/chosen": -2.617513656616211,
      "logits/rejected": -1.9240167140960693,
      "logps/chosen": -89.8355941772461,
      "logps/rejected": -234.59814453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0398447513580322,
      "rewards/margins": 12.165966033935547,
      "rewards/rejected": -11.126121520996094,
      "step": 6867
    },
    {
      "epoch": 2.7472,
      "grad_norm": 0.19046254456043243,
      "learning_rate": 8.44e-08,
      "logits/chosen": -2.6700801849365234,
      "logits/rejected": -2.664485454559326,
      "logps/chosen": -131.0556182861328,
      "logps/rejected": -132.51846313476562,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.089047908782959,
      "rewards/margins": 6.783773899078369,
      "rewards/rejected": -9.872821807861328,
      "step": 6868
    },
    {
      "epoch": 2.7476000000000003,
      "grad_norm": 5.745827820646809e-06,
      "learning_rate": 8.426666666666667e-08,
      "logits/chosen": -2.596391439437866,
      "logits/rejected": -1.701944351196289,
      "logps/chosen": -111.47207641601562,
      "logps/rejected": -258.60308837890625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8034489154815674,
      "rewards/margins": 18.459733963012695,
      "rewards/rejected": -16.65628433227539,
      "step": 6869
    },
    {
      "epoch": 2.748,
      "grad_norm": 0.001577889546751976,
      "learning_rate": 8.413333333333333e-08,
      "logits/chosen": -2.143958568572998,
      "logits/rejected": -1.2541868686676025,
      "logps/chosen": -178.33389282226562,
      "logps/rejected": -203.06288146972656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1657302975654602,
      "rewards/margins": 13.255701065063477,
      "rewards/rejected": -13.421432495117188,
      "step": 6870
    },
    {
      "epoch": 2.7484,
      "grad_norm": 0.006533872336149216,
      "learning_rate": 8.4e-08,
      "logits/chosen": -2.677786111831665,
      "logits/rejected": -2.3597412109375,
      "logps/chosen": -71.30685424804688,
      "logps/rejected": -147.45840454101562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.865094006061554,
      "rewards/margins": 10.317307472229004,
      "rewards/rejected": -9.452213287353516,
      "step": 6871
    },
    {
      "epoch": 2.7488,
      "grad_norm": 0.06851751357316971,
      "learning_rate": 8.386666666666666e-08,
      "logits/chosen": -2.868607521057129,
      "logits/rejected": -2.9756128787994385,
      "logps/chosen": -44.98358154296875,
      "logps/rejected": -113.65186309814453,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1116521805524826,
      "rewards/margins": 7.6272430419921875,
      "rewards/rejected": -7.738894939422607,
      "step": 6872
    },
    {
      "epoch": 2.7492,
      "grad_norm": 7.152432441711426,
      "learning_rate": 8.373333333333334e-08,
      "logits/chosen": -2.59210205078125,
      "logits/rejected": -2.6149003505706787,
      "logps/chosen": -102.706787109375,
      "logps/rejected": -88.30876922607422,
      "loss": 0.0314,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9835033416748047,
      "rewards/margins": 5.079124450683594,
      "rewards/rejected": -6.062627792358398,
      "step": 6873
    },
    {
      "epoch": 2.7496,
      "grad_norm": 0.002114545553922653,
      "learning_rate": 8.36e-08,
      "logits/chosen": -2.5118160247802734,
      "logits/rejected": -1.8635387420654297,
      "logps/chosen": -85.39457702636719,
      "logps/rejected": -157.0616455078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.193451404571533,
      "rewards/margins": 13.413839340209961,
      "rewards/rejected": -11.22038745880127,
      "step": 6874
    },
    {
      "epoch": 2.75,
      "grad_norm": 13.764509201049805,
      "learning_rate": 8.346666666666666e-08,
      "logits/chosen": -1.9295637607574463,
      "logits/rejected": -1.4509673118591309,
      "logps/chosen": -271.2508544921875,
      "logps/rejected": -239.76010131835938,
      "loss": 0.0571,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.558813571929932,
      "rewards/margins": 7.228812217712402,
      "rewards/rejected": -11.787626266479492,
      "step": 6875
    },
    {
      "epoch": 2.7504,
      "grad_norm": 0.0036746314726769924,
      "learning_rate": 8.333333333333333e-08,
      "logits/chosen": -2.7162866592407227,
      "logits/rejected": -2.229923725128174,
      "logps/chosen": -75.06536865234375,
      "logps/rejected": -137.49569702148438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6636524200439453,
      "rewards/margins": 10.777872085571289,
      "rewards/rejected": -10.114219665527344,
      "step": 6876
    },
    {
      "epoch": 2.7508,
      "grad_norm": 0.43903249502182007,
      "learning_rate": 8.319999999999999e-08,
      "logits/chosen": -2.730740547180176,
      "logits/rejected": -2.0783488750457764,
      "logps/chosen": -77.58979797363281,
      "logps/rejected": -122.10086822509766,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2638968825340271,
      "rewards/margins": 7.95969295501709,
      "rewards/rejected": -8.223589897155762,
      "step": 6877
    },
    {
      "epoch": 2.7512,
      "grad_norm": 0.00011759229528252035,
      "learning_rate": 8.306666666666666e-08,
      "logits/chosen": -2.5156445503234863,
      "logits/rejected": -2.0990335941314697,
      "logps/chosen": -104.7523193359375,
      "logps/rejected": -251.4471893310547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8698421716690063,
      "rewards/margins": 15.088750839233398,
      "rewards/rejected": -14.218908309936523,
      "step": 6878
    },
    {
      "epoch": 2.7516,
      "grad_norm": 4.0932598494691774e-05,
      "learning_rate": 8.293333333333332e-08,
      "logits/chosen": -2.558393716812134,
      "logits/rejected": -1.6979870796203613,
      "logps/chosen": -89.82342529296875,
      "logps/rejected": -223.0689697265625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9937107563018799,
      "rewards/margins": 16.151443481445312,
      "rewards/rejected": -15.157733917236328,
      "step": 6879
    },
    {
      "epoch": 2.752,
      "grad_norm": 0.019977092742919922,
      "learning_rate": 8.28e-08,
      "logits/chosen": -2.8633785247802734,
      "logits/rejected": -2.215208053588867,
      "logps/chosen": -87.55650329589844,
      "logps/rejected": -199.7698211669922,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.007823526859283447,
      "rewards/margins": 13.55004596710205,
      "rewards/rejected": -13.54222297668457,
      "step": 6880
    },
    {
      "epoch": 2.7523999999999997,
      "grad_norm": 0.0003897963906638324,
      "learning_rate": 8.266666666666667e-08,
      "logits/chosen": -2.6183600425720215,
      "logits/rejected": -2.0244388580322266,
      "logps/chosen": -96.5582046508789,
      "logps/rejected": -221.04946899414062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2139884978532791,
      "rewards/margins": 15.56437873840332,
      "rewards/rejected": -15.350391387939453,
      "step": 6881
    },
    {
      "epoch": 2.7528,
      "grad_norm": 0.6673542261123657,
      "learning_rate": 8.253333333333333e-08,
      "logits/chosen": -2.612311840057373,
      "logits/rejected": -2.0415189266204834,
      "logps/chosen": -94.13945007324219,
      "logps/rejected": -124.25650024414062,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6374400854110718,
      "rewards/margins": 9.303923606872559,
      "rewards/rejected": -8.666482925415039,
      "step": 6882
    },
    {
      "epoch": 2.7532,
      "grad_norm": 0.21515405178070068,
      "learning_rate": 8.24e-08,
      "logits/chosen": -2.8428306579589844,
      "logits/rejected": -2.5460267066955566,
      "logps/chosen": -83.90379333496094,
      "logps/rejected": -115.22120666503906,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7919935584068298,
      "rewards/margins": 6.948421478271484,
      "rewards/rejected": -7.740414619445801,
      "step": 6883
    },
    {
      "epoch": 2.7536,
      "grad_norm": 0.005581941921263933,
      "learning_rate": 8.226666666666666e-08,
      "logits/chosen": -2.9199156761169434,
      "logits/rejected": -2.415067672729492,
      "logps/chosen": -76.4083251953125,
      "logps/rejected": -161.89495849609375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.201208472251892,
      "rewards/margins": 11.958887100219727,
      "rewards/rejected": -10.757678985595703,
      "step": 6884
    },
    {
      "epoch": 2.754,
      "grad_norm": 0.03316618874669075,
      "learning_rate": 8.213333333333333e-08,
      "logits/chosen": -2.190046787261963,
      "logits/rejected": -1.887963891029358,
      "logps/chosen": -117.33927154541016,
      "logps/rejected": -165.48992919921875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.11184578388929367,
      "rewards/margins": 10.336925506591797,
      "rewards/rejected": -10.448770523071289,
      "step": 6885
    },
    {
      "epoch": 2.7544,
      "grad_norm": 0.009524990804493427,
      "learning_rate": 8.2e-08,
      "logits/chosen": -2.5406322479248047,
      "logits/rejected": -2.056936264038086,
      "logps/chosen": -117.53594207763672,
      "logps/rejected": -168.54457092285156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3569785952568054,
      "rewards/margins": 10.77226448059082,
      "rewards/rejected": -10.41528606414795,
      "step": 6886
    },
    {
      "epoch": 2.7548,
      "grad_norm": 0.9970575571060181,
      "learning_rate": 8.186666666666667e-08,
      "logits/chosen": -2.525634288787842,
      "logits/rejected": -2.539008140563965,
      "logps/chosen": -125.34478759765625,
      "logps/rejected": -136.38494873046875,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4105769991874695,
      "rewards/margins": 8.239675521850586,
      "rewards/rejected": -7.829099178314209,
      "step": 6887
    },
    {
      "epoch": 2.7552,
      "grad_norm": 1.1703065633773804,
      "learning_rate": 8.173333333333334e-08,
      "logits/chosen": -2.8196356296539307,
      "logits/rejected": -2.606527328491211,
      "logps/chosen": -54.343360900878906,
      "logps/rejected": -119.49755096435547,
      "loss": 0.0049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3639459609985352,
      "rewards/margins": 9.404999732971191,
      "rewards/rejected": -8.041053771972656,
      "step": 6888
    },
    {
      "epoch": 2.7556000000000003,
      "grad_norm": 0.5361005663871765,
      "learning_rate": 8.16e-08,
      "logits/chosen": -2.367985248565674,
      "logits/rejected": -1.759153127670288,
      "logps/chosen": -225.96368408203125,
      "logps/rejected": -153.7312469482422,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8057034015655518,
      "rewards/margins": 8.125405311584473,
      "rewards/rejected": -9.931108474731445,
      "step": 6889
    },
    {
      "epoch": 2.7560000000000002,
      "grad_norm": 0.04820888116955757,
      "learning_rate": 8.146666666666667e-08,
      "logits/chosen": -2.817788600921631,
      "logits/rejected": -2.3300089836120605,
      "logps/chosen": -69.255859375,
      "logps/rejected": -123.54310607910156,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31776389479637146,
      "rewards/margins": 8.640743255615234,
      "rewards/rejected": -8.322979927062988,
      "step": 6890
    },
    {
      "epoch": 2.7564,
      "grad_norm": 0.6573190093040466,
      "learning_rate": 8.133333333333332e-08,
      "logits/chosen": -2.5745270252227783,
      "logits/rejected": -2.5852818489074707,
      "logps/chosen": -101.76292419433594,
      "logps/rejected": -97.03068542480469,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2948295474052429,
      "rewards/margins": 6.098082542419434,
      "rewards/rejected": -6.392911911010742,
      "step": 6891
    },
    {
      "epoch": 2.7568,
      "grad_norm": 0.005715031176805496,
      "learning_rate": 8.119999999999999e-08,
      "logits/chosen": -2.4895687103271484,
      "logits/rejected": -2.113450050354004,
      "logps/chosen": -154.94186401367188,
      "logps/rejected": -199.96563720703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0621094703674316,
      "rewards/margins": 12.42664909362793,
      "rewards/rejected": -14.488758087158203,
      "step": 6892
    },
    {
      "epoch": 2.7572,
      "grad_norm": 7.141553851397475e-06,
      "learning_rate": 8.106666666666666e-08,
      "logits/chosen": -1.9922354221343994,
      "logits/rejected": -1.530794620513916,
      "logps/chosen": -89.3871078491211,
      "logps/rejected": -337.9915771484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4115946292877197,
      "rewards/margins": 19.95470428466797,
      "rewards/rejected": -18.543109893798828,
      "step": 6893
    },
    {
      "epoch": 2.7576,
      "grad_norm": 3.5226999898441136e-05,
      "learning_rate": 8.093333333333333e-08,
      "logits/chosen": -2.585920810699463,
      "logits/rejected": -1.781457543373108,
      "logps/chosen": -49.14115524291992,
      "logps/rejected": -209.4240264892578,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1257307529449463,
      "rewards/margins": 16.118099212646484,
      "rewards/rejected": -13.992366790771484,
      "step": 6894
    },
    {
      "epoch": 2.758,
      "grad_norm": 0.0024177280720323324,
      "learning_rate": 8.08e-08,
      "logits/chosen": -2.431102991104126,
      "logits/rejected": -1.7534196376800537,
      "logps/chosen": -147.23538208007812,
      "logps/rejected": -166.64804077148438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5231910347938538,
      "rewards/margins": 11.885218620300293,
      "rewards/rejected": -11.362028121948242,
      "step": 6895
    },
    {
      "epoch": 2.7584,
      "grad_norm": 0.0032283037435263395,
      "learning_rate": 8.066666666666666e-08,
      "logits/chosen": -2.453850269317627,
      "logits/rejected": -1.907228708267212,
      "logps/chosen": -120.18518829345703,
      "logps/rejected": -259.3178405761719,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7316250801086426,
      "rewards/margins": 13.933229446411133,
      "rewards/rejected": -15.664855003356934,
      "step": 6896
    },
    {
      "epoch": 2.7588,
      "grad_norm": 0.072905033826828,
      "learning_rate": 8.053333333333333e-08,
      "logits/chosen": -2.5931644439697266,
      "logits/rejected": -2.322096109390259,
      "logps/chosen": -56.685733795166016,
      "logps/rejected": -123.55752563476562,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0858447551727295,
      "rewards/margins": 9.206472396850586,
      "rewards/rejected": -8.120627403259277,
      "step": 6897
    },
    {
      "epoch": 2.7592,
      "grad_norm": 0.25975480675697327,
      "learning_rate": 8.039999999999999e-08,
      "logits/chosen": -2.509066104888916,
      "logits/rejected": -2.4305853843688965,
      "logps/chosen": -135.30996704101562,
      "logps/rejected": -144.70223999023438,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.296087622642517,
      "rewards/margins": 7.562441349029541,
      "rewards/rejected": -8.858529090881348,
      "step": 6898
    },
    {
      "epoch": 2.7596,
      "grad_norm": 0.010077819228172302,
      "learning_rate": 8.026666666666666e-08,
      "logits/chosen": -2.6035938262939453,
      "logits/rejected": -2.650834560394287,
      "logps/chosen": -95.55816650390625,
      "logps/rejected": -150.93113708496094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1344661712646484,
      "rewards/margins": 10.571501731872559,
      "rewards/rejected": -9.43703556060791,
      "step": 6899
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.0032309438101947308,
      "learning_rate": 8.013333333333334e-08,
      "logits/chosen": -2.2203116416931152,
      "logits/rejected": -1.8499603271484375,
      "logps/chosen": -135.27488708496094,
      "logps/rejected": -203.2236785888672,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4424175024032593,
      "rewards/margins": 13.188407897949219,
      "rewards/rejected": -11.745989799499512,
      "step": 6900
    },
    {
      "epoch": 2.7603999999999997,
      "grad_norm": 0.20031751692295074,
      "learning_rate": 8e-08,
      "logits/chosen": -2.6331942081451416,
      "logits/rejected": -1.9801287651062012,
      "logps/chosen": -91.92367553710938,
      "logps/rejected": -162.59573364257812,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2191704511642456,
      "rewards/margins": 11.081716537475586,
      "rewards/rejected": -9.86254596710205,
      "step": 6901
    },
    {
      "epoch": 2.7608,
      "grad_norm": 0.15025705099105835,
      "learning_rate": 7.986666666666667e-08,
      "logits/chosen": -2.5290427207946777,
      "logits/rejected": -2.241729497909546,
      "logps/chosen": -116.62352752685547,
      "logps/rejected": -161.4131317138672,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3679050803184509,
      "rewards/margins": 9.67709732055664,
      "rewards/rejected": -10.045001983642578,
      "step": 6902
    },
    {
      "epoch": 2.7612,
      "grad_norm": 0.0025333473458886147,
      "learning_rate": 7.973333333333333e-08,
      "logits/chosen": -2.114741086959839,
      "logits/rejected": -1.3035271167755127,
      "logps/chosen": -183.20303344726562,
      "logps/rejected": -208.7641143798828,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1100848913192749,
      "rewards/margins": 12.456169128417969,
      "rewards/rejected": -12.566254615783691,
      "step": 6903
    },
    {
      "epoch": 2.7616,
      "grad_norm": 0.010708419606089592,
      "learning_rate": 7.96e-08,
      "logits/chosen": -2.403130531311035,
      "logits/rejected": -1.6620867252349854,
      "logps/chosen": -175.07952880859375,
      "logps/rejected": -186.86094665527344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9540290832519531,
      "rewards/margins": 10.698834419250488,
      "rewards/rejected": -11.652863502502441,
      "step": 6904
    },
    {
      "epoch": 2.762,
      "grad_norm": 0.020409001037478447,
      "learning_rate": 7.946666666666666e-08,
      "logits/chosen": -2.3765411376953125,
      "logits/rejected": -2.025327682495117,
      "logps/chosen": -151.93466186523438,
      "logps/rejected": -190.10281372070312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.776627779006958,
      "rewards/margins": 9.385184288024902,
      "rewards/rejected": -10.161811828613281,
      "step": 6905
    },
    {
      "epoch": 2.7624,
      "grad_norm": 0.00022014831483829767,
      "learning_rate": 7.933333333333333e-08,
      "logits/chosen": -2.6465773582458496,
      "logits/rejected": -1.6465609073638916,
      "logps/chosen": -76.85116577148438,
      "logps/rejected": -223.28793334960938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.178756833076477,
      "rewards/margins": 14.523859024047852,
      "rewards/rejected": -15.702616691589355,
      "step": 6906
    },
    {
      "epoch": 2.7628,
      "grad_norm": 0.044725555926561356,
      "learning_rate": 7.920000000000001e-08,
      "logits/chosen": -2.6956675052642822,
      "logits/rejected": -2.226858139038086,
      "logps/chosen": -52.266014099121094,
      "logps/rejected": -179.45716857910156,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2952074408531189,
      "rewards/margins": 11.707588195800781,
      "rewards/rejected": -11.412381172180176,
      "step": 6907
    },
    {
      "epoch": 2.7632,
      "grad_norm": 0.06327863037586212,
      "learning_rate": 7.906666666666666e-08,
      "logits/chosen": -2.879234790802002,
      "logits/rejected": -2.4036428928375244,
      "logps/chosen": -54.52202606201172,
      "logps/rejected": -144.14523315429688,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24363481998443604,
      "rewards/margins": 10.437699317932129,
      "rewards/rejected": -10.19406509399414,
      "step": 6908
    },
    {
      "epoch": 2.7636,
      "grad_norm": 0.15118081867694855,
      "learning_rate": 7.893333333333333e-08,
      "logits/chosen": -3.2847049236297607,
      "logits/rejected": -2.9561610221862793,
      "logps/chosen": -51.853973388671875,
      "logps/rejected": -122.32746124267578,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1662561893463135,
      "rewards/margins": 7.992459774017334,
      "rewards/rejected": -6.826203346252441,
      "step": 6909
    },
    {
      "epoch": 2.7640000000000002,
      "grad_norm": 0.8660244345664978,
      "learning_rate": 7.879999999999999e-08,
      "logits/chosen": -2.9073896408081055,
      "logits/rejected": -2.535367012023926,
      "logps/chosen": -91.48953247070312,
      "logps/rejected": -156.70692443847656,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.29122889041900635,
      "rewards/margins": 8.850040435791016,
      "rewards/rejected": -9.141268730163574,
      "step": 6910
    },
    {
      "epoch": 2.7644,
      "grad_norm": 0.0004761618038173765,
      "learning_rate": 7.866666666666666e-08,
      "logits/chosen": -2.2556772232055664,
      "logits/rejected": -1.0629371404647827,
      "logps/chosen": -120.41976928710938,
      "logps/rejected": -233.04074096679688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1549763679504395,
      "rewards/margins": 14.66372299194336,
      "rewards/rejected": -13.508747100830078,
      "step": 6911
    },
    {
      "epoch": 2.7648,
      "grad_norm": 0.010083554312586784,
      "learning_rate": 7.853333333333332e-08,
      "logits/chosen": -2.86612606048584,
      "logits/rejected": -2.218385934829712,
      "logps/chosen": -84.18716430664062,
      "logps/rejected": -170.66812133789062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.48091623187065125,
      "rewards/margins": 10.543495178222656,
      "rewards/rejected": -11.02441120147705,
      "step": 6912
    },
    {
      "epoch": 2.7652,
      "grad_norm": 6.081105709075928,
      "learning_rate": 7.839999999999999e-08,
      "logits/chosen": -2.814589262008667,
      "logits/rejected": -2.6741890907287598,
      "logps/chosen": -96.39989471435547,
      "logps/rejected": -97.77536010742188,
      "loss": 0.0396,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5884196758270264,
      "rewards/margins": 5.537106513977051,
      "rewards/rejected": -6.125525951385498,
      "step": 6913
    },
    {
      "epoch": 2.7656,
      "grad_norm": 0.0028804310131818056,
      "learning_rate": 7.826666666666667e-08,
      "logits/chosen": -2.485856533050537,
      "logits/rejected": -1.7591314315795898,
      "logps/chosen": -70.4974594116211,
      "logps/rejected": -155.39962768554688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4412306547164917,
      "rewards/margins": 11.591716766357422,
      "rewards/rejected": -10.15048599243164,
      "step": 6914
    },
    {
      "epoch": 2.766,
      "grad_norm": 0.007736551575362682,
      "learning_rate": 7.813333333333333e-08,
      "logits/chosen": -2.9795267581939697,
      "logits/rejected": -2.2904140949249268,
      "logps/chosen": -60.36002731323242,
      "logps/rejected": -165.12693786621094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6446850299835205,
      "rewards/margins": 12.320886611938477,
      "rewards/rejected": -10.676202774047852,
      "step": 6915
    },
    {
      "epoch": 2.7664,
      "grad_norm": 169.38998413085938,
      "learning_rate": 7.8e-08,
      "logits/chosen": -2.0165796279907227,
      "logits/rejected": -1.6804336309432983,
      "logps/chosen": -254.14674377441406,
      "logps/rejected": -189.9691162109375,
      "loss": 1.0141,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -4.264280796051025,
      "rewards/margins": 4.703895092010498,
      "rewards/rejected": -8.968175888061523,
      "step": 6916
    },
    {
      "epoch": 2.7668,
      "grad_norm": 0.014337395317852497,
      "learning_rate": 7.786666666666666e-08,
      "logits/chosen": -2.788386821746826,
      "logits/rejected": -2.3570713996887207,
      "logps/chosen": -31.82117462158203,
      "logps/rejected": -145.02706909179688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6823947429656982,
      "rewards/margins": 10.284521102905273,
      "rewards/rejected": -8.602127075195312,
      "step": 6917
    },
    {
      "epoch": 2.7672,
      "grad_norm": 0.0013508159900084138,
      "learning_rate": 7.773333333333333e-08,
      "logits/chosen": -2.5833117961883545,
      "logits/rejected": -1.7259501218795776,
      "logps/chosen": -59.00165939331055,
      "logps/rejected": -176.02734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7330623865127563,
      "rewards/margins": 13.538230895996094,
      "rewards/rejected": -12.805169105529785,
      "step": 6918
    },
    {
      "epoch": 2.7676,
      "grad_norm": 0.9639727473258972,
      "learning_rate": 7.76e-08,
      "logits/chosen": -2.7147140502929688,
      "logits/rejected": -2.3948636054992676,
      "logps/chosen": -62.5002555847168,
      "logps/rejected": -116.07772827148438,
      "loss": 0.0075,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4259651303291321,
      "rewards/margins": 7.637646675109863,
      "rewards/rejected": -8.06361198425293,
      "step": 6919
    },
    {
      "epoch": 2.768,
      "grad_norm": 0.04630138725042343,
      "learning_rate": 7.746666666666667e-08,
      "logits/chosen": -2.4918718338012695,
      "logits/rejected": -1.8973063230514526,
      "logps/chosen": -202.25369262695312,
      "logps/rejected": -169.96998596191406,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.42609328031539917,
      "rewards/margins": 10.586444854736328,
      "rewards/rejected": -11.01253890991211,
      "step": 6920
    },
    {
      "epoch": 2.7683999999999997,
      "grad_norm": 0.01551157608628273,
      "learning_rate": 7.733333333333334e-08,
      "logits/chosen": -2.4593887329101562,
      "logits/rejected": -1.8205617666244507,
      "logps/chosen": -97.97615051269531,
      "logps/rejected": -153.91452026367188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.07668990641832352,
      "rewards/margins": 10.8550443649292,
      "rewards/rejected": -10.931734085083008,
      "step": 6921
    },
    {
      "epoch": 2.7688,
      "grad_norm": 0.012465598061680794,
      "learning_rate": 7.72e-08,
      "logits/chosen": -2.6618261337280273,
      "logits/rejected": -2.209993600845337,
      "logps/chosen": -135.47003173828125,
      "logps/rejected": -209.32005310058594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.40628546476364136,
      "rewards/margins": 12.734548568725586,
      "rewards/rejected": -13.14083480834961,
      "step": 6922
    },
    {
      "epoch": 2.7692,
      "grad_norm": 5.977291220915504e-05,
      "learning_rate": 7.706666666666667e-08,
      "logits/chosen": -2.6222753524780273,
      "logits/rejected": -1.689413070678711,
      "logps/chosen": -124.76252746582031,
      "logps/rejected": -211.14566040039062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1107940748333931,
      "rewards/margins": 15.443254470825195,
      "rewards/rejected": -15.554048538208008,
      "step": 6923
    },
    {
      "epoch": 2.7696,
      "grad_norm": 0.17451713979244232,
      "learning_rate": 7.693333333333333e-08,
      "logits/chosen": -2.45756196975708,
      "logits/rejected": -1.8651765584945679,
      "logps/chosen": -62.8544807434082,
      "logps/rejected": -175.19631958007812,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.508351743221283,
      "rewards/margins": 11.302471160888672,
      "rewards/rejected": -11.810822486877441,
      "step": 6924
    },
    {
      "epoch": 2.77,
      "grad_norm": 1.5746009012218565e-05,
      "learning_rate": 7.679999999999999e-08,
      "logits/chosen": -2.3879730701446533,
      "logits/rejected": -1.6732803583145142,
      "logps/chosen": -92.31278991699219,
      "logps/rejected": -240.9631805419922,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7042317390441895,
      "rewards/margins": 17.705448150634766,
      "rewards/rejected": -15.001214981079102,
      "step": 6925
    },
    {
      "epoch": 2.7704,
      "grad_norm": 0.007705754600465298,
      "learning_rate": 7.666666666666665e-08,
      "logits/chosen": -2.4435436725616455,
      "logits/rejected": -1.902216911315918,
      "logps/chosen": -99.94444274902344,
      "logps/rejected": -230.34423828125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2488389015197754,
      "rewards/margins": 13.12353515625,
      "rewards/rejected": -11.874696731567383,
      "step": 6926
    },
    {
      "epoch": 2.7708,
      "grad_norm": 0.017479250207543373,
      "learning_rate": 7.653333333333333e-08,
      "logits/chosen": -2.2875514030456543,
      "logits/rejected": -1.759908676147461,
      "logps/chosen": -148.0933380126953,
      "logps/rejected": -264.7049560546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.13180391490459442,
      "rewards/margins": 11.984777450561523,
      "rewards/rejected": -12.116580963134766,
      "step": 6927
    },
    {
      "epoch": 2.7712,
      "grad_norm": 2.076683759689331,
      "learning_rate": 7.64e-08,
      "logits/chosen": -2.729640483856201,
      "logits/rejected": -2.4348793029785156,
      "logps/chosen": -113.47322082519531,
      "logps/rejected": -102.23479461669922,
      "loss": 0.0082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6169627904891968,
      "rewards/margins": 7.824705600738525,
      "rewards/rejected": -6.207742691040039,
      "step": 6928
    },
    {
      "epoch": 2.7716,
      "grad_norm": 0.026431448757648468,
      "learning_rate": 7.626666666666666e-08,
      "logits/chosen": -2.805044174194336,
      "logits/rejected": -2.304839611053467,
      "logps/chosen": -110.52365112304688,
      "logps/rejected": -157.67562866210938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1440788209438324,
      "rewards/margins": 10.471923828125,
      "rewards/rejected": -10.327845573425293,
      "step": 6929
    },
    {
      "epoch": 2.7720000000000002,
      "grad_norm": 0.008962507359683514,
      "learning_rate": 7.613333333333333e-08,
      "logits/chosen": -2.313788652420044,
      "logits/rejected": -1.580880880355835,
      "logps/chosen": -125.96812438964844,
      "logps/rejected": -207.16195678710938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8701931238174438,
      "rewards/margins": 14.688802719116211,
      "rewards/rejected": -12.818609237670898,
      "step": 6930
    },
    {
      "epoch": 2.7724,
      "grad_norm": 0.021399805322289467,
      "learning_rate": 7.599999999999999e-08,
      "logits/chosen": -2.9153566360473633,
      "logits/rejected": -2.143272638320923,
      "logps/chosen": -78.03205108642578,
      "logps/rejected": -149.11175537109375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5590368509292603,
      "rewards/margins": 9.448135375976562,
      "rewards/rejected": -8.88909912109375,
      "step": 6931
    },
    {
      "epoch": 2.7728,
      "grad_norm": 0.0027211951091885567,
      "learning_rate": 7.586666666666666e-08,
      "logits/chosen": -2.5764288902282715,
      "logits/rejected": -2.318476676940918,
      "logps/chosen": -142.86349487304688,
      "logps/rejected": -158.9503936767578,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22538185119628906,
      "rewards/margins": 12.021333694458008,
      "rewards/rejected": -11.795951843261719,
      "step": 6932
    },
    {
      "epoch": 2.7732,
      "grad_norm": 0.029419459402561188,
      "learning_rate": 7.573333333333332e-08,
      "logits/chosen": -2.8993799686431885,
      "logits/rejected": -2.517615556716919,
      "logps/chosen": -79.93338775634766,
      "logps/rejected": -147.46737670898438,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7289704084396362,
      "rewards/margins": 8.805822372436523,
      "rewards/rejected": -10.53479290008545,
      "step": 6933
    },
    {
      "epoch": 2.7736,
      "grad_norm": 0.03796003386378288,
      "learning_rate": 7.56e-08,
      "logits/chosen": -2.492673397064209,
      "logits/rejected": -1.9132134914398193,
      "logps/chosen": -155.25511169433594,
      "logps/rejected": -192.41029357910156,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1882118284702301,
      "rewards/margins": 12.623189926147461,
      "rewards/rejected": -12.434978485107422,
      "step": 6934
    },
    {
      "epoch": 2.774,
      "grad_norm": 0.0006442965823225677,
      "learning_rate": 7.546666666666667e-08,
      "logits/chosen": -2.9543771743774414,
      "logits/rejected": -2.415315628051758,
      "logps/chosen": -100.81957244873047,
      "logps/rejected": -218.78726196289062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16285276412963867,
      "rewards/margins": 15.475347518920898,
      "rewards/rejected": -15.312494277954102,
      "step": 6935
    },
    {
      "epoch": 2.7744,
      "grad_norm": 6.142455822555348e-05,
      "learning_rate": 7.533333333333333e-08,
      "logits/chosen": -2.4715576171875,
      "logits/rejected": -1.7762863636016846,
      "logps/chosen": -77.57704162597656,
      "logps/rejected": -245.79376220703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.349862664937973,
      "rewards/margins": 15.751754760742188,
      "rewards/rejected": -16.10161781311035,
      "step": 6936
    },
    {
      "epoch": 2.7748,
      "grad_norm": 0.01046063657850027,
      "learning_rate": 7.52e-08,
      "logits/chosen": -2.656826972961426,
      "logits/rejected": -2.165113687515259,
      "logps/chosen": -87.14318084716797,
      "logps/rejected": -167.32559204101562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0567951202392578,
      "rewards/margins": 11.2464017868042,
      "rewards/rejected": -10.189606666564941,
      "step": 6937
    },
    {
      "epoch": 2.7752,
      "grad_norm": 1.3367546796798706,
      "learning_rate": 7.506666666666666e-08,
      "logits/chosen": -2.667182445526123,
      "logits/rejected": -2.4515347480773926,
      "logps/chosen": -122.79832458496094,
      "logps/rejected": -158.4185333251953,
      "loss": 0.005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.0122110843658447,
      "rewards/margins": 8.212320327758789,
      "rewards/rejected": -11.224531173706055,
      "step": 6938
    },
    {
      "epoch": 2.7756,
      "grad_norm": 0.004683691542595625,
      "learning_rate": 7.493333333333333e-08,
      "logits/chosen": -2.375105142593384,
      "logits/rejected": -1.8987678289413452,
      "logps/chosen": -66.27613067626953,
      "logps/rejected": -257.17694091796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2870742976665497,
      "rewards/margins": 16.071128845214844,
      "rewards/rejected": -16.358203887939453,
      "step": 6939
    },
    {
      "epoch": 2.776,
      "grad_norm": 0.0024820687249302864,
      "learning_rate": 7.480000000000001e-08,
      "logits/chosen": -2.662769317626953,
      "logits/rejected": -1.753204345703125,
      "logps/chosen": -97.12535095214844,
      "logps/rejected": -189.25067138671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.37537848949432373,
      "rewards/margins": 12.811063766479492,
      "rewards/rejected": -13.186443328857422,
      "step": 6940
    },
    {
      "epoch": 2.7763999999999998,
      "grad_norm": 0.19957005977630615,
      "learning_rate": 7.466666666666667e-08,
      "logits/chosen": -2.6494364738464355,
      "logits/rejected": -2.2457332611083984,
      "logps/chosen": -79.61579895019531,
      "logps/rejected": -131.78857421875,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.12204495072364807,
      "rewards/margins": 8.288881301879883,
      "rewards/rejected": -8.41092586517334,
      "step": 6941
    },
    {
      "epoch": 2.7768,
      "grad_norm": 0.20993174612522125,
      "learning_rate": 7.453333333333333e-08,
      "logits/chosen": -2.1471455097198486,
      "logits/rejected": -1.4084528684616089,
      "logps/chosen": -71.12419128417969,
      "logps/rejected": -196.46734619140625,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.023279190063476562,
      "rewards/margins": 10.077666282653809,
      "rewards/rejected": -10.100945472717285,
      "step": 6942
    },
    {
      "epoch": 2.7772,
      "grad_norm": 0.005745957139879465,
      "learning_rate": 7.439999999999999e-08,
      "logits/chosen": -2.3951356410980225,
      "logits/rejected": -1.567368984222412,
      "logps/chosen": -81.33404541015625,
      "logps/rejected": -218.48138427734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2993580102920532,
      "rewards/margins": 12.37142276763916,
      "rewards/rejected": -12.072065353393555,
      "step": 6943
    },
    {
      "epoch": 2.7776,
      "grad_norm": 42.49393844604492,
      "learning_rate": 7.426666666666666e-08,
      "logits/chosen": -2.8444981575012207,
      "logits/rejected": -2.2732505798339844,
      "logps/chosen": -106.7080078125,
      "logps/rejected": -127.60369873046875,
      "loss": 0.2265,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8377635478973389,
      "rewards/margins": 3.58032488822937,
      "rewards/rejected": -5.418088436126709,
      "step": 6944
    },
    {
      "epoch": 2.778,
      "grad_norm": 0.13537518680095673,
      "learning_rate": 7.413333333333332e-08,
      "logits/chosen": -2.5139989852905273,
      "logits/rejected": -2.3379290103912354,
      "logps/chosen": -132.52224731445312,
      "logps/rejected": -127.64391326904297,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1606701612472534,
      "rewards/margins": 7.331789970397949,
      "rewards/rejected": -8.492460250854492,
      "step": 6945
    },
    {
      "epoch": 2.7784,
      "grad_norm": 0.05319447070360184,
      "learning_rate": 7.399999999999999e-08,
      "logits/chosen": -2.5854153633117676,
      "logits/rejected": -2.0519468784332275,
      "logps/chosen": -109.7694091796875,
      "logps/rejected": -140.12493896484375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.421065330505371,
      "rewards/margins": 11.093876838684082,
      "rewards/rejected": -9.672811508178711,
      "step": 6946
    },
    {
      "epoch": 2.7788,
      "grad_norm": 0.005417594686150551,
      "learning_rate": 7.386666666666667e-08,
      "logits/chosen": -2.934770107269287,
      "logits/rejected": -2.4686472415924072,
      "logps/chosen": -90.13024139404297,
      "logps/rejected": -221.37181091308594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18895912170410156,
      "rewards/margins": 15.1124267578125,
      "rewards/rejected": -14.923467636108398,
      "step": 6947
    },
    {
      "epoch": 2.7792,
      "grad_norm": 0.08688671141862869,
      "learning_rate": 7.373333333333333e-08,
      "logits/chosen": -2.548739194869995,
      "logits/rejected": -2.032668352127075,
      "logps/chosen": -73.6095962524414,
      "logps/rejected": -178.5721435546875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0330321788787842,
      "rewards/margins": 10.271088600158691,
      "rewards/rejected": -11.304121017456055,
      "step": 6948
    },
    {
      "epoch": 2.7796,
      "grad_norm": 0.00346073554828763,
      "learning_rate": 7.36e-08,
      "logits/chosen": -2.3301467895507812,
      "logits/rejected": -1.6293525695800781,
      "logps/chosen": -151.53564453125,
      "logps/rejected": -182.018310546875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3505474030971527,
      "rewards/margins": 13.734065055847168,
      "rewards/rejected": -13.38351821899414,
      "step": 6949
    },
    {
      "epoch": 2.7800000000000002,
      "grad_norm": 0.09362079203128815,
      "learning_rate": 7.346666666666666e-08,
      "logits/chosen": -2.0644564628601074,
      "logits/rejected": -1.187023401260376,
      "logps/chosen": -159.05392456054688,
      "logps/rejected": -227.64141845703125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.3482162952423096,
      "rewards/margins": 11.403060913085938,
      "rewards/rejected": -13.751277923583984,
      "step": 6950
    },
    {
      "epoch": 2.7804,
      "grad_norm": 0.006420051213353872,
      "learning_rate": 7.333333333333333e-08,
      "logits/chosen": -2.3634121417999268,
      "logits/rejected": -1.8107935190200806,
      "logps/chosen": -87.95913696289062,
      "logps/rejected": -217.527587890625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.11107176542282104,
      "rewards/margins": 11.861605644226074,
      "rewards/rejected": -11.972677230834961,
      "step": 6951
    },
    {
      "epoch": 2.7808,
      "grad_norm": 2.620713710784912,
      "learning_rate": 7.32e-08,
      "logits/chosen": -2.8436055183410645,
      "logits/rejected": -2.8646559715270996,
      "logps/chosen": -86.0436782836914,
      "logps/rejected": -86.41014862060547,
      "loss": 0.0127,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5925579071044922,
      "rewards/margins": 5.674442291259766,
      "rewards/rejected": -5.081884384155273,
      "step": 6952
    },
    {
      "epoch": 2.7812,
      "grad_norm": 0.006846926175057888,
      "learning_rate": 7.306666666666666e-08,
      "logits/chosen": -2.5213794708251953,
      "logits/rejected": -2.2928929328918457,
      "logps/chosen": -80.27539825439453,
      "logps/rejected": -143.8816680908203,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14929616451263428,
      "rewards/margins": 10.315035820007324,
      "rewards/rejected": -10.165739059448242,
      "step": 6953
    },
    {
      "epoch": 2.7816,
      "grad_norm": 0.5497199892997742,
      "learning_rate": 7.293333333333334e-08,
      "logits/chosen": -3.064101457595825,
      "logits/rejected": -2.762197971343994,
      "logps/chosen": -56.33915710449219,
      "logps/rejected": -130.006591796875,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8151216506958008,
      "rewards/margins": 7.647877216339111,
      "rewards/rejected": -8.46299934387207,
      "step": 6954
    },
    {
      "epoch": 2.782,
      "grad_norm": 136.09912109375,
      "learning_rate": 7.28e-08,
      "logits/chosen": -2.591728925704956,
      "logits/rejected": -2.254653215408325,
      "logps/chosen": -168.9267120361328,
      "logps/rejected": -139.18838500976562,
      "loss": 0.7214,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -3.1870968341827393,
      "rewards/margins": 5.627165794372559,
      "rewards/rejected": -8.814262390136719,
      "step": 6955
    },
    {
      "epoch": 2.7824,
      "grad_norm": 0.02228660322725773,
      "learning_rate": 7.266666666666667e-08,
      "logits/chosen": -2.2904348373413086,
      "logits/rejected": -1.510674238204956,
      "logps/chosen": -118.36488342285156,
      "logps/rejected": -160.55064392089844,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.868072509765625,
      "rewards/margins": 11.61390209197998,
      "rewards/rejected": -10.745829582214355,
      "step": 6956
    },
    {
      "epoch": 2.7828,
      "grad_norm": 1.7733327150344849,
      "learning_rate": 7.253333333333333e-08,
      "logits/chosen": -2.821894645690918,
      "logits/rejected": -2.7734975814819336,
      "logps/chosen": -113.23184204101562,
      "logps/rejected": -117.04727935791016,
      "loss": 0.0093,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.13398322463035583,
      "rewards/margins": 6.029877662658691,
      "rewards/rejected": -6.16386079788208,
      "step": 6957
    },
    {
      "epoch": 2.7832,
      "grad_norm": 0.012875664979219437,
      "learning_rate": 7.24e-08,
      "logits/chosen": -2.06140398979187,
      "logits/rejected": -1.2639548778533936,
      "logps/chosen": -133.26361083984375,
      "logps/rejected": -199.8221435546875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21721726655960083,
      "rewards/margins": 11.834919929504395,
      "rewards/rejected": -11.61770248413086,
      "step": 6958
    },
    {
      "epoch": 2.7836,
      "grad_norm": 0.0017744357464835048,
      "learning_rate": 7.226666666666667e-08,
      "logits/chosen": -3.2713775634765625,
      "logits/rejected": -2.6639485359191895,
      "logps/chosen": -52.33781433105469,
      "logps/rejected": -174.64181518554688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.62640380859375,
      "rewards/margins": 13.778639793395996,
      "rewards/rejected": -11.15223503112793,
      "step": 6959
    },
    {
      "epoch": 2.784,
      "grad_norm": 0.04110163077712059,
      "learning_rate": 7.213333333333332e-08,
      "logits/chosen": -2.5973939895629883,
      "logits/rejected": -2.249807834625244,
      "logps/chosen": -64.7606201171875,
      "logps/rejected": -115.56645202636719,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.29953932762146,
      "rewards/margins": 8.666067123413086,
      "rewards/rejected": -7.366527080535889,
      "step": 6960
    },
    {
      "epoch": 2.7843999999999998,
      "grad_norm": 16.387636184692383,
      "learning_rate": 7.2e-08,
      "logits/chosen": -2.5877785682678223,
      "logits/rejected": -2.21439790725708,
      "logps/chosen": -158.37542724609375,
      "logps/rejected": -154.075439453125,
      "loss": 0.0698,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6058319807052612,
      "rewards/margins": 8.46019172668457,
      "rewards/rejected": -10.066022872924805,
      "step": 6961
    },
    {
      "epoch": 2.7848,
      "grad_norm": 0.044835273176431656,
      "learning_rate": 7.186666666666666e-08,
      "logits/chosen": -2.3511829376220703,
      "logits/rejected": -1.5055291652679443,
      "logps/chosen": -115.25294494628906,
      "logps/rejected": -169.17410278320312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2739543914794922,
      "rewards/margins": 11.681623458862305,
      "rewards/rejected": -10.407669067382812,
      "step": 6962
    },
    {
      "epoch": 2.7852,
      "grad_norm": 0.03916563466191292,
      "learning_rate": 7.173333333333333e-08,
      "logits/chosen": -2.5249581336975098,
      "logits/rejected": -2.369016170501709,
      "logps/chosen": -105.21038818359375,
      "logps/rejected": -151.45391845703125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9197132587432861,
      "rewards/margins": 8.609823226928711,
      "rewards/rejected": -9.529536247253418,
      "step": 6963
    },
    {
      "epoch": 2.7856,
      "grad_norm": 0.21723252534866333,
      "learning_rate": 7.159999999999999e-08,
      "logits/chosen": -2.9143805503845215,
      "logits/rejected": -2.579650402069092,
      "logps/chosen": -69.20398712158203,
      "logps/rejected": -135.29644775390625,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.09764441847801208,
      "rewards/margins": 9.203836441040039,
      "rewards/rejected": -9.301480293273926,
      "step": 6964
    },
    {
      "epoch": 2.786,
      "grad_norm": 0.28084850311279297,
      "learning_rate": 7.146666666666666e-08,
      "logits/chosen": -2.5953164100646973,
      "logits/rejected": -2.3537051677703857,
      "logps/chosen": -89.1788330078125,
      "logps/rejected": -126.82994079589844,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.17597350478172302,
      "rewards/margins": 7.965153694152832,
      "rewards/rejected": -8.141127586364746,
      "step": 6965
    },
    {
      "epoch": 2.7864,
      "grad_norm": 0.3017745018005371,
      "learning_rate": 7.133333333333332e-08,
      "logits/chosen": -2.5121045112609863,
      "logits/rejected": -1.8836578130722046,
      "logps/chosen": -91.47676086425781,
      "logps/rejected": -123.39473724365234,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1969842910766602,
      "rewards/margins": 8.466507911682129,
      "rewards/rejected": -7.269524097442627,
      "step": 6966
    },
    {
      "epoch": 2.7868,
      "grad_norm": 0.0030576097778975964,
      "learning_rate": 7.12e-08,
      "logits/chosen": -2.492980480194092,
      "logits/rejected": -1.8957633972167969,
      "logps/chosen": -72.01884460449219,
      "logps/rejected": -171.13011169433594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.291174292564392,
      "rewards/margins": 12.086854934692383,
      "rewards/rejected": -10.79568099975586,
      "step": 6967
    },
    {
      "epoch": 2.7872,
      "grad_norm": 0.28869903087615967,
      "learning_rate": 7.106666666666667e-08,
      "logits/chosen": -2.8818817138671875,
      "logits/rejected": -2.6181821823120117,
      "logps/chosen": -58.32966995239258,
      "logps/rejected": -109.193603515625,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9001742601394653,
      "rewards/margins": 7.817636489868164,
      "rewards/rejected": -6.917462348937988,
      "step": 6968
    },
    {
      "epoch": 2.7876,
      "grad_norm": 0.21560698747634888,
      "learning_rate": 7.093333333333333e-08,
      "logits/chosen": -2.4541120529174805,
      "logits/rejected": -2.1776866912841797,
      "logps/chosen": -92.73287963867188,
      "logps/rejected": -113.78560638427734,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8864903450012207,
      "rewards/margins": 8.995922088623047,
      "rewards/rejected": -7.109431743621826,
      "step": 6969
    },
    {
      "epoch": 2.7880000000000003,
      "grad_norm": 0.041529182344675064,
      "learning_rate": 7.08e-08,
      "logits/chosen": -2.4856619834899902,
      "logits/rejected": -1.6965302228927612,
      "logps/chosen": -104.17410278320312,
      "logps/rejected": -205.6540985107422,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2911868691444397,
      "rewards/margins": 12.265085220336914,
      "rewards/rejected": -11.973897933959961,
      "step": 6970
    },
    {
      "epoch": 2.7884,
      "grad_norm": 0.7689751386642456,
      "learning_rate": 7.066666666666666e-08,
      "logits/chosen": -2.373913526535034,
      "logits/rejected": -1.6968388557434082,
      "logps/chosen": -120.78522491455078,
      "logps/rejected": -156.9989013671875,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9491685628890991,
      "rewards/margins": 7.620978355407715,
      "rewards/rejected": -8.570146560668945,
      "step": 6971
    },
    {
      "epoch": 2.7888,
      "grad_norm": 0.03425327688455582,
      "learning_rate": 7.053333333333333e-08,
      "logits/chosen": -2.5561699867248535,
      "logits/rejected": -2.0182058811187744,
      "logps/chosen": -66.7463150024414,
      "logps/rejected": -287.3784484863281,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.816145658493042,
      "rewards/margins": 15.262678146362305,
      "rewards/rejected": -13.446533203125,
      "step": 6972
    },
    {
      "epoch": 2.7892,
      "grad_norm": 0.008608660660684109,
      "learning_rate": 7.04e-08,
      "logits/chosen": -2.435922861099243,
      "logits/rejected": -1.630441665649414,
      "logps/chosen": -97.54945373535156,
      "logps/rejected": -171.85601806640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8118525743484497,
      "rewards/margins": 10.318506240844727,
      "rewards/rejected": -11.130359649658203,
      "step": 6973
    },
    {
      "epoch": 2.7896,
      "grad_norm": 0.07037188857793808,
      "learning_rate": 7.026666666666667e-08,
      "logits/chosen": -2.322481155395508,
      "logits/rejected": -2.2441341876983643,
      "logps/chosen": -175.26431274414062,
      "logps/rejected": -159.65887451171875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8661732077598572,
      "rewards/margins": 8.367281913757324,
      "rewards/rejected": -9.233455657958984,
      "step": 6974
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.14531750977039337,
      "learning_rate": 7.013333333333334e-08,
      "logits/chosen": -2.566507339477539,
      "logits/rejected": -2.1675925254821777,
      "logps/chosen": -98.8166732788086,
      "logps/rejected": -150.6641387939453,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.36916980147361755,
      "rewards/margins": 10.251121520996094,
      "rewards/rejected": -9.881952285766602,
      "step": 6975
    },
    {
      "epoch": 2.7904,
      "grad_norm": 0.09950702637434006,
      "learning_rate": 7e-08,
      "logits/chosen": -2.6557812690734863,
      "logits/rejected": -2.3207616806030273,
      "logps/chosen": -52.13471221923828,
      "logps/rejected": -120.8831558227539,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.11674489080905914,
      "rewards/margins": 7.715315818786621,
      "rewards/rejected": -7.832060813903809,
      "step": 6976
    },
    {
      "epoch": 2.7908,
      "grad_norm": 0.21874591708183289,
      "learning_rate": 6.986666666666666e-08,
      "logits/chosen": -2.952052593231201,
      "logits/rejected": -2.369041681289673,
      "logps/chosen": -70.75550842285156,
      "logps/rejected": -204.8577117919922,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.654507040977478,
      "rewards/margins": 13.296211242675781,
      "rewards/rejected": -13.95071792602539,
      "step": 6977
    },
    {
      "epoch": 2.7912,
      "grad_norm": 0.01952395960688591,
      "learning_rate": 6.973333333333332e-08,
      "logits/chosen": -2.297084093093872,
      "logits/rejected": -1.781803846359253,
      "logps/chosen": -125.91242980957031,
      "logps/rejected": -141.47622680664062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6937835216522217,
      "rewards/margins": 9.245813369750977,
      "rewards/rejected": -9.939597129821777,
      "step": 6978
    },
    {
      "epoch": 2.7916,
      "grad_norm": 0.0015382637502625585,
      "learning_rate": 6.959999999999999e-08,
      "logits/chosen": -2.666665554046631,
      "logits/rejected": -1.7348697185516357,
      "logps/chosen": -65.83129119873047,
      "logps/rejected": -214.45364379882812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6222891807556152,
      "rewards/margins": 15.026655197143555,
      "rewards/rejected": -13.404367446899414,
      "step": 6979
    },
    {
      "epoch": 2.792,
      "grad_norm": 0.02940399758517742,
      "learning_rate": 6.946666666666665e-08,
      "logits/chosen": -2.923964738845825,
      "logits/rejected": -2.5423288345336914,
      "logps/chosen": -56.87308120727539,
      "logps/rejected": -158.94505310058594,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.567629337310791,
      "rewards/margins": 12.139871597290039,
      "rewards/rejected": -10.572242736816406,
      "step": 6980
    },
    {
      "epoch": 2.7923999999999998,
      "grad_norm": 0.004872395657002926,
      "learning_rate": 6.933333333333333e-08,
      "logits/chosen": -2.603407382965088,
      "logits/rejected": -2.0531506538391113,
      "logps/chosen": -132.5373077392578,
      "logps/rejected": -159.42083740234375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.19198662042617798,
      "rewards/margins": 11.455118179321289,
      "rewards/rejected": -11.647104263305664,
      "step": 6981
    },
    {
      "epoch": 2.7927999999999997,
      "grad_norm": 0.01831830106675625,
      "learning_rate": 6.92e-08,
      "logits/chosen": -3.0119335651397705,
      "logits/rejected": -2.4774820804595947,
      "logps/chosen": -53.147098541259766,
      "logps/rejected": -123.80484771728516,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19750061631202698,
      "rewards/margins": 9.266435623168945,
      "rewards/rejected": -9.06893539428711,
      "step": 6982
    },
    {
      "epoch": 2.7932,
      "grad_norm": 0.016176993027329445,
      "learning_rate": 6.906666666666666e-08,
      "logits/chosen": -2.897113561630249,
      "logits/rejected": -2.592383861541748,
      "logps/chosen": -61.761653900146484,
      "logps/rejected": -167.4656982421875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12296067178249359,
      "rewards/margins": 11.530664443969727,
      "rewards/rejected": -11.407703399658203,
      "step": 6983
    },
    {
      "epoch": 2.7936,
      "grad_norm": 0.023120209574699402,
      "learning_rate": 6.893333333333333e-08,
      "logits/chosen": -2.8397130966186523,
      "logits/rejected": -2.0571303367614746,
      "logps/chosen": -78.03424072265625,
      "logps/rejected": -223.5225830078125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7383766174316406,
      "rewards/margins": 12.44686508178711,
      "rewards/rejected": -13.18524169921875,
      "step": 6984
    },
    {
      "epoch": 2.794,
      "grad_norm": 0.006516200490295887,
      "learning_rate": 6.88e-08,
      "logits/chosen": -2.617187976837158,
      "logits/rejected": -1.828201413154602,
      "logps/chosen": -112.23751831054688,
      "logps/rejected": -167.1854248046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4834396541118622,
      "rewards/margins": 11.617847442626953,
      "rewards/rejected": -11.134407043457031,
      "step": 6985
    },
    {
      "epoch": 2.7944,
      "grad_norm": 0.00039063458098098636,
      "learning_rate": 6.866666666666666e-08,
      "logits/chosen": -2.677581548690796,
      "logits/rejected": -2.2064597606658936,
      "logps/chosen": -80.00529479980469,
      "logps/rejected": -198.93731689453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.007896065711975,
      "rewards/margins": 15.417015075683594,
      "rewards/rejected": -14.40911865234375,
      "step": 6986
    },
    {
      "epoch": 2.7948,
      "grad_norm": 0.0009798763785511255,
      "learning_rate": 6.853333333333334e-08,
      "logits/chosen": -2.5086755752563477,
      "logits/rejected": -1.9754060506820679,
      "logps/chosen": -49.442970275878906,
      "logps/rejected": -199.83743286132812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6513382196426392,
      "rewards/margins": 15.021770477294922,
      "rewards/rejected": -13.37043285369873,
      "step": 6987
    },
    {
      "epoch": 2.7952,
      "grad_norm": 0.19971896708011627,
      "learning_rate": 6.84e-08,
      "logits/chosen": -2.7496213912963867,
      "logits/rejected": -2.253865957260132,
      "logps/chosen": -76.845947265625,
      "logps/rejected": -147.27239990234375,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6490856409072876,
      "rewards/margins": 10.589963912963867,
      "rewards/rejected": -9.940877914428711,
      "step": 6988
    },
    {
      "epoch": 2.7956,
      "grad_norm": 0.6044188141822815,
      "learning_rate": 6.826666666666667e-08,
      "logits/chosen": -3.1082634925842285,
      "logits/rejected": -2.719362258911133,
      "logps/chosen": -32.49895477294922,
      "logps/rejected": -142.8706512451172,
      "loss": 0.0051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7858148217201233,
      "rewards/margins": 11.51353931427002,
      "rewards/rejected": -10.7277250289917,
      "step": 6989
    },
    {
      "epoch": 2.7960000000000003,
      "grad_norm": 1.298310326092178e-05,
      "learning_rate": 6.813333333333333e-08,
      "logits/chosen": -2.486555814743042,
      "logits/rejected": -1.642971158027649,
      "logps/chosen": -112.35760498046875,
      "logps/rejected": -293.179931640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.213513970375061,
      "rewards/margins": 18.05331039428711,
      "rewards/rejected": -16.83979606628418,
      "step": 6990
    },
    {
      "epoch": 2.7964,
      "grad_norm": 0.016261933371424675,
      "learning_rate": 6.8e-08,
      "logits/chosen": -2.569002866744995,
      "logits/rejected": -2.1172847747802734,
      "logps/chosen": -137.32369995117188,
      "logps/rejected": -182.0137176513672,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4230315685272217,
      "rewards/margins": 12.935371398925781,
      "rewards/rejected": -11.512338638305664,
      "step": 6991
    },
    {
      "epoch": 2.7968,
      "grad_norm": 0.7770259380340576,
      "learning_rate": 6.786666666666667e-08,
      "logits/chosen": -2.1914496421813965,
      "logits/rejected": -1.525752305984497,
      "logps/chosen": -174.5725860595703,
      "logps/rejected": -156.38331604003906,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.676745653152466,
      "rewards/margins": 7.930148124694824,
      "rewards/rejected": -10.606893539428711,
      "step": 6992
    },
    {
      "epoch": 2.7972,
      "grad_norm": 3.0147642974043265e-05,
      "learning_rate": 6.773333333333333e-08,
      "logits/chosen": -2.166048526763916,
      "logits/rejected": -1.5249757766723633,
      "logps/chosen": -183.26966857910156,
      "logps/rejected": -302.85943603515625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.008760064840316772,
      "rewards/margins": 16.759689331054688,
      "rewards/rejected": -16.768449783325195,
      "step": 6993
    },
    {
      "epoch": 2.7976,
      "grad_norm": 6.207607269287109,
      "learning_rate": 6.76e-08,
      "logits/chosen": -2.480656147003174,
      "logits/rejected": -2.37019944190979,
      "logps/chosen": -76.19915008544922,
      "logps/rejected": -139.31109619140625,
      "loss": 0.0458,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5074552297592163,
      "rewards/margins": 8.522554397583008,
      "rewards/rejected": -9.030009269714355,
      "step": 6994
    },
    {
      "epoch": 2.798,
      "grad_norm": 0.012455426156520844,
      "learning_rate": 6.746666666666666e-08,
      "logits/chosen": -2.894622802734375,
      "logits/rejected": -2.491560697555542,
      "logps/chosen": -60.52618408203125,
      "logps/rejected": -152.135009765625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9784731268882751,
      "rewards/margins": 9.739591598510742,
      "rewards/rejected": -10.71806526184082,
      "step": 6995
    },
    {
      "epoch": 2.7984,
      "grad_norm": 1.5306117534637451,
      "learning_rate": 6.733333333333333e-08,
      "logits/chosen": -2.360105037689209,
      "logits/rejected": -1.8220012187957764,
      "logps/chosen": -84.32078552246094,
      "logps/rejected": -168.46385192871094,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8437755703926086,
      "rewards/margins": 9.962261199951172,
      "rewards/rejected": -10.806036949157715,
      "step": 6996
    },
    {
      "epoch": 2.7988,
      "grad_norm": 0.016971321776509285,
      "learning_rate": 6.719999999999999e-08,
      "logits/chosen": -2.7090322971343994,
      "logits/rejected": -2.243722915649414,
      "logps/chosen": -108.17446899414062,
      "logps/rejected": -210.32162475585938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7587193250656128,
      "rewards/margins": 13.243390083312988,
      "rewards/rejected": -14.00210952758789,
      "step": 6997
    },
    {
      "epoch": 2.7992,
      "grad_norm": 0.6467064619064331,
      "learning_rate": 6.706666666666666e-08,
      "logits/chosen": -2.896306276321411,
      "logits/rejected": -2.4973111152648926,
      "logps/chosen": -64.59909057617188,
      "logps/rejected": -132.48098754882812,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7845990657806396,
      "rewards/margins": 9.730813980102539,
      "rewards/rejected": -7.94621467590332,
      "step": 6998
    },
    {
      "epoch": 2.7996,
      "grad_norm": 0.06341602653265,
      "learning_rate": 6.693333333333332e-08,
      "logits/chosen": -2.807023286819458,
      "logits/rejected": -2.3578784465789795,
      "logps/chosen": -77.19821166992188,
      "logps/rejected": -207.70323181152344,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9047811031341553,
      "rewards/margins": 13.680876731872559,
      "rewards/rejected": -14.585657119750977,
      "step": 6999
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.018922429531812668,
      "learning_rate": 6.679999999999999e-08,
      "logits/chosen": -2.5467681884765625,
      "logits/rejected": -2.336899757385254,
      "logps/chosen": -101.29702758789062,
      "logps/rejected": -185.4479217529297,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2868694067001343,
      "rewards/margins": 9.978076934814453,
      "rewards/rejected": -10.264946937561035,
      "step": 7000
    },
    {
      "epoch": 2.8004,
      "grad_norm": 0.954102098941803,
      "learning_rate": 6.666666666666667e-08,
      "logits/chosen": -2.6800694465637207,
      "logits/rejected": -2.6050736904144287,
      "logps/chosen": -124.65988159179688,
      "logps/rejected": -118.77806091308594,
      "loss": 0.0049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.241475820541382,
      "rewards/margins": 5.334346771240234,
      "rewards/rejected": -7.575822830200195,
      "step": 7001
    },
    {
      "epoch": 2.8007999999999997,
      "grad_norm": 0.0009623868390917778,
      "learning_rate": 6.653333333333333e-08,
      "logits/chosen": -2.617279052734375,
      "logits/rejected": -1.6281505823135376,
      "logps/chosen": -96.38433074951172,
      "logps/rejected": -195.34417724609375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6816734075546265,
      "rewards/margins": 12.73198127746582,
      "rewards/rejected": -11.050307273864746,
      "step": 7002
    },
    {
      "epoch": 2.8012,
      "grad_norm": 0.0947674959897995,
      "learning_rate": 6.64e-08,
      "logits/chosen": -2.5595264434814453,
      "logits/rejected": -1.9032199382781982,
      "logps/chosen": -138.40692138671875,
      "logps/rejected": -155.52767944335938,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9794338345527649,
      "rewards/margins": 8.202756881713867,
      "rewards/rejected": -9.18218994140625,
      "step": 7003
    },
    {
      "epoch": 2.8016,
      "grad_norm": 2.3229923248291016,
      "learning_rate": 6.626666666666666e-08,
      "logits/chosen": -2.9571259021759033,
      "logits/rejected": -2.8548800945281982,
      "logps/chosen": -84.93199157714844,
      "logps/rejected": -78.5807876586914,
      "loss": 0.0158,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35714951157569885,
      "rewards/margins": 4.80673885345459,
      "rewards/rejected": -4.449589252471924,
      "step": 7004
    },
    {
      "epoch": 2.802,
      "grad_norm": 0.08530735224485397,
      "learning_rate": 6.613333333333333e-08,
      "logits/chosen": -2.385671615600586,
      "logits/rejected": -1.8476076126098633,
      "logps/chosen": -209.34442138671875,
      "logps/rejected": -191.01719665527344,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.3154563903808594,
      "rewards/margins": 7.889029026031494,
      "rewards/rejected": -11.204484939575195,
      "step": 7005
    },
    {
      "epoch": 2.8024,
      "grad_norm": 0.00044277976849116385,
      "learning_rate": 6.6e-08,
      "logits/chosen": -2.709306478500366,
      "logits/rejected": -2.36971116065979,
      "logps/chosen": -75.12953186035156,
      "logps/rejected": -192.55859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5153946280479431,
      "rewards/margins": 13.726184844970703,
      "rewards/rejected": -13.210790634155273,
      "step": 7006
    },
    {
      "epoch": 2.8028,
      "grad_norm": 0.028568698093295097,
      "learning_rate": 6.586666666666667e-08,
      "logits/chosen": -2.936093807220459,
      "logits/rejected": -2.521211862564087,
      "logps/chosen": -74.654052734375,
      "logps/rejected": -145.28213500976562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10094448924064636,
      "rewards/margins": 10.290186882019043,
      "rewards/rejected": -10.189242362976074,
      "step": 7007
    },
    {
      "epoch": 2.8032,
      "grad_norm": 0.047367870807647705,
      "learning_rate": 6.573333333333334e-08,
      "logits/chosen": -2.7048845291137695,
      "logits/rejected": -2.4005346298217773,
      "logps/chosen": -66.27499389648438,
      "logps/rejected": -143.7755584716797,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.150402307510376,
      "rewards/margins": 9.116039276123047,
      "rewards/rejected": -10.266441345214844,
      "step": 7008
    },
    {
      "epoch": 2.8036,
      "grad_norm": 0.022043591365218163,
      "learning_rate": 6.56e-08,
      "logits/chosen": -2.5682644844055176,
      "logits/rejected": -1.932582974433899,
      "logps/chosen": -123.41958618164062,
      "logps/rejected": -171.8878173828125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.282142996788025,
      "rewards/margins": 9.265872955322266,
      "rewards/rejected": -10.548015594482422,
      "step": 7009
    },
    {
      "epoch": 2.8040000000000003,
      "grad_norm": 0.061873819679021835,
      "learning_rate": 6.546666666666667e-08,
      "logits/chosen": -2.6293790340423584,
      "logits/rejected": -2.3078737258911133,
      "logps/chosen": -99.4630126953125,
      "logps/rejected": -198.4358367919922,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.036520421504974365,
      "rewards/margins": 14.309348106384277,
      "rewards/rejected": -14.2728271484375,
      "step": 7010
    },
    {
      "epoch": 2.8044000000000002,
      "grad_norm": 0.024913901463150978,
      "learning_rate": 6.533333333333332e-08,
      "logits/chosen": -2.9210634231567383,
      "logits/rejected": -2.6356515884399414,
      "logps/chosen": -44.22148895263672,
      "logps/rejected": -133.86343383789062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3319892883300781,
      "rewards/margins": 9.189942359924316,
      "rewards/rejected": -9.521931648254395,
      "step": 7011
    },
    {
      "epoch": 2.8048,
      "grad_norm": 0.001005377620458603,
      "learning_rate": 6.519999999999999e-08,
      "logits/chosen": -2.439014434814453,
      "logits/rejected": -2.4968438148498535,
      "logps/chosen": -103.64570617675781,
      "logps/rejected": -223.61221313476562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3510280847549438,
      "rewards/margins": 14.004925727844238,
      "rewards/rejected": -12.653897285461426,
      "step": 7012
    },
    {
      "epoch": 2.8052,
      "grad_norm": 0.002360898070037365,
      "learning_rate": 6.506666666666665e-08,
      "logits/chosen": -2.440751791000366,
      "logits/rejected": -1.8393058776855469,
      "logps/chosen": -71.76136779785156,
      "logps/rejected": -181.39707946777344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.26761341094970703,
      "rewards/margins": 12.871514320373535,
      "rewards/rejected": -12.603900909423828,
      "step": 7013
    },
    {
      "epoch": 2.8056,
      "grad_norm": 0.00024414758081547916,
      "learning_rate": 6.493333333333333e-08,
      "logits/chosen": -2.5519349575042725,
      "logits/rejected": -1.8601205348968506,
      "logps/chosen": -74.04700469970703,
      "logps/rejected": -220.406005859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2645055651664734,
      "rewards/margins": 16.511072158813477,
      "rewards/rejected": -16.246566772460938,
      "step": 7014
    },
    {
      "epoch": 2.806,
      "grad_norm": 0.005697871558368206,
      "learning_rate": 6.48e-08,
      "logits/chosen": -2.4924674034118652,
      "logits/rejected": -2.2786664962768555,
      "logps/chosen": -101.6117935180664,
      "logps/rejected": -157.2460479736328,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6563596725463867,
      "rewards/margins": 11.49649429321289,
      "rewards/rejected": -12.152854919433594,
      "step": 7015
    },
    {
      "epoch": 2.8064,
      "grad_norm": 0.27346271276474,
      "learning_rate": 6.466666666666666e-08,
      "logits/chosen": -2.3600292205810547,
      "logits/rejected": -1.8713502883911133,
      "logps/chosen": -127.28167724609375,
      "logps/rejected": -175.13473510742188,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.402827262878418,
      "rewards/margins": 6.762868881225586,
      "rewards/rejected": -11.16569709777832,
      "step": 7016
    },
    {
      "epoch": 2.8068,
      "grad_norm": 0.03235636278986931,
      "learning_rate": 6.453333333333333e-08,
      "logits/chosen": -2.250337839126587,
      "logits/rejected": -2.1158080101013184,
      "logps/chosen": -135.52584838867188,
      "logps/rejected": -181.30120849609375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8181007504463196,
      "rewards/margins": 10.199141502380371,
      "rewards/rejected": -9.381040573120117,
      "step": 7017
    },
    {
      "epoch": 2.8072,
      "grad_norm": 0.0020763901993632317,
      "learning_rate": 6.44e-08,
      "logits/chosen": -2.579810380935669,
      "logits/rejected": -2.2873048782348633,
      "logps/chosen": -57.79296112060547,
      "logps/rejected": -206.93743896484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0526962280273438,
      "rewards/margins": 14.717487335205078,
      "rewards/rejected": -12.664791107177734,
      "step": 7018
    },
    {
      "epoch": 2.8076,
      "grad_norm": 0.8778237700462341,
      "learning_rate": 6.426666666666666e-08,
      "logits/chosen": -2.5190272331237793,
      "logits/rejected": -2.4396138191223145,
      "logps/chosen": -104.43516540527344,
      "logps/rejected": -111.26535034179688,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.540243148803711,
      "rewards/margins": 6.740780830383301,
      "rewards/rejected": -8.281023979187012,
      "step": 7019
    },
    {
      "epoch": 2.808,
      "grad_norm": 0.01400855090469122,
      "learning_rate": 6.413333333333333e-08,
      "logits/chosen": -2.462587833404541,
      "logits/rejected": -2.1291379928588867,
      "logps/chosen": -68.08123779296875,
      "logps/rejected": -184.20269775390625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6732333898544312,
      "rewards/margins": 11.532829284667969,
      "rewards/rejected": -9.859596252441406,
      "step": 7020
    },
    {
      "epoch": 2.8084,
      "grad_norm": 0.008199111558496952,
      "learning_rate": 6.4e-08,
      "logits/chosen": -2.777338743209839,
      "logits/rejected": -2.4537549018859863,
      "logps/chosen": -88.6461181640625,
      "logps/rejected": -171.93341064453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0259846448898315,
      "rewards/margins": 12.993204116821289,
      "rewards/rejected": -11.967220306396484,
      "step": 7021
    },
    {
      "epoch": 2.8087999999999997,
      "grad_norm": 0.0015926905907690525,
      "learning_rate": 6.386666666666667e-08,
      "logits/chosen": -2.523986339569092,
      "logits/rejected": -1.8665289878845215,
      "logps/chosen": -69.43907165527344,
      "logps/rejected": -187.56048583984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6963150501251221,
      "rewards/margins": 12.304224014282227,
      "rewards/rejected": -11.607908248901367,
      "step": 7022
    },
    {
      "epoch": 2.8092,
      "grad_norm": 0.00022497758618555963,
      "learning_rate": 6.373333333333333e-08,
      "logits/chosen": -2.6488523483276367,
      "logits/rejected": -1.8804099559783936,
      "logps/chosen": -78.99757385253906,
      "logps/rejected": -183.22003173828125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2723407745361328,
      "rewards/margins": 14.276155471801758,
      "rewards/rejected": -13.003814697265625,
      "step": 7023
    },
    {
      "epoch": 2.8096,
      "grad_norm": 0.00021204634686000645,
      "learning_rate": 6.36e-08,
      "logits/chosen": -2.174699306488037,
      "logits/rejected": -1.5139631032943726,
      "logps/chosen": -62.555076599121094,
      "logps/rejected": -290.4073486328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.111820697784424,
      "rewards/margins": 17.586687088012695,
      "rewards/rejected": -15.47486686706543,
      "step": 7024
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.0012981818290427327,
      "learning_rate": 6.346666666666667e-08,
      "logits/chosen": -2.3366992473602295,
      "logits/rejected": -1.8103992938995361,
      "logps/chosen": -135.59817504882812,
      "logps/rejected": -203.0093994140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.020738601684570312,
      "rewards/margins": 12.348320007324219,
      "rewards/rejected": -12.369058609008789,
      "step": 7025
    },
    {
      "epoch": 2.8104,
      "grad_norm": 0.009163725189864635,
      "learning_rate": 6.333333333333333e-08,
      "logits/chosen": -2.9131126403808594,
      "logits/rejected": -2.421454668045044,
      "logps/chosen": -64.51004028320312,
      "logps/rejected": -145.96078491210938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.19739419221878052,
      "rewards/margins": 10.314376831054688,
      "rewards/rejected": -10.511770248413086,
      "step": 7026
    },
    {
      "epoch": 2.8108,
      "grad_norm": 0.0006735385395586491,
      "learning_rate": 6.32e-08,
      "logits/chosen": -2.732158660888672,
      "logits/rejected": -2.4842429161071777,
      "logps/chosen": -90.73211669921875,
      "logps/rejected": -185.74659729003906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.030247688293457,
      "rewards/margins": 12.84320068359375,
      "rewards/rejected": -13.873448371887207,
      "step": 7027
    },
    {
      "epoch": 2.8112,
      "grad_norm": 0.07458139955997467,
      "learning_rate": 6.306666666666666e-08,
      "logits/chosen": -2.3511605262756348,
      "logits/rejected": -2.1458520889282227,
      "logps/chosen": -155.01132202148438,
      "logps/rejected": -158.971435546875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.4897422790527344,
      "rewards/margins": 8.571907043457031,
      "rewards/rejected": -11.061649322509766,
      "step": 7028
    },
    {
      "epoch": 2.8116,
      "grad_norm": 0.0020184037275612354,
      "learning_rate": 6.293333333333333e-08,
      "logits/chosen": -2.0849194526672363,
      "logits/rejected": -1.2691833972930908,
      "logps/chosen": -271.37701416015625,
      "logps/rejected": -232.0999298095703,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.013508677482605,
      "rewards/margins": 13.816701889038086,
      "rewards/rejected": -14.830209732055664,
      "step": 7029
    },
    {
      "epoch": 2.8120000000000003,
      "grad_norm": 0.217048779129982,
      "learning_rate": 6.279999999999999e-08,
      "logits/chosen": -2.770942211151123,
      "logits/rejected": -2.4048001766204834,
      "logps/chosen": -65.44596862792969,
      "logps/rejected": -115.48155212402344,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0806362628936768,
      "rewards/margins": 7.414736747741699,
      "rewards/rejected": -6.334100723266602,
      "step": 7030
    },
    {
      "epoch": 2.8124000000000002,
      "grad_norm": 1.6358933448791504,
      "learning_rate": 6.266666666666666e-08,
      "logits/chosen": -2.843183994293213,
      "logits/rejected": -2.6976757049560547,
      "logps/chosen": -62.98424530029297,
      "logps/rejected": -86.10078430175781,
      "loss": 0.0097,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0849319696426392,
      "rewards/margins": 6.9269280433654785,
      "rewards/rejected": -5.841996192932129,
      "step": 7031
    },
    {
      "epoch": 2.8128,
      "grad_norm": 0.004044140689074993,
      "learning_rate": 6.253333333333332e-08,
      "logits/chosen": -2.4727554321289062,
      "logits/rejected": -1.7841486930847168,
      "logps/chosen": -108.89063262939453,
      "logps/rejected": -190.40182495117188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20685425400733948,
      "rewards/margins": 13.052955627441406,
      "rewards/rejected": -12.846100807189941,
      "step": 7032
    },
    {
      "epoch": 2.8132,
      "grad_norm": 13.177735328674316,
      "learning_rate": 6.239999999999999e-08,
      "logits/chosen": -2.188908100128174,
      "logits/rejected": -2.017874240875244,
      "logps/chosen": -285.59698486328125,
      "logps/rejected": -172.8831329345703,
      "loss": 0.0409,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.479612350463867,
      "rewards/margins": 4.644374370574951,
      "rewards/rejected": -11.123987197875977,
      "step": 7033
    },
    {
      "epoch": 2.8136,
      "grad_norm": 0.014343569055199623,
      "learning_rate": 6.226666666666667e-08,
      "logits/chosen": -2.235903739929199,
      "logits/rejected": -1.8589359521865845,
      "logps/chosen": -163.37295532226562,
      "logps/rejected": -162.5004119873047,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7707077264785767,
      "rewards/margins": 10.464786529541016,
      "rewards/rejected": -8.694079399108887,
      "step": 7034
    },
    {
      "epoch": 2.814,
      "grad_norm": 0.04258991777896881,
      "learning_rate": 6.213333333333333e-08,
      "logits/chosen": -2.502291440963745,
      "logits/rejected": -2.164551258087158,
      "logps/chosen": -120.46391296386719,
      "logps/rejected": -198.05654907226562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7283775210380554,
      "rewards/margins": 9.864924430847168,
      "rewards/rejected": -10.593301773071289,
      "step": 7035
    },
    {
      "epoch": 2.8144,
      "grad_norm": 0.003141911933198571,
      "learning_rate": 6.2e-08,
      "logits/chosen": -2.620772361755371,
      "logits/rejected": -2.118894577026367,
      "logps/chosen": -110.7872314453125,
      "logps/rejected": -198.03073120117188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9284587502479553,
      "rewards/margins": 15.306902885437012,
      "rewards/rejected": -14.37844467163086,
      "step": 7036
    },
    {
      "epoch": 2.8148,
      "grad_norm": 69.63636779785156,
      "learning_rate": 6.186666666666666e-08,
      "logits/chosen": -2.5076382160186768,
      "logits/rejected": -1.960265040397644,
      "logps/chosen": -190.27810668945312,
      "logps/rejected": -207.5266571044922,
      "loss": 0.4464,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -5.28741979598999,
      "rewards/margins": 8.053272247314453,
      "rewards/rejected": -13.340691566467285,
      "step": 7037
    },
    {
      "epoch": 2.8152,
      "grad_norm": 0.003021677490323782,
      "learning_rate": 6.173333333333333e-08,
      "logits/chosen": -2.2409465312957764,
      "logits/rejected": -1.7402119636535645,
      "logps/chosen": -110.49446105957031,
      "logps/rejected": -167.01718139648438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40915220975875854,
      "rewards/margins": 11.392902374267578,
      "rewards/rejected": -10.983750343322754,
      "step": 7038
    },
    {
      "epoch": 2.8156,
      "grad_norm": 0.08785339444875717,
      "learning_rate": 6.16e-08,
      "logits/chosen": -2.8214621543884277,
      "logits/rejected": -2.6662440299987793,
      "logps/chosen": -109.22698211669922,
      "logps/rejected": -171.60202026367188,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34631580114364624,
      "rewards/margins": 9.480310440063477,
      "rewards/rejected": -9.133995056152344,
      "step": 7039
    },
    {
      "epoch": 2.816,
      "grad_norm": 0.0012633950682356954,
      "learning_rate": 6.146666666666666e-08,
      "logits/chosen": -2.602792263031006,
      "logits/rejected": -1.9841771125793457,
      "logps/chosen": -70.77801513671875,
      "logps/rejected": -203.85423278808594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8807167410850525,
      "rewards/margins": 12.79515552520752,
      "rewards/rejected": -13.675872802734375,
      "step": 7040
    },
    {
      "epoch": 2.8164,
      "grad_norm": 0.015258862636983395,
      "learning_rate": 6.133333333333333e-08,
      "logits/chosen": -2.6046223640441895,
      "logits/rejected": -2.060760021209717,
      "logps/chosen": -126.48406219482422,
      "logps/rejected": -196.14198303222656,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.2513184547424316,
      "rewards/margins": 10.840417861938477,
      "rewards/rejected": -13.09173583984375,
      "step": 7041
    },
    {
      "epoch": 2.8167999999999997,
      "grad_norm": 0.0008577425614930689,
      "learning_rate": 6.119999999999999e-08,
      "logits/chosen": -2.517604351043701,
      "logits/rejected": -1.688277006149292,
      "logps/chosen": -115.61703491210938,
      "logps/rejected": -220.00424194335938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6322993636131287,
      "rewards/margins": 13.860898971557617,
      "rewards/rejected": -14.49319839477539,
      "step": 7042
    },
    {
      "epoch": 2.8172,
      "grad_norm": 0.050753913819789886,
      "learning_rate": 6.106666666666666e-08,
      "logits/chosen": -2.751051902770996,
      "logits/rejected": -1.926483154296875,
      "logps/chosen": -99.82130432128906,
      "logps/rejected": -235.21615600585938,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7485229969024658,
      "rewards/margins": 11.936863899230957,
      "rewards/rejected": -12.685386657714844,
      "step": 7043
    },
    {
      "epoch": 2.8176,
      "grad_norm": 0.006472498644143343,
      "learning_rate": 6.093333333333332e-08,
      "logits/chosen": -2.553915023803711,
      "logits/rejected": -1.9379223585128784,
      "logps/chosen": -123.3765869140625,
      "logps/rejected": -209.08261108398438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.039532482624053955,
      "rewards/margins": 12.8819580078125,
      "rewards/rejected": -12.842424392700195,
      "step": 7044
    },
    {
      "epoch": 2.818,
      "grad_norm": 1.349593162536621,
      "learning_rate": 6.08e-08,
      "logits/chosen": -2.5337741374969482,
      "logits/rejected": -2.4637317657470703,
      "logps/chosen": -140.14895629882812,
      "logps/rejected": -114.80899047851562,
      "loss": 0.0086,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.7870240211486816,
      "rewards/margins": 4.781968116760254,
      "rewards/rejected": -7.5689921379089355,
      "step": 7045
    },
    {
      "epoch": 2.8184,
      "grad_norm": 0.00463136238977313,
      "learning_rate": 6.066666666666667e-08,
      "logits/chosen": -2.280301570892334,
      "logits/rejected": -1.5074000358581543,
      "logps/chosen": -138.25570678710938,
      "logps/rejected": -176.45223999023438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.173892617225647,
      "rewards/margins": 12.012350082397461,
      "rewards/rejected": -10.838457107543945,
      "step": 7046
    },
    {
      "epoch": 2.8188,
      "grad_norm": 0.009604114107787609,
      "learning_rate": 6.053333333333333e-08,
      "logits/chosen": -2.3550682067871094,
      "logits/rejected": -1.5449038743972778,
      "logps/chosen": -130.08840942382812,
      "logps/rejected": -230.56784057617188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4797603487968445,
      "rewards/margins": 13.198689460754395,
      "rewards/rejected": -12.718929290771484,
      "step": 7047
    },
    {
      "epoch": 2.8192,
      "grad_norm": 4.17259407043457,
      "learning_rate": 6.04e-08,
      "logits/chosen": -2.136089563369751,
      "logits/rejected": -1.6801939010620117,
      "logps/chosen": -199.92198181152344,
      "logps/rejected": -263.2412109375,
      "loss": 0.0153,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -6.114508152008057,
      "rewards/margins": 12.169641494750977,
      "rewards/rejected": -18.284149169921875,
      "step": 7048
    },
    {
      "epoch": 2.8196,
      "grad_norm": 0.0002515703672543168,
      "learning_rate": 6.026666666666666e-08,
      "logits/chosen": -2.6670422554016113,
      "logits/rejected": -2.216395616531372,
      "logps/chosen": -99.74234008789062,
      "logps/rejected": -221.72634887695312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5817486047744751,
      "rewards/margins": 15.554319381713867,
      "rewards/rejected": -14.972570419311523,
      "step": 7049
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.000263379595708102,
      "learning_rate": 6.013333333333333e-08,
      "logits/chosen": -2.223422050476074,
      "logits/rejected": -1.2232122421264648,
      "logps/chosen": -147.63479614257812,
      "logps/rejected": -256.1988220214844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19860565662384033,
      "rewards/margins": 16.66377830505371,
      "rewards/rejected": -16.465173721313477,
      "step": 7050
    },
    {
      "epoch": 2.8204000000000002,
      "grad_norm": 0.000852677330840379,
      "learning_rate": 6e-08,
      "logits/chosen": -2.4490175247192383,
      "logits/rejected": -1.8581054210662842,
      "logps/chosen": -135.69058227539062,
      "logps/rejected": -219.8162841796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5055896639823914,
      "rewards/margins": 14.367330551147461,
      "rewards/rejected": -13.861741065979004,
      "step": 7051
    },
    {
      "epoch": 2.8208,
      "grad_norm": 0.08522383868694305,
      "learning_rate": 5.986666666666666e-08,
      "logits/chosen": -2.434619903564453,
      "logits/rejected": -1.9472742080688477,
      "logps/chosen": -73.10276794433594,
      "logps/rejected": -171.68212890625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2414665222167969,
      "rewards/margins": 11.72028636932373,
      "rewards/rejected": -10.47882080078125,
      "step": 7052
    },
    {
      "epoch": 2.8212,
      "grad_norm": 0.01534679252654314,
      "learning_rate": 5.973333333333333e-08,
      "logits/chosen": -2.5110392570495605,
      "logits/rejected": -2.224273681640625,
      "logps/chosen": -55.96710205078125,
      "logps/rejected": -136.58038330078125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6633156538009644,
      "rewards/margins": 10.56028938293457,
      "rewards/rejected": -8.896973609924316,
      "step": 7053
    },
    {
      "epoch": 2.8216,
      "grad_norm": 0.003585627069696784,
      "learning_rate": 5.96e-08,
      "logits/chosen": -2.111759901046753,
      "logits/rejected": -1.4571151733398438,
      "logps/chosen": -274.4352111816406,
      "logps/rejected": -315.76544189453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.589810848236084,
      "rewards/margins": 11.74072265625,
      "rewards/rejected": -15.330533981323242,
      "step": 7054
    },
    {
      "epoch": 2.822,
      "grad_norm": 0.024681584909558296,
      "learning_rate": 5.946666666666666e-08,
      "logits/chosen": -2.8509597778320312,
      "logits/rejected": -2.4371724128723145,
      "logps/chosen": -54.67299270629883,
      "logps/rejected": -147.8272247314453,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12249812483787537,
      "rewards/margins": 10.690167427062988,
      "rewards/rejected": -10.567668914794922,
      "step": 7055
    },
    {
      "epoch": 2.8224,
      "grad_norm": 1.107131004333496,
      "learning_rate": 5.9333333333333335e-08,
      "logits/chosen": -2.7438488006591797,
      "logits/rejected": -2.4451375007629395,
      "logps/chosen": -66.21814727783203,
      "logps/rejected": -142.1999969482422,
      "loss": 0.0078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06758004426956177,
      "rewards/margins": 9.56031608581543,
      "rewards/rejected": -9.492735862731934,
      "step": 7056
    },
    {
      "epoch": 2.8228,
      "grad_norm": 0.01738642528653145,
      "learning_rate": 5.92e-08,
      "logits/chosen": -2.920142889022827,
      "logits/rejected": -2.5188474655151367,
      "logps/chosen": -118.9063720703125,
      "logps/rejected": -156.99356079101562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.26093292236328125,
      "rewards/margins": 10.08128833770752,
      "rewards/rejected": -10.3422212600708,
      "step": 7057
    },
    {
      "epoch": 2.8232,
      "grad_norm": 1.2019448280334473,
      "learning_rate": 5.9066666666666666e-08,
      "logits/chosen": -2.3570351600646973,
      "logits/rejected": -1.8294508457183838,
      "logps/chosen": -107.66941833496094,
      "logps/rejected": -165.16909790039062,
      "loss": 0.0079,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21954619884490967,
      "rewards/margins": 10.768452644348145,
      "rewards/rejected": -10.548906326293945,
      "step": 7058
    },
    {
      "epoch": 2.8236,
      "grad_norm": 0.00873481947928667,
      "learning_rate": 5.8933333333333325e-08,
      "logits/chosen": -2.68526554107666,
      "logits/rejected": -2.301211357116699,
      "logps/chosen": -86.57012939453125,
      "logps/rejected": -220.76341247558594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5788673162460327,
      "rewards/margins": 14.705267906188965,
      "rewards/rejected": -13.1264009475708,
      "step": 7059
    },
    {
      "epoch": 2.824,
      "grad_norm": 0.04071170091629028,
      "learning_rate": 5.88e-08,
      "logits/chosen": -2.290250778198242,
      "logits/rejected": -2.23364520072937,
      "logps/chosen": -215.58590698242188,
      "logps/rejected": -168.5021209716797,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0989865064620972,
      "rewards/margins": 8.532468795776367,
      "rewards/rejected": -9.631455421447754,
      "step": 7060
    },
    {
      "epoch": 2.8244,
      "grad_norm": 0.10300210863351822,
      "learning_rate": 5.866666666666666e-08,
      "logits/chosen": -2.3711533546447754,
      "logits/rejected": -1.9762554168701172,
      "logps/chosen": -93.46145629882812,
      "logps/rejected": -133.79345703125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.009893223643302917,
      "rewards/margins": 7.789701461791992,
      "rewards/rejected": -7.779808044433594,
      "step": 7061
    },
    {
      "epoch": 2.8247999999999998,
      "grad_norm": 0.0482386089861393,
      "learning_rate": 5.853333333333333e-08,
      "logits/chosen": -2.5713613033294678,
      "logits/rejected": -2.3174662590026855,
      "logps/chosen": -113.34661865234375,
      "logps/rejected": -136.40093994140625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9985717535018921,
      "rewards/margins": 8.821053504943848,
      "rewards/rejected": -9.819624900817871,
      "step": 7062
    },
    {
      "epoch": 2.8252,
      "grad_norm": 4.568902492523193,
      "learning_rate": 5.84e-08,
      "logits/chosen": -2.4004933834075928,
      "logits/rejected": -1.9818859100341797,
      "logps/chosen": -138.42091369628906,
      "logps/rejected": -193.10488891601562,
      "loss": 0.0224,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8170027136802673,
      "rewards/margins": 10.401442527770996,
      "rewards/rejected": -11.21844482421875,
      "step": 7063
    },
    {
      "epoch": 2.8256,
      "grad_norm": 6.683133602142334,
      "learning_rate": 5.8266666666666666e-08,
      "logits/chosen": -2.4291112422943115,
      "logits/rejected": -2.3157002925872803,
      "logps/chosen": -63.4754524230957,
      "logps/rejected": -143.03318786621094,
      "loss": 0.057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9436231851577759,
      "rewards/margins": 8.55299186706543,
      "rewards/rejected": -9.496615409851074,
      "step": 7064
    },
    {
      "epoch": 2.826,
      "grad_norm": 162.73922729492188,
      "learning_rate": 5.813333333333333e-08,
      "logits/chosen": -2.1243789196014404,
      "logits/rejected": -2.0449233055114746,
      "logps/chosen": -239.0897216796875,
      "logps/rejected": -167.4718017578125,
      "loss": 0.5752,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -8.254547119140625,
      "rewards/margins": 2.5980000495910645,
      "rewards/rejected": -10.852547645568848,
      "step": 7065
    },
    {
      "epoch": 2.8264,
      "grad_norm": 2.9630582332611084,
      "learning_rate": 5.8e-08,
      "logits/chosen": -2.782703399658203,
      "logits/rejected": -2.575578212738037,
      "logps/chosen": -99.9769287109375,
      "logps/rejected": -116.16015625,
      "loss": 0.0149,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.047656625509262085,
      "rewards/margins": 7.314218997955322,
      "rewards/rejected": -7.361875534057617,
      "step": 7066
    },
    {
      "epoch": 2.8268,
      "grad_norm": 0.00024802336702123284,
      "learning_rate": 5.786666666666666e-08,
      "logits/chosen": -2.392502784729004,
      "logits/rejected": -1.5778368711471558,
      "logps/chosen": -101.18207550048828,
      "logps/rejected": -231.3731689453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8516132235527039,
      "rewards/margins": 15.647109985351562,
      "rewards/rejected": -14.795495986938477,
      "step": 7067
    },
    {
      "epoch": 2.8272,
      "grad_norm": 1.0765300989151,
      "learning_rate": 5.773333333333333e-08,
      "logits/chosen": -2.8415493965148926,
      "logits/rejected": -2.871469020843506,
      "logps/chosen": -73.82084655761719,
      "logps/rejected": -82.7743911743164,
      "loss": 0.0079,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6453040838241577,
      "rewards/margins": 4.992373466491699,
      "rewards/rejected": -5.6376776695251465,
      "step": 7068
    },
    {
      "epoch": 2.8276,
      "grad_norm": 5.5223816161742434e-05,
      "learning_rate": 5.759999999999999e-08,
      "logits/chosen": -2.760847568511963,
      "logits/rejected": -2.1121363639831543,
      "logps/chosen": -97.98699951171875,
      "logps/rejected": -227.1658477783203,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6887298822402954,
      "rewards/margins": 16.249204635620117,
      "rewards/rejected": -16.93793487548828,
      "step": 7069
    },
    {
      "epoch": 2.828,
      "grad_norm": 0.0008433338953182101,
      "learning_rate": 5.7466666666666665e-08,
      "logits/chosen": -2.639179229736328,
      "logits/rejected": -2.207655668258667,
      "logps/chosen": -106.85865783691406,
      "logps/rejected": -146.85047912597656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9708747863769531,
      "rewards/margins": 12.795404434204102,
      "rewards/rejected": -10.824529647827148,
      "step": 7070
    },
    {
      "epoch": 2.8284000000000002,
      "grad_norm": 0.00978355947881937,
      "learning_rate": 5.733333333333333e-08,
      "logits/chosen": -2.867934226989746,
      "logits/rejected": -2.183938503265381,
      "logps/chosen": -44.38959503173828,
      "logps/rejected": -209.6487579345703,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3422179222106934,
      "rewards/margins": 16.197547912597656,
      "rewards/rejected": -14.855330467224121,
      "step": 7071
    },
    {
      "epoch": 2.8288,
      "grad_norm": 0.01614406332373619,
      "learning_rate": 5.7199999999999996e-08,
      "logits/chosen": -2.636841297149658,
      "logits/rejected": -2.1771888732910156,
      "logps/chosen": -92.72213745117188,
      "logps/rejected": -174.52157592773438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7469006180763245,
      "rewards/margins": 10.491813659667969,
      "rewards/rejected": -11.238714218139648,
      "step": 7072
    },
    {
      "epoch": 2.8292,
      "grad_norm": 1.310181736946106,
      "learning_rate": 5.706666666666667e-08,
      "logits/chosen": -2.593524932861328,
      "logits/rejected": -1.9525055885314941,
      "logps/chosen": -114.67665100097656,
      "logps/rejected": -151.21835327148438,
      "loss": 0.0061,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1722278594970703,
      "rewards/margins": 8.28883171081543,
      "rewards/rejected": -8.461060523986816,
      "step": 7073
    },
    {
      "epoch": 2.8296,
      "grad_norm": 0.00575135787948966,
      "learning_rate": 5.6933333333333334e-08,
      "logits/chosen": -2.4455971717834473,
      "logits/rejected": -1.834068775177002,
      "logps/chosen": -120.37145233154297,
      "logps/rejected": -174.22378540039062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03704681992530823,
      "rewards/margins": 11.901972770690918,
      "rewards/rejected": -11.8649263381958,
      "step": 7074
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.943901777267456,
      "learning_rate": 5.68e-08,
      "logits/chosen": -2.5057172775268555,
      "logits/rejected": -2.1070616245269775,
      "logps/chosen": -111.56552124023438,
      "logps/rejected": -100.76690673828125,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2790253162384033,
      "rewards/margins": 6.770819664001465,
      "rewards/rejected": -5.491794586181641,
      "step": 7075
    },
    {
      "epoch": 2.8304,
      "grad_norm": 0.0004902241635136306,
      "learning_rate": 5.666666666666666e-08,
      "logits/chosen": -2.7325668334960938,
      "logits/rejected": -2.174905776977539,
      "logps/chosen": -42.007015228271484,
      "logps/rejected": -207.13510131835938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07604417204856873,
      "rewards/margins": 13.941944122314453,
      "rewards/rejected": -13.865900039672852,
      "step": 7076
    },
    {
      "epoch": 2.8308,
      "grad_norm": 0.0001396498701069504,
      "learning_rate": 5.653333333333333e-08,
      "logits/chosen": -2.704573631286621,
      "logits/rejected": -1.9742223024368286,
      "logps/chosen": -77.5298080444336,
      "logps/rejected": -228.46954345703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9130045175552368,
      "rewards/margins": 16.571876525878906,
      "rewards/rejected": -15.658872604370117,
      "step": 7077
    },
    {
      "epoch": 2.8312,
      "grad_norm": 0.0004394612624309957,
      "learning_rate": 5.6399999999999995e-08,
      "logits/chosen": -2.5606870651245117,
      "logits/rejected": -1.825373649597168,
      "logps/chosen": -172.8701171875,
      "logps/rejected": -206.82264709472656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8850967884063721,
      "rewards/margins": 13.968414306640625,
      "rewards/rejected": -13.083317756652832,
      "step": 7078
    },
    {
      "epoch": 2.8316,
      "grad_norm": 0.0032181658316403627,
      "learning_rate": 5.626666666666666e-08,
      "logits/chosen": -2.3919103145599365,
      "logits/rejected": -1.8969485759735107,
      "logps/chosen": -124.64767456054688,
      "logps/rejected": -215.32363891601562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2054802030324936,
      "rewards/margins": 13.970778465270996,
      "rewards/rejected": -14.17625904083252,
      "step": 7079
    },
    {
      "epoch": 2.832,
      "grad_norm": 0.09621625393629074,
      "learning_rate": 5.613333333333333e-08,
      "logits/chosen": -2.8350298404693604,
      "logits/rejected": -2.3750386238098145,
      "logps/chosen": -63.69735336303711,
      "logps/rejected": -126.38330841064453,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6617523431777954,
      "rewards/margins": 9.170254707336426,
      "rewards/rejected": -8.508502960205078,
      "step": 7080
    },
    {
      "epoch": 2.8324,
      "grad_norm": 0.006636790465563536,
      "learning_rate": 5.6e-08,
      "logits/chosen": -2.123983860015869,
      "logits/rejected": -1.5570261478424072,
      "logps/chosen": -87.49467468261719,
      "logps/rejected": -152.96165466308594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5190556049346924,
      "rewards/margins": 10.763664245605469,
      "rewards/rejected": -9.244608879089355,
      "step": 7081
    },
    {
      "epoch": 2.8327999999999998,
      "grad_norm": 0.009018990211188793,
      "learning_rate": 5.5866666666666664e-08,
      "logits/chosen": -2.6543190479278564,
      "logits/rejected": -2.4633893966674805,
      "logps/chosen": -71.08214569091797,
      "logps/rejected": -210.92547607421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7174892425537109,
      "rewards/margins": 14.649689674377441,
      "rewards/rejected": -13.93220043182373,
      "step": 7082
    },
    {
      "epoch": 2.8332,
      "grad_norm": 1.2894877195358276,
      "learning_rate": 5.5733333333333336e-08,
      "logits/chosen": -2.5919103622436523,
      "logits/rejected": -2.345414638519287,
      "logps/chosen": -163.40933227539062,
      "logps/rejected": -124.76469421386719,
      "loss": 0.005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.0858585834503174,
      "rewards/margins": 6.28978157043457,
      "rewards/rejected": -9.375639915466309,
      "step": 7083
    },
    {
      "epoch": 2.8336,
      "grad_norm": 6.618677139282227,
      "learning_rate": 5.5599999999999995e-08,
      "logits/chosen": -2.876274585723877,
      "logits/rejected": -2.802035331726074,
      "logps/chosen": -144.22378540039062,
      "logps/rejected": -107.47798156738281,
      "loss": 0.0279,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.162203550338745,
      "rewards/margins": 4.4927239418029785,
      "rewards/rejected": -7.6549272537231445,
      "step": 7084
    },
    {
      "epoch": 2.834,
      "grad_norm": 0.0037736129015684128,
      "learning_rate": 5.546666666666666e-08,
      "logits/chosen": -2.130265712738037,
      "logits/rejected": -1.316544532775879,
      "logps/chosen": -162.28868103027344,
      "logps/rejected": -199.00253295898438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3820781707763672,
      "rewards/margins": 12.23619270324707,
      "rewards/rejected": -12.618270874023438,
      "step": 7085
    },
    {
      "epoch": 2.8344,
      "grad_norm": 0.8360545635223389,
      "learning_rate": 5.5333333333333326e-08,
      "logits/chosen": -2.61382794380188,
      "logits/rejected": -2.2156996726989746,
      "logps/chosen": -100.22496032714844,
      "logps/rejected": -131.44818115234375,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.264725923538208,
      "rewards/margins": 6.310647010803223,
      "rewards/rejected": -7.575372695922852,
      "step": 7086
    },
    {
      "epoch": 2.8348,
      "grad_norm": 0.10228625684976578,
      "learning_rate": 5.52e-08,
      "logits/chosen": -2.7917304039001465,
      "logits/rejected": -2.3730039596557617,
      "logps/chosen": -126.95398712158203,
      "logps/rejected": -139.681640625,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6201759576797485,
      "rewards/margins": 10.143718719482422,
      "rewards/rejected": -9.523542404174805,
      "step": 7087
    },
    {
      "epoch": 2.8352,
      "grad_norm": 0.21431882679462433,
      "learning_rate": 5.5066666666666663e-08,
      "logits/chosen": -2.5753540992736816,
      "logits/rejected": -2.1999268531799316,
      "logps/chosen": -171.3033447265625,
      "logps/rejected": -153.64959716796875,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3361188769340515,
      "rewards/margins": 8.857900619506836,
      "rewards/rejected": -9.194019317626953,
      "step": 7088
    },
    {
      "epoch": 2.8356,
      "grad_norm": 5.305851936340332,
      "learning_rate": 5.493333333333333e-08,
      "logits/chosen": -2.906899929046631,
      "logits/rejected": -2.551450252532959,
      "logps/chosen": -134.92823791503906,
      "logps/rejected": -99.31771850585938,
      "loss": 0.0339,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.5063602924346924,
      "rewards/margins": 3.8753557205200195,
      "rewards/rejected": -6.381715774536133,
      "step": 7089
    },
    {
      "epoch": 2.836,
      "grad_norm": 0.5803835988044739,
      "learning_rate": 5.48e-08,
      "logits/chosen": -2.4702553749084473,
      "logits/rejected": -2.05014705657959,
      "logps/chosen": -128.53070068359375,
      "logps/rejected": -130.27891540527344,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3605491816997528,
      "rewards/margins": 7.9625244140625,
      "rewards/rejected": -8.323073387145996,
      "step": 7090
    },
    {
      "epoch": 2.8364000000000003,
      "grad_norm": 0.026304753497242928,
      "learning_rate": 5.4666666666666666e-08,
      "logits/chosen": -2.429290294647217,
      "logits/rejected": -1.8866169452667236,
      "logps/chosen": -150.06454467773438,
      "logps/rejected": -192.351318359375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8870716094970703,
      "rewards/margins": 10.637176513671875,
      "rewards/rejected": -11.524248123168945,
      "step": 7091
    },
    {
      "epoch": 2.8368,
      "grad_norm": 0.003248513676226139,
      "learning_rate": 5.453333333333333e-08,
      "logits/chosen": -2.579832077026367,
      "logits/rejected": -1.6793808937072754,
      "logps/chosen": -77.79035186767578,
      "logps/rejected": -140.01565551757812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.117774248123169,
      "rewards/margins": 11.256778717041016,
      "rewards/rejected": -9.139004707336426,
      "step": 7092
    },
    {
      "epoch": 2.8372,
      "grad_norm": 0.027493497356772423,
      "learning_rate": 5.44e-08,
      "logits/chosen": -2.6240148544311523,
      "logits/rejected": -2.1869890689849854,
      "logps/chosen": -69.75665283203125,
      "logps/rejected": -149.0702667236328,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2800526022911072,
      "rewards/margins": 9.765445709228516,
      "rewards/rejected": -9.485393524169922,
      "step": 7093
    },
    {
      "epoch": 2.8376,
      "grad_norm": 0.002892180811613798,
      "learning_rate": 5.426666666666666e-08,
      "logits/chosen": -2.9274978637695312,
      "logits/rejected": -2.4658403396606445,
      "logps/chosen": -70.02659606933594,
      "logps/rejected": -159.429931640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8615415692329407,
      "rewards/margins": 11.322333335876465,
      "rewards/rejected": -10.46079158782959,
      "step": 7094
    },
    {
      "epoch": 2.838,
      "grad_norm": 0.0012657656334340572,
      "learning_rate": 5.413333333333333e-08,
      "logits/chosen": -2.513248920440674,
      "logits/rejected": -1.6844782829284668,
      "logps/chosen": -91.93415832519531,
      "logps/rejected": -182.9643096923828,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3713516294956207,
      "rewards/margins": 12.638568878173828,
      "rewards/rejected": -12.267216682434082,
      "step": 7095
    },
    {
      "epoch": 2.8384,
      "grad_norm": 0.028871629387140274,
      "learning_rate": 5.3999999999999994e-08,
      "logits/chosen": -2.882854461669922,
      "logits/rejected": -2.375840663909912,
      "logps/chosen": -61.942237854003906,
      "logps/rejected": -126.67680358886719,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4776611626148224,
      "rewards/margins": 9.092581748962402,
      "rewards/rejected": -8.614920616149902,
      "step": 7096
    },
    {
      "epoch": 2.8388,
      "grad_norm": 0.0027498153503984213,
      "learning_rate": 5.3866666666666666e-08,
      "logits/chosen": -2.7678046226501465,
      "logits/rejected": -2.3521456718444824,
      "logps/chosen": -53.37565612792969,
      "logps/rejected": -148.19761657714844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.120517611503601,
      "rewards/margins": 11.425747871398926,
      "rewards/rejected": -10.305230140686035,
      "step": 7097
    },
    {
      "epoch": 2.8392,
      "grad_norm": 0.002152784029021859,
      "learning_rate": 5.373333333333333e-08,
      "logits/chosen": -2.5054931640625,
      "logits/rejected": -1.769659161567688,
      "logps/chosen": -119.32722473144531,
      "logps/rejected": -238.0686798095703,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4855480194091797,
      "rewards/margins": 12.852048873901367,
      "rewards/rejected": -12.366500854492188,
      "step": 7098
    },
    {
      "epoch": 2.8396,
      "grad_norm": 0.013804451562464237,
      "learning_rate": 5.36e-08,
      "logits/chosen": -2.3859407901763916,
      "logits/rejected": -1.672558069229126,
      "logps/chosen": -121.61116790771484,
      "logps/rejected": -151.671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.010233104228973389,
      "rewards/margins": 10.354604721069336,
      "rewards/rejected": -10.364837646484375,
      "step": 7099
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.07520580291748047,
      "learning_rate": 5.346666666666667e-08,
      "logits/chosen": -2.580583095550537,
      "logits/rejected": -2.0054707527160645,
      "logps/chosen": -74.31151580810547,
      "logps/rejected": -153.75491333007812,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0498863458633423,
      "rewards/margins": 11.799105644226074,
      "rewards/rejected": -10.749218940734863,
      "step": 7100
    },
    {
      "epoch": 2.8404,
      "grad_norm": 0.0128819290548563,
      "learning_rate": 5.3333333333333334e-08,
      "logits/chosen": -2.4199299812316895,
      "logits/rejected": -1.9631413221359253,
      "logps/chosen": -61.55278778076172,
      "logps/rejected": -174.0572509765625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7662484645843506,
      "rewards/margins": 13.232368469238281,
      "rewards/rejected": -11.466119766235352,
      "step": 7101
    },
    {
      "epoch": 2.8407999999999998,
      "grad_norm": 0.21000167727470398,
      "learning_rate": 5.319999999999999e-08,
      "logits/chosen": -2.8124918937683105,
      "logits/rejected": -2.372494697570801,
      "logps/chosen": -69.54345703125,
      "logps/rejected": -151.17889404296875,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7436983585357666,
      "rewards/margins": 11.781457901000977,
      "rewards/rejected": -10.037759780883789,
      "step": 7102
    },
    {
      "epoch": 2.8411999999999997,
      "grad_norm": 0.00555118964985013,
      "learning_rate": 5.3066666666666665e-08,
      "logits/chosen": -2.9101438522338867,
      "logits/rejected": -2.3202571868896484,
      "logps/chosen": -48.02093505859375,
      "logps/rejected": -172.0668182373047,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1426817178726196,
      "rewards/margins": 12.86417007446289,
      "rewards/rejected": -11.721488952636719,
      "step": 7103
    },
    {
      "epoch": 2.8416,
      "grad_norm": 0.0014646414201706648,
      "learning_rate": 5.293333333333333e-08,
      "logits/chosen": -2.2204136848449707,
      "logits/rejected": -1.4649606943130493,
      "logps/chosen": -88.81061553955078,
      "logps/rejected": -203.8883056640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6172590255737305,
      "rewards/margins": 15.618337631225586,
      "rewards/rejected": -15.001077651977539,
      "step": 7104
    },
    {
      "epoch": 2.842,
      "grad_norm": 0.07612476497888565,
      "learning_rate": 5.2799999999999996e-08,
      "logits/chosen": -2.6680073738098145,
      "logits/rejected": -2.077486753463745,
      "logps/chosen": -116.834228515625,
      "logps/rejected": -198.69891357421875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0267746448516846,
      "rewards/margins": 11.939960479736328,
      "rewards/rejected": -12.966734886169434,
      "step": 7105
    },
    {
      "epoch": 2.8424,
      "grad_norm": 0.0274409931153059,
      "learning_rate": 5.266666666666666e-08,
      "logits/chosen": -2.5034947395324707,
      "logits/rejected": -2.065225601196289,
      "logps/chosen": -99.41046905517578,
      "logps/rejected": -151.569091796875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.06688344478607178,
      "rewards/margins": 10.255536079406738,
      "rewards/rejected": -10.322420120239258,
      "step": 7106
    },
    {
      "epoch": 2.8428,
      "grad_norm": 0.06894133985042572,
      "learning_rate": 5.2533333333333334e-08,
      "logits/chosen": -2.629845142364502,
      "logits/rejected": -2.460925340652466,
      "logps/chosen": -67.01237487792969,
      "logps/rejected": -108.69778442382812,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22187462449073792,
      "rewards/margins": 7.916241645812988,
      "rewards/rejected": -7.694366931915283,
      "step": 7107
    },
    {
      "epoch": 2.8432,
      "grad_norm": 0.00015466571494471282,
      "learning_rate": 5.24e-08,
      "logits/chosen": -2.8458187580108643,
      "logits/rejected": -1.9213712215423584,
      "logps/chosen": -63.90496826171875,
      "logps/rejected": -171.91513061523438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4039463996887207,
      "rewards/margins": 15.085622787475586,
      "rewards/rejected": -12.681676864624023,
      "step": 7108
    },
    {
      "epoch": 2.8436,
      "grad_norm": 0.00033775350311771035,
      "learning_rate": 5.2266666666666665e-08,
      "logits/chosen": -2.506178140640259,
      "logits/rejected": -1.5790174007415771,
      "logps/chosen": -169.76776123046875,
      "logps/rejected": -218.1219940185547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3550255000591278,
      "rewards/margins": 13.742971420288086,
      "rewards/rejected": -13.387945175170898,
      "step": 7109
    },
    {
      "epoch": 2.844,
      "grad_norm": 0.042104288935661316,
      "learning_rate": 5.213333333333333e-08,
      "logits/chosen": -3.16921067237854,
      "logits/rejected": -2.750840663909912,
      "logps/chosen": -53.93653106689453,
      "logps/rejected": -170.81373596191406,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3781509399414062,
      "rewards/margins": 11.363826751708984,
      "rewards/rejected": -9.985675811767578,
      "step": 7110
    },
    {
      "epoch": 2.8444000000000003,
      "grad_norm": 0.021907970309257507,
      "learning_rate": 5.1999999999999996e-08,
      "logits/chosen": -2.3170948028564453,
      "logits/rejected": -1.4895343780517578,
      "logps/chosen": -127.73213195800781,
      "logps/rejected": -166.1236572265625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.22967875003814697,
      "rewards/margins": 10.974891662597656,
      "rewards/rejected": -11.204570770263672,
      "step": 7111
    },
    {
      "epoch": 2.8448,
      "grad_norm": 0.37721356749534607,
      "learning_rate": 5.186666666666666e-08,
      "logits/chosen": -2.3911120891571045,
      "logits/rejected": -1.869563341140747,
      "logps/chosen": -108.64837646484375,
      "logps/rejected": -203.34877014160156,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9551027417182922,
      "rewards/margins": 7.3118367195129395,
      "rewards/rejected": -6.356733798980713,
      "step": 7112
    },
    {
      "epoch": 2.8452,
      "grad_norm": 0.0003987555974163115,
      "learning_rate": 5.1733333333333333e-08,
      "logits/chosen": -2.448422908782959,
      "logits/rejected": -1.3977291584014893,
      "logps/chosen": -90.028564453125,
      "logps/rejected": -201.1873779296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4449355602264404,
      "rewards/margins": 14.065505981445312,
      "rewards/rejected": -12.620570182800293,
      "step": 7113
    },
    {
      "epoch": 2.8456,
      "grad_norm": 0.03397896885871887,
      "learning_rate": 5.16e-08,
      "logits/chosen": -2.078685760498047,
      "logits/rejected": -1.7481234073638916,
      "logps/chosen": -160.2329559326172,
      "logps/rejected": -272.3316345214844,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.033452242612838745,
      "rewards/margins": 11.071561813354492,
      "rewards/rejected": -11.10501480102539,
      "step": 7114
    },
    {
      "epoch": 2.846,
      "grad_norm": 0.04250756651163101,
      "learning_rate": 5.1466666666666664e-08,
      "logits/chosen": -2.6795754432678223,
      "logits/rejected": -2.389939785003662,
      "logps/chosen": -143.22308349609375,
      "logps/rejected": -173.587158203125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.482069969177246,
      "rewards/margins": 8.843423843383789,
      "rewards/rejected": -11.325494766235352,
      "step": 7115
    },
    {
      "epoch": 2.8464,
      "grad_norm": 1.9170624017715454,
      "learning_rate": 5.133333333333333e-08,
      "logits/chosen": -2.5905380249023438,
      "logits/rejected": -1.971095323562622,
      "logps/chosen": -111.9051513671875,
      "logps/rejected": -140.05026245117188,
      "loss": 0.0085,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4925975799560547,
      "rewards/margins": 9.69894790649414,
      "rewards/rejected": -10.191545486450195,
      "step": 7116
    },
    {
      "epoch": 2.8468,
      "grad_norm": 0.013461211696267128,
      "learning_rate": 5.12e-08,
      "logits/chosen": -2.4080700874328613,
      "logits/rejected": -1.7905466556549072,
      "logps/chosen": -155.8959503173828,
      "logps/rejected": -213.912841796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.280926465988159,
      "rewards/margins": 11.767468452453613,
      "rewards/rejected": -14.048395156860352,
      "step": 7117
    },
    {
      "epoch": 2.8472,
      "grad_norm": 0.0028751769568771124,
      "learning_rate": 5.106666666666667e-08,
      "logits/chosen": -2.422407627105713,
      "logits/rejected": -2.1718435287475586,
      "logps/chosen": -120.47006225585938,
      "logps/rejected": -240.24978637695312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.4570558071136475,
      "rewards/margins": 13.370237350463867,
      "rewards/rejected": -15.827293395996094,
      "step": 7118
    },
    {
      "epoch": 2.8476,
      "grad_norm": 0.004392456728965044,
      "learning_rate": 5.0933333333333326e-08,
      "logits/chosen": -2.343294620513916,
      "logits/rejected": -1.7892537117004395,
      "logps/chosen": -89.07624816894531,
      "logps/rejected": -200.39254760742188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.381073474884033,
      "rewards/margins": 12.861549377441406,
      "rewards/rejected": -9.480475425720215,
      "step": 7119
    },
    {
      "epoch": 2.848,
      "grad_norm": 0.4019966423511505,
      "learning_rate": 5.08e-08,
      "logits/chosen": -2.782611608505249,
      "logits/rejected": -2.4886584281921387,
      "logps/chosen": -94.20006561279297,
      "logps/rejected": -135.33261108398438,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.280723214149475,
      "rewards/margins": 7.243395805358887,
      "rewards/rejected": -8.524118423461914,
      "step": 7120
    },
    {
      "epoch": 2.8484,
      "grad_norm": 0.061695851385593414,
      "learning_rate": 5.0666666666666664e-08,
      "logits/chosen": -2.849242687225342,
      "logits/rejected": -2.576740026473999,
      "logps/chosen": -120.42304992675781,
      "logps/rejected": -124.55143737792969,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7889717221260071,
      "rewards/margins": 7.8587751388549805,
      "rewards/rejected": -8.647747039794922,
      "step": 7121
    },
    {
      "epoch": 2.8487999999999998,
      "grad_norm": 0.00043638836359605193,
      "learning_rate": 5.053333333333333e-08,
      "logits/chosen": -2.4940056800842285,
      "logits/rejected": -1.806475043296814,
      "logps/chosen": -129.39999389648438,
      "logps/rejected": -209.63766479492188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0794419050216675,
      "rewards/margins": 14.951616287231445,
      "rewards/rejected": -13.872174263000488,
      "step": 7122
    },
    {
      "epoch": 2.8491999999999997,
      "grad_norm": 0.0001709373900666833,
      "learning_rate": 5.04e-08,
      "logits/chosen": -2.4146597385406494,
      "logits/rejected": -2.0037848949432373,
      "logps/chosen": -73.419189453125,
      "logps/rejected": -197.7813720703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6615116596221924,
      "rewards/margins": 15.748779296875,
      "rewards/rejected": -14.08726692199707,
      "step": 7123
    },
    {
      "epoch": 2.8496,
      "grad_norm": 0.03809409961104393,
      "learning_rate": 5.026666666666667e-08,
      "logits/chosen": -2.427565574645996,
      "logits/rejected": -2.178384780883789,
      "logps/chosen": -78.70890808105469,
      "logps/rejected": -191.10089111328125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.088717222213745,
      "rewards/margins": 12.749736785888672,
      "rewards/rejected": -10.661019325256348,
      "step": 7124
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.006709561683237553,
      "learning_rate": 5.013333333333333e-08,
      "logits/chosen": -2.417078971862793,
      "logits/rejected": -2.3157858848571777,
      "logps/chosen": -55.90676498413086,
      "logps/rejected": -137.64093017578125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3652329444885254,
      "rewards/margins": 10.90943717956543,
      "rewards/rejected": -9.544204711914062,
      "step": 7125
    },
    {
      "epoch": 2.8504,
      "grad_norm": 0.11659124493598938,
      "learning_rate": 5e-08,
      "logits/chosen": -2.6862545013427734,
      "logits/rejected": -2.2568531036376953,
      "logps/chosen": -115.54341888427734,
      "logps/rejected": -138.71868896484375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.313378095626831,
      "rewards/margins": 11.231181144714355,
      "rewards/rejected": -9.917802810668945,
      "step": 7126
    },
    {
      "epoch": 2.8508,
      "grad_norm": 0.2278616577386856,
      "learning_rate": 4.986666666666666e-08,
      "logits/chosen": -2.9539706707000732,
      "logits/rejected": -2.7707300186157227,
      "logps/chosen": -67.259765625,
      "logps/rejected": -183.00631713867188,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7871240973472595,
      "rewards/margins": 11.161930084228516,
      "rewards/rejected": -10.374805450439453,
      "step": 7127
    },
    {
      "epoch": 2.8512,
      "grad_norm": 0.0035926043055951595,
      "learning_rate": 4.973333333333333e-08,
      "logits/chosen": -2.543606758117676,
      "logits/rejected": -1.9906529188156128,
      "logps/chosen": -66.87527465820312,
      "logps/rejected": -177.1549072265625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9303028583526611,
      "rewards/margins": 11.806621551513672,
      "rewards/rejected": -10.876317977905273,
      "step": 7128
    },
    {
      "epoch": 2.8516,
      "grad_norm": 0.010288833640515804,
      "learning_rate": 4.9599999999999994e-08,
      "logits/chosen": -2.5764527320861816,
      "logits/rejected": -1.8598685264587402,
      "logps/chosen": -127.01785278320312,
      "logps/rejected": -161.99879455566406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3863086700439453,
      "rewards/margins": 10.618545532226562,
      "rewards/rejected": -11.004854202270508,
      "step": 7129
    },
    {
      "epoch": 2.852,
      "grad_norm": 0.10429800301790237,
      "learning_rate": 4.9466666666666666e-08,
      "logits/chosen": -2.0087714195251465,
      "logits/rejected": -1.4956481456756592,
      "logps/chosen": -113.66049194335938,
      "logps/rejected": -161.85003662109375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13840562105178833,
      "rewards/margins": 9.751896858215332,
      "rewards/rejected": -9.61349105834961,
      "step": 7130
    },
    {
      "epoch": 2.8524000000000003,
      "grad_norm": 0.00976105872541666,
      "learning_rate": 4.933333333333333e-08,
      "logits/chosen": -2.6103265285491943,
      "logits/rejected": -2.5371768474578857,
      "logps/chosen": -153.97119140625,
      "logps/rejected": -172.19912719726562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.39272308349609375,
      "rewards/margins": 10.965578079223633,
      "rewards/rejected": -11.358301162719727,
      "step": 7131
    },
    {
      "epoch": 2.8528000000000002,
      "grad_norm": 0.03417007625102997,
      "learning_rate": 4.92e-08,
      "logits/chosen": -2.749868392944336,
      "logits/rejected": -2.504729986190796,
      "logps/chosen": -69.46006774902344,
      "logps/rejected": -122.73638153076172,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2379074096679688,
      "rewards/margins": 9.687641143798828,
      "rewards/rejected": -8.449734687805176,
      "step": 7132
    },
    {
      "epoch": 2.8532,
      "grad_norm": 0.10176270455121994,
      "learning_rate": 4.906666666666666e-08,
      "logits/chosen": -2.5863876342773438,
      "logits/rejected": -2.3550848960876465,
      "logps/chosen": -37.81423568725586,
      "logps/rejected": -229.00906372070312,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7540757656097412,
      "rewards/margins": 10.847729682922363,
      "rewards/rejected": -10.09365463256836,
      "step": 7133
    },
    {
      "epoch": 2.8536,
      "grad_norm": 0.8935783505439758,
      "learning_rate": 4.8933333333333335e-08,
      "logits/chosen": -2.8362526893615723,
      "logits/rejected": -2.5388705730438232,
      "logps/chosen": -99.17095947265625,
      "logps/rejected": -123.23927307128906,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1619957685470581,
      "rewards/margins": 7.438771724700928,
      "rewards/rejected": -7.276776313781738,
      "step": 7134
    },
    {
      "epoch": 2.854,
      "grad_norm": 0.144008606672287,
      "learning_rate": 4.88e-08,
      "logits/chosen": -2.9695472717285156,
      "logits/rejected": -2.5053746700286865,
      "logps/chosen": -87.3173828125,
      "logps/rejected": -151.45606994628906,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2316040992736816,
      "rewards/margins": 8.544282913208008,
      "rewards/rejected": -9.775887489318848,
      "step": 7135
    },
    {
      "epoch": 2.8544,
      "grad_norm": 0.26902198791503906,
      "learning_rate": 4.866666666666666e-08,
      "logits/chosen": -2.5817222595214844,
      "logits/rejected": -2.4632458686828613,
      "logps/chosen": -115.32660675048828,
      "logps/rejected": -122.71963500976562,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.274289608001709,
      "rewards/margins": 7.262161731719971,
      "rewards/rejected": -7.53645133972168,
      "step": 7136
    },
    {
      "epoch": 2.8548,
      "grad_norm": 0.06503075361251831,
      "learning_rate": 4.853333333333333e-08,
      "logits/chosen": -2.349046230316162,
      "logits/rejected": -2.156428575515747,
      "logps/chosen": -118.38595581054688,
      "logps/rejected": -158.8661651611328,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2576320171356201,
      "rewards/margins": 8.52640151977539,
      "rewards/rejected": -8.784032821655273,
      "step": 7137
    },
    {
      "epoch": 2.8552,
      "grad_norm": 0.030720029026269913,
      "learning_rate": 4.8399999999999997e-08,
      "logits/chosen": -2.662956714630127,
      "logits/rejected": -2.0305569171905518,
      "logps/chosen": -110.2325439453125,
      "logps/rejected": -213.92539978027344,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8980640769004822,
      "rewards/margins": 14.349519729614258,
      "rewards/rejected": -15.247583389282227,
      "step": 7138
    },
    {
      "epoch": 2.8556,
      "grad_norm": 2.8188111782073975,
      "learning_rate": 4.826666666666666e-08,
      "logits/chosen": -2.8169660568237305,
      "logits/rejected": -2.4402284622192383,
      "logps/chosen": -70.08914184570312,
      "logps/rejected": -87.90694427490234,
      "loss": 0.014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9983100891113281,
      "rewards/margins": 5.350899696350098,
      "rewards/rejected": -4.3525896072387695,
      "step": 7139
    },
    {
      "epoch": 2.856,
      "grad_norm": 0.12884151935577393,
      "learning_rate": 4.8133333333333334e-08,
      "logits/chosen": -2.4558324813842773,
      "logits/rejected": -2.055790662765503,
      "logps/chosen": -163.09678649902344,
      "logps/rejected": -178.00228881835938,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.473961353302002,
      "rewards/margins": 7.974461555480957,
      "rewards/rejected": -12.448423385620117,
      "step": 7140
    },
    {
      "epoch": 2.8564,
      "grad_norm": 0.010384729132056236,
      "learning_rate": 4.8e-08,
      "logits/chosen": -2.469379425048828,
      "logits/rejected": -1.8787882328033447,
      "logps/chosen": -164.31192016601562,
      "logps/rejected": -185.5082244873047,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.239871621131897,
      "rewards/margins": 11.231573104858398,
      "rewards/rejected": -12.471444129943848,
      "step": 7141
    },
    {
      "epoch": 2.8568,
      "grad_norm": 0.0009928509825840592,
      "learning_rate": 4.7866666666666665e-08,
      "logits/chosen": -2.115020751953125,
      "logits/rejected": -1.3776941299438477,
      "logps/chosen": -160.1599578857422,
      "logps/rejected": -268.03948974609375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8835921883583069,
      "rewards/margins": 12.950756072998047,
      "rewards/rejected": -13.834348678588867,
      "step": 7142
    },
    {
      "epoch": 2.8571999999999997,
      "grad_norm": 0.005724931135773659,
      "learning_rate": 4.773333333333333e-08,
      "logits/chosen": -2.692242383956909,
      "logits/rejected": -2.3639862537384033,
      "logps/chosen": -71.22908782958984,
      "logps/rejected": -174.5399169921875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6550533771514893,
      "rewards/margins": 11.820170402526855,
      "rewards/rejected": -11.165117263793945,
      "step": 7143
    },
    {
      "epoch": 2.8576,
      "grad_norm": 0.29049190878868103,
      "learning_rate": 4.76e-08,
      "logits/chosen": -2.850404977798462,
      "logits/rejected": -2.682865619659424,
      "logps/chosen": -79.88636016845703,
      "logps/rejected": -177.26458740234375,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8236175775527954,
      "rewards/margins": 14.884366989135742,
      "rewards/rejected": -13.060749053955078,
      "step": 7144
    },
    {
      "epoch": 2.858,
      "grad_norm": 0.010091062635183334,
      "learning_rate": 4.746666666666666e-08,
      "logits/chosen": -2.5282583236694336,
      "logits/rejected": -2.035694122314453,
      "logps/chosen": -95.57171630859375,
      "logps/rejected": -264.6811218261719,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25064224004745483,
      "rewards/margins": 16.78029441833496,
      "rewards/rejected": -16.529651641845703,
      "step": 7145
    },
    {
      "epoch": 2.8584,
      "grad_norm": 0.002546103438362479,
      "learning_rate": 4.733333333333333e-08,
      "logits/chosen": -2.5749459266662598,
      "logits/rejected": -1.8046505451202393,
      "logps/chosen": -178.1016082763672,
      "logps/rejected": -194.77784729003906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2914347648620605,
      "rewards/margins": 12.504768371582031,
      "rewards/rejected": -13.796202659606934,
      "step": 7146
    },
    {
      "epoch": 2.8588,
      "grad_norm": 0.4592413306236267,
      "learning_rate": 4.72e-08,
      "logits/chosen": -2.485213279724121,
      "logits/rejected": -2.1634416580200195,
      "logps/chosen": -88.04434204101562,
      "logps/rejected": -211.4491729736328,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7465919852256775,
      "rewards/margins": 12.465291023254395,
      "rewards/rejected": -11.71869945526123,
      "step": 7147
    },
    {
      "epoch": 2.8592,
      "grad_norm": 1.6402373313903809,
      "learning_rate": 4.7066666666666665e-08,
      "logits/chosen": -2.4337892532348633,
      "logits/rejected": -2.2211270332336426,
      "logps/chosen": -147.89404296875,
      "logps/rejected": -265.5558776855469,
      "loss": 0.0067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.762949824333191,
      "rewards/margins": 11.899332046508789,
      "rewards/rejected": -13.662281036376953,
      "step": 7148
    },
    {
      "epoch": 2.8596,
      "grad_norm": 0.042395833879709244,
      "learning_rate": 4.693333333333333e-08,
      "logits/chosen": -2.5505638122558594,
      "logits/rejected": -2.0066888332366943,
      "logps/chosen": -129.1051483154297,
      "logps/rejected": -204.9660186767578,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09004676342010498,
      "rewards/margins": 9.259411811828613,
      "rewards/rejected": -9.169364929199219,
      "step": 7149
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.3038616478443146,
      "learning_rate": 4.68e-08,
      "logits/chosen": -2.8433141708374023,
      "logits/rejected": -2.7116024494171143,
      "logps/chosen": -39.23121643066406,
      "logps/rejected": -119.8410415649414,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0816078186035156,
      "rewards/margins": 8.374921798706055,
      "rewards/rejected": -7.293314456939697,
      "step": 7150
    },
    {
      "epoch": 2.8604000000000003,
      "grad_norm": 0.011796103790402412,
      "learning_rate": 4.666666666666667e-08,
      "logits/chosen": -2.1183221340179443,
      "logits/rejected": -1.7412843704223633,
      "logps/chosen": -192.44503784179688,
      "logps/rejected": -193.05101013183594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2017639875411987,
      "rewards/margins": 10.923752784729004,
      "rewards/rejected": -12.125516891479492,
      "step": 7151
    },
    {
      "epoch": 2.8608000000000002,
      "grad_norm": 0.0011785050155594945,
      "learning_rate": 4.653333333333333e-08,
      "logits/chosen": -2.5009982585906982,
      "logits/rejected": -2.153092861175537,
      "logps/chosen": -88.88001251220703,
      "logps/rejected": -203.635498046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2611848711967468,
      "rewards/margins": 13.043353080749512,
      "rewards/rejected": -13.30453872680664,
      "step": 7152
    },
    {
      "epoch": 2.8612,
      "grad_norm": 0.002291077747941017,
      "learning_rate": 4.639999999999999e-08,
      "logits/chosen": -2.598421812057495,
      "logits/rejected": -1.7016276121139526,
      "logps/chosen": -89.76802825927734,
      "logps/rejected": -204.07260131835938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4621950089931488,
      "rewards/margins": 13.391124725341797,
      "rewards/rejected": -12.928929328918457,
      "step": 7153
    },
    {
      "epoch": 2.8616,
      "grad_norm": 0.056125033646821976,
      "learning_rate": 4.6266666666666664e-08,
      "logits/chosen": -2.6776645183563232,
      "logits/rejected": -2.2768542766571045,
      "logps/chosen": -91.84906005859375,
      "logps/rejected": -130.96620178222656,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4464119076728821,
      "rewards/margins": 8.564111709594727,
      "rewards/rejected": -9.010523796081543,
      "step": 7154
    },
    {
      "epoch": 2.862,
      "grad_norm": 3.7769248485565186,
      "learning_rate": 4.613333333333333e-08,
      "logits/chosen": -2.863219976425171,
      "logits/rejected": -2.4511704444885254,
      "logps/chosen": -82.80915832519531,
      "logps/rejected": -139.95947265625,
      "loss": 0.0216,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1620769500732422,
      "rewards/margins": 7.212115287780762,
      "rewards/rejected": -7.374192237854004,
      "step": 7155
    },
    {
      "epoch": 2.8624,
      "grad_norm": 0.17882339656352997,
      "learning_rate": 4.5999999999999995e-08,
      "logits/chosen": -2.9015448093414307,
      "logits/rejected": -2.427248001098633,
      "logps/chosen": -93.17623901367188,
      "logps/rejected": -141.1773681640625,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04915313795208931,
      "rewards/margins": 9.76826000213623,
      "rewards/rejected": -9.719106674194336,
      "step": 7156
    },
    {
      "epoch": 2.8628,
      "grad_norm": 0.0687263235449791,
      "learning_rate": 4.586666666666667e-08,
      "logits/chosen": -2.5110673904418945,
      "logits/rejected": -1.9656627178192139,
      "logps/chosen": -181.4994659423828,
      "logps/rejected": -146.99990844726562,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.383066177368164,
      "rewards/margins": 8.124235153198242,
      "rewards/rejected": -10.507301330566406,
      "step": 7157
    },
    {
      "epoch": 2.8632,
      "grad_norm": 6.910174852237105e-05,
      "learning_rate": 4.573333333333333e-08,
      "logits/chosen": -2.2689101696014404,
      "logits/rejected": -1.5544893741607666,
      "logps/chosen": -108.37189483642578,
      "logps/rejected": -234.59677124023438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6208031177520752,
      "rewards/margins": 16.070030212402344,
      "rewards/rejected": -14.449227333068848,
      "step": 7158
    },
    {
      "epoch": 2.8636,
      "grad_norm": 0.02646446041762829,
      "learning_rate": 4.56e-08,
      "logits/chosen": -2.492213726043701,
      "logits/rejected": -1.9362478256225586,
      "logps/chosen": -55.54493713378906,
      "logps/rejected": -137.79469299316406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4013292193412781,
      "rewards/margins": 9.244751930236816,
      "rewards/rejected": -8.843422889709473,
      "step": 7159
    },
    {
      "epoch": 2.864,
      "grad_norm": 0.00872094463557005,
      "learning_rate": 4.546666666666667e-08,
      "logits/chosen": -2.1317198276519775,
      "logits/rejected": -1.5694259405136108,
      "logps/chosen": -91.88015747070312,
      "logps/rejected": -147.24334716796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.281958818435669,
      "rewards/margins": 10.440818786621094,
      "rewards/rejected": -9.158859252929688,
      "step": 7160
    },
    {
      "epoch": 2.8644,
      "grad_norm": 0.001843767473474145,
      "learning_rate": 4.5333333333333336e-08,
      "logits/chosen": -2.3955330848693848,
      "logits/rejected": -1.8814756870269775,
      "logps/chosen": -79.72427368164062,
      "logps/rejected": -212.7383270263672,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.810412049293518,
      "rewards/margins": 14.35087776184082,
      "rewards/rejected": -12.540465354919434,
      "step": 7161
    },
    {
      "epoch": 2.8648,
      "grad_norm": 0.0024008476175367832,
      "learning_rate": 4.5199999999999994e-08,
      "logits/chosen": -2.4002277851104736,
      "logits/rejected": -2.0684964656829834,
      "logps/chosen": -106.65302276611328,
      "logps/rejected": -214.3096923828125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4019066095352173,
      "rewards/margins": 15.795467376708984,
      "rewards/rejected": -14.393560409545898,
      "step": 7162
    },
    {
      "epoch": 2.8651999999999997,
      "grad_norm": 0.09248387813568115,
      "learning_rate": 4.506666666666666e-08,
      "logits/chosen": -2.5875539779663086,
      "logits/rejected": -2.276209831237793,
      "logps/chosen": -127.6746826171875,
      "logps/rejected": -155.553466796875,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34535372257232666,
      "rewards/margins": 10.255362510681152,
      "rewards/rejected": -9.910008430480957,
      "step": 7163
    },
    {
      "epoch": 2.8656,
      "grad_norm": 54.35901641845703,
      "learning_rate": 4.493333333333333e-08,
      "logits/chosen": -2.5496156215667725,
      "logits/rejected": -2.587273359298706,
      "logps/chosen": -264.9797058105469,
      "logps/rejected": -152.04367065429688,
      "loss": 0.1852,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -5.433738708496094,
      "rewards/margins": 3.988579511642456,
      "rewards/rejected": -9.422318458557129,
      "step": 7164
    },
    {
      "epoch": 2.866,
      "grad_norm": 0.012279415503144264,
      "learning_rate": 4.48e-08,
      "logits/chosen": -2.7424426078796387,
      "logits/rejected": -2.356747627258301,
      "logps/chosen": -80.44763946533203,
      "logps/rejected": -267.73687744140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10852891206741333,
      "rewards/margins": 13.088716506958008,
      "rewards/rejected": -12.980188369750977,
      "step": 7165
    },
    {
      "epoch": 2.8664,
      "grad_norm": 74.52822875976562,
      "learning_rate": 4.466666666666666e-08,
      "logits/chosen": -2.8149540424346924,
      "logits/rejected": -2.3092715740203857,
      "logps/chosen": -81.25602722167969,
      "logps/rejected": -159.78407287597656,
      "loss": 0.4323,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -1.4429802894592285,
      "rewards/margins": 9.477948188781738,
      "rewards/rejected": -10.920928955078125,
      "step": 7166
    },
    {
      "epoch": 2.8668,
      "grad_norm": 0.015100479125976562,
      "learning_rate": 4.4533333333333335e-08,
      "logits/chosen": -2.7974612712860107,
      "logits/rejected": -2.4537153244018555,
      "logps/chosen": -73.44403839111328,
      "logps/rejected": -159.7881622314453,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5871681571006775,
      "rewards/margins": 11.469841003417969,
      "rewards/rejected": -10.882673263549805,
      "step": 7167
    },
    {
      "epoch": 2.8672,
      "grad_norm": 0.0037559131160378456,
      "learning_rate": 4.44e-08,
      "logits/chosen": -2.247790575027466,
      "logits/rejected": -1.30889892578125,
      "logps/chosen": -113.13967895507812,
      "logps/rejected": -203.9188690185547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.29155808687210083,
      "rewards/margins": 13.764440536499023,
      "rewards/rejected": -13.472883224487305,
      "step": 7168
    },
    {
      "epoch": 2.8676,
      "grad_norm": 0.02843909151852131,
      "learning_rate": 4.4266666666666666e-08,
      "logits/chosen": -2.503818988800049,
      "logits/rejected": -1.9675986766815186,
      "logps/chosen": -112.87806701660156,
      "logps/rejected": -172.75814819335938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8851358890533447,
      "rewards/margins": 10.301246643066406,
      "rewards/rejected": -11.186383247375488,
      "step": 7169
    },
    {
      "epoch": 2.868,
      "grad_norm": 0.05863010138273239,
      "learning_rate": 4.4133333333333325e-08,
      "logits/chosen": -2.2451846599578857,
      "logits/rejected": -1.7534993886947632,
      "logps/chosen": -140.70632934570312,
      "logps/rejected": -181.1765594482422,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34946441650390625,
      "rewards/margins": 10.576993942260742,
      "rewards/rejected": -10.227530479431152,
      "step": 7170
    },
    {
      "epoch": 2.8684,
      "grad_norm": 0.0007256643148139119,
      "learning_rate": 4.4e-08,
      "logits/chosen": -2.610261917114258,
      "logits/rejected": -2.180556058883667,
      "logps/chosen": -51.88859558105469,
      "logps/rejected": -218.09332275390625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4208277761936188,
      "rewards/margins": 13.821619033813477,
      "rewards/rejected": -13.40079116821289,
      "step": 7171
    },
    {
      "epoch": 2.8688000000000002,
      "grad_norm": 0.0075502353720366955,
      "learning_rate": 4.386666666666666e-08,
      "logits/chosen": -2.4837021827697754,
      "logits/rejected": -2.011094331741333,
      "logps/chosen": -91.12289428710938,
      "logps/rejected": -179.2028045654297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8462555408477783,
      "rewards/margins": 13.066770553588867,
      "rewards/rejected": -11.220514297485352,
      "step": 7172
    },
    {
      "epoch": 2.8692,
      "grad_norm": 0.004222758114337921,
      "learning_rate": 4.373333333333333e-08,
      "logits/chosen": -2.846059560775757,
      "logits/rejected": -2.2042317390441895,
      "logps/chosen": -48.30939483642578,
      "logps/rejected": -179.2046661376953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7922266125679016,
      "rewards/margins": 12.431476593017578,
      "rewards/rejected": -11.639250755310059,
      "step": 7173
    },
    {
      "epoch": 2.8696,
      "grad_norm": 0.00264767836779356,
      "learning_rate": 4.36e-08,
      "logits/chosen": -2.9918887615203857,
      "logits/rejected": -2.4061031341552734,
      "logps/chosen": -45.53744125366211,
      "logps/rejected": -234.75750732421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20109902322292328,
      "rewards/margins": 14.404729843139648,
      "rewards/rejected": -14.203630447387695,
      "step": 7174
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.0691104382276535,
      "learning_rate": 4.3466666666666665e-08,
      "logits/chosen": -2.5097756385803223,
      "logits/rejected": -2.1168596744537354,
      "logps/chosen": -75.77957153320312,
      "logps/rejected": -148.5311279296875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7798932790756226,
      "rewards/margins": 10.585161209106445,
      "rewards/rejected": -9.805268287658691,
      "step": 7175
    },
    {
      "epoch": 2.8704,
      "grad_norm": 0.018707484006881714,
      "learning_rate": 4.333333333333333e-08,
      "logits/chosen": -2.5261425971984863,
      "logits/rejected": -2.278738498687744,
      "logps/chosen": -127.78065490722656,
      "logps/rejected": -155.413330078125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18518716096878052,
      "rewards/margins": 9.298089981079102,
      "rewards/rejected": -9.112902641296387,
      "step": 7176
    },
    {
      "epoch": 2.8708,
      "grad_norm": 0.005593723617494106,
      "learning_rate": 4.32e-08,
      "logits/chosen": -2.5731887817382812,
      "logits/rejected": -1.968770980834961,
      "logps/chosen": -123.65316772460938,
      "logps/rejected": -188.7617950439453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38609960675239563,
      "rewards/margins": 11.347311019897461,
      "rewards/rejected": -10.961212158203125,
      "step": 7177
    },
    {
      "epoch": 2.8712,
      "grad_norm": 0.006298402324318886,
      "learning_rate": 4.306666666666667e-08,
      "logits/chosen": -2.25844407081604,
      "logits/rejected": -1.9663922786712646,
      "logps/chosen": -135.93353271484375,
      "logps/rejected": -216.0291290283203,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.48550570011138916,
      "rewards/margins": 10.683711051940918,
      "rewards/rejected": -11.169217109680176,
      "step": 7178
    },
    {
      "epoch": 2.8716,
      "grad_norm": 0.036908671259880066,
      "learning_rate": 4.293333333333333e-08,
      "logits/chosen": -2.379117250442505,
      "logits/rejected": -1.857133388519287,
      "logps/chosen": -123.70355224609375,
      "logps/rejected": -180.39480590820312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6098930239677429,
      "rewards/margins": 10.709651947021484,
      "rewards/rejected": -10.09975814819336,
      "step": 7179
    },
    {
      "epoch": 2.872,
      "grad_norm": 0.1538582742214203,
      "learning_rate": 4.279999999999999e-08,
      "logits/chosen": -2.352590560913086,
      "logits/rejected": -1.918885588645935,
      "logps/chosen": -157.69406127929688,
      "logps/rejected": -126.06403350830078,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0566506385803223,
      "rewards/margins": 7.165865898132324,
      "rewards/rejected": -8.222516059875488,
      "step": 7180
    },
    {
      "epoch": 2.8724,
      "grad_norm": 0.15042230486869812,
      "learning_rate": 4.2666666666666665e-08,
      "logits/chosen": -2.7970895767211914,
      "logits/rejected": -2.46392822265625,
      "logps/chosen": -57.75725555419922,
      "logps/rejected": -196.38726806640625,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0590180158615112,
      "rewards/margins": 12.653203964233398,
      "rewards/rejected": -11.594186782836914,
      "step": 7181
    },
    {
      "epoch": 2.8728,
      "grad_norm": 0.00016950993449427187,
      "learning_rate": 4.253333333333333e-08,
      "logits/chosen": -2.728142738342285,
      "logits/rejected": -2.197936534881592,
      "logps/chosen": -77.27142333984375,
      "logps/rejected": -197.74087524414062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1701726913452148,
      "rewards/margins": 15.057024955749512,
      "rewards/rejected": -13.886852264404297,
      "step": 7182
    },
    {
      "epoch": 2.8731999999999998,
      "grad_norm": 0.0031113221775740385,
      "learning_rate": 4.2399999999999996e-08,
      "logits/chosen": -2.3076069355010986,
      "logits/rejected": -1.731933832168579,
      "logps/chosen": -134.5171356201172,
      "logps/rejected": -205.68170166015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.056909203529358,
      "rewards/margins": 11.539033889770508,
      "rewards/rejected": -12.595943450927734,
      "step": 7183
    },
    {
      "epoch": 2.8736,
      "grad_norm": 0.00044734685798175633,
      "learning_rate": 4.226666666666667e-08,
      "logits/chosen": -2.7192442417144775,
      "logits/rejected": -2.183867931365967,
      "logps/chosen": -62.396156311035156,
      "logps/rejected": -213.69720458984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.172914981842041,
      "rewards/margins": 13.476425170898438,
      "rewards/rejected": -14.64933967590332,
      "step": 7184
    },
    {
      "epoch": 2.874,
      "grad_norm": 0.05564218759536743,
      "learning_rate": 4.2133333333333333e-08,
      "logits/chosen": -2.5474956035614014,
      "logits/rejected": -1.869513988494873,
      "logps/chosen": -133.68081665039062,
      "logps/rejected": -169.00833129882812,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3328312635421753,
      "rewards/margins": 8.354774475097656,
      "rewards/rejected": -9.687605857849121,
      "step": 7185
    },
    {
      "epoch": 2.8744,
      "grad_norm": 0.005863274447619915,
      "learning_rate": 4.2e-08,
      "logits/chosen": -2.348970413208008,
      "logits/rejected": -1.333305835723877,
      "logps/chosen": -150.77999877929688,
      "logps/rejected": -158.91619873046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019541561603546143,
      "rewards/margins": 10.894281387329102,
      "rewards/rejected": -10.874740600585938,
      "step": 7186
    },
    {
      "epoch": 2.8748,
      "grad_norm": 10.811078071594238,
      "learning_rate": 4.186666666666667e-08,
      "logits/chosen": -2.5008883476257324,
      "logits/rejected": -1.8426661491394043,
      "logps/chosen": -97.13044738769531,
      "logps/rejected": -131.1361083984375,
      "loss": 0.0617,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5629249811172485,
      "rewards/margins": 7.720963954925537,
      "rewards/rejected": -9.283888816833496,
      "step": 7187
    },
    {
      "epoch": 2.8752,
      "grad_norm": 0.019855594262480736,
      "learning_rate": 4.173333333333333e-08,
      "logits/chosen": -2.9143519401550293,
      "logits/rejected": -2.4210047721862793,
      "logps/chosen": -55.75878143310547,
      "logps/rejected": -168.41436767578125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.07195910811424255,
      "rewards/margins": 10.09250545501709,
      "rewards/rejected": -10.164464950561523,
      "step": 7188
    },
    {
      "epoch": 2.8756,
      "grad_norm": 0.02845473773777485,
      "learning_rate": 4.1599999999999995e-08,
      "logits/chosen": -2.694978713989258,
      "logits/rejected": -2.2645201683044434,
      "logps/chosen": -70.71083068847656,
      "logps/rejected": -145.70188903808594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.553083062171936,
      "rewards/margins": 9.112602233886719,
      "rewards/rejected": -9.665685653686523,
      "step": 7189
    },
    {
      "epoch": 2.876,
      "grad_norm": 0.0004142704710830003,
      "learning_rate": 4.146666666666666e-08,
      "logits/chosen": -2.6838271617889404,
      "logits/rejected": -2.2115015983581543,
      "logps/chosen": -45.916709899902344,
      "logps/rejected": -189.53549194335938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9342676401138306,
      "rewards/margins": 13.545332908630371,
      "rewards/rejected": -12.611064910888672,
      "step": 7190
    },
    {
      "epoch": 2.8764,
      "grad_norm": 0.0002462879929225892,
      "learning_rate": 4.133333333333333e-08,
      "logits/chosen": -2.072415351867676,
      "logits/rejected": -1.3398900032043457,
      "logps/chosen": -79.67245483398438,
      "logps/rejected": -212.55532836914062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0126556158065796,
      "rewards/margins": 14.48443603515625,
      "rewards/rejected": -13.471780776977539,
      "step": 7191
    },
    {
      "epoch": 2.8768000000000002,
      "grad_norm": 0.001277623581700027,
      "learning_rate": 4.12e-08,
      "logits/chosen": -2.7340216636657715,
      "logits/rejected": -2.427098274230957,
      "logps/chosen": -80.40641021728516,
      "logps/rejected": -198.76795959472656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7625370025634766,
      "rewards/margins": 14.485063552856445,
      "rewards/rejected": -13.722526550292969,
      "step": 7192
    },
    {
      "epoch": 2.8772,
      "grad_norm": 0.32634440064430237,
      "learning_rate": 4.1066666666666664e-08,
      "logits/chosen": -2.7277445793151855,
      "logits/rejected": -1.8866674900054932,
      "logps/chosen": -95.37115478515625,
      "logps/rejected": -133.3173828125,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.942318320274353,
      "rewards/margins": 8.633679389953613,
      "rewards/rejected": -7.691360950469971,
      "step": 7193
    },
    {
      "epoch": 2.8776,
      "grad_norm": 0.0009152664570137858,
      "learning_rate": 4.0933333333333336e-08,
      "logits/chosen": -2.234018325805664,
      "logits/rejected": -1.5224684476852417,
      "logps/chosen": -169.68130493164062,
      "logps/rejected": -200.16757202148438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10286331176757812,
      "rewards/margins": 13.226807594299316,
      "rewards/rejected": -13.123944282531738,
      "step": 7194
    },
    {
      "epoch": 2.878,
      "grad_norm": 0.023015040904283524,
      "learning_rate": 4.08e-08,
      "logits/chosen": -2.8758904933929443,
      "logits/rejected": -2.5998964309692383,
      "logps/chosen": -57.534202575683594,
      "logps/rejected": -120.4127197265625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9532791376113892,
      "rewards/margins": 9.585965156555176,
      "rewards/rejected": -7.632685661315918,
      "step": 7195
    },
    {
      "epoch": 2.8784,
      "grad_norm": 0.112938791513443,
      "learning_rate": 4.066666666666666e-08,
      "logits/chosen": -2.9036810398101807,
      "logits/rejected": -2.5091323852539062,
      "logps/chosen": -59.797119140625,
      "logps/rejected": -121.26292419433594,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.802642822265625,
      "rewards/margins": 8.864721298217773,
      "rewards/rejected": -8.062078475952148,
      "step": 7196
    },
    {
      "epoch": 2.8788,
      "grad_norm": 0.01566517911851406,
      "learning_rate": 4.053333333333333e-08,
      "logits/chosen": -2.2988967895507812,
      "logits/rejected": -1.695777416229248,
      "logps/chosen": -138.7721405029297,
      "logps/rejected": -192.83416748046875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.587773859500885,
      "rewards/margins": 12.678458213806152,
      "rewards/rejected": -12.090683937072754,
      "step": 7197
    },
    {
      "epoch": 2.8792,
      "grad_norm": 0.05288528650999069,
      "learning_rate": 4.04e-08,
      "logits/chosen": -2.471998691558838,
      "logits/rejected": -1.886749267578125,
      "logps/chosen": -137.2465362548828,
      "logps/rejected": -153.2412567138672,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3292720317840576,
      "rewards/margins": 9.483848571777344,
      "rewards/rejected": -9.15457534790039,
      "step": 7198
    },
    {
      "epoch": 2.8796,
      "grad_norm": 0.0027349567972123623,
      "learning_rate": 4.026666666666666e-08,
      "logits/chosen": -2.4761435985565186,
      "logits/rejected": -1.9317820072174072,
      "logps/chosen": -85.98553466796875,
      "logps/rejected": -178.01202392578125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.48980486392974854,
      "rewards/margins": 13.642864227294922,
      "rewards/rejected": -13.153059005737305,
      "step": 7199
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.3248003423213959,
      "learning_rate": 4.013333333333333e-08,
      "logits/chosen": -2.496401786804199,
      "logits/rejected": -2.147336006164551,
      "logps/chosen": -56.651466369628906,
      "logps/rejected": -189.15264892578125,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.316351294517517,
      "rewards/margins": 9.444324493408203,
      "rewards/rejected": -8.127973556518555,
      "step": 7200
    },
    {
      "epoch": 2.8804,
      "grad_norm": 0.013270135037600994,
      "learning_rate": 4e-08,
      "logits/chosen": -2.9791383743286133,
      "logits/rejected": -2.511432647705078,
      "logps/chosen": -64.79076385498047,
      "logps/rejected": -159.0059814453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35793837904930115,
      "rewards/margins": 10.615220069885254,
      "rewards/rejected": -10.257282257080078,
      "step": 7201
    },
    {
      "epoch": 2.8808,
      "grad_norm": 0.00357655412517488,
      "learning_rate": 3.9866666666666666e-08,
      "logits/chosen": -2.9738268852233887,
      "logits/rejected": -2.6473464965820312,
      "logps/chosen": -51.21775817871094,
      "logps/rejected": -170.9176788330078,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.577742099761963,
      "rewards/margins": 13.06340217590332,
      "rewards/rejected": -11.485660552978516,
      "step": 7202
    },
    {
      "epoch": 2.8811999999999998,
      "grad_norm": 3.885449405061081e-05,
      "learning_rate": 3.973333333333333e-08,
      "logits/chosen": -2.4833712577819824,
      "logits/rejected": -1.8902215957641602,
      "logps/chosen": -92.08642578125,
      "logps/rejected": -282.252685546875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5148143768310547,
      "rewards/margins": 16.761714935302734,
      "rewards/rejected": -16.24690055847168,
      "step": 7203
    },
    {
      "epoch": 2.8816,
      "grad_norm": 0.0013237935490906239,
      "learning_rate": 3.9600000000000004e-08,
      "logits/chosen": -2.115537643432617,
      "logits/rejected": -1.6258636713027954,
      "logps/chosen": -119.905517578125,
      "logps/rejected": -240.4032440185547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7485790252685547,
      "rewards/margins": 12.887322425842285,
      "rewards/rejected": -13.63590145111084,
      "step": 7204
    },
    {
      "epoch": 2.882,
      "grad_norm": 1.567914605140686,
      "learning_rate": 3.946666666666666e-08,
      "logits/chosen": -2.584627628326416,
      "logits/rejected": -2.443984270095825,
      "logps/chosen": -124.65577697753906,
      "logps/rejected": -120.34127807617188,
      "loss": 0.0082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.479525089263916,
      "rewards/margins": 5.829806327819824,
      "rewards/rejected": -7.30933141708374,
      "step": 7205
    },
    {
      "epoch": 2.8824,
      "grad_norm": 0.07389689236879349,
      "learning_rate": 3.933333333333333e-08,
      "logits/chosen": -2.6457200050354004,
      "logits/rejected": -2.198185443878174,
      "logps/chosen": -107.25794219970703,
      "logps/rejected": -123.01646423339844,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8091911673545837,
      "rewards/margins": 7.878636837005615,
      "rewards/rejected": -8.687828063964844,
      "step": 7206
    },
    {
      "epoch": 2.8828,
      "grad_norm": 0.00015629410336259753,
      "learning_rate": 3.9199999999999994e-08,
      "logits/chosen": -2.8009033203125,
      "logits/rejected": -2.307889938354492,
      "logps/chosen": -54.07902526855469,
      "logps/rejected": -204.18594360351562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4385168552398682,
      "rewards/margins": 14.921252250671387,
      "rewards/rejected": -13.482735633850098,
      "step": 7207
    },
    {
      "epoch": 2.8832,
      "grad_norm": 0.14800016582012177,
      "learning_rate": 3.9066666666666666e-08,
      "logits/chosen": -2.5164427757263184,
      "logits/rejected": -2.0877132415771484,
      "logps/chosen": -154.76318359375,
      "logps/rejected": -195.1522216796875,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.567879676818848,
      "rewards/margins": 9.268855094909668,
      "rewards/rejected": -13.836734771728516,
      "step": 7208
    },
    {
      "epoch": 2.8836,
      "grad_norm": 0.010361428372561932,
      "learning_rate": 3.893333333333333e-08,
      "logits/chosen": -3.0097484588623047,
      "logits/rejected": -2.34175443649292,
      "logps/chosen": -30.173320770263672,
      "logps/rejected": -134.1627197265625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.60979163646698,
      "rewards/margins": 10.445457458496094,
      "rewards/rejected": -8.83566665649414,
      "step": 7209
    },
    {
      "epoch": 2.884,
      "grad_norm": 2.7985621272819117e-05,
      "learning_rate": 3.88e-08,
      "logits/chosen": -2.5774788856506348,
      "logits/rejected": -1.7989261150360107,
      "logps/chosen": -62.890594482421875,
      "logps/rejected": -288.45257568359375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5031797885894775,
      "rewards/margins": 16.707061767578125,
      "rewards/rejected": -15.203883171081543,
      "step": 7210
    },
    {
      "epoch": 2.8844,
      "grad_norm": 0.016159381717443466,
      "learning_rate": 3.866666666666667e-08,
      "logits/chosen": -2.8618454933166504,
      "logits/rejected": -2.237196445465088,
      "logps/chosen": -71.4954833984375,
      "logps/rejected": -199.76046752929688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.004631996154785156,
      "rewards/margins": 13.611823081970215,
      "rewards/rejected": -13.60719108581543,
      "step": 7211
    },
    {
      "epoch": 2.8848000000000003,
      "grad_norm": 0.09728027135133743,
      "learning_rate": 3.8533333333333334e-08,
      "logits/chosen": -2.470006227493286,
      "logits/rejected": -1.9300826787948608,
      "logps/chosen": -83.05034637451172,
      "logps/rejected": -146.08303833007812,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22222888469696045,
      "rewards/margins": 8.873502731323242,
      "rewards/rejected": -8.651273727416992,
      "step": 7212
    },
    {
      "epoch": 2.8852,
      "grad_norm": 1.434802770614624,
      "learning_rate": 3.839999999999999e-08,
      "logits/chosen": -2.344865322113037,
      "logits/rejected": -2.016357421875,
      "logps/chosen": -132.32200622558594,
      "logps/rejected": -144.41146850585938,
      "loss": 0.0073,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.43915748596191406,
      "rewards/margins": 9.054243087768555,
      "rewards/rejected": -9.493400573730469,
      "step": 7213
    },
    {
      "epoch": 2.8856,
      "grad_norm": 0.12469062954187393,
      "learning_rate": 3.8266666666666665e-08,
      "logits/chosen": -2.898299217224121,
      "logits/rejected": -2.6058101654052734,
      "logps/chosen": -81.40093994140625,
      "logps/rejected": -124.21761322021484,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8775180578231812,
      "rewards/margins": 8.028305053710938,
      "rewards/rejected": -7.150786876678467,
      "step": 7214
    },
    {
      "epoch": 2.886,
      "grad_norm": 0.0033327897544950247,
      "learning_rate": 3.813333333333333e-08,
      "logits/chosen": -2.5726842880249023,
      "logits/rejected": -2.0329792499542236,
      "logps/chosen": -135.6875,
      "logps/rejected": -244.01138305664062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03720548748970032,
      "rewards/margins": 11.859804153442383,
      "rewards/rejected": -11.822599411010742,
      "step": 7215
    },
    {
      "epoch": 2.8864,
      "grad_norm": 0.00032559281680732965,
      "learning_rate": 3.7999999999999996e-08,
      "logits/chosen": -2.5559959411621094,
      "logits/rejected": -1.997807264328003,
      "logps/chosen": -78.32453918457031,
      "logps/rejected": -286.0028381347656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.26832008361816406,
      "rewards/margins": 16.691892623901367,
      "rewards/rejected": -16.96021270751953,
      "step": 7216
    },
    {
      "epoch": 2.8868,
      "grad_norm": 0.006255706772208214,
      "learning_rate": 3.786666666666666e-08,
      "logits/chosen": -2.604617118835449,
      "logits/rejected": -1.8722593784332275,
      "logps/chosen": -109.58595275878906,
      "logps/rejected": -164.4873046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.028594970703125,
      "rewards/margins": 11.67170238494873,
      "rewards/rejected": -11.643107414245605,
      "step": 7217
    },
    {
      "epoch": 2.8872,
      "grad_norm": 0.008114459924399853,
      "learning_rate": 3.7733333333333334e-08,
      "logits/chosen": -2.0710113048553467,
      "logits/rejected": -1.6380144357681274,
      "logps/chosen": -211.82156372070312,
      "logps/rejected": -212.45169067382812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.3537118434906006,
      "rewards/margins": 11.04422378540039,
      "rewards/rejected": -13.39793586730957,
      "step": 7218
    },
    {
      "epoch": 2.8876,
      "grad_norm": 0.012733186595141888,
      "learning_rate": 3.76e-08,
      "logits/chosen": -2.719125509262085,
      "logits/rejected": -2.3645882606506348,
      "logps/chosen": -80.28803253173828,
      "logps/rejected": -137.91693115234375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3156208992004395,
      "rewards/margins": 10.273526191711426,
      "rewards/rejected": -8.957904815673828,
      "step": 7219
    },
    {
      "epoch": 2.888,
      "grad_norm": 0.19800767302513123,
      "learning_rate": 3.7466666666666665e-08,
      "logits/chosen": -3.1012768745422363,
      "logits/rejected": -2.767488479614258,
      "logps/chosen": -71.03411865234375,
      "logps/rejected": -108.50386047363281,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5023038983345032,
      "rewards/margins": 6.831903457641602,
      "rewards/rejected": -6.329599380493164,
      "step": 7220
    },
    {
      "epoch": 2.8884,
      "grad_norm": 0.3756727874279022,
      "learning_rate": 3.733333333333334e-08,
      "logits/chosen": -2.931264638900757,
      "logits/rejected": -2.877504825592041,
      "logps/chosen": -104.87896728515625,
      "logps/rejected": -115.286376953125,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.43825799226760864,
      "rewards/margins": 6.923852920532227,
      "rewards/rejected": -7.3621110916137695,
      "step": 7221
    },
    {
      "epoch": 2.8888,
      "grad_norm": 0.0028346609324216843,
      "learning_rate": 3.7199999999999996e-08,
      "logits/chosen": -2.61017107963562,
      "logits/rejected": -1.7856831550598145,
      "logps/chosen": -71.77880096435547,
      "logps/rejected": -174.80584716796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7587063908576965,
      "rewards/margins": 11.60057258605957,
      "rewards/rejected": -10.841866493225098,
      "step": 7222
    },
    {
      "epoch": 2.8891999999999998,
      "grad_norm": 0.0011500983964651823,
      "learning_rate": 3.706666666666666e-08,
      "logits/chosen": -2.5754454135894775,
      "logits/rejected": -1.7884447574615479,
      "logps/chosen": -155.57492065429688,
      "logps/rejected": -213.6864471435547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.06472549587488174,
      "rewards/margins": 13.384271621704102,
      "rewards/rejected": -13.448996543884277,
      "step": 7223
    },
    {
      "epoch": 2.8895999999999997,
      "grad_norm": 5.490350723266602,
      "learning_rate": 3.693333333333333e-08,
      "logits/chosen": -2.5285816192626953,
      "logits/rejected": -2.4877116680145264,
      "logps/chosen": -83.09918212890625,
      "logps/rejected": -100.85775756835938,
      "loss": 0.039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05613955855369568,
      "rewards/margins": 5.361496925354004,
      "rewards/rejected": -5.305357456207275,
      "step": 7224
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.41220515966415405,
      "learning_rate": 3.68e-08,
      "logits/chosen": -2.9394264221191406,
      "logits/rejected": -2.434248447418213,
      "logps/chosen": -60.445465087890625,
      "logps/rejected": -164.62022399902344,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4228513836860657,
      "rewards/margins": 11.393850326538086,
      "rewards/rejected": -10.970999717712402,
      "step": 7225
    },
    {
      "epoch": 2.8904,
      "grad_norm": 0.06703611463308334,
      "learning_rate": 3.6666666666666664e-08,
      "logits/chosen": -2.3229618072509766,
      "logits/rejected": -1.7848443984985352,
      "logps/chosen": -113.85697937011719,
      "logps/rejected": -156.24575805664062,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1712726354598999,
      "rewards/margins": 8.82844066619873,
      "rewards/rejected": -8.999712944030762,
      "step": 7226
    },
    {
      "epoch": 2.8908,
      "grad_norm": 0.000994549598544836,
      "learning_rate": 3.653333333333333e-08,
      "logits/chosen": -2.2463035583496094,
      "logits/rejected": -1.4108359813690186,
      "logps/chosen": -152.31793212890625,
      "logps/rejected": -254.4252471923828,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3816467225551605,
      "rewards/margins": 14.533662796020508,
      "rewards/rejected": -14.152017593383789,
      "step": 7227
    },
    {
      "epoch": 2.8912,
      "grad_norm": 0.010323467664420605,
      "learning_rate": 3.64e-08,
      "logits/chosen": -2.501254081726074,
      "logits/rejected": -1.8244277238845825,
      "logps/chosen": -174.82838439941406,
      "logps/rejected": -187.65200805664062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1347074657678604,
      "rewards/margins": 11.896081924438477,
      "rewards/rejected": -12.030789375305176,
      "step": 7228
    },
    {
      "epoch": 2.8916,
      "grad_norm": 0.0166030190885067,
      "learning_rate": 3.626666666666667e-08,
      "logits/chosen": -2.478200674057007,
      "logits/rejected": -1.7257633209228516,
      "logps/chosen": -84.4679946899414,
      "logps/rejected": -163.14834594726562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7798389196395874,
      "rewards/margins": 10.587724685668945,
      "rewards/rejected": -9.807886123657227,
      "step": 7229
    },
    {
      "epoch": 2.892,
      "grad_norm": 0.007979008369147778,
      "learning_rate": 3.613333333333333e-08,
      "logits/chosen": -2.9470009803771973,
      "logits/rejected": -2.28572416305542,
      "logps/chosen": -42.55833053588867,
      "logps/rejected": -140.7235107421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8452047109603882,
      "rewards/margins": 10.081792831420898,
      "rewards/rejected": -9.236587524414062,
      "step": 7230
    },
    {
      "epoch": 2.8924,
      "grad_norm": 0.17055505514144897,
      "learning_rate": 3.6e-08,
      "logits/chosen": -2.4933056831359863,
      "logits/rejected": -1.8849852085113525,
      "logps/chosen": -87.33928680419922,
      "logps/rejected": -157.36630249023438,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.842353105545044,
      "rewards/margins": 11.105764389038086,
      "rewards/rejected": -10.263410568237305,
      "step": 7231
    },
    {
      "epoch": 2.8928000000000003,
      "grad_norm": 20.19306755065918,
      "learning_rate": 3.5866666666666664e-08,
      "logits/chosen": -2.5797019004821777,
      "logits/rejected": -2.1301016807556152,
      "logps/chosen": -144.1643524169922,
      "logps/rejected": -214.97708129882812,
      "loss": 0.0667,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.9579060077667236,
      "rewards/margins": 10.461523056030273,
      "rewards/rejected": -13.419429779052734,
      "step": 7232
    },
    {
      "epoch": 2.8932,
      "grad_norm": 3.9957103729248047,
      "learning_rate": 3.573333333333333e-08,
      "logits/chosen": -2.4026544094085693,
      "logits/rejected": -2.103875160217285,
      "logps/chosen": -139.67449951171875,
      "logps/rejected": -191.7193603515625,
      "loss": 0.0181,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0847373902797699,
      "rewards/margins": 9.936433792114258,
      "rewards/rejected": -9.851696014404297,
      "step": 7233
    },
    {
      "epoch": 2.8936,
      "grad_norm": 7.075411319732666,
      "learning_rate": 3.56e-08,
      "logits/chosen": -2.6174964904785156,
      "logits/rejected": -2.303757667541504,
      "logps/chosen": -94.49571228027344,
      "logps/rejected": -154.27804565429688,
      "loss": 0.0425,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.718979835510254,
      "rewards/margins": 7.792845726013184,
      "rewards/rejected": -9.511825561523438,
      "step": 7234
    },
    {
      "epoch": 2.894,
      "grad_norm": 0.028273357078433037,
      "learning_rate": 3.5466666666666667e-08,
      "logits/chosen": -2.8515639305114746,
      "logits/rejected": -2.1805272102355957,
      "logps/chosen": -46.21689224243164,
      "logps/rejected": -136.3316650390625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5836405754089355,
      "rewards/margins": 11.182718276977539,
      "rewards/rejected": -9.599078178405762,
      "step": 7235
    },
    {
      "epoch": 2.8944,
      "grad_norm": 0.10825410485267639,
      "learning_rate": 3.533333333333333e-08,
      "logits/chosen": -2.549759864807129,
      "logits/rejected": -2.4226996898651123,
      "logps/chosen": -185.35504150390625,
      "logps/rejected": -152.22671508789062,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9671539068222046,
      "rewards/margins": 7.4174909591674805,
      "rewards/rejected": -8.384645462036133,
      "step": 7236
    },
    {
      "epoch": 2.8948,
      "grad_norm": 2.19028639793396,
      "learning_rate": 3.52e-08,
      "logits/chosen": -2.8414077758789062,
      "logits/rejected": -2.7852325439453125,
      "logps/chosen": -124.52987670898438,
      "logps/rejected": -145.69363403320312,
      "loss": 0.0072,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32200050354003906,
      "rewards/margins": 6.029264450073242,
      "rewards/rejected": -5.707263946533203,
      "step": 7237
    },
    {
      "epoch": 2.8952,
      "grad_norm": 0.0002735672169364989,
      "learning_rate": 3.506666666666667e-08,
      "logits/chosen": -2.5362744331359863,
      "logits/rejected": -1.8511695861816406,
      "logps/chosen": -110.8192138671875,
      "logps/rejected": -198.06471252441406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2902950048446655,
      "rewards/margins": 15.899622917175293,
      "rewards/rejected": -14.60932731628418,
      "step": 7238
    },
    {
      "epoch": 2.8956,
      "grad_norm": 0.0014621110167354345,
      "learning_rate": 3.493333333333333e-08,
      "logits/chosen": -2.522158622741699,
      "logits/rejected": -1.9673678874969482,
      "logps/chosen": -105.83927917480469,
      "logps/rejected": -188.5878143310547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21010780334472656,
      "rewards/margins": 12.75894546508789,
      "rewards/rejected": -12.548837661743164,
      "step": 7239
    },
    {
      "epoch": 2.896,
      "grad_norm": 0.15784117579460144,
      "learning_rate": 3.4799999999999994e-08,
      "logits/chosen": -2.737152576446533,
      "logits/rejected": -2.291698932647705,
      "logps/chosen": -66.08786010742188,
      "logps/rejected": -95.45970153808594,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1610116958618164,
      "rewards/margins": 7.018587112426758,
      "rewards/rejected": -5.857575416564941,
      "step": 7240
    },
    {
      "epoch": 2.8964,
      "grad_norm": 0.0030791708268225193,
      "learning_rate": 3.4666666666666666e-08,
      "logits/chosen": -2.208500385284424,
      "logits/rejected": -1.3038032054901123,
      "logps/chosen": -161.865966796875,
      "logps/rejected": -192.8082733154297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33083805441856384,
      "rewards/margins": 12.840507507324219,
      "rewards/rejected": -12.509669303894043,
      "step": 7241
    },
    {
      "epoch": 2.8968,
      "grad_norm": 2.7776863134931773e-05,
      "learning_rate": 3.453333333333333e-08,
      "logits/chosen": -2.371664047241211,
      "logits/rejected": -1.6525681018829346,
      "logps/chosen": -88.13665771484375,
      "logps/rejected": -264.5401611328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5445613861083984,
      "rewards/margins": 17.24087905883789,
      "rewards/rejected": -15.696317672729492,
      "step": 7242
    },
    {
      "epoch": 2.8971999999999998,
      "grad_norm": 0.00284744193777442,
      "learning_rate": 3.44e-08,
      "logits/chosen": -2.6431803703308105,
      "logits/rejected": -2.193598985671997,
      "logps/chosen": -78.29347229003906,
      "logps/rejected": -149.59384155273438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8933712244033813,
      "rewards/margins": 11.233009338378906,
      "rewards/rejected": -10.339638710021973,
      "step": 7243
    },
    {
      "epoch": 2.8975999999999997,
      "grad_norm": 0.13745978474617004,
      "learning_rate": 3.426666666666667e-08,
      "logits/chosen": -2.7143492698669434,
      "logits/rejected": -2.4101548194885254,
      "logps/chosen": -73.04933166503906,
      "logps/rejected": -116.94996643066406,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.63443523645401,
      "rewards/margins": 8.353094100952148,
      "rewards/rejected": -7.718659400939941,
      "step": 7244
    },
    {
      "epoch": 2.898,
      "grad_norm": 0.5788700580596924,
      "learning_rate": 3.4133333333333335e-08,
      "logits/chosen": -2.564911365509033,
      "logits/rejected": -2.5531692504882812,
      "logps/chosen": -66.8158950805664,
      "logps/rejected": -111.69352722167969,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6431792974472046,
      "rewards/margins": 7.582595348358154,
      "rewards/rejected": -6.93941593170166,
      "step": 7245
    },
    {
      "epoch": 2.8984,
      "grad_norm": 0.0918726697564125,
      "learning_rate": 3.4e-08,
      "logits/chosen": -2.3427014350891113,
      "logits/rejected": -2.053194046020508,
      "logps/chosen": -125.5548095703125,
      "logps/rejected": -166.77621459960938,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.23747938871383667,
      "rewards/margins": 9.590438842773438,
      "rewards/rejected": -9.82791805267334,
      "step": 7246
    },
    {
      "epoch": 2.8988,
      "grad_norm": 0.0008426944259554148,
      "learning_rate": 3.3866666666666666e-08,
      "logits/chosen": -2.4788753986358643,
      "logits/rejected": -2.061652421951294,
      "logps/chosen": -83.18169403076172,
      "logps/rejected": -185.59637451171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7984333038330078,
      "rewards/margins": 12.924917221069336,
      "rewards/rejected": -11.126483917236328,
      "step": 7247
    },
    {
      "epoch": 2.8992,
      "grad_norm": 0.005208562593907118,
      "learning_rate": 3.373333333333333e-08,
      "logits/chosen": -2.877810478210449,
      "logits/rejected": -2.4440455436706543,
      "logps/chosen": -71.22640991210938,
      "logps/rejected": -159.38990783691406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5589885711669922,
      "rewards/margins": 12.17721939086914,
      "rewards/rejected": -11.618230819702148,
      "step": 7248
    },
    {
      "epoch": 2.8996,
      "grad_norm": 1.975907802581787,
      "learning_rate": 3.3599999999999996e-08,
      "logits/chosen": -2.3219685554504395,
      "logits/rejected": -2.4005565643310547,
      "logps/chosen": -61.56214904785156,
      "logps/rejected": -127.20068359375,
      "loss": 0.0126,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6683634519577026,
      "rewards/margins": 7.275190830230713,
      "rewards/rejected": -7.943553924560547,
      "step": 7249
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.5044959783554077,
      "learning_rate": 3.346666666666666e-08,
      "logits/chosen": -2.467968463897705,
      "logits/rejected": -2.063358783721924,
      "logps/chosen": -145.8873291015625,
      "logps/rejected": -156.48214721679688,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5456966161727905,
      "rewards/margins": 8.287886619567871,
      "rewards/rejected": -8.83358383178711,
      "step": 7250
    },
    {
      "epoch": 2.9004,
      "grad_norm": 0.0033148929942399263,
      "learning_rate": 3.3333333333333334e-08,
      "logits/chosen": -2.5437941551208496,
      "logits/rejected": -2.1855318546295166,
      "logps/chosen": -58.624786376953125,
      "logps/rejected": -179.29483032226562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3437817096710205,
      "rewards/margins": 13.328913688659668,
      "rewards/rejected": -11.985132217407227,
      "step": 7251
    },
    {
      "epoch": 2.9008000000000003,
      "grad_norm": 0.04540976136922836,
      "learning_rate": 3.32e-08,
      "logits/chosen": -2.7420005798339844,
      "logits/rejected": -1.9349311590194702,
      "logps/chosen": -56.47581100463867,
      "logps/rejected": -146.65069580078125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3833814859390259,
      "rewards/margins": 11.638402938842773,
      "rewards/rejected": -10.255021095275879,
      "step": 7252
    },
    {
      "epoch": 2.9012000000000002,
      "grad_norm": 0.19783955812454224,
      "learning_rate": 3.3066666666666665e-08,
      "logits/chosen": -2.789297342300415,
      "logits/rejected": -2.5059447288513184,
      "logps/chosen": -141.68243408203125,
      "logps/rejected": -153.5218505859375,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.13822442293167114,
      "rewards/margins": 9.184715270996094,
      "rewards/rejected": -9.3229398727417,
      "step": 7253
    },
    {
      "epoch": 2.9016,
      "grad_norm": 0.22777190804481506,
      "learning_rate": 3.293333333333334e-08,
      "logits/chosen": -2.679276466369629,
      "logits/rejected": -2.708831787109375,
      "logps/chosen": -64.13973236083984,
      "logps/rejected": -136.82777404785156,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.03549480438232422,
      "rewards/margins": 8.823204040527344,
      "rewards/rejected": -8.858697891235352,
      "step": 7254
    },
    {
      "epoch": 2.902,
      "grad_norm": 0.004146140068769455,
      "learning_rate": 3.28e-08,
      "logits/chosen": -2.362478494644165,
      "logits/rejected": -1.7873815298080444,
      "logps/chosen": -71.87149810791016,
      "logps/rejected": -183.23472595214844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.665241003036499,
      "rewards/margins": 12.640753746032715,
      "rewards/rejected": -9.975512504577637,
      "step": 7255
    },
    {
      "epoch": 2.9024,
      "grad_norm": 0.010755672119557858,
      "learning_rate": 3.266666666666666e-08,
      "logits/chosen": -2.3283891677856445,
      "logits/rejected": -1.8278729915618896,
      "logps/chosen": -215.478515625,
      "logps/rejected": -232.26815795898438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.5039827823638916,
      "rewards/margins": 13.859232902526855,
      "rewards/rejected": -16.36321449279785,
      "step": 7256
    },
    {
      "epoch": 2.9028,
      "grad_norm": 0.004375559277832508,
      "learning_rate": 3.253333333333333e-08,
      "logits/chosen": -2.4914474487304688,
      "logits/rejected": -1.869625210762024,
      "logps/chosen": -123.36709594726562,
      "logps/rejected": -184.96524047851562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10179633647203445,
      "rewards/margins": 11.93767261505127,
      "rewards/rejected": -11.83587646484375,
      "step": 7257
    },
    {
      "epoch": 2.9032,
      "grad_norm": 0.15074628591537476,
      "learning_rate": 3.24e-08,
      "logits/chosen": -2.567258358001709,
      "logits/rejected": -2.0902037620544434,
      "logps/chosen": -140.82339477539062,
      "logps/rejected": -143.8370819091797,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.520983874797821,
      "rewards/margins": 9.701395034790039,
      "rewards/rejected": -9.180410385131836,
      "step": 7258
    },
    {
      "epoch": 2.9036,
      "grad_norm": 0.01899454928934574,
      "learning_rate": 3.2266666666666664e-08,
      "logits/chosen": -2.6923930644989014,
      "logits/rejected": -1.9199256896972656,
      "logps/chosen": -76.03270721435547,
      "logps/rejected": -164.40037536621094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.578600287437439,
      "rewards/margins": 10.24850845336914,
      "rewards/rejected": -9.66990852355957,
      "step": 7259
    },
    {
      "epoch": 2.904,
      "grad_norm": 0.001773491851054132,
      "learning_rate": 3.213333333333333e-08,
      "logits/chosen": -2.498950719833374,
      "logits/rejected": -2.248751401901245,
      "logps/chosen": -83.02333068847656,
      "logps/rejected": -169.95654296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08485758304595947,
      "rewards/margins": 12.271282196044922,
      "rewards/rejected": -12.186424255371094,
      "step": 7260
    },
    {
      "epoch": 2.9044,
      "grad_norm": 0.0002609536168165505,
      "learning_rate": 3.2e-08,
      "logits/chosen": -2.811614513397217,
      "logits/rejected": -2.3252615928649902,
      "logps/chosen": -54.11243438720703,
      "logps/rejected": -197.71212768554688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6513973474502563,
      "rewards/margins": 15.408454895019531,
      "rewards/rejected": -13.757057189941406,
      "step": 7261
    },
    {
      "epoch": 2.9048,
      "grad_norm": 0.0030165587086230516,
      "learning_rate": 3.186666666666667e-08,
      "logits/chosen": -2.503674268722534,
      "logits/rejected": -2.2377774715423584,
      "logps/chosen": -69.36308288574219,
      "logps/rejected": -173.77316284179688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7473650574684143,
      "rewards/margins": 12.76298713684082,
      "rewards/rejected": -12.015621185302734,
      "step": 7262
    },
    {
      "epoch": 2.9052,
      "grad_norm": 0.0868707150220871,
      "learning_rate": 3.173333333333333e-08,
      "logits/chosen": -2.8679866790771484,
      "logits/rejected": -2.2875170707702637,
      "logps/chosen": -44.2296142578125,
      "logps/rejected": -123.22351837158203,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2084004878997803,
      "rewards/margins": 10.12835693359375,
      "rewards/rejected": -7.919956207275391,
      "step": 7263
    },
    {
      "epoch": 2.9055999999999997,
      "grad_norm": 0.01428261399269104,
      "learning_rate": 3.16e-08,
      "logits/chosen": -2.3710405826568604,
      "logits/rejected": -1.8659687042236328,
      "logps/chosen": -133.561279296875,
      "logps/rejected": -189.33987426757812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2608829736709595,
      "rewards/margins": 11.70460033416748,
      "rewards/rejected": -12.965482711791992,
      "step": 7264
    },
    {
      "epoch": 2.906,
      "grad_norm": 0.013265913352370262,
      "learning_rate": 3.1466666666666664e-08,
      "logits/chosen": -2.4587392807006836,
      "logits/rejected": -1.6249279975891113,
      "logps/chosen": -80.38897705078125,
      "logps/rejected": -165.13079833984375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5444053411483765,
      "rewards/margins": 9.96969223022461,
      "rewards/rejected": -9.425287246704102,
      "step": 7265
    },
    {
      "epoch": 2.9064,
      "grad_norm": 0.0028424470219761133,
      "learning_rate": 3.133333333333333e-08,
      "logits/chosen": -2.3233120441436768,
      "logits/rejected": -1.9726048707962036,
      "logps/chosen": -73.0400619506836,
      "logps/rejected": -174.87168884277344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08416081964969635,
      "rewards/margins": 11.062034606933594,
      "rewards/rejected": -10.977873802185059,
      "step": 7266
    },
    {
      "epoch": 2.9068,
      "grad_norm": 1.8791553974151611,
      "learning_rate": 3.1199999999999995e-08,
      "logits/chosen": -2.6894092559814453,
      "logits/rejected": -2.6420860290527344,
      "logps/chosen": -125.16188049316406,
      "logps/rejected": -136.99122619628906,
      "loss": 0.0082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.1437888145446777,
      "rewards/margins": 5.724458694458008,
      "rewards/rejected": -8.868247985839844,
      "step": 7267
    },
    {
      "epoch": 2.9072,
      "grad_norm": 0.06453430652618408,
      "learning_rate": 3.106666666666667e-08,
      "logits/chosen": -2.5314419269561768,
      "logits/rejected": -2.081183433532715,
      "logps/chosen": -128.83131408691406,
      "logps/rejected": -147.58689880371094,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2600932717323303,
      "rewards/margins": 10.18030071258545,
      "rewards/rejected": -9.920207977294922,
      "step": 7268
    },
    {
      "epoch": 2.9076,
      "grad_norm": 0.007906313054263592,
      "learning_rate": 3.093333333333333e-08,
      "logits/chosen": -2.936469793319702,
      "logits/rejected": -2.287648916244507,
      "logps/chosen": -47.44654846191406,
      "logps/rejected": -138.77334594726562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1141717433929443,
      "rewards/margins": 11.42060661315918,
      "rewards/rejected": -10.306435585021973,
      "step": 7269
    },
    {
      "epoch": 2.908,
      "grad_norm": 0.0699114128947258,
      "learning_rate": 3.08e-08,
      "logits/chosen": -2.3667819499969482,
      "logits/rejected": -1.9290424585342407,
      "logps/chosen": -103.43757629394531,
      "logps/rejected": -222.74346923828125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.4625415802001953,
      "rewards/margins": 10.961527824401855,
      "rewards/rejected": -14.42406940460205,
      "step": 7270
    },
    {
      "epoch": 2.9084,
      "grad_norm": 0.001671145437285304,
      "learning_rate": 3.0666666666666663e-08,
      "logits/chosen": -2.8242735862731934,
      "logits/rejected": -2.2563633918762207,
      "logps/chosen": -110.82620239257812,
      "logps/rejected": -179.77593994140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3720703125,
      "rewards/margins": 13.709405899047852,
      "rewards/rejected": -12.337335586547852,
      "step": 7271
    },
    {
      "epoch": 2.9088000000000003,
      "grad_norm": 0.1957543045282364,
      "learning_rate": 3.053333333333333e-08,
      "logits/chosen": -2.5996010303497314,
      "logits/rejected": -2.0217700004577637,
      "logps/chosen": -63.357643127441406,
      "logps/rejected": -135.5443572998047,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.12821407616138458,
      "rewards/margins": 8.754380226135254,
      "rewards/rejected": -8.88259506225586,
      "step": 7272
    },
    {
      "epoch": 2.9092000000000002,
      "grad_norm": 0.3869013786315918,
      "learning_rate": 3.04e-08,
      "logits/chosen": -2.3206138610839844,
      "logits/rejected": -1.5625027418136597,
      "logps/chosen": -142.87469482421875,
      "logps/rejected": -152.87428283691406,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.18033897876739502,
      "rewards/margins": 9.703615188598633,
      "rewards/rejected": -9.883955001831055,
      "step": 7273
    },
    {
      "epoch": 2.9096,
      "grad_norm": 0.027750417590141296,
      "learning_rate": 3.0266666666666666e-08,
      "logits/chosen": -2.3729443550109863,
      "logits/rejected": -1.6217522621154785,
      "logps/chosen": -116.04763793945312,
      "logps/rejected": -264.296630859375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.17546916007995605,
      "rewards/margins": 13.887702941894531,
      "rewards/rejected": -14.06317138671875,
      "step": 7274
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.06960691511631012,
      "learning_rate": 3.013333333333333e-08,
      "logits/chosen": -2.7652876377105713,
      "logits/rejected": -2.508993625640869,
      "logps/chosen": -40.163631439208984,
      "logps/rejected": -93.8665542602539,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5946836471557617,
      "rewards/margins": 8.417869567871094,
      "rewards/rejected": -6.823185920715332,
      "step": 7275
    },
    {
      "epoch": 2.9104,
      "grad_norm": 0.043225180357694626,
      "learning_rate": 3e-08,
      "logits/chosen": -2.457416534423828,
      "logits/rejected": -1.8313043117523193,
      "logps/chosen": -117.43365478515625,
      "logps/rejected": -245.62249755859375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7276536822319031,
      "rewards/margins": 9.092047691345215,
      "rewards/rejected": -9.819701194763184,
      "step": 7276
    },
    {
      "epoch": 2.9108,
      "grad_norm": 0.006859412882477045,
      "learning_rate": 2.986666666666666e-08,
      "logits/chosen": -2.4166886806488037,
      "logits/rejected": -1.882197380065918,
      "logps/chosen": -110.60803985595703,
      "logps/rejected": -162.7506561279297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5099431872367859,
      "rewards/margins": 10.795995712280273,
      "rewards/rejected": -10.286052703857422,
      "step": 7277
    },
    {
      "epoch": 2.9112,
      "grad_norm": 6.746709004801232e-06,
      "learning_rate": 2.973333333333333e-08,
      "logits/chosen": -2.4227359294891357,
      "logits/rejected": -1.7543034553527832,
      "logps/chosen": -73.89897155761719,
      "logps/rejected": -228.46316528320312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5776088237762451,
      "rewards/margins": 17.897991180419922,
      "rewards/rejected": -16.320383071899414,
      "step": 7278
    },
    {
      "epoch": 2.9116,
      "grad_norm": 0.16628135740756989,
      "learning_rate": 2.96e-08,
      "logits/chosen": -2.675164222717285,
      "logits/rejected": -2.5094566345214844,
      "logps/chosen": -141.40135192871094,
      "logps/rejected": -152.323486328125,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8883568048477173,
      "rewards/margins": 10.15456485748291,
      "rewards/rejected": -11.04292106628418,
      "step": 7279
    },
    {
      "epoch": 2.912,
      "grad_norm": 0.09793096780776978,
      "learning_rate": 2.9466666666666663e-08,
      "logits/chosen": -2.811018228530884,
      "logits/rejected": -2.4587950706481934,
      "logps/chosen": -97.86445617675781,
      "logps/rejected": -151.2598876953125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3783932030200958,
      "rewards/margins": 10.590378761291504,
      "rewards/rejected": -10.968771934509277,
      "step": 7280
    },
    {
      "epoch": 2.9124,
      "grad_norm": 0.304814875125885,
      "learning_rate": 2.933333333333333e-08,
      "logits/chosen": -2.165045976638794,
      "logits/rejected": -1.6361010074615479,
      "logps/chosen": -126.58798217773438,
      "logps/rejected": -195.05784606933594,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.099541187286377,
      "rewards/margins": 11.629077911376953,
      "rewards/rejected": -9.529536247253418,
      "step": 7281
    },
    {
      "epoch": 2.9128,
      "grad_norm": 0.05418361350893974,
      "learning_rate": 2.92e-08,
      "logits/chosen": -2.8926002979278564,
      "logits/rejected": -2.4772238731384277,
      "logps/chosen": -83.70209503173828,
      "logps/rejected": -173.25596618652344,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.441835641860962,
      "rewards/margins": 10.334464073181152,
      "rewards/rejected": -11.776300430297852,
      "step": 7282
    },
    {
      "epoch": 2.9132,
      "grad_norm": 0.04019278660416603,
      "learning_rate": 2.9066666666666666e-08,
      "logits/chosen": -2.6536149978637695,
      "logits/rejected": -1.7076724767684937,
      "logps/chosen": -120.947265625,
      "logps/rejected": -219.00106811523438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3040821552276611,
      "rewards/margins": 11.622880935668945,
      "rewards/rejected": -12.926961898803711,
      "step": 7283
    },
    {
      "epoch": 2.9135999999999997,
      "grad_norm": 0.042202699929475784,
      "learning_rate": 2.893333333333333e-08,
      "logits/chosen": -2.475677728652954,
      "logits/rejected": -2.056887149810791,
      "logps/chosen": -150.62942504882812,
      "logps/rejected": -161.93875122070312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.006090544164180756,
      "rewards/margins": 10.339111328125,
      "rewards/rejected": -10.34520149230957,
      "step": 7284
    },
    {
      "epoch": 2.914,
      "grad_norm": 0.0013417464215308428,
      "learning_rate": 2.8799999999999996e-08,
      "logits/chosen": -2.8896987438201904,
      "logits/rejected": -2.363798141479492,
      "logps/chosen": -82.76287841796875,
      "logps/rejected": -190.34536743164062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3657032251358032,
      "rewards/margins": 13.419670104980469,
      "rewards/rejected": -13.053967475891113,
      "step": 7285
    },
    {
      "epoch": 2.9144,
      "grad_norm": 0.00011406656267354265,
      "learning_rate": 2.8666666666666665e-08,
      "logits/chosen": -2.7434282302856445,
      "logits/rejected": -2.2051680088043213,
      "logps/chosen": -60.6081657409668,
      "logps/rejected": -187.36593627929688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5301309823989868,
      "rewards/margins": 14.845100402832031,
      "rewards/rejected": -14.314970016479492,
      "step": 7286
    },
    {
      "epoch": 2.9148,
      "grad_norm": 0.003235696582123637,
      "learning_rate": 2.8533333333333334e-08,
      "logits/chosen": -2.799496650695801,
      "logits/rejected": -2.3127987384796143,
      "logps/chosen": -72.52005004882812,
      "logps/rejected": -250.31207275390625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5896700024604797,
      "rewards/margins": 16.849403381347656,
      "rewards/rejected": -16.259733200073242,
      "step": 7287
    },
    {
      "epoch": 2.9152,
      "grad_norm": 0.015701910480856895,
      "learning_rate": 2.84e-08,
      "logits/chosen": -2.5060601234436035,
      "logits/rejected": -1.9256031513214111,
      "logps/chosen": -106.36763000488281,
      "logps/rejected": -174.84396362304688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0470912903547287,
      "rewards/margins": 12.046760559082031,
      "rewards/rejected": -12.093851089477539,
      "step": 7288
    },
    {
      "epoch": 2.9156,
      "grad_norm": 0.0014741099439561367,
      "learning_rate": 2.8266666666666665e-08,
      "logits/chosen": -2.4954047203063965,
      "logits/rejected": -1.870055913925171,
      "logps/chosen": -124.34832000732422,
      "logps/rejected": -231.6988067626953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.35897135734558105,
      "rewards/margins": 14.561626434326172,
      "rewards/rejected": -14.920597076416016,
      "step": 7289
    },
    {
      "epoch": 2.916,
      "grad_norm": 0.6046035289764404,
      "learning_rate": 2.813333333333333e-08,
      "logits/chosen": -2.900679349899292,
      "logits/rejected": -2.9450621604919434,
      "logps/chosen": -39.4616584777832,
      "logps/rejected": -174.06639099121094,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6973376274108887,
      "rewards/margins": 11.582449913024902,
      "rewards/rejected": -12.279787063598633,
      "step": 7290
    },
    {
      "epoch": 2.9164,
      "grad_norm": 0.30207470059394836,
      "learning_rate": 2.8e-08,
      "logits/chosen": -2.8575215339660645,
      "logits/rejected": -2.651587963104248,
      "logps/chosen": -82.92848205566406,
      "logps/rejected": -119.88580322265625,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7735391855239868,
      "rewards/margins": 6.5665082931518555,
      "rewards/rejected": -8.340046882629395,
      "step": 7291
    },
    {
      "epoch": 2.9168,
      "grad_norm": 0.0016240368131548166,
      "learning_rate": 2.7866666666666668e-08,
      "logits/chosen": -2.527961254119873,
      "logits/rejected": -2.187925100326538,
      "logps/chosen": -120.10562896728516,
      "logps/rejected": -199.71450805664062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.796251058578491,
      "rewards/margins": 11.833159446716309,
      "rewards/rejected": -14.629410743713379,
      "step": 7292
    },
    {
      "epoch": 2.9172000000000002,
      "grad_norm": 23.511404037475586,
      "learning_rate": 2.773333333333333e-08,
      "logits/chosen": -2.4380881786346436,
      "logits/rejected": -1.9070043563842773,
      "logps/chosen": -111.69357299804688,
      "logps/rejected": -142.21295166015625,
      "loss": 0.106,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.205348253250122,
      "rewards/margins": 7.814441680908203,
      "rewards/rejected": -9.019789695739746,
      "step": 7293
    },
    {
      "epoch": 2.9176,
      "grad_norm": 0.9494692087173462,
      "learning_rate": 2.76e-08,
      "logits/chosen": -2.6792209148406982,
      "logits/rejected": -2.5486044883728027,
      "logps/chosen": -60.65586853027344,
      "logps/rejected": -106.69921112060547,
      "loss": 0.0083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.1830554008483887,
      "rewards/margins": 5.101638317108154,
      "rewards/rejected": -7.284693717956543,
      "step": 7294
    },
    {
      "epoch": 2.918,
      "grad_norm": 0.018548280000686646,
      "learning_rate": 2.7466666666666664e-08,
      "logits/chosen": -2.2904138565063477,
      "logits/rejected": -1.8810641765594482,
      "logps/chosen": -146.7458953857422,
      "logps/rejected": -172.360595703125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1407829523086548,
      "rewards/margins": 9.889211654663086,
      "rewards/rejected": -11.02999496459961,
      "step": 7295
    },
    {
      "epoch": 2.9184,
      "grad_norm": 0.058328721672296524,
      "learning_rate": 2.7333333333333333e-08,
      "logits/chosen": -2.9391345977783203,
      "logits/rejected": -2.3975625038146973,
      "logps/chosen": -65.36599731445312,
      "logps/rejected": -130.07449340820312,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1272052526473999,
      "rewards/margins": 8.031986236572266,
      "rewards/rejected": -7.904780387878418,
      "step": 7296
    },
    {
      "epoch": 2.9188,
      "grad_norm": 3.0206105709075928,
      "learning_rate": 2.72e-08,
      "logits/chosen": -2.466709613800049,
      "logits/rejected": -2.263091564178467,
      "logps/chosen": -69.3729248046875,
      "logps/rejected": -156.34750366210938,
      "loss": 0.0131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13851338624954224,
      "rewards/margins": 8.193442344665527,
      "rewards/rejected": -8.05492877960205,
      "step": 7297
    },
    {
      "epoch": 2.9192,
      "grad_norm": 0.11395958811044693,
      "learning_rate": 2.7066666666666664e-08,
      "logits/chosen": -2.057678699493408,
      "logits/rejected": -1.3901605606079102,
      "logps/chosen": -104.23980712890625,
      "logps/rejected": -174.470703125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.05346184968948364,
      "rewards/margins": 10.17892074584961,
      "rewards/rejected": -10.232382774353027,
      "step": 7298
    },
    {
      "epoch": 2.9196,
      "grad_norm": 0.0772685557603836,
      "learning_rate": 2.6933333333333333e-08,
      "logits/chosen": -2.5669846534729004,
      "logits/rejected": -2.079874038696289,
      "logps/chosen": -94.56246948242188,
      "logps/rejected": -133.20343017578125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3326263427734375,
      "rewards/margins": 10.700176239013672,
      "rewards/rejected": -8.367549896240234,
      "step": 7299
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.1713232696056366,
      "learning_rate": 2.68e-08,
      "logits/chosen": -2.528665781021118,
      "logits/rejected": -2.0978636741638184,
      "logps/chosen": -164.1123504638672,
      "logps/rejected": -153.1322479248047,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5777844190597534,
      "rewards/margins": 10.040958404541016,
      "rewards/rejected": -10.618742942810059,
      "step": 7300
    },
    {
      "epoch": 2.9204,
      "grad_norm": 0.02209322154521942,
      "learning_rate": 2.6666666666666667e-08,
      "logits/chosen": -2.720369338989258,
      "logits/rejected": -2.3430962562561035,
      "logps/chosen": -111.80565643310547,
      "logps/rejected": -158.44775390625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6749718189239502,
      "rewards/margins": 10.98254680633545,
      "rewards/rejected": -10.307575225830078,
      "step": 7301
    },
    {
      "epoch": 2.9208,
      "grad_norm": 0.0016317206900566816,
      "learning_rate": 2.6533333333333333e-08,
      "logits/chosen": -2.9654417037963867,
      "logits/rejected": -2.4632015228271484,
      "logps/chosen": -93.45501708984375,
      "logps/rejected": -180.9573974609375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5571844577789307,
      "rewards/margins": 12.468069076538086,
      "rewards/rejected": -11.910883903503418,
      "step": 7302
    },
    {
      "epoch": 2.9212,
      "grad_norm": 0.0048560090363025665,
      "learning_rate": 2.6399999999999998e-08,
      "logits/chosen": -2.3605761528015137,
      "logits/rejected": -2.0198590755462646,
      "logps/chosen": -172.7364501953125,
      "logps/rejected": -200.24905395507812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5140540599822998,
      "rewards/margins": 11.269458770751953,
      "rewards/rejected": -12.783513069152832,
      "step": 7303
    },
    {
      "epoch": 2.9215999999999998,
      "grad_norm": 0.002146691083908081,
      "learning_rate": 2.6266666666666667e-08,
      "logits/chosen": -2.4651947021484375,
      "logits/rejected": -1.6719238758087158,
      "logps/chosen": -152.8282470703125,
      "logps/rejected": -177.32017517089844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20454558730125427,
      "rewards/margins": 12.021278381347656,
      "rewards/rejected": -11.816733360290527,
      "step": 7304
    },
    {
      "epoch": 2.922,
      "grad_norm": 6.704388618469238,
      "learning_rate": 2.6133333333333332e-08,
      "logits/chosen": -2.580848217010498,
      "logits/rejected": -2.2728195190429688,
      "logps/chosen": -104.03419494628906,
      "logps/rejected": -201.70526123046875,
      "loss": 0.0454,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.4537179470062256,
      "rewards/margins": 11.088470458984375,
      "rewards/rejected": -14.542187690734863,
      "step": 7305
    },
    {
      "epoch": 2.9224,
      "grad_norm": 2.3586318492889404,
      "learning_rate": 2.5999999999999998e-08,
      "logits/chosen": -2.3181369304656982,
      "logits/rejected": -2.1290743350982666,
      "logps/chosen": -147.32801818847656,
      "logps/rejected": -151.00439453125,
      "loss": 0.0088,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.453044891357422,
      "rewards/margins": 5.620997905731201,
      "rewards/rejected": -10.074043273925781,
      "step": 7306
    },
    {
      "epoch": 2.9228,
      "grad_norm": 0.2624620795249939,
      "learning_rate": 2.5866666666666667e-08,
      "logits/chosen": -2.2763891220092773,
      "logits/rejected": -1.656247854232788,
      "logps/chosen": -147.78887939453125,
      "logps/rejected": -143.97506713867188,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.662348210811615,
      "rewards/margins": 7.897894859313965,
      "rewards/rejected": -8.560242652893066,
      "step": 7307
    },
    {
      "epoch": 2.9232,
      "grad_norm": 7.526383706135675e-05,
      "learning_rate": 2.5733333333333332e-08,
      "logits/chosen": -2.274472236633301,
      "logits/rejected": -1.3850212097167969,
      "logps/chosen": -92.99732971191406,
      "logps/rejected": -231.0167236328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3299148082733154,
      "rewards/margins": 15.72177505493164,
      "rewards/rejected": -14.391860008239746,
      "step": 7308
    },
    {
      "epoch": 2.9236,
      "grad_norm": 0.001829253975301981,
      "learning_rate": 2.56e-08,
      "logits/chosen": -2.546265125274658,
      "logits/rejected": -1.9348421096801758,
      "logps/chosen": -74.93008422851562,
      "logps/rejected": -171.08827209472656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0712677240371704,
      "rewards/margins": 12.05221939086914,
      "rewards/rejected": -10.980951309204102,
      "step": 7309
    },
    {
      "epoch": 2.924,
      "grad_norm": 31.013227462768555,
      "learning_rate": 2.5466666666666663e-08,
      "logits/chosen": -2.5833070278167725,
      "logits/rejected": -2.096964120864868,
      "logps/chosen": -101.2098388671875,
      "logps/rejected": -121.37764739990234,
      "loss": 0.1728,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6873507499694824,
      "rewards/margins": 7.524535179138184,
      "rewards/rejected": -8.211885452270508,
      "step": 7310
    },
    {
      "epoch": 2.9244,
      "grad_norm": 0.0014301927294582129,
      "learning_rate": 2.5333333333333332e-08,
      "logits/chosen": -2.644862174987793,
      "logits/rejected": -2.282897472381592,
      "logps/chosen": -86.26034545898438,
      "logps/rejected": -151.1189727783203,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9117580652236938,
      "rewards/margins": 12.064189910888672,
      "rewards/rejected": -10.15243148803711,
      "step": 7311
    },
    {
      "epoch": 2.9248,
      "grad_norm": 0.05839250981807709,
      "learning_rate": 2.52e-08,
      "logits/chosen": -2.6829497814178467,
      "logits/rejected": -2.3510873317718506,
      "logps/chosen": -111.71257019042969,
      "logps/rejected": -150.7945556640625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8943256139755249,
      "rewards/margins": 10.020598411560059,
      "rewards/rejected": -9.126273155212402,
      "step": 7312
    },
    {
      "epoch": 2.9252000000000002,
      "grad_norm": 15.598154067993164,
      "learning_rate": 2.5066666666666666e-08,
      "logits/chosen": -2.4817633628845215,
      "logits/rejected": -2.253910541534424,
      "logps/chosen": -132.42454528808594,
      "logps/rejected": -150.30609130859375,
      "loss": 0.116,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0116701126098633,
      "rewards/margins": 8.200294494628906,
      "rewards/rejected": -9.21196460723877,
      "step": 7313
    },
    {
      "epoch": 2.9256,
      "grad_norm": 131.36460876464844,
      "learning_rate": 2.493333333333333e-08,
      "logits/chosen": -2.460712194442749,
      "logits/rejected": -2.3764476776123047,
      "logps/chosen": -163.1990203857422,
      "logps/rejected": -138.75350952148438,
      "loss": 4.5511,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -6.877686500549316,
      "rewards/margins": 2.315615177154541,
      "rewards/rejected": -9.1933012008667,
      "step": 7314
    },
    {
      "epoch": 2.926,
      "grad_norm": 0.014039522968232632,
      "learning_rate": 2.4799999999999997e-08,
      "logits/chosen": -2.6031486988067627,
      "logits/rejected": -2.2816548347473145,
      "logps/chosen": -109.99061584472656,
      "logps/rejected": -169.87625122070312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8418571949005127,
      "rewards/margins": 11.115718841552734,
      "rewards/rejected": -9.273860931396484,
      "step": 7315
    },
    {
      "epoch": 2.9264,
      "grad_norm": 0.32672297954559326,
      "learning_rate": 2.4666666666666666e-08,
      "logits/chosen": -2.666341781616211,
      "logits/rejected": -2.4872424602508545,
      "logps/chosen": -93.96200561523438,
      "logps/rejected": -136.5688018798828,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16169090569019318,
      "rewards/margins": 9.450159072875977,
      "rewards/rejected": -9.288468360900879,
      "step": 7316
    },
    {
      "epoch": 2.9268,
      "grad_norm": 0.08808412402868271,
      "learning_rate": 2.453333333333333e-08,
      "logits/chosen": -2.388864517211914,
      "logits/rejected": -2.3100147247314453,
      "logps/chosen": -129.7237548828125,
      "logps/rejected": -123.18000793457031,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6445304751396179,
      "rewards/margins": 7.932185173034668,
      "rewards/rejected": -8.576715469360352,
      "step": 7317
    },
    {
      "epoch": 2.9272,
      "grad_norm": 0.3736954629421234,
      "learning_rate": 2.44e-08,
      "logits/chosen": -2.7026021480560303,
      "logits/rejected": -2.269909620285034,
      "logps/chosen": -55.00480270385742,
      "logps/rejected": -117.62763977050781,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1690223217010498,
      "rewards/margins": 8.371816635131836,
      "rewards/rejected": -7.202794075012207,
      "step": 7318
    },
    {
      "epoch": 2.9276,
      "grad_norm": 0.08827865868806839,
      "learning_rate": 2.4266666666666666e-08,
      "logits/chosen": -2.8031036853790283,
      "logits/rejected": -2.6151034832000732,
      "logps/chosen": -94.81306457519531,
      "logps/rejected": -137.85670471191406,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.48090821504592896,
      "rewards/margins": 9.445405006408691,
      "rewards/rejected": -9.926313400268555,
      "step": 7319
    },
    {
      "epoch": 2.928,
      "grad_norm": 0.037989258766174316,
      "learning_rate": 2.413333333333333e-08,
      "logits/chosen": -2.961599826812744,
      "logits/rejected": -2.4167208671569824,
      "logps/chosen": -79.85663604736328,
      "logps/rejected": -132.86297607421875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4091300964355469,
      "rewards/margins": 9.219552040100098,
      "rewards/rejected": -7.810421943664551,
      "step": 7320
    },
    {
      "epoch": 2.9284,
      "grad_norm": 0.28636887669563293,
      "learning_rate": 2.4e-08,
      "logits/chosen": -2.6387667655944824,
      "logits/rejected": -2.2796616554260254,
      "logps/chosen": -70.77899932861328,
      "logps/rejected": -131.43435668945312,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.419300377368927,
      "rewards/margins": 7.9652581214904785,
      "rewards/rejected": -8.384557723999023,
      "step": 7321
    },
    {
      "epoch": 2.9288,
      "grad_norm": 0.04634449630975723,
      "learning_rate": 2.3866666666666665e-08,
      "logits/chosen": -2.3786346912384033,
      "logits/rejected": -1.7313640117645264,
      "logps/chosen": -126.30791473388672,
      "logps/rejected": -147.49261474609375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.36577337980270386,
      "rewards/margins": 8.53089714050293,
      "rewards/rejected": -8.8966703414917,
      "step": 7322
    },
    {
      "epoch": 2.9292,
      "grad_norm": 0.007414714898914099,
      "learning_rate": 2.373333333333333e-08,
      "logits/chosen": -2.5994884967803955,
      "logits/rejected": -2.0917534828186035,
      "logps/chosen": -55.9195442199707,
      "logps/rejected": -169.26730346679688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4512596130371094,
      "rewards/margins": 12.18622875213623,
      "rewards/rejected": -11.734969139099121,
      "step": 7323
    },
    {
      "epoch": 2.9295999999999998,
      "grad_norm": 0.1404242217540741,
      "learning_rate": 2.36e-08,
      "logits/chosen": -2.746314525604248,
      "logits/rejected": -2.5286498069763184,
      "logps/chosen": -62.286407470703125,
      "logps/rejected": -100.81692504882812,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08191756904125214,
      "rewards/margins": 7.065781116485596,
      "rewards/rejected": -6.983863830566406,
      "step": 7324
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.005902557168155909,
      "learning_rate": 2.3466666666666665e-08,
      "logits/chosen": -2.701951026916504,
      "logits/rejected": -2.0677857398986816,
      "logps/chosen": -72.29386901855469,
      "logps/rejected": -152.99636840820312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3771069049835205,
      "rewards/margins": 11.638330459594727,
      "rewards/rejected": -9.261222839355469,
      "step": 7325
    },
    {
      "epoch": 2.9304,
      "grad_norm": 0.05795943737030029,
      "learning_rate": 2.3333333333333334e-08,
      "logits/chosen": -2.0890631675720215,
      "logits/rejected": -1.5897216796875,
      "logps/chosen": -69.25701141357422,
      "logps/rejected": -153.41818237304688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9294841885566711,
      "rewards/margins": 10.333148002624512,
      "rewards/rejected": -9.403663635253906,
      "step": 7326
    },
    {
      "epoch": 2.9308,
      "grad_norm": 0.003371645463630557,
      "learning_rate": 2.3199999999999996e-08,
      "logits/chosen": -2.4302163124084473,
      "logits/rejected": -2.2295889854431152,
      "logps/chosen": -178.15756225585938,
      "logps/rejected": -200.96795654296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6268059015274048,
      "rewards/margins": 12.385339736938477,
      "rewards/rejected": -14.012145042419434,
      "step": 7327
    },
    {
      "epoch": 2.9312,
      "grad_norm": 0.010511315427720547,
      "learning_rate": 2.3066666666666665e-08,
      "logits/chosen": -2.5577309131622314,
      "logits/rejected": -2.11293363571167,
      "logps/chosen": -67.51777648925781,
      "logps/rejected": -205.90133666992188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1793599128723145,
      "rewards/margins": 12.716596603393555,
      "rewards/rejected": -11.537235260009766,
      "step": 7328
    },
    {
      "epoch": 2.9316,
      "grad_norm": 0.01868288591504097,
      "learning_rate": 2.2933333333333334e-08,
      "logits/chosen": -2.8708696365356445,
      "logits/rejected": -2.4556212425231934,
      "logps/chosen": -48.834754943847656,
      "logps/rejected": -146.8934326171875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.37806928157806396,
      "rewards/margins": 9.536731719970703,
      "rewards/rejected": -9.914800643920898,
      "step": 7329
    },
    {
      "epoch": 2.932,
      "grad_norm": 0.00342755694873631,
      "learning_rate": 2.28e-08,
      "logits/chosen": -2.7477974891662598,
      "logits/rejected": -2.2388882637023926,
      "logps/chosen": -54.08771896362305,
      "logps/rejected": -129.0042724609375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9728977680206299,
      "rewards/margins": 11.038759231567383,
      "rewards/rejected": -9.065860748291016,
      "step": 7330
    },
    {
      "epoch": 2.9324,
      "grad_norm": 0.00428477069362998,
      "learning_rate": 2.2666666666666668e-08,
      "logits/chosen": -2.461937427520752,
      "logits/rejected": -1.7000436782836914,
      "logps/chosen": -143.07342529296875,
      "logps/rejected": -199.07208251953125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5241146087646484,
      "rewards/margins": 12.449615478515625,
      "rewards/rejected": -13.973730087280273,
      "step": 7331
    },
    {
      "epoch": 2.9328,
      "grad_norm": 0.0010057187173515558,
      "learning_rate": 2.253333333333333e-08,
      "logits/chosen": -2.4475836753845215,
      "logits/rejected": -1.8855177164077759,
      "logps/chosen": -86.58390045166016,
      "logps/rejected": -253.52243041992188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6186638474464417,
      "rewards/margins": 14.64776611328125,
      "rewards/rejected": -14.02910327911377,
      "step": 7332
    },
    {
      "epoch": 2.9332000000000003,
      "grad_norm": 0.0019998433999717236,
      "learning_rate": 2.24e-08,
      "logits/chosen": -2.284766435623169,
      "logits/rejected": -1.413548469543457,
      "logps/chosen": -183.27171325683594,
      "logps/rejected": -154.31930541992188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8443573713302612,
      "rewards/margins": 11.838364601135254,
      "rewards/rejected": -10.994007110595703,
      "step": 7333
    },
    {
      "epoch": 2.9336,
      "grad_norm": 6.34037351119332e-05,
      "learning_rate": 2.2266666666666668e-08,
      "logits/chosen": -2.387439250946045,
      "logits/rejected": -1.7575905323028564,
      "logps/chosen": -94.30323791503906,
      "logps/rejected": -213.5018768310547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17210426926612854,
      "rewards/margins": 15.603496551513672,
      "rewards/rejected": -15.431392669677734,
      "step": 7334
    },
    {
      "epoch": 2.934,
      "grad_norm": 0.096725232899189,
      "learning_rate": 2.2133333333333333e-08,
      "logits/chosen": -2.012604236602783,
      "logits/rejected": -1.3114089965820312,
      "logps/chosen": -232.40464782714844,
      "logps/rejected": -246.36099243164062,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -5.17150354385376,
      "rewards/margins": 10.623948097229004,
      "rewards/rejected": -15.795452117919922,
      "step": 7335
    },
    {
      "epoch": 2.9344,
      "grad_norm": 0.002265231916680932,
      "learning_rate": 2.2e-08,
      "logits/chosen": -2.6912732124328613,
      "logits/rejected": -2.2325401306152344,
      "logps/chosen": -36.8699951171875,
      "logps/rejected": -167.78253173828125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2323153018951416,
      "rewards/margins": 12.159928321838379,
      "rewards/rejected": -10.9276123046875,
      "step": 7336
    },
    {
      "epoch": 2.9348,
      "grad_norm": 0.19153563678264618,
      "learning_rate": 2.1866666666666664e-08,
      "logits/chosen": -2.409665822982788,
      "logits/rejected": -1.7895991802215576,
      "logps/chosen": -111.47388458251953,
      "logps/rejected": -192.48681640625,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3048049807548523,
      "rewards/margins": 10.858747482299805,
      "rewards/rejected": -11.163553237915039,
      "step": 7337
    },
    {
      "epoch": 2.9352,
      "grad_norm": 0.0972837433218956,
      "learning_rate": 2.1733333333333333e-08,
      "logits/chosen": -2.6050806045532227,
      "logits/rejected": -2.3277230262756348,
      "logps/chosen": -110.41744995117188,
      "logps/rejected": -167.61953735351562,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.024504482746124268,
      "rewards/margins": 12.10672378540039,
      "rewards/rejected": -12.131227493286133,
      "step": 7338
    },
    {
      "epoch": 2.9356,
      "grad_norm": 2.830291748046875,
      "learning_rate": 2.16e-08,
      "logits/chosen": -2.614626407623291,
      "logits/rejected": -2.501763343811035,
      "logps/chosen": -103.54145812988281,
      "logps/rejected": -123.42571258544922,
      "loss": 0.0128,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.6531786918640137,
      "rewards/margins": 6.163220405578613,
      "rewards/rejected": -8.816399574279785,
      "step": 7339
    },
    {
      "epoch": 2.936,
      "grad_norm": 0.0012714503100141883,
      "learning_rate": 2.1466666666666664e-08,
      "logits/chosen": -2.572303056716919,
      "logits/rejected": -1.7520649433135986,
      "logps/chosen": -97.83384704589844,
      "logps/rejected": -183.26649475097656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1399447917938232,
      "rewards/margins": 14.123437881469727,
      "rewards/rejected": -12.98349380493164,
      "step": 7340
    },
    {
      "epoch": 2.9364,
      "grad_norm": 0.18938903510570526,
      "learning_rate": 2.1333333333333332e-08,
      "logits/chosen": -2.5173215866088867,
      "logits/rejected": -2.2939510345458984,
      "logps/chosen": -105.7057876586914,
      "logps/rejected": -161.2018585205078,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.550786018371582,
      "rewards/margins": 8.915529251098633,
      "rewards/rejected": -10.466316223144531,
      "step": 7341
    },
    {
      "epoch": 2.9368,
      "grad_norm": 1.9287667274475098,
      "learning_rate": 2.1199999999999998e-08,
      "logits/chosen": -2.5032691955566406,
      "logits/rejected": -1.8724143505096436,
      "logps/chosen": -62.494930267333984,
      "logps/rejected": -145.24356079101562,
      "loss": 0.0155,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0694282054901123,
      "rewards/margins": 8.256641387939453,
      "rewards/rejected": -8.326069831848145,
      "step": 7342
    },
    {
      "epoch": 2.9372,
      "grad_norm": 0.3906981348991394,
      "learning_rate": 2.1066666666666667e-08,
      "logits/chosen": -2.7537331581115723,
      "logits/rejected": -2.4448390007019043,
      "logps/chosen": -57.358150482177734,
      "logps/rejected": -79.95645904541016,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0910909175872803,
      "rewards/margins": 7.070122241973877,
      "rewards/rejected": -4.979031085968018,
      "step": 7343
    },
    {
      "epoch": 2.9375999999999998,
      "grad_norm": 0.04805561900138855,
      "learning_rate": 2.0933333333333335e-08,
      "logits/chosen": -2.490227699279785,
      "logits/rejected": -1.9606993198394775,
      "logps/chosen": -143.61431884765625,
      "logps/rejected": -153.33914184570312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.24330827593803406,
      "rewards/margins": 10.690221786499023,
      "rewards/rejected": -10.9335298538208,
      "step": 7344
    },
    {
      "epoch": 2.9379999999999997,
      "grad_norm": 0.012942535802721977,
      "learning_rate": 2.0799999999999998e-08,
      "logits/chosen": -2.685807466506958,
      "logits/rejected": -2.091157913208008,
      "logps/chosen": -65.07504272460938,
      "logps/rejected": -134.30738830566406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1907546520233154,
      "rewards/margins": 10.653873443603516,
      "rewards/rejected": -8.463118553161621,
      "step": 7345
    },
    {
      "epoch": 2.9384,
      "grad_norm": 0.06206471845507622,
      "learning_rate": 2.0666666666666666e-08,
      "logits/chosen": -2.6548266410827637,
      "logits/rejected": -2.414858102798462,
      "logps/chosen": -66.62705993652344,
      "logps/rejected": -131.1075897216797,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.683275043964386,
      "rewards/margins": 9.559903144836426,
      "rewards/rejected": -8.876627922058105,
      "step": 7346
    },
    {
      "epoch": 2.9388,
      "grad_norm": 0.015220098197460175,
      "learning_rate": 2.0533333333333332e-08,
      "logits/chosen": -2.3818397521972656,
      "logits/rejected": -2.3633713722229004,
      "logps/chosen": -60.00563430786133,
      "logps/rejected": -145.92459106445312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.06410064548254013,
      "rewards/margins": 9.787395477294922,
      "rewards/rejected": -9.851496696472168,
      "step": 7347
    },
    {
      "epoch": 2.9392,
      "grad_norm": 0.020916884765028954,
      "learning_rate": 2.04e-08,
      "logits/chosen": -2.7672486305236816,
      "logits/rejected": -1.9498573541641235,
      "logps/chosen": -47.00138854980469,
      "logps/rejected": -150.33416748046875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1952936202287674,
      "rewards/margins": 10.92742919921875,
      "rewards/rejected": -10.732135772705078,
      "step": 7348
    },
    {
      "epoch": 2.9396,
      "grad_norm": 0.0003836682008113712,
      "learning_rate": 2.0266666666666666e-08,
      "logits/chosen": -2.2468409538269043,
      "logits/rejected": -1.4568207263946533,
      "logps/chosen": -120.03997802734375,
      "logps/rejected": -199.8397216796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3212352991104126,
      "rewards/margins": 14.245214462280273,
      "rewards/rejected": -12.923978805541992,
      "step": 7349
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.00015959412849042565,
      "learning_rate": 2.013333333333333e-08,
      "logits/chosen": -2.5825085639953613,
      "logits/rejected": -1.6647512912750244,
      "logps/chosen": -79.0802001953125,
      "logps/rejected": -256.05548095703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.03367018699646,
      "rewards/margins": 15.458477020263672,
      "rewards/rejected": -14.424806594848633,
      "step": 7350
    },
    {
      "epoch": 2.9404,
      "grad_norm": 0.0007800417952239513,
      "learning_rate": 2e-08,
      "logits/chosen": -2.8221495151519775,
      "logits/rejected": -2.18742036819458,
      "logps/chosen": -57.869537353515625,
      "logps/rejected": -183.52481079101562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7095857262611389,
      "rewards/margins": 13.698537826538086,
      "rewards/rejected": -12.988951683044434,
      "step": 7351
    },
    {
      "epoch": 2.9408,
      "grad_norm": 90.3160629272461,
      "learning_rate": 1.9866666666666666e-08,
      "logits/chosen": -2.5008111000061035,
      "logits/rejected": -1.9892034530639648,
      "logps/chosen": -85.75101470947266,
      "logps/rejected": -115.05360412597656,
      "loss": 0.9172,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -4.026017189025879,
      "rewards/margins": 3.1497206687927246,
      "rewards/rejected": -7.175737380981445,
      "step": 7352
    },
    {
      "epoch": 2.9412000000000003,
      "grad_norm": 0.0005254103452898562,
      "learning_rate": 1.973333333333333e-08,
      "logits/chosen": -2.4536328315734863,
      "logits/rejected": -1.791930913925171,
      "logps/chosen": -95.12686157226562,
      "logps/rejected": -183.08213806152344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.939139187335968,
      "rewards/margins": 13.051968574523926,
      "rewards/rejected": -12.112829208374023,
      "step": 7353
    },
    {
      "epoch": 2.9416,
      "grad_norm": 2.651683807373047,
      "learning_rate": 1.9599999999999997e-08,
      "logits/chosen": -2.777015209197998,
      "logits/rejected": -2.7967147827148438,
      "logps/chosen": -74.32527160644531,
      "logps/rejected": -92.95144653320312,
      "loss": 0.0158,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.76226806640625,
      "rewards/margins": 4.341650485992432,
      "rewards/rejected": -6.103918075561523,
      "step": 7354
    },
    {
      "epoch": 2.942,
      "grad_norm": 0.005302334204316139,
      "learning_rate": 1.9466666666666666e-08,
      "logits/chosen": -2.8583621978759766,
      "logits/rejected": -2.294583320617676,
      "logps/chosen": -61.1385498046875,
      "logps/rejected": -192.22064208984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2984224557876587,
      "rewards/margins": 15.151412963867188,
      "rewards/rejected": -13.852991104125977,
      "step": 7355
    },
    {
      "epoch": 2.9424,
      "grad_norm": 0.4251910150051117,
      "learning_rate": 1.9333333333333334e-08,
      "logits/chosen": -2.6321816444396973,
      "logits/rejected": -2.0581154823303223,
      "logps/chosen": -68.95288848876953,
      "logps/rejected": -136.3058624267578,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6336770057678223,
      "rewards/margins": 9.925840377807617,
      "rewards/rejected": -8.292162895202637,
      "step": 7356
    },
    {
      "epoch": 2.9428,
      "grad_norm": 0.05294376611709595,
      "learning_rate": 1.9199999999999997e-08,
      "logits/chosen": -2.522465229034424,
      "logits/rejected": -2.184518814086914,
      "logps/chosen": -48.23420715332031,
      "logps/rejected": -134.08474731445312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3162285089492798,
      "rewards/margins": 8.618924140930176,
      "rewards/rejected": -8.935152053833008,
      "step": 7357
    },
    {
      "epoch": 2.9432,
      "grad_norm": 0.926292896270752,
      "learning_rate": 1.9066666666666665e-08,
      "logits/chosen": -2.7114853858947754,
      "logits/rejected": -2.5503718852996826,
      "logps/chosen": -100.3473892211914,
      "logps/rejected": -116.40339660644531,
      "loss": 0.0051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6447608470916748,
      "rewards/margins": 6.16685152053833,
      "rewards/rejected": -6.811612129211426,
      "step": 7358
    },
    {
      "epoch": 2.9436,
      "grad_norm": 1.0857369899749756,
      "learning_rate": 1.893333333333333e-08,
      "logits/chosen": -2.1492104530334473,
      "logits/rejected": -1.716526746749878,
      "logps/chosen": -163.84405517578125,
      "logps/rejected": -192.56561279296875,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.280617713928223,
      "rewards/margins": 9.455766677856445,
      "rewards/rejected": -13.736385345458984,
      "step": 7359
    },
    {
      "epoch": 2.944,
      "grad_norm": 0.1109405905008316,
      "learning_rate": 1.88e-08,
      "logits/chosen": -2.288287401199341,
      "logits/rejected": -2.030691146850586,
      "logps/chosen": -147.6845703125,
      "logps/rejected": -169.01614379882812,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7826690673828125,
      "rewards/margins": 9.03719711303711,
      "rewards/rejected": -9.819866180419922,
      "step": 7360
    },
    {
      "epoch": 2.9444,
      "grad_norm": 0.0042016697116196156,
      "learning_rate": 1.866666666666667e-08,
      "logits/chosen": -2.501615285873413,
      "logits/rejected": -2.148986339569092,
      "logps/chosen": -70.68658447265625,
      "logps/rejected": -179.12255859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.716770589351654,
      "rewards/margins": 11.341825485229492,
      "rewards/rejected": -10.625055313110352,
      "step": 7361
    },
    {
      "epoch": 2.9448,
      "grad_norm": 0.08676029741764069,
      "learning_rate": 1.853333333333333e-08,
      "logits/chosen": -2.423448085784912,
      "logits/rejected": -2.1422107219696045,
      "logps/chosen": -115.03463745117188,
      "logps/rejected": -181.02664184570312,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.4506423473358154,
      "rewards/margins": 9.292682647705078,
      "rewards/rejected": -11.743324279785156,
      "step": 7362
    },
    {
      "epoch": 2.9452,
      "grad_norm": 0.0001341872994089499,
      "learning_rate": 1.84e-08,
      "logits/chosen": -2.5133283138275146,
      "logits/rejected": -1.9654903411865234,
      "logps/chosen": -71.36561584472656,
      "logps/rejected": -256.288330078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0757049322128296,
      "rewards/margins": 14.952739715576172,
      "rewards/rejected": -13.877035140991211,
      "step": 7363
    },
    {
      "epoch": 2.9455999999999998,
      "grad_norm": 0.11893577873706818,
      "learning_rate": 1.8266666666666665e-08,
      "logits/chosen": -2.7383556365966797,
      "logits/rejected": -2.223771572113037,
      "logps/chosen": -118.81024169921875,
      "logps/rejected": -179.65963745117188,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.19767114520072937,
      "rewards/margins": 11.132129669189453,
      "rewards/rejected": -11.329800605773926,
      "step": 7364
    },
    {
      "epoch": 2.9459999999999997,
      "grad_norm": 0.14826564490795135,
      "learning_rate": 1.8133333333333334e-08,
      "logits/chosen": -2.7720947265625,
      "logits/rejected": -2.1327946186065674,
      "logps/chosen": -101.82695007324219,
      "logps/rejected": -205.42547607421875,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8953577280044556,
      "rewards/margins": 12.830598831176758,
      "rewards/rejected": -13.725955963134766,
      "step": 7365
    },
    {
      "epoch": 2.9464,
      "grad_norm": 0.07535002380609512,
      "learning_rate": 1.8e-08,
      "logits/chosen": -2.2913758754730225,
      "logits/rejected": -2.064401626586914,
      "logps/chosen": -185.65145874023438,
      "logps/rejected": -133.82374572753906,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.37680983543396,
      "rewards/margins": 7.780740261077881,
      "rewards/rejected": -10.157550811767578,
      "step": 7366
    },
    {
      "epoch": 2.9468,
      "grad_norm": 0.06172805652022362,
      "learning_rate": 1.7866666666666665e-08,
      "logits/chosen": -2.503377676010132,
      "logits/rejected": -1.8136374950408936,
      "logps/chosen": -134.06346130371094,
      "logps/rejected": -163.89407348632812,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.25675278902053833,
      "rewards/margins": 11.349769592285156,
      "rewards/rejected": -11.606522560119629,
      "step": 7367
    },
    {
      "epoch": 2.9472,
      "grad_norm": 0.011189768090844154,
      "learning_rate": 1.7733333333333333e-08,
      "logits/chosen": -2.5764451026916504,
      "logits/rejected": -1.9052257537841797,
      "logps/chosen": -110.54004669189453,
      "logps/rejected": -200.1604766845703,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.161041259765625,
      "rewards/margins": 13.58170223236084,
      "rewards/rejected": -13.742744445800781,
      "step": 7368
    },
    {
      "epoch": 2.9476,
      "grad_norm": 183.06790161132812,
      "learning_rate": 1.76e-08,
      "logits/chosen": -2.677370548248291,
      "logits/rejected": -2.274362564086914,
      "logps/chosen": -180.8269805908203,
      "logps/rejected": -117.95932006835938,
      "loss": 1.3291,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -3.886474609375,
      "rewards/margins": 3.887094020843506,
      "rewards/rejected": -7.773568630218506,
      "step": 7369
    },
    {
      "epoch": 2.948,
      "grad_norm": 0.044443536549806595,
      "learning_rate": 1.7466666666666664e-08,
      "logits/chosen": -2.7014665603637695,
      "logits/rejected": -2.2553930282592773,
      "logps/chosen": -61.139122009277344,
      "logps/rejected": -158.4804229736328,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5707235336303711,
      "rewards/margins": 11.39482307434082,
      "rewards/rejected": -10.824100494384766,
      "step": 7370
    },
    {
      "epoch": 2.9484,
      "grad_norm": 0.0004079265636391938,
      "learning_rate": 1.7333333333333333e-08,
      "logits/chosen": -2.4592125415802,
      "logits/rejected": -1.438779354095459,
      "logps/chosen": -73.63054656982422,
      "logps/rejected": -194.53524780273438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7967287302017212,
      "rewards/margins": 13.843093872070312,
      "rewards/rejected": -12.046365737915039,
      "step": 7371
    },
    {
      "epoch": 2.9488,
      "grad_norm": 0.008844620548188686,
      "learning_rate": 1.72e-08,
      "logits/chosen": -2.1839756965637207,
      "logits/rejected": -1.7187671661376953,
      "logps/chosen": -199.89859008789062,
      "logps/rejected": -218.01853942871094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3890488147735596,
      "rewards/margins": 11.800780296325684,
      "rewards/rejected": -13.189828872680664,
      "step": 7372
    },
    {
      "epoch": 2.9492000000000003,
      "grad_norm": 0.006937580183148384,
      "learning_rate": 1.7066666666666667e-08,
      "logits/chosen": -3.037592887878418,
      "logits/rejected": -2.733330726623535,
      "logps/chosen": -51.33653259277344,
      "logps/rejected": -128.997314453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5628879070281982,
      "rewards/margins": 10.99267292022705,
      "rewards/rejected": -9.429784774780273,
      "step": 7373
    },
    {
      "epoch": 2.9496,
      "grad_norm": 0.009811684489250183,
      "learning_rate": 1.6933333333333333e-08,
      "logits/chosen": -2.7120606899261475,
      "logits/rejected": -2.0218141078948975,
      "logps/chosen": -63.4398193359375,
      "logps/rejected": -144.05052185058594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7369476556777954,
      "rewards/margins": 11.482728004455566,
      "rewards/rejected": -9.745780944824219,
      "step": 7374
    },
    {
      "epoch": 2.95,
      "grad_norm": 2.634955308167264e-05,
      "learning_rate": 1.6799999999999998e-08,
      "logits/chosen": -2.2826995849609375,
      "logits/rejected": -2.0018372535705566,
      "logps/chosen": -75.09197998046875,
      "logps/rejected": -288.05645751953125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7802006006240845,
      "rewards/margins": 16.567195892333984,
      "rewards/rejected": -15.786995887756348,
      "step": 7375
    },
    {
      "epoch": 2.9504,
      "grad_norm": 9.568198584020138e-05,
      "learning_rate": 1.6666666666666667e-08,
      "logits/chosen": -2.536250352859497,
      "logits/rejected": -1.7643580436706543,
      "logps/chosen": -66.63050842285156,
      "logps/rejected": -202.38235473632812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4065334796905518,
      "rewards/margins": 15.244656562805176,
      "rewards/rejected": -13.838123321533203,
      "step": 7376
    },
    {
      "epoch": 2.9508,
      "grad_norm": 1.6872584819793701,
      "learning_rate": 1.6533333333333332e-08,
      "logits/chosen": -2.9460208415985107,
      "logits/rejected": -2.8245081901550293,
      "logps/chosen": -93.14118194580078,
      "logps/rejected": -84.77949523925781,
      "loss": 0.006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41443902254104614,
      "rewards/margins": 5.685133934020996,
      "rewards/rejected": -5.270694732666016,
      "step": 7377
    },
    {
      "epoch": 2.9512,
      "grad_norm": 0.00021320527594070882,
      "learning_rate": 1.64e-08,
      "logits/chosen": -2.6809792518615723,
      "logits/rejected": -2.078925848007202,
      "logps/chosen": -101.51827239990234,
      "logps/rejected": -267.94415283203125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8652752637863159,
      "rewards/margins": 16.809757232666016,
      "rewards/rejected": -17.675033569335938,
      "step": 7378
    },
    {
      "epoch": 2.9516,
      "grad_norm": 0.37222543358802795,
      "learning_rate": 1.6266666666666663e-08,
      "logits/chosen": -2.8252596855163574,
      "logits/rejected": -2.7548305988311768,
      "logps/chosen": -71.56312561035156,
      "logps/rejected": -137.82022094726562,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7714954614639282,
      "rewards/margins": 9.031168937683105,
      "rewards/rejected": -9.802663803100586,
      "step": 7379
    },
    {
      "epoch": 2.952,
      "grad_norm": 0.050061002373695374,
      "learning_rate": 1.6133333333333332e-08,
      "logits/chosen": -2.821005344390869,
      "logits/rejected": -2.408841133117676,
      "logps/chosen": -53.155853271484375,
      "logps/rejected": -153.60699462890625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.02696971595287323,
      "rewards/margins": 10.341888427734375,
      "rewards/rejected": -10.368858337402344,
      "step": 7380
    },
    {
      "epoch": 2.9524,
      "grad_norm": 0.024823902174830437,
      "learning_rate": 1.6e-08,
      "logits/chosen": -2.301060914993286,
      "logits/rejected": -1.7074074745178223,
      "logps/chosen": -148.2764129638672,
      "logps/rejected": -178.42718505859375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8716336488723755,
      "rewards/margins": 8.960412979125977,
      "rewards/rejected": -10.832045555114746,
      "step": 7381
    },
    {
      "epoch": 2.9528,
      "grad_norm": 0.015349017456173897,
      "learning_rate": 1.5866666666666666e-08,
      "logits/chosen": -2.4065122604370117,
      "logits/rejected": -2.101947784423828,
      "logps/chosen": -143.72543334960938,
      "logps/rejected": -162.46630859375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6774239540100098,
      "rewards/margins": 10.856195449829102,
      "rewards/rejected": -9.17877197265625,
      "step": 7382
    },
    {
      "epoch": 2.9532,
      "grad_norm": 0.016953304409980774,
      "learning_rate": 1.5733333333333332e-08,
      "logits/chosen": -2.728217124938965,
      "logits/rejected": -2.4156711101531982,
      "logps/chosen": -93.57250213623047,
      "logps/rejected": -148.96725463867188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4841776192188263,
      "rewards/margins": 9.587238311767578,
      "rewards/rejected": -10.071414947509766,
      "step": 7383
    },
    {
      "epoch": 2.9536,
      "grad_norm": 0.6679665446281433,
      "learning_rate": 1.5599999999999997e-08,
      "logits/chosen": -2.500425338745117,
      "logits/rejected": -2.0332038402557373,
      "logps/chosen": -87.6602783203125,
      "logps/rejected": -176.4619598388672,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3061143755912781,
      "rewards/margins": 12.921220779418945,
      "rewards/rejected": -12.615106582641602,
      "step": 7384
    },
    {
      "epoch": 2.9539999999999997,
      "grad_norm": 0.1236206665635109,
      "learning_rate": 1.5466666666666666e-08,
      "logits/chosen": -2.83413028717041,
      "logits/rejected": -2.3005728721618652,
      "logps/chosen": -67.26417541503906,
      "logps/rejected": -140.8506317138672,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2268913984298706,
      "rewards/margins": 11.258401870727539,
      "rewards/rejected": -10.031511306762695,
      "step": 7385
    },
    {
      "epoch": 2.9544,
      "grad_norm": 0.025762425735592842,
      "learning_rate": 1.5333333333333332e-08,
      "logits/chosen": -2.5574235916137695,
      "logits/rejected": -2.330460548400879,
      "logps/chosen": -112.09903717041016,
      "logps/rejected": -132.5844268798828,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9740314483642578,
      "rewards/margins": 9.042584419250488,
      "rewards/rejected": -8.06855297088623,
      "step": 7386
    },
    {
      "epoch": 2.9548,
      "grad_norm": 0.008606094866991043,
      "learning_rate": 1.52e-08,
      "logits/chosen": -2.756617546081543,
      "logits/rejected": -2.2447986602783203,
      "logps/chosen": -83.51617431640625,
      "logps/rejected": -148.30654907226562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.19142456352710724,
      "rewards/margins": 10.051595687866211,
      "rewards/rejected": -10.243020057678223,
      "step": 7387
    },
    {
      "epoch": 2.9552,
      "grad_norm": 4.827383041381836,
      "learning_rate": 1.5066666666666666e-08,
      "logits/chosen": -2.4104456901550293,
      "logits/rejected": -2.2038044929504395,
      "logps/chosen": -73.62864685058594,
      "logps/rejected": -124.1790771484375,
      "loss": 0.0452,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09562075138092041,
      "rewards/margins": 7.663984298706055,
      "rewards/rejected": -7.568364143371582,
      "step": 7388
    },
    {
      "epoch": 2.9556,
      "grad_norm": 0.011185374110937119,
      "learning_rate": 1.493333333333333e-08,
      "logits/chosen": -2.723422050476074,
      "logits/rejected": -2.219440460205078,
      "logps/chosen": -79.84322357177734,
      "logps/rejected": -176.62918090820312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7286279797554016,
      "rewards/margins": 11.289502143859863,
      "rewards/rejected": -12.0181303024292,
      "step": 7389
    },
    {
      "epoch": 2.956,
      "grad_norm": 0.0017280402826145291,
      "learning_rate": 1.48e-08,
      "logits/chosen": -2.3777971267700195,
      "logits/rejected": -1.931161880493164,
      "logps/chosen": -183.30599975585938,
      "logps/rejected": -256.3021545410156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.989467144012451,
      "rewards/margins": 12.515974044799805,
      "rewards/rejected": -15.505440711975098,
      "step": 7390
    },
    {
      "epoch": 2.9564,
      "grad_norm": 0.011285084299743176,
      "learning_rate": 1.4666666666666666e-08,
      "logits/chosen": -2.7999091148376465,
      "logits/rejected": -2.2738521099090576,
      "logps/chosen": -55.772926330566406,
      "logps/rejected": -162.87335205078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.508750855922699,
      "rewards/margins": 11.55402946472168,
      "rewards/rejected": -11.045278549194336,
      "step": 7391
    },
    {
      "epoch": 2.9568,
      "grad_norm": 0.0047169639728963375,
      "learning_rate": 1.4533333333333333e-08,
      "logits/chosen": -2.511423110961914,
      "logits/rejected": -2.3052353858947754,
      "logps/chosen": -90.71792602539062,
      "logps/rejected": -178.531494140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2667174339294434,
      "rewards/margins": 11.943795204162598,
      "rewards/rejected": -10.677078247070312,
      "step": 7392
    },
    {
      "epoch": 2.9572000000000003,
      "grad_norm": 0.04754166677594185,
      "learning_rate": 1.4399999999999998e-08,
      "logits/chosen": -2.466672420501709,
      "logits/rejected": -2.387535810470581,
      "logps/chosen": -109.09817504882812,
      "logps/rejected": -141.48971557617188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.29007184505462646,
      "rewards/margins": 8.30370807647705,
      "rewards/rejected": -8.593779563903809,
      "step": 7393
    },
    {
      "epoch": 2.9576000000000002,
      "grad_norm": 0.0297816414386034,
      "learning_rate": 1.4266666666666667e-08,
      "logits/chosen": -2.5864205360412598,
      "logits/rejected": -1.9732694625854492,
      "logps/chosen": -61.82537078857422,
      "logps/rejected": -138.94216918945312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.848727822303772,
      "rewards/margins": 9.26883316040039,
      "rewards/rejected": -8.420105934143066,
      "step": 7394
    },
    {
      "epoch": 2.958,
      "grad_norm": 0.21376781165599823,
      "learning_rate": 1.4133333333333333e-08,
      "logits/chosen": -2.517256736755371,
      "logits/rejected": -2.45292329788208,
      "logps/chosen": -78.28578186035156,
      "logps/rejected": -141.67288208007812,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0925976037979126,
      "rewards/margins": 10.023527145385742,
      "rewards/rejected": -8.930929183959961,
      "step": 7395
    },
    {
      "epoch": 2.9584,
      "grad_norm": 0.010283061303198338,
      "learning_rate": 1.4e-08,
      "logits/chosen": -2.6602439880371094,
      "logits/rejected": -2.380533218383789,
      "logps/chosen": -79.34710693359375,
      "logps/rejected": -156.6714324951172,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3872860074043274,
      "rewards/margins": 11.786824226379395,
      "rewards/rejected": -11.399538040161133,
      "step": 7396
    },
    {
      "epoch": 2.9588,
      "grad_norm": 0.04835579916834831,
      "learning_rate": 1.3866666666666665e-08,
      "logits/chosen": -2.402859687805176,
      "logits/rejected": -1.9749703407287598,
      "logps/chosen": -148.06658935546875,
      "logps/rejected": -148.19615173339844,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.404279351234436,
      "rewards/margins": 9.586670875549316,
      "rewards/rejected": -8.182391166687012,
      "step": 7397
    },
    {
      "epoch": 2.9592,
      "grad_norm": 0.0792630985379219,
      "learning_rate": 1.3733333333333332e-08,
      "logits/chosen": -2.5679874420166016,
      "logits/rejected": -1.992260217666626,
      "logps/chosen": -112.09733581542969,
      "logps/rejected": -179.71749877929688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7994346618652344,
      "rewards/margins": 11.052249908447266,
      "rewards/rejected": -11.8516845703125,
      "step": 7398
    },
    {
      "epoch": 2.9596,
      "grad_norm": 0.0012108433293178678,
      "learning_rate": 1.36e-08,
      "logits/chosen": -2.440176486968994,
      "logits/rejected": -1.7814326286315918,
      "logps/chosen": -116.2950439453125,
      "logps/rejected": -218.96104431152344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8111461400985718,
      "rewards/margins": 13.4136962890625,
      "rewards/rejected": -14.224842071533203,
      "step": 7399
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.1739465743303299,
      "learning_rate": 1.3466666666666666e-08,
      "logits/chosen": -2.6666858196258545,
      "logits/rejected": -2.492591619491577,
      "logps/chosen": -53.308204650878906,
      "logps/rejected": -128.84381103515625,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.21820354461669922,
      "rewards/margins": 8.924789428710938,
      "rewards/rejected": -9.142992973327637,
      "step": 7400
    },
    {
      "epoch": 2.9604,
      "grad_norm": 0.0028651596512645483,
      "learning_rate": 1.3333333333333334e-08,
      "logits/chosen": -2.4792628288269043,
      "logits/rejected": -1.8722116947174072,
      "logps/chosen": -175.9563751220703,
      "logps/rejected": -200.90826416015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.41616517305374146,
      "rewards/margins": 12.539422988891602,
      "rewards/rejected": -12.955587387084961,
      "step": 7401
    },
    {
      "epoch": 2.9608,
      "grad_norm": 0.7096849083900452,
      "learning_rate": 1.3199999999999999e-08,
      "logits/chosen": -2.73167085647583,
      "logits/rejected": -2.4561429023742676,
      "logps/chosen": -75.81287384033203,
      "logps/rejected": -144.11888122558594,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.25989437103271484,
      "rewards/margins": 8.820028305053711,
      "rewards/rejected": -9.079922676086426,
      "step": 7402
    },
    {
      "epoch": 2.9612,
      "grad_norm": 0.06895267218351364,
      "learning_rate": 1.3066666666666666e-08,
      "logits/chosen": -2.4055094718933105,
      "logits/rejected": -2.1736080646514893,
      "logps/chosen": -90.71380615234375,
      "logps/rejected": -189.07479858398438,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.775140404701233,
      "rewards/margins": 10.97295093536377,
      "rewards/rejected": -9.197811126708984,
      "step": 7403
    },
    {
      "epoch": 2.9616,
      "grad_norm": 0.029652554541826248,
      "learning_rate": 1.2933333333333333e-08,
      "logits/chosen": -2.668210506439209,
      "logits/rejected": -1.9213826656341553,
      "logps/chosen": -65.1418228149414,
      "logps/rejected": -154.39059448242188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0243240594863892,
      "rewards/margins": 9.920572280883789,
      "rewards/rejected": -8.896248817443848,
      "step": 7404
    },
    {
      "epoch": 2.9619999999999997,
      "grad_norm": 0.02060207910835743,
      "learning_rate": 1.28e-08,
      "logits/chosen": -2.384229898452759,
      "logits/rejected": -2.0044851303100586,
      "logps/chosen": -126.77104187011719,
      "logps/rejected": -198.3284149169922,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.5968494415283203,
      "rewards/margins": 10.762964248657227,
      "rewards/rejected": -13.359813690185547,
      "step": 7405
    },
    {
      "epoch": 2.9624,
      "grad_norm": 0.029545428231358528,
      "learning_rate": 1.2666666666666666e-08,
      "logits/chosen": -2.499098062515259,
      "logits/rejected": -1.8134009838104248,
      "logps/chosen": -92.662109375,
      "logps/rejected": -164.49725341796875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9307682514190674,
      "rewards/margins": 9.64262866973877,
      "rewards/rejected": -10.573396682739258,
      "step": 7406
    },
    {
      "epoch": 2.9628,
      "grad_norm": 0.13140782713890076,
      "learning_rate": 1.2533333333333333e-08,
      "logits/chosen": -2.411067485809326,
      "logits/rejected": -1.8012758493423462,
      "logps/chosen": -102.93864440917969,
      "logps/rejected": -138.79519653320312,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9526439905166626,
      "rewards/margins": 10.32791519165039,
      "rewards/rejected": -8.37527084350586,
      "step": 7407
    },
    {
      "epoch": 2.9632,
      "grad_norm": 5.2453007810981944e-05,
      "learning_rate": 1.2399999999999999e-08,
      "logits/chosen": -2.7767674922943115,
      "logits/rejected": -2.01938533782959,
      "logps/chosen": -55.64826202392578,
      "logps/rejected": -223.93519592285156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09818610548973083,
      "rewards/margins": 16.035877227783203,
      "rewards/rejected": -15.937690734863281,
      "step": 7408
    },
    {
      "epoch": 2.9636,
      "grad_norm": 0.012124846689403057,
      "learning_rate": 1.2266666666666666e-08,
      "logits/chosen": -2.6668930053710938,
      "logits/rejected": -1.778223991394043,
      "logps/chosen": -71.22396087646484,
      "logps/rejected": -188.95474243164062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14278584718704224,
      "rewards/margins": 12.61253833770752,
      "rewards/rejected": -12.469752311706543,
      "step": 7409
    },
    {
      "epoch": 2.964,
      "grad_norm": 0.2385449856519699,
      "learning_rate": 1.2133333333333333e-08,
      "logits/chosen": -2.5049219131469727,
      "logits/rejected": -2.2036571502685547,
      "logps/chosen": -122.28907775878906,
      "logps/rejected": -127.6126480102539,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33231085538864136,
      "rewards/margins": 8.1979398727417,
      "rewards/rejected": -7.865629196166992,
      "step": 7410
    },
    {
      "epoch": 2.9644,
      "grad_norm": 0.15631380677223206,
      "learning_rate": 1.2e-08,
      "logits/chosen": -2.1479604244232178,
      "logits/rejected": -1.7197880744934082,
      "logps/chosen": -198.59458923339844,
      "logps/rejected": -207.97158813476562,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.1987969875335693,
      "rewards/margins": 8.639793395996094,
      "rewards/rejected": -11.838590621948242,
      "step": 7411
    },
    {
      "epoch": 2.9648,
      "grad_norm": 0.00020219438010826707,
      "learning_rate": 1.1866666666666665e-08,
      "logits/chosen": -2.3698644638061523,
      "logits/rejected": -1.3109700679779053,
      "logps/chosen": -107.91949462890625,
      "logps/rejected": -199.72500610351562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6282591819763184,
      "rewards/margins": 14.571952819824219,
      "rewards/rejected": -12.943693161010742,
      "step": 7412
    },
    {
      "epoch": 2.9652,
      "grad_norm": 0.051276080310344696,
      "learning_rate": 1.1733333333333333e-08,
      "logits/chosen": -2.661125421524048,
      "logits/rejected": -2.314633846282959,
      "logps/chosen": -77.68711853027344,
      "logps/rejected": -167.62831115722656,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2514005899429321,
      "rewards/margins": 13.756460189819336,
      "rewards/rejected": -12.505060195922852,
      "step": 7413
    },
    {
      "epoch": 2.9656000000000002,
      "grad_norm": 10.883906364440918,
      "learning_rate": 1.1599999999999998e-08,
      "logits/chosen": -2.4749526977539062,
      "logits/rejected": -2.1902873516082764,
      "logps/chosen": -129.23410034179688,
      "logps/rejected": -206.1798095703125,
      "loss": 0.0352,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5317349433898926,
      "rewards/margins": 8.896638870239258,
      "rewards/rejected": -10.428373336791992,
      "step": 7414
    },
    {
      "epoch": 2.966,
      "grad_norm": 0.0014606559416279197,
      "learning_rate": 1.1466666666666667e-08,
      "logits/chosen": -2.1048057079315186,
      "logits/rejected": -1.2722047567367554,
      "logps/chosen": -71.76043701171875,
      "logps/rejected": -205.046630859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3883655071258545,
      "rewards/margins": 14.573282241821289,
      "rewards/rejected": -12.184915542602539,
      "step": 7415
    },
    {
      "epoch": 2.9664,
      "grad_norm": 0.0011024210834875703,
      "learning_rate": 1.1333333333333334e-08,
      "logits/chosen": -2.3879263401031494,
      "logits/rejected": -1.7507457733154297,
      "logps/chosen": -151.56434631347656,
      "logps/rejected": -217.23583984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4318406581878662,
      "rewards/margins": 12.461223602294922,
      "rewards/rejected": -13.893064498901367,
      "step": 7416
    },
    {
      "epoch": 2.9668,
      "grad_norm": 0.0123814158141613,
      "learning_rate": 1.12e-08,
      "logits/chosen": -2.571908473968506,
      "logits/rejected": -2.092175006866455,
      "logps/chosen": -92.31001281738281,
      "logps/rejected": -172.98959350585938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05882370471954346,
      "rewards/margins": 12.264766693115234,
      "rewards/rejected": -12.20594310760498,
      "step": 7417
    },
    {
      "epoch": 2.9672,
      "grad_norm": 0.09068546444177628,
      "learning_rate": 1.1066666666666667e-08,
      "logits/chosen": -2.6319961547851562,
      "logits/rejected": -2.2653064727783203,
      "logps/chosen": -94.74494934082031,
      "logps/rejected": -157.93453979492188,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3986576199531555,
      "rewards/margins": 10.430919647216797,
      "rewards/rejected": -10.032262802124023,
      "step": 7418
    },
    {
      "epoch": 2.9676,
      "grad_norm": 0.05504012852907181,
      "learning_rate": 1.0933333333333332e-08,
      "logits/chosen": -2.550029754638672,
      "logits/rejected": -2.0347771644592285,
      "logps/chosen": -97.13250732421875,
      "logps/rejected": -128.88832092285156,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.372267246246338,
      "rewards/margins": 8.777976989746094,
      "rewards/rejected": -7.405709743499756,
      "step": 7419
    },
    {
      "epoch": 2.968,
      "grad_norm": 0.008701875805854797,
      "learning_rate": 1.08e-08,
      "logits/chosen": -2.348365306854248,
      "logits/rejected": -1.9267394542694092,
      "logps/chosen": -162.27828979492188,
      "logps/rejected": -196.19357299804688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3116798400878906,
      "rewards/margins": 11.195898056030273,
      "rewards/rejected": -12.507577896118164,
      "step": 7420
    },
    {
      "epoch": 2.9684,
      "grad_norm": 0.04437541589140892,
      "learning_rate": 1.0666666666666666e-08,
      "logits/chosen": -2.7508139610290527,
      "logits/rejected": -2.447655200958252,
      "logps/chosen": -84.93688201904297,
      "logps/rejected": -154.3759307861328,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5775761604309082,
      "rewards/margins": 9.922658920288086,
      "rewards/rejected": -11.500235557556152,
      "step": 7421
    },
    {
      "epoch": 2.9688,
      "grad_norm": 0.02236092835664749,
      "learning_rate": 1.0533333333333333e-08,
      "logits/chosen": -2.7448043823242188,
      "logits/rejected": -2.3019113540649414,
      "logps/chosen": -96.3807373046875,
      "logps/rejected": -157.8354034423828,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9239966869354248,
      "rewards/margins": 9.229896545410156,
      "rewards/rejected": -11.15389347076416,
      "step": 7422
    },
    {
      "epoch": 2.9692,
      "grad_norm": 0.0020173746161162853,
      "learning_rate": 1.0399999999999999e-08,
      "logits/chosen": -2.9226951599121094,
      "logits/rejected": -2.3188693523406982,
      "logps/chosen": -58.10466766357422,
      "logps/rejected": -149.89529418945312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2451380491256714,
      "rewards/margins": 12.138198852539062,
      "rewards/rejected": -10.893060684204102,
      "step": 7423
    },
    {
      "epoch": 2.9696,
      "grad_norm": 0.0044844201765954494,
      "learning_rate": 1.0266666666666666e-08,
      "logits/chosen": -2.3743510246276855,
      "logits/rejected": -1.841797113418579,
      "logps/chosen": -92.90347290039062,
      "logps/rejected": -215.87232971191406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5096954107284546,
      "rewards/margins": 12.229294776916504,
      "rewards/rejected": -11.719598770141602,
      "step": 7424
    },
    {
      "epoch": 2.9699999999999998,
      "grad_norm": 0.00667143240571022,
      "learning_rate": 1.0133333333333333e-08,
      "logits/chosen": -2.194594621658325,
      "logits/rejected": -1.523688554763794,
      "logps/chosen": -110.80402374267578,
      "logps/rejected": -191.60824584960938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.43129581212997437,
      "rewards/margins": 14.301580429077148,
      "rewards/rejected": -13.870285034179688,
      "step": 7425
    },
    {
      "epoch": 2.9704,
      "grad_norm": 0.015585253946483135,
      "learning_rate": 1e-08,
      "logits/chosen": -2.5647470951080322,
      "logits/rejected": -1.971449613571167,
      "logps/chosen": -81.16133117675781,
      "logps/rejected": -174.1446533203125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6310362219810486,
      "rewards/margins": 11.62421989440918,
      "rewards/rejected": -10.993183135986328,
      "step": 7426
    },
    {
      "epoch": 2.9708,
      "grad_norm": 0.019632613286376,
      "learning_rate": 9.866666666666666e-09,
      "logits/chosen": -2.6946821212768555,
      "logits/rejected": -2.2975220680236816,
      "logps/chosen": -89.55460357666016,
      "logps/rejected": -207.76568603515625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9262903332710266,
      "rewards/margins": 10.425531387329102,
      "rewards/rejected": -9.49924087524414,
      "step": 7427
    },
    {
      "epoch": 2.9712,
      "grad_norm": 0.06518920511007309,
      "learning_rate": 9.733333333333333e-09,
      "logits/chosen": -2.9176955223083496,
      "logits/rejected": -2.6468734741210938,
      "logps/chosen": -116.27098083496094,
      "logps/rejected": -153.10797119140625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08240777254104614,
      "rewards/margins": 9.140421867370605,
      "rewards/rejected": -9.222829818725586,
      "step": 7428
    },
    {
      "epoch": 2.9716,
      "grad_norm": 0.017390597611665726,
      "learning_rate": 9.599999999999998e-09,
      "logits/chosen": -2.747100830078125,
      "logits/rejected": -2.1468536853790283,
      "logps/chosen": -114.0213394165039,
      "logps/rejected": -147.07205200195312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3167533874511719,
      "rewards/margins": 9.178523063659668,
      "rewards/rejected": -8.861769676208496,
      "step": 7429
    },
    {
      "epoch": 2.972,
      "grad_norm": 0.0007513646851293743,
      "learning_rate": 9.466666666666665e-09,
      "logits/chosen": -2.521454334259033,
      "logits/rejected": -1.8299046754837036,
      "logps/chosen": -94.53205871582031,
      "logps/rejected": -191.80482482910156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7836158871650696,
      "rewards/margins": 14.33578109741211,
      "rewards/rejected": -13.552165031433105,
      "step": 7430
    },
    {
      "epoch": 2.9724,
      "grad_norm": 0.0005572655936703086,
      "learning_rate": 9.333333333333334e-09,
      "logits/chosen": -2.4379191398620605,
      "logits/rejected": -1.7576512098312378,
      "logps/chosen": -224.71340942382812,
      "logps/rejected": -214.2560577392578,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.15321844816207886,
      "rewards/margins": 13.408855438232422,
      "rewards/rejected": -13.56207275390625,
      "step": 7431
    },
    {
      "epoch": 2.9728,
      "grad_norm": 0.0011853256728500128,
      "learning_rate": 9.2e-09,
      "logits/chosen": -2.6003315448760986,
      "logits/rejected": -1.7468147277832031,
      "logps/chosen": -76.34944915771484,
      "logps/rejected": -174.96096801757812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.36226487159729,
      "rewards/margins": 12.914190292358398,
      "rewards/rejected": -11.551925659179688,
      "step": 7432
    },
    {
      "epoch": 2.9732,
      "grad_norm": 0.003730823053047061,
      "learning_rate": 9.066666666666667e-09,
      "logits/chosen": -2.8234105110168457,
      "logits/rejected": -2.5022268295288086,
      "logps/chosen": -67.17588806152344,
      "logps/rejected": -169.6549072265625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.48561424016952515,
      "rewards/margins": 11.641645431518555,
      "rewards/rejected": -11.156031608581543,
      "step": 7433
    },
    {
      "epoch": 2.9736000000000002,
      "grad_norm": 0.18224860727787018,
      "learning_rate": 8.933333333333332e-09,
      "logits/chosen": -2.53244948387146,
      "logits/rejected": -2.0151491165161133,
      "logps/chosen": -99.53842163085938,
      "logps/rejected": -172.6337890625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2794055938720703,
      "rewards/margins": 13.470270156860352,
      "rewards/rejected": -11.190864562988281,
      "step": 7434
    },
    {
      "epoch": 2.974,
      "grad_norm": 0.06183125823736191,
      "learning_rate": 8.8e-09,
      "logits/chosen": -3.0098257064819336,
      "logits/rejected": -2.5715224742889404,
      "logps/chosen": -47.33885192871094,
      "logps/rejected": -144.8426513671875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9435226917266846,
      "rewards/margins": 10.098051071166992,
      "rewards/rejected": -9.15452766418457,
      "step": 7435
    },
    {
      "epoch": 2.9744,
      "grad_norm": 3.077912697335705e-05,
      "learning_rate": 8.666666666666667e-09,
      "logits/chosen": -2.994725227355957,
      "logits/rejected": -2.2880606651306152,
      "logps/chosen": -34.62498474121094,
      "logps/rejected": -243.74501037597656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4808768332004547,
      "rewards/margins": 17.029747009277344,
      "rewards/rejected": -16.548870086669922,
      "step": 7436
    },
    {
      "epoch": 2.9748,
      "grad_norm": 0.00693918764591217,
      "learning_rate": 8.533333333333334e-09,
      "logits/chosen": -2.6468677520751953,
      "logits/rejected": -2.0979056358337402,
      "logps/chosen": -87.39448547363281,
      "logps/rejected": -174.3827667236328,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2962898313999176,
      "rewards/margins": 11.628725051879883,
      "rewards/rejected": -11.925015449523926,
      "step": 7437
    },
    {
      "epoch": 2.9752,
      "grad_norm": 0.019423553720116615,
      "learning_rate": 8.399999999999999e-09,
      "logits/chosen": -2.7379398345947266,
      "logits/rejected": -2.5835328102111816,
      "logps/chosen": -85.21473693847656,
      "logps/rejected": -136.4861297607422,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16243287920951843,
      "rewards/margins": 9.272854804992676,
      "rewards/rejected": -9.110422134399414,
      "step": 7438
    },
    {
      "epoch": 2.9756,
      "grad_norm": 0.3779275715351105,
      "learning_rate": 8.266666666666666e-09,
      "logits/chosen": -2.4361371994018555,
      "logits/rejected": -2.0960161685943604,
      "logps/chosen": -181.56053161621094,
      "logps/rejected": -215.53134155273438,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1201233863830566,
      "rewards/margins": 10.320476531982422,
      "rewards/rejected": -11.44059944152832,
      "step": 7439
    },
    {
      "epoch": 2.976,
      "grad_norm": 1.0177081823349,
      "learning_rate": 8.133333333333332e-09,
      "logits/chosen": -2.406672477722168,
      "logits/rejected": -1.9732670783996582,
      "logps/chosen": -122.6380386352539,
      "logps/rejected": -147.80763244628906,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08795279264450073,
      "rewards/margins": 9.674869537353516,
      "rewards/rejected": -9.586915969848633,
      "step": 7440
    },
    {
      "epoch": 2.9764,
      "grad_norm": 0.025450823828577995,
      "learning_rate": 8e-09,
      "logits/chosen": -2.225080966949463,
      "logits/rejected": -1.9060595035552979,
      "logps/chosen": -200.35569763183594,
      "logps/rejected": -220.97402954101562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.2425737380981445,
      "rewards/margins": 14.119012832641602,
      "rewards/rejected": -16.36158561706543,
      "step": 7441
    },
    {
      "epoch": 2.9768,
      "grad_norm": 0.036667097359895706,
      "learning_rate": 7.866666666666666e-09,
      "logits/chosen": -2.5280895233154297,
      "logits/rejected": -2.5583107471466064,
      "logps/chosen": -160.4038848876953,
      "logps/rejected": -146.59788513183594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2279319763183594,
      "rewards/margins": 10.14793586730957,
      "rewards/rejected": -11.37586784362793,
      "step": 7442
    },
    {
      "epoch": 2.9772,
      "grad_norm": 0.0019480381160974503,
      "learning_rate": 7.733333333333333e-09,
      "logits/chosen": -2.6233644485473633,
      "logits/rejected": -2.047786235809326,
      "logps/chosen": -90.2439956665039,
      "logps/rejected": -219.9003143310547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1107208728790283,
      "rewards/margins": 14.033681869506836,
      "rewards/rejected": -12.92296028137207,
      "step": 7443
    },
    {
      "epoch": 2.9776,
      "grad_norm": 0.3127712309360504,
      "learning_rate": 7.6e-09,
      "logits/chosen": -2.798708915710449,
      "logits/rejected": -2.317065954208374,
      "logps/chosen": -77.8565673828125,
      "logps/rejected": -172.39295959472656,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27139320969581604,
      "rewards/margins": 8.898004531860352,
      "rewards/rejected": -8.62661075592041,
      "step": 7444
    },
    {
      "epoch": 2.9779999999999998,
      "grad_norm": 0.030678240582346916,
      "learning_rate": 7.466666666666666e-09,
      "logits/chosen": -2.402207136154175,
      "logits/rejected": -1.71372652053833,
      "logps/chosen": -187.99594116210938,
      "logps/rejected": -186.58364868164062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.476454973220825,
      "rewards/margins": 10.171207427978516,
      "rewards/rejected": -12.647662162780762,
      "step": 7445
    },
    {
      "epoch": 2.9784,
      "grad_norm": 0.030052023008465767,
      "learning_rate": 7.333333333333333e-09,
      "logits/chosen": -2.963700771331787,
      "logits/rejected": -2.68363094329834,
      "logps/chosen": -65.9827651977539,
      "logps/rejected": -103.2801513671875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.529464602470398,
      "rewards/margins": 8.767600059509277,
      "rewards/rejected": -7.238135814666748,
      "step": 7446
    },
    {
      "epoch": 2.9788,
      "grad_norm": 3.565164566040039,
      "learning_rate": 7.199999999999999e-09,
      "logits/chosen": -2.3747470378875732,
      "logits/rejected": -1.9201198816299438,
      "logps/chosen": -148.4182891845703,
      "logps/rejected": -155.79705810546875,
      "loss": 0.0078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.8556694984436035,
      "rewards/margins": 6.472036361694336,
      "rewards/rejected": -9.327705383300781,
      "step": 7447
    },
    {
      "epoch": 2.9792,
      "grad_norm": 0.0008318240870721638,
      "learning_rate": 7.066666666666666e-09,
      "logits/chosen": -2.372340202331543,
      "logits/rejected": -1.8822414875030518,
      "logps/chosen": -119.36463165283203,
      "logps/rejected": -200.65899658203125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06812936067581177,
      "rewards/margins": 12.995137214660645,
      "rewards/rejected": -12.927007675170898,
      "step": 7448
    },
    {
      "epoch": 2.9796,
      "grad_norm": 3.133589052595198e-05,
      "learning_rate": 6.9333333333333326e-09,
      "logits/chosen": -2.6853504180908203,
      "logits/rejected": -2.1433749198913574,
      "logps/chosen": -81.46282196044922,
      "logps/rejected": -237.4749755859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8660789132118225,
      "rewards/margins": 16.367490768432617,
      "rewards/rejected": -17.233570098876953,
      "step": 7449
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.052224572747945786,
      "learning_rate": 6.8e-09,
      "logits/chosen": -2.768935203552246,
      "logits/rejected": -1.9972364902496338,
      "logps/chosen": -84.26229858398438,
      "logps/rejected": -172.69273376464844,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0569911003112793,
      "rewards/margins": 10.917905807495117,
      "rewards/rejected": -8.86091423034668,
      "step": 7450
    },
    {
      "epoch": 2.9804,
      "grad_norm": 0.005085432436317205,
      "learning_rate": 6.666666666666667e-09,
      "logits/chosen": -2.4580492973327637,
      "logits/rejected": -1.9325189590454102,
      "logps/chosen": -88.36620330810547,
      "logps/rejected": -180.21116638183594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2249175310134888,
      "rewards/margins": 11.987071990966797,
      "rewards/rejected": -10.762153625488281,
      "step": 7451
    },
    {
      "epoch": 2.9808,
      "grad_norm": 0.011662634089589119,
      "learning_rate": 6.533333333333333e-09,
      "logits/chosen": -2.7039084434509277,
      "logits/rejected": -2.339211940765381,
      "logps/chosen": -48.200592041015625,
      "logps/rejected": -164.5642852783203,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.11715704202651978,
      "rewards/margins": 10.811039924621582,
      "rewards/rejected": -10.928196907043457,
      "step": 7452
    },
    {
      "epoch": 2.9812,
      "grad_norm": 0.005494429264217615,
      "learning_rate": 6.4e-09,
      "logits/chosen": -2.4928836822509766,
      "logits/rejected": -2.0964245796203613,
      "logps/chosen": -127.64127349853516,
      "logps/rejected": -209.12147521972656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5643921494483948,
      "rewards/margins": 12.752689361572266,
      "rewards/rejected": -13.317081451416016,
      "step": 7453
    },
    {
      "epoch": 2.9816000000000003,
      "grad_norm": 0.03691300004720688,
      "learning_rate": 6.2666666666666665e-09,
      "logits/chosen": -2.674384117126465,
      "logits/rejected": -2.179903984069824,
      "logps/chosen": -144.22117614746094,
      "logps/rejected": -153.5992431640625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2286561131477356,
      "rewards/margins": 9.69611644744873,
      "rewards/rejected": -9.467460632324219,
      "step": 7454
    },
    {
      "epoch": 2.982,
      "grad_norm": 0.027283625677227974,
      "learning_rate": 6.133333333333333e-09,
      "logits/chosen": -2.690551519393921,
      "logits/rejected": -2.1985721588134766,
      "logps/chosen": -74.72743225097656,
      "logps/rejected": -123.38224792480469,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6713117361068726,
      "rewards/margins": 8.672717094421387,
      "rewards/rejected": -8.001405715942383,
      "step": 7455
    },
    {
      "epoch": 2.9824,
      "grad_norm": 0.007963882759213448,
      "learning_rate": 6e-09,
      "logits/chosen": -2.2353830337524414,
      "logits/rejected": -1.3081997632980347,
      "logps/chosen": -103.3475112915039,
      "logps/rejected": -166.45901489257812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3739204406738281,
      "rewards/margins": 10.430868148803711,
      "rewards/rejected": -10.056947708129883,
      "step": 7456
    },
    {
      "epoch": 2.9828,
      "grad_norm": 0.3395879864692688,
      "learning_rate": 5.866666666666666e-09,
      "logits/chosen": -2.503230333328247,
      "logits/rejected": -1.8357267379760742,
      "logps/chosen": -172.6629180908203,
      "logps/rejected": -212.17681884765625,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -4.33519172668457,
      "rewards/margins": 9.700508117675781,
      "rewards/rejected": -14.035699844360352,
      "step": 7457
    },
    {
      "epoch": 2.9832,
      "grad_norm": 0.004922930616885424,
      "learning_rate": 5.733333333333333e-09,
      "logits/chosen": -2.412287712097168,
      "logits/rejected": -2.2516181468963623,
      "logps/chosen": -71.41378784179688,
      "logps/rejected": -153.141845703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7657489776611328,
      "rewards/margins": 11.61020278930664,
      "rewards/rejected": -9.844453811645508,
      "step": 7458
    },
    {
      "epoch": 2.9836,
      "grad_norm": 0.0004246866737958044,
      "learning_rate": 5.6e-09,
      "logits/chosen": -2.2378008365631104,
      "logits/rejected": -1.6891238689422607,
      "logps/chosen": -114.76878356933594,
      "logps/rejected": -210.65225219726562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9538182020187378,
      "rewards/margins": 13.808565139770508,
      "rewards/rejected": -12.85474681854248,
      "step": 7459
    },
    {
      "epoch": 2.984,
      "grad_norm": 0.0035690939985215664,
      "learning_rate": 5.466666666666666e-09,
      "logits/chosen": -2.8964405059814453,
      "logits/rejected": -2.4454708099365234,
      "logps/chosen": -43.08976745605469,
      "logps/rejected": -138.41873168945312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.253607988357544,
      "rewards/margins": 11.274890899658203,
      "rewards/rejected": -10.021283149719238,
      "step": 7460
    },
    {
      "epoch": 2.9844,
      "grad_norm": 0.0026725667994469404,
      "learning_rate": 5.333333333333333e-09,
      "logits/chosen": -2.138514995574951,
      "logits/rejected": -1.2458648681640625,
      "logps/chosen": -271.5586242675781,
      "logps/rejected": -196.58563232421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7559341192245483,
      "rewards/margins": 11.742420196533203,
      "rewards/rejected": -12.498353958129883,
      "step": 7461
    },
    {
      "epoch": 2.9848,
      "grad_norm": 0.011374837718904018,
      "learning_rate": 5.1999999999999994e-09,
      "logits/chosen": -2.8131160736083984,
      "logits/rejected": -2.3647212982177734,
      "logps/chosen": -86.31055450439453,
      "logps/rejected": -133.8353729248047,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21953316032886505,
      "rewards/margins": 10.012053489685059,
      "rewards/rejected": -9.792520523071289,
      "step": 7462
    },
    {
      "epoch": 2.9852,
      "grad_norm": 0.021845052018761635,
      "learning_rate": 5.0666666666666665e-09,
      "logits/chosen": -2.7338547706604004,
      "logits/rejected": -2.3309664726257324,
      "logps/chosen": -68.10484313964844,
      "logps/rejected": -231.65626525878906,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8920006155967712,
      "rewards/margins": 14.271286010742188,
      "rewards/rejected": -13.37928581237793,
      "step": 7463
    },
    {
      "epoch": 2.9856,
      "grad_norm": 0.04151031747460365,
      "learning_rate": 4.933333333333333e-09,
      "logits/chosen": -2.7853524684906006,
      "logits/rejected": -2.4009056091308594,
      "logps/chosen": -63.873329162597656,
      "logps/rejected": -171.40484619140625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.839443027973175,
      "rewards/margins": 11.439512252807617,
      "rewards/rejected": -12.278955459594727,
      "step": 7464
    },
    {
      "epoch": 2.9859999999999998,
      "grad_norm": 0.014848997816443443,
      "learning_rate": 4.799999999999999e-09,
      "logits/chosen": -2.7798266410827637,
      "logits/rejected": -2.1120808124542236,
      "logps/chosen": -103.8342056274414,
      "logps/rejected": -152.73736572265625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06816673278808594,
      "rewards/margins": 9.751249313354492,
      "rewards/rejected": -9.683082580566406,
      "step": 7465
    },
    {
      "epoch": 2.9864,
      "grad_norm": 0.34801819920539856,
      "learning_rate": 4.666666666666667e-09,
      "logits/chosen": -2.45307993888855,
      "logits/rejected": -2.049644708633423,
      "logps/chosen": -94.28730773925781,
      "logps/rejected": -138.7569122314453,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2678229808807373,
      "rewards/margins": 8.762181282043457,
      "rewards/rejected": -8.49435806274414,
      "step": 7466
    },
    {
      "epoch": 2.9868,
      "grad_norm": 0.577695906162262,
      "learning_rate": 4.533333333333333e-09,
      "logits/chosen": -2.3707194328308105,
      "logits/rejected": -1.824094533920288,
      "logps/chosen": -60.12220764160156,
      "logps/rejected": -146.72457885742188,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.21940955519676208,
      "rewards/margins": 7.131224632263184,
      "rewards/rejected": -7.350634574890137,
      "step": 7467
    },
    {
      "epoch": 2.9872,
      "grad_norm": 0.00885826162993908,
      "learning_rate": 4.4e-09,
      "logits/chosen": -2.6820554733276367,
      "logits/rejected": -2.254939079284668,
      "logps/chosen": -77.75790405273438,
      "logps/rejected": -134.38648986816406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1625285148620605,
      "rewards/margins": 11.894196510314941,
      "rewards/rejected": -9.731668472290039,
      "step": 7468
    },
    {
      "epoch": 2.9876,
      "grad_norm": 0.06111213564872742,
      "learning_rate": 4.266666666666667e-09,
      "logits/chosen": -2.5399956703186035,
      "logits/rejected": -2.1560654640197754,
      "logps/chosen": -118.79698181152344,
      "logps/rejected": -230.95750427246094,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4067089259624481,
      "rewards/margins": 14.298853874206543,
      "rewards/rejected": -14.705562591552734,
      "step": 7469
    },
    {
      "epoch": 2.988,
      "grad_norm": 0.20058242976665497,
      "learning_rate": 4.133333333333333e-09,
      "logits/chosen": -2.4410672187805176,
      "logits/rejected": -1.5782604217529297,
      "logps/chosen": -60.06753158569336,
      "logps/rejected": -175.7061767578125,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6968605518341064,
      "rewards/margins": 11.876269340515137,
      "rewards/rejected": -11.179408073425293,
      "step": 7470
    },
    {
      "epoch": 2.9884,
      "grad_norm": 0.20198886096477509,
      "learning_rate": 4e-09,
      "logits/chosen": -2.3863537311553955,
      "logits/rejected": -2.1079249382019043,
      "logps/chosen": -112.94969177246094,
      "logps/rejected": -179.15133666992188,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.005181103944778442,
      "rewards/margins": 10.184075355529785,
      "rewards/rejected": -10.18925666809082,
      "step": 7471
    },
    {
      "epoch": 2.9888,
      "grad_norm": 2.9578490284620784e-05,
      "learning_rate": 3.8666666666666665e-09,
      "logits/chosen": -2.684804677963257,
      "logits/rejected": -2.0695643424987793,
      "logps/chosen": -139.11988830566406,
      "logps/rejected": -244.57803344726562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.345462828874588,
      "rewards/margins": 16.63845443725586,
      "rewards/rejected": -16.983919143676758,
      "step": 7472
    },
    {
      "epoch": 2.9892,
      "grad_norm": 0.0011132158106192946,
      "learning_rate": 3.733333333333333e-09,
      "logits/chosen": -2.3727400302886963,
      "logits/rejected": -1.7863470315933228,
      "logps/chosen": -151.60218811035156,
      "logps/rejected": -206.43112182617188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.89242023229599,
      "rewards/margins": 13.539953231811523,
      "rewards/rejected": -14.432373046875,
      "step": 7473
    },
    {
      "epoch": 2.9896000000000003,
      "grad_norm": 0.18340067565441132,
      "learning_rate": 3.5999999999999996e-09,
      "logits/chosen": -2.7818734645843506,
      "logits/rejected": -2.445478916168213,
      "logps/chosen": -68.06343078613281,
      "logps/rejected": -142.6056671142578,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.45903417468070984,
      "rewards/margins": 9.129213333129883,
      "rewards/rejected": -9.588247299194336,
      "step": 7474
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.027774062007665634,
      "learning_rate": 3.4666666666666663e-09,
      "logits/chosen": -2.8866820335388184,
      "logits/rejected": -2.3104565143585205,
      "logps/chosen": -90.70072937011719,
      "logps/rejected": -192.45852661132812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.42113837599754333,
      "rewards/margins": 12.650232315063477,
      "rewards/rejected": -13.071371078491211,
      "step": 7475
    },
    {
      "epoch": 2.9904,
      "grad_norm": 0.03345422074198723,
      "learning_rate": 3.3333333333333334e-09,
      "logits/chosen": -2.849010467529297,
      "logits/rejected": -2.473888874053955,
      "logps/chosen": -42.93544006347656,
      "logps/rejected": -114.13113403320312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.970130205154419,
      "rewards/margins": 9.684886932373047,
      "rewards/rejected": -7.714756965637207,
      "step": 7476
    },
    {
      "epoch": 2.9908,
      "grad_norm": 0.0011309680994600058,
      "learning_rate": 3.2e-09,
      "logits/chosen": -2.3823962211608887,
      "logits/rejected": -1.7611638307571411,
      "logps/chosen": -103.05439758300781,
      "logps/rejected": -208.95803833007812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7067338228225708,
      "rewards/margins": 13.80428695678711,
      "rewards/rejected": -12.097553253173828,
      "step": 7477
    },
    {
      "epoch": 2.9912,
      "grad_norm": 0.03283790126442909,
      "learning_rate": 3.0666666666666664e-09,
      "logits/chosen": -2.743992328643799,
      "logits/rejected": -2.0550472736358643,
      "logps/chosen": -94.00846099853516,
      "logps/rejected": -167.45948791503906,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34561386704444885,
      "rewards/margins": 11.589786529541016,
      "rewards/rejected": -11.244172096252441,
      "step": 7478
    },
    {
      "epoch": 2.9916,
      "grad_norm": 6.457653999328613,
      "learning_rate": 2.933333333333333e-09,
      "logits/chosen": -2.85313081741333,
      "logits/rejected": -2.6354923248291016,
      "logps/chosen": -128.20201110839844,
      "logps/rejected": -117.03556823730469,
      "loss": 0.02,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9179393649101257,
      "rewards/margins": 6.902541637420654,
      "rewards/rejected": -7.820480823516846,
      "step": 7479
    },
    {
      "epoch": 2.992,
      "grad_norm": 0.398708701133728,
      "learning_rate": 2.8e-09,
      "logits/chosen": -2.7111105918884277,
      "logits/rejected": -2.7120141983032227,
      "logps/chosen": -68.24947357177734,
      "logps/rejected": -96.79057312011719,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8624727725982666,
      "rewards/margins": 6.6301445960998535,
      "rewards/rejected": -5.767671585083008,
      "step": 7480
    },
    {
      "epoch": 2.9924,
      "grad_norm": 3.653693784144707e-05,
      "learning_rate": 2.6666666666666666e-09,
      "logits/chosen": -2.26564359664917,
      "logits/rejected": -1.4779342412948608,
      "logps/chosen": -86.5139389038086,
      "logps/rejected": -208.83505249023438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2000447511672974,
      "rewards/margins": 16.453954696655273,
      "rewards/rejected": -15.253910064697266,
      "step": 7481
    },
    {
      "epoch": 2.9928,
      "grad_norm": 0.029384221881628036,
      "learning_rate": 2.5333333333333333e-09,
      "logits/chosen": -2.0937294960021973,
      "logits/rejected": -1.7538267374038696,
      "logps/chosen": -108.59333038330078,
      "logps/rejected": -147.51535034179688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4274555444717407,
      "rewards/margins": 9.978588104248047,
      "rewards/rejected": -8.551132202148438,
      "step": 7482
    },
    {
      "epoch": 2.9932,
      "grad_norm": 0.026132293045520782,
      "learning_rate": 2.3999999999999996e-09,
      "logits/chosen": -2.6727113723754883,
      "logits/rejected": -2.335919141769409,
      "logps/chosen": -74.2533950805664,
      "logps/rejected": -133.60797119140625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9691489934921265,
      "rewards/margins": 9.128703117370605,
      "rewards/rejected": -8.159554481506348,
      "step": 7483
    },
    {
      "epoch": 2.9936,
      "grad_norm": 0.04434390366077423,
      "learning_rate": 2.2666666666666667e-09,
      "logits/chosen": -2.4999141693115234,
      "logits/rejected": -2.06805419921875,
      "logps/chosen": -103.59698486328125,
      "logps/rejected": -127.01679992675781,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.743716835975647,
      "rewards/margins": 8.588170051574707,
      "rewards/rejected": -7.84445333480835,
      "step": 7484
    },
    {
      "epoch": 2.9939999999999998,
      "grad_norm": 9.75558505160734e-05,
      "learning_rate": 2.1333333333333334e-09,
      "logits/chosen": -2.2070112228393555,
      "logits/rejected": -1.5117578506469727,
      "logps/chosen": -138.3485107421875,
      "logps/rejected": -252.56875610351562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.464664936065674,
      "rewards/margins": 16.987327575683594,
      "rewards/rejected": -14.522663116455078,
      "step": 7485
    },
    {
      "epoch": 2.9943999999999997,
      "grad_norm": 6.259951078391168e-06,
      "learning_rate": 2e-09,
      "logits/chosen": -2.4695472717285156,
      "logits/rejected": -1.5648994445800781,
      "logps/chosen": -102.35939025878906,
      "logps/rejected": -239.50433349609375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.529473900794983,
      "rewards/margins": 17.96061897277832,
      "rewards/rejected": -16.43114471435547,
      "step": 7486
    },
    {
      "epoch": 2.9948,
      "grad_norm": 0.008194178342819214,
      "learning_rate": 1.8666666666666664e-09,
      "logits/chosen": -2.7356221675872803,
      "logits/rejected": -2.304276466369629,
      "logps/chosen": -87.53156280517578,
      "logps/rejected": -199.64312744140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3309365510940552,
      "rewards/margins": 15.458962440490723,
      "rewards/rejected": -14.128026008605957,
      "step": 7487
    },
    {
      "epoch": 2.9952,
      "grad_norm": 4.44164514541626,
      "learning_rate": 1.7333333333333331e-09,
      "logits/chosen": -2.4164798259735107,
      "logits/rejected": -1.9758837223052979,
      "logps/chosen": -205.31683349609375,
      "logps/rejected": -194.00848388671875,
      "loss": 0.0257,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -7.357586860656738,
      "rewards/margins": 3.7039058208465576,
      "rewards/rejected": -11.061492919921875,
      "step": 7488
    },
    {
      "epoch": 2.9956,
      "grad_norm": 8.142097794916481e-05,
      "learning_rate": 1.6e-09,
      "logits/chosen": -2.470324993133545,
      "logits/rejected": -2.089082717895508,
      "logps/chosen": -173.0518035888672,
      "logps/rejected": -253.41204833984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.1800217628479004,
      "rewards/margins": 15.191770553588867,
      "rewards/rejected": -18.37179183959961,
      "step": 7489
    },
    {
      "epoch": 2.996,
      "grad_norm": 0.006461766082793474,
      "learning_rate": 1.4666666666666666e-09,
      "logits/chosen": -2.5347671508789062,
      "logits/rejected": -1.5287954807281494,
      "logps/chosen": -134.3248748779297,
      "logps/rejected": -188.38644409179688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1922764778137207,
      "rewards/margins": 11.928482055664062,
      "rewards/rejected": -10.7362060546875,
      "step": 7490
    },
    {
      "epoch": 2.9964,
      "grad_norm": 0.019637851044535637,
      "learning_rate": 1.3333333333333333e-09,
      "logits/chosen": -2.448147773742676,
      "logits/rejected": -2.118837594985962,
      "logps/chosen": -88.5234603881836,
      "logps/rejected": -192.70712280273438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.50946843624115,
      "rewards/margins": 15.347917556762695,
      "rewards/rejected": -13.838448524475098,
      "step": 7491
    },
    {
      "epoch": 2.9968,
      "grad_norm": 0.00035427947295829654,
      "learning_rate": 1.1999999999999998e-09,
      "logits/chosen": -2.6399011611938477,
      "logits/rejected": -2.242809772491455,
      "logps/chosen": -97.81298828125,
      "logps/rejected": -240.2851104736328,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.013804437592625618,
      "rewards/margins": 14.991565704345703,
      "rewards/rejected": -15.005369186401367,
      "step": 7492
    },
    {
      "epoch": 2.9972,
      "grad_norm": 0.01654098555445671,
      "learning_rate": 1.0666666666666667e-09,
      "logits/chosen": -2.3823513984680176,
      "logits/rejected": -1.9287309646606445,
      "logps/chosen": -189.0617218017578,
      "logps/rejected": -202.21240234375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0651569366455078,
      "rewards/margins": 11.189411163330078,
      "rewards/rejected": -12.254568099975586,
      "step": 7493
    },
    {
      "epoch": 2.9976000000000003,
      "grad_norm": 6.0018504882464185e-05,
      "learning_rate": 9.333333333333332e-10,
      "logits/chosen": -2.5344529151916504,
      "logits/rejected": -2.0170538425445557,
      "logps/chosen": -76.93170928955078,
      "logps/rejected": -286.8476867675781,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8063255548477173,
      "rewards/margins": 16.38361930847168,
      "rewards/rejected": -14.57729434967041,
      "step": 7494
    },
    {
      "epoch": 2.998,
      "grad_norm": 0.0015852604992687702,
      "learning_rate": 8e-10,
      "logits/chosen": -2.4382641315460205,
      "logits/rejected": -2.0295281410217285,
      "logps/chosen": -134.87779235839844,
      "logps/rejected": -157.52352905273438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0163291692733765,
      "rewards/margins": 11.985882759094238,
      "rewards/rejected": -10.969552993774414,
      "step": 7495
    },
    {
      "epoch": 2.9984,
      "grad_norm": 0.6593692898750305,
      "learning_rate": 6.666666666666666e-10,
      "logits/chosen": -2.9891812801361084,
      "logits/rejected": -2.9749951362609863,
      "logps/chosen": -69.63478088378906,
      "logps/rejected": -89.53166198730469,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.002585768699646,
      "rewards/margins": 6.387144088745117,
      "rewards/rejected": -5.38455867767334,
      "step": 7496
    },
    {
      "epoch": 2.9988,
      "grad_norm": 0.03646627813577652,
      "learning_rate": 5.333333333333334e-10,
      "logits/chosen": -2.7772438526153564,
      "logits/rejected": -2.27559232711792,
      "logps/chosen": -53.155921936035156,
      "logps/rejected": -135.78985595703125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5133382678031921,
      "rewards/margins": 9.431638717651367,
      "rewards/rejected": -8.91830062866211,
      "step": 7497
    },
    {
      "epoch": 2.9992,
      "grad_norm": 0.09296639263629913,
      "learning_rate": 4e-10,
      "logits/chosen": -2.5760703086853027,
      "logits/rejected": -2.549428939819336,
      "logps/chosen": -131.9853057861328,
      "logps/rejected": -147.29934692382812,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25191381573677063,
      "rewards/margins": 9.922189712524414,
      "rewards/rejected": -9.670276641845703,
      "step": 7498
    },
    {
      "epoch": 2.9996,
      "grad_norm": 0.3596087694168091,
      "learning_rate": 2.666666666666667e-10,
      "logits/chosen": -2.868441581726074,
      "logits/rejected": -3.0048394203186035,
      "logps/chosen": -47.92246627807617,
      "logps/rejected": -129.2381134033203,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3828299045562744,
      "rewards/margins": 7.489651679992676,
      "rewards/rejected": -8.872482299804688,
      "step": 7499
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.030829789116978645,
      "learning_rate": 1.3333333333333334e-10,
      "logits/chosen": -2.4808504581451416,
      "logits/rejected": -1.9404969215393066,
      "logps/chosen": -97.42906951904297,
      "logps/rejected": -171.35696411132812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1894325315952301,
      "rewards/margins": 10.76634407043457,
      "rewards/rejected": -10.576911926269531,
      "step": 7500
    }
  ],
  "logging_steps": 1,
  "max_steps": 7500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
