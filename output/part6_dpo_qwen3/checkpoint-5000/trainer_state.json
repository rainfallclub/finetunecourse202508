{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0004,
      "grad_norm": 15.268645286560059,
      "learning_rate": 1e-06,
      "logits/chosen": -2.0962538719177246,
      "logits/rejected": -1.5989779233932495,
      "logps/chosen": -141.30502319335938,
      "logps/rejected": -97.38442993164062,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 1
    },
    {
      "epoch": 0.0008,
      "grad_norm": 18.559490203857422,
      "learning_rate": 9.998666666666665e-07,
      "logits/chosen": -1.7126741409301758,
      "logits/rejected": -1.8161518573760986,
      "logps/chosen": -139.18313598632812,
      "logps/rejected": -95.85646057128906,
      "loss": 0.6952,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.02568512037396431,
      "rewards/margins": -0.0036640167236328125,
      "rewards/rejected": -0.022021103650331497,
      "step": 2
    },
    {
      "epoch": 0.0012,
      "grad_norm": 20.533489227294922,
      "learning_rate": 9.997333333333333e-07,
      "logits/chosen": -2.177920341491699,
      "logits/rejected": -2.4348926544189453,
      "logps/chosen": -169.28517150878906,
      "logps/rejected": -124.09404754638672,
      "loss": 0.7149,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.002748871222138405,
      "rewards/margins": -0.04219131916761398,
      "rewards/rejected": 0.03944244235754013,
      "step": 3
    },
    {
      "epoch": 0.0016,
      "grad_norm": 15.507535934448242,
      "learning_rate": 9.996e-07,
      "logits/chosen": -1.7446495294570923,
      "logits/rejected": -1.632487177848816,
      "logps/chosen": -130.4578857421875,
      "logps/rejected": -86.64102172851562,
      "loss": 0.7189,
      "rewards/accuracies": 0.0,
      "rewards/chosen": -0.005595779046416283,
      "rewards/margins": -0.050760649144649506,
      "rewards/rejected": 0.04516487196087837,
      "step": 4
    },
    {
      "epoch": 0.002,
      "grad_norm": 15.394692420959473,
      "learning_rate": 9.994666666666665e-07,
      "logits/chosen": -2.273918867111206,
      "logits/rejected": -1.559133529663086,
      "logps/chosen": -124.44734191894531,
      "logps/rejected": -126.39563751220703,
      "loss": 0.6834,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.035858917981386185,
      "rewards/margins": 0.02031593583524227,
      "rewards/rejected": 0.015542984008789062,
      "step": 5
    },
    {
      "epoch": 0.0024,
      "grad_norm": 18.38969612121582,
      "learning_rate": 9.993333333333333e-07,
      "logits/chosen": -1.7581608295440674,
      "logits/rejected": -2.2266016006469727,
      "logps/chosen": -126.73479461669922,
      "logps/rejected": -96.23471069335938,
      "loss": 0.7004,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0033397674560546875,
      "rewards/margins": -0.012259293347597122,
      "rewards/rejected": 0.008919524028897285,
      "step": 6
    },
    {
      "epoch": 0.0028,
      "grad_norm": 17.38357162475586,
      "learning_rate": 9.992e-07,
      "logits/chosen": -1.8269122838974,
      "logits/rejected": -1.7972356081008911,
      "logps/chosen": -141.53372192382812,
      "logps/rejected": -126.15385437011719,
      "loss": 0.6665,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07202110439538956,
      "rewards/margins": 0.05435600504279137,
      "rewards/rejected": 0.01766509935259819,
      "step": 7
    },
    {
      "epoch": 0.0032,
      "grad_norm": 18.870851516723633,
      "learning_rate": 9.990666666666667e-07,
      "logits/chosen": -1.7665770053863525,
      "logits/rejected": -1.974238395690918,
      "logps/chosen": -133.5233154296875,
      "logps/rejected": -133.27151489257812,
      "loss": 0.6895,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0028987883124500513,
      "rewards/margins": 0.007365417201071978,
      "rewards/rejected": -0.00446662912145257,
      "step": 8
    },
    {
      "epoch": 0.0036,
      "grad_norm": 13.048956871032715,
      "learning_rate": 9.989333333333333e-07,
      "logits/chosen": -1.7168858051300049,
      "logits/rejected": -1.8025894165039062,
      "logps/chosen": -134.64039611816406,
      "logps/rejected": -104.56708526611328,
      "loss": 0.6712,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020360182970762253,
      "rewards/margins": 0.044315338134765625,
      "rewards/rejected": -0.023955155164003372,
      "step": 9
    },
    {
      "epoch": 0.004,
      "grad_norm": 13.940608024597168,
      "learning_rate": 9.988e-07,
      "logits/chosen": -1.7688770294189453,
      "logits/rejected": -1.8757812976837158,
      "logps/chosen": -116.80616760253906,
      "logps/rejected": -78.88996124267578,
      "loss": 0.6877,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.018634416162967682,
      "rewards/margins": 0.010954665951430798,
      "rewards/rejected": -0.029589081183075905,
      "step": 10
    },
    {
      "epoch": 0.0044,
      "grad_norm": 22.395299911499023,
      "learning_rate": 9.986666666666667e-07,
      "logits/chosen": -1.8239552974700928,
      "logits/rejected": -2.7285313606262207,
      "logps/chosen": -199.5662384033203,
      "logps/rejected": -157.8272705078125,
      "loss": 0.6664,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06701354682445526,
      "rewards/margins": 0.054311372339725494,
      "rewards/rejected": 0.012702180072665215,
      "step": 11
    },
    {
      "epoch": 0.0048,
      "grad_norm": 17.99517822265625,
      "learning_rate": 9.985333333333332e-07,
      "logits/chosen": -2.072694778442383,
      "logits/rejected": -2.5550262928009033,
      "logps/chosen": -142.35650634765625,
      "logps/rejected": -147.95098876953125,
      "loss": 0.6832,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0028808601200580597,
      "rewards/margins": 0.020740129053592682,
      "rewards/rejected": -0.017859268933534622,
      "step": 12
    },
    {
      "epoch": 0.0052,
      "grad_norm": 16.15470314025879,
      "learning_rate": 9.983999999999998e-07,
      "logits/chosen": -1.6167486906051636,
      "logits/rejected": -1.5138400793075562,
      "logps/chosen": -130.76853942871094,
      "logps/rejected": -88.59736633300781,
      "loss": 0.6808,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.00668678293004632,
      "rewards/margins": 0.024772262200713158,
      "rewards/rejected": -0.03145904466509819,
      "step": 13
    },
    {
      "epoch": 0.0056,
      "grad_norm": 15.526069641113281,
      "learning_rate": 9.982666666666666e-07,
      "logits/chosen": -1.855992078781128,
      "logits/rejected": -1.3738099336624146,
      "logps/chosen": -148.4079132080078,
      "logps/rejected": -91.90140533447266,
      "loss": 0.6657,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.055754851549863815,
      "rewards/margins": 0.05648994445800781,
      "rewards/rejected": -0.0007350919768214226,
      "step": 14
    },
    {
      "epoch": 0.006,
      "grad_norm": 16.91189956665039,
      "learning_rate": 9.981333333333332e-07,
      "logits/chosen": -2.034663200378418,
      "logits/rejected": -1.628522515296936,
      "logps/chosen": -129.13966369628906,
      "logps/rejected": -93.59890747070312,
      "loss": 0.6893,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.014293290674686432,
      "rewards/margins": 0.007852554321289062,
      "rewards/rejected": 0.006440735422074795,
      "step": 15
    },
    {
      "epoch": 0.0064,
      "grad_norm": 17.97140121459961,
      "learning_rate": 9.98e-07,
      "logits/chosen": -1.9350566864013672,
      "logits/rejected": -1.5779852867126465,
      "logps/chosen": -129.540283203125,
      "logps/rejected": -86.20384216308594,
      "loss": 0.6755,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.011561967432498932,
      "rewards/margins": 0.03553657606244087,
      "rewards/rejected": -0.02397460862994194,
      "step": 16
    },
    {
      "epoch": 0.0068,
      "grad_norm": 16.75215721130371,
      "learning_rate": 9.978666666666666e-07,
      "logits/chosen": -1.766183614730835,
      "logits/rejected": -2.2132043838500977,
      "logps/chosen": -124.06391143798828,
      "logps/rejected": -108.18140411376953,
      "loss": 0.705,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.02003936842083931,
      "rewards/margins": -0.02303924411535263,
      "rewards/rejected": 0.0029998784884810448,
      "step": 17
    },
    {
      "epoch": 0.0072,
      "grad_norm": 18.881425857543945,
      "learning_rate": 9.977333333333334e-07,
      "logits/chosen": -1.9784189462661743,
      "logits/rejected": -2.3239870071411133,
      "logps/chosen": -165.9981689453125,
      "logps/rejected": -114.57511901855469,
      "loss": 0.6597,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.025995636358857155,
      "rewards/margins": 0.06869659572839737,
      "rewards/rejected": -0.042700957506895065,
      "step": 18
    },
    {
      "epoch": 0.0076,
      "grad_norm": 14.448744773864746,
      "learning_rate": 9.976e-07,
      "logits/chosen": -1.8071515560150146,
      "logits/rejected": -1.889855980873108,
      "logps/chosen": -128.1116485595703,
      "logps/rejected": -91.82168579101562,
      "loss": 0.6835,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.008287429809570312,
      "rewards/margins": 0.019606400281190872,
      "rewards/rejected": -0.027893828228116035,
      "step": 19
    },
    {
      "epoch": 0.008,
      "grad_norm": 18.2933406829834,
      "learning_rate": 9.974666666666666e-07,
      "logits/chosen": -1.5390557050704956,
      "logits/rejected": -1.9970080852508545,
      "logps/chosen": -117.3240737915039,
      "logps/rejected": -123.45561981201172,
      "loss": 0.6855,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.030649185180664062,
      "rewards/margins": 0.015288161113858223,
      "rewards/rejected": 0.01536102406680584,
      "step": 20
    },
    {
      "epoch": 0.0084,
      "grad_norm": 12.873006820678711,
      "learning_rate": 9.973333333333332e-07,
      "logits/chosen": -1.898914098739624,
      "logits/rejected": -1.7070127725601196,
      "logps/chosen": -109.45529174804688,
      "logps/rejected": -84.67681884765625,
      "loss": 0.7054,
      "rewards/accuracies": 0.0,
      "rewards/chosen": -0.03913498297333717,
      "rewards/margins": -0.024189379066228867,
      "rewards/rejected": -0.014945602975785732,
      "step": 21
    },
    {
      "epoch": 0.0088,
      "grad_norm": 19.545398712158203,
      "learning_rate": 9.972e-07,
      "logits/chosen": -1.7529393434524536,
      "logits/rejected": -2.02059268951416,
      "logps/chosen": -147.76353454589844,
      "logps/rejected": -114.94943237304688,
      "loss": 0.6594,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08001403510570526,
      "rewards/margins": 0.06916351616382599,
      "rewards/rejected": 0.010850525461137295,
      "step": 22
    },
    {
      "epoch": 0.0092,
      "grad_norm": 19.397075653076172,
      "learning_rate": 9.970666666666665e-07,
      "logits/chosen": -2.4685115814208984,
      "logits/rejected": -2.187530279159546,
      "logps/chosen": -215.649658203125,
      "logps/rejected": -111.81138610839844,
      "loss": 0.6663,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.028031159192323685,
      "rewards/margins": 0.05489311367273331,
      "rewards/rejected": -0.026861954480409622,
      "step": 23
    },
    {
      "epoch": 0.0096,
      "grad_norm": 15.801180839538574,
      "learning_rate": 9.969333333333333e-07,
      "logits/chosen": -1.7768816947937012,
      "logits/rejected": -1.8414264917373657,
      "logps/chosen": -126.51141357421875,
      "logps/rejected": -85.896240234375,
      "loss": 0.711,
      "rewards/accuracies": 0.0,
      "rewards/chosen": -0.03930091857910156,
      "rewards/margins": -0.03543281555175781,
      "rewards/rejected": -0.00386810302734375,
      "step": 24
    },
    {
      "epoch": 0.01,
      "grad_norm": 16.18854522705078,
      "learning_rate": 9.968e-07,
      "logits/chosen": -2.1684629917144775,
      "logits/rejected": -1.6804865598678589,
      "logps/chosen": -163.31649780273438,
      "logps/rejected": -106.45844268798828,
      "loss": 0.6711,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03536529839038849,
      "rewards/margins": 0.044553376734256744,
      "rewards/rejected": -0.009188080206513405,
      "step": 25
    },
    {
      "epoch": 0.0104,
      "grad_norm": 22.206920623779297,
      "learning_rate": 9.966666666666667e-07,
      "logits/chosen": -2.4919862747192383,
      "logits/rejected": -2.34519100189209,
      "logps/chosen": -218.3912811279297,
      "logps/rejected": -129.6809539794922,
      "loss": 0.6925,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.007659912109375,
      "rewards/margins": 0.0018981937319040298,
      "rewards/rejected": 0.0057617188431322575,
      "step": 26
    },
    {
      "epoch": 0.0108,
      "grad_norm": 17.785036087036133,
      "learning_rate": 9.965333333333333e-07,
      "logits/chosen": -1.7693232297897339,
      "logits/rejected": -1.965179204940796,
      "logps/chosen": -140.98226928710938,
      "logps/rejected": -85.98965454101562,
      "loss": 0.7028,
      "rewards/accuracies": 0.0,
      "rewards/chosen": -0.006244277581572533,
      "rewards/margins": -0.01911010779440403,
      "rewards/rejected": 0.012865829281508923,
      "step": 27
    },
    {
      "epoch": 0.0112,
      "grad_norm": 16.0792179107666,
      "learning_rate": 9.964e-07,
      "logits/chosen": -2.009298324584961,
      "logits/rejected": -2.608586549758911,
      "logps/chosen": -110.61824035644531,
      "logps/rejected": -90.97868347167969,
      "loss": 0.7047,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.01475448627024889,
      "rewards/margins": -0.022517776116728783,
      "rewards/rejected": 0.03727226331830025,
      "step": 28
    },
    {
      "epoch": 0.0116,
      "grad_norm": 14.745043754577637,
      "learning_rate": 9.962666666666667e-07,
      "logits/chosen": -2.267284393310547,
      "logits/rejected": -1.7393840551376343,
      "logps/chosen": -138.57550048828125,
      "logps/rejected": -93.46116638183594,
      "loss": 0.6822,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.016648102551698685,
      "rewards/margins": 0.021984100341796875,
      "rewards/rejected": -0.005335998721420765,
      "step": 29
    },
    {
      "epoch": 0.012,
      "grad_norm": 18.98749542236328,
      "learning_rate": 9.961333333333333e-07,
      "logits/chosen": -1.769726037979126,
      "logits/rejected": -1.8742523193359375,
      "logps/chosen": -131.3254852294922,
      "logps/rejected": -107.02200317382812,
      "loss": 0.6856,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.058469776064157486,
      "rewards/margins": 0.015188600867986679,
      "rewards/rejected": 0.04328117147088051,
      "step": 30
    },
    {
      "epoch": 0.0124,
      "grad_norm": 19.522212982177734,
      "learning_rate": 9.959999999999999e-07,
      "logits/chosen": -2.2330358028411865,
      "logits/rejected": -2.1218183040618896,
      "logps/chosen": -237.57534790039062,
      "logps/rejected": -114.80904388427734,
      "loss": 0.6729,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.00352325476706028,
      "rewards/margins": 0.04116630554199219,
      "rewards/rejected": -0.04468956217169762,
      "step": 31
    },
    {
      "epoch": 0.0128,
      "grad_norm": 19.63932228088379,
      "learning_rate": 9.958666666666667e-07,
      "logits/chosen": -2.412781238555908,
      "logits/rejected": -1.7499345541000366,
      "logps/chosen": -206.09365844726562,
      "logps/rejected": -67.52679443359375,
      "loss": 0.6589,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04961395263671875,
      "rewards/margins": 0.06969451904296875,
      "rewards/rejected": -0.02008056640625,
      "step": 32
    },
    {
      "epoch": 0.0132,
      "grad_norm": 17.69650650024414,
      "learning_rate": 9.957333333333332e-07,
      "logits/chosen": -1.6253671646118164,
      "logits/rejected": -2.033331871032715,
      "logps/chosen": -113.88346862792969,
      "logps/rejected": -85.34220886230469,
      "loss": 0.6979,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.030107498168945312,
      "rewards/margins": -0.009000398218631744,
      "rewards/rejected": 0.03910789638757706,
      "step": 33
    },
    {
      "epoch": 0.0136,
      "grad_norm": 19.4537296295166,
      "learning_rate": 9.956e-07,
      "logits/chosen": -2.076167345046997,
      "logits/rejected": -2.3828537464141846,
      "logps/chosen": -161.0933837890625,
      "logps/rejected": -115.01722717285156,
      "loss": 0.6896,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019722746685147285,
      "rewards/margins": 0.007160949055105448,
      "rewards/rejected": 0.012561798095703125,
      "step": 34
    },
    {
      "epoch": 0.014,
      "grad_norm": 22.96538543701172,
      "learning_rate": 9.954666666666666e-07,
      "logits/chosen": -2.3133888244628906,
      "logits/rejected": -2.6402382850646973,
      "logps/chosen": -209.50311279296875,
      "logps/rejected": -127.80835723876953,
      "loss": 0.6735,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.007847595028579235,
      "rewards/margins": 0.040604401379823685,
      "rewards/rejected": -0.032756805419921875,
      "step": 35
    },
    {
      "epoch": 0.0144,
      "grad_norm": 23.46953010559082,
      "learning_rate": 9.953333333333332e-07,
      "logits/chosen": -1.634922981262207,
      "logits/rejected": -2.367600917816162,
      "logps/chosen": -125.64468383789062,
      "logps/rejected": -189.32369995117188,
      "loss": 0.6942,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.03695335611701012,
      "rewards/margins": -0.0020725224167108536,
      "rewards/rejected": 0.03902588039636612,
      "step": 36
    },
    {
      "epoch": 0.0148,
      "grad_norm": 14.803617477416992,
      "learning_rate": 9.952e-07,
      "logits/chosen": -1.7581226825714111,
      "logits/rejected": -1.3446294069290161,
      "logps/chosen": -121.99390411376953,
      "logps/rejected": -98.12307739257812,
      "loss": 0.6683,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0010826103389263153,
      "rewards/margins": 0.050516895949840546,
      "rewards/rejected": -0.05159950256347656,
      "step": 37
    },
    {
      "epoch": 0.0152,
      "grad_norm": 14.754836082458496,
      "learning_rate": 9.950666666666666e-07,
      "logits/chosen": -1.575131893157959,
      "logits/rejected": -1.665920376777649,
      "logps/chosen": -101.79885864257812,
      "logps/rejected": -84.91105651855469,
      "loss": 0.6709,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01482238806784153,
      "rewards/margins": 0.045107267796993256,
      "rewards/rejected": -0.030284881591796875,
      "step": 38
    },
    {
      "epoch": 0.0156,
      "grad_norm": 18.52816390991211,
      "learning_rate": 9.949333333333332e-07,
      "logits/chosen": -1.7090415954589844,
      "logits/rejected": -1.9603424072265625,
      "logps/chosen": -177.39813232421875,
      "logps/rejected": -105.76730346679688,
      "loss": 0.659,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08289527893066406,
      "rewards/margins": 0.06985321640968323,
      "rewards/rejected": 0.013042068108916283,
      "step": 39
    },
    {
      "epoch": 0.016,
      "grad_norm": 18.07594108581543,
      "learning_rate": 9.948e-07,
      "logits/chosen": -1.9365999698638916,
      "logits/rejected": -2.733116865158081,
      "logps/chosen": -167.9061279296875,
      "logps/rejected": -158.46560668945312,
      "loss": 0.663,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04372558742761612,
      "rewards/margins": 0.06185455247759819,
      "rewards/rejected": -0.01812896691262722,
      "step": 40
    },
    {
      "epoch": 0.0164,
      "grad_norm": 28.139802932739258,
      "learning_rate": 9.946666666666666e-07,
      "logits/chosen": -2.7157182693481445,
      "logits/rejected": -2.0608575344085693,
      "logps/chosen": -240.67324829101562,
      "logps/rejected": -160.4871826171875,
      "loss": 0.6837,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.034554291516542435,
      "rewards/margins": 0.019081879407167435,
      "rewards/rejected": 0.015472412109375,
      "step": 41
    },
    {
      "epoch": 0.0168,
      "grad_norm": 26.66353988647461,
      "learning_rate": 9.945333333333334e-07,
      "logits/chosen": -2.552783489227295,
      "logits/rejected": -2.6458077430725098,
      "logps/chosen": -286.088134765625,
      "logps/rejected": -99.53726196289062,
      "loss": 0.6683,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04709625244140625,
      "rewards/margins": 0.0504859983921051,
      "rewards/rejected": -0.0033897398971021175,
      "step": 42
    },
    {
      "epoch": 0.0172,
      "grad_norm": 15.103856086730957,
      "learning_rate": 9.944e-07,
      "logits/chosen": -1.8241989612579346,
      "logits/rejected": -2.387251377105713,
      "logps/chosen": -146.152587890625,
      "logps/rejected": -113.26583099365234,
      "loss": 0.6544,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09020271897315979,
      "rewards/margins": 0.07922706753015518,
      "rewards/rejected": 0.010975646786391735,
      "step": 43
    },
    {
      "epoch": 0.0176,
      "grad_norm": 17.608186721801758,
      "learning_rate": 9.942666666666665e-07,
      "logits/chosen": -2.0570569038391113,
      "logits/rejected": -1.9006211757659912,
      "logps/chosen": -135.58775329589844,
      "logps/rejected": -94.543701171875,
      "loss": 0.674,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01442489679902792,
      "rewards/margins": 0.03878059610724449,
      "rewards/rejected": -0.024355698376893997,
      "step": 44
    },
    {
      "epoch": 0.018,
      "grad_norm": 16.249309539794922,
      "learning_rate": 9.941333333333333e-07,
      "logits/chosen": -1.7012863159179688,
      "logits/rejected": -2.4735844135284424,
      "logps/chosen": -154.8673553466797,
      "logps/rejected": -103.80404663085938,
      "loss": 0.666,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06349410861730576,
      "rewards/margins": 0.055002592504024506,
      "rewards/rejected": 0.00849151611328125,
      "step": 45
    },
    {
      "epoch": 0.0184,
      "grad_norm": 14.00233268737793,
      "learning_rate": 9.94e-07,
      "logits/chosen": -1.9254735708236694,
      "logits/rejected": -1.9299339056015015,
      "logps/chosen": -132.3321533203125,
      "logps/rejected": -104.31640625,
      "loss": 0.6873,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.02253417670726776,
      "rewards/margins": 0.012893673032522202,
      "rewards/rejected": 0.00964050367474556,
      "step": 46
    },
    {
      "epoch": 0.0188,
      "grad_norm": 26.015302658081055,
      "learning_rate": 9.938666666666667e-07,
      "logits/chosen": -1.9186015129089355,
      "logits/rejected": -2.4075851440429688,
      "logps/chosen": -150.0072479248047,
      "logps/rejected": -225.1713409423828,
      "loss": 0.6628,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06930770725011826,
      "rewards/margins": 0.062042236328125,
      "rewards/rejected": 0.0072654723189771175,
      "step": 47
    },
    {
      "epoch": 0.0192,
      "grad_norm": 18.922983169555664,
      "learning_rate": 9.937333333333333e-07,
      "logits/chosen": -2.0237221717834473,
      "logits/rejected": -1.920959234237671,
      "logps/chosen": -166.958251953125,
      "logps/rejected": -81.97706604003906,
      "loss": 0.6518,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07478408515453339,
      "rewards/margins": 0.08478470146656036,
      "rewards/rejected": -0.01000061072409153,
      "step": 48
    },
    {
      "epoch": 0.0196,
      "grad_norm": 17.02379608154297,
      "learning_rate": 9.936e-07,
      "logits/chosen": -2.1564223766326904,
      "logits/rejected": -2.026033878326416,
      "logps/chosen": -143.2440185546875,
      "logps/rejected": -97.61506652832031,
      "loss": 0.6755,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.01055984478443861,
      "rewards/margins": 0.03626212850213051,
      "rewards/rejected": -0.04682197794318199,
      "step": 49
    },
    {
      "epoch": 0.02,
      "grad_norm": 17.77133560180664,
      "learning_rate": 9.934666666666667e-07,
      "logits/chosen": -1.6027106046676636,
      "logits/rejected": -2.0677852630615234,
      "logps/chosen": -91.84933471679688,
      "logps/rejected": -101.90319061279297,
      "loss": 0.6699,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.05220756679773331,
      "rewards/margins": 0.04782600700855255,
      "rewards/rejected": 0.0043815611861646175,
      "step": 50
    },
    {
      "epoch": 0.0204,
      "grad_norm": 28.90410614013672,
      "learning_rate": 9.933333333333333e-07,
      "logits/chosen": -2.1330180168151855,
      "logits/rejected": -2.8160853385925293,
      "logps/chosen": -275.0372619628906,
      "logps/rejected": -194.62237548828125,
      "loss": 0.6836,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03525543212890625,
      "rewards/margins": 0.01934356614947319,
      "rewards/rejected": 0.01591186597943306,
      "step": 51
    },
    {
      "epoch": 0.0208,
      "grad_norm": 20.151111602783203,
      "learning_rate": 9.931999999999999e-07,
      "logits/chosen": -2.281667709350586,
      "logits/rejected": -2.1183063983917236,
      "logps/chosen": -256.320556640625,
      "logps/rejected": -89.94184875488281,
      "loss": 0.6999,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.01470108050853014,
      "rewards/margins": -0.012873077765107155,
      "rewards/rejected": -0.001828002743422985,
      "step": 52
    },
    {
      "epoch": 0.0212,
      "grad_norm": 17.802396774291992,
      "learning_rate": 9.930666666666667e-07,
      "logits/chosen": -2.1729109287261963,
      "logits/rejected": -2.3027310371398926,
      "logps/chosen": -125.382568359375,
      "logps/rejected": -104.61614990234375,
      "loss": 0.7013,
      "rewards/accuracies": 0.0,
      "rewards/chosen": -0.015759658068418503,
      "rewards/margins": -0.016231916844844818,
      "rewards/rejected": 0.0004722587764263153,
      "step": 53
    },
    {
      "epoch": 0.0216,
      "grad_norm": 15.116493225097656,
      "learning_rate": 9.929333333333333e-07,
      "logits/chosen": -1.6753242015838623,
      "logits/rejected": -1.476914405822754,
      "logps/chosen": -130.230224609375,
      "logps/rejected": -78.7014389038086,
      "loss": 0.6874,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.007488632574677467,
      "rewards/margins": 0.0115203857421875,
      "rewards/rejected": -0.019009018316864967,
      "step": 54
    },
    {
      "epoch": 0.022,
      "grad_norm": 16.937232971191406,
      "learning_rate": 9.928e-07,
      "logits/chosen": -1.8340983390808105,
      "logits/rejected": -2.377750873565674,
      "logps/chosen": -150.10707092285156,
      "logps/rejected": -131.81777954101562,
      "loss": 0.6534,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06528015434741974,
      "rewards/margins": 0.0814308226108551,
      "rewards/rejected": -0.016150664538145065,
      "step": 55
    },
    {
      "epoch": 0.0224,
      "grad_norm": 20.31101417541504,
      "learning_rate": 9.926666666666666e-07,
      "logits/chosen": -2.332122802734375,
      "logits/rejected": -2.5658206939697266,
      "logps/chosen": -232.4404296875,
      "logps/rejected": -100.7155990600586,
      "loss": 0.6372,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10222168266773224,
      "rewards/margins": 0.11526603996753693,
      "rewards/rejected": -0.013044358231127262,
      "step": 56
    },
    {
      "epoch": 0.0228,
      "grad_norm": 15.842887878417969,
      "learning_rate": 9.925333333333334e-07,
      "logits/chosen": -1.8553822040557861,
      "logits/rejected": -1.6204549074172974,
      "logps/chosen": -132.67355346679688,
      "logps/rejected": -113.84458923339844,
      "loss": 0.6595,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.048065185546875,
      "rewards/margins": 0.06971053779125214,
      "rewards/rejected": -0.021645354107022285,
      "step": 57
    },
    {
      "epoch": 0.0232,
      "grad_norm": 14.077000617980957,
      "learning_rate": 9.923999999999998e-07,
      "logits/chosen": -2.0795702934265137,
      "logits/rejected": -2.0205037593841553,
      "logps/chosen": -114.88067626953125,
      "logps/rejected": -88.38291931152344,
      "loss": 0.6731,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.034580230712890625,
      "rewards/margins": 0.04043465107679367,
      "rewards/rejected": -0.00585441617295146,
      "step": 58
    },
    {
      "epoch": 0.0236,
      "grad_norm": 12.676863670349121,
      "learning_rate": 9.922666666666666e-07,
      "logits/chosen": -1.5518436431884766,
      "logits/rejected": -1.1851948499679565,
      "logps/chosen": -115.12754821777344,
      "logps/rejected": -78.93302154541016,
      "loss": 0.6566,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0667518600821495,
      "rewards/margins": 0.07456283271312714,
      "rewards/rejected": -0.00781097449362278,
      "step": 59
    },
    {
      "epoch": 0.024,
      "grad_norm": 17.23594093322754,
      "learning_rate": 9.921333333333332e-07,
      "logits/chosen": -1.828049659729004,
      "logits/rejected": -2.867356061935425,
      "logps/chosen": -125.35696411132812,
      "logps/rejected": -108.71138000488281,
      "loss": 0.6362,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10068587958812714,
      "rewards/margins": 0.117401123046875,
      "rewards/rejected": -0.016715239733457565,
      "step": 60
    },
    {
      "epoch": 0.0244,
      "grad_norm": 17.488977432250977,
      "learning_rate": 9.92e-07,
      "logits/chosen": -1.9849358797073364,
      "logits/rejected": -2.3513412475585938,
      "logps/chosen": -142.21914672851562,
      "logps/rejected": -114.14791870117188,
      "loss": 0.6758,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.035797882825136185,
      "rewards/margins": 0.03527183458209038,
      "rewards/rejected": 0.0005260473117232323,
      "step": 61
    },
    {
      "epoch": 0.0248,
      "grad_norm": 15.173555374145508,
      "learning_rate": 9.918666666666666e-07,
      "logits/chosen": -1.553051233291626,
      "logits/rejected": -1.2227493524551392,
      "logps/chosen": -143.1680145263672,
      "logps/rejected": -94.0614013671875,
      "loss": 0.6518,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05357170104980469,
      "rewards/margins": 0.08518867939710617,
      "rewards/rejected": -0.031616974622011185,
      "step": 62
    },
    {
      "epoch": 0.0252,
      "grad_norm": 20.562759399414062,
      "learning_rate": 9.917333333333334e-07,
      "logits/chosen": -2.055173873901367,
      "logits/rejected": -1.8441481590270996,
      "logps/chosen": -169.99073791503906,
      "logps/rejected": -103.92961120605469,
      "loss": 0.6329,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09799766540527344,
      "rewards/margins": 0.12439727783203125,
      "rewards/rejected": -0.026399612426757812,
      "step": 63
    },
    {
      "epoch": 0.0256,
      "grad_norm": 22.30881118774414,
      "learning_rate": 9.916e-07,
      "logits/chosen": -2.46634578704834,
      "logits/rejected": -2.5149569511413574,
      "logps/chosen": -210.63673400878906,
      "logps/rejected": -112.09579467773438,
      "loss": 0.6602,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.004399871453642845,
      "rewards/margins": 0.06797905266284943,
      "rewards/rejected": -0.07237891852855682,
      "step": 64
    },
    {
      "epoch": 0.026,
      "grad_norm": 14.843899726867676,
      "learning_rate": 9.914666666666668e-07,
      "logits/chosen": -1.829179286956787,
      "logits/rejected": -1.9911881685256958,
      "logps/chosen": -161.7623291015625,
      "logps/rejected": -110.47225952148438,
      "loss": 0.6592,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01631317101418972,
      "rewards/margins": 0.07014846801757812,
      "rewards/rejected": -0.053835298866033554,
      "step": 65
    },
    {
      "epoch": 0.0264,
      "grad_norm": 19.764955520629883,
      "learning_rate": 9.913333333333333e-07,
      "logits/chosen": -2.2900290489196777,
      "logits/rejected": -2.396500587463379,
      "logps/chosen": -148.09092712402344,
      "logps/rejected": -148.50753784179688,
      "loss": 0.6542,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05524139478802681,
      "rewards/margins": 0.07956542819738388,
      "rewards/rejected": -0.02432403527200222,
      "step": 66
    },
    {
      "epoch": 0.0268,
      "grad_norm": 24.845687866210938,
      "learning_rate": 9.912e-07,
      "logits/chosen": -2.068051815032959,
      "logits/rejected": -2.160712957382202,
      "logps/chosen": -180.23828125,
      "logps/rejected": -170.91012573242188,
      "loss": 0.6355,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.042337801307439804,
      "rewards/margins": 0.11898232251405716,
      "rewards/rejected": -0.07664451748132706,
      "step": 67
    },
    {
      "epoch": 0.0272,
      "grad_norm": 14.874155044555664,
      "learning_rate": 9.910666666666665e-07,
      "logits/chosen": -1.7558984756469727,
      "logits/rejected": -1.6776914596557617,
      "logps/chosen": -120.3953857421875,
      "logps/rejected": -97.99595642089844,
      "loss": 0.6484,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08037300407886505,
      "rewards/margins": 0.09183350205421448,
      "rewards/rejected": -0.011460496112704277,
      "step": 68
    },
    {
      "epoch": 0.0276,
      "grad_norm": 16.714710235595703,
      "learning_rate": 9.909333333333333e-07,
      "logits/chosen": -2.105867862701416,
      "logits/rejected": -1.7474136352539062,
      "logps/chosen": -131.31967163085938,
      "logps/rejected": -95.01858520507812,
      "loss": 0.6717,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.13812561333179474,
      "rewards/margins": 0.04423561319708824,
      "rewards/rejected": 0.0938899964094162,
      "step": 69
    },
    {
      "epoch": 0.028,
      "grad_norm": 22.11811637878418,
      "learning_rate": 9.908e-07,
      "logits/chosen": -2.5218067169189453,
      "logits/rejected": -3.0962352752685547,
      "logps/chosen": -252.256103515625,
      "logps/rejected": -146.64378356933594,
      "loss": 0.6412,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06695175170898438,
      "rewards/margins": 0.10682182013988495,
      "rewards/rejected": -0.03987007215619087,
      "step": 70
    },
    {
      "epoch": 0.0284,
      "grad_norm": 12.963066101074219,
      "learning_rate": 9.906666666666667e-07,
      "logits/chosen": -1.8854413032531738,
      "logits/rejected": -2.2844231128692627,
      "logps/chosen": -130.07159423828125,
      "logps/rejected": -90.880859375,
      "loss": 0.664,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.034569550305604935,
      "rewards/margins": 0.0590946227312088,
      "rewards/rejected": -0.024525070562958717,
      "step": 71
    },
    {
      "epoch": 0.0288,
      "grad_norm": 18.709592819213867,
      "learning_rate": 9.905333333333333e-07,
      "logits/chosen": -1.9021315574645996,
      "logits/rejected": -1.7508814334869385,
      "logps/chosen": -146.32740783691406,
      "logps/rejected": -106.37086486816406,
      "loss": 0.6439,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11481171101331711,
      "rewards/margins": 0.10113830864429474,
      "rewards/rejected": 0.01367340236902237,
      "step": 72
    },
    {
      "epoch": 0.0292,
      "grad_norm": 19.694570541381836,
      "learning_rate": 9.903999999999999e-07,
      "logits/chosen": -2.229421854019165,
      "logits/rejected": -2.2215378284454346,
      "logps/chosen": -165.1767120361328,
      "logps/rejected": -136.94815063476562,
      "loss": 0.657,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.04168663173913956,
      "rewards/margins": 0.07518959045410156,
      "rewards/rejected": -0.033502958714962006,
      "step": 73
    },
    {
      "epoch": 0.0296,
      "grad_norm": 17.84062957763672,
      "learning_rate": 9.902666666666667e-07,
      "logits/chosen": -1.838245153427124,
      "logits/rejected": -2.0767107009887695,
      "logps/chosen": -205.581787109375,
      "logps/rejected": -120.64607238769531,
      "loss": 0.6661,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03529052808880806,
      "rewards/margins": 0.05486908182501793,
      "rewards/rejected": -0.01957855373620987,
      "step": 74
    },
    {
      "epoch": 0.03,
      "grad_norm": 15.731291770935059,
      "learning_rate": 9.901333333333333e-07,
      "logits/chosen": -2.0329017639160156,
      "logits/rejected": -1.7718348503112793,
      "logps/chosen": -136.8147430419922,
      "logps/rejected": -83.40031433105469,
      "loss": 0.6685,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06049766391515732,
      "rewards/margins": 0.04989662021398544,
      "rewards/rejected": 0.010601043701171875,
      "step": 75
    },
    {
      "epoch": 0.0304,
      "grad_norm": 19.705913543701172,
      "learning_rate": 9.9e-07,
      "logits/chosen": -1.9686598777770996,
      "logits/rejected": -0.6899585723876953,
      "logps/chosen": -150.36831665039062,
      "logps/rejected": -90.32443237304688,
      "loss": 0.6831,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01732788048684597,
      "rewards/margins": 0.020177077502012253,
      "rewards/rejected": -0.00284919748082757,
      "step": 76
    },
    {
      "epoch": 0.0308,
      "grad_norm": 13.857951164245605,
      "learning_rate": 9.898666666666666e-07,
      "logits/chosen": -1.7545959949493408,
      "logits/rejected": -2.328512668609619,
      "logps/chosen": -98.66815185546875,
      "logps/rejected": -89.36514282226562,
      "loss": 0.6828,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.029914094135165215,
      "rewards/margins": 0.02077026292681694,
      "rewards/rejected": 0.009143829345703125,
      "step": 77
    },
    {
      "epoch": 0.0312,
      "grad_norm": 17.667057037353516,
      "learning_rate": 9.897333333333332e-07,
      "logits/chosen": -1.9052948951721191,
      "logits/rejected": -2.7356977462768555,
      "logps/chosen": -134.87713623046875,
      "logps/rejected": -109.49652099609375,
      "loss": 0.613,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09220504760742188,
      "rewards/margins": 0.16733360290527344,
      "rewards/rejected": -0.07512855529785156,
      "step": 78
    },
    {
      "epoch": 0.0316,
      "grad_norm": 15.39405345916748,
      "learning_rate": 9.896e-07,
      "logits/chosen": -1.70086669921875,
      "logits/rejected": -1.9838168621063232,
      "logps/chosen": -117.1656723022461,
      "logps/rejected": -95.73876953125,
      "loss": 0.6874,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0034526826348155737,
      "rewards/margins": 0.011592102237045765,
      "rewards/rejected": -0.015044784173369408,
      "step": 79
    },
    {
      "epoch": 0.032,
      "grad_norm": 14.087607383728027,
      "learning_rate": 9.894666666666666e-07,
      "logits/chosen": -1.9575486183166504,
      "logits/rejected": -1.1111326217651367,
      "logps/chosen": -141.99407958984375,
      "logps/rejected": -91.0013427734375,
      "loss": 0.6428,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.102686308324337,
      "rewards/margins": 0.10444411635398865,
      "rewards/rejected": -0.001757812686264515,
      "step": 80
    },
    {
      "epoch": 0.0324,
      "grad_norm": 15.958888053894043,
      "learning_rate": 9.893333333333332e-07,
      "logits/chosen": -1.6057820320129395,
      "logits/rejected": -2.064767599105835,
      "logps/chosen": -94.27120971679688,
      "logps/rejected": -87.64957427978516,
      "loss": 0.6481,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03683318942785263,
      "rewards/margins": 0.09215393662452698,
      "rewards/rejected": -0.05532074347138405,
      "step": 81
    },
    {
      "epoch": 0.0328,
      "grad_norm": 16.293102264404297,
      "learning_rate": 9.892e-07,
      "logits/chosen": -1.5957437753677368,
      "logits/rejected": -1.8465337753295898,
      "logps/chosen": -119.57984924316406,
      "logps/rejected": -88.26005554199219,
      "loss": 0.6893,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.004384231753647327,
      "rewards/margins": 0.007747269235551357,
      "rewards/rejected": -0.00336303748190403,
      "step": 82
    },
    {
      "epoch": 0.0332,
      "grad_norm": 12.743635177612305,
      "learning_rate": 9.890666666666666e-07,
      "logits/chosen": -1.608886480331421,
      "logits/rejected": -1.7567203044891357,
      "logps/chosen": -90.18060302734375,
      "logps/rejected": -75.48092651367188,
      "loss": 0.6602,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07611121982336044,
      "rewards/margins": 0.06724701076745987,
      "rewards/rejected": 0.008864211849868298,
      "step": 83
    },
    {
      "epoch": 0.0336,
      "grad_norm": 17.19230842590332,
      "learning_rate": 9.889333333333334e-07,
      "logits/chosen": -1.568068504333496,
      "logits/rejected": -1.3784832954406738,
      "logps/chosen": -110.80276489257812,
      "logps/rejected": -85.98505401611328,
      "loss": 0.6522,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1103740707039833,
      "rewards/margins": 0.08369942009449005,
      "rewards/rejected": 0.026674650609493256,
      "step": 84
    },
    {
      "epoch": 0.034,
      "grad_norm": 14.33228588104248,
      "learning_rate": 9.888e-07,
      "logits/chosen": -2.0637664794921875,
      "logits/rejected": -1.5569608211517334,
      "logps/chosen": -126.31349182128906,
      "logps/rejected": -99.03831481933594,
      "loss": 0.6052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16483306884765625,
      "rewards/margins": 0.1844886839389801,
      "rewards/rejected": -0.019655609503388405,
      "step": 85
    },
    {
      "epoch": 0.0344,
      "grad_norm": 14.69825267791748,
      "learning_rate": 9.886666666666665e-07,
      "logits/chosen": -1.5927397012710571,
      "logits/rejected": -1.7374259233474731,
      "logps/chosen": -122.82614135742188,
      "logps/rejected": -82.06378173828125,
      "loss": 0.6525,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026733780279755592,
      "rewards/margins": 0.08368492126464844,
      "rewards/rejected": -0.056951142847537994,
      "step": 86
    },
    {
      "epoch": 0.0348,
      "grad_norm": 20.375770568847656,
      "learning_rate": 9.885333333333333e-07,
      "logits/chosen": -2.048142910003662,
      "logits/rejected": -1.8018927574157715,
      "logps/chosen": -143.46107482910156,
      "logps/rejected": -112.17155456542969,
      "loss": 0.5996,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15129432082176208,
      "rewards/margins": 0.19732627272605896,
      "rewards/rejected": -0.046031951904296875,
      "step": 87
    },
    {
      "epoch": 0.0352,
      "grad_norm": 19.477373123168945,
      "learning_rate": 9.884e-07,
      "logits/chosen": -1.7977895736694336,
      "logits/rejected": -2.172156810760498,
      "logps/chosen": -160.9176483154297,
      "logps/rejected": -79.54032897949219,
      "loss": 0.6106,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14735642075538635,
      "rewards/margins": 0.1725563108921051,
      "rewards/rejected": -0.02519989013671875,
      "step": 88
    },
    {
      "epoch": 0.0356,
      "grad_norm": 16.732576370239258,
      "learning_rate": 9.882666666666665e-07,
      "logits/chosen": -2.046168804168701,
      "logits/rejected": -1.484595537185669,
      "logps/chosen": -144.45005798339844,
      "logps/rejected": -85.40672302246094,
      "loss": 0.658,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07279892265796661,
      "rewards/margins": 0.07154503464698792,
      "rewards/rejected": 0.0012538908049464226,
      "step": 89
    },
    {
      "epoch": 0.036,
      "grad_norm": 12.772564888000488,
      "learning_rate": 9.881333333333333e-07,
      "logits/chosen": -1.839338779449463,
      "logits/rejected": -1.7328921556472778,
      "logps/chosen": -105.72523498535156,
      "logps/rejected": -94.20047760009766,
      "loss": 0.6471,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08348732441663742,
      "rewards/margins": 0.09457817673683167,
      "rewards/rejected": -0.01109085138887167,
      "step": 90
    },
    {
      "epoch": 0.0364,
      "grad_norm": 18.13473892211914,
      "learning_rate": 9.88e-07,
      "logits/chosen": -1.6932276487350464,
      "logits/rejected": -2.6458075046539307,
      "logps/chosen": -143.515380859375,
      "logps/rejected": -123.06657409667969,
      "loss": 0.6363,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10314521938562393,
      "rewards/margins": 0.11795349419116974,
      "rewards/rejected": -0.014808272942900658,
      "step": 91
    },
    {
      "epoch": 0.0368,
      "grad_norm": 21.661787033081055,
      "learning_rate": 9.878666666666667e-07,
      "logits/chosen": -2.432231903076172,
      "logits/rejected": -1.718930721282959,
      "logps/chosen": -279.097900390625,
      "logps/rejected": -102.74058532714844,
      "loss": 0.5476,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.237091064453125,
      "rewards/margins": 0.31601715087890625,
      "rewards/rejected": -0.07892608642578125,
      "step": 92
    },
    {
      "epoch": 0.0372,
      "grad_norm": 13.998065948486328,
      "learning_rate": 9.877333333333333e-07,
      "logits/chosen": -1.7183303833007812,
      "logits/rejected": -2.075889825820923,
      "logps/chosen": -103.90614318847656,
      "logps/rejected": -98.4964370727539,
      "loss": 0.6837,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0732646957039833,
      "rewards/margins": 0.018997954204678535,
      "rewards/rejected": 0.05426674336194992,
      "step": 93
    },
    {
      "epoch": 0.0376,
      "grad_norm": 13.255802154541016,
      "learning_rate": 9.876e-07,
      "logits/chosen": -1.629063367843628,
      "logits/rejected": -1.3524420261383057,
      "logps/chosen": -129.51748657226562,
      "logps/rejected": -88.32110595703125,
      "loss": 0.6221,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06403236836194992,
      "rewards/margins": 0.1475570797920227,
      "rewards/rejected": -0.08352470397949219,
      "step": 94
    },
    {
      "epoch": 0.038,
      "grad_norm": 15.666373252868652,
      "learning_rate": 9.874666666666667e-07,
      "logits/chosen": -1.5227608680725098,
      "logits/rejected": -1.709985613822937,
      "logps/chosen": -102.67716979980469,
      "logps/rejected": -74.5689697265625,
      "loss": 0.65,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.04401397705078125,
      "rewards/margins": 0.09072533249855042,
      "rewards/rejected": -0.04671135172247887,
      "step": 95
    },
    {
      "epoch": 0.0384,
      "grad_norm": 18.292804718017578,
      "learning_rate": 9.873333333333333e-07,
      "logits/chosen": -2.000744342803955,
      "logits/rejected": -2.0697855949401855,
      "logps/chosen": -177.24237060546875,
      "logps/rejected": -124.65414428710938,
      "loss": 0.6231,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.068090058863163,
      "rewards/margins": 0.14673499763011932,
      "rewards/rejected": -0.07864494621753693,
      "step": 96
    },
    {
      "epoch": 0.0388,
      "grad_norm": 13.980618476867676,
      "learning_rate": 9.871999999999998e-07,
      "logits/chosen": -1.7916755676269531,
      "logits/rejected": -1.7037749290466309,
      "logps/chosen": -144.85272216796875,
      "logps/rejected": -93.83772277832031,
      "loss": 0.6107,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11533279716968536,
      "rewards/margins": 0.17354965209960938,
      "rewards/rejected": -0.05821686238050461,
      "step": 97
    },
    {
      "epoch": 0.0392,
      "grad_norm": 16.345590591430664,
      "learning_rate": 9.870666666666666e-07,
      "logits/chosen": -1.9776489734649658,
      "logits/rejected": -2.353071689605713,
      "logps/chosen": -163.74359130859375,
      "logps/rejected": -117.38883972167969,
      "loss": 0.6493,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11024323105812073,
      "rewards/margins": 0.08994331955909729,
      "rewards/rejected": 0.020299911499023438,
      "step": 98
    },
    {
      "epoch": 0.0396,
      "grad_norm": 18.39475440979004,
      "learning_rate": 9.869333333333332e-07,
      "logits/chosen": -1.7298741340637207,
      "logits/rejected": -2.0405936241149902,
      "logps/chosen": -145.92327880859375,
      "logps/rejected": -123.8099365234375,
      "loss": 0.6391,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13484573364257812,
      "rewards/margins": 0.11129799485206604,
      "rewards/rejected": 0.023547744378447533,
      "step": 99
    },
    {
      "epoch": 0.04,
      "grad_norm": 18.886127471923828,
      "learning_rate": 9.868e-07,
      "logits/chosen": -1.6741081476211548,
      "logits/rejected": -2.3774328231811523,
      "logps/chosen": -139.03604125976562,
      "logps/rejected": -141.11602783203125,
      "loss": 0.6239,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1066841185092926,
      "rewards/margins": 0.1436203122138977,
      "rewards/rejected": -0.036936189979314804,
      "step": 100
    },
    {
      "epoch": 0.0404,
      "grad_norm": 19.56816291809082,
      "learning_rate": 9.866666666666666e-07,
      "logits/chosen": -1.8933100700378418,
      "logits/rejected": -2.4314823150634766,
      "logps/chosen": -152.89767456054688,
      "logps/rejected": -106.08081817626953,
      "loss": 0.6222,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09491425007581711,
      "rewards/margins": 0.14737015962600708,
      "rewards/rejected": -0.052455902099609375,
      "step": 101
    },
    {
      "epoch": 0.0408,
      "grad_norm": 16.520334243774414,
      "learning_rate": 9.865333333333334e-07,
      "logits/chosen": -1.8958203792572021,
      "logits/rejected": -2.0363762378692627,
      "logps/chosen": -122.16990661621094,
      "logps/rejected": -97.57208251953125,
      "loss": 0.6312,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08582305908203125,
      "rewards/margins": 0.12985363602638245,
      "rewards/rejected": -0.0440305732190609,
      "step": 102
    },
    {
      "epoch": 0.0412,
      "grad_norm": 18.3576602935791,
      "learning_rate": 9.864e-07,
      "logits/chosen": -1.419433355331421,
      "logits/rejected": -2.140188217163086,
      "logps/chosen": -183.26040649414062,
      "logps/rejected": -135.98756408691406,
      "loss": 0.6334,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04486045613884926,
      "rewards/margins": 0.12506599724292755,
      "rewards/rejected": -0.080205537378788,
      "step": 103
    },
    {
      "epoch": 0.0416,
      "grad_norm": 21.300661087036133,
      "learning_rate": 9.862666666666666e-07,
      "logits/chosen": -2.4994099140167236,
      "logits/rejected": -2.2457401752471924,
      "logps/chosen": -211.32351684570312,
      "logps/rejected": -91.309814453125,
      "loss": 0.575,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21860963106155396,
      "rewards/margins": 0.25278663635253906,
      "rewards/rejected": -0.0341770201921463,
      "step": 104
    },
    {
      "epoch": 0.042,
      "grad_norm": 12.334599494934082,
      "learning_rate": 9.861333333333332e-07,
      "logits/chosen": -1.6656514406204224,
      "logits/rejected": -1.077675461769104,
      "logps/chosen": -114.31867980957031,
      "logps/rejected": -79.24226379394531,
      "loss": 0.6386,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11570052802562714,
      "rewards/margins": 0.11301612854003906,
      "rewards/rejected": 0.002684403210878372,
      "step": 105
    },
    {
      "epoch": 0.0424,
      "grad_norm": 14.970508575439453,
      "learning_rate": 9.86e-07,
      "logits/chosen": -1.445604681968689,
      "logits/rejected": -0.9720816612243652,
      "logps/chosen": -156.21939086914062,
      "logps/rejected": -71.15359497070312,
      "loss": 0.6528,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04674339294433594,
      "rewards/margins": 0.08315467834472656,
      "rewards/rejected": -0.036411285400390625,
      "step": 106
    },
    {
      "epoch": 0.0428,
      "grad_norm": 22.000452041625977,
      "learning_rate": 9.858666666666665e-07,
      "logits/chosen": -2.3113765716552734,
      "logits/rejected": -2.401641368865967,
      "logps/chosen": -229.74722290039062,
      "logps/rejected": -145.42892456054688,
      "loss": 0.6542,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12602311372756958,
      "rewards/margins": 0.07960586994886398,
      "rewards/rejected": 0.046417236328125,
      "step": 107
    },
    {
      "epoch": 0.0432,
      "grad_norm": 13.101555824279785,
      "learning_rate": 9.857333333333333e-07,
      "logits/chosen": -1.3077367544174194,
      "logits/rejected": -1.9646720886230469,
      "logps/chosen": -95.53903198242188,
      "logps/rejected": -104.07557678222656,
      "loss": 0.6654,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02707367017865181,
      "rewards/margins": 0.056795503944158554,
      "rewards/rejected": -0.029721833765506744,
      "step": 108
    },
    {
      "epoch": 0.0436,
      "grad_norm": 16.839040756225586,
      "learning_rate": 9.856e-07,
      "logits/chosen": -2.109894275665283,
      "logits/rejected": -2.1068825721740723,
      "logps/chosen": -132.70985412597656,
      "logps/rejected": -108.37861633300781,
      "loss": 0.6411,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07268676906824112,
      "rewards/margins": 0.10908546298742294,
      "rewards/rejected": -0.03639869764447212,
      "step": 109
    },
    {
      "epoch": 0.044,
      "grad_norm": 20.03768539428711,
      "learning_rate": 9.854666666666667e-07,
      "logits/chosen": -2.3207902908325195,
      "logits/rejected": -2.1836650371551514,
      "logps/chosen": -187.83773803710938,
      "logps/rejected": -115.78532409667969,
      "loss": 0.5884,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15940171480178833,
      "rewards/margins": 0.22201958298683167,
      "rewards/rejected": -0.06261787563562393,
      "step": 110
    },
    {
      "epoch": 0.0444,
      "grad_norm": 16.243183135986328,
      "learning_rate": 9.853333333333333e-07,
      "logits/chosen": -2.057976245880127,
      "logits/rejected": -2.0548839569091797,
      "logps/chosen": -142.3499755859375,
      "logps/rejected": -93.60911560058594,
      "loss": 0.6171,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0777561217546463,
      "rewards/margins": 0.15998879075050354,
      "rewards/rejected": -0.08223266899585724,
      "step": 111
    },
    {
      "epoch": 0.0448,
      "grad_norm": 15.276758193969727,
      "learning_rate": 9.852e-07,
      "logits/chosen": -2.180441379547119,
      "logits/rejected": -0.6790106892585754,
      "logps/chosen": -130.08984375,
      "logps/rejected": -63.86539840698242,
      "loss": 0.6457,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09185562282800674,
      "rewards/margins": 0.09835243225097656,
      "rewards/rejected": -0.006496811285614967,
      "step": 112
    },
    {
      "epoch": 0.0452,
      "grad_norm": 21.796789169311523,
      "learning_rate": 9.850666666666667e-07,
      "logits/chosen": -2.3623909950256348,
      "logits/rejected": -2.7811007499694824,
      "logps/chosen": -237.7881317138672,
      "logps/rejected": -153.8236846923828,
      "loss": 0.5839,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2023361325263977,
      "rewards/margins": 0.23209229111671448,
      "rewards/rejected": -0.02975616417825222,
      "step": 113
    },
    {
      "epoch": 0.0456,
      "grad_norm": 15.595510482788086,
      "learning_rate": 9.849333333333333e-07,
      "logits/chosen": -2.125636339187622,
      "logits/rejected": -2.245238780975342,
      "logps/chosen": -161.5030517578125,
      "logps/rejected": -85.53143310546875,
      "loss": 0.6132,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11492843925952911,
      "rewards/margins": 0.16689491271972656,
      "rewards/rejected": -0.05196647718548775,
      "step": 114
    },
    {
      "epoch": 0.046,
      "grad_norm": 26.26072883605957,
      "learning_rate": 9.847999999999999e-07,
      "logits/chosen": -2.0711257457733154,
      "logits/rejected": -2.204113245010376,
      "logps/chosen": -204.3936767578125,
      "logps/rejected": -182.1153564453125,
      "loss": 0.5935,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20060577988624573,
      "rewards/margins": 0.21036683022975922,
      "rewards/rejected": -0.00976104661822319,
      "step": 115
    },
    {
      "epoch": 0.0464,
      "grad_norm": 14.486900329589844,
      "learning_rate": 9.846666666666667e-07,
      "logits/chosen": -2.221343994140625,
      "logits/rejected": -2.0165634155273438,
      "logps/chosen": -146.66693115234375,
      "logps/rejected": -107.51242065429688,
      "loss": 0.5988,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15962372720241547,
      "rewards/margins": 0.19892846047878265,
      "rewards/rejected": -0.03930473327636719,
      "step": 116
    },
    {
      "epoch": 0.0468,
      "grad_norm": 18.305198669433594,
      "learning_rate": 9.845333333333333e-07,
      "logits/chosen": -1.8502734899520874,
      "logits/rejected": -2.7396020889282227,
      "logps/chosen": -155.7273406982422,
      "logps/rejected": -120.23420715332031,
      "loss": 0.5519,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12648430466651917,
      "rewards/margins": 0.3064125180244446,
      "rewards/rejected": -0.17992821335792542,
      "step": 117
    },
    {
      "epoch": 0.0472,
      "grad_norm": 15.908095359802246,
      "learning_rate": 9.844e-07,
      "logits/chosen": -1.7377122640609741,
      "logits/rejected": -1.5911084413528442,
      "logps/chosen": -120.967041015625,
      "logps/rejected": -98.99386596679688,
      "loss": 0.6453,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04794349893927574,
      "rewards/margins": 0.0989101454615593,
      "rewards/rejected": -0.050966646522283554,
      "step": 118
    },
    {
      "epoch": 0.0476,
      "grad_norm": 15.962641716003418,
      "learning_rate": 9.842666666666666e-07,
      "logits/chosen": -1.6771297454833984,
      "logits/rejected": -2.0074148178100586,
      "logps/chosen": -139.32168579101562,
      "logps/rejected": -81.22798919677734,
      "loss": 0.5998,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17242127656936646,
      "rewards/margins": 0.19646377861499786,
      "rewards/rejected": -0.024042509496212006,
      "step": 119
    },
    {
      "epoch": 0.048,
      "grad_norm": 17.576963424682617,
      "learning_rate": 9.841333333333332e-07,
      "logits/chosen": -1.8365471363067627,
      "logits/rejected": -1.9910356998443604,
      "logps/chosen": -156.4036865234375,
      "logps/rejected": -99.62088012695312,
      "loss": 0.6486,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09878578782081604,
      "rewards/margins": 0.09112358093261719,
      "rewards/rejected": 0.007662201300263405,
      "step": 120
    },
    {
      "epoch": 0.0484,
      "grad_norm": 19.981935501098633,
      "learning_rate": 9.84e-07,
      "logits/chosen": -1.4530558586120605,
      "logits/rejected": -2.2601699829101562,
      "logps/chosen": -102.81451416015625,
      "logps/rejected": -117.30548095703125,
      "loss": 0.5956,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08140335232019424,
      "rewards/margins": 0.20608064532279968,
      "rewards/rejected": -0.12467728555202484,
      "step": 121
    },
    {
      "epoch": 0.0488,
      "grad_norm": 21.89099884033203,
      "learning_rate": 9.838666666666666e-07,
      "logits/chosen": -2.3285040855407715,
      "logits/rejected": -2.631226062774658,
      "logps/chosen": -274.4410095214844,
      "logps/rejected": -96.0296630859375,
      "loss": 0.5562,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20077896118164062,
      "rewards/margins": 0.2968257963657379,
      "rewards/rejected": -0.0960468277335167,
      "step": 122
    },
    {
      "epoch": 0.0492,
      "grad_norm": 19.490921020507812,
      "learning_rate": 9.837333333333334e-07,
      "logits/chosen": -2.6520438194274902,
      "logits/rejected": -2.310559034347534,
      "logps/chosen": -184.15594482421875,
      "logps/rejected": -172.6906280517578,
      "loss": 0.5817,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19271165132522583,
      "rewards/margins": 0.23771438002586365,
      "rewards/rejected": -0.04500274360179901,
      "step": 123
    },
    {
      "epoch": 0.0496,
      "grad_norm": 15.697385787963867,
      "learning_rate": 9.836e-07,
      "logits/chosen": -1.557201862335205,
      "logits/rejected": -2.0135326385498047,
      "logps/chosen": -103.99072265625,
      "logps/rejected": -91.6646957397461,
      "loss": 0.5952,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11811714619398117,
      "rewards/margins": 0.21274642646312714,
      "rewards/rejected": -0.09462929517030716,
      "step": 124
    },
    {
      "epoch": 0.05,
      "grad_norm": 13.952727317810059,
      "learning_rate": 9.834666666666666e-07,
      "logits/chosen": -1.929701328277588,
      "logits/rejected": -1.1438987255096436,
      "logps/chosen": -142.57223510742188,
      "logps/rejected": -82.155517578125,
      "loss": 0.5768,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19206085801124573,
      "rewards/margins": 0.2485988587141037,
      "rewards/rejected": -0.05653801187872887,
      "step": 125
    },
    {
      "epoch": 0.0504,
      "grad_norm": 15.0107421875,
      "learning_rate": 9.833333333333332e-07,
      "logits/chosen": -2.189079999923706,
      "logits/rejected": -2.02347993850708,
      "logps/chosen": -118.85124206542969,
      "logps/rejected": -90.61763000488281,
      "loss": 0.6432,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09380455315113068,
      "rewards/margins": 0.1029537245631218,
      "rewards/rejected": -0.00914916954934597,
      "step": 126
    },
    {
      "epoch": 0.0508,
      "grad_norm": 17.011873245239258,
      "learning_rate": 9.832e-07,
      "logits/chosen": -2.054011583328247,
      "logits/rejected": -2.403829574584961,
      "logps/chosen": -166.46905517578125,
      "logps/rejected": -87.9356689453125,
      "loss": 0.6325,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.058249667286872864,
      "rewards/margins": 0.12618140876293182,
      "rewards/rejected": -0.06793174892663956,
      "step": 127
    },
    {
      "epoch": 0.0512,
      "grad_norm": 11.702942848205566,
      "learning_rate": 9.830666666666665e-07,
      "logits/chosen": -1.3431546688079834,
      "logits/rejected": -1.3693511486053467,
      "logps/chosen": -101.6780776977539,
      "logps/rejected": -78.43663787841797,
      "loss": 0.6175,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1922042965888977,
      "rewards/margins": 0.157477006316185,
      "rewards/rejected": 0.03472728654742241,
      "step": 128
    },
    {
      "epoch": 0.0516,
      "grad_norm": 25.791763305664062,
      "learning_rate": 9.829333333333333e-07,
      "logits/chosen": -2.6555137634277344,
      "logits/rejected": -2.8192639350891113,
      "logps/chosen": -311.8077392578125,
      "logps/rejected": -145.9608612060547,
      "loss": 0.5698,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.208384707570076,
      "rewards/margins": 0.2727977931499481,
      "rewards/rejected": -0.06441307067871094,
      "step": 129
    },
    {
      "epoch": 0.052,
      "grad_norm": 15.89791202545166,
      "learning_rate": 9.828e-07,
      "logits/chosen": -1.8406221866607666,
      "logits/rejected": -1.9640171527862549,
      "logps/chosen": -139.01805114746094,
      "logps/rejected": -104.70498657226562,
      "loss": 0.5819,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15753594040870667,
      "rewards/margins": 0.23655778169631958,
      "rewards/rejected": -0.07902184128761292,
      "step": 130
    },
    {
      "epoch": 0.0524,
      "grad_norm": 14.179627418518066,
      "learning_rate": 9.826666666666667e-07,
      "logits/chosen": -1.7563591003417969,
      "logits/rejected": -1.4206898212432861,
      "logps/chosen": -129.05917358398438,
      "logps/rejected": -85.9144287109375,
      "loss": 0.5749,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1758296936750412,
      "rewards/margins": 0.25250929594039917,
      "rewards/rejected": -0.07667960971593857,
      "step": 131
    },
    {
      "epoch": 0.0528,
      "grad_norm": 14.063115119934082,
      "learning_rate": 9.825333333333333e-07,
      "logits/chosen": -2.0387840270996094,
      "logits/rejected": -1.6896064281463623,
      "logps/chosen": -179.62429809570312,
      "logps/rejected": -79.63372802734375,
      "loss": 0.576,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2864517271518707,
      "rewards/margins": 0.2516910433769226,
      "rewards/rejected": 0.03476066514849663,
      "step": 132
    },
    {
      "epoch": 0.0532,
      "grad_norm": 13.622482299804688,
      "learning_rate": 9.824e-07,
      "logits/chosen": -1.8548057079315186,
      "logits/rejected": -1.6043614149093628,
      "logps/chosen": -144.44952392578125,
      "logps/rejected": -83.07308959960938,
      "loss": 0.6573,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07315750420093536,
      "rewards/margins": 0.07394561916589737,
      "rewards/rejected": -0.0007881163619458675,
      "step": 133
    },
    {
      "epoch": 0.0536,
      "grad_norm": 19.27880096435547,
      "learning_rate": 9.822666666666665e-07,
      "logits/chosen": -2.188555955886841,
      "logits/rejected": -2.5962328910827637,
      "logps/chosen": -251.93218994140625,
      "logps/rejected": -136.022705078125,
      "loss": 0.6102,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1306350827217102,
      "rewards/margins": 0.17752686142921448,
      "rewards/rejected": -0.04689178615808487,
      "step": 134
    },
    {
      "epoch": 0.054,
      "grad_norm": 16.98014259338379,
      "learning_rate": 9.821333333333333e-07,
      "logits/chosen": -1.9756762981414795,
      "logits/rejected": -2.4651503562927246,
      "logps/chosen": -166.1409454345703,
      "logps/rejected": -118.79713439941406,
      "loss": 0.5748,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15307465195655823,
      "rewards/margins": 0.25335121154785156,
      "rewards/rejected": -0.10027657449245453,
      "step": 135
    },
    {
      "epoch": 0.0544,
      "grad_norm": 22.63155174255371,
      "learning_rate": 9.819999999999999e-07,
      "logits/chosen": -1.6490697860717773,
      "logits/rejected": -2.213749885559082,
      "logps/chosen": -114.50428771972656,
      "logps/rejected": -122.80213928222656,
      "loss": 0.5784,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17385903000831604,
      "rewards/margins": 0.24683494865894318,
      "rewards/rejected": -0.07297592610120773,
      "step": 136
    },
    {
      "epoch": 0.0548,
      "grad_norm": 15.556617736816406,
      "learning_rate": 9.818666666666667e-07,
      "logits/chosen": -1.60704505443573,
      "logits/rejected": -1.962072491645813,
      "logps/chosen": -111.97550201416016,
      "logps/rejected": -89.14640808105469,
      "loss": 0.5682,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1753585785627365,
      "rewards/margins": 0.2734626829624176,
      "rewards/rejected": -0.0981040969491005,
      "step": 137
    },
    {
      "epoch": 0.0552,
      "grad_norm": 12.877341270446777,
      "learning_rate": 9.817333333333333e-07,
      "logits/chosen": -1.8117485046386719,
      "logits/rejected": -2.168675184249878,
      "logps/chosen": -125.15906524658203,
      "logps/rejected": -77.50230407714844,
      "loss": 0.615,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12182235717773438,
      "rewards/margins": 0.1632007658481598,
      "rewards/rejected": -0.04137840121984482,
      "step": 138
    },
    {
      "epoch": 0.0556,
      "grad_norm": 19.220170974731445,
      "learning_rate": 9.816e-07,
      "logits/chosen": -2.188631296157837,
      "logits/rejected": -2.877505302429199,
      "logps/chosen": -187.6610107421875,
      "logps/rejected": -126.01800537109375,
      "loss": 0.5613,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16644859313964844,
      "rewards/margins": 0.28391990065574646,
      "rewards/rejected": -0.11747130751609802,
      "step": 139
    },
    {
      "epoch": 0.056,
      "grad_norm": 16.20087432861328,
      "learning_rate": 9.814666666666666e-07,
      "logits/chosen": -0.8425953388214111,
      "logits/rejected": -1.5475273132324219,
      "logps/chosen": -74.40362548828125,
      "logps/rejected": -89.17984008789062,
      "loss": 0.6714,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020931243896484375,
      "rewards/margins": 0.04391022026538849,
      "rewards/rejected": -0.022978972643613815,
      "step": 140
    },
    {
      "epoch": 0.0564,
      "grad_norm": 16.840490341186523,
      "learning_rate": 9.813333333333332e-07,
      "logits/chosen": -2.192967176437378,
      "logits/rejected": -2.0997726917266846,
      "logps/chosen": -205.1632537841797,
      "logps/rejected": -109.11978149414062,
      "loss": 0.5763,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25127488374710083,
      "rewards/margins": 0.2496509552001953,
      "rewards/rejected": 0.0016239164397120476,
      "step": 141
    },
    {
      "epoch": 0.0568,
      "grad_norm": 17.08500862121582,
      "learning_rate": 9.811999999999998e-07,
      "logits/chosen": -2.263871669769287,
      "logits/rejected": -2.0736634731292725,
      "logps/chosen": -207.9578857421875,
      "logps/rejected": -127.64493560791016,
      "loss": 0.5358,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2606254518032074,
      "rewards/margins": 0.34419745206832886,
      "rewards/rejected": -0.08357200771570206,
      "step": 142
    },
    {
      "epoch": 0.0572,
      "grad_norm": 18.429752349853516,
      "learning_rate": 9.810666666666666e-07,
      "logits/chosen": -2.571035861968994,
      "logits/rejected": -2.8539562225341797,
      "logps/chosen": -196.5228271484375,
      "logps/rejected": -128.70339965820312,
      "loss": 0.5437,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22439804673194885,
      "rewards/margins": 0.3252830505371094,
      "rewards/rejected": -0.10088501125574112,
      "step": 143
    },
    {
      "epoch": 0.0576,
      "grad_norm": 16.15090560913086,
      "learning_rate": 9.809333333333332e-07,
      "logits/chosen": -2.034083366394043,
      "logits/rejected": -2.313743829727173,
      "logps/chosen": -182.19390869140625,
      "logps/rejected": -132.27133178710938,
      "loss": 0.5807,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18238678574562073,
      "rewards/margins": 0.24390333890914917,
      "rewards/rejected": -0.061516571789979935,
      "step": 144
    },
    {
      "epoch": 0.058,
      "grad_norm": 18.955289840698242,
      "learning_rate": 9.808e-07,
      "logits/chosen": -1.7546772956848145,
      "logits/rejected": -3.003480911254883,
      "logps/chosen": -172.38414001464844,
      "logps/rejected": -153.219482421875,
      "loss": 0.5714,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19987717270851135,
      "rewards/margins": 0.2604011595249176,
      "rewards/rejected": -0.06052398681640625,
      "step": 145
    },
    {
      "epoch": 0.0584,
      "grad_norm": 16.100811004638672,
      "learning_rate": 9.806666666666666e-07,
      "logits/chosen": -1.650451421737671,
      "logits/rejected": -1.8339166641235352,
      "logps/chosen": -137.22622680664062,
      "logps/rejected": -108.16848754882812,
      "loss": 0.5691,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2737136781215668,
      "rewards/margins": 0.269461065530777,
      "rewards/rejected": 0.004252624697983265,
      "step": 146
    },
    {
      "epoch": 0.0588,
      "grad_norm": 16.062238693237305,
      "learning_rate": 9.805333333333334e-07,
      "logits/chosen": -2.0108327865600586,
      "logits/rejected": -1.9688408374786377,
      "logps/chosen": -147.32965087890625,
      "logps/rejected": -106.92489624023438,
      "loss": 0.5429,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2516532838344574,
      "rewards/margins": 0.3275165557861328,
      "rewards/rejected": -0.07586327195167542,
      "step": 147
    },
    {
      "epoch": 0.0592,
      "grad_norm": 19.41815185546875,
      "learning_rate": 9.804e-07,
      "logits/chosen": -1.88361656665802,
      "logits/rejected": -2.537898063659668,
      "logps/chosen": -164.31126403808594,
      "logps/rejected": -124.55421447753906,
      "loss": 0.5687,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16668397188186646,
      "rewards/margins": 0.26656532287597656,
      "rewards/rejected": -0.0998813658952713,
      "step": 148
    },
    {
      "epoch": 0.0596,
      "grad_norm": 16.076560974121094,
      "learning_rate": 9.802666666666666e-07,
      "logits/chosen": -2.641026496887207,
      "logits/rejected": -1.3925323486328125,
      "logps/chosen": -173.63626098632812,
      "logps/rejected": -89.8122787475586,
      "loss": 0.5625,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22151756286621094,
      "rewards/margins": 0.2833747863769531,
      "rewards/rejected": -0.06185722351074219,
      "step": 149
    },
    {
      "epoch": 0.06,
      "grad_norm": 16.512855529785156,
      "learning_rate": 9.801333333333333e-07,
      "logits/chosen": -1.6614898443222046,
      "logits/rejected": -2.7015652656555176,
      "logps/chosen": -141.14886474609375,
      "logps/rejected": -127.87471771240234,
      "loss": 0.5778,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.202616885304451,
      "rewards/margins": 0.24678954482078552,
      "rewards/rejected": -0.04417266696691513,
      "step": 150
    },
    {
      "epoch": 0.0604,
      "grad_norm": 18.047340393066406,
      "learning_rate": 9.8e-07,
      "logits/chosen": -1.652674674987793,
      "logits/rejected": -2.7260563373565674,
      "logps/chosen": -194.11416625976562,
      "logps/rejected": -141.75668334960938,
      "loss": 0.5161,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3393501341342926,
      "rewards/margins": 0.39276808500289917,
      "rewards/rejected": -0.05341796949505806,
      "step": 151
    },
    {
      "epoch": 0.0608,
      "grad_norm": 14.638249397277832,
      "learning_rate": 9.798666666666665e-07,
      "logits/chosen": -1.8058282136917114,
      "logits/rejected": -2.0847957134246826,
      "logps/chosen": -132.90631103515625,
      "logps/rejected": -103.008056640625,
      "loss": 0.5548,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2041977047920227,
      "rewards/margins": 0.2990760803222656,
      "rewards/rejected": -0.09487839043140411,
      "step": 152
    },
    {
      "epoch": 0.0612,
      "grad_norm": 15.180319786071777,
      "learning_rate": 9.797333333333333e-07,
      "logits/chosen": -1.8054167032241821,
      "logits/rejected": -1.2182873487472534,
      "logps/chosen": -104.54069519042969,
      "logps/rejected": -79.49069213867188,
      "loss": 0.5733,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20556221902370453,
      "rewards/margins": 0.2564014494419098,
      "rewards/rejected": -0.05083923414349556,
      "step": 153
    },
    {
      "epoch": 0.0616,
      "grad_norm": 12.9650239944458,
      "learning_rate": 9.796e-07,
      "logits/chosen": -2.1349174976348877,
      "logits/rejected": -1.8102164268493652,
      "logps/chosen": -129.23423767089844,
      "logps/rejected": -79.31046295166016,
      "loss": 0.5921,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08696365356445312,
      "rewards/margins": 0.2139057219028473,
      "rewards/rejected": -0.12694206833839417,
      "step": 154
    },
    {
      "epoch": 0.062,
      "grad_norm": 15.669412612915039,
      "learning_rate": 9.794666666666667e-07,
      "logits/chosen": -1.8290032148361206,
      "logits/rejected": -2.4571051597595215,
      "logps/chosen": -142.26760864257812,
      "logps/rejected": -111.42227172851562,
      "loss": 0.5143,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1999797821044922,
      "rewards/margins": 0.4084823727607727,
      "rewards/rejected": -0.20850259065628052,
      "step": 155
    },
    {
      "epoch": 0.0624,
      "grad_norm": 14.61257553100586,
      "learning_rate": 9.793333333333333e-07,
      "logits/chosen": -1.7019667625427246,
      "logits/rejected": -2.0564043521881104,
      "logps/chosen": -126.24273681640625,
      "logps/rejected": -111.01832580566406,
      "loss": 0.5895,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2014152556657791,
      "rewards/margins": 0.2200828492641449,
      "rewards/rejected": -0.01866760291159153,
      "step": 156
    },
    {
      "epoch": 0.0628,
      "grad_norm": 16.338693618774414,
      "learning_rate": 9.791999999999999e-07,
      "logits/chosen": -2.012239456176758,
      "logits/rejected": -2.1166462898254395,
      "logps/chosen": -146.27285766601562,
      "logps/rejected": -111.22502136230469,
      "loss": 0.6308,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14533615112304688,
      "rewards/margins": 0.13078002631664276,
      "rewards/rejected": 0.01455612201243639,
      "step": 157
    },
    {
      "epoch": 0.0632,
      "grad_norm": 16.779497146606445,
      "learning_rate": 9.790666666666667e-07,
      "logits/chosen": -1.960517168045044,
      "logits/rejected": -2.7365355491638184,
      "logps/chosen": -151.17686462402344,
      "logps/rejected": -145.17361450195312,
      "loss": 0.516,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2662929594516754,
      "rewards/margins": 0.39287757873535156,
      "rewards/rejected": -0.12658463418483734,
      "step": 158
    },
    {
      "epoch": 0.0636,
      "grad_norm": 11.858336448669434,
      "learning_rate": 9.789333333333333e-07,
      "logits/chosen": -2.1855359077453613,
      "logits/rejected": -1.7295805215835571,
      "logps/chosen": -110.62324523925781,
      "logps/rejected": -82.30279541015625,
      "loss": 0.6174,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13471832871437073,
      "rewards/margins": 0.16103097796440125,
      "rewards/rejected": -0.026312638074159622,
      "step": 159
    },
    {
      "epoch": 0.064,
      "grad_norm": 17.028392791748047,
      "learning_rate": 9.788e-07,
      "logits/chosen": -2.2083301544189453,
      "logits/rejected": -2.9642767906188965,
      "logps/chosen": -227.50674438476562,
      "logps/rejected": -107.16842651367188,
      "loss": 0.5259,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33281248807907104,
      "rewards/margins": 0.36922532320022583,
      "rewards/rejected": -0.036412812769412994,
      "step": 160
    },
    {
      "epoch": 0.0644,
      "grad_norm": 17.649633407592773,
      "learning_rate": 9.786666666666666e-07,
      "logits/chosen": -1.765994906425476,
      "logits/rejected": -1.3423244953155518,
      "logps/chosen": -110.0899429321289,
      "logps/rejected": -100.90400695800781,
      "loss": 0.5782,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1041717529296875,
      "rewards/margins": 0.24951058626174927,
      "rewards/rejected": -0.14533881843090057,
      "step": 161
    },
    {
      "epoch": 0.0648,
      "grad_norm": 12.647132873535156,
      "learning_rate": 9.785333333333332e-07,
      "logits/chosen": -2.211967945098877,
      "logits/rejected": -2.005005359649658,
      "logps/chosen": -111.91612243652344,
      "logps/rejected": -89.70962524414062,
      "loss": 0.5165,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2811824679374695,
      "rewards/margins": 0.3919239044189453,
      "rewards/rejected": -0.11074142903089523,
      "step": 162
    },
    {
      "epoch": 0.0652,
      "grad_norm": 16.61075210571289,
      "learning_rate": 9.784e-07,
      "logits/chosen": -2.4071669578552246,
      "logits/rejected": -2.184173107147217,
      "logps/chosen": -173.39834594726562,
      "logps/rejected": -117.89629364013672,
      "loss": 0.5164,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3299964964389801,
      "rewards/margins": 0.392190158367157,
      "rewards/rejected": -0.06219368055462837,
      "step": 163
    },
    {
      "epoch": 0.0656,
      "grad_norm": 19.198423385620117,
      "learning_rate": 9.782666666666666e-07,
      "logits/chosen": -1.9441978931427002,
      "logits/rejected": -2.3099210262298584,
      "logps/chosen": -123.56977081298828,
      "logps/rejected": -107.15276336669922,
      "loss": 0.5267,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2631179988384247,
      "rewards/margins": 0.36734962463378906,
      "rewards/rejected": -0.10423164814710617,
      "step": 164
    },
    {
      "epoch": 0.066,
      "grad_norm": 19.69503402709961,
      "learning_rate": 9.781333333333332e-07,
      "logits/chosen": -2.1997952461242676,
      "logits/rejected": -2.33231520652771,
      "logps/chosen": -174.5355224609375,
      "logps/rejected": -100.70094299316406,
      "loss": 0.5456,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.273651123046875,
      "rewards/margins": 0.3210411071777344,
      "rewards/rejected": -0.047389984130859375,
      "step": 165
    },
    {
      "epoch": 0.0664,
      "grad_norm": 19.390872955322266,
      "learning_rate": 9.78e-07,
      "logits/chosen": -1.8328014612197876,
      "logits/rejected": -2.6837551593780518,
      "logps/chosen": -182.2578582763672,
      "logps/rejected": -102.48872375488281,
      "loss": 0.5862,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2382461577653885,
      "rewards/margins": 0.2267223298549652,
      "rewards/rejected": 0.011523818597197533,
      "step": 166
    },
    {
      "epoch": 0.0668,
      "grad_norm": 11.696626663208008,
      "learning_rate": 9.778666666666666e-07,
      "logits/chosen": -1.4906256198883057,
      "logits/rejected": -1.4851430654525757,
      "logps/chosen": -91.81202697753906,
      "logps/rejected": -75.73088073730469,
      "loss": 0.5813,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17421264946460724,
      "rewards/margins": 0.23778611421585083,
      "rewards/rejected": -0.063573457300663,
      "step": 167
    },
    {
      "epoch": 0.0672,
      "grad_norm": 15.718013763427734,
      "learning_rate": 9.777333333333334e-07,
      "logits/chosen": -1.5250873565673828,
      "logits/rejected": -1.8478777408599854,
      "logps/chosen": -88.44502258300781,
      "logps/rejected": -95.0108871459961,
      "loss": 0.5783,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15121689438819885,
      "rewards/margins": 0.25579607486724854,
      "rewards/rejected": -0.10457916557788849,
      "step": 168
    },
    {
      "epoch": 0.0676,
      "grad_norm": 15.467487335205078,
      "learning_rate": 9.776e-07,
      "logits/chosen": -1.7737884521484375,
      "logits/rejected": -2.1716063022613525,
      "logps/chosen": -148.76531982421875,
      "logps/rejected": -96.52543640136719,
      "loss": 0.5815,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14743728935718536,
      "rewards/margins": 0.23884201049804688,
      "rewards/rejected": -0.09140472114086151,
      "step": 169
    },
    {
      "epoch": 0.068,
      "grad_norm": 11.654568672180176,
      "learning_rate": 9.774666666666668e-07,
      "logits/chosen": -1.7390048503875732,
      "logits/rejected": -1.4214506149291992,
      "logps/chosen": -107.29423522949219,
      "logps/rejected": -104.99266052246094,
      "loss": 0.5643,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27152901887893677,
      "rewards/margins": 0.28374141454696655,
      "rewards/rejected": -0.012212377041578293,
      "step": 170
    },
    {
      "epoch": 0.0684,
      "grad_norm": 14.616536140441895,
      "learning_rate": 9.773333333333333e-07,
      "logits/chosen": -1.59368896484375,
      "logits/rejected": -2.0859522819519043,
      "logps/chosen": -109.82626342773438,
      "logps/rejected": -105.86161804199219,
      "loss": 0.5249,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13855209946632385,
      "rewards/margins": 0.371524453163147,
      "rewards/rejected": -0.23297233879566193,
      "step": 171
    },
    {
      "epoch": 0.0688,
      "grad_norm": 19.789323806762695,
      "learning_rate": 9.772e-07,
      "logits/chosen": -2.1503982543945312,
      "logits/rejected": -2.3471133708953857,
      "logps/chosen": -146.87960815429688,
      "logps/rejected": -129.30630493164062,
      "loss": 0.509,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22852478921413422,
      "rewards/margins": 0.4104183316230774,
      "rewards/rejected": -0.18189354240894318,
      "step": 172
    },
    {
      "epoch": 0.0692,
      "grad_norm": 14.606046676635742,
      "learning_rate": 9.770666666666665e-07,
      "logits/chosen": -2.170980215072632,
      "logits/rejected": -1.9674601554870605,
      "logps/chosen": -205.819091796875,
      "logps/rejected": -96.16998291015625,
      "loss": 0.453,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4504402279853821,
      "rewards/margins": 0.5569747686386108,
      "rewards/rejected": -0.10653457790613174,
      "step": 173
    },
    {
      "epoch": 0.0696,
      "grad_norm": 15.157222747802734,
      "learning_rate": 9.769333333333333e-07,
      "logits/chosen": -2.074598550796509,
      "logits/rejected": -2.364358901977539,
      "logps/chosen": -222.5376739501953,
      "logps/rejected": -106.90171813964844,
      "loss": 0.4868,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4048721194267273,
      "rewards/margins": 0.4714488983154297,
      "rewards/rejected": -0.0665767639875412,
      "step": 174
    },
    {
      "epoch": 0.07,
      "grad_norm": 15.200950622558594,
      "learning_rate": 9.768e-07,
      "logits/chosen": -2.084573745727539,
      "logits/rejected": -1.6992114782333374,
      "logps/chosen": -138.96473693847656,
      "logps/rejected": -107.50279235839844,
      "loss": 0.5341,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3280777037143707,
      "rewards/margins": 0.3486618101596832,
      "rewards/rejected": -0.02058410830795765,
      "step": 175
    },
    {
      "epoch": 0.0704,
      "grad_norm": 16.123685836791992,
      "learning_rate": 9.766666666666667e-07,
      "logits/chosen": -1.7355825901031494,
      "logits/rejected": -2.3261115550994873,
      "logps/chosen": -120.07325744628906,
      "logps/rejected": -138.27145385742188,
      "loss": 0.5981,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12051849067211151,
      "rewards/margins": 0.2023494690656662,
      "rewards/rejected": -0.08183097839355469,
      "step": 176
    },
    {
      "epoch": 0.0708,
      "grad_norm": 15.511720657348633,
      "learning_rate": 9.765333333333333e-07,
      "logits/chosen": -2.244464159011841,
      "logits/rejected": -2.4061684608459473,
      "logps/chosen": -158.6040802001953,
      "logps/rejected": -134.68585205078125,
      "loss": 0.4694,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.315390020608902,
      "rewards/margins": 0.5143744945526123,
      "rewards/rejected": -0.1989845335483551,
      "step": 177
    },
    {
      "epoch": 0.0712,
      "grad_norm": 15.288220405578613,
      "learning_rate": 9.764e-07,
      "logits/chosen": -1.8441169261932373,
      "logits/rejected": -1.5067811012268066,
      "logps/chosen": -92.47331237792969,
      "logps/rejected": -82.22018432617188,
      "loss": 0.5645,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14815406501293182,
      "rewards/margins": 0.277688205242157,
      "rewards/rejected": -0.12953415513038635,
      "step": 178
    },
    {
      "epoch": 0.0716,
      "grad_norm": 14.865889549255371,
      "learning_rate": 9.762666666666667e-07,
      "logits/chosen": -1.8147497177124023,
      "logits/rejected": -2.1655097007751465,
      "logps/chosen": -120.60774993896484,
      "logps/rejected": -118.31983947753906,
      "loss": 0.5231,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32050856947898865,
      "rewards/margins": 0.3774387240409851,
      "rewards/rejected": -0.05693016201257706,
      "step": 179
    },
    {
      "epoch": 0.072,
      "grad_norm": 16.678058624267578,
      "learning_rate": 9.761333333333333e-07,
      "logits/chosen": -1.527198076248169,
      "logits/rejected": -2.0419836044311523,
      "logps/chosen": -150.2867431640625,
      "logps/rejected": -95.1392822265625,
      "loss": 0.5809,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17415352165699005,
      "rewards/margins": 0.243072509765625,
      "rewards/rejected": -0.06891899555921555,
      "step": 180
    },
    {
      "epoch": 0.0724,
      "grad_norm": 19.896114349365234,
      "learning_rate": 9.759999999999998e-07,
      "logits/chosen": -2.090074300765991,
      "logits/rejected": -2.952662467956543,
      "logps/chosen": -208.0070037841797,
      "logps/rejected": -179.32958984375,
      "loss": 0.4718,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.37166786193847656,
      "rewards/margins": 0.5062954425811768,
      "rewards/rejected": -0.1346275359392166,
      "step": 181
    },
    {
      "epoch": 0.0728,
      "grad_norm": 13.993875503540039,
      "learning_rate": 9.758666666666666e-07,
      "logits/chosen": -1.824662446975708,
      "logits/rejected": -1.7559947967529297,
      "logps/chosen": -125.5269775390625,
      "logps/rejected": -96.40750885009766,
      "loss": 0.541,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2263568937778473,
      "rewards/margins": 0.3320114016532898,
      "rewards/rejected": -0.1056545227766037,
      "step": 182
    },
    {
      "epoch": 0.0732,
      "grad_norm": 14.98769760131836,
      "learning_rate": 9.757333333333332e-07,
      "logits/chosen": -1.9969737529754639,
      "logits/rejected": -1.7142882347106934,
      "logps/chosen": -133.49554443359375,
      "logps/rejected": -96.38359069824219,
      "loss": 0.5051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.292227178812027,
      "rewards/margins": 0.42026978731155396,
      "rewards/rejected": -0.12804260849952698,
      "step": 183
    },
    {
      "epoch": 0.0736,
      "grad_norm": 15.131768226623535,
      "learning_rate": 9.756e-07,
      "logits/chosen": -2.0803496837615967,
      "logits/rejected": -2.287137985229492,
      "logps/chosen": -242.0331573486328,
      "logps/rejected": -98.29158020019531,
      "loss": 0.489,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4122089445590973,
      "rewards/margins": 0.4962169826030731,
      "rewards/rejected": -0.08400802314281464,
      "step": 184
    },
    {
      "epoch": 0.074,
      "grad_norm": 15.406317710876465,
      "learning_rate": 9.754666666666666e-07,
      "logits/chosen": -2.240523338317871,
      "logits/rejected": -1.7456936836242676,
      "logps/chosen": -185.1173553466797,
      "logps/rejected": -115.43141174316406,
      "loss": 0.4272,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4454086422920227,
      "rewards/margins": 0.6339473724365234,
      "rewards/rejected": -0.18853874504566193,
      "step": 185
    },
    {
      "epoch": 0.0744,
      "grad_norm": 13.471597671508789,
      "learning_rate": 9.753333333333334e-07,
      "logits/chosen": -2.3313302993774414,
      "logits/rejected": -1.7066056728363037,
      "logps/chosen": -158.2538604736328,
      "logps/rejected": -96.03717803955078,
      "loss": 0.4857,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3834671080112457,
      "rewards/margins": 0.47373849153518677,
      "rewards/rejected": -0.09027137607336044,
      "step": 186
    },
    {
      "epoch": 0.0748,
      "grad_norm": 15.715229034423828,
      "learning_rate": 9.752e-07,
      "logits/chosen": -1.854846477508545,
      "logits/rejected": -2.0235133171081543,
      "logps/chosen": -151.14126586914062,
      "logps/rejected": -105.80384063720703,
      "loss": 0.5049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2543777525424957,
      "rewards/margins": 0.42098045349121094,
      "rewards/rejected": -0.1666027009487152,
      "step": 187
    },
    {
      "epoch": 0.0752,
      "grad_norm": 15.894173622131348,
      "learning_rate": 9.750666666666666e-07,
      "logits/chosen": -1.9996623992919922,
      "logits/rejected": -1.3001651763916016,
      "logps/chosen": -119.51295471191406,
      "logps/rejected": -76.61112976074219,
      "loss": 0.5411,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.158488467335701,
      "rewards/margins": 0.33609312772750854,
      "rewards/rejected": -0.17760467529296875,
      "step": 188
    },
    {
      "epoch": 0.0756,
      "grad_norm": 14.249238967895508,
      "learning_rate": 9.749333333333332e-07,
      "logits/chosen": -2.0415666103363037,
      "logits/rejected": -2.5201871395111084,
      "logps/chosen": -168.14474487304688,
      "logps/rejected": -106.42434692382812,
      "loss": 0.469,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.44506949186325073,
      "rewards/margins": 0.5168560147285461,
      "rewards/rejected": -0.07178650051355362,
      "step": 189
    },
    {
      "epoch": 0.076,
      "grad_norm": 17.31495475769043,
      "learning_rate": 9.748e-07,
      "logits/chosen": -1.843214750289917,
      "logits/rejected": -1.8760234117507935,
      "logps/chosen": -125.88813781738281,
      "logps/rejected": -120.24752044677734,
      "loss": 0.5991,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17427712678909302,
      "rewards/margins": 0.20184290409088135,
      "rewards/rejected": -0.027565766125917435,
      "step": 190
    },
    {
      "epoch": 0.0764,
      "grad_norm": 17.70566749572754,
      "learning_rate": 9.746666666666666e-07,
      "logits/chosen": -2.205873966217041,
      "logits/rejected": -2.0358760356903076,
      "logps/chosen": -162.6166534423828,
      "logps/rejected": -99.768310546875,
      "loss": 0.478,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.28176918625831604,
      "rewards/margins": 0.4903907775878906,
      "rewards/rejected": -0.20862160623073578,
      "step": 191
    },
    {
      "epoch": 0.0768,
      "grad_norm": 12.92448616027832,
      "learning_rate": 9.745333333333334e-07,
      "logits/chosen": -1.5102382898330688,
      "logits/rejected": -1.3043839931488037,
      "logps/chosen": -117.97699737548828,
      "logps/rejected": -89.12928009033203,
      "loss": 0.6251,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11035384982824326,
      "rewards/margins": 0.14354248344898224,
      "rewards/rejected": -0.033188629895448685,
      "step": 192
    },
    {
      "epoch": 0.0772,
      "grad_norm": 16.93018341064453,
      "learning_rate": 9.744e-07,
      "logits/chosen": -2.0458381175994873,
      "logits/rejected": -1.1773983240127563,
      "logps/chosen": -206.13661193847656,
      "logps/rejected": -105.74281311035156,
      "loss": 0.4571,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4906959533691406,
      "rewards/margins": 0.5474452972412109,
      "rewards/rejected": -0.05674934387207031,
      "step": 193
    },
    {
      "epoch": 0.0776,
      "grad_norm": 19.97800064086914,
      "learning_rate": 9.742666666666665e-07,
      "logits/chosen": -1.6069295406341553,
      "logits/rejected": -1.716064453125,
      "logps/chosen": -96.5454330444336,
      "logps/rejected": -124.51791381835938,
      "loss": 0.5727,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24188080430030823,
      "rewards/margins": 0.2717094421386719,
      "rewards/rejected": -0.029828645288944244,
      "step": 194
    },
    {
      "epoch": 0.078,
      "grad_norm": 12.952960014343262,
      "learning_rate": 9.741333333333333e-07,
      "logits/chosen": -2.056898832321167,
      "logits/rejected": -1.7396833896636963,
      "logps/chosen": -159.60598754882812,
      "logps/rejected": -87.42559051513672,
      "loss": 0.4792,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35908928513526917,
      "rewards/margins": 0.4923160672187805,
      "rewards/rejected": -0.13322678208351135,
      "step": 195
    },
    {
      "epoch": 0.0784,
      "grad_norm": 14.311073303222656,
      "learning_rate": 9.74e-07,
      "logits/chosen": -1.9444609880447388,
      "logits/rejected": -2.2826600074768066,
      "logps/chosen": -135.68763732910156,
      "logps/rejected": -129.58062744140625,
      "loss": 0.5527,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17344476282596588,
      "rewards/margins": 0.3042759299278259,
      "rewards/rejected": -0.13083115220069885,
      "step": 196
    },
    {
      "epoch": 0.0788,
      "grad_norm": 16.00174331665039,
      "learning_rate": 9.738666666666667e-07,
      "logits/chosen": -1.9642858505249023,
      "logits/rejected": -1.9293482303619385,
      "logps/chosen": -150.9709930419922,
      "logps/rejected": -95.71429443359375,
      "loss": 0.445,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4788574278354645,
      "rewards/margins": 0.5793483853340149,
      "rewards/rejected": -0.10049095004796982,
      "step": 197
    },
    {
      "epoch": 0.0792,
      "grad_norm": 15.673871040344238,
      "learning_rate": 9.737333333333333e-07,
      "logits/chosen": -2.11210036277771,
      "logits/rejected": -2.029848337173462,
      "logps/chosen": -177.69149780273438,
      "logps/rejected": -94.47491455078125,
      "loss": 0.5444,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3459320068359375,
      "rewards/margins": 0.3243519067764282,
      "rewards/rejected": 0.021580124273896217,
      "step": 198
    },
    {
      "epoch": 0.0796,
      "grad_norm": 14.848771095275879,
      "learning_rate": 9.735999999999999e-07,
      "logits/chosen": -1.8076493740081787,
      "logits/rejected": -2.259716033935547,
      "logps/chosen": -152.45913696289062,
      "logps/rejected": -124.85626983642578,
      "loss": 0.4746,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.28693312406539917,
      "rewards/margins": 0.5019451379776001,
      "rewards/rejected": -0.21501198410987854,
      "step": 199
    },
    {
      "epoch": 0.08,
      "grad_norm": 14.82997989654541,
      "learning_rate": 9.734666666666667e-07,
      "logits/chosen": -1.857046365737915,
      "logits/rejected": -2.217176914215088,
      "logps/chosen": -162.9516143798828,
      "logps/rejected": -118.65200805664062,
      "loss": 0.4306,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.48549577593803406,
      "rewards/margins": 0.6249634027481079,
      "rewards/rejected": -0.13946762681007385,
      "step": 200
    },
    {
      "epoch": 0.0804,
      "grad_norm": 14.736102104187012,
      "learning_rate": 9.733333333333333e-07,
      "logits/chosen": -2.2667078971862793,
      "logits/rejected": -2.433317184448242,
      "logps/chosen": -177.34384155273438,
      "logps/rejected": -101.17034912109375,
      "loss": 0.4285,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.534613847732544,
      "rewards/margins": 0.6258449554443359,
      "rewards/rejected": -0.09123115241527557,
      "step": 201
    },
    {
      "epoch": 0.0808,
      "grad_norm": 12.882009506225586,
      "learning_rate": 9.731999999999998e-07,
      "logits/chosen": -2.2204251289367676,
      "logits/rejected": -1.6443371772766113,
      "logps/chosen": -168.23825073242188,
      "logps/rejected": -73.51646423339844,
      "loss": 0.4316,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4392665922641754,
      "rewards/margins": 0.6192005276679993,
      "rewards/rejected": -0.17993393540382385,
      "step": 202
    },
    {
      "epoch": 0.0812,
      "grad_norm": 14.241583824157715,
      "learning_rate": 9.730666666666666e-07,
      "logits/chosen": -1.9037933349609375,
      "logits/rejected": -1.9895234107971191,
      "logps/chosen": -101.24972534179688,
      "logps/rejected": -86.82413482666016,
      "loss": 0.5401,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22802506387233734,
      "rewards/margins": 0.3339744806289673,
      "rewards/rejected": -0.10594940185546875,
      "step": 203
    },
    {
      "epoch": 0.0816,
      "grad_norm": 16.731718063354492,
      "learning_rate": 9.729333333333332e-07,
      "logits/chosen": -2.3595635890960693,
      "logits/rejected": -1.6469991207122803,
      "logps/chosen": -121.2806167602539,
      "logps/rejected": -90.17388916015625,
      "loss": 0.4785,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14852866530418396,
      "rewards/margins": 0.48829346895217896,
      "rewards/rejected": -0.3397647738456726,
      "step": 204
    },
    {
      "epoch": 0.082,
      "grad_norm": 15.068917274475098,
      "learning_rate": 9.728e-07,
      "logits/chosen": -2.0658040046691895,
      "logits/rejected": -2.211104393005371,
      "logps/chosen": -153.06173706054688,
      "logps/rejected": -91.54537963867188,
      "loss": 0.5424,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19624672830104828,
      "rewards/margins": 0.3339042663574219,
      "rewards/rejected": -0.1376575529575348,
      "step": 205
    },
    {
      "epoch": 0.0824,
      "grad_norm": 11.88391399383545,
      "learning_rate": 9.726666666666666e-07,
      "logits/chosen": -2.4001708030700684,
      "logits/rejected": -2.201834201812744,
      "logps/chosen": -149.08433532714844,
      "logps/rejected": -89.62236022949219,
      "loss": 0.4921,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.354592889547348,
      "rewards/margins": 0.45856666564941406,
      "rewards/rejected": -0.10397377610206604,
      "step": 206
    },
    {
      "epoch": 0.0828,
      "grad_norm": 16.016521453857422,
      "learning_rate": 9.725333333333334e-07,
      "logits/chosen": -1.8883070945739746,
      "logits/rejected": -1.9385926723480225,
      "logps/chosen": -131.09130859375,
      "logps/rejected": -116.44227600097656,
      "loss": 0.4469,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33204424381256104,
      "rewards/margins": 0.5738884210586548,
      "rewards/rejected": -0.24184417724609375,
      "step": 207
    },
    {
      "epoch": 0.0832,
      "grad_norm": 12.821227073669434,
      "learning_rate": 9.724e-07,
      "logits/chosen": -1.6401491165161133,
      "logits/rejected": -1.812258243560791,
      "logps/chosen": -123.44853210449219,
      "logps/rejected": -89.39974975585938,
      "loss": 0.4968,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38880616426467896,
      "rewards/margins": 0.4450504183769226,
      "rewards/rejected": -0.05624427646398544,
      "step": 208
    },
    {
      "epoch": 0.0836,
      "grad_norm": 13.846927642822266,
      "learning_rate": 9.722666666666666e-07,
      "logits/chosen": -2.1907646656036377,
      "logits/rejected": -2.530543327331543,
      "logps/chosen": -157.84646606445312,
      "logps/rejected": -100.83956146240234,
      "loss": 0.4941,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.309347927570343,
      "rewards/margins": 0.4552879333496094,
      "rewards/rejected": -0.14594002068042755,
      "step": 209
    },
    {
      "epoch": 0.084,
      "grad_norm": 16.779155731201172,
      "learning_rate": 9.721333333333332e-07,
      "logits/chosen": -2.006211042404175,
      "logits/rejected": -1.9967141151428223,
      "logps/chosen": -143.937255859375,
      "logps/rejected": -128.22962951660156,
      "loss": 0.5251,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19099655747413635,
      "rewards/margins": 0.371829628944397,
      "rewards/rejected": -0.18083305656909943,
      "step": 210
    },
    {
      "epoch": 0.0844,
      "grad_norm": 16.147998809814453,
      "learning_rate": 9.72e-07,
      "logits/chosen": -2.2497398853302,
      "logits/rejected": -1.672083854675293,
      "logps/chosen": -176.862060546875,
      "logps/rejected": -110.10736846923828,
      "loss": 0.4752,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39635008573532104,
      "rewards/margins": 0.5049575567245483,
      "rewards/rejected": -0.10860748589038849,
      "step": 211
    },
    {
      "epoch": 0.0848,
      "grad_norm": 16.68891143798828,
      "learning_rate": 9.718666666666666e-07,
      "logits/chosen": -1.5778892040252686,
      "logits/rejected": -1.5080230236053467,
      "logps/chosen": -161.0042724609375,
      "logps/rejected": -94.73396301269531,
      "loss": 0.4299,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42661401629447937,
      "rewards/margins": 0.6246651411056519,
      "rewards/rejected": -0.1980510801076889,
      "step": 212
    },
    {
      "epoch": 0.0852,
      "grad_norm": 13.428424835205078,
      "learning_rate": 9.717333333333334e-07,
      "logits/chosen": -1.6321356296539307,
      "logits/rejected": -1.7972686290740967,
      "logps/chosen": -125.76956176757812,
      "logps/rejected": -112.60945892333984,
      "loss": 0.4655,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3437759578227997,
      "rewards/margins": 0.5366237759590149,
      "rewards/rejected": -0.1928478181362152,
      "step": 213
    },
    {
      "epoch": 0.0856,
      "grad_norm": 12.402342796325684,
      "learning_rate": 9.716e-07,
      "logits/chosen": -1.8785911798477173,
      "logits/rejected": -1.6035146713256836,
      "logps/chosen": -106.28009796142578,
      "logps/rejected": -86.62583923339844,
      "loss": 0.4859,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.331796258687973,
      "rewards/margins": 0.46982574462890625,
      "rewards/rejected": -0.13802948594093323,
      "step": 214
    },
    {
      "epoch": 0.086,
      "grad_norm": 18.293663024902344,
      "learning_rate": 9.714666666666667e-07,
      "logits/chosen": -2.300957679748535,
      "logits/rejected": -2.326000690460205,
      "logps/chosen": -195.41734313964844,
      "logps/rejected": -103.15274810791016,
      "loss": 0.5064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.28258171677589417,
      "rewards/margins": 0.41882896423339844,
      "rewards/rejected": -0.13624724745750427,
      "step": 215
    },
    {
      "epoch": 0.0864,
      "grad_norm": 18.159160614013672,
      "learning_rate": 9.713333333333333e-07,
      "logits/chosen": -2.253613233566284,
      "logits/rejected": -2.6576449871063232,
      "logps/chosen": -147.88206481933594,
      "logps/rejected": -166.6992950439453,
      "loss": 0.4277,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3695465326309204,
      "rewards/margins": 0.6470695734024048,
      "rewards/rejected": -0.2775230407714844,
      "step": 216
    },
    {
      "epoch": 0.0868,
      "grad_norm": 15.261011123657227,
      "learning_rate": 9.712e-07,
      "logits/chosen": -1.8707119226455688,
      "logits/rejected": -1.9900498390197754,
      "logps/chosen": -174.16351318359375,
      "logps/rejected": -166.2998046875,
      "loss": 0.4062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5838775634765625,
      "rewards/margins": 0.699601411819458,
      "rewards/rejected": -0.11572380363941193,
      "step": 217
    },
    {
      "epoch": 0.0872,
      "grad_norm": 17.32415771484375,
      "learning_rate": 9.710666666666665e-07,
      "logits/chosen": -1.9045389890670776,
      "logits/rejected": -2.2801499366760254,
      "logps/chosen": -150.41754150390625,
      "logps/rejected": -95.56461334228516,
      "loss": 0.4847,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3257896304130554,
      "rewards/margins": 0.4723087251186371,
      "rewards/rejected": -0.14651909470558167,
      "step": 218
    },
    {
      "epoch": 0.0876,
      "grad_norm": 13.010327339172363,
      "learning_rate": 9.709333333333333e-07,
      "logits/chosen": -2.253253936767578,
      "logits/rejected": -1.780455231666565,
      "logps/chosen": -144.5403289794922,
      "logps/rejected": -114.48267364501953,
      "loss": 0.4978,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4547683596611023,
      "rewards/margins": 0.4425193667411804,
      "rewards/rejected": 0.012248992919921875,
      "step": 219
    },
    {
      "epoch": 0.088,
      "grad_norm": 14.240906715393066,
      "learning_rate": 9.707999999999999e-07,
      "logits/chosen": -2.1533291339874268,
      "logits/rejected": -2.270066738128662,
      "logps/chosen": -156.06695556640625,
      "logps/rejected": -120.27235412597656,
      "loss": 0.4045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4091266691684723,
      "rewards/margins": 0.7161449193954468,
      "rewards/rejected": -0.3070182800292969,
      "step": 220
    },
    {
      "epoch": 0.0884,
      "grad_norm": 15.02370548248291,
      "learning_rate": 9.706666666666667e-07,
      "logits/chosen": -2.0176281929016113,
      "logits/rejected": -2.130157470703125,
      "logps/chosen": -113.82833862304688,
      "logps/rejected": -124.34172058105469,
      "loss": 0.5231,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27414438128471375,
      "rewards/margins": 0.38011208176612854,
      "rewards/rejected": -0.10596771538257599,
      "step": 221
    },
    {
      "epoch": 0.0888,
      "grad_norm": 14.024950981140137,
      "learning_rate": 9.705333333333333e-07,
      "logits/chosen": -1.941678762435913,
      "logits/rejected": -2.318819522857666,
      "logps/chosen": -178.1046600341797,
      "logps/rejected": -105.17333221435547,
      "loss": 0.5269,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25038450956344604,
      "rewards/margins": 0.38955458998680115,
      "rewards/rejected": -0.1391700804233551,
      "step": 222
    },
    {
      "epoch": 0.0892,
      "grad_norm": 13.387491226196289,
      "learning_rate": 9.704e-07,
      "logits/chosen": -1.5315625667572021,
      "logits/rejected": -2.238101005554199,
      "logps/chosen": -118.40945434570312,
      "logps/rejected": -101.35859680175781,
      "loss": 0.4773,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24906808137893677,
      "rewards/margins": 0.49147874116897583,
      "rewards/rejected": -0.24241065979003906,
      "step": 223
    },
    {
      "epoch": 0.0896,
      "grad_norm": 14.968443870544434,
      "learning_rate": 9.702666666666666e-07,
      "logits/chosen": -2.2186012268066406,
      "logits/rejected": -1.6234768629074097,
      "logps/chosen": -198.57061767578125,
      "logps/rejected": -95.89431762695312,
      "loss": 0.4588,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4812244474887848,
      "rewards/margins": 0.5567028522491455,
      "rewards/rejected": -0.07547836750745773,
      "step": 224
    },
    {
      "epoch": 0.09,
      "grad_norm": 15.982439041137695,
      "learning_rate": 9.701333333333332e-07,
      "logits/chosen": -2.2798233032226562,
      "logits/rejected": -1.962646245956421,
      "logps/chosen": -166.54209899902344,
      "logps/rejected": -96.27203369140625,
      "loss": 0.4498,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4393013119697571,
      "rewards/margins": 0.5656677484512329,
      "rewards/rejected": -0.12636642158031464,
      "step": 225
    },
    {
      "epoch": 0.0904,
      "grad_norm": 14.837868690490723,
      "learning_rate": 9.7e-07,
      "logits/chosen": -1.6572561264038086,
      "logits/rejected": -2.1773009300231934,
      "logps/chosen": -103.69522857666016,
      "logps/rejected": -102.8018798828125,
      "loss": 0.4991,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.30112725496292114,
      "rewards/margins": 0.4387268126010895,
      "rewards/rejected": -0.13759955763816833,
      "step": 226
    },
    {
      "epoch": 0.0908,
      "grad_norm": 14.208680152893066,
      "learning_rate": 9.698666666666666e-07,
      "logits/chosen": -1.4208736419677734,
      "logits/rejected": -1.3328171968460083,
      "logps/chosen": -106.84479522705078,
      "logps/rejected": -80.41463470458984,
      "loss": 0.4664,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3593311309814453,
      "rewards/margins": 0.5286544561386108,
      "rewards/rejected": -0.16932335495948792,
      "step": 227
    },
    {
      "epoch": 0.0912,
      "grad_norm": 17.428030014038086,
      "learning_rate": 9.697333333333332e-07,
      "logits/chosen": -1.9049392938613892,
      "logits/rejected": -2.4695568084716797,
      "logps/chosen": -182.75888061523438,
      "logps/rejected": -135.72079467773438,
      "loss": 0.3717,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.46642762422561646,
      "rewards/margins": 0.8024986982345581,
      "rewards/rejected": -0.3360710144042969,
      "step": 228
    },
    {
      "epoch": 0.0916,
      "grad_norm": 17.37397003173828,
      "learning_rate": 9.696e-07,
      "logits/chosen": -2.140303611755371,
      "logits/rejected": -2.914701223373413,
      "logps/chosen": -164.29571533203125,
      "logps/rejected": -123.92433166503906,
      "loss": 0.395,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.29230424761772156,
      "rewards/margins": 0.7290370464324951,
      "rewards/rejected": -0.43673285841941833,
      "step": 229
    },
    {
      "epoch": 0.092,
      "grad_norm": 13.955336570739746,
      "learning_rate": 9.694666666666666e-07,
      "logits/chosen": -2.015725612640381,
      "logits/rejected": -2.167724132537842,
      "logps/chosen": -134.08160400390625,
      "logps/rejected": -95.20018005371094,
      "loss": 0.5033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3542465269565582,
      "rewards/margins": 0.4244880676269531,
      "rewards/rejected": -0.0702415481209755,
      "step": 230
    },
    {
      "epoch": 0.0924,
      "grad_norm": 17.08428955078125,
      "learning_rate": 9.693333333333334e-07,
      "logits/chosen": -1.942035436630249,
      "logits/rejected": -2.088365316390991,
      "logps/chosen": -120.11309051513672,
      "logps/rejected": -80.60171508789062,
      "loss": 0.4092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4403885006904602,
      "rewards/margins": 0.6894012689590454,
      "rewards/rejected": -0.249012753367424,
      "step": 231
    },
    {
      "epoch": 0.0928,
      "grad_norm": 18.178504943847656,
      "learning_rate": 9.692e-07,
      "logits/chosen": -2.576084613800049,
      "logits/rejected": -2.490009307861328,
      "logps/chosen": -228.98785400390625,
      "logps/rejected": -92.71510314941406,
      "loss": 0.4958,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4200836420059204,
      "rewards/margins": 0.44351959228515625,
      "rewards/rejected": -0.02343597449362278,
      "step": 232
    },
    {
      "epoch": 0.0932,
      "grad_norm": 14.501802444458008,
      "learning_rate": 9.690666666666666e-07,
      "logits/chosen": -2.1531410217285156,
      "logits/rejected": -2.4351577758789062,
      "logps/chosen": -179.93899536132812,
      "logps/rejected": -106.36511993408203,
      "loss": 0.3891,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5112098455429077,
      "rewards/margins": 0.7435615658760071,
      "rewards/rejected": -0.23235169053077698,
      "step": 233
    },
    {
      "epoch": 0.0936,
      "grad_norm": 13.428903579711914,
      "learning_rate": 9.689333333333334e-07,
      "logits/chosen": -2.0008480548858643,
      "logits/rejected": -2.3601698875427246,
      "logps/chosen": -158.54116821289062,
      "logps/rejected": -130.5196990966797,
      "loss": 0.3503,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5931060910224915,
      "rewards/margins": 0.8748180866241455,
      "rewards/rejected": -0.28171196579933167,
      "step": 234
    },
    {
      "epoch": 0.094,
      "grad_norm": 14.82013988494873,
      "learning_rate": 9.688e-07,
      "logits/chosen": -1.5637784004211426,
      "logits/rejected": -2.013777494430542,
      "logps/chosen": -93.13448333740234,
      "logps/rejected": -99.59672546386719,
      "loss": 0.4681,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20000076293945312,
      "rewards/margins": 0.5234672427177429,
      "rewards/rejected": -0.3234664797782898,
      "step": 235
    },
    {
      "epoch": 0.0944,
      "grad_norm": 17.690406799316406,
      "learning_rate": 9.686666666666667e-07,
      "logits/chosen": -2.3357632160186768,
      "logits/rejected": -2.152374267578125,
      "logps/chosen": -192.16802978515625,
      "logps/rejected": -97.89231872558594,
      "loss": 0.42,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.515192449092865,
      "rewards/margins": 0.6607521176338196,
      "rewards/rejected": -0.14555969834327698,
      "step": 236
    },
    {
      "epoch": 0.0948,
      "grad_norm": 11.723567008972168,
      "learning_rate": 9.685333333333333e-07,
      "logits/chosen": -1.92128586769104,
      "logits/rejected": -2.067342519760132,
      "logps/chosen": -124.56971740722656,
      "logps/rejected": -85.61102294921875,
      "loss": 0.4537,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5045673847198486,
      "rewards/margins": 0.5575062036514282,
      "rewards/rejected": -0.05293884128332138,
      "step": 237
    },
    {
      "epoch": 0.0952,
      "grad_norm": 16.076438903808594,
      "learning_rate": 9.684e-07,
      "logits/chosen": -2.256013870239258,
      "logits/rejected": -1.724149465560913,
      "logps/chosen": -214.64968872070312,
      "logps/rejected": -93.27490997314453,
      "loss": 0.4643,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.49576568603515625,
      "rewards/margins": 0.5262737274169922,
      "rewards/rejected": -0.030508041381835938,
      "step": 238
    },
    {
      "epoch": 0.0956,
      "grad_norm": 12.952951431274414,
      "learning_rate": 9.682666666666667e-07,
      "logits/chosen": -2.1350767612457275,
      "logits/rejected": -1.2335193157196045,
      "logps/chosen": -161.3805694580078,
      "logps/rejected": -79.20146942138672,
      "loss": 0.4553,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3854309320449829,
      "rewards/margins": 0.5510826110839844,
      "rewards/rejected": -0.16565170884132385,
      "step": 239
    },
    {
      "epoch": 0.096,
      "grad_norm": 13.834997177124023,
      "learning_rate": 9.681333333333333e-07,
      "logits/chosen": -1.8890717029571533,
      "logits/rejected": -2.007157564163208,
      "logps/chosen": -105.3575439453125,
      "logps/rejected": -116.54779815673828,
      "loss": 0.4798,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39406928420066833,
      "rewards/margins": 0.49736785888671875,
      "rewards/rejected": -0.10329856723546982,
      "step": 240
    },
    {
      "epoch": 0.0964,
      "grad_norm": 14.985712051391602,
      "learning_rate": 9.679999999999999e-07,
      "logits/chosen": -1.860418438911438,
      "logits/rejected": -2.181546449661255,
      "logps/chosen": -177.0812530517578,
      "logps/rejected": -113.07230377197266,
      "loss": 0.3429,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5864593982696533,
      "rewards/margins": 0.8941993713378906,
      "rewards/rejected": -0.3077400326728821,
      "step": 241
    },
    {
      "epoch": 0.0968,
      "grad_norm": 13.226746559143066,
      "learning_rate": 9.678666666666667e-07,
      "logits/chosen": -2.0790252685546875,
      "logits/rejected": -1.7745285034179688,
      "logps/chosen": -146.37181091308594,
      "logps/rejected": -101.08578491210938,
      "loss": 0.4113,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5695144534111023,
      "rewards/margins": 0.6761447787284851,
      "rewards/rejected": -0.10663032531738281,
      "step": 242
    },
    {
      "epoch": 0.0972,
      "grad_norm": 14.157883644104004,
      "learning_rate": 9.677333333333333e-07,
      "logits/chosen": -2.2719197273254395,
      "logits/rejected": -1.691918134689331,
      "logps/chosen": -149.65744018554688,
      "logps/rejected": -101.78333282470703,
      "loss": 0.4437,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32227858901023865,
      "rewards/margins": 0.6018452048301697,
      "rewards/rejected": -0.27956658601760864,
      "step": 243
    },
    {
      "epoch": 0.0976,
      "grad_norm": 16.863330841064453,
      "learning_rate": 9.676e-07,
      "logits/chosen": -1.6504204273223877,
      "logits/rejected": -2.2937865257263184,
      "logps/chosen": -104.95082092285156,
      "logps/rejected": -95.10338592529297,
      "loss": 0.4742,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16331520676612854,
      "rewards/margins": 0.5195053219795227,
      "rewards/rejected": -0.35619011521339417,
      "step": 244
    },
    {
      "epoch": 0.098,
      "grad_norm": 13.270169258117676,
      "learning_rate": 9.674666666666666e-07,
      "logits/chosen": -2.4256162643432617,
      "logits/rejected": -2.2663378715515137,
      "logps/chosen": -182.0302734375,
      "logps/rejected": -115.6131591796875,
      "loss": 0.3288,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7172187566757202,
      "rewards/margins": 0.9459270238876343,
      "rewards/rejected": -0.22870826721191406,
      "step": 245
    },
    {
      "epoch": 0.0984,
      "grad_norm": 18.02309799194336,
      "learning_rate": 9.673333333333332e-07,
      "logits/chosen": -2.6302289962768555,
      "logits/rejected": -2.5427021980285645,
      "logps/chosen": -277.4732666015625,
      "logps/rejected": -148.17173767089844,
      "loss": 0.4067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5911407470703125,
      "rewards/margins": 0.7089531421661377,
      "rewards/rejected": -0.11781235039234161,
      "step": 246
    },
    {
      "epoch": 0.0988,
      "grad_norm": 13.121500015258789,
      "learning_rate": 9.671999999999998e-07,
      "logits/chosen": -1.8138922452926636,
      "logits/rejected": -1.3967217206954956,
      "logps/chosen": -103.49849700927734,
      "logps/rejected": -85.5018310546875,
      "loss": 0.4916,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5319942235946655,
      "rewards/margins": 0.45793455839157104,
      "rewards/rejected": 0.07405968010425568,
      "step": 247
    },
    {
      "epoch": 0.0992,
      "grad_norm": 12.717131614685059,
      "learning_rate": 9.670666666666666e-07,
      "logits/chosen": -1.9978442192077637,
      "logits/rejected": -1.7970010042190552,
      "logps/chosen": -122.52836608886719,
      "logps/rejected": -106.88394165039062,
      "loss": 0.3877,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5129833221435547,
      "rewards/margins": 0.7671844959259033,
      "rewards/rejected": -0.25420114398002625,
      "step": 248
    },
    {
      "epoch": 0.0996,
      "grad_norm": 14.945093154907227,
      "learning_rate": 9.669333333333332e-07,
      "logits/chosen": -1.780381441116333,
      "logits/rejected": -2.645908832550049,
      "logps/chosen": -116.75480651855469,
      "logps/rejected": -105.56498718261719,
      "loss": 0.3741,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.591862142086029,
      "rewards/margins": 0.7907257080078125,
      "rewards/rejected": -0.19886359572410583,
      "step": 249
    },
    {
      "epoch": 0.1,
      "grad_norm": 12.660970687866211,
      "learning_rate": 9.668e-07,
      "logits/chosen": -1.7348272800445557,
      "logits/rejected": -2.2098636627197266,
      "logps/chosen": -121.22599029541016,
      "logps/rejected": -112.13688659667969,
      "loss": 0.5008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41399574279785156,
      "rewards/margins": 0.4388920068740845,
      "rewards/rejected": -0.02489623986184597,
      "step": 250
    },
    {
      "epoch": 0.1004,
      "grad_norm": 14.017123222351074,
      "learning_rate": 9.666666666666666e-07,
      "logits/chosen": -1.7260699272155762,
      "logits/rejected": -1.8862907886505127,
      "logps/chosen": -129.4001922607422,
      "logps/rejected": -100.81625366210938,
      "loss": 0.5105,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3612464964389801,
      "rewards/margins": 0.4105995297431946,
      "rewards/rejected": -0.04935302957892418,
      "step": 251
    },
    {
      "epoch": 0.1008,
      "grad_norm": 12.803179740905762,
      "learning_rate": 9.665333333333334e-07,
      "logits/chosen": -1.6699068546295166,
      "logits/rejected": -1.7115110158920288,
      "logps/chosen": -124.13719177246094,
      "logps/rejected": -90.83358764648438,
      "loss": 0.554,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2832580804824829,
      "rewards/margins": 0.3011035919189453,
      "rewards/rejected": -0.01784553751349449,
      "step": 252
    },
    {
      "epoch": 0.1012,
      "grad_norm": 13.48849868774414,
      "learning_rate": 9.664e-07,
      "logits/chosen": -2.3457536697387695,
      "logits/rejected": -2.6351468563079834,
      "logps/chosen": -189.88150024414062,
      "logps/rejected": -90.67217254638672,
      "loss": 0.4449,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5346351861953735,
      "rewards/margins": 0.5837607979774475,
      "rewards/rejected": -0.04912567138671875,
      "step": 253
    },
    {
      "epoch": 0.1016,
      "grad_norm": 11.36355209350586,
      "learning_rate": 9.662666666666668e-07,
      "logits/chosen": -2.135857105255127,
      "logits/rejected": -1.5216760635375977,
      "logps/chosen": -131.07232666015625,
      "logps/rejected": -101.21012878417969,
      "loss": 0.4552,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4482731223106384,
      "rewards/margins": 0.5981605648994446,
      "rewards/rejected": -0.14988747239112854,
      "step": 254
    },
    {
      "epoch": 0.102,
      "grad_norm": 12.444218635559082,
      "learning_rate": 9.661333333333331e-07,
      "logits/chosen": -1.4147748947143555,
      "logits/rejected": -1.6266463994979858,
      "logps/chosen": -98.68913269042969,
      "logps/rejected": -97.20632934570312,
      "loss": 0.3903,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4710426330566406,
      "rewards/margins": 0.7411762475967407,
      "rewards/rejected": -0.2701336145401001,
      "step": 255
    },
    {
      "epoch": 0.1024,
      "grad_norm": 11.75374698638916,
      "learning_rate": 9.66e-07,
      "logits/chosen": -1.8503799438476562,
      "logits/rejected": -0.6449410319328308,
      "logps/chosen": -117.7560806274414,
      "logps/rejected": -101.7578125,
      "loss": 0.5354,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32694053649902344,
      "rewards/margins": 0.3536338806152344,
      "rewards/rejected": -0.026693344116210938,
      "step": 256
    },
    {
      "epoch": 0.1028,
      "grad_norm": 15.933476448059082,
      "learning_rate": 9.658666666666665e-07,
      "logits/chosen": -1.4785983562469482,
      "logits/rejected": -2.14064884185791,
      "logps/chosen": -82.36963653564453,
      "logps/rejected": -162.23117065429688,
      "loss": 0.4988,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22802849113941193,
      "rewards/margins": 0.4367450773715973,
      "rewards/rejected": -0.20871660113334656,
      "step": 257
    },
    {
      "epoch": 0.1032,
      "grad_norm": 13.58607006072998,
      "learning_rate": 9.657333333333333e-07,
      "logits/chosen": -1.6574561595916748,
      "logits/rejected": -1.944331169128418,
      "logps/chosen": -90.38685607910156,
      "logps/rejected": -123.44944763183594,
      "loss": 0.4064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4194103479385376,
      "rewards/margins": 0.7000744342803955,
      "rewards/rejected": -0.2806640565395355,
      "step": 258
    },
    {
      "epoch": 0.1036,
      "grad_norm": 16.40294647216797,
      "learning_rate": 9.656e-07,
      "logits/chosen": -1.8118057250976562,
      "logits/rejected": -2.393745183944702,
      "logps/chosen": -143.25665283203125,
      "logps/rejected": -163.5789337158203,
      "loss": 0.4307,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41404953598976135,
      "rewards/margins": 0.6424552798271179,
      "rewards/rejected": -0.22840577363967896,
      "step": 259
    },
    {
      "epoch": 0.104,
      "grad_norm": 12.925787925720215,
      "learning_rate": 9.654666666666667e-07,
      "logits/chosen": -1.6314772367477417,
      "logits/rejected": -2.849891185760498,
      "logps/chosen": -125.13861083984375,
      "logps/rejected": -114.05514526367188,
      "loss": 0.4717,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4843147397041321,
      "rewards/margins": 0.512169599533081,
      "rewards/rejected": -0.02785491943359375,
      "step": 260
    },
    {
      "epoch": 0.1044,
      "grad_norm": 14.709826469421387,
      "learning_rate": 9.653333333333333e-07,
      "logits/chosen": -1.9443655014038086,
      "logits/rejected": -2.177612781524658,
      "logps/chosen": -161.83827209472656,
      "logps/rejected": -124.79002380371094,
      "loss": 0.4022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5565750002861023,
      "rewards/margins": 0.7045966982841492,
      "rewards/rejected": -0.14802169799804688,
      "step": 261
    },
    {
      "epoch": 0.1048,
      "grad_norm": 11.923142433166504,
      "learning_rate": 9.651999999999999e-07,
      "logits/chosen": -1.5806279182434082,
      "logits/rejected": -1.8267011642456055,
      "logps/chosen": -109.14571380615234,
      "logps/rejected": -106.8717041015625,
      "loss": 0.4414,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4895431697368622,
      "rewards/margins": 0.6323383450508118,
      "rewards/rejected": -0.14279517531394958,
      "step": 262
    },
    {
      "epoch": 0.1052,
      "grad_norm": 12.957624435424805,
      "learning_rate": 9.650666666666667e-07,
      "logits/chosen": -1.6351819038391113,
      "logits/rejected": -2.181095600128174,
      "logps/chosen": -119.09001922607422,
      "logps/rejected": -115.56104278564453,
      "loss": 0.4543,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22364579141139984,
      "rewards/margins": 0.5571655035018921,
      "rewards/rejected": -0.33351975679397583,
      "step": 263
    },
    {
      "epoch": 0.1056,
      "grad_norm": 14.71950626373291,
      "learning_rate": 9.649333333333333e-07,
      "logits/chosen": -1.5031843185424805,
      "logits/rejected": -2.155705213546753,
      "logps/chosen": -92.73391723632812,
      "logps/rejected": -108.80449676513672,
      "loss": 0.4393,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16787758469581604,
      "rewards/margins": 0.5957512259483337,
      "rewards/rejected": -0.4278736114501953,
      "step": 264
    },
    {
      "epoch": 0.106,
      "grad_norm": 12.255167961120605,
      "learning_rate": 9.647999999999999e-07,
      "logits/chosen": -2.1706669330596924,
      "logits/rejected": -1.5778170824050903,
      "logps/chosen": -169.06385803222656,
      "logps/rejected": -89.34149169921875,
      "loss": 0.3383,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7389877438545227,
      "rewards/margins": 0.9313598871231079,
      "rewards/rejected": -0.1923721432685852,
      "step": 265
    },
    {
      "epoch": 0.1064,
      "grad_norm": 12.810718536376953,
      "learning_rate": 9.646666666666666e-07,
      "logits/chosen": -2.113994598388672,
      "logits/rejected": -2.246091842651367,
      "logps/chosen": -141.31121826171875,
      "logps/rejected": -94.7398681640625,
      "loss": 0.4456,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24442750215530396,
      "rewards/margins": 0.5775673389434814,
      "rewards/rejected": -0.3331398069858551,
      "step": 266
    },
    {
      "epoch": 0.1068,
      "grad_norm": 12.814823150634766,
      "learning_rate": 9.645333333333332e-07,
      "logits/chosen": -2.577113151550293,
      "logits/rejected": -1.9904897212982178,
      "logps/chosen": -154.8084716796875,
      "logps/rejected": -95.49163055419922,
      "loss": 0.3742,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5887168645858765,
      "rewards/margins": 0.7901100516319275,
      "rewards/rejected": -0.20139312744140625,
      "step": 267
    },
    {
      "epoch": 0.1072,
      "grad_norm": 12.490878105163574,
      "learning_rate": 9.644e-07,
      "logits/chosen": -1.4608542919158936,
      "logits/rejected": -2.34346079826355,
      "logps/chosen": -87.32855987548828,
      "logps/rejected": -93.2695541381836,
      "loss": 0.431,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4067363739013672,
      "rewards/margins": 0.6186774969100952,
      "rewards/rejected": -0.21194115281105042,
      "step": 268
    },
    {
      "epoch": 0.1076,
      "grad_norm": 13.632731437683105,
      "learning_rate": 9.642666666666666e-07,
      "logits/chosen": -1.5706424713134766,
      "logits/rejected": -1.5374231338500977,
      "logps/chosen": -89.33229064941406,
      "logps/rejected": -75.82127380371094,
      "loss": 0.4167,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6319893002510071,
      "rewards/margins": 0.6601657867431641,
      "rewards/rejected": -0.028176497668027878,
      "step": 269
    },
    {
      "epoch": 0.108,
      "grad_norm": 13.949299812316895,
      "learning_rate": 9.641333333333332e-07,
      "logits/chosen": -2.299685478210449,
      "logits/rejected": -2.457095146179199,
      "logps/chosen": -180.1892547607422,
      "logps/rejected": -129.17735290527344,
      "loss": 0.3484,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5437561273574829,
      "rewards/margins": 0.9170010089874268,
      "rewards/rejected": -0.37324488162994385,
      "step": 270
    },
    {
      "epoch": 0.1084,
      "grad_norm": 13.616464614868164,
      "learning_rate": 9.64e-07,
      "logits/chosen": -1.808245062828064,
      "logits/rejected": -2.702030658721924,
      "logps/chosen": -105.7900619506836,
      "logps/rejected": -91.72907257080078,
      "loss": 0.4375,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5208076238632202,
      "rewards/margins": 0.605634331703186,
      "rewards/rejected": -0.08482666313648224,
      "step": 271
    },
    {
      "epoch": 0.1088,
      "grad_norm": 14.529186248779297,
      "learning_rate": 9.638666666666666e-07,
      "logits/chosen": -1.9646403789520264,
      "logits/rejected": -2.3881032466888428,
      "logps/chosen": -157.9747314453125,
      "logps/rejected": -126.92338562011719,
      "loss": 0.4478,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.360015869140625,
      "rewards/margins": 0.573615312576294,
      "rewards/rejected": -0.21359939873218536,
      "step": 272
    },
    {
      "epoch": 0.1092,
      "grad_norm": 16.15298843383789,
      "learning_rate": 9.637333333333334e-07,
      "logits/chosen": -2.059417486190796,
      "logits/rejected": -2.5135841369628906,
      "logps/chosen": -159.54086303710938,
      "logps/rejected": -153.89810180664062,
      "loss": 0.4112,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5374259948730469,
      "rewards/margins": 0.6776069402694702,
      "rewards/rejected": -0.14018097519874573,
      "step": 273
    },
    {
      "epoch": 0.1096,
      "grad_norm": 14.441097259521484,
      "learning_rate": 9.636e-07,
      "logits/chosen": -1.60220468044281,
      "logits/rejected": -2.8087642192840576,
      "logps/chosen": -160.77578735351562,
      "logps/rejected": -187.2012481689453,
      "loss": 0.388,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6046172976493835,
      "rewards/margins": 0.746899425983429,
      "rewards/rejected": -0.14228211343288422,
      "step": 274
    },
    {
      "epoch": 0.11,
      "grad_norm": 14.174406051635742,
      "learning_rate": 9.634666666666666e-07,
      "logits/chosen": -1.6434221267700195,
      "logits/rejected": -2.659200668334961,
      "logps/chosen": -109.69621276855469,
      "logps/rejected": -116.26573181152344,
      "loss": 0.5175,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24618759751319885,
      "rewards/margins": 0.3949470520019531,
      "rewards/rejected": -0.14875945448875427,
      "step": 275
    },
    {
      "epoch": 0.1104,
      "grad_norm": 13.706230163574219,
      "learning_rate": 9.633333333333334e-07,
      "logits/chosen": -1.96561861038208,
      "logits/rejected": -1.7666106224060059,
      "logps/chosen": -135.7518768310547,
      "logps/rejected": -99.56953430175781,
      "loss": 0.5474,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.227131649851799,
      "rewards/margins": 0.3184940218925476,
      "rewards/rejected": -0.0913623794913292,
      "step": 276
    },
    {
      "epoch": 0.1108,
      "grad_norm": 14.198793411254883,
      "learning_rate": 9.632e-07,
      "logits/chosen": -2.131075382232666,
      "logits/rejected": -2.222280979156494,
      "logps/chosen": -166.10751342773438,
      "logps/rejected": -111.48271179199219,
      "loss": 0.4293,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39697265625,
      "rewards/margins": 0.6355884671211243,
      "rewards/rejected": -0.23861581087112427,
      "step": 277
    },
    {
      "epoch": 0.1112,
      "grad_norm": 10.941250801086426,
      "learning_rate": 9.630666666666665e-07,
      "logits/chosen": -2.07045578956604,
      "logits/rejected": -1.7385600805282593,
      "logps/chosen": -143.64100646972656,
      "logps/rejected": -104.48219299316406,
      "loss": 0.3398,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7541378140449524,
      "rewards/margins": 0.9048290252685547,
      "rewards/rejected": -0.1506912261247635,
      "step": 278
    },
    {
      "epoch": 0.1116,
      "grad_norm": 16.170984268188477,
      "learning_rate": 9.629333333333333e-07,
      "logits/chosen": -2.4641847610473633,
      "logits/rejected": -2.96100115776062,
      "logps/chosen": -155.5049591064453,
      "logps/rejected": -128.6614532470703,
      "loss": 0.3496,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6048153042793274,
      "rewards/margins": 0.8883018493652344,
      "rewards/rejected": -0.28348657488822937,
      "step": 279
    },
    {
      "epoch": 0.112,
      "grad_norm": 10.861207008361816,
      "learning_rate": 9.628e-07,
      "logits/chosen": -1.5554205179214478,
      "logits/rejected": -1.966877818107605,
      "logps/chosen": -103.84083557128906,
      "logps/rejected": -93.73564147949219,
      "loss": 0.4011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4433143734931946,
      "rewards/margins": 0.7564064264297485,
      "rewards/rejected": -0.31309205293655396,
      "step": 280
    },
    {
      "epoch": 0.1124,
      "grad_norm": 16.86087989807129,
      "learning_rate": 9.626666666666667e-07,
      "logits/chosen": -2.0318076610565186,
      "logits/rejected": -2.2931957244873047,
      "logps/chosen": -121.47476196289062,
      "logps/rejected": -113.82978820800781,
      "loss": 0.6005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03026122972369194,
      "rewards/margins": 0.19605103135108948,
      "rewards/rejected": -0.16578979790210724,
      "step": 281
    },
    {
      "epoch": 0.1128,
      "grad_norm": 10.541813850402832,
      "learning_rate": 9.625333333333333e-07,
      "logits/chosen": -2.0686566829681396,
      "logits/rejected": -1.7719664573669434,
      "logps/chosen": -111.71642303466797,
      "logps/rejected": -79.50823211669922,
      "loss": 0.4039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6062930822372437,
      "rewards/margins": 0.7064918279647827,
      "rewards/rejected": -0.10019874572753906,
      "step": 282
    },
    {
      "epoch": 0.1132,
      "grad_norm": 15.196579933166504,
      "learning_rate": 9.624e-07,
      "logits/chosen": -1.823004961013794,
      "logits/rejected": -2.2738234996795654,
      "logps/chosen": -130.42620849609375,
      "logps/rejected": -137.06317138671875,
      "loss": 0.4314,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4289790987968445,
      "rewards/margins": 0.6248573064804077,
      "rewards/rejected": -0.19587822258472443,
      "step": 283
    },
    {
      "epoch": 0.1136,
      "grad_norm": 13.254646301269531,
      "learning_rate": 9.622666666666667e-07,
      "logits/chosen": -1.6032708883285522,
      "logits/rejected": -1.796459674835205,
      "logps/chosen": -105.35039520263672,
      "logps/rejected": -100.4823226928711,
      "loss": 0.4508,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4079548120498657,
      "rewards/margins": 0.5641731023788452,
      "rewards/rejected": -0.15621833503246307,
      "step": 284
    },
    {
      "epoch": 0.114,
      "grad_norm": 12.205452919006348,
      "learning_rate": 9.621333333333333e-07,
      "logits/chosen": -1.9285612106323242,
      "logits/rejected": -2.0166232585906982,
      "logps/chosen": -134.33636474609375,
      "logps/rejected": -114.4319076538086,
      "loss": 0.3633,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5674408078193665,
      "rewards/margins": 0.8448017239570618,
      "rewards/rejected": -0.2773609161376953,
      "step": 285
    },
    {
      "epoch": 0.1144,
      "grad_norm": 13.710352897644043,
      "learning_rate": 9.619999999999999e-07,
      "logits/chosen": -2.447223663330078,
      "logits/rejected": -1.9562852382659912,
      "logps/chosen": -229.28265380859375,
      "logps/rejected": -103.91162872314453,
      "loss": 0.316,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7774956226348877,
      "rewards/margins": 1.0263240337371826,
      "rewards/rejected": -0.24882851541042328,
      "step": 286
    },
    {
      "epoch": 0.1148,
      "grad_norm": 11.021951675415039,
      "learning_rate": 9.618666666666667e-07,
      "logits/chosen": -1.9942350387573242,
      "logits/rejected": -1.22480309009552,
      "logps/chosen": -119.92402648925781,
      "logps/rejected": -80.40452575683594,
      "loss": 0.4877,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.43754690885543823,
      "rewards/margins": 0.4660850465297699,
      "rewards/rejected": -0.028538133949041367,
      "step": 287
    },
    {
      "epoch": 0.1152,
      "grad_norm": 11.910274505615234,
      "learning_rate": 9.617333333333332e-07,
      "logits/chosen": -1.96437406539917,
      "logits/rejected": -1.9358832836151123,
      "logps/chosen": -135.69320678710938,
      "logps/rejected": -94.74333190917969,
      "loss": 0.4475,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5837554931640625,
      "rewards/margins": 0.6064090728759766,
      "rewards/rejected": -0.022653579711914062,
      "step": 288
    },
    {
      "epoch": 0.1156,
      "grad_norm": 12.223573684692383,
      "learning_rate": 9.616e-07,
      "logits/chosen": -2.1841092109680176,
      "logits/rejected": -2.469616413116455,
      "logps/chosen": -141.5284423828125,
      "logps/rejected": -119.0548095703125,
      "loss": 0.3472,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6530395746231079,
      "rewards/margins": 0.8791583776473999,
      "rewards/rejected": -0.22611886262893677,
      "step": 289
    },
    {
      "epoch": 0.116,
      "grad_norm": 9.239107131958008,
      "learning_rate": 9.614666666666666e-07,
      "logits/chosen": -1.969975471496582,
      "logits/rejected": -1.9230351448059082,
      "logps/chosen": -110.49855041503906,
      "logps/rejected": -75.00497436523438,
      "loss": 0.3356,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6847175359725952,
      "rewards/margins": 0.9320671558380127,
      "rewards/rejected": -0.2473495602607727,
      "step": 290
    },
    {
      "epoch": 0.1164,
      "grad_norm": 12.382530212402344,
      "learning_rate": 9.613333333333334e-07,
      "logits/chosen": -2.270829677581787,
      "logits/rejected": -2.456331968307495,
      "logps/chosen": -118.67245483398438,
      "logps/rejected": -88.2711181640625,
      "loss": 0.5034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39361533522605896,
      "rewards/margins": 0.44158250093460083,
      "rewards/rejected": -0.047967150807380676,
      "step": 291
    },
    {
      "epoch": 0.1168,
      "grad_norm": 17.528404235839844,
      "learning_rate": 9.612e-07,
      "logits/chosen": -2.2578470706939697,
      "logits/rejected": -1.6357388496398926,
      "logps/chosen": -219.80523681640625,
      "logps/rejected": -150.09262084960938,
      "loss": 0.3829,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5295112729072571,
      "rewards/margins": 0.7951278686523438,
      "rewards/rejected": -0.26561662554740906,
      "step": 292
    },
    {
      "epoch": 0.1172,
      "grad_norm": 11.938892364501953,
      "learning_rate": 9.610666666666666e-07,
      "logits/chosen": -1.9261858463287354,
      "logits/rejected": -2.4814350605010986,
      "logps/chosen": -155.42689514160156,
      "logps/rejected": -106.7828140258789,
      "loss": 0.374,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4703819453716278,
      "rewards/margins": 0.7906948328018188,
      "rewards/rejected": -0.32031288743019104,
      "step": 293
    },
    {
      "epoch": 0.1176,
      "grad_norm": 12.196470260620117,
      "learning_rate": 9.609333333333332e-07,
      "logits/chosen": -2.1155619621276855,
      "logits/rejected": -1.6123104095458984,
      "logps/chosen": -144.27293395996094,
      "logps/rejected": -110.16448211669922,
      "loss": 0.4257,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4105846583843231,
      "rewards/margins": 0.6906574964523315,
      "rewards/rejected": -0.28007280826568604,
      "step": 294
    },
    {
      "epoch": 0.118,
      "grad_norm": 14.276862144470215,
      "learning_rate": 9.608e-07,
      "logits/chosen": -1.6354470252990723,
      "logits/rejected": -2.095930576324463,
      "logps/chosen": -123.89559173583984,
      "logps/rejected": -106.47134399414062,
      "loss": 0.4381,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45509567856788635,
      "rewards/margins": 0.598432183265686,
      "rewards/rejected": -0.1433364897966385,
      "step": 295
    },
    {
      "epoch": 0.1184,
      "grad_norm": 14.819598197937012,
      "learning_rate": 9.606666666666666e-07,
      "logits/chosen": -1.9527920484542847,
      "logits/rejected": -2.4182543754577637,
      "logps/chosen": -115.63445281982422,
      "logps/rejected": -116.065673828125,
      "loss": 0.3461,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41061514616012573,
      "rewards/margins": 0.8945556282997131,
      "rewards/rejected": -0.4839405119419098,
      "step": 296
    },
    {
      "epoch": 0.1188,
      "grad_norm": 14.786139488220215,
      "learning_rate": 9.605333333333334e-07,
      "logits/chosen": -2.6746888160705566,
      "logits/rejected": -2.6630215644836426,
      "logps/chosen": -222.24911499023438,
      "logps/rejected": -87.84962463378906,
      "loss": 0.3554,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7071526050567627,
      "rewards/margins": 0.859463095664978,
      "rewards/rejected": -0.1523105651140213,
      "step": 297
    },
    {
      "epoch": 0.1192,
      "grad_norm": 16.786563873291016,
      "learning_rate": 9.604e-07,
      "logits/chosen": -2.3788492679595947,
      "logits/rejected": -2.739400625228882,
      "logps/chosen": -277.93994140625,
      "logps/rejected": -106.21590423583984,
      "loss": 0.3665,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.568804144859314,
      "rewards/margins": 0.8235050439834595,
      "rewards/rejected": -0.2547008693218231,
      "step": 298
    },
    {
      "epoch": 0.1196,
      "grad_norm": 14.5476713180542,
      "learning_rate": 9.602666666666667e-07,
      "logits/chosen": -2.568037509918213,
      "logits/rejected": -2.0788893699645996,
      "logps/chosen": -158.58004760742188,
      "logps/rejected": -107.69029235839844,
      "loss": 0.4625,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3375355005264282,
      "rewards/margins": 0.5526905059814453,
      "rewards/rejected": -0.21515503525733948,
      "step": 299
    },
    {
      "epoch": 0.12,
      "grad_norm": 12.40864372253418,
      "learning_rate": 9.601333333333333e-07,
      "logits/chosen": -2.3200607299804688,
      "logits/rejected": -2.2355618476867676,
      "logps/chosen": -164.9247283935547,
      "logps/rejected": -111.97676849365234,
      "loss": 0.3938,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5528885126113892,
      "rewards/margins": 0.8012443780899048,
      "rewards/rejected": -0.24835586547851562,
      "step": 300
    },
    {
      "epoch": 0.1204,
      "grad_norm": 10.663963317871094,
      "learning_rate": 9.6e-07,
      "logits/chosen": -2.020142078399658,
      "logits/rejected": -1.3340409994125366,
      "logps/chosen": -137.63560485839844,
      "logps/rejected": -73.5970687866211,
      "loss": 0.3668,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6810901761054993,
      "rewards/margins": 0.8139957189559937,
      "rewards/rejected": -0.13290557265281677,
      "step": 301
    },
    {
      "epoch": 0.1208,
      "grad_norm": 13.159858703613281,
      "learning_rate": 9.598666666666665e-07,
      "logits/chosen": -2.058608055114746,
      "logits/rejected": -1.8802704811096191,
      "logps/chosen": -167.01620483398438,
      "logps/rejected": -94.14705657958984,
      "loss": 0.35,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5670463442802429,
      "rewards/margins": 0.8715389370918274,
      "rewards/rejected": -0.3044925630092621,
      "step": 302
    },
    {
      "epoch": 0.1212,
      "grad_norm": 14.050731658935547,
      "learning_rate": 9.597333333333333e-07,
      "logits/chosen": -2.1952905654907227,
      "logits/rejected": -2.5662851333618164,
      "logps/chosen": -141.9801025390625,
      "logps/rejected": -181.38534545898438,
      "loss": 0.3053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7144893407821655,
      "rewards/margins": 1.0440860986709595,
      "rewards/rejected": -0.32959669828414917,
      "step": 303
    },
    {
      "epoch": 0.1216,
      "grad_norm": 12.985161781311035,
      "learning_rate": 9.595999999999999e-07,
      "logits/chosen": -2.288228750228882,
      "logits/rejected": -1.903712272644043,
      "logps/chosen": -198.84637451171875,
      "logps/rejected": -102.85623931884766,
      "loss": 0.3741,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7462104558944702,
      "rewards/margins": 0.7936439514160156,
      "rewards/rejected": -0.04743346944451332,
      "step": 304
    },
    {
      "epoch": 0.122,
      "grad_norm": 11.640898704528809,
      "learning_rate": 9.594666666666667e-07,
      "logits/chosen": -2.058647394180298,
      "logits/rejected": -2.224377155303955,
      "logps/chosen": -163.2994384765625,
      "logps/rejected": -105.71807098388672,
      "loss": 0.4207,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6801013946533203,
      "rewards/margins": 0.7357528209686279,
      "rewards/rejected": -0.055651478469371796,
      "step": 305
    },
    {
      "epoch": 0.1224,
      "grad_norm": 14.999980926513672,
      "learning_rate": 9.593333333333333e-07,
      "logits/chosen": -1.9643926620483398,
      "logits/rejected": -2.6374833583831787,
      "logps/chosen": -137.06289672851562,
      "logps/rejected": -122.50288391113281,
      "loss": 0.4377,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33203619718551636,
      "rewards/margins": 0.6025474667549133,
      "rewards/rejected": -0.270511269569397,
      "step": 306
    },
    {
      "epoch": 0.1228,
      "grad_norm": 14.916993141174316,
      "learning_rate": 9.592e-07,
      "logits/chosen": -1.9617637395858765,
      "logits/rejected": -2.258445978164673,
      "logps/chosen": -131.87094116210938,
      "logps/rejected": -93.09133911132812,
      "loss": 0.4291,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.492239385843277,
      "rewards/margins": 0.659641683101654,
      "rewards/rejected": -0.1674022674560547,
      "step": 307
    },
    {
      "epoch": 0.1232,
      "grad_norm": 11.987850189208984,
      "learning_rate": 9.590666666666667e-07,
      "logits/chosen": -2.1662557125091553,
      "logits/rejected": -2.093965530395508,
      "logps/chosen": -166.61483764648438,
      "logps/rejected": -157.8675537109375,
      "loss": 0.3608,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7445014715194702,
      "rewards/margins": 0.836090087890625,
      "rewards/rejected": -0.091588594019413,
      "step": 308
    },
    {
      "epoch": 0.1236,
      "grad_norm": 12.436102867126465,
      "learning_rate": 9.589333333333332e-07,
      "logits/chosen": -2.1055893898010254,
      "logits/rejected": -1.5288081169128418,
      "logps/chosen": -179.09536743164062,
      "logps/rejected": -99.20947265625,
      "loss": 0.2563,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9129433035850525,
      "rewards/margins": 1.2405757904052734,
      "rewards/rejected": -0.3276325464248657,
      "step": 309
    },
    {
      "epoch": 0.124,
      "grad_norm": 11.942190170288086,
      "learning_rate": 9.588e-07,
      "logits/chosen": -2.3960509300231934,
      "logits/rejected": -2.079711675643921,
      "logps/chosen": -187.5016326904297,
      "logps/rejected": -107.17412567138672,
      "loss": 0.2872,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8936004638671875,
      "rewards/margins": 1.2133773565292358,
      "rewards/rejected": -0.3197769224643707,
      "step": 310
    },
    {
      "epoch": 0.1244,
      "grad_norm": 11.078207969665527,
      "learning_rate": 9.586666666666666e-07,
      "logits/chosen": -1.915602684020996,
      "logits/rejected": -1.677961826324463,
      "logps/chosen": -115.867431640625,
      "logps/rejected": -93.24171447753906,
      "loss": 0.433,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6520645022392273,
      "rewards/margins": 0.6147556304931641,
      "rewards/rejected": 0.03730888292193413,
      "step": 311
    },
    {
      "epoch": 0.1248,
      "grad_norm": 10.957127571105957,
      "learning_rate": 9.585333333333332e-07,
      "logits/chosen": -2.038909912109375,
      "logits/rejected": -2.6339728832244873,
      "logps/chosen": -169.66282653808594,
      "logps/rejected": -127.91425323486328,
      "loss": 0.2622,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8870781064033508,
      "rewards/margins": 1.206984281539917,
      "rewards/rejected": -0.31990623474121094,
      "step": 312
    },
    {
      "epoch": 0.1252,
      "grad_norm": 9.657113075256348,
      "learning_rate": 9.584e-07,
      "logits/chosen": -2.0026679039001465,
      "logits/rejected": -1.0023781061172485,
      "logps/chosen": -130.56137084960938,
      "logps/rejected": -72.73910522460938,
      "loss": 0.4211,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6541957855224609,
      "rewards/margins": 0.6586955785751343,
      "rewards/rejected": -0.004499815404415131,
      "step": 313
    },
    {
      "epoch": 0.1256,
      "grad_norm": 10.376707077026367,
      "learning_rate": 9.582666666666666e-07,
      "logits/chosen": -2.3139424324035645,
      "logits/rejected": -2.542186737060547,
      "logps/chosen": -124.09696960449219,
      "logps/rejected": -119.01596069335938,
      "loss": 0.2727,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8785732388496399,
      "rewards/margins": 1.163343071937561,
      "rewards/rejected": -0.28476983308792114,
      "step": 314
    },
    {
      "epoch": 0.126,
      "grad_norm": 14.284221649169922,
      "learning_rate": 9.581333333333332e-07,
      "logits/chosen": -1.691880702972412,
      "logits/rejected": -1.9907406568527222,
      "logps/chosen": -140.1698455810547,
      "logps/rejected": -93.45320129394531,
      "loss": 0.5539,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3637496829032898,
      "rewards/margins": 0.3015918731689453,
      "rewards/rejected": 0.062157824635505676,
      "step": 315
    },
    {
      "epoch": 0.1264,
      "grad_norm": 12.131782531738281,
      "learning_rate": 9.58e-07,
      "logits/chosen": -2.175274610519409,
      "logits/rejected": -2.0548791885375977,
      "logps/chosen": -175.84104919433594,
      "logps/rejected": -151.5435333251953,
      "loss": 0.4274,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.684238851070404,
      "rewards/margins": 0.7764854431152344,
      "rewards/rejected": -0.09224662184715271,
      "step": 316
    },
    {
      "epoch": 0.1268,
      "grad_norm": 13.421792030334473,
      "learning_rate": 9.578666666666666e-07,
      "logits/chosen": -1.858530879020691,
      "logits/rejected": -2.8102331161499023,
      "logps/chosen": -146.52438354492188,
      "logps/rejected": -119.43385314941406,
      "loss": 0.3082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6565731167793274,
      "rewards/margins": 1.033708930015564,
      "rewards/rejected": -0.37713584303855896,
      "step": 317
    },
    {
      "epoch": 0.1272,
      "grad_norm": 13.030791282653809,
      "learning_rate": 9.577333333333334e-07,
      "logits/chosen": -1.7606556415557861,
      "logits/rejected": -2.333479642868042,
      "logps/chosen": -183.80255126953125,
      "logps/rejected": -167.63864135742188,
      "loss": 0.2515,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8599929809570312,
      "rewards/margins": 1.2517859935760498,
      "rewards/rejected": -0.39179307222366333,
      "step": 318
    },
    {
      "epoch": 0.1276,
      "grad_norm": 13.80737018585205,
      "learning_rate": 9.576e-07,
      "logits/chosen": -1.8543338775634766,
      "logits/rejected": -3.0451345443725586,
      "logps/chosen": -198.4344482421875,
      "logps/rejected": -172.7421112060547,
      "loss": 0.2964,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5486297607421875,
      "rewards/margins": 1.06842041015625,
      "rewards/rejected": -0.5197906494140625,
      "step": 319
    },
    {
      "epoch": 0.128,
      "grad_norm": 11.926711082458496,
      "learning_rate": 9.574666666666667e-07,
      "logits/chosen": -2.2329564094543457,
      "logits/rejected": -2.427905797958374,
      "logps/chosen": -195.26426696777344,
      "logps/rejected": -137.20236206054688,
      "loss": 0.3332,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7112144827842712,
      "rewards/margins": 0.9315564036369324,
      "rewards/rejected": -0.22034187614917755,
      "step": 320
    },
    {
      "epoch": 0.1284,
      "grad_norm": 11.058405876159668,
      "learning_rate": 9.573333333333333e-07,
      "logits/chosen": -2.170854091644287,
      "logits/rejected": -2.284374713897705,
      "logps/chosen": -193.06680297851562,
      "logps/rejected": -99.57476806640625,
      "loss": 0.2982,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9952560663223267,
      "rewards/margins": 1.0578136444091797,
      "rewards/rejected": -0.06255760788917542,
      "step": 321
    },
    {
      "epoch": 0.1288,
      "grad_norm": 11.332831382751465,
      "learning_rate": 9.572e-07,
      "logits/chosen": -2.208094358444214,
      "logits/rejected": -2.789024829864502,
      "logps/chosen": -159.32907104492188,
      "logps/rejected": -152.3526611328125,
      "loss": 0.3001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8543083667755127,
      "rewards/margins": 1.0501617193222046,
      "rewards/rejected": -0.19585342705249786,
      "step": 322
    },
    {
      "epoch": 0.1292,
      "grad_norm": 11.533520698547363,
      "learning_rate": 9.570666666666665e-07,
      "logits/chosen": -1.9344141483306885,
      "logits/rejected": -1.6428004503250122,
      "logps/chosen": -126.77522277832031,
      "logps/rejected": -104.25895690917969,
      "loss": 0.4609,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5018707513809204,
      "rewards/margins": 0.5582630038261414,
      "rewards/rejected": -0.05639229714870453,
      "step": 323
    },
    {
      "epoch": 0.1296,
      "grad_norm": 11.75419807434082,
      "learning_rate": 9.569333333333333e-07,
      "logits/chosen": -2.2427096366882324,
      "logits/rejected": -2.6767568588256836,
      "logps/chosen": -148.96722412109375,
      "logps/rejected": -121.97100830078125,
      "loss": 0.3111,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5852543115615845,
      "rewards/margins": 1.0097222328186035,
      "rewards/rejected": -0.42446786165237427,
      "step": 324
    },
    {
      "epoch": 0.13,
      "grad_norm": 9.735590934753418,
      "learning_rate": 9.567999999999999e-07,
      "logits/chosen": -2.254542350769043,
      "logits/rejected": -1.5541445016860962,
      "logps/chosen": -143.7095947265625,
      "logps/rejected": -86.95208740234375,
      "loss": 0.3342,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0367828607559204,
      "rewards/margins": 1.017345905303955,
      "rewards/rejected": 0.0194370299577713,
      "step": 325
    },
    {
      "epoch": 0.1304,
      "grad_norm": 12.297895431518555,
      "learning_rate": 9.566666666666667e-07,
      "logits/chosen": -2.00960111618042,
      "logits/rejected": -2.3351025581359863,
      "logps/chosen": -100.96467590332031,
      "logps/rejected": -118.62254333496094,
      "loss": 0.4289,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3766746520996094,
      "rewards/margins": 0.6250816583633423,
      "rewards/rejected": -0.24840699136257172,
      "step": 326
    },
    {
      "epoch": 0.1308,
      "grad_norm": 11.732319831848145,
      "learning_rate": 9.565333333333333e-07,
      "logits/chosen": -1.6790229082107544,
      "logits/rejected": -2.071122646331787,
      "logps/chosen": -86.78253936767578,
      "logps/rejected": -90.49698638916016,
      "loss": 0.5167,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33662301301956177,
      "rewards/margins": 0.41987189650535583,
      "rewards/rejected": -0.08324889838695526,
      "step": 327
    },
    {
      "epoch": 0.1312,
      "grad_norm": 7.506840229034424,
      "learning_rate": 9.564e-07,
      "logits/chosen": -2.361652135848999,
      "logits/rejected": -2.6782002449035645,
      "logps/chosen": -167.8133087158203,
      "logps/rejected": -130.01739501953125,
      "loss": 0.1581,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1103591918945312,
      "rewards/margins": 1.7668159008026123,
      "rewards/rejected": -0.6564567685127258,
      "step": 328
    },
    {
      "epoch": 0.1316,
      "grad_norm": 10.992173194885254,
      "learning_rate": 9.562666666666667e-07,
      "logits/chosen": -2.296079158782959,
      "logits/rejected": -2.2335174083709717,
      "logps/chosen": -200.86203002929688,
      "logps/rejected": -87.53048706054688,
      "loss": 0.2611,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9115607738494873,
      "rewards/margins": 1.2935978174209595,
      "rewards/rejected": -0.3820369839668274,
      "step": 329
    },
    {
      "epoch": 0.132,
      "grad_norm": 15.394968032836914,
      "learning_rate": 9.561333333333332e-07,
      "logits/chosen": -1.6588709354400635,
      "logits/rejected": -1.9331907033920288,
      "logps/chosen": -118.10418701171875,
      "logps/rejected": -90.86491394042969,
      "loss": 0.5889,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11032639443874359,
      "rewards/margins": 0.22175446152687073,
      "rewards/rejected": -0.11142807453870773,
      "step": 330
    },
    {
      "epoch": 0.1324,
      "grad_norm": 12.797173500061035,
      "learning_rate": 9.559999999999998e-07,
      "logits/chosen": -1.4791088104248047,
      "logits/rejected": -2.070399761199951,
      "logps/chosen": -117.97552490234375,
      "logps/rejected": -93.49156951904297,
      "loss": 0.4149,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7531921863555908,
      "rewards/margins": 0.6690124273300171,
      "rewards/rejected": 0.08417969197034836,
      "step": 331
    },
    {
      "epoch": 0.1328,
      "grad_norm": 11.30887508392334,
      "learning_rate": 9.558666666666666e-07,
      "logits/chosen": -1.8146429061889648,
      "logits/rejected": -1.4118348360061646,
      "logps/chosen": -86.69029235839844,
      "logps/rejected": -85.42684173583984,
      "loss": 0.3698,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5579643249511719,
      "rewards/margins": 0.8196926116943359,
      "rewards/rejected": -0.26172828674316406,
      "step": 332
    },
    {
      "epoch": 0.1332,
      "grad_norm": 10.904187202453613,
      "learning_rate": 9.557333333333332e-07,
      "logits/chosen": -1.649134874343872,
      "logits/rejected": -1.9934391975402832,
      "logps/chosen": -107.49665832519531,
      "logps/rejected": -94.91162109375,
      "loss": 0.3847,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5585654973983765,
      "rewards/margins": 0.7625980377197266,
      "rewards/rejected": -0.2040325254201889,
      "step": 333
    },
    {
      "epoch": 0.1336,
      "grad_norm": 10.141546249389648,
      "learning_rate": 9.556e-07,
      "logits/chosen": -2.1645326614379883,
      "logits/rejected": -2.094012975692749,
      "logps/chosen": -121.65289306640625,
      "logps/rejected": -108.60608673095703,
      "loss": 0.3963,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7382984161376953,
      "rewards/margins": 0.7695339322090149,
      "rewards/rejected": -0.031235501170158386,
      "step": 334
    },
    {
      "epoch": 0.134,
      "grad_norm": 10.338302612304688,
      "learning_rate": 9.554666666666666e-07,
      "logits/chosen": -1.9099140167236328,
      "logits/rejected": -1.711198091506958,
      "logps/chosen": -141.37588500976562,
      "logps/rejected": -83.49897766113281,
      "loss": 0.3438,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7056339383125305,
      "rewards/margins": 0.8964035511016846,
      "rewards/rejected": -0.19076958298683167,
      "step": 335
    },
    {
      "epoch": 0.1344,
      "grad_norm": 9.51525592803955,
      "learning_rate": 9.553333333333334e-07,
      "logits/chosen": -1.9487619400024414,
      "logits/rejected": -2.1649580001831055,
      "logps/chosen": -121.84542083740234,
      "logps/rejected": -101.561767578125,
      "loss": 0.2909,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9277992248535156,
      "rewards/margins": 1.1176254749298096,
      "rewards/rejected": -0.18982620537281036,
      "step": 336
    },
    {
      "epoch": 0.1348,
      "grad_norm": 10.147809028625488,
      "learning_rate": 9.552e-07,
      "logits/chosen": -2.257451057434082,
      "logits/rejected": -1.9222394227981567,
      "logps/chosen": -191.10719299316406,
      "logps/rejected": -85.64939880371094,
      "loss": 0.2309,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1129478216171265,
      "rewards/margins": 1.3723182678222656,
      "rewards/rejected": -0.25937044620513916,
      "step": 337
    },
    {
      "epoch": 0.1352,
      "grad_norm": 12.834878921508789,
      "learning_rate": 9.550666666666666e-07,
      "logits/chosen": -1.7756242752075195,
      "logits/rejected": -2.4170122146606445,
      "logps/chosen": -118.72027587890625,
      "logps/rejected": -107.18551635742188,
      "loss": 0.4657,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38856619596481323,
      "rewards/margins": 0.5436553955078125,
      "rewards/rejected": -0.15508919954299927,
      "step": 338
    },
    {
      "epoch": 0.1356,
      "grad_norm": 8.74482536315918,
      "learning_rate": 9.549333333333334e-07,
      "logits/chosen": -2.071829319000244,
      "logits/rejected": -2.2646644115448,
      "logps/chosen": -107.88862609863281,
      "logps/rejected": -101.2119140625,
      "loss": 0.2349,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8171809911727905,
      "rewards/margins": 1.3466548919677734,
      "rewards/rejected": -0.5294739007949829,
      "step": 339
    },
    {
      "epoch": 0.136,
      "grad_norm": 12.520222663879395,
      "learning_rate": 9.548e-07,
      "logits/chosen": -1.8740763664245605,
      "logits/rejected": -1.7102367877960205,
      "logps/chosen": -113.11312103271484,
      "logps/rejected": -92.58493041992188,
      "loss": 0.4299,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6516456604003906,
      "rewards/margins": 0.6301235556602478,
      "rewards/rejected": 0.02152213454246521,
      "step": 340
    },
    {
      "epoch": 0.1364,
      "grad_norm": 8.720784187316895,
      "learning_rate": 9.546666666666665e-07,
      "logits/chosen": -2.001288890838623,
      "logits/rejected": -2.1833841800689697,
      "logps/chosen": -159.24212646484375,
      "logps/rejected": -96.96380615234375,
      "loss": 0.2513,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.082759141921997,
      "rewards/margins": 1.3303020000457764,
      "rewards/rejected": -0.24754294753074646,
      "step": 341
    },
    {
      "epoch": 0.1368,
      "grad_norm": 13.765422821044922,
      "learning_rate": 9.545333333333333e-07,
      "logits/chosen": -2.085275173187256,
      "logits/rejected": -2.728032112121582,
      "logps/chosen": -157.38633728027344,
      "logps/rejected": -98.18443298339844,
      "loss": 0.3213,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8185989260673523,
      "rewards/margins": 1.0216732025146484,
      "rewards/rejected": -0.20307426154613495,
      "step": 342
    },
    {
      "epoch": 0.1372,
      "grad_norm": 9.867291450500488,
      "learning_rate": 9.544e-07,
      "logits/chosen": -2.5137381553649902,
      "logits/rejected": -2.128641366958618,
      "logps/chosen": -163.31146240234375,
      "logps/rejected": -113.5212173461914,
      "loss": 0.2539,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9958854913711548,
      "rewards/margins": 1.315298080444336,
      "rewards/rejected": -0.31941261887550354,
      "step": 343
    },
    {
      "epoch": 0.1376,
      "grad_norm": 10.123295783996582,
      "learning_rate": 9.542666666666667e-07,
      "logits/chosen": -2.068319082260132,
      "logits/rejected": -1.8827178478240967,
      "logps/chosen": -150.27740478515625,
      "logps/rejected": -102.6128158569336,
      "loss": 0.274,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9344837665557861,
      "rewards/margins": 1.1655871868133545,
      "rewards/rejected": -0.23110350966453552,
      "step": 344
    },
    {
      "epoch": 0.138,
      "grad_norm": 11.688067436218262,
      "learning_rate": 9.541333333333333e-07,
      "logits/chosen": -2.127321243286133,
      "logits/rejected": -2.603987216949463,
      "logps/chosen": -119.79167175292969,
      "logps/rejected": -122.39602661132812,
      "loss": 0.2632,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4507888853549957,
      "rewards/margins": 1.2014251947402954,
      "rewards/rejected": -0.7506363391876221,
      "step": 345
    },
    {
      "epoch": 0.1384,
      "grad_norm": 14.33978271484375,
      "learning_rate": 9.539999999999999e-07,
      "logits/chosen": -1.8845057487487793,
      "logits/rejected": -2.0055880546569824,
      "logps/chosen": -146.91270446777344,
      "logps/rejected": -113.65312957763672,
      "loss": 0.3626,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4611145257949829,
      "rewards/margins": 0.8436771631240845,
      "rewards/rejected": -0.38256263732910156,
      "step": 346
    },
    {
      "epoch": 0.1388,
      "grad_norm": 10.98196029663086,
      "learning_rate": 9.538666666666667e-07,
      "logits/chosen": -1.896848440170288,
      "logits/rejected": -2.1198980808258057,
      "logps/chosen": -131.83883666992188,
      "logps/rejected": -149.12075805664062,
      "loss": 0.2443,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8171112537384033,
      "rewards/margins": 1.2859902381896973,
      "rewards/rejected": -0.46887892484664917,
      "step": 347
    },
    {
      "epoch": 0.1392,
      "grad_norm": 15.018998146057129,
      "learning_rate": 9.537333333333333e-07,
      "logits/chosen": -1.6546475887298584,
      "logits/rejected": -2.3062362670898438,
      "logps/chosen": -88.27896118164062,
      "logps/rejected": -164.96200561523438,
      "loss": 0.4536,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5107277035713196,
      "rewards/margins": 0.5783588290214539,
      "rewards/rejected": -0.06763114780187607,
      "step": 348
    },
    {
      "epoch": 0.1396,
      "grad_norm": 11.12929916381836,
      "learning_rate": 9.536e-07,
      "logits/chosen": -2.2950496673583984,
      "logits/rejected": -2.369715690612793,
      "logps/chosen": -183.5143585205078,
      "logps/rejected": -110.28754425048828,
      "loss": 0.2431,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8320801258087158,
      "rewards/margins": 1.3070781230926514,
      "rewards/rejected": -0.4749981164932251,
      "step": 349
    },
    {
      "epoch": 0.14,
      "grad_norm": 9.235968589782715,
      "learning_rate": 9.534666666666667e-07,
      "logits/chosen": -1.8936326503753662,
      "logits/rejected": -2.929123878479004,
      "logps/chosen": -155.58470153808594,
      "logps/rejected": -104.74146270751953,
      "loss": 0.2588,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8917827606201172,
      "rewards/margins": 1.3213393688201904,
      "rewards/rejected": -0.429556667804718,
      "step": 350
    },
    {
      "epoch": 0.1404,
      "grad_norm": 13.856289863586426,
      "learning_rate": 9.533333333333333e-07,
      "logits/chosen": -1.919039011001587,
      "logits/rejected": -1.7163231372833252,
      "logps/chosen": -137.10513305664062,
      "logps/rejected": -97.58039093017578,
      "loss": 0.3802,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4284507930278778,
      "rewards/margins": 0.7732959985733032,
      "rewards/rejected": -0.3448452055454254,
      "step": 351
    },
    {
      "epoch": 0.1408,
      "grad_norm": 13.493905067443848,
      "learning_rate": 9.532e-07,
      "logits/chosen": -1.4531432390213013,
      "logits/rejected": -2.5324740409851074,
      "logps/chosen": -75.1290512084961,
      "logps/rejected": -120.27294921875,
      "loss": 0.4163,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4479801058769226,
      "rewards/margins": 0.6642040014266968,
      "rewards/rejected": -0.21622391045093536,
      "step": 352
    },
    {
      "epoch": 0.1412,
      "grad_norm": 12.82694149017334,
      "learning_rate": 9.530666666666666e-07,
      "logits/chosen": -1.7151232957839966,
      "logits/rejected": -2.196300506591797,
      "logps/chosen": -138.0375518798828,
      "logps/rejected": -101.56670379638672,
      "loss": 0.4329,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42985114455223083,
      "rewards/margins": 0.6267986297607422,
      "rewards/rejected": -0.19694748520851135,
      "step": 353
    },
    {
      "epoch": 0.1416,
      "grad_norm": 12.656393051147461,
      "learning_rate": 9.529333333333332e-07,
      "logits/chosen": -1.7616283893585205,
      "logits/rejected": -2.234405517578125,
      "logps/chosen": -125.9428482055664,
      "logps/rejected": -95.98524475097656,
      "loss": 0.3771,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3472389280796051,
      "rewards/margins": 0.8057087063789368,
      "rewards/rejected": -0.45846980810165405,
      "step": 354
    },
    {
      "epoch": 0.142,
      "grad_norm": 11.418084144592285,
      "learning_rate": 9.527999999999999e-07,
      "logits/chosen": -2.2805190086364746,
      "logits/rejected": -1.6600629091262817,
      "logps/chosen": -166.3076934814453,
      "logps/rejected": -100.41447448730469,
      "loss": 0.32,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8029266595840454,
      "rewards/margins": 0.9782726168632507,
      "rewards/rejected": -0.1753460019826889,
      "step": 355
    },
    {
      "epoch": 0.1424,
      "grad_norm": 14.274686813354492,
      "learning_rate": 9.526666666666666e-07,
      "logits/chosen": -2.160705327987671,
      "logits/rejected": -1.2577961683273315,
      "logps/chosen": -130.42681884765625,
      "logps/rejected": -107.40043640136719,
      "loss": 0.5507,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.37729111313819885,
      "rewards/margins": 0.46296578645706177,
      "rewards/rejected": -0.08567467331886292,
      "step": 356
    },
    {
      "epoch": 0.1428,
      "grad_norm": 11.299083709716797,
      "learning_rate": 9.525333333333333e-07,
      "logits/chosen": -1.8485956192016602,
      "logits/rejected": -2.3741636276245117,
      "logps/chosen": -167.78311157226562,
      "logps/rejected": -146.5095977783203,
      "loss": 0.2382,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.067840576171875,
      "rewards/margins": 1.313985824584961,
      "rewards/rejected": -0.24614524841308594,
      "step": 357
    },
    {
      "epoch": 0.1432,
      "grad_norm": 9.336177825927734,
      "learning_rate": 9.524e-07,
      "logits/chosen": -2.260824203491211,
      "logits/rejected": -2.607541561126709,
      "logps/chosen": -98.86637878417969,
      "logps/rejected": -103.50428009033203,
      "loss": 0.3252,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7557506561279297,
      "rewards/margins": 1.0795044898986816,
      "rewards/rejected": -0.3237537443637848,
      "step": 358
    },
    {
      "epoch": 0.1436,
      "grad_norm": 8.682798385620117,
      "learning_rate": 9.522666666666667e-07,
      "logits/chosen": -1.8525636196136475,
      "logits/rejected": -2.8452634811401367,
      "logps/chosen": -106.86477661132812,
      "logps/rejected": -112.48531341552734,
      "loss": 0.2278,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9767674207687378,
      "rewards/margins": 1.380671739578247,
      "rewards/rejected": -0.40390434861183167,
      "step": 359
    },
    {
      "epoch": 0.144,
      "grad_norm": 9.145380973815918,
      "learning_rate": 9.521333333333334e-07,
      "logits/chosen": -1.6418769359588623,
      "logits/rejected": -1.9786100387573242,
      "logps/chosen": -99.93850708007812,
      "logps/rejected": -80.95884704589844,
      "loss": 0.2996,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8148006796836853,
      "rewards/margins": 1.0917046070098877,
      "rewards/rejected": -0.2769039273262024,
      "step": 360
    },
    {
      "epoch": 0.1444,
      "grad_norm": 10.36797046661377,
      "learning_rate": 9.52e-07,
      "logits/chosen": -2.0813405513763428,
      "logits/rejected": -2.046511650085449,
      "logps/chosen": -140.75628662109375,
      "logps/rejected": -124.78031921386719,
      "loss": 0.3442,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7576786279678345,
      "rewards/margins": 1.0147217512130737,
      "rewards/rejected": -0.25704309344291687,
      "step": 361
    },
    {
      "epoch": 0.1448,
      "grad_norm": 13.570343971252441,
      "learning_rate": 9.518666666666666e-07,
      "logits/chosen": -2.005720615386963,
      "logits/rejected": -2.793525218963623,
      "logps/chosen": -175.9668731689453,
      "logps/rejected": -125.14128112792969,
      "loss": 0.3443,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6709270477294922,
      "rewards/margins": 0.9494178891181946,
      "rewards/rejected": -0.2784908413887024,
      "step": 362
    },
    {
      "epoch": 0.1452,
      "grad_norm": 6.987004280090332,
      "learning_rate": 9.517333333333332e-07,
      "logits/chosen": -1.8027461767196655,
      "logits/rejected": -1.8652089834213257,
      "logps/chosen": -94.84709167480469,
      "logps/rejected": -84.95722961425781,
      "loss": 0.244,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9833306074142456,
      "rewards/margins": 1.3669519424438477,
      "rewards/rejected": -0.3836214244365692,
      "step": 363
    },
    {
      "epoch": 0.1456,
      "grad_norm": 11.490894317626953,
      "learning_rate": 9.515999999999999e-07,
      "logits/chosen": -2.0487098693847656,
      "logits/rejected": -2.5485012531280518,
      "logps/chosen": -167.71572875976562,
      "logps/rejected": -115.78235626220703,
      "loss": 0.2918,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8333466053009033,
      "rewards/margins": 1.108116626739502,
      "rewards/rejected": -0.27476999163627625,
      "step": 364
    },
    {
      "epoch": 0.146,
      "grad_norm": 12.685693740844727,
      "learning_rate": 9.514666666666666e-07,
      "logits/chosen": -2.0365726947784424,
      "logits/rejected": -2.2284841537475586,
      "logps/chosen": -140.4332275390625,
      "logps/rejected": -97.76905059814453,
      "loss": 0.3872,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.37633323669433594,
      "rewards/margins": 0.7507511377334595,
      "rewards/rejected": -0.37441787123680115,
      "step": 365
    },
    {
      "epoch": 0.1464,
      "grad_norm": 7.3211565017700195,
      "learning_rate": 9.513333333333333e-07,
      "logits/chosen": -1.7710072994232178,
      "logits/rejected": -1.6665716171264648,
      "logps/chosen": -116.36080932617188,
      "logps/rejected": -82.16951751708984,
      "loss": 0.1877,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2544617652893066,
      "rewards/margins": 1.5898869037628174,
      "rewards/rejected": -0.3354251980781555,
      "step": 366
    },
    {
      "epoch": 0.1468,
      "grad_norm": 7.510016441345215,
      "learning_rate": 9.512e-07,
      "logits/chosen": -1.7499362230300903,
      "logits/rejected": -2.1663451194763184,
      "logps/chosen": -137.49813842773438,
      "logps/rejected": -110.95579528808594,
      "loss": 0.192,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.202662706375122,
      "rewards/margins": 1.6484477519989014,
      "rewards/rejected": -0.44578513503074646,
      "step": 367
    },
    {
      "epoch": 0.1472,
      "grad_norm": 7.877624034881592,
      "learning_rate": 9.510666666666666e-07,
      "logits/chosen": -1.9763375520706177,
      "logits/rejected": -2.513627052307129,
      "logps/chosen": -140.45654296875,
      "logps/rejected": -113.225830078125,
      "loss": 0.2448,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.202449083328247,
      "rewards/margins": 1.3416630029678345,
      "rewards/rejected": -0.1392139494419098,
      "step": 368
    },
    {
      "epoch": 0.1476,
      "grad_norm": 9.813507080078125,
      "learning_rate": 9.509333333333333e-07,
      "logits/chosen": -2.2253241539001465,
      "logits/rejected": -2.0527586936950684,
      "logps/chosen": -149.95877075195312,
      "logps/rejected": -98.8197021484375,
      "loss": 0.2069,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2354103326797485,
      "rewards/margins": 1.4861046075820923,
      "rewards/rejected": -0.25069427490234375,
      "step": 369
    },
    {
      "epoch": 0.148,
      "grad_norm": 9.5536470413208,
      "learning_rate": 9.508e-07,
      "logits/chosen": -1.9323830604553223,
      "logits/rejected": -2.1039233207702637,
      "logps/chosen": -156.32528686523438,
      "logps/rejected": -124.0758056640625,
      "loss": 0.2734,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1184509992599487,
      "rewards/margins": 1.2805111408233643,
      "rewards/rejected": -0.16206015646457672,
      "step": 370
    },
    {
      "epoch": 0.1484,
      "grad_norm": 7.910000801086426,
      "learning_rate": 9.506666666666667e-07,
      "logits/chosen": -1.8300211429595947,
      "logits/rejected": -1.297459602355957,
      "logps/chosen": -99.21824645996094,
      "logps/rejected": -124.9365005493164,
      "loss": 0.2975,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0642063617706299,
      "rewards/margins": 1.0616652965545654,
      "rewards/rejected": 0.0025409720838069916,
      "step": 371
    },
    {
      "epoch": 0.1488,
      "grad_norm": 10.368349075317383,
      "learning_rate": 9.505333333333333e-07,
      "logits/chosen": -2.067460060119629,
      "logits/rejected": -1.8475725650787354,
      "logps/chosen": -139.50064086914062,
      "logps/rejected": -80.68698120117188,
      "loss": 0.2913,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8239769339561462,
      "rewards/margins": 1.1013561487197876,
      "rewards/rejected": -0.27737924456596375,
      "step": 372
    },
    {
      "epoch": 0.1492,
      "grad_norm": 7.3329362869262695,
      "learning_rate": 9.503999999999999e-07,
      "logits/chosen": -1.9526185989379883,
      "logits/rejected": -2.2015793323516846,
      "logps/chosen": -127.7243881225586,
      "logps/rejected": -112.26014709472656,
      "loss": 0.1865,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2661080360412598,
      "rewards/margins": 1.588815689086914,
      "rewards/rejected": -0.32270774245262146,
      "step": 373
    },
    {
      "epoch": 0.1496,
      "grad_norm": 11.53016185760498,
      "learning_rate": 9.502666666666666e-07,
      "logits/chosen": -2.140340805053711,
      "logits/rejected": -2.8700661659240723,
      "logps/chosen": -164.28280639648438,
      "logps/rejected": -104.07437896728516,
      "loss": 0.3431,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5127601623535156,
      "rewards/margins": 0.8964020013809204,
      "rewards/rejected": -0.3836418092250824,
      "step": 374
    },
    {
      "epoch": 0.15,
      "grad_norm": 7.28753137588501,
      "learning_rate": 9.501333333333333e-07,
      "logits/chosen": -2.5547945499420166,
      "logits/rejected": -2.5946521759033203,
      "logps/chosen": -182.91717529296875,
      "logps/rejected": -133.85110473632812,
      "loss": 0.1466,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2150650024414062,
      "rewards/margins": 1.8501789569854736,
      "rewards/rejected": -0.6351138949394226,
      "step": 375
    },
    {
      "epoch": 0.1504,
      "grad_norm": 9.148015975952148,
      "learning_rate": 9.499999999999999e-07,
      "logits/chosen": -1.6617413759231567,
      "logits/rejected": -2.2854645252227783,
      "logps/chosen": -98.10789489746094,
      "logps/rejected": -81.83000183105469,
      "loss": 0.3176,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8450019955635071,
      "rewards/margins": 0.984173595905304,
      "rewards/rejected": -0.13917160034179688,
      "step": 376
    },
    {
      "epoch": 0.1508,
      "grad_norm": 10.297746658325195,
      "learning_rate": 9.498666666666666e-07,
      "logits/chosen": -2.529423713684082,
      "logits/rejected": -2.45241379737854,
      "logps/chosen": -256.02069091796875,
      "logps/rejected": -124.77095794677734,
      "loss": 0.2154,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9964935779571533,
      "rewards/margins": 1.4332561492919922,
      "rewards/rejected": -0.43676263093948364,
      "step": 377
    },
    {
      "epoch": 0.1512,
      "grad_norm": 12.253778457641602,
      "learning_rate": 9.497333333333333e-07,
      "logits/chosen": -2.2363340854644775,
      "logits/rejected": -2.313307762145996,
      "logps/chosen": -163.7865753173828,
      "logps/rejected": -105.56155395507812,
      "loss": 0.3235,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7563934922218323,
      "rewards/margins": 1.039902925491333,
      "rewards/rejected": -0.28350943326950073,
      "step": 378
    },
    {
      "epoch": 0.1516,
      "grad_norm": 9.639123916625977,
      "learning_rate": 9.496e-07,
      "logits/chosen": -1.6128370761871338,
      "logits/rejected": -2.859222412109375,
      "logps/chosen": -107.07048034667969,
      "logps/rejected": -103.79112243652344,
      "loss": 0.3328,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6085479855537415,
      "rewards/margins": 0.9559154510498047,
      "rewards/rejected": -0.3473674952983856,
      "step": 379
    },
    {
      "epoch": 0.152,
      "grad_norm": 13.886418342590332,
      "learning_rate": 9.494666666666667e-07,
      "logits/chosen": -2.138012409210205,
      "logits/rejected": -1.797116756439209,
      "logps/chosen": -120.83674621582031,
      "logps/rejected": -76.87982940673828,
      "loss": 0.3862,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6390007138252258,
      "rewards/margins": 0.7585057020187378,
      "rewards/rejected": -0.11950492858886719,
      "step": 380
    },
    {
      "epoch": 0.1524,
      "grad_norm": 9.497507095336914,
      "learning_rate": 9.493333333333334e-07,
      "logits/chosen": -1.9699599742889404,
      "logits/rejected": -2.350442409515381,
      "logps/chosen": -138.3687286376953,
      "logps/rejected": -130.41033935546875,
      "loss": 0.2235,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.042568564414978,
      "rewards/margins": 1.4287029504776,
      "rewards/rejected": -0.3861343264579773,
      "step": 381
    },
    {
      "epoch": 0.1528,
      "grad_norm": 9.270492553710938,
      "learning_rate": 9.492e-07,
      "logits/chosen": -1.741117238998413,
      "logits/rejected": -2.386035442352295,
      "logps/chosen": -123.07484436035156,
      "logps/rejected": -114.18351745605469,
      "loss": 0.2813,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9830993413925171,
      "rewards/margins": 1.1257762908935547,
      "rewards/rejected": -0.1426769196987152,
      "step": 382
    },
    {
      "epoch": 0.1532,
      "grad_norm": 10.245641708374023,
      "learning_rate": 9.490666666666665e-07,
      "logits/chosen": -1.928135871887207,
      "logits/rejected": -2.569612503051758,
      "logps/chosen": -120.55267333984375,
      "logps/rejected": -156.81797790527344,
      "loss": 0.2595,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.756029486656189,
      "rewards/margins": 1.293749213218689,
      "rewards/rejected": -0.5377197265625,
      "step": 383
    },
    {
      "epoch": 0.1536,
      "grad_norm": 12.067938804626465,
      "learning_rate": 9.489333333333332e-07,
      "logits/chosen": -2.441046714782715,
      "logits/rejected": -2.292257070541382,
      "logps/chosen": -180.46432495117188,
      "logps/rejected": -94.191650390625,
      "loss": 0.3546,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6873119473457336,
      "rewards/margins": 0.8563335537910461,
      "rewards/rejected": -0.1690216064453125,
      "step": 384
    },
    {
      "epoch": 0.154,
      "grad_norm": 8.169790267944336,
      "learning_rate": 9.487999999999999e-07,
      "logits/chosen": -2.1459455490112305,
      "logits/rejected": -1.6647861003875732,
      "logps/chosen": -155.9969940185547,
      "logps/rejected": -95.02266693115234,
      "loss": 0.2649,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2378612756729126,
      "rewards/margins": 1.255697250366211,
      "rewards/rejected": -0.017836004495620728,
      "step": 385
    },
    {
      "epoch": 0.1544,
      "grad_norm": 6.733552932739258,
      "learning_rate": 9.486666666666666e-07,
      "logits/chosen": -1.963012456893921,
      "logits/rejected": -2.6092190742492676,
      "logps/chosen": -152.21453857421875,
      "logps/rejected": -109.95803833007812,
      "loss": 0.1857,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3353309631347656,
      "rewards/margins": 1.5899609327316284,
      "rewards/rejected": -0.254629909992218,
      "step": 386
    },
    {
      "epoch": 0.1548,
      "grad_norm": 12.216314315795898,
      "learning_rate": 9.485333333333333e-07,
      "logits/chosen": -2.3652167320251465,
      "logits/rejected": -2.5351710319519043,
      "logps/chosen": -188.51052856445312,
      "logps/rejected": -122.753173828125,
      "loss": 0.2681,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0679374933242798,
      "rewards/margins": 1.3116893768310547,
      "rewards/rejected": -0.2437519133090973,
      "step": 387
    },
    {
      "epoch": 0.1552,
      "grad_norm": 13.942158699035645,
      "learning_rate": 9.484e-07,
      "logits/chosen": -1.9994442462921143,
      "logits/rejected": -2.442103385925293,
      "logps/chosen": -184.11099243164062,
      "logps/rejected": -116.03318786621094,
      "loss": 0.2599,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6710761785507202,
      "rewards/margins": 1.2169184684753418,
      "rewards/rejected": -0.5458423495292664,
      "step": 388
    },
    {
      "epoch": 0.1556,
      "grad_norm": 12.331748962402344,
      "learning_rate": 9.482666666666667e-07,
      "logits/chosen": -2.0864217281341553,
      "logits/rejected": -2.063352584838867,
      "logps/chosen": -146.79855346679688,
      "logps/rejected": -124.34456634521484,
      "loss": 0.3149,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4649433195590973,
      "rewards/margins": 1.0654239654541016,
      "rewards/rejected": -0.6004806756973267,
      "step": 389
    },
    {
      "epoch": 0.156,
      "grad_norm": 11.62092399597168,
      "learning_rate": 9.481333333333334e-07,
      "logits/chosen": -1.8897068500518799,
      "logits/rejected": -2.3556714057922363,
      "logps/chosen": -100.704833984375,
      "logps/rejected": -98.68241882324219,
      "loss": 0.4524,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9004650115966797,
      "rewards/margins": 0.5983417630195618,
      "rewards/rejected": 0.3021232485771179,
      "step": 390
    },
    {
      "epoch": 0.1564,
      "grad_norm": 11.608728408813477,
      "learning_rate": 9.479999999999999e-07,
      "logits/chosen": -2.3386034965515137,
      "logits/rejected": -2.7307748794555664,
      "logps/chosen": -173.66171264648438,
      "logps/rejected": -145.55361938476562,
      "loss": 0.28,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5952682495117188,
      "rewards/margins": 1.1594493389129639,
      "rewards/rejected": -0.5641811490058899,
      "step": 391
    },
    {
      "epoch": 0.1568,
      "grad_norm": 12.726834297180176,
      "learning_rate": 9.478666666666666e-07,
      "logits/chosen": -2.354743242263794,
      "logits/rejected": -2.717852830886841,
      "logps/chosen": -157.46881103515625,
      "logps/rejected": -139.5148162841797,
      "loss": 0.3507,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8644520044326782,
      "rewards/margins": 0.9663242697715759,
      "rewards/rejected": -0.10187225043773651,
      "step": 392
    },
    {
      "epoch": 0.1572,
      "grad_norm": 7.993042469024658,
      "learning_rate": 9.477333333333332e-07,
      "logits/chosen": -1.5804051160812378,
      "logits/rejected": -2.326617956161499,
      "logps/chosen": -117.14856719970703,
      "logps/rejected": -122.335205078125,
      "loss": 0.1875,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2884899377822876,
      "rewards/margins": 1.5827057361602783,
      "rewards/rejected": -0.29421576857566833,
      "step": 393
    },
    {
      "epoch": 0.1576,
      "grad_norm": 7.231118202209473,
      "learning_rate": 9.475999999999999e-07,
      "logits/chosen": -1.8528920412063599,
      "logits/rejected": -1.639711618423462,
      "logps/chosen": -92.0528564453125,
      "logps/rejected": -73.64485168457031,
      "loss": 0.2567,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1102015972137451,
      "rewards/margins": 1.2984516620635986,
      "rewards/rejected": -0.18824997544288635,
      "step": 394
    },
    {
      "epoch": 0.158,
      "grad_norm": 6.852899074554443,
      "learning_rate": 9.474666666666666e-07,
      "logits/chosen": -1.8281446695327759,
      "logits/rejected": -2.2063965797424316,
      "logps/chosen": -101.5073013305664,
      "logps/rejected": -106.08369445800781,
      "loss": 0.1602,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2424888610839844,
      "rewards/margins": 1.7554783821105957,
      "rewards/rejected": -0.5129894614219666,
      "step": 395
    },
    {
      "epoch": 0.1584,
      "grad_norm": 13.540509223937988,
      "learning_rate": 9.473333333333333e-07,
      "logits/chosen": -2.3715319633483887,
      "logits/rejected": -2.4869179725646973,
      "logps/chosen": -290.996826171875,
      "logps/rejected": -145.32095336914062,
      "loss": 0.2411,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0565086603164673,
      "rewards/margins": 1.38390052318573,
      "rewards/rejected": -0.3273918330669403,
      "step": 396
    },
    {
      "epoch": 0.1588,
      "grad_norm": 10.180379867553711,
      "learning_rate": 9.472e-07,
      "logits/chosen": -1.4122016429901123,
      "logits/rejected": -1.9342224597930908,
      "logps/chosen": -85.53691101074219,
      "logps/rejected": -87.52035522460938,
      "loss": 0.335,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6664243936538696,
      "rewards/margins": 0.9846780300140381,
      "rewards/rejected": -0.31825369596481323,
      "step": 397
    },
    {
      "epoch": 0.1592,
      "grad_norm": 11.034773826599121,
      "learning_rate": 9.470666666666666e-07,
      "logits/chosen": -2.0228371620178223,
      "logits/rejected": -2.3751461505889893,
      "logps/chosen": -117.36116790771484,
      "logps/rejected": -114.21444702148438,
      "loss": 0.3268,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2135917842388153,
      "rewards/margins": 0.9509170651435852,
      "rewards/rejected": -0.7373253107070923,
      "step": 398
    },
    {
      "epoch": 0.1596,
      "grad_norm": 8.054386138916016,
      "learning_rate": 9.469333333333333e-07,
      "logits/chosen": -1.5510790348052979,
      "logits/rejected": -1.9145108461380005,
      "logps/chosen": -99.90288543701172,
      "logps/rejected": -98.9764175415039,
      "loss": 0.2298,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5541046261787415,
      "rewards/margins": 1.3647063970565796,
      "rewards/rejected": -0.8106018304824829,
      "step": 399
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.975530624389648,
      "learning_rate": 9.468e-07,
      "logits/chosen": -2.4158143997192383,
      "logits/rejected": -2.0161213874816895,
      "logps/chosen": -190.5890655517578,
      "logps/rejected": -166.11181640625,
      "loss": 0.1725,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.205596923828125,
      "rewards/margins": 1.6697670221328735,
      "rewards/rejected": -0.46417009830474854,
      "step": 400
    },
    {
      "epoch": 0.1604,
      "grad_norm": 9.282535552978516,
      "learning_rate": 9.466666666666666e-07,
      "logits/chosen": -2.262916326522827,
      "logits/rejected": -2.5856990814208984,
      "logps/chosen": -134.20362854003906,
      "logps/rejected": -127.04547882080078,
      "loss": 0.2976,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9665489196777344,
      "rewards/margins": 1.1875946521759033,
      "rewards/rejected": -0.22104568779468536,
      "step": 401
    },
    {
      "epoch": 0.1608,
      "grad_norm": 7.493899345397949,
      "learning_rate": 9.465333333333333e-07,
      "logits/chosen": -2.134458541870117,
      "logits/rejected": -2.6458992958068848,
      "logps/chosen": -164.6883544921875,
      "logps/rejected": -153.93038940429688,
      "loss": 0.1373,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.569145917892456,
      "rewards/margins": 1.9639228582382202,
      "rewards/rejected": -0.3947769105434418,
      "step": 402
    },
    {
      "epoch": 0.1612,
      "grad_norm": 11.629280090332031,
      "learning_rate": 9.464e-07,
      "logits/chosen": -2.383512258529663,
      "logits/rejected": -2.286909580230713,
      "logps/chosen": -168.97279357910156,
      "logps/rejected": -99.29438781738281,
      "loss": 0.3008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9659870266914368,
      "rewards/margins": 1.123666763305664,
      "rewards/rejected": -0.1576797515153885,
      "step": 403
    },
    {
      "epoch": 0.1616,
      "grad_norm": 9.20734691619873,
      "learning_rate": 9.462666666666666e-07,
      "logits/chosen": -1.583045482635498,
      "logits/rejected": -2.120948314666748,
      "logps/chosen": -97.80064392089844,
      "logps/rejected": -89.93172454833984,
      "loss": 0.3815,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1660698652267456,
      "rewards/margins": 0.892707109451294,
      "rewards/rejected": 0.2733627259731293,
      "step": 404
    },
    {
      "epoch": 0.162,
      "grad_norm": 11.907289505004883,
      "learning_rate": 9.461333333333333e-07,
      "logits/chosen": -1.7811925411224365,
      "logits/rejected": -2.633497714996338,
      "logps/chosen": -99.49870300292969,
      "logps/rejected": -111.71630859375,
      "loss": 0.3545,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3083316683769226,
      "rewards/margins": 0.8653049468994141,
      "rewards/rejected": -0.5569732785224915,
      "step": 405
    },
    {
      "epoch": 0.1624,
      "grad_norm": 11.104279518127441,
      "learning_rate": 9.459999999999999e-07,
      "logits/chosen": -2.2487576007843018,
      "logits/rejected": -1.8973045349121094,
      "logps/chosen": -106.34475708007812,
      "logps/rejected": -84.4996337890625,
      "loss": 0.3515,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.848435640335083,
      "rewards/margins": 0.8995281457901001,
      "rewards/rejected": -0.05109252780675888,
      "step": 406
    },
    {
      "epoch": 0.1628,
      "grad_norm": 8.51587200164795,
      "learning_rate": 9.458666666666666e-07,
      "logits/chosen": -2.086266279220581,
      "logits/rejected": -2.070124387741089,
      "logps/chosen": -128.45416259765625,
      "logps/rejected": -100.02627563476562,
      "loss": 0.2431,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.821384072303772,
      "rewards/margins": 1.4821232557296753,
      "rewards/rejected": -0.6607391238212585,
      "step": 407
    },
    {
      "epoch": 0.1632,
      "grad_norm": 11.920384407043457,
      "learning_rate": 9.457333333333333e-07,
      "logits/chosen": -1.6838351488113403,
      "logits/rejected": -3.0173068046569824,
      "logps/chosen": -95.30009460449219,
      "logps/rejected": -109.85481262207031,
      "loss": 0.2781,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2770458459854126,
      "rewards/margins": 1.1428791284561157,
      "rewards/rejected": -0.8658332824707031,
      "step": 408
    },
    {
      "epoch": 0.1636,
      "grad_norm": 8.275662422180176,
      "learning_rate": 9.456e-07,
      "logits/chosen": -2.2192814350128174,
      "logits/rejected": -2.5773162841796875,
      "logps/chosen": -133.86627197265625,
      "logps/rejected": -132.1903076171875,
      "loss": 0.1958,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2782368659973145,
      "rewards/margins": 1.715040922164917,
      "rewards/rejected": -0.4368042051792145,
      "step": 409
    },
    {
      "epoch": 0.164,
      "grad_norm": 5.816837310791016,
      "learning_rate": 9.454666666666666e-07,
      "logits/chosen": -2.0674705505371094,
      "logits/rejected": -2.271671772003174,
      "logps/chosen": -130.803955078125,
      "logps/rejected": -122.76443481445312,
      "loss": 0.1261,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1916625499725342,
      "rewards/margins": 2.0421204566955566,
      "rewards/rejected": -0.8504577875137329,
      "step": 410
    },
    {
      "epoch": 0.1644,
      "grad_norm": 8.385333061218262,
      "learning_rate": 9.453333333333333e-07,
      "logits/chosen": -2.3192989826202393,
      "logits/rejected": -2.6337850093841553,
      "logps/chosen": -293.2218933105469,
      "logps/rejected": -119.7346420288086,
      "loss": 0.183,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2165474891662598,
      "rewards/margins": 1.7497090101242065,
      "rewards/rejected": -0.5331615209579468,
      "step": 411
    },
    {
      "epoch": 0.1648,
      "grad_norm": 8.10377311706543,
      "learning_rate": 9.452e-07,
      "logits/chosen": -1.922171950340271,
      "logits/rejected": -2.0256476402282715,
      "logps/chosen": -113.44041442871094,
      "logps/rejected": -108.41461181640625,
      "loss": 0.2458,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.319321870803833,
      "rewards/margins": 1.4050121307373047,
      "rewards/rejected": -0.08569031208753586,
      "step": 412
    },
    {
      "epoch": 0.1652,
      "grad_norm": 9.302472114562988,
      "learning_rate": 9.450666666666667e-07,
      "logits/chosen": -2.264190673828125,
      "logits/rejected": -1.2961950302124023,
      "logps/chosen": -134.43714904785156,
      "logps/rejected": -107.28605651855469,
      "loss": 0.2652,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.036341905593872,
      "rewards/margins": 1.2001854181289673,
      "rewards/rejected": -0.1638435423374176,
      "step": 413
    },
    {
      "epoch": 0.1656,
      "grad_norm": 4.8103227615356445,
      "learning_rate": 9.449333333333332e-07,
      "logits/chosen": -2.463682174682617,
      "logits/rejected": -2.4808731079101562,
      "logps/chosen": -156.03012084960938,
      "logps/rejected": -139.5924072265625,
      "loss": 0.0885,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4927231073379517,
      "rewards/margins": 2.3805863857269287,
      "rewards/rejected": -0.8878631591796875,
      "step": 414
    },
    {
      "epoch": 0.166,
      "grad_norm": 8.39031982421875,
      "learning_rate": 9.447999999999999e-07,
      "logits/chosen": -1.6984713077545166,
      "logits/rejected": -2.845871925354004,
      "logps/chosen": -123.16020202636719,
      "logps/rejected": -145.24798583984375,
      "loss": 0.1849,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2149349451065063,
      "rewards/margins": 1.603813648223877,
      "rewards/rejected": -0.38887864351272583,
      "step": 415
    },
    {
      "epoch": 0.1664,
      "grad_norm": 6.619210243225098,
      "learning_rate": 9.446666666666666e-07,
      "logits/chosen": -2.0965235233306885,
      "logits/rejected": -1.6821401119232178,
      "logps/chosen": -110.07695007324219,
      "logps/rejected": -92.12284088134766,
      "loss": 0.1776,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.373697280883789,
      "rewards/margins": 1.6381773948669434,
      "rewards/rejected": -0.26448002457618713,
      "step": 416
    },
    {
      "epoch": 0.1668,
      "grad_norm": 5.979409694671631,
      "learning_rate": 9.445333333333333e-07,
      "logits/chosen": -1.9234840869903564,
      "logits/rejected": -2.7448582649230957,
      "logps/chosen": -170.98329162597656,
      "logps/rejected": -119.53779602050781,
      "loss": 0.1444,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3956592082977295,
      "rewards/margins": 2.0119826793670654,
      "rewards/rejected": -0.6163234710693359,
      "step": 417
    },
    {
      "epoch": 0.1672,
      "grad_norm": 8.729636192321777,
      "learning_rate": 9.444e-07,
      "logits/chosen": -2.2540154457092285,
      "logits/rejected": -2.082726240158081,
      "logps/chosen": -124.50347900390625,
      "logps/rejected": -96.92491149902344,
      "loss": 0.361,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9766941666603088,
      "rewards/margins": 0.979261040687561,
      "rewards/rejected": -0.002566911280155182,
      "step": 418
    },
    {
      "epoch": 0.1676,
      "grad_norm": 8.098226547241211,
      "learning_rate": 9.442666666666667e-07,
      "logits/chosen": -2.249913215637207,
      "logits/rejected": -2.991631507873535,
      "logps/chosen": -176.66258239746094,
      "logps/rejected": -108.28280639648438,
      "loss": 0.1658,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4155998229980469,
      "rewards/margins": 1.7377254962921143,
      "rewards/rejected": -0.322125643491745,
      "step": 419
    },
    {
      "epoch": 0.168,
      "grad_norm": 8.106107711791992,
      "learning_rate": 9.441333333333333e-07,
      "logits/chosen": -1.9299628734588623,
      "logits/rejected": -2.544675350189209,
      "logps/chosen": -115.36860656738281,
      "logps/rejected": -108.35554504394531,
      "loss": 0.1979,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.047328233718872,
      "rewards/margins": 1.6106986999511719,
      "rewards/rejected": -0.5633705258369446,
      "step": 420
    },
    {
      "epoch": 0.1684,
      "grad_norm": 6.2054314613342285,
      "learning_rate": 9.439999999999999e-07,
      "logits/chosen": -2.303799629211426,
      "logits/rejected": -2.532221794128418,
      "logps/chosen": -115.06330108642578,
      "logps/rejected": -99.20648193359375,
      "loss": 0.1463,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2335362434387207,
      "rewards/margins": 1.903997778892517,
      "rewards/rejected": -0.6704616546630859,
      "step": 421
    },
    {
      "epoch": 0.1688,
      "grad_norm": 11.477980613708496,
      "learning_rate": 9.438666666666666e-07,
      "logits/chosen": -1.8046691417694092,
      "logits/rejected": -2.1795172691345215,
      "logps/chosen": -83.42847442626953,
      "logps/rejected": -91.38618469238281,
      "loss": 0.4085,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6901096105575562,
      "rewards/margins": 0.8716487884521484,
      "rewards/rejected": -0.1815391629934311,
      "step": 422
    },
    {
      "epoch": 0.1692,
      "grad_norm": 7.315863132476807,
      "learning_rate": 9.437333333333333e-07,
      "logits/chosen": -2.018951177597046,
      "logits/rejected": -2.1429224014282227,
      "logps/chosen": -128.6773681640625,
      "logps/rejected": -100.15084838867188,
      "loss": 0.1988,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9219543933868408,
      "rewards/margins": 1.5867302417755127,
      "rewards/rejected": -0.6647758483886719,
      "step": 423
    },
    {
      "epoch": 0.1696,
      "grad_norm": 6.397770404815674,
      "learning_rate": 9.436e-07,
      "logits/chosen": -1.9370198249816895,
      "logits/rejected": -2.3889541625976562,
      "logps/chosen": -154.3780517578125,
      "logps/rejected": -149.08726501464844,
      "loss": 0.1345,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3697669506072998,
      "rewards/margins": 1.9527592658996582,
      "rewards/rejected": -0.5829921960830688,
      "step": 424
    },
    {
      "epoch": 0.17,
      "grad_norm": 8.32265567779541,
      "learning_rate": 9.434666666666666e-07,
      "logits/chosen": -1.7096772193908691,
      "logits/rejected": -1.998321533203125,
      "logps/chosen": -124.79930114746094,
      "logps/rejected": -118.1744155883789,
      "loss": 0.2828,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9994838833808899,
      "rewards/margins": 1.2588279247283936,
      "rewards/rejected": -0.25934410095214844,
      "step": 425
    },
    {
      "epoch": 0.1704,
      "grad_norm": 6.179605484008789,
      "learning_rate": 9.433333333333333e-07,
      "logits/chosen": -2.3468103408813477,
      "logits/rejected": -0.9958484768867493,
      "logps/chosen": -125.40372467041016,
      "logps/rejected": -82.32990264892578,
      "loss": 0.1436,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3836288452148438,
      "rewards/margins": 1.8683381080627441,
      "rewards/rejected": -0.4847091734409332,
      "step": 426
    },
    {
      "epoch": 0.1708,
      "grad_norm": 6.535146236419678,
      "learning_rate": 9.432e-07,
      "logits/chosen": -2.2682557106018066,
      "logits/rejected": -2.063283920288086,
      "logps/chosen": -134.14938354492188,
      "logps/rejected": -100.34223937988281,
      "loss": 0.1435,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4050865173339844,
      "rewards/margins": 1.9089516401290894,
      "rewards/rejected": -0.5038650631904602,
      "step": 427
    },
    {
      "epoch": 0.1712,
      "grad_norm": 5.884174823760986,
      "learning_rate": 9.430666666666667e-07,
      "logits/chosen": -1.8248474597930908,
      "logits/rejected": -2.3534207344055176,
      "logps/chosen": -134.84408569335938,
      "logps/rejected": -97.16986846923828,
      "loss": 0.1436,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4124809503555298,
      "rewards/margins": 1.9432317018508911,
      "rewards/rejected": -0.5307506918907166,
      "step": 428
    },
    {
      "epoch": 0.1716,
      "grad_norm": 8.814674377441406,
      "learning_rate": 9.429333333333332e-07,
      "logits/chosen": -2.276615619659424,
      "logits/rejected": -2.6491267681121826,
      "logps/chosen": -113.9880599975586,
      "logps/rejected": -118.1513900756836,
      "loss": 0.2398,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8845447301864624,
      "rewards/margins": 1.316028118133545,
      "rewards/rejected": -0.4314834475517273,
      "step": 429
    },
    {
      "epoch": 0.172,
      "grad_norm": 6.068268299102783,
      "learning_rate": 9.427999999999999e-07,
      "logits/chosen": -2.0569188594818115,
      "logits/rejected": -2.561729907989502,
      "logps/chosen": -114.49224853515625,
      "logps/rejected": -103.50003051757812,
      "loss": 0.1569,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.107407808303833,
      "rewards/margins": 1.87101411819458,
      "rewards/rejected": -0.7636063098907471,
      "step": 430
    },
    {
      "epoch": 0.1724,
      "grad_norm": 7.818686008453369,
      "learning_rate": 9.426666666666666e-07,
      "logits/chosen": -2.3460164070129395,
      "logits/rejected": -2.8258485794067383,
      "logps/chosen": -143.8641357421875,
      "logps/rejected": -120.41709899902344,
      "loss": 0.2017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.561100721359253,
      "rewards/margins": 1.5937714576721191,
      "rewards/rejected": -0.03267059102654457,
      "step": 431
    },
    {
      "epoch": 0.1728,
      "grad_norm": 11.137125015258789,
      "learning_rate": 9.425333333333333e-07,
      "logits/chosen": -2.2966296672821045,
      "logits/rejected": -1.9364142417907715,
      "logps/chosen": -149.65728759765625,
      "logps/rejected": -105.409912109375,
      "loss": 0.2959,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0997109413146973,
      "rewards/margins": 1.076439380645752,
      "rewards/rejected": 0.023271560668945312,
      "step": 432
    },
    {
      "epoch": 0.1732,
      "grad_norm": 5.980758190155029,
      "learning_rate": 9.424e-07,
      "logits/chosen": -2.1824090480804443,
      "logits/rejected": -2.2439587116241455,
      "logps/chosen": -187.43394470214844,
      "logps/rejected": -115.23277282714844,
      "loss": 0.1324,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.54509699344635,
      "rewards/margins": 1.9552574157714844,
      "rewards/rejected": -0.4101604223251343,
      "step": 433
    },
    {
      "epoch": 0.1736,
      "grad_norm": 8.1349458694458,
      "learning_rate": 9.422666666666667e-07,
      "logits/chosen": -1.4908968210220337,
      "logits/rejected": -1.942918062210083,
      "logps/chosen": -103.36329650878906,
      "logps/rejected": -93.49767303466797,
      "loss": 0.2925,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5786159634590149,
      "rewards/margins": 1.2599185705184937,
      "rewards/rejected": -0.6813026666641235,
      "step": 434
    },
    {
      "epoch": 0.174,
      "grad_norm": 13.22981071472168,
      "learning_rate": 9.421333333333334e-07,
      "logits/chosen": -2.3302969932556152,
      "logits/rejected": -2.616847038269043,
      "logps/chosen": -179.09432983398438,
      "logps/rejected": -130.3411407470703,
      "loss": 0.3163,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6278091669082642,
      "rewards/margins": 0.991899847984314,
      "rewards/rejected": -0.3640907406806946,
      "step": 435
    },
    {
      "epoch": 0.1744,
      "grad_norm": 7.862563133239746,
      "learning_rate": 9.419999999999999e-07,
      "logits/chosen": -2.053072929382324,
      "logits/rejected": -1.8508379459381104,
      "logps/chosen": -126.90092468261719,
      "logps/rejected": -100.38697814941406,
      "loss": 0.2113,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9883193969726562,
      "rewards/margins": 1.656222939491272,
      "rewards/rejected": -0.6679035425186157,
      "step": 436
    },
    {
      "epoch": 0.1748,
      "grad_norm": 6.747744560241699,
      "learning_rate": 9.418666666666666e-07,
      "logits/chosen": -1.9168550968170166,
      "logits/rejected": -1.7541354894638062,
      "logps/chosen": -138.14523315429688,
      "logps/rejected": -115.1312255859375,
      "loss": 0.1521,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2456600666046143,
      "rewards/margins": 1.8072396516799927,
      "rewards/rejected": -0.5615795254707336,
      "step": 437
    },
    {
      "epoch": 0.1752,
      "grad_norm": 5.787333965301514,
      "learning_rate": 9.417333333333332e-07,
      "logits/chosen": -1.9010568857192993,
      "logits/rejected": -3.181495189666748,
      "logps/chosen": -164.4212646484375,
      "logps/rejected": -112.22901916503906,
      "loss": 0.1842,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2456135749816895,
      "rewards/margins": 1.814113736152649,
      "rewards/rejected": -0.5685001611709595,
      "step": 438
    },
    {
      "epoch": 0.1756,
      "grad_norm": 7.601593494415283,
      "learning_rate": 9.415999999999999e-07,
      "logits/chosen": -2.4204039573669434,
      "logits/rejected": -1.974669337272644,
      "logps/chosen": -187.41041564941406,
      "logps/rejected": -104.352294921875,
      "loss": 0.1447,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5117676258087158,
      "rewards/margins": 1.9046318531036377,
      "rewards/rejected": -0.3928642272949219,
      "step": 439
    },
    {
      "epoch": 0.176,
      "grad_norm": 7.6505937576293945,
      "learning_rate": 9.414666666666666e-07,
      "logits/chosen": -2.194939136505127,
      "logits/rejected": -2.2222583293914795,
      "logps/chosen": -147.02491760253906,
      "logps/rejected": -146.78890991210938,
      "loss": 0.1643,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2609658241271973,
      "rewards/margins": 2.0199334621429443,
      "rewards/rejected": -0.7589676380157471,
      "step": 440
    },
    {
      "epoch": 0.1764,
      "grad_norm": 12.316521644592285,
      "learning_rate": 9.413333333333333e-07,
      "logits/chosen": -1.9452686309814453,
      "logits/rejected": -2.38389253616333,
      "logps/chosen": -131.67819213867188,
      "logps/rejected": -108.72720336914062,
      "loss": 0.2448,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3599029779434204,
      "rewards/margins": 1.3122456073760986,
      "rewards/rejected": 0.04765739291906357,
      "step": 441
    },
    {
      "epoch": 0.1768,
      "grad_norm": 4.64815092086792,
      "learning_rate": 9.412e-07,
      "logits/chosen": -2.4159021377563477,
      "logits/rejected": -3.33536958694458,
      "logps/chosen": -216.40895080566406,
      "logps/rejected": -198.18710327148438,
      "loss": 0.0888,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9821555614471436,
      "rewards/margins": 2.3874523639678955,
      "rewards/rejected": -0.4052967131137848,
      "step": 442
    },
    {
      "epoch": 0.1772,
      "grad_norm": 7.3499932289123535,
      "learning_rate": 9.410666666666667e-07,
      "logits/chosen": -1.7514774799346924,
      "logits/rejected": -1.9795430898666382,
      "logps/chosen": -118.07240295410156,
      "logps/rejected": -152.90371704101562,
      "loss": 0.1691,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6114898920059204,
      "rewards/margins": 1.735388994216919,
      "rewards/rejected": -0.12389908730983734,
      "step": 443
    },
    {
      "epoch": 0.1776,
      "grad_norm": 7.234891414642334,
      "learning_rate": 9.409333333333333e-07,
      "logits/chosen": -2.02608585357666,
      "logits/rejected": -1.2404935359954834,
      "logps/chosen": -103.52883911132812,
      "logps/rejected": -82.70048522949219,
      "loss": 0.1866,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5756187438964844,
      "rewards/margins": 1.609704613685608,
      "rewards/rejected": -0.034085847437381744,
      "step": 444
    },
    {
      "epoch": 0.178,
      "grad_norm": 9.575199127197266,
      "learning_rate": 9.408e-07,
      "logits/chosen": -2.07270884513855,
      "logits/rejected": -1.8885571956634521,
      "logps/chosen": -138.49627685546875,
      "logps/rejected": -98.65254211425781,
      "loss": 0.4402,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.6128708124160767,
      "rewards/margins": 0.8972675204277039,
      "rewards/rejected": -0.284396767616272,
      "step": 445
    },
    {
      "epoch": 0.1784,
      "grad_norm": 6.634030818939209,
      "learning_rate": 9.406666666666666e-07,
      "logits/chosen": -1.5759129524230957,
      "logits/rejected": -2.458585262298584,
      "logps/chosen": -148.43994140625,
      "logps/rejected": -109.31562805175781,
      "loss": 0.1692,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4010944366455078,
      "rewards/margins": 1.720193862915039,
      "rewards/rejected": -0.31909945607185364,
      "step": 446
    },
    {
      "epoch": 0.1788,
      "grad_norm": 5.504769325256348,
      "learning_rate": 9.405333333333333e-07,
      "logits/chosen": -2.127640962600708,
      "logits/rejected": -1.6023845672607422,
      "logps/chosen": -106.97239685058594,
      "logps/rejected": -73.93147277832031,
      "loss": 0.1532,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3446674346923828,
      "rewards/margins": 1.8087456226348877,
      "rewards/rejected": -0.4640781283378601,
      "step": 447
    },
    {
      "epoch": 0.1792,
      "grad_norm": 6.930108547210693,
      "learning_rate": 9.403999999999999e-07,
      "logits/chosen": -2.1305220127105713,
      "logits/rejected": -1.2350587844848633,
      "logps/chosen": -145.03695678710938,
      "logps/rejected": -91.62367248535156,
      "loss": 0.1965,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4827752113342285,
      "rewards/margins": 1.5541744232177734,
      "rewards/rejected": -0.07139930874109268,
      "step": 448
    },
    {
      "epoch": 0.1796,
      "grad_norm": 9.250455856323242,
      "learning_rate": 9.402666666666666e-07,
      "logits/chosen": -2.6436195373535156,
      "logits/rejected": -1.6963984966278076,
      "logps/chosen": -203.39376831054688,
      "logps/rejected": -105.1161117553711,
      "loss": 0.2157,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2963128089904785,
      "rewards/margins": 1.4723851680755615,
      "rewards/rejected": -0.17607231438159943,
      "step": 449
    },
    {
      "epoch": 0.18,
      "grad_norm": 5.300508975982666,
      "learning_rate": 9.401333333333333e-07,
      "logits/chosen": -2.1291260719299316,
      "logits/rejected": -2.3204665184020996,
      "logps/chosen": -203.15408325195312,
      "logps/rejected": -100.4522933959961,
      "loss": 0.1209,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9568657875061035,
      "rewards/margins": 2.1259963512420654,
      "rewards/rejected": -0.16913071274757385,
      "step": 450
    },
    {
      "epoch": 0.1804,
      "grad_norm": 4.042469024658203,
      "learning_rate": 9.399999999999999e-07,
      "logits/chosen": -2.47550106048584,
      "logits/rejected": -2.9114866256713867,
      "logps/chosen": -161.17791748046875,
      "logps/rejected": -107.19690704345703,
      "loss": 0.0761,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5642235279083252,
      "rewards/margins": 2.5698370933532715,
      "rewards/rejected": -1.0056136846542358,
      "step": 451
    },
    {
      "epoch": 0.1808,
      "grad_norm": 10.688429832458496,
      "learning_rate": 9.398666666666666e-07,
      "logits/chosen": -2.0545477867126465,
      "logits/rejected": -2.1191048622131348,
      "logps/chosen": -133.54193115234375,
      "logps/rejected": -85.60525512695312,
      "loss": 0.23,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7820972800254822,
      "rewards/margins": 1.366734266281128,
      "rewards/rejected": -0.5846370458602905,
      "step": 452
    },
    {
      "epoch": 0.1812,
      "grad_norm": 3.32944393157959,
      "learning_rate": 9.397333333333333e-07,
      "logits/chosen": -2.142470359802246,
      "logits/rejected": -2.7580747604370117,
      "logps/chosen": -116.7171401977539,
      "logps/rejected": -111.27946472167969,
      "loss": 0.0633,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6816718578338623,
      "rewards/margins": 2.7443270683288574,
      "rewards/rejected": -1.0626552104949951,
      "step": 453
    },
    {
      "epoch": 0.1816,
      "grad_norm": 6.971113204956055,
      "learning_rate": 9.396e-07,
      "logits/chosen": -2.113433837890625,
      "logits/rejected": -2.282649517059326,
      "logps/chosen": -130.66732788085938,
      "logps/rejected": -135.16641235351562,
      "loss": 0.1176,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7894141674041748,
      "rewards/margins": 2.189654588699341,
      "rewards/rejected": -0.40024030208587646,
      "step": 454
    },
    {
      "epoch": 0.182,
      "grad_norm": 7.704702854156494,
      "learning_rate": 9.394666666666667e-07,
      "logits/chosen": -2.1240177154541016,
      "logits/rejected": -2.2992191314697266,
      "logps/chosen": -103.53217315673828,
      "logps/rejected": -106.92797088623047,
      "loss": 0.173,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.320868730545044,
      "rewards/margins": 1.6792826652526855,
      "rewards/rejected": -0.35841408371925354,
      "step": 455
    },
    {
      "epoch": 0.1824,
      "grad_norm": 10.083902359008789,
      "learning_rate": 9.393333333333334e-07,
      "logits/chosen": -1.9764409065246582,
      "logits/rejected": -1.1617236137390137,
      "logps/chosen": -134.4671173095703,
      "logps/rejected": -82.9744873046875,
      "loss": 0.3405,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9935131072998047,
      "rewards/margins": 1.0585845708847046,
      "rewards/rejected": -0.0650714859366417,
      "step": 456
    },
    {
      "epoch": 0.1828,
      "grad_norm": 6.4895148277282715,
      "learning_rate": 9.391999999999999e-07,
      "logits/chosen": -2.176215171813965,
      "logits/rejected": -2.926297903060913,
      "logps/chosen": -212.63372802734375,
      "logps/rejected": -159.96017456054688,
      "loss": 0.124,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5062682628631592,
      "rewards/margins": 2.0947251319885254,
      "rewards/rejected": -0.5884567499160767,
      "step": 457
    },
    {
      "epoch": 0.1832,
      "grad_norm": 5.975185394287109,
      "learning_rate": 9.390666666666666e-07,
      "logits/chosen": -2.3848628997802734,
      "logits/rejected": -2.3087618350982666,
      "logps/chosen": -157.17202758789062,
      "logps/rejected": -97.91046905517578,
      "loss": 0.1304,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2610931396484375,
      "rewards/margins": 2.0017876625061035,
      "rewards/rejected": -0.7406944632530212,
      "step": 458
    },
    {
      "epoch": 0.1836,
      "grad_norm": 18.055784225463867,
      "learning_rate": 9.389333333333332e-07,
      "logits/chosen": -1.391488790512085,
      "logits/rejected": -2.138089418411255,
      "logps/chosen": -107.22169494628906,
      "logps/rejected": -115.40748596191406,
      "loss": 0.478,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0745006799697876,
      "rewards/margins": 0.7484028339385986,
      "rewards/rejected": -0.673902153968811,
      "step": 459
    },
    {
      "epoch": 0.184,
      "grad_norm": 3.3201849460601807,
      "learning_rate": 9.387999999999999e-07,
      "logits/chosen": -2.0140299797058105,
      "logits/rejected": -2.1154141426086426,
      "logps/chosen": -131.0970458984375,
      "logps/rejected": -100.79759979248047,
      "loss": 0.0771,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8930022716522217,
      "rewards/margins": 2.523904800415039,
      "rewards/rejected": -0.6309025287628174,
      "step": 460
    },
    {
      "epoch": 0.1844,
      "grad_norm": 12.132363319396973,
      "learning_rate": 9.386666666666666e-07,
      "logits/chosen": -1.4297386407852173,
      "logits/rejected": -2.849109649658203,
      "logps/chosen": -77.12767028808594,
      "logps/rejected": -97.65412902832031,
      "loss": 0.3881,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5588917136192322,
      "rewards/margins": 0.7522026300430298,
      "rewards/rejected": -0.19331094622612,
      "step": 461
    },
    {
      "epoch": 0.1848,
      "grad_norm": 5.204902648925781,
      "learning_rate": 9.385333333333333e-07,
      "logits/chosen": -2.268874168395996,
      "logits/rejected": -2.6243464946746826,
      "logps/chosen": -130.04022216796875,
      "logps/rejected": -137.17710876464844,
      "loss": 0.0879,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8182837963104248,
      "rewards/margins": 2.3945412635803223,
      "rewards/rejected": -0.5762573480606079,
      "step": 462
    },
    {
      "epoch": 0.1852,
      "grad_norm": 9.027400016784668,
      "learning_rate": 9.384e-07,
      "logits/chosen": -1.9738661050796509,
      "logits/rejected": -1.3579847812652588,
      "logps/chosen": -151.41860961914062,
      "logps/rejected": -98.27037048339844,
      "loss": 0.3418,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1727256774902344,
      "rewards/margins": 1.5565627813339233,
      "rewards/rejected": -0.38383713364601135,
      "step": 463
    },
    {
      "epoch": 0.1856,
      "grad_norm": 6.04000186920166,
      "learning_rate": 9.382666666666667e-07,
      "logits/chosen": -1.8526535034179688,
      "logits/rejected": -2.176706075668335,
      "logps/chosen": -121.70663452148438,
      "logps/rejected": -100.78193664550781,
      "loss": 0.1241,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0633249282836914,
      "rewards/margins": 2.1793699264526367,
      "rewards/rejected": -0.11604499816894531,
      "step": 464
    },
    {
      "epoch": 0.186,
      "grad_norm": 6.481776714324951,
      "learning_rate": 9.381333333333334e-07,
      "logits/chosen": -2.1348252296447754,
      "logits/rejected": -2.245180606842041,
      "logps/chosen": -161.78897094726562,
      "logps/rejected": -104.4202880859375,
      "loss": 0.1568,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.434721827507019,
      "rewards/margins": 1.7838444709777832,
      "rewards/rejected": -0.34912264347076416,
      "step": 465
    },
    {
      "epoch": 0.1864,
      "grad_norm": 9.108842849731445,
      "learning_rate": 9.379999999999998e-07,
      "logits/chosen": -1.861648678779602,
      "logits/rejected": -2.655672550201416,
      "logps/chosen": -85.4677734375,
      "logps/rejected": -103.27925109863281,
      "loss": 0.2284,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1527760028839111,
      "rewards/margins": 1.6360622644424438,
      "rewards/rejected": -0.4832862615585327,
      "step": 466
    },
    {
      "epoch": 0.1868,
      "grad_norm": 4.975726127624512,
      "learning_rate": 9.378666666666665e-07,
      "logits/chosen": -1.9347612857818604,
      "logits/rejected": -2.7255496978759766,
      "logps/chosen": -155.42257690429688,
      "logps/rejected": -137.68121337890625,
      "loss": 0.0861,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.871163249015808,
      "rewards/margins": 2.4128637313842773,
      "rewards/rejected": -0.5417003631591797,
      "step": 467
    },
    {
      "epoch": 0.1872,
      "grad_norm": 7.5759596824646,
      "learning_rate": 9.377333333333332e-07,
      "logits/chosen": -2.5957915782928467,
      "logits/rejected": -2.233893394470215,
      "logps/chosen": -171.5383758544922,
      "logps/rejected": -115.33436584472656,
      "loss": 0.1749,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.463759183883667,
      "rewards/margins": 1.6928398609161377,
      "rewards/rejected": -0.22908057272434235,
      "step": 468
    },
    {
      "epoch": 0.1876,
      "grad_norm": 7.440673828125,
      "learning_rate": 9.375999999999999e-07,
      "logits/chosen": -1.7707229852676392,
      "logits/rejected": -2.1156740188598633,
      "logps/chosen": -135.9198455810547,
      "logps/rejected": -95.57026672363281,
      "loss": 0.2197,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3008906841278076,
      "rewards/margins": 1.5213226079940796,
      "rewards/rejected": -0.22043190896511078,
      "step": 469
    },
    {
      "epoch": 0.188,
      "grad_norm": 7.3313679695129395,
      "learning_rate": 9.374666666666666e-07,
      "logits/chosen": -2.0598385334014893,
      "logits/rejected": -2.0804684162139893,
      "logps/chosen": -159.87742614746094,
      "logps/rejected": -178.82406616210938,
      "loss": 0.167,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9132914543151855,
      "rewards/margins": 1.7949976921081543,
      "rewards/rejected": 0.11829376965761185,
      "step": 470
    },
    {
      "epoch": 0.1884,
      "grad_norm": 5.165286064147949,
      "learning_rate": 9.373333333333333e-07,
      "logits/chosen": -1.6266288757324219,
      "logits/rejected": -1.555564045906067,
      "logps/chosen": -80.11933898925781,
      "logps/rejected": -84.73303985595703,
      "loss": 0.116,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4195873737335205,
      "rewards/margins": 2.104351043701172,
      "rewards/rejected": -0.6847637295722961,
      "step": 471
    },
    {
      "epoch": 0.1888,
      "grad_norm": 6.676267623901367,
      "learning_rate": 9.372e-07,
      "logits/chosen": -1.274720311164856,
      "logits/rejected": -0.9806585311889648,
      "logps/chosen": -74.62461853027344,
      "logps/rejected": -70.06828308105469,
      "loss": 0.1839,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3631412982940674,
      "rewards/margins": 1.7829976081848145,
      "rewards/rejected": -0.4198562800884247,
      "step": 472
    },
    {
      "epoch": 0.1892,
      "grad_norm": 5.950916767120361,
      "learning_rate": 9.370666666666667e-07,
      "logits/chosen": -2.2108678817749023,
      "logits/rejected": -2.193936586380005,
      "logps/chosen": -177.296142578125,
      "logps/rejected": -107.01580810546875,
      "loss": 0.1448,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.676648736000061,
      "rewards/margins": 1.9884960651397705,
      "rewards/rejected": -0.3118473291397095,
      "step": 473
    },
    {
      "epoch": 0.1896,
      "grad_norm": 9.389249801635742,
      "learning_rate": 9.369333333333333e-07,
      "logits/chosen": -1.9428333044052124,
      "logits/rejected": -1.8118391036987305,
      "logps/chosen": -160.3140869140625,
      "logps/rejected": -89.69818115234375,
      "loss": 0.1643,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.320764183998108,
      "rewards/margins": 1.8144879341125488,
      "rewards/rejected": -0.49372369050979614,
      "step": 474
    },
    {
      "epoch": 0.19,
      "grad_norm": 3.5098044872283936,
      "learning_rate": 9.368e-07,
      "logits/chosen": -2.639662265777588,
      "logits/rejected": -2.2615902423858643,
      "logps/chosen": -224.0150146484375,
      "logps/rejected": -119.14244842529297,
      "loss": 0.0584,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.16938853263855,
      "rewards/margins": 2.824075698852539,
      "rewards/rejected": -0.6546871662139893,
      "step": 475
    },
    {
      "epoch": 0.1904,
      "grad_norm": 7.909759998321533,
      "learning_rate": 9.366666666666666e-07,
      "logits/chosen": -2.3286094665527344,
      "logits/rejected": -2.8753740787506104,
      "logps/chosen": -184.1855926513672,
      "logps/rejected": -125.60003662109375,
      "loss": 0.2286,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5114414691925049,
      "rewards/margins": 1.6209359169006348,
      "rewards/rejected": -0.1094944030046463,
      "step": 476
    },
    {
      "epoch": 0.1908,
      "grad_norm": 2.9873569011688232,
      "learning_rate": 9.365333333333332e-07,
      "logits/chosen": -2.0419881343841553,
      "logits/rejected": -2.9406967163085938,
      "logps/chosen": -190.1077880859375,
      "logps/rejected": -136.4575653076172,
      "loss": 0.0522,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6683974266052246,
      "rewards/margins": 2.9302597045898438,
      "rewards/rejected": -0.261862188577652,
      "step": 477
    },
    {
      "epoch": 0.1912,
      "grad_norm": 5.245849132537842,
      "learning_rate": 9.363999999999999e-07,
      "logits/chosen": -1.902796983718872,
      "logits/rejected": -2.4646544456481934,
      "logps/chosen": -103.12382507324219,
      "logps/rejected": -112.0045166015625,
      "loss": 0.1264,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7631611824035645,
      "rewards/margins": 2.2770779132843018,
      "rewards/rejected": -0.5139167904853821,
      "step": 478
    },
    {
      "epoch": 0.1916,
      "grad_norm": 8.573039054870605,
      "learning_rate": 9.362666666666666e-07,
      "logits/chosen": -2.6905782222747803,
      "logits/rejected": -1.7225764989852905,
      "logps/chosen": -168.5077362060547,
      "logps/rejected": -104.77801513671875,
      "loss": 0.1503,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2822175025939941,
      "rewards/margins": 1.8196285963058472,
      "rewards/rejected": -0.5374111533164978,
      "step": 479
    },
    {
      "epoch": 0.192,
      "grad_norm": 6.761692523956299,
      "learning_rate": 9.361333333333333e-07,
      "logits/chosen": -2.4644131660461426,
      "logits/rejected": -2.5562548637390137,
      "logps/chosen": -150.86978149414062,
      "logps/rejected": -101.41934967041016,
      "loss": 0.1804,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8817596435546875,
      "rewards/margins": 1.7961888313293457,
      "rewards/rejected": 0.08557091653347015,
      "step": 480
    },
    {
      "epoch": 0.1924,
      "grad_norm": 7.2054619789123535,
      "learning_rate": 9.36e-07,
      "logits/chosen": -1.875030279159546,
      "logits/rejected": -2.1668243408203125,
      "logps/chosen": -92.24864196777344,
      "logps/rejected": -107.23648071289062,
      "loss": 0.172,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0622665882110596,
      "rewards/margins": 1.6880345344543457,
      "rewards/rejected": -0.6257679462432861,
      "step": 481
    },
    {
      "epoch": 0.1928,
      "grad_norm": 3.2494962215423584,
      "learning_rate": 9.358666666666666e-07,
      "logits/chosen": -2.011373996734619,
      "logits/rejected": -1.9632880687713623,
      "logps/chosen": -118.10133361816406,
      "logps/rejected": -108.17488098144531,
      "loss": 0.0643,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.148768186569214,
      "rewards/margins": 2.7185707092285156,
      "rewards/rejected": -0.5698025226593018,
      "step": 482
    },
    {
      "epoch": 0.1932,
      "grad_norm": 6.263394832611084,
      "learning_rate": 9.357333333333333e-07,
      "logits/chosen": -1.5265491008758545,
      "logits/rejected": -1.8561413288116455,
      "logps/chosen": -113.87718200683594,
      "logps/rejected": -96.06974792480469,
      "loss": 0.1597,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2007758617401123,
      "rewards/margins": 1.777627944946289,
      "rewards/rejected": -0.5768520832061768,
      "step": 483
    },
    {
      "epoch": 0.1936,
      "grad_norm": 7.649388313293457,
      "learning_rate": 9.356e-07,
      "logits/chosen": -2.1203877925872803,
      "logits/rejected": -2.2890663146972656,
      "logps/chosen": -101.34011840820312,
      "logps/rejected": -107.54862976074219,
      "loss": 0.1852,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4202160835266113,
      "rewards/margins": 1.5923199653625488,
      "rewards/rejected": -0.1721038818359375,
      "step": 484
    },
    {
      "epoch": 0.194,
      "grad_norm": 8.296296119689941,
      "learning_rate": 9.354666666666667e-07,
      "logits/chosen": -2.304760217666626,
      "logits/rejected": -2.0613529682159424,
      "logps/chosen": -170.64195251464844,
      "logps/rejected": -107.89627838134766,
      "loss": 0.1747,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4068171977996826,
      "rewards/margins": 1.7733074426651,
      "rewards/rejected": -0.3664901852607727,
      "step": 485
    },
    {
      "epoch": 0.1944,
      "grad_norm": 7.827240467071533,
      "learning_rate": 9.353333333333333e-07,
      "logits/chosen": -1.635887861251831,
      "logits/rejected": -2.829770803451538,
      "logps/chosen": -105.89061737060547,
      "logps/rejected": -108.74900817871094,
      "loss": 0.1696,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7939281463623047,
      "rewards/margins": 1.7054401636123657,
      "rewards/rejected": -0.911512017250061,
      "step": 486
    },
    {
      "epoch": 0.1948,
      "grad_norm": 5.5571699142456055,
      "learning_rate": 9.352e-07,
      "logits/chosen": -1.6761243343353271,
      "logits/rejected": -2.4692819118499756,
      "logps/chosen": -92.88251495361328,
      "logps/rejected": -120.38194274902344,
      "loss": 0.1136,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.330418348312378,
      "rewards/margins": 2.1547462940216064,
      "rewards/rejected": -0.8243278861045837,
      "step": 487
    },
    {
      "epoch": 0.1952,
      "grad_norm": 4.8322930335998535,
      "learning_rate": 9.350666666666666e-07,
      "logits/chosen": -1.980518102645874,
      "logits/rejected": -1.4668534994125366,
      "logps/chosen": -101.28154754638672,
      "logps/rejected": -75.36158752441406,
      "loss": 0.1067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6772751808166504,
      "rewards/margins": 2.2135226726531982,
      "rewards/rejected": -0.5362476706504822,
      "step": 488
    },
    {
      "epoch": 0.1956,
      "grad_norm": 11.600099563598633,
      "learning_rate": 9.349333333333332e-07,
      "logits/chosen": -1.902313470840454,
      "logits/rejected": -2.3676528930664062,
      "logps/chosen": -141.4244384765625,
      "logps/rejected": -116.42291259765625,
      "loss": 0.2581,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0769004821777344,
      "rewards/margins": 1.6776984930038452,
      "rewards/rejected": -0.6007980704307556,
      "step": 489
    },
    {
      "epoch": 0.196,
      "grad_norm": 4.391833305358887,
      "learning_rate": 9.347999999999999e-07,
      "logits/chosen": -1.9164855480194092,
      "logits/rejected": -2.018462896347046,
      "logps/chosen": -86.02653503417969,
      "logps/rejected": -94.04102325439453,
      "loss": 0.1106,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4922528266906738,
      "rewards/margins": 2.1474504470825195,
      "rewards/rejected": -0.6551975607872009,
      "step": 490
    },
    {
      "epoch": 0.1964,
      "grad_norm": 4.494683265686035,
      "learning_rate": 9.346666666666666e-07,
      "logits/chosen": -2.0389132499694824,
      "logits/rejected": -2.354536294937134,
      "logps/chosen": -181.27871704101562,
      "logps/rejected": -123.42303466796875,
      "loss": 0.0951,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7625961303710938,
      "rewards/margins": 2.3136444091796875,
      "rewards/rejected": -0.5510482788085938,
      "step": 491
    },
    {
      "epoch": 0.1968,
      "grad_norm": 9.418853759765625,
      "learning_rate": 9.345333333333333e-07,
      "logits/chosen": -1.9829561710357666,
      "logits/rejected": -1.9130961894989014,
      "logps/chosen": -147.15000915527344,
      "logps/rejected": -92.23004150390625,
      "loss": 0.2478,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5768696069717407,
      "rewards/margins": 1.2890231609344482,
      "rewards/rejected": -0.7121536135673523,
      "step": 492
    },
    {
      "epoch": 0.1972,
      "grad_norm": 7.2088165283203125,
      "learning_rate": 9.344e-07,
      "logits/chosen": -1.5732342004776,
      "logits/rejected": -2.444749355316162,
      "logps/chosen": -93.45362854003906,
      "logps/rejected": -90.08836364746094,
      "loss": 0.2023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.806311845779419,
      "rewards/margins": 1.6226593255996704,
      "rewards/rejected": -0.8163474798202515,
      "step": 493
    },
    {
      "epoch": 0.1976,
      "grad_norm": 7.227087497711182,
      "learning_rate": 9.342666666666667e-07,
      "logits/chosen": -1.7847840785980225,
      "logits/rejected": -2.924168109893799,
      "logps/chosen": -104.07260131835938,
      "logps/rejected": -131.7213134765625,
      "loss": 0.1754,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4224357604980469,
      "rewards/margins": 1.7949786186218262,
      "rewards/rejected": -0.37254294753074646,
      "step": 494
    },
    {
      "epoch": 0.198,
      "grad_norm": 10.597424507141113,
      "learning_rate": 9.341333333333333e-07,
      "logits/chosen": -2.2907211780548096,
      "logits/rejected": -2.5026845932006836,
      "logps/chosen": -136.13319396972656,
      "logps/rejected": -157.5258026123047,
      "loss": 0.2759,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9583473205566406,
      "rewards/margins": 1.3819308280944824,
      "rewards/rejected": -0.42358362674713135,
      "step": 495
    },
    {
      "epoch": 0.1984,
      "grad_norm": 4.1756157875061035,
      "learning_rate": 9.34e-07,
      "logits/chosen": -2.379871368408203,
      "logits/rejected": -2.3513474464416504,
      "logps/chosen": -142.880615234375,
      "logps/rejected": -94.85346221923828,
      "loss": 0.0945,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8144347667694092,
      "rewards/margins": 2.311368465423584,
      "rewards/rejected": -0.4969337582588196,
      "step": 496
    },
    {
      "epoch": 0.1988,
      "grad_norm": 8.597823143005371,
      "learning_rate": 9.338666666666666e-07,
      "logits/chosen": -2.07090163230896,
      "logits/rejected": -2.977062225341797,
      "logps/chosen": -171.72543334960938,
      "logps/rejected": -114.67951965332031,
      "loss": 0.1669,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9353339672088623,
      "rewards/margins": 1.8114227056503296,
      "rewards/rejected": -0.8760887384414673,
      "step": 497
    },
    {
      "epoch": 0.1992,
      "grad_norm": 10.794647216796875,
      "learning_rate": 9.337333333333333e-07,
      "logits/chosen": -1.734929084777832,
      "logits/rejected": -2.386897087097168,
      "logps/chosen": -87.17213439941406,
      "logps/rejected": -113.28622436523438,
      "loss": 0.2866,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7945491671562195,
      "rewards/margins": 1.664189100265503,
      "rewards/rejected": -0.8696399927139282,
      "step": 498
    },
    {
      "epoch": 0.1996,
      "grad_norm": 6.347395896911621,
      "learning_rate": 9.335999999999999e-07,
      "logits/chosen": -2.1863510608673096,
      "logits/rejected": -2.6890039443969727,
      "logps/chosen": -198.66835021972656,
      "logps/rejected": -109.26004791259766,
      "loss": 0.1534,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2794113159179688,
      "rewards/margins": 2.150639533996582,
      "rewards/rejected": -0.8712280988693237,
      "step": 499
    },
    {
      "epoch": 0.2,
      "grad_norm": 13.940518379211426,
      "learning_rate": 9.334666666666666e-07,
      "logits/chosen": -1.9059054851531982,
      "logits/rejected": -2.036984920501709,
      "logps/chosen": -116.38938903808594,
      "logps/rejected": -171.67164611816406,
      "loss": 0.2798,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0613521337509155,
      "rewards/margins": 1.1343482732772827,
      "rewards/rejected": -0.07299615442752838,
      "step": 500
    },
    {
      "epoch": 0.2004,
      "grad_norm": 8.061468124389648,
      "learning_rate": 9.333333333333333e-07,
      "logits/chosen": -2.34066104888916,
      "logits/rejected": -3.34915828704834,
      "logps/chosen": -122.47455596923828,
      "logps/rejected": -101.56172180175781,
      "loss": 0.1885,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2572883367538452,
      "rewards/margins": 1.6253037452697754,
      "rewards/rejected": -0.3680152893066406,
      "step": 501
    },
    {
      "epoch": 0.2008,
      "grad_norm": 11.606132507324219,
      "learning_rate": 9.332e-07,
      "logits/chosen": -2.2449567317962646,
      "logits/rejected": -2.422640323638916,
      "logps/chosen": -128.5067138671875,
      "logps/rejected": -116.58114624023438,
      "loss": 0.3194,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5791565179824829,
      "rewards/margins": 0.9822303652763367,
      "rewards/rejected": -0.40307387709617615,
      "step": 502
    },
    {
      "epoch": 0.2012,
      "grad_norm": 6.091205596923828,
      "learning_rate": 9.330666666666667e-07,
      "logits/chosen": -2.3752846717834473,
      "logits/rejected": -2.8104844093322754,
      "logps/chosen": -160.57070922851562,
      "logps/rejected": -142.38006591796875,
      "loss": 0.0979,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7417564392089844,
      "rewards/margins": 2.424215078353882,
      "rewards/rejected": -0.6824585199356079,
      "step": 503
    },
    {
      "epoch": 0.2016,
      "grad_norm": 5.132981300354004,
      "learning_rate": 9.329333333333332e-07,
      "logits/chosen": -2.3334970474243164,
      "logits/rejected": -2.7119503021240234,
      "logps/chosen": -159.86447143554688,
      "logps/rejected": -112.59825134277344,
      "loss": 0.1331,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2504478693008423,
      "rewards/margins": 2.005718231201172,
      "rewards/rejected": -0.7552704215049744,
      "step": 504
    },
    {
      "epoch": 0.202,
      "grad_norm": 6.313882350921631,
      "learning_rate": 9.327999999999999e-07,
      "logits/chosen": -2.3980395793914795,
      "logits/rejected": -2.643448829650879,
      "logps/chosen": -165.32369995117188,
      "logps/rejected": -107.30244445800781,
      "loss": 0.1302,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8517022132873535,
      "rewards/margins": 2.188805103302002,
      "rewards/rejected": -0.3371029198169708,
      "step": 505
    },
    {
      "epoch": 0.2024,
      "grad_norm": 4.633833408355713,
      "learning_rate": 9.326666666666666e-07,
      "logits/chosen": -2.3942010402679443,
      "logits/rejected": -2.236712694168091,
      "logps/chosen": -127.91885375976562,
      "logps/rejected": -100.73226165771484,
      "loss": 0.1035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0233891010284424,
      "rewards/margins": 2.3731911182403564,
      "rewards/rejected": -0.34980201721191406,
      "step": 506
    },
    {
      "epoch": 0.2028,
      "grad_norm": 6.689391136169434,
      "learning_rate": 9.325333333333333e-07,
      "logits/chosen": -1.9617741107940674,
      "logits/rejected": -2.7298288345336914,
      "logps/chosen": -141.82858276367188,
      "logps/rejected": -106.39894104003906,
      "loss": 0.1687,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5395160913467407,
      "rewards/margins": 1.7802479267120361,
      "rewards/rejected": -0.24073180556297302,
      "step": 507
    },
    {
      "epoch": 0.2032,
      "grad_norm": 4.192946434020996,
      "learning_rate": 9.324e-07,
      "logits/chosen": -2.070082664489746,
      "logits/rejected": -2.6764841079711914,
      "logps/chosen": -215.19357299804688,
      "logps/rejected": -179.49163818359375,
      "loss": 0.0697,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.213052272796631,
      "rewards/margins": 2.8321189880371094,
      "rewards/rejected": -0.619066596031189,
      "step": 508
    },
    {
      "epoch": 0.2036,
      "grad_norm": 5.330076694488525,
      "learning_rate": 9.322666666666667e-07,
      "logits/chosen": -2.248229742050171,
      "logits/rejected": -2.1239218711853027,
      "logps/chosen": -165.724609375,
      "logps/rejected": -128.76390075683594,
      "loss": 0.1162,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.563328504562378,
      "rewards/margins": 2.286799669265747,
      "rewards/rejected": -0.7234710454940796,
      "step": 509
    },
    {
      "epoch": 0.204,
      "grad_norm": 10.955513954162598,
      "learning_rate": 9.321333333333333e-07,
      "logits/chosen": -2.1721315383911133,
      "logits/rejected": -2.471055507659912,
      "logps/chosen": -164.7738037109375,
      "logps/rejected": -118.41771697998047,
      "loss": 0.2697,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6077102422714233,
      "rewards/margins": 1.17875337600708,
      "rewards/rejected": -0.5710430145263672,
      "step": 510
    },
    {
      "epoch": 0.2044,
      "grad_norm": 10.442501068115234,
      "learning_rate": 9.32e-07,
      "logits/chosen": -2.0005998611450195,
      "logits/rejected": -2.6251673698425293,
      "logps/chosen": -154.5841522216797,
      "logps/rejected": -123.58727264404297,
      "loss": 0.2738,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7635536193847656,
      "rewards/margins": 1.158346176147461,
      "rewards/rejected": -0.3947925567626953,
      "step": 511
    },
    {
      "epoch": 0.2048,
      "grad_norm": 10.34024715423584,
      "learning_rate": 9.318666666666666e-07,
      "logits/chosen": -1.9066263437271118,
      "logits/rejected": -2.4763245582580566,
      "logps/chosen": -95.86939239501953,
      "logps/rejected": -144.7663116455078,
      "loss": 0.2742,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7839027643203735,
      "rewards/margins": 1.161989688873291,
      "rewards/rejected": -0.3780868649482727,
      "step": 512
    },
    {
      "epoch": 0.2052,
      "grad_norm": 3.960362195968628,
      "learning_rate": 9.317333333333333e-07,
      "logits/chosen": -1.9978461265563965,
      "logits/rejected": -2.012683391571045,
      "logps/chosen": -168.5716552734375,
      "logps/rejected": -134.04898071289062,
      "loss": 0.0897,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2705495357513428,
      "rewards/margins": 2.4645657539367676,
      "rewards/rejected": -0.19401627779006958,
      "step": 513
    },
    {
      "epoch": 0.2056,
      "grad_norm": 3.8010120391845703,
      "learning_rate": 9.315999999999999e-07,
      "logits/chosen": -2.1080710887908936,
      "logits/rejected": -2.9360415935516357,
      "logps/chosen": -137.08108520507812,
      "logps/rejected": -124.10154724121094,
      "loss": 0.0684,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1974217891693115,
      "rewards/margins": 2.8576011657714844,
      "rewards/rejected": -0.6601795554161072,
      "step": 514
    },
    {
      "epoch": 0.206,
      "grad_norm": 4.854564189910889,
      "learning_rate": 9.314666666666666e-07,
      "logits/chosen": -2.324739933013916,
      "logits/rejected": -2.597329616546631,
      "logps/chosen": -162.18719482421875,
      "logps/rejected": -171.10263061523438,
      "loss": 0.0807,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.900201439857483,
      "rewards/margins": 2.482192277908325,
      "rewards/rejected": -0.5819908380508423,
      "step": 515
    },
    {
      "epoch": 0.2064,
      "grad_norm": 3.2335822582244873,
      "learning_rate": 9.313333333333333e-07,
      "logits/chosen": -1.9362287521362305,
      "logits/rejected": -1.9500513076782227,
      "logps/chosen": -108.2002182006836,
      "logps/rejected": -94.03109741210938,
      "loss": 0.0731,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0196890830993652,
      "rewards/margins": 2.593721866607666,
      "rewards/rejected": -0.5740326046943665,
      "step": 516
    },
    {
      "epoch": 0.2068,
      "grad_norm": 1.7654461860656738,
      "learning_rate": 9.312e-07,
      "logits/chosen": -2.5060510635375977,
      "logits/rejected": -2.60414457321167,
      "logps/chosen": -186.52133178710938,
      "logps/rejected": -121.45533752441406,
      "loss": 0.0287,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3722052574157715,
      "rewards/margins": 3.5664894580841064,
      "rewards/rejected": -1.1942840814590454,
      "step": 517
    },
    {
      "epoch": 0.2072,
      "grad_norm": 1.9872816801071167,
      "learning_rate": 9.310666666666667e-07,
      "logits/chosen": -2.0246059894561768,
      "logits/rejected": -2.7776737213134766,
      "logps/chosen": -135.18260192871094,
      "logps/rejected": -128.4952850341797,
      "loss": 0.0339,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0687530040740967,
      "rewards/margins": 3.3787193298339844,
      "rewards/rejected": -1.3099663257598877,
      "step": 518
    },
    {
      "epoch": 0.2076,
      "grad_norm": 8.403228759765625,
      "learning_rate": 9.309333333333333e-07,
      "logits/chosen": -2.011042594909668,
      "logits/rejected": -1.6528054475784302,
      "logps/chosen": -191.68197631835938,
      "logps/rejected": -98.7454605102539,
      "loss": 0.1706,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4736428260803223,
      "rewards/margins": 1.6934845447540283,
      "rewards/rejected": -0.21984176337718964,
      "step": 519
    },
    {
      "epoch": 0.208,
      "grad_norm": 2.142554759979248,
      "learning_rate": 9.307999999999999e-07,
      "logits/chosen": -1.8042792081832886,
      "logits/rejected": -2.91148042678833,
      "logps/chosen": -94.10345458984375,
      "logps/rejected": -128.07647705078125,
      "loss": 0.0414,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9781670570373535,
      "rewards/margins": 3.2218968868255615,
      "rewards/rejected": -1.243729829788208,
      "step": 520
    },
    {
      "epoch": 0.2084,
      "grad_norm": 11.745914459228516,
      "learning_rate": 9.306666666666666e-07,
      "logits/chosen": -2.3091044425964355,
      "logits/rejected": -2.490844964981079,
      "logps/chosen": -137.16847229003906,
      "logps/rejected": -99.60391235351562,
      "loss": 0.1994,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9724781513214111,
      "rewards/margins": 1.5674580335617065,
      "rewards/rejected": -0.5949798822402954,
      "step": 521
    },
    {
      "epoch": 0.2088,
      "grad_norm": 3.8497989177703857,
      "learning_rate": 9.305333333333333e-07,
      "logits/chosen": -2.3329851627349854,
      "logits/rejected": -2.154874324798584,
      "logps/chosen": -140.24830627441406,
      "logps/rejected": -103.74093627929688,
      "loss": 0.0784,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8731849193572998,
      "rewards/margins": 2.511683940887451,
      "rewards/rejected": -0.6384990811347961,
      "step": 522
    },
    {
      "epoch": 0.2092,
      "grad_norm": 9.97929573059082,
      "learning_rate": 9.303999999999999e-07,
      "logits/chosen": -1.9388933181762695,
      "logits/rejected": -2.5194199085235596,
      "logps/chosen": -98.15507507324219,
      "logps/rejected": -103.97845458984375,
      "loss": 0.293,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.035801649093628,
      "rewards/margins": 1.1688064336776733,
      "rewards/rejected": -0.13300475478172302,
      "step": 523
    },
    {
      "epoch": 0.2096,
      "grad_norm": 9.46906566619873,
      "learning_rate": 9.302666666666666e-07,
      "logits/chosen": -2.164567470550537,
      "logits/rejected": -2.879485845565796,
      "logps/chosen": -181.82583618164062,
      "logps/rejected": -114.92262268066406,
      "loss": 0.1835,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3956940174102783,
      "rewards/margins": 1.6661076545715332,
      "rewards/rejected": -0.2704135775566101,
      "step": 524
    },
    {
      "epoch": 0.21,
      "grad_norm": 7.801684856414795,
      "learning_rate": 9.301333333333333e-07,
      "logits/chosen": -2.194638729095459,
      "logits/rejected": -1.8523585796356201,
      "logps/chosen": -99.1300048828125,
      "logps/rejected": -81.2927474975586,
      "loss": 0.1943,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.956578016281128,
      "rewards/margins": 1.8204548358917236,
      "rewards/rejected": 0.13612328469753265,
      "step": 525
    },
    {
      "epoch": 0.2104,
      "grad_norm": 5.766552448272705,
      "learning_rate": 9.3e-07,
      "logits/chosen": -2.2930564880371094,
      "logits/rejected": -1.4864250421524048,
      "logps/chosen": -106.78300476074219,
      "logps/rejected": -80.27959442138672,
      "loss": 0.1432,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2654004096984863,
      "rewards/margins": 1.8823307752609253,
      "rewards/rejected": -0.616930365562439,
      "step": 526
    },
    {
      "epoch": 0.2108,
      "grad_norm": 5.2296462059021,
      "learning_rate": 9.298666666666666e-07,
      "logits/chosen": -2.1747851371765137,
      "logits/rejected": -2.899171829223633,
      "logps/chosen": -139.06375122070312,
      "logps/rejected": -127.78770446777344,
      "loss": 0.098,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4703361988067627,
      "rewards/margins": 2.2854061126708984,
      "rewards/rejected": -0.8150699734687805,
      "step": 527
    },
    {
      "epoch": 0.2112,
      "grad_norm": 8.327896118164062,
      "learning_rate": 9.297333333333333e-07,
      "logits/chosen": -2.568650960922241,
      "logits/rejected": -2.846795082092285,
      "logps/chosen": -201.46524047851562,
      "logps/rejected": -153.58688354492188,
      "loss": 0.1325,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.709869384765625,
      "rewards/margins": 2.1291422843933105,
      "rewards/rejected": -0.4192729890346527,
      "step": 528
    },
    {
      "epoch": 0.2116,
      "grad_norm": 4.584876537322998,
      "learning_rate": 9.296e-07,
      "logits/chosen": -2.382266044616699,
      "logits/rejected": -2.3085780143737793,
      "logps/chosen": -120.27632904052734,
      "logps/rejected": -89.17654418945312,
      "loss": 0.0972,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.917510986328125,
      "rewards/margins": 2.3541531562805176,
      "rewards/rejected": -0.4366421103477478,
      "step": 529
    },
    {
      "epoch": 0.212,
      "grad_norm": 3.335068941116333,
      "learning_rate": 9.294666666666667e-07,
      "logits/chosen": -2.248896360397339,
      "logits/rejected": -3.2816991806030273,
      "logps/chosen": -182.5233154296875,
      "logps/rejected": -119.84210205078125,
      "loss": 0.0608,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9551904201507568,
      "rewards/margins": 2.780116319656372,
      "rewards/rejected": -0.8249260187149048,
      "step": 530
    },
    {
      "epoch": 0.2124,
      "grad_norm": 3.947721242904663,
      "learning_rate": 9.293333333333333e-07,
      "logits/chosen": -1.3544588088989258,
      "logits/rejected": -2.3086771965026855,
      "logps/chosen": -97.50584411621094,
      "logps/rejected": -108.17301177978516,
      "loss": 0.062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8721497058868408,
      "rewards/margins": 2.8495891094207764,
      "rewards/rejected": -0.9774395227432251,
      "step": 531
    },
    {
      "epoch": 0.2128,
      "grad_norm": 9.49806022644043,
      "learning_rate": 9.292e-07,
      "logits/chosen": -1.7887885570526123,
      "logits/rejected": -2.7117953300476074,
      "logps/chosen": -107.69741821289062,
      "logps/rejected": -136.1416015625,
      "loss": 0.1795,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2809380292892456,
      "rewards/margins": 2.1246020793914795,
      "rewards/rejected": -0.8436641693115234,
      "step": 532
    },
    {
      "epoch": 0.2132,
      "grad_norm": 3.193403482437134,
      "learning_rate": 9.290666666666666e-07,
      "logits/chosen": -2.267568588256836,
      "logits/rejected": -2.1862120628356934,
      "logps/chosen": -128.17739868164062,
      "logps/rejected": -81.00589752197266,
      "loss": 0.0745,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1424763202667236,
      "rewards/margins": 2.5594544410705566,
      "rewards/rejected": -0.41697806119918823,
      "step": 533
    },
    {
      "epoch": 0.2136,
      "grad_norm": 5.751621723175049,
      "learning_rate": 9.289333333333333e-07,
      "logits/chosen": -2.1338367462158203,
      "logits/rejected": -2.381269931793213,
      "logps/chosen": -181.854736328125,
      "logps/rejected": -129.5194854736328,
      "loss": 0.1244,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4010848999023438,
      "rewards/margins": 2.179605484008789,
      "rewards/rejected": -0.7785205841064453,
      "step": 534
    },
    {
      "epoch": 0.214,
      "grad_norm": 6.077519416809082,
      "learning_rate": 9.287999999999999e-07,
      "logits/chosen": -2.2039172649383545,
      "logits/rejected": -1.9957239627838135,
      "logps/chosen": -190.97586059570312,
      "logps/rejected": -114.42587280273438,
      "loss": 0.1535,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5787034034729004,
      "rewards/margins": 2.179396629333496,
      "rewards/rejected": -0.6006931066513062,
      "step": 535
    },
    {
      "epoch": 0.2144,
      "grad_norm": 14.790604591369629,
      "learning_rate": 9.286666666666666e-07,
      "logits/chosen": -2.2446517944335938,
      "logits/rejected": -2.4892234802246094,
      "logps/chosen": -165.88514709472656,
      "logps/rejected": -125.22573852539062,
      "loss": 0.3465,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3733131885528564,
      "rewards/margins": 1.7197871208190918,
      "rewards/rejected": -0.3464741110801697,
      "step": 536
    },
    {
      "epoch": 0.2148,
      "grad_norm": 5.488980770111084,
      "learning_rate": 9.285333333333333e-07,
      "logits/chosen": -2.212526798248291,
      "logits/rejected": -1.6551121473312378,
      "logps/chosen": -162.16534423828125,
      "logps/rejected": -133.26698303222656,
      "loss": 0.1314,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7671089172363281,
      "rewards/margins": 1.999193549156189,
      "rewards/rejected": -0.23208463191986084,
      "step": 537
    },
    {
      "epoch": 0.2152,
      "grad_norm": 3.652303695678711,
      "learning_rate": 9.284e-07,
      "logits/chosen": -2.2762832641601562,
      "logits/rejected": -2.5127334594726562,
      "logps/chosen": -190.56881713867188,
      "logps/rejected": -106.97624206542969,
      "loss": 0.084,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4333107471466064,
      "rewards/margins": 2.4367167949676514,
      "rewards/rejected": -1.0034061670303345,
      "step": 538
    },
    {
      "epoch": 0.2156,
      "grad_norm": 7.612290859222412,
      "learning_rate": 9.282666666666667e-07,
      "logits/chosen": -2.1288957595825195,
      "logits/rejected": -1.8794869184494019,
      "logps/chosen": -139.8837890625,
      "logps/rejected": -82.68946838378906,
      "loss": 0.1517,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6946022510528564,
      "rewards/margins": 1.8822021484375,
      "rewards/rejected": -0.18759994208812714,
      "step": 539
    },
    {
      "epoch": 0.216,
      "grad_norm": 6.8561787605285645,
      "learning_rate": 9.281333333333334e-07,
      "logits/chosen": -2.022470712661743,
      "logits/rejected": -2.4979071617126465,
      "logps/chosen": -167.8480224609375,
      "logps/rejected": -108.19313049316406,
      "loss": 0.1161,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9723526239395142,
      "rewards/margins": 2.094348430633545,
      "rewards/rejected": -0.1219959408044815,
      "step": 540
    },
    {
      "epoch": 0.2164,
      "grad_norm": 5.6509480476379395,
      "learning_rate": 9.28e-07,
      "logits/chosen": -2.2327651977539062,
      "logits/rejected": -2.1090238094329834,
      "logps/chosen": -145.49172973632812,
      "logps/rejected": -107.03411865234375,
      "loss": 0.1092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.40617835521698,
      "rewards/margins": 2.3346738815307617,
      "rewards/rejected": -0.928495466709137,
      "step": 541
    },
    {
      "epoch": 0.2168,
      "grad_norm": 5.225980281829834,
      "learning_rate": 9.278666666666665e-07,
      "logits/chosen": -1.9520273208618164,
      "logits/rejected": -1.9309102296829224,
      "logps/chosen": -118.64085388183594,
      "logps/rejected": -96.96512603759766,
      "loss": 0.1519,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7083179950714111,
      "rewards/margins": 1.9277527332305908,
      "rewards/rejected": -0.2194347381591797,
      "step": 542
    },
    {
      "epoch": 0.2172,
      "grad_norm": 5.784890651702881,
      "learning_rate": 9.277333333333332e-07,
      "logits/chosen": -1.6409220695495605,
      "logits/rejected": -2.227893829345703,
      "logps/chosen": -85.7620620727539,
      "logps/rejected": -99.86888122558594,
      "loss": 0.1518,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.693817138671875,
      "rewards/margins": 1.8092701435089111,
      "rewards/rejected": -0.11545296758413315,
      "step": 543
    },
    {
      "epoch": 0.2176,
      "grad_norm": 3.4736433029174805,
      "learning_rate": 9.275999999999999e-07,
      "logits/chosen": -2.35071063041687,
      "logits/rejected": -2.086319923400879,
      "logps/chosen": -167.17947387695312,
      "logps/rejected": -88.9920883178711,
      "loss": 0.0839,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.873517632484436,
      "rewards/margins": 2.4435176849365234,
      "rewards/rejected": -0.5700000524520874,
      "step": 544
    },
    {
      "epoch": 0.218,
      "grad_norm": 9.985095977783203,
      "learning_rate": 9.274666666666666e-07,
      "logits/chosen": -2.4703733921051025,
      "logits/rejected": -2.706338882446289,
      "logps/chosen": -170.5040740966797,
      "logps/rejected": -123.49715423583984,
      "loss": 0.1689,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7115601301193237,
      "rewards/margins": 1.9648830890655518,
      "rewards/rejected": -0.2533229887485504,
      "step": 545
    },
    {
      "epoch": 0.2184,
      "grad_norm": 6.831315040588379,
      "learning_rate": 9.273333333333333e-07,
      "logits/chosen": -2.012416362762451,
      "logits/rejected": -1.9262511730194092,
      "logps/chosen": -125.55955505371094,
      "logps/rejected": -117.21409606933594,
      "loss": 0.1415,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.922071933746338,
      "rewards/margins": 2.5539231300354004,
      "rewards/rejected": -0.6318511962890625,
      "step": 546
    },
    {
      "epoch": 0.2188,
      "grad_norm": 6.472436904907227,
      "learning_rate": 9.272e-07,
      "logits/chosen": -2.5583999156951904,
      "logits/rejected": -2.545283794403076,
      "logps/chosen": -161.5812225341797,
      "logps/rejected": -203.7899169921875,
      "loss": 0.1523,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.970386028289795,
      "rewards/margins": 2.1239612102508545,
      "rewards/rejected": -0.153575137257576,
      "step": 547
    },
    {
      "epoch": 0.2192,
      "grad_norm": 9.201415061950684,
      "learning_rate": 9.270666666666667e-07,
      "logits/chosen": -1.8144350051879883,
      "logits/rejected": -2.3927693367004395,
      "logps/chosen": -97.26458740234375,
      "logps/rejected": -112.35279846191406,
      "loss": 0.2245,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9553241729736328,
      "rewards/margins": 1.384965419769287,
      "rewards/rejected": -0.42964133620262146,
      "step": 548
    },
    {
      "epoch": 0.2196,
      "grad_norm": 6.676873207092285,
      "learning_rate": 9.269333333333334e-07,
      "logits/chosen": -2.3260927200317383,
      "logits/rejected": -2.691859722137451,
      "logps/chosen": -191.578857421875,
      "logps/rejected": -195.8448944091797,
      "loss": 0.0779,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3778939247131348,
      "rewards/margins": 2.868323564529419,
      "rewards/rejected": -0.49042969942092896,
      "step": 549
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.6931257247924805,
      "learning_rate": 9.268e-07,
      "logits/chosen": -2.247598886489868,
      "logits/rejected": -2.8830230236053467,
      "logps/chosen": -122.86264038085938,
      "logps/rejected": -117.52342224121094,
      "loss": 0.036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.577867269515991,
      "rewards/margins": 3.3304548263549805,
      "rewards/rejected": -0.7525874972343445,
      "step": 550
    },
    {
      "epoch": 0.2204,
      "grad_norm": 3.9729151725769043,
      "learning_rate": 9.266666666666665e-07,
      "logits/chosen": -2.2526190280914307,
      "logits/rejected": -1.09675133228302,
      "logps/chosen": -149.23028564453125,
      "logps/rejected": -89.18367004394531,
      "loss": 0.0856,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2528395652770996,
      "rewards/margins": 2.458261489868164,
      "rewards/rejected": -0.20542185008525848,
      "step": 551
    },
    {
      "epoch": 0.2208,
      "grad_norm": 7.275918483734131,
      "learning_rate": 9.265333333333332e-07,
      "logits/chosen": -1.6633868217468262,
      "logits/rejected": -2.2727580070495605,
      "logps/chosen": -78.98997497558594,
      "logps/rejected": -80.80867004394531,
      "loss": 0.1565,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8979556560516357,
      "rewards/margins": 2.1236889362335205,
      "rewards/rejected": -0.2257331907749176,
      "step": 552
    },
    {
      "epoch": 0.2212,
      "grad_norm": 8.737053871154785,
      "learning_rate": 9.263999999999999e-07,
      "logits/chosen": -1.9771852493286133,
      "logits/rejected": -1.7337861061096191,
      "logps/chosen": -141.6680908203125,
      "logps/rejected": -99.94248962402344,
      "loss": 0.2613,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4028122425079346,
      "rewards/margins": 1.3290514945983887,
      "rewards/rejected": 0.07376060634851456,
      "step": 553
    },
    {
      "epoch": 0.2216,
      "grad_norm": 12.1159029006958,
      "learning_rate": 9.262666666666666e-07,
      "logits/chosen": -1.3889268636703491,
      "logits/rejected": -2.3517754077911377,
      "logps/chosen": -72.01126098632812,
      "logps/rejected": -93.17059326171875,
      "loss": 0.3245,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0118225812911987,
      "rewards/margins": 1.1696629524230957,
      "rewards/rejected": -0.15784034132957458,
      "step": 554
    },
    {
      "epoch": 0.222,
      "grad_norm": 7.2783894538879395,
      "learning_rate": 9.261333333333333e-07,
      "logits/chosen": -1.8668746948242188,
      "logits/rejected": -2.288020610809326,
      "logps/chosen": -131.17205810546875,
      "logps/rejected": -87.94537353515625,
      "loss": 0.1431,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6719074249267578,
      "rewards/margins": 1.9134891033172607,
      "rewards/rejected": -0.2415817230939865,
      "step": 555
    },
    {
      "epoch": 0.2224,
      "grad_norm": 2.911193609237671,
      "learning_rate": 9.26e-07,
      "logits/chosen": -2.615859031677246,
      "logits/rejected": -2.7870874404907227,
      "logps/chosen": -203.58816528320312,
      "logps/rejected": -112.55313110351562,
      "loss": 0.0461,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4382071495056152,
      "rewards/margins": 3.062826633453369,
      "rewards/rejected": -0.6246193051338196,
      "step": 556
    },
    {
      "epoch": 0.2228,
      "grad_norm": 2.84824538230896,
      "learning_rate": 9.258666666666666e-07,
      "logits/chosen": -2.7778053283691406,
      "logits/rejected": -2.7426300048828125,
      "logps/chosen": -172.4766845703125,
      "logps/rejected": -110.80818939208984,
      "loss": 0.0604,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4453606605529785,
      "rewards/margins": 2.894925355911255,
      "rewards/rejected": -0.44956475496292114,
      "step": 557
    },
    {
      "epoch": 0.2232,
      "grad_norm": 4.1483001708984375,
      "learning_rate": 9.257333333333333e-07,
      "logits/chosen": -1.877084732055664,
      "logits/rejected": -2.7329397201538086,
      "logps/chosen": -76.476318359375,
      "logps/rejected": -113.31039428710938,
      "loss": 0.1037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8400115966796875,
      "rewards/margins": 2.223817825317383,
      "rewards/rejected": -0.3838062286376953,
      "step": 558
    },
    {
      "epoch": 0.2236,
      "grad_norm": 6.721107482910156,
      "learning_rate": 9.256e-07,
      "logits/chosen": -1.8684786558151245,
      "logits/rejected": -1.3766605854034424,
      "logps/chosen": -119.37174987792969,
      "logps/rejected": -84.96134948730469,
      "loss": 0.1347,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3858890533447266,
      "rewards/margins": 2.0157620906829834,
      "rewards/rejected": -0.6298729181289673,
      "step": 559
    },
    {
      "epoch": 0.224,
      "grad_norm": 14.068025588989258,
      "learning_rate": 9.254666666666667e-07,
      "logits/chosen": -1.8085551261901855,
      "logits/rejected": -2.581085205078125,
      "logps/chosen": -138.67770385742188,
      "logps/rejected": -75.34889221191406,
      "loss": 0.3266,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1929975748062134,
      "rewards/margins": 1.1489458084106445,
      "rewards/rejected": 0.04405173659324646,
      "step": 560
    },
    {
      "epoch": 0.2244,
      "grad_norm": 5.707910060882568,
      "learning_rate": 9.253333333333333e-07,
      "logits/chosen": -2.06376051902771,
      "logits/rejected": -2.452502727508545,
      "logps/chosen": -106.71575927734375,
      "logps/rejected": -110.91313934326172,
      "loss": 0.1515,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9648075103759766,
      "rewards/margins": 2.504641532897949,
      "rewards/rejected": -0.5398338437080383,
      "step": 561
    },
    {
      "epoch": 0.2248,
      "grad_norm": 2.6644763946533203,
      "learning_rate": 9.251999999999999e-07,
      "logits/chosen": -2.313443899154663,
      "logits/rejected": -2.06732177734375,
      "logps/chosen": -126.06765747070312,
      "logps/rejected": -116.53884887695312,
      "loss": 0.0601,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4872121810913086,
      "rewards/margins": 3.223539113998413,
      "rewards/rejected": -0.7363271713256836,
      "step": 562
    },
    {
      "epoch": 0.2252,
      "grad_norm": 3.793586254119873,
      "learning_rate": 9.250666666666666e-07,
      "logits/chosen": -1.9201891422271729,
      "logits/rejected": -1.975314736366272,
      "logps/chosen": -129.16915893554688,
      "logps/rejected": -163.87814331054688,
      "loss": 0.0589,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4163055419921875,
      "rewards/margins": 2.8054356575012207,
      "rewards/rejected": -0.38913002610206604,
      "step": 563
    },
    {
      "epoch": 0.2256,
      "grad_norm": 9.26096248626709,
      "learning_rate": 9.249333333333333e-07,
      "logits/chosen": -2.008767604827881,
      "logits/rejected": -1.9087507724761963,
      "logps/chosen": -88.34838104248047,
      "logps/rejected": -92.07745361328125,
      "loss": 0.2742,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1747231483459473,
      "rewards/margins": 1.2010676860809326,
      "rewards/rejected": -0.026344671845436096,
      "step": 564
    },
    {
      "epoch": 0.226,
      "grad_norm": 2.3584682941436768,
      "learning_rate": 9.247999999999999e-07,
      "logits/chosen": -2.4677979946136475,
      "logits/rejected": -2.0262768268585205,
      "logps/chosen": -230.76785278320312,
      "logps/rejected": -106.66011047363281,
      "loss": 0.0337,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.905118465423584,
      "rewards/margins": 3.504652976989746,
      "rewards/rejected": -0.599534273147583,
      "step": 565
    },
    {
      "epoch": 0.2264,
      "grad_norm": 3.5413615703582764,
      "learning_rate": 9.246666666666666e-07,
      "logits/chosen": -1.4039177894592285,
      "logits/rejected": -1.7595361471176147,
      "logps/chosen": -72.85565185546875,
      "logps/rejected": -99.61497497558594,
      "loss": 0.083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9809813499450684,
      "rewards/margins": 2.507230043411255,
      "rewards/rejected": -0.526248574256897,
      "step": 566
    },
    {
      "epoch": 0.2268,
      "grad_norm": 5.150127410888672,
      "learning_rate": 9.245333333333333e-07,
      "logits/chosen": -2.2812533378601074,
      "logits/rejected": -1.720871925354004,
      "logps/chosen": -115.15081787109375,
      "logps/rejected": -86.54025268554688,
      "loss": 0.1476,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5362969636917114,
      "rewards/margins": 1.8803516626358032,
      "rewards/rejected": -0.34405481815338135,
      "step": 567
    },
    {
      "epoch": 0.2272,
      "grad_norm": 11.58620834350586,
      "learning_rate": 9.244e-07,
      "logits/chosen": -1.947754144668579,
      "logits/rejected": -2.1800503730773926,
      "logps/chosen": -96.94453430175781,
      "logps/rejected": -114.76966857910156,
      "loss": 0.2551,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8202621936798096,
      "rewards/margins": 1.4956014156341553,
      "rewards/rejected": -0.6753391027450562,
      "step": 568
    },
    {
      "epoch": 0.2276,
      "grad_norm": 8.476699829101562,
      "learning_rate": 9.242666666666667e-07,
      "logits/chosen": -2.445157527923584,
      "logits/rejected": -3.088357925415039,
      "logps/chosen": -137.68206787109375,
      "logps/rejected": -147.3998260498047,
      "loss": 0.1689,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8436832427978516,
      "rewards/margins": 1.6967731714248657,
      "rewards/rejected": -0.8530899286270142,
      "step": 569
    },
    {
      "epoch": 0.228,
      "grad_norm": 3.1538174152374268,
      "learning_rate": 9.241333333333333e-07,
      "logits/chosen": -1.9219484329223633,
      "logits/rejected": -2.291541337966919,
      "logps/chosen": -152.57351684570312,
      "logps/rejected": -104.71359252929688,
      "loss": 0.0577,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1773910522460938,
      "rewards/margins": 2.8646116256713867,
      "rewards/rejected": -0.6872207522392273,
      "step": 570
    },
    {
      "epoch": 0.2284,
      "grad_norm": 4.460324287414551,
      "learning_rate": 9.24e-07,
      "logits/chosen": -2.426373243331909,
      "logits/rejected": -2.2482120990753174,
      "logps/chosen": -122.36277770996094,
      "logps/rejected": -119.12437438964844,
      "loss": 0.0863,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.170900344848633,
      "rewards/margins": 2.4059133529663086,
      "rewards/rejected": -0.23501282930374146,
      "step": 571
    },
    {
      "epoch": 0.2288,
      "grad_norm": 16.09914207458496,
      "learning_rate": 9.238666666666665e-07,
      "logits/chosen": -1.9340250492095947,
      "logits/rejected": -1.9430322647094727,
      "logps/chosen": -85.14479064941406,
      "logps/rejected": -94.7332992553711,
      "loss": 0.4243,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1484276056289673,
      "rewards/margins": 0.6850197315216064,
      "rewards/rejected": 0.4634079039096832,
      "step": 572
    },
    {
      "epoch": 0.2292,
      "grad_norm": 6.198967456817627,
      "learning_rate": 9.237333333333332e-07,
      "logits/chosen": -1.8831725120544434,
      "logits/rejected": -2.4512951374053955,
      "logps/chosen": -126.92953491210938,
      "logps/rejected": -91.201171875,
      "loss": 0.1249,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.104355812072754,
      "rewards/margins": 2.177952527999878,
      "rewards/rejected": -0.07359695434570312,
      "step": 573
    },
    {
      "epoch": 0.2296,
      "grad_norm": 8.941195487976074,
      "learning_rate": 9.235999999999999e-07,
      "logits/chosen": -2.057032585144043,
      "logits/rejected": -1.5232040882110596,
      "logps/chosen": -147.32150268554688,
      "logps/rejected": -83.08203887939453,
      "loss": 0.1764,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2663238048553467,
      "rewards/margins": 1.7332710027694702,
      "rewards/rejected": -0.46694719791412354,
      "step": 574
    },
    {
      "epoch": 0.23,
      "grad_norm": 11.443182945251465,
      "learning_rate": 9.234666666666666e-07,
      "logits/chosen": -2.175344944000244,
      "logits/rejected": -1.6657061576843262,
      "logps/chosen": -183.8204345703125,
      "logps/rejected": -103.93013763427734,
      "loss": 0.2174,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6701736450195312,
      "rewards/margins": 1.7148667573928833,
      "rewards/rejected": -0.0446930006146431,
      "step": 575
    },
    {
      "epoch": 0.2304,
      "grad_norm": 3.4408156871795654,
      "learning_rate": 9.233333333333333e-07,
      "logits/chosen": -2.0061593055725098,
      "logits/rejected": -2.1777520179748535,
      "logps/chosen": -94.15010070800781,
      "logps/rejected": -96.13677978515625,
      "loss": 0.0752,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2707786560058594,
      "rewards/margins": 2.6477060317993164,
      "rewards/rejected": -0.3769271969795227,
      "step": 576
    },
    {
      "epoch": 0.2308,
      "grad_norm": 5.864231109619141,
      "learning_rate": 9.232e-07,
      "logits/chosen": -2.5547213554382324,
      "logits/rejected": -2.394847869873047,
      "logps/chosen": -140.03366088867188,
      "logps/rejected": -112.99923706054688,
      "loss": 0.0998,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.636209487915039,
      "rewards/margins": 2.2655396461486816,
      "rewards/rejected": -0.629330039024353,
      "step": 577
    },
    {
      "epoch": 0.2312,
      "grad_norm": 2.269970417022705,
      "learning_rate": 9.230666666666667e-07,
      "logits/chosen": -2.07314133644104,
      "logits/rejected": -2.1813621520996094,
      "logps/chosen": -83.76766967773438,
      "logps/rejected": -79.97016906738281,
      "loss": 0.0533,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1296730041503906,
      "rewards/margins": 2.911652088165283,
      "rewards/rejected": -0.7819790244102478,
      "step": 578
    },
    {
      "epoch": 0.2316,
      "grad_norm": 2.2934765815734863,
      "learning_rate": 9.229333333333334e-07,
      "logits/chosen": -1.9840595722198486,
      "logits/rejected": -2.0849814414978027,
      "logps/chosen": -137.22811889648438,
      "logps/rejected": -107.272705078125,
      "loss": 0.0392,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.621138572692871,
      "rewards/margins": 3.2257251739501953,
      "rewards/rejected": -0.6045867800712585,
      "step": 579
    },
    {
      "epoch": 0.232,
      "grad_norm": 3.560678482055664,
      "learning_rate": 9.227999999999999e-07,
      "logits/chosen": -2.607558250427246,
      "logits/rejected": -2.966257095336914,
      "logps/chosen": -146.4925994873047,
      "logps/rejected": -185.451904296875,
      "loss": 0.0546,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9671261310577393,
      "rewards/margins": 3.057671070098877,
      "rewards/rejected": -1.0905449390411377,
      "step": 580
    },
    {
      "epoch": 0.2324,
      "grad_norm": 13.073211669921875,
      "learning_rate": 9.226666666666666e-07,
      "logits/chosen": -2.135881185531616,
      "logits/rejected": -2.117236614227295,
      "logps/chosen": -93.72666931152344,
      "logps/rejected": -76.86854553222656,
      "loss": 0.2803,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.59397554397583,
      "rewards/margins": 1.5513912439346313,
      "rewards/rejected": 0.04258422553539276,
      "step": 581
    },
    {
      "epoch": 0.2328,
      "grad_norm": 12.24453067779541,
      "learning_rate": 9.225333333333333e-07,
      "logits/chosen": -1.6558988094329834,
      "logits/rejected": -2.116823673248291,
      "logps/chosen": -83.32247161865234,
      "logps/rejected": -111.07148742675781,
      "loss": 0.3043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1430546045303345,
      "rewards/margins": 1.118778944015503,
      "rewards/rejected": 0.024275589734315872,
      "step": 582
    },
    {
      "epoch": 0.2332,
      "grad_norm": 1.9165395498275757,
      "learning_rate": 9.224e-07,
      "logits/chosen": -2.288022756576538,
      "logits/rejected": -2.2787857055664062,
      "logps/chosen": -109.76866149902344,
      "logps/rejected": -111.55516815185547,
      "loss": 0.0483,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.45866060256958,
      "rewards/margins": 3.0070643424987793,
      "rewards/rejected": -0.5484035611152649,
      "step": 583
    },
    {
      "epoch": 0.2336,
      "grad_norm": 4.992643356323242,
      "learning_rate": 9.222666666666666e-07,
      "logits/chosen": -2.35801100730896,
      "logits/rejected": -2.312654972076416,
      "logps/chosen": -135.92361450195312,
      "logps/rejected": -127.72065734863281,
      "loss": 0.0798,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.137688636779785,
      "rewards/margins": 2.847416877746582,
      "rewards/rejected": -0.7097282409667969,
      "step": 584
    },
    {
      "epoch": 0.234,
      "grad_norm": 2.4812498092651367,
      "learning_rate": 9.221333333333333e-07,
      "logits/chosen": -2.1561849117279053,
      "logits/rejected": -2.6343307495117188,
      "logps/chosen": -126.67349243164062,
      "logps/rejected": -95.99671936035156,
      "loss": 0.0555,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7158427238464355,
      "rewards/margins": 2.9985780715942383,
      "rewards/rejected": -0.2827354371547699,
      "step": 585
    },
    {
      "epoch": 0.2344,
      "grad_norm": 7.52426290512085,
      "learning_rate": 9.22e-07,
      "logits/chosen": -2.371603012084961,
      "logits/rejected": -1.8571598529815674,
      "logps/chosen": -204.82809448242188,
      "logps/rejected": -102.08214569091797,
      "loss": 0.1091,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0733611583709717,
      "rewards/margins": 2.4365429878234863,
      "rewards/rejected": -0.3631816804409027,
      "step": 586
    },
    {
      "epoch": 0.2348,
      "grad_norm": 8.2027006149292,
      "learning_rate": 9.218666666666666e-07,
      "logits/chosen": -2.355703353881836,
      "logits/rejected": -2.598933696746826,
      "logps/chosen": -159.668212890625,
      "logps/rejected": -108.14897155761719,
      "loss": 0.1462,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.373582363128662,
      "rewards/margins": 2.1779251098632812,
      "rewards/rejected": 0.19565734267234802,
      "step": 587
    },
    {
      "epoch": 0.2352,
      "grad_norm": 2.270596981048584,
      "learning_rate": 9.217333333333333e-07,
      "logits/chosen": -2.079501152038574,
      "logits/rejected": -2.669987440109253,
      "logps/chosen": -123.7654037475586,
      "logps/rejected": -108.2442626953125,
      "loss": 0.0439,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.817138671875,
      "rewards/margins": 3.304234504699707,
      "rewards/rejected": -0.4870956838130951,
      "step": 588
    },
    {
      "epoch": 0.2356,
      "grad_norm": 1.822716474533081,
      "learning_rate": 9.215999999999999e-07,
      "logits/chosen": -2.431321620941162,
      "logits/rejected": -3.006063222885132,
      "logps/chosen": -181.23281860351562,
      "logps/rejected": -108.57621765136719,
      "loss": 0.0292,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5486671924591064,
      "rewards/margins": 3.521383285522461,
      "rewards/rejected": -0.9727161526679993,
      "step": 589
    },
    {
      "epoch": 0.236,
      "grad_norm": 3.6992082595825195,
      "learning_rate": 9.214666666666666e-07,
      "logits/chosen": -2.0377626419067383,
      "logits/rejected": -1.9542253017425537,
      "logps/chosen": -92.93869018554688,
      "logps/rejected": -80.43787384033203,
      "loss": 0.1011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6279139518737793,
      "rewards/margins": 2.240509033203125,
      "rewards/rejected": -0.6125950217247009,
      "step": 590
    },
    {
      "epoch": 0.2364,
      "grad_norm": 3.731442451477051,
      "learning_rate": 9.213333333333333e-07,
      "logits/chosen": -2.091855525970459,
      "logits/rejected": -2.18501353263855,
      "logps/chosen": -123.89698791503906,
      "logps/rejected": -104.71955871582031,
      "loss": 0.0699,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2076733112335205,
      "rewards/margins": 3.1222352981567383,
      "rewards/rejected": -0.9145618677139282,
      "step": 591
    },
    {
      "epoch": 0.2368,
      "grad_norm": 6.133926868438721,
      "learning_rate": 9.212e-07,
      "logits/chosen": -2.525125503540039,
      "logits/rejected": -2.6639397144317627,
      "logps/chosen": -122.28089904785156,
      "logps/rejected": -91.8167724609375,
      "loss": 0.147,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.788764238357544,
      "rewards/margins": 1.889958143234253,
      "rewards/rejected": -0.10119400918483734,
      "step": 592
    },
    {
      "epoch": 0.2372,
      "grad_norm": 1.2387627363204956,
      "learning_rate": 9.210666666666667e-07,
      "logits/chosen": -2.549286127090454,
      "logits/rejected": -2.660712718963623,
      "logps/chosen": -139.23745727539062,
      "logps/rejected": -127.6725845336914,
      "loss": 0.0236,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5606510639190674,
      "rewards/margins": 4.113010406494141,
      "rewards/rejected": -1.5523591041564941,
      "step": 593
    },
    {
      "epoch": 0.2376,
      "grad_norm": 4.921478748321533,
      "learning_rate": 9.209333333333333e-07,
      "logits/chosen": -2.533721446990967,
      "logits/rejected": -2.5240461826324463,
      "logps/chosen": -154.33767700195312,
      "logps/rejected": -147.677734375,
      "loss": 0.099,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.060211181640625,
      "rewards/margins": 2.3983986377716064,
      "rewards/rejected": -0.33818739652633667,
      "step": 594
    },
    {
      "epoch": 0.238,
      "grad_norm": 8.155335426330566,
      "learning_rate": 9.207999999999999e-07,
      "logits/chosen": -2.2015774250030518,
      "logits/rejected": -2.496580123901367,
      "logps/chosen": -86.99923706054688,
      "logps/rejected": -107.70211791992188,
      "loss": 0.2151,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5887291431427002,
      "rewards/margins": 1.954121470451355,
      "rewards/rejected": -0.3653923273086548,
      "step": 595
    },
    {
      "epoch": 0.2384,
      "grad_norm": 4.275660514831543,
      "learning_rate": 9.206666666666666e-07,
      "logits/chosen": -2.1645426750183105,
      "logits/rejected": -2.1494979858398438,
      "logps/chosen": -115.29388427734375,
      "logps/rejected": -97.72644805908203,
      "loss": 0.101,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9049309492111206,
      "rewards/margins": 2.2581734657287598,
      "rewards/rejected": -0.3532424867153168,
      "step": 596
    },
    {
      "epoch": 0.2388,
      "grad_norm": 2.9136528968811035,
      "learning_rate": 9.205333333333333e-07,
      "logits/chosen": -2.661978244781494,
      "logits/rejected": -3.2127506732940674,
      "logps/chosen": -167.0438232421875,
      "logps/rejected": -119.70510864257812,
      "loss": 0.0446,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.254100799560547,
      "rewards/margins": 3.209984540939331,
      "rewards/rejected": -0.955883800983429,
      "step": 597
    },
    {
      "epoch": 0.2392,
      "grad_norm": 7.498394966125488,
      "learning_rate": 9.203999999999999e-07,
      "logits/chosen": -2.0011396408081055,
      "logits/rejected": -2.2106826305389404,
      "logps/chosen": -94.99571228027344,
      "logps/rejected": -85.79864501953125,
      "loss": 0.181,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.00275456905365,
      "rewards/margins": 1.7371490001678467,
      "rewards/rejected": -0.7343944311141968,
      "step": 598
    },
    {
      "epoch": 0.2396,
      "grad_norm": 1.8346984386444092,
      "learning_rate": 9.202666666666666e-07,
      "logits/chosen": -2.3456835746765137,
      "logits/rejected": -2.4709577560424805,
      "logps/chosen": -123.18428039550781,
      "logps/rejected": -134.09866333007812,
      "loss": 0.0269,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5835509300231934,
      "rewards/margins": 3.60667085647583,
      "rewards/rejected": -1.0231198072433472,
      "step": 599
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.5443551540374756,
      "learning_rate": 9.201333333333333e-07,
      "logits/chosen": -2.646080493927002,
      "logits/rejected": -3.141538381576538,
      "logps/chosen": -222.87399291992188,
      "logps/rejected": -128.4886016845703,
      "loss": 0.0445,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.173970937728882,
      "rewards/margins": 3.419400691986084,
      "rewards/rejected": -1.2454299926757812,
      "step": 600
    },
    {
      "epoch": 0.2404,
      "grad_norm": 1.7674599885940552,
      "learning_rate": 9.2e-07,
      "logits/chosen": -2.0882856845855713,
      "logits/rejected": -2.8447682857513428,
      "logps/chosen": -115.40510559082031,
      "logps/rejected": -121.89952850341797,
      "loss": 0.0336,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7328076362609863,
      "rewards/margins": 3.4546332359313965,
      "rewards/rejected": -0.7218254208564758,
      "step": 601
    },
    {
      "epoch": 0.2408,
      "grad_norm": 2.687648296356201,
      "learning_rate": 9.198666666666667e-07,
      "logits/chosen": -2.1581485271453857,
      "logits/rejected": -2.4255685806274414,
      "logps/chosen": -190.29580688476562,
      "logps/rejected": -93.99517822265625,
      "loss": 0.0694,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5336410999298096,
      "rewards/margins": 2.953861713409424,
      "rewards/rejected": -0.4202207624912262,
      "step": 602
    },
    {
      "epoch": 0.2412,
      "grad_norm": 4.428715229034424,
      "learning_rate": 9.197333333333333e-07,
      "logits/chosen": -1.7661645412445068,
      "logits/rejected": -2.6880130767822266,
      "logps/chosen": -121.15853881835938,
      "logps/rejected": -137.2882080078125,
      "loss": 0.0804,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0260536670684814,
      "rewards/margins": 2.4805078506469727,
      "rewards/rejected": -0.45445406436920166,
      "step": 603
    },
    {
      "epoch": 0.2416,
      "grad_norm": 6.288358688354492,
      "learning_rate": 9.196e-07,
      "logits/chosen": -2.091054677963257,
      "logits/rejected": -2.391326904296875,
      "logps/chosen": -123.60911560058594,
      "logps/rejected": -123.90898132324219,
      "loss": 0.1282,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.678629755973816,
      "rewards/margins": 2.043154239654541,
      "rewards/rejected": -0.3645244538784027,
      "step": 604
    },
    {
      "epoch": 0.242,
      "grad_norm": 3.9890217781066895,
      "learning_rate": 9.194666666666666e-07,
      "logits/chosen": -2.2490429878234863,
      "logits/rejected": -3.1022450923919678,
      "logps/chosen": -130.23219299316406,
      "logps/rejected": -127.15831756591797,
      "loss": 0.0821,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.594042181968689,
      "rewards/margins": 2.4590492248535156,
      "rewards/rejected": -0.8650070428848267,
      "step": 605
    },
    {
      "epoch": 0.2424,
      "grad_norm": 4.15163516998291,
      "learning_rate": 9.193333333333333e-07,
      "logits/chosen": -1.9424594640731812,
      "logits/rejected": -2.5894763469696045,
      "logps/chosen": -107.03257751464844,
      "logps/rejected": -139.507080078125,
      "loss": 0.0769,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2107162475585938,
      "rewards/margins": 3.0438895225524902,
      "rewards/rejected": -0.833173394203186,
      "step": 606
    },
    {
      "epoch": 0.2428,
      "grad_norm": 6.592341899871826,
      "learning_rate": 9.192e-07,
      "logits/chosen": -2.288283348083496,
      "logits/rejected": -2.283653736114502,
      "logps/chosen": -91.71868133544922,
      "logps/rejected": -109.86637115478516,
      "loss": 0.1527,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0075607299804688,
      "rewards/margins": 2.0300490856170654,
      "rewards/rejected": -1.0224883556365967,
      "step": 607
    },
    {
      "epoch": 0.2432,
      "grad_norm": 1.3478922843933105,
      "learning_rate": 9.190666666666666e-07,
      "logits/chosen": -2.076326847076416,
      "logits/rejected": -2.2959961891174316,
      "logps/chosen": -100.6220703125,
      "logps/rejected": -105.02949523925781,
      "loss": 0.0336,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.356198310852051,
      "rewards/margins": 3.4033596515655518,
      "rewards/rejected": -1.0471614599227905,
      "step": 608
    },
    {
      "epoch": 0.2436,
      "grad_norm": 8.744962692260742,
      "learning_rate": 9.189333333333333e-07,
      "logits/chosen": -1.9705755710601807,
      "logits/rejected": -1.7805335521697998,
      "logps/chosen": -106.59883117675781,
      "logps/rejected": -98.12866973876953,
      "loss": 0.15,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8856182098388672,
      "rewards/margins": 2.2105236053466797,
      "rewards/rejected": -0.3249053955078125,
      "step": 609
    },
    {
      "epoch": 0.244,
      "grad_norm": 4.192782402038574,
      "learning_rate": 9.187999999999999e-07,
      "logits/chosen": -1.9193332195281982,
      "logits/rejected": -2.441084384918213,
      "logps/chosen": -118.85003662109375,
      "logps/rejected": -145.639404296875,
      "loss": 0.0512,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2334342002868652,
      "rewards/margins": 3.1838035583496094,
      "rewards/rejected": -0.9503692388534546,
      "step": 610
    },
    {
      "epoch": 0.2444,
      "grad_norm": 4.817984104156494,
      "learning_rate": 9.186666666666666e-07,
      "logits/chosen": -2.0918993949890137,
      "logits/rejected": -1.8604998588562012,
      "logps/chosen": -140.11582946777344,
      "logps/rejected": -89.33271789550781,
      "loss": 0.0829,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.728837490081787,
      "rewards/margins": 2.7159247398376465,
      "rewards/rejected": 0.012912750244140625,
      "step": 611
    },
    {
      "epoch": 0.2448,
      "grad_norm": 6.1236572265625,
      "learning_rate": 9.185333333333333e-07,
      "logits/chosen": -1.8853590488433838,
      "logits/rejected": -2.4752180576324463,
      "logps/chosen": -126.18761444091797,
      "logps/rejected": -105.61322021484375,
      "loss": 0.1017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4849371910095215,
      "rewards/margins": 2.7678403854370117,
      "rewards/rejected": -0.2829033136367798,
      "step": 612
    },
    {
      "epoch": 0.2452,
      "grad_norm": 4.791440486907959,
      "learning_rate": 9.184e-07,
      "logits/chosen": -2.093857526779175,
      "logits/rejected": -2.9014904499053955,
      "logps/chosen": -160.82887268066406,
      "logps/rejected": -127.09999084472656,
      "loss": 0.0772,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1247611045837402,
      "rewards/margins": 2.6821913719177246,
      "rewards/rejected": -0.5574302673339844,
      "step": 613
    },
    {
      "epoch": 0.2456,
      "grad_norm": 3.762228012084961,
      "learning_rate": 9.182666666666667e-07,
      "logits/chosen": -1.8682012557983398,
      "logits/rejected": -2.8035030364990234,
      "logps/chosen": -99.35635375976562,
      "logps/rejected": -113.27562713623047,
      "loss": 0.0863,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.843681812286377,
      "rewards/margins": 2.602992057800293,
      "rewards/rejected": -0.7593101263046265,
      "step": 614
    },
    {
      "epoch": 0.246,
      "grad_norm": 2.464498996734619,
      "learning_rate": 9.181333333333333e-07,
      "logits/chosen": -2.372800827026367,
      "logits/rejected": -2.2947182655334473,
      "logps/chosen": -126.82908630371094,
      "logps/rejected": -86.53638458251953,
      "loss": 0.0547,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3480963706970215,
      "rewards/margins": 2.882110118865967,
      "rewards/rejected": -0.5340137481689453,
      "step": 615
    },
    {
      "epoch": 0.2464,
      "grad_norm": 18.60863494873047,
      "learning_rate": 9.18e-07,
      "logits/chosen": -1.9920580387115479,
      "logits/rejected": -3.5917739868164062,
      "logps/chosen": -107.25332641601562,
      "logps/rejected": -139.3303680419922,
      "loss": 0.2926,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1247131824493408,
      "rewards/margins": 1.6774479150772095,
      "rewards/rejected": -0.5527347922325134,
      "step": 616
    },
    {
      "epoch": 0.2468,
      "grad_norm": 5.975152492523193,
      "learning_rate": 9.178666666666666e-07,
      "logits/chosen": -2.137723445892334,
      "logits/rejected": -3.0126357078552246,
      "logps/chosen": -147.91952514648438,
      "logps/rejected": -123.01336669921875,
      "loss": 0.116,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2880730628967285,
      "rewards/margins": 2.100728988647461,
      "rewards/rejected": -0.812656044960022,
      "step": 617
    },
    {
      "epoch": 0.2472,
      "grad_norm": 4.805010795593262,
      "learning_rate": 9.177333333333332e-07,
      "logits/chosen": -1.5574352741241455,
      "logits/rejected": -2.4105944633483887,
      "logps/chosen": -96.75300598144531,
      "logps/rejected": -97.66769409179688,
      "loss": 0.0906,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8259937763214111,
      "rewards/margins": 2.554739475250244,
      "rewards/rejected": -0.728745698928833,
      "step": 618
    },
    {
      "epoch": 0.2476,
      "grad_norm": 2.5749592781066895,
      "learning_rate": 9.175999999999999e-07,
      "logits/chosen": -2.3138394355773926,
      "logits/rejected": -1.9986528158187866,
      "logps/chosen": -159.53414916992188,
      "logps/rejected": -111.28475952148438,
      "loss": 0.0469,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.604696750640869,
      "rewards/margins": 3.2527005672454834,
      "rewards/rejected": -0.6480037569999695,
      "step": 619
    },
    {
      "epoch": 0.248,
      "grad_norm": 1.4511947631835938,
      "learning_rate": 9.174666666666666e-07,
      "logits/chosen": -2.2789502143859863,
      "logits/rejected": -2.358292579650879,
      "logps/chosen": -114.35531616210938,
      "logps/rejected": -110.7822036743164,
      "loss": 0.0262,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.997640609741211,
      "rewards/margins": 3.634840488433838,
      "rewards/rejected": -0.6371997594833374,
      "step": 620
    },
    {
      "epoch": 0.2484,
      "grad_norm": 6.095137596130371,
      "learning_rate": 9.173333333333333e-07,
      "logits/chosen": -1.8216123580932617,
      "logits/rejected": -2.70164155960083,
      "logps/chosen": -82.97135925292969,
      "logps/rejected": -121.21495056152344,
      "loss": 0.0983,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.420744776725769,
      "rewards/margins": 2.2869629859924316,
      "rewards/rejected": -0.8662182092666626,
      "step": 621
    },
    {
      "epoch": 0.2488,
      "grad_norm": 5.185318946838379,
      "learning_rate": 9.172e-07,
      "logits/chosen": -2.307450771331787,
      "logits/rejected": -2.9182114601135254,
      "logps/chosen": -92.93429565429688,
      "logps/rejected": -120.03754425048828,
      "loss": 0.1043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.346314549446106,
      "rewards/margins": 2.230534076690674,
      "rewards/rejected": -0.884219765663147,
      "step": 622
    },
    {
      "epoch": 0.2492,
      "grad_norm": 14.825998306274414,
      "learning_rate": 9.170666666666667e-07,
      "logits/chosen": -2.3967771530151367,
      "logits/rejected": -2.0506834983825684,
      "logps/chosen": -139.56143188476562,
      "logps/rejected": -85.3072280883789,
      "loss": 0.2916,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.541904091835022,
      "rewards/margins": 1.7504818439483643,
      "rewards/rejected": -0.2085777223110199,
      "step": 623
    },
    {
      "epoch": 0.2496,
      "grad_norm": 10.156535148620605,
      "learning_rate": 9.169333333333334e-07,
      "logits/chosen": -2.3175601959228516,
      "logits/rejected": -2.496799945831299,
      "logps/chosen": -100.32350158691406,
      "logps/rejected": -86.17234802246094,
      "loss": 0.2602,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5848820209503174,
      "rewards/margins": 1.215055227279663,
      "rewards/rejected": 0.36982688307762146,
      "step": 624
    },
    {
      "epoch": 0.25,
      "grad_norm": 13.01721477508545,
      "learning_rate": 9.168e-07,
      "logits/chosen": -2.130720615386963,
      "logits/rejected": -2.0666606426239014,
      "logps/chosen": -146.96890258789062,
      "logps/rejected": -90.62645721435547,
      "loss": 0.2617,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7306369543075562,
      "rewards/margins": 2.1104159355163574,
      "rewards/rejected": -0.37977904081344604,
      "step": 625
    },
    {
      "epoch": 0.2504,
      "grad_norm": 1.4628798961639404,
      "learning_rate": 9.166666666666665e-07,
      "logits/chosen": -2.2636475563049316,
      "logits/rejected": -2.4741523265838623,
      "logps/chosen": -134.47119140625,
      "logps/rejected": -113.16146850585938,
      "loss": 0.0321,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.416177272796631,
      "rewards/margins": 3.481356620788574,
      "rewards/rejected": -1.0651791095733643,
      "step": 626
    },
    {
      "epoch": 0.2508,
      "grad_norm": 2.687530040740967,
      "learning_rate": 9.165333333333332e-07,
      "logits/chosen": -2.5677576065063477,
      "logits/rejected": -2.62863826751709,
      "logps/chosen": -208.03515625,
      "logps/rejected": -103.0213851928711,
      "loss": 0.0422,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.368025302886963,
      "rewards/margins": 3.166776180267334,
      "rewards/rejected": -0.7987511157989502,
      "step": 627
    },
    {
      "epoch": 0.2512,
      "grad_norm": 9.929285049438477,
      "learning_rate": 9.163999999999999e-07,
      "logits/chosen": -1.9500765800476074,
      "logits/rejected": -2.1025426387786865,
      "logps/chosen": -100.94731140136719,
      "logps/rejected": -84.50849914550781,
      "loss": 0.2194,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5922088623046875,
      "rewards/margins": 1.4358493089675903,
      "rewards/rejected": 0.1563594788312912,
      "step": 628
    },
    {
      "epoch": 0.2516,
      "grad_norm": 3.9538214206695557,
      "learning_rate": 9.162666666666666e-07,
      "logits/chosen": -1.892045259475708,
      "logits/rejected": -3.1342644691467285,
      "logps/chosen": -221.69845581054688,
      "logps/rejected": -137.94296264648438,
      "loss": 0.0689,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8828376531600952,
      "rewards/margins": 2.996607780456543,
      "rewards/rejected": -1.1137700080871582,
      "step": 629
    },
    {
      "epoch": 0.252,
      "grad_norm": 5.027427673339844,
      "learning_rate": 9.161333333333333e-07,
      "logits/chosen": -1.8619444370269775,
      "logits/rejected": -2.4819986820220947,
      "logps/chosen": -98.96493530273438,
      "logps/rejected": -100.77584838867188,
      "loss": 0.1243,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9430019855499268,
      "rewards/margins": 2.2630958557128906,
      "rewards/rejected": -0.32009392976760864,
      "step": 630
    },
    {
      "epoch": 0.2524,
      "grad_norm": 6.846052169799805,
      "learning_rate": 9.16e-07,
      "logits/chosen": -1.9328484535217285,
      "logits/rejected": -2.109179973602295,
      "logps/chosen": -92.80586242675781,
      "logps/rejected": -84.44673919677734,
      "loss": 0.24,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3498684167861938,
      "rewards/margins": 1.6951401233673096,
      "rewards/rejected": -0.3452717065811157,
      "step": 631
    },
    {
      "epoch": 0.2528,
      "grad_norm": 3.758017063140869,
      "learning_rate": 9.158666666666667e-07,
      "logits/chosen": -1.9829437732696533,
      "logits/rejected": -1.8337843418121338,
      "logps/chosen": -103.67214965820312,
      "logps/rejected": -96.71917724609375,
      "loss": 0.0816,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.842125415802002,
      "rewards/margins": 2.4820141792297363,
      "rewards/rejected": -0.6398887634277344,
      "step": 632
    },
    {
      "epoch": 0.2532,
      "grad_norm": 2.618180274963379,
      "learning_rate": 9.157333333333333e-07,
      "logits/chosen": -2.147724151611328,
      "logits/rejected": -2.5247979164123535,
      "logps/chosen": -98.50144958496094,
      "logps/rejected": -116.24337768554688,
      "loss": 0.0529,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.432115077972412,
      "rewards/margins": 3.1032509803771973,
      "rewards/rejected": -0.6711357235908508,
      "step": 633
    },
    {
      "epoch": 0.2536,
      "grad_norm": 9.856761932373047,
      "learning_rate": 9.156e-07,
      "logits/chosen": -1.7190887928009033,
      "logits/rejected": -2.466355800628662,
      "logps/chosen": -83.59065246582031,
      "logps/rejected": -126.86363220214844,
      "loss": 0.2244,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0320518016815186,
      "rewards/margins": 1.7948377132415771,
      "rewards/rejected": -0.7627857327461243,
      "step": 634
    },
    {
      "epoch": 0.254,
      "grad_norm": 3.278820753097534,
      "learning_rate": 9.154666666666667e-07,
      "logits/chosen": -1.9428156614303589,
      "logits/rejected": -2.3831334114074707,
      "logps/chosen": -85.6966552734375,
      "logps/rejected": -91.93339538574219,
      "loss": 0.0562,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1490349769592285,
      "rewards/margins": 3.0333542823791504,
      "rewards/rejected": -0.8843193054199219,
      "step": 635
    },
    {
      "epoch": 0.2544,
      "grad_norm": 4.9757819175720215,
      "learning_rate": 9.153333333333332e-07,
      "logits/chosen": -2.593398332595825,
      "logits/rejected": -2.4093992710113525,
      "logps/chosen": -182.8833770751953,
      "logps/rejected": -188.8056640625,
      "loss": 0.0665,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.34392249584198,
      "rewards/margins": 2.978208065032959,
      "rewards/rejected": -1.6342856884002686,
      "step": 636
    },
    {
      "epoch": 0.2548,
      "grad_norm": 5.479861259460449,
      "learning_rate": 9.151999999999999e-07,
      "logits/chosen": -2.029139757156372,
      "logits/rejected": -2.738028049468994,
      "logps/chosen": -122.44214630126953,
      "logps/rejected": -121.04122924804688,
      "loss": 0.1765,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2165435552597046,
      "rewards/margins": 1.7535511255264282,
      "rewards/rejected": -0.5370075106620789,
      "step": 637
    },
    {
      "epoch": 0.2552,
      "grad_norm": 2.6797831058502197,
      "learning_rate": 9.150666666666666e-07,
      "logits/chosen": -2.4800291061401367,
      "logits/rejected": -2.6440541744232178,
      "logps/chosen": -120.71875,
      "logps/rejected": -93.04219055175781,
      "loss": 0.0572,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6608989238739014,
      "rewards/margins": 2.9030425548553467,
      "rewards/rejected": -0.2421436309814453,
      "step": 638
    },
    {
      "epoch": 0.2556,
      "grad_norm": 5.948469638824463,
      "learning_rate": 9.149333333333333e-07,
      "logits/chosen": -1.9257464408874512,
      "logits/rejected": -2.301483154296875,
      "logps/chosen": -98.64579010009766,
      "logps/rejected": -100.60517883300781,
      "loss": 0.1576,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2904279232025146,
      "rewards/margins": 2.2689123153686523,
      "rewards/rejected": 0.021515652537345886,
      "step": 639
    },
    {
      "epoch": 0.256,
      "grad_norm": 2.951962947845459,
      "learning_rate": 9.147999999999999e-07,
      "logits/chosen": -2.1346874237060547,
      "logits/rejected": -1.9719233512878418,
      "logps/chosen": -111.85379028320312,
      "logps/rejected": -111.41073608398438,
      "loss": 0.052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.183615207672119,
      "rewards/margins": 3.127419948577881,
      "rewards/rejected": -0.9438049793243408,
      "step": 640
    },
    {
      "epoch": 0.2564,
      "grad_norm": 1.4520378112792969,
      "learning_rate": 9.146666666666666e-07,
      "logits/chosen": -2.6491494178771973,
      "logits/rejected": -2.951993942260742,
      "logps/chosen": -165.86827087402344,
      "logps/rejected": -145.5135498046875,
      "loss": 0.0212,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.951367139816284,
      "rewards/margins": 3.849713087081909,
      "rewards/rejected": -0.898345947265625,
      "step": 641
    },
    {
      "epoch": 0.2568,
      "grad_norm": 4.344520568847656,
      "learning_rate": 9.145333333333333e-07,
      "logits/chosen": -1.6574347019195557,
      "logits/rejected": -2.563598155975342,
      "logps/chosen": -91.97959899902344,
      "logps/rejected": -106.73517608642578,
      "loss": 0.1117,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4052006006240845,
      "rewards/margins": 2.289746046066284,
      "rewards/rejected": -0.8845455646514893,
      "step": 642
    },
    {
      "epoch": 0.2572,
      "grad_norm": 7.065405368804932,
      "learning_rate": 9.144e-07,
      "logits/chosen": -2.333543539047241,
      "logits/rejected": -2.1804773807525635,
      "logps/chosen": -100.03074645996094,
      "logps/rejected": -106.16514587402344,
      "loss": 0.1151,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6831119060516357,
      "rewards/margins": 2.269943952560425,
      "rewards/rejected": -0.5868320465087891,
      "step": 643
    },
    {
      "epoch": 0.2576,
      "grad_norm": 6.603237628936768,
      "learning_rate": 9.142666666666667e-07,
      "logits/chosen": -2.005920171737671,
      "logits/rejected": -2.1309168338775635,
      "logps/chosen": -94.166748046875,
      "logps/rejected": -89.30760955810547,
      "loss": 0.1028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9826807975769043,
      "rewards/margins": 2.6064693927764893,
      "rewards/rejected": -0.6237884759902954,
      "step": 644
    },
    {
      "epoch": 0.258,
      "grad_norm": 2.7952585220336914,
      "learning_rate": 9.141333333333333e-07,
      "logits/chosen": -1.5953776836395264,
      "logits/rejected": -2.9921679496765137,
      "logps/chosen": -120.91213989257812,
      "logps/rejected": -128.52857971191406,
      "loss": 0.0524,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.568727970123291,
      "rewards/margins": 3.2037854194641113,
      "rewards/rejected": -0.6350574493408203,
      "step": 645
    },
    {
      "epoch": 0.2584,
      "grad_norm": 4.501978874206543,
      "learning_rate": 9.14e-07,
      "logits/chosen": -1.9920580387115479,
      "logits/rejected": -3.1762685775756836,
      "logps/chosen": -172.05557250976562,
      "logps/rejected": -178.21726989746094,
      "loss": 0.065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9548240900039673,
      "rewards/margins": 2.843935489654541,
      "rewards/rejected": -0.8891113996505737,
      "step": 646
    },
    {
      "epoch": 0.2588,
      "grad_norm": 6.055637359619141,
      "learning_rate": 9.138666666666666e-07,
      "logits/chosen": -2.128467321395874,
      "logits/rejected": -2.7891697883605957,
      "logps/chosen": -97.78475952148438,
      "logps/rejected": -79.19200134277344,
      "loss": 0.1017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4462718963623047,
      "rewards/margins": 2.2535452842712402,
      "rewards/rejected": 0.1927265226840973,
      "step": 647
    },
    {
      "epoch": 0.2592,
      "grad_norm": 2.61346435546875,
      "learning_rate": 9.137333333333332e-07,
      "logits/chosen": -2.1622917652130127,
      "logits/rejected": -1.5987831354141235,
      "logps/chosen": -158.40487670898438,
      "logps/rejected": -86.8759536743164,
      "loss": 0.0423,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.727529287338257,
      "rewards/margins": 3.3359060287475586,
      "rewards/rejected": -0.6083767414093018,
      "step": 648
    },
    {
      "epoch": 0.2596,
      "grad_norm": 4.251710414886475,
      "learning_rate": 9.135999999999999e-07,
      "logits/chosen": -2.3999063968658447,
      "logits/rejected": -2.793610095977783,
      "logps/chosen": -118.791259765625,
      "logps/rejected": -112.33242797851562,
      "loss": 0.067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.338296413421631,
      "rewards/margins": 3.040872097015381,
      "rewards/rejected": -0.70257568359375,
      "step": 649
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.4628846645355225,
      "learning_rate": 9.134666666666666e-07,
      "logits/chosen": -2.1673269271850586,
      "logits/rejected": -1.9629733562469482,
      "logps/chosen": -144.6033477783203,
      "logps/rejected": -84.50051879882812,
      "loss": 0.0404,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.625413656234741,
      "rewards/margins": 3.2004313468933105,
      "rewards/rejected": -0.5750175714492798,
      "step": 650
    },
    {
      "epoch": 0.2604,
      "grad_norm": 2.813429355621338,
      "learning_rate": 9.133333333333333e-07,
      "logits/chosen": -1.9240422248840332,
      "logits/rejected": -2.7454988956451416,
      "logps/chosen": -129.96932983398438,
      "logps/rejected": -120.92296600341797,
      "loss": 0.0551,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2601916790008545,
      "rewards/margins": 2.93778657913208,
      "rewards/rejected": -0.677594780921936,
      "step": 651
    },
    {
      "epoch": 0.2608,
      "grad_norm": 2.035322427749634,
      "learning_rate": 9.132e-07,
      "logits/chosen": -2.1208510398864746,
      "logits/rejected": -2.2722296714782715,
      "logps/chosen": -111.75753021240234,
      "logps/rejected": -116.72166442871094,
      "loss": 0.0334,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.467906951904297,
      "rewards/margins": 3.3830649852752686,
      "rewards/rejected": -0.9151580333709717,
      "step": 652
    },
    {
      "epoch": 0.2612,
      "grad_norm": 4.571382999420166,
      "learning_rate": 9.130666666666667e-07,
      "logits/chosen": -2.476959228515625,
      "logits/rejected": -1.9766845703125,
      "logps/chosen": -109.01823425292969,
      "logps/rejected": -91.74859619140625,
      "loss": 0.1031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.037296772003174,
      "rewards/margins": 2.304036855697632,
      "rewards/rejected": -0.2667400538921356,
      "step": 653
    },
    {
      "epoch": 0.2616,
      "grad_norm": 4.659188747406006,
      "learning_rate": 9.129333333333334e-07,
      "logits/chosen": -2.4615092277526855,
      "logits/rejected": -2.5207395553588867,
      "logps/chosen": -126.23793029785156,
      "logps/rejected": -93.65419006347656,
      "loss": 0.0893,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.512636661529541,
      "rewards/margins": 3.0339417457580566,
      "rewards/rejected": -0.5213050842285156,
      "step": 654
    },
    {
      "epoch": 0.262,
      "grad_norm": 3.9765820503234863,
      "learning_rate": 9.127999999999999e-07,
      "logits/chosen": -1.9224023818969727,
      "logits/rejected": -2.5693345069885254,
      "logps/chosen": -155.72650146484375,
      "logps/rejected": -179.90684509277344,
      "loss": 0.0623,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1692519187927246,
      "rewards/margins": 2.796952724456787,
      "rewards/rejected": -0.6277008056640625,
      "step": 655
    },
    {
      "epoch": 0.2624,
      "grad_norm": 2.6814534664154053,
      "learning_rate": 9.126666666666666e-07,
      "logits/chosen": -2.1433987617492676,
      "logits/rejected": -2.441004753112793,
      "logps/chosen": -138.41949462890625,
      "logps/rejected": -118.01567077636719,
      "loss": 0.0466,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8745094537734985,
      "rewards/margins": 3.0494816303253174,
      "rewards/rejected": -1.1749721765518188,
      "step": 656
    },
    {
      "epoch": 0.2628,
      "grad_norm": 1.227753758430481,
      "learning_rate": 9.125333333333332e-07,
      "logits/chosen": -2.5131564140319824,
      "logits/rejected": -2.200596809387207,
      "logps/chosen": -142.93563842773438,
      "logps/rejected": -122.82645416259766,
      "loss": 0.0222,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.949624538421631,
      "rewards/margins": 3.8632583618164062,
      "rewards/rejected": -0.9136337041854858,
      "step": 657
    },
    {
      "epoch": 0.2632,
      "grad_norm": 2.2534425258636475,
      "learning_rate": 9.123999999999999e-07,
      "logits/chosen": -1.6866905689239502,
      "logits/rejected": -2.1100845336914062,
      "logps/chosen": -76.25530242919922,
      "logps/rejected": -104.33982849121094,
      "loss": 0.0475,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5470433235168457,
      "rewards/margins": 3.0292482376098633,
      "rewards/rejected": -0.4822048544883728,
      "step": 658
    },
    {
      "epoch": 0.2636,
      "grad_norm": 1.2392001152038574,
      "learning_rate": 9.122666666666666e-07,
      "logits/chosen": -2.2874796390533447,
      "logits/rejected": -2.3900489807128906,
      "logps/chosen": -180.99984741210938,
      "logps/rejected": -194.3689727783203,
      "loss": 0.0179,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.330059051513672,
      "rewards/margins": 4.1386308670043945,
      "rewards/rejected": -0.8085718154907227,
      "step": 659
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.625062108039856,
      "learning_rate": 9.121333333333333e-07,
      "logits/chosen": -2.3233389854431152,
      "logits/rejected": -3.061715602874756,
      "logps/chosen": -191.6136016845703,
      "logps/rejected": -125.26553344726562,
      "loss": 0.0096,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.39815616607666,
      "rewards/margins": 4.773125648498535,
      "rewards/rejected": -1.3749698400497437,
      "step": 660
    },
    {
      "epoch": 0.2644,
      "grad_norm": 6.260097503662109,
      "learning_rate": 9.12e-07,
      "logits/chosen": -1.840411901473999,
      "logits/rejected": -2.495509147644043,
      "logps/chosen": -89.62991333007812,
      "logps/rejected": -126.14179229736328,
      "loss": 0.1073,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2781877517700195,
      "rewards/margins": 2.3562660217285156,
      "rewards/rejected": -0.07807847857475281,
      "step": 661
    },
    {
      "epoch": 0.2648,
      "grad_norm": 4.737067222595215,
      "learning_rate": 9.118666666666667e-07,
      "logits/chosen": -1.9632641077041626,
      "logits/rejected": -2.082942008972168,
      "logps/chosen": -149.10818481445312,
      "logps/rejected": -93.7806167602539,
      "loss": 0.0612,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.039891242980957,
      "rewards/margins": 3.7278213500976562,
      "rewards/rejected": -0.6879302859306335,
      "step": 662
    },
    {
      "epoch": 0.2652,
      "grad_norm": 4.154921531677246,
      "learning_rate": 9.117333333333333e-07,
      "logits/chosen": -2.5149223804473877,
      "logits/rejected": -2.2163515090942383,
      "logps/chosen": -115.46180725097656,
      "logps/rejected": -91.33511352539062,
      "loss": 0.0875,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.675013542175293,
      "rewards/margins": 2.4699411392211914,
      "rewards/rejected": 0.20507241785526276,
      "step": 663
    },
    {
      "epoch": 0.2656,
      "grad_norm": 4.725563049316406,
      "learning_rate": 9.115999999999999e-07,
      "logits/chosen": -1.8103420734405518,
      "logits/rejected": -2.505194664001465,
      "logps/chosen": -79.84246826171875,
      "logps/rejected": -81.76876831054688,
      "loss": 0.0928,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.932121992111206,
      "rewards/margins": 2.3693878650665283,
      "rewards/rejected": -0.4372657835483551,
      "step": 664
    },
    {
      "epoch": 0.266,
      "grad_norm": 1.0180751085281372,
      "learning_rate": 9.114666666666666e-07,
      "logits/chosen": -1.9909167289733887,
      "logits/rejected": -2.098916530609131,
      "logps/chosen": -114.28233337402344,
      "logps/rejected": -119.86067199707031,
      "loss": 0.0171,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0563483238220215,
      "rewards/margins": 4.097560405731201,
      "rewards/rejected": -1.0412120819091797,
      "step": 665
    },
    {
      "epoch": 0.2664,
      "grad_norm": 1.611797571182251,
      "learning_rate": 9.113333333333333e-07,
      "logits/chosen": -2.1398606300354004,
      "logits/rejected": -2.4473540782928467,
      "logps/chosen": -190.47613525390625,
      "logps/rejected": -99.43647003173828,
      "loss": 0.0248,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7068839073181152,
      "rewards/margins": 3.8100461959838867,
      "rewards/rejected": -1.1031620502471924,
      "step": 666
    },
    {
      "epoch": 0.2668,
      "grad_norm": 4.74930477142334,
      "learning_rate": 9.112e-07,
      "logits/chosen": -2.239687442779541,
      "logits/rejected": -2.532036781311035,
      "logps/chosen": -108.57333374023438,
      "logps/rejected": -100.15486145019531,
      "loss": 0.1054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8207318782806396,
      "rewards/margins": 2.1964008808135986,
      "rewards/rejected": -0.37566912174224854,
      "step": 667
    },
    {
      "epoch": 0.2672,
      "grad_norm": 3.7634103298187256,
      "learning_rate": 9.110666666666666e-07,
      "logits/chosen": -2.000108242034912,
      "logits/rejected": -2.2977075576782227,
      "logps/chosen": -101.85896301269531,
      "logps/rejected": -123.23554992675781,
      "loss": 0.0528,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2741751670837402,
      "rewards/margins": 3.081704616546631,
      "rewards/rejected": -0.8075294494628906,
      "step": 668
    },
    {
      "epoch": 0.2676,
      "grad_norm": 1.801719307899475,
      "learning_rate": 9.109333333333333e-07,
      "logits/chosen": -2.5175607204437256,
      "logits/rejected": -2.79771089553833,
      "logps/chosen": -119.07755279541016,
      "logps/rejected": -178.95782470703125,
      "loss": 0.0233,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9845192432403564,
      "rewards/margins": 3.8760979175567627,
      "rewards/rejected": -0.8915786743164062,
      "step": 669
    },
    {
      "epoch": 0.268,
      "grad_norm": 4.0733137130737305,
      "learning_rate": 9.108e-07,
      "logits/chosen": -2.2461166381835938,
      "logits/rejected": -3.030999183654785,
      "logps/chosen": -151.25814819335938,
      "logps/rejected": -107.90272521972656,
      "loss": 0.0752,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.79917049407959,
      "rewards/margins": 2.9858810901641846,
      "rewards/rejected": -0.18671073019504547,
      "step": 670
    },
    {
      "epoch": 0.2684,
      "grad_norm": 0.9375492334365845,
      "learning_rate": 9.106666666666666e-07,
      "logits/chosen": -2.136272668838501,
      "logits/rejected": -2.239959239959717,
      "logps/chosen": -126.152099609375,
      "logps/rejected": -115.1767578125,
      "loss": 0.0204,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.702495574951172,
      "rewards/margins": 3.9432570934295654,
      "rewards/rejected": -1.2407615184783936,
      "step": 671
    },
    {
      "epoch": 0.2688,
      "grad_norm": 2.8299942016601562,
      "learning_rate": 9.105333333333333e-07,
      "logits/chosen": -1.8512637615203857,
      "logits/rejected": -1.8943030834197998,
      "logps/chosen": -105.47193908691406,
      "logps/rejected": -91.88406372070312,
      "loss": 0.035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5725646018981934,
      "rewards/margins": 4.007025241851807,
      "rewards/rejected": -1.4344605207443237,
      "step": 672
    },
    {
      "epoch": 0.2692,
      "grad_norm": 2.253965139389038,
      "learning_rate": 9.103999999999999e-07,
      "logits/chosen": -2.1878104209899902,
      "logits/rejected": -2.6938562393188477,
      "logps/chosen": -121.34249877929688,
      "logps/rejected": -114.95521545410156,
      "loss": 0.0418,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.316411256790161,
      "rewards/margins": 3.1791863441467285,
      "rewards/rejected": -0.8627750873565674,
      "step": 673
    },
    {
      "epoch": 0.2696,
      "grad_norm": 1.8182103633880615,
      "learning_rate": 9.102666666666666e-07,
      "logits/chosen": -2.154306411743164,
      "logits/rejected": -2.487062692642212,
      "logps/chosen": -118.20606994628906,
      "logps/rejected": -114.1349868774414,
      "loss": 0.0335,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.689612865447998,
      "rewards/margins": 3.710282802581787,
      "rewards/rejected": -1.020669937133789,
      "step": 674
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.447295665740967,
      "learning_rate": 9.101333333333333e-07,
      "logits/chosen": -1.9368700981140137,
      "logits/rejected": -1.800550937652588,
      "logps/chosen": -62.08528518676758,
      "logps/rejected": -86.57322692871094,
      "loss": 0.0766,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7975716590881348,
      "rewards/margins": 2.842895030975342,
      "rewards/rejected": -1.0453236103057861,
      "step": 675
    },
    {
      "epoch": 0.2704,
      "grad_norm": 3.9969985485076904,
      "learning_rate": 9.1e-07,
      "logits/chosen": -2.675591468811035,
      "logits/rejected": -2.964029550552368,
      "logps/chosen": -102.57295227050781,
      "logps/rejected": -113.34738159179688,
      "loss": 0.0667,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4312143325805664,
      "rewards/margins": 3.49800968170166,
      "rewards/rejected": -1.0667953491210938,
      "step": 676
    },
    {
      "epoch": 0.2708,
      "grad_norm": 8.511209487915039,
      "learning_rate": 9.098666666666667e-07,
      "logits/chosen": -2.3348324298858643,
      "logits/rejected": -2.8126614093780518,
      "logps/chosen": -150.8041534423828,
      "logps/rejected": -145.87220764160156,
      "loss": 0.1335,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.228490114212036,
      "rewards/margins": 2.7405972480773926,
      "rewards/rejected": -0.5121070742607117,
      "step": 677
    },
    {
      "epoch": 0.2712,
      "grad_norm": 3.5089333057403564,
      "learning_rate": 9.097333333333332e-07,
      "logits/chosen": -2.091057538986206,
      "logits/rejected": -2.476940631866455,
      "logps/chosen": -115.14058685302734,
      "logps/rejected": -128.09002685546875,
      "loss": 0.0603,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3708252906799316,
      "rewards/margins": 2.8318190574645996,
      "rewards/rejected": -1.460994005203247,
      "step": 678
    },
    {
      "epoch": 0.2716,
      "grad_norm": 3.380591630935669,
      "learning_rate": 9.095999999999999e-07,
      "logits/chosen": -2.1161789894104004,
      "logits/rejected": -2.219529151916504,
      "logps/chosen": -172.34298706054688,
      "logps/rejected": -105.7918701171875,
      "loss": 0.0562,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3710079193115234,
      "rewards/margins": 3.7196168899536133,
      "rewards/rejected": -1.3486088514328003,
      "step": 679
    },
    {
      "epoch": 0.272,
      "grad_norm": 3.961294412612915,
      "learning_rate": 9.094666666666666e-07,
      "logits/chosen": -1.8428101539611816,
      "logits/rejected": -2.0523838996887207,
      "logps/chosen": -140.20343017578125,
      "logps/rejected": -96.31861877441406,
      "loss": 0.0754,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.312382459640503,
      "rewards/margins": 2.9640450477600098,
      "rewards/rejected": -0.6516624689102173,
      "step": 680
    },
    {
      "epoch": 0.2724,
      "grad_norm": 2.8804285526275635,
      "learning_rate": 9.093333333333333e-07,
      "logits/chosen": -2.5130484104156494,
      "logits/rejected": -2.5615038871765137,
      "logps/chosen": -146.12490844726562,
      "logps/rejected": -101.67068481445312,
      "loss": 0.0479,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4819436073303223,
      "rewards/margins": 3.066345691680908,
      "rewards/rejected": -0.5844020843505859,
      "step": 681
    },
    {
      "epoch": 0.2728,
      "grad_norm": 0.9237185120582581,
      "learning_rate": 9.092e-07,
      "logits/chosen": -2.3986005783081055,
      "logits/rejected": -3.9616618156433105,
      "logps/chosen": -120.57514953613281,
      "logps/rejected": -151.72943115234375,
      "loss": 0.0152,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7460358142852783,
      "rewards/margins": 4.3620100021362305,
      "rewards/rejected": -1.6159744262695312,
      "step": 682
    },
    {
      "epoch": 0.2732,
      "grad_norm": 2.61718487739563,
      "learning_rate": 9.090666666666666e-07,
      "logits/chosen": -2.5265989303588867,
      "logits/rejected": -2.185500383377075,
      "logps/chosen": -106.39381408691406,
      "logps/rejected": -91.10379028320312,
      "loss": 0.0537,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7782669067382812,
      "rewards/margins": 2.973410129547119,
      "rewards/rejected": -0.19514313340187073,
      "step": 683
    },
    {
      "epoch": 0.2736,
      "grad_norm": 5.393703460693359,
      "learning_rate": 9.089333333333333e-07,
      "logits/chosen": -2.0729644298553467,
      "logits/rejected": -2.710751533508301,
      "logps/chosen": -115.59335327148438,
      "logps/rejected": -108.46546936035156,
      "loss": 0.0968,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4310723543167114,
      "rewards/margins": 2.58748722076416,
      "rewards/rejected": -1.1564147472381592,
      "step": 684
    },
    {
      "epoch": 0.274,
      "grad_norm": 7.280807018280029,
      "learning_rate": 9.088e-07,
      "logits/chosen": -1.7855565547943115,
      "logits/rejected": -2.466660976409912,
      "logps/chosen": -111.51449584960938,
      "logps/rejected": -186.94000244140625,
      "loss": 0.0954,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4782581329345703,
      "rewards/margins": 2.545175075531006,
      "rewards/rejected": -1.0669167041778564,
      "step": 685
    },
    {
      "epoch": 0.2744,
      "grad_norm": 2.6546971797943115,
      "learning_rate": 9.086666666666666e-07,
      "logits/chosen": -2.1623363494873047,
      "logits/rejected": -2.6208534240722656,
      "logps/chosen": -142.87228393554688,
      "logps/rejected": -117.123779296875,
      "loss": 0.0456,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.120494842529297,
      "rewards/margins": 3.1782963275909424,
      "rewards/rejected": -1.0578014850616455,
      "step": 686
    },
    {
      "epoch": 0.2748,
      "grad_norm": 1.7562819719314575,
      "learning_rate": 9.085333333333333e-07,
      "logits/chosen": -2.216831922531128,
      "logits/rejected": -2.3343491554260254,
      "logps/chosen": -154.68994140625,
      "logps/rejected": -107.7681884765625,
      "loss": 0.0282,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0589394569396973,
      "rewards/margins": 3.562202215194702,
      "rewards/rejected": -0.5032626986503601,
      "step": 687
    },
    {
      "epoch": 0.2752,
      "grad_norm": 1.0018490552902222,
      "learning_rate": 9.084e-07,
      "logits/chosen": -2.7288005352020264,
      "logits/rejected": -2.9146595001220703,
      "logps/chosen": -188.252685546875,
      "logps/rejected": -140.36557006835938,
      "loss": 0.0143,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1311559677124023,
      "rewards/margins": 4.3426055908203125,
      "rewards/rejected": -1.2114498615264893,
      "step": 688
    },
    {
      "epoch": 0.2756,
      "grad_norm": 4.997928619384766,
      "learning_rate": 9.082666666666666e-07,
      "logits/chosen": -2.357656717300415,
      "logits/rejected": -2.511890411376953,
      "logps/chosen": -160.33779907226562,
      "logps/rejected": -119.73135375976562,
      "loss": 0.0978,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0221991539001465,
      "rewards/margins": 2.7109973430633545,
      "rewards/rejected": -0.6887981295585632,
      "step": 689
    },
    {
      "epoch": 0.276,
      "grad_norm": 3.638631582260132,
      "learning_rate": 9.081333333333333e-07,
      "logits/chosen": -2.29526424407959,
      "logits/rejected": -2.9870150089263916,
      "logps/chosen": -124.8494873046875,
      "logps/rejected": -237.424560546875,
      "loss": 0.0461,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.289111614227295,
      "rewards/margins": 3.097496509552002,
      "rewards/rejected": -0.8083847165107727,
      "step": 690
    },
    {
      "epoch": 0.2764,
      "grad_norm": 1.5483884811401367,
      "learning_rate": 9.08e-07,
      "logits/chosen": -2.410339832305908,
      "logits/rejected": -2.8980937004089355,
      "logps/chosen": -167.6585693359375,
      "logps/rejected": -148.31134033203125,
      "loss": 0.027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.243488311767578,
      "rewards/margins": 3.662797212600708,
      "rewards/rejected": -0.4193088710308075,
      "step": 691
    },
    {
      "epoch": 0.2768,
      "grad_norm": 1.7064744234085083,
      "learning_rate": 9.078666666666666e-07,
      "logits/chosen": -1.6731996536254883,
      "logits/rejected": -2.550992250442505,
      "logps/chosen": -107.39697265625,
      "logps/rejected": -149.00025939941406,
      "loss": 0.0331,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8988349437713623,
      "rewards/margins": 3.400763988494873,
      "rewards/rejected": -1.5019290447235107,
      "step": 692
    },
    {
      "epoch": 0.2772,
      "grad_norm": 4.3314056396484375,
      "learning_rate": 9.077333333333332e-07,
      "logits/chosen": -2.518362283706665,
      "logits/rejected": -3.113176107406616,
      "logps/chosen": -165.25778198242188,
      "logps/rejected": -113.6509780883789,
      "loss": 0.0683,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8737298250198364,
      "rewards/margins": 3.2939281463623047,
      "rewards/rejected": -1.4201980829238892,
      "step": 693
    },
    {
      "epoch": 0.2776,
      "grad_norm": 0.8846026659011841,
      "learning_rate": 9.075999999999999e-07,
      "logits/chosen": -2.255570411682129,
      "logits/rejected": -2.4367737770080566,
      "logps/chosen": -98.72421264648438,
      "logps/rejected": -116.69699096679688,
      "loss": 0.0199,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.855330467224121,
      "rewards/margins": 3.9915919303894043,
      "rewards/rejected": -1.1362613439559937,
      "step": 694
    },
    {
      "epoch": 0.278,
      "grad_norm": 1.142778754234314,
      "learning_rate": 9.074666666666666e-07,
      "logits/chosen": -2.3776843547821045,
      "logits/rejected": -2.0968170166015625,
      "logps/chosen": -169.224609375,
      "logps/rejected": -93.4073486328125,
      "loss": 0.0246,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.571791648864746,
      "rewards/margins": 3.831056833267212,
      "rewards/rejected": -1.2592653036117554,
      "step": 695
    },
    {
      "epoch": 0.2784,
      "grad_norm": 2.472511053085327,
      "learning_rate": 9.073333333333333e-07,
      "logits/chosen": -2.067255973815918,
      "logits/rejected": -2.8361668586730957,
      "logps/chosen": -110.52415466308594,
      "logps/rejected": -123.69294738769531,
      "loss": 0.0311,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.580460786819458,
      "rewards/margins": 3.638373613357544,
      "rewards/rejected": -1.057912826538086,
      "step": 696
    },
    {
      "epoch": 0.2788,
      "grad_norm": 0.5030413269996643,
      "learning_rate": 9.072e-07,
      "logits/chosen": -2.061736583709717,
      "logits/rejected": -1.959744930267334,
      "logps/chosen": -133.75787353515625,
      "logps/rejected": -109.75362396240234,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4479877948760986,
      "rewards/margins": 5.244077682495117,
      "rewards/rejected": -1.79608952999115,
      "step": 697
    },
    {
      "epoch": 0.2792,
      "grad_norm": 5.440914154052734,
      "learning_rate": 9.070666666666667e-07,
      "logits/chosen": -2.217369794845581,
      "logits/rejected": -2.7645978927612305,
      "logps/chosen": -133.2884063720703,
      "logps/rejected": -159.9510040283203,
      "loss": 0.1031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1852924823760986,
      "rewards/margins": 3.2569878101348877,
      "rewards/rejected": -1.071695327758789,
      "step": 698
    },
    {
      "epoch": 0.2796,
      "grad_norm": 9.989261627197266,
      "learning_rate": 9.069333333333334e-07,
      "logits/chosen": -2.186359405517578,
      "logits/rejected": -2.7622969150543213,
      "logps/chosen": -125.54292297363281,
      "logps/rejected": -91.32066345214844,
      "loss": 0.1455,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0437259674072266,
      "rewards/margins": 2.395174026489258,
      "rewards/rejected": -0.35144808888435364,
      "step": 699
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.4463865756988525,
      "learning_rate": 9.068e-07,
      "logits/chosen": -2.416017770767212,
      "logits/rejected": -2.8063249588012695,
      "logps/chosen": -203.16925048828125,
      "logps/rejected": -142.60281372070312,
      "loss": 0.0265,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8033199310302734,
      "rewards/margins": 3.7575111389160156,
      "rewards/rejected": -0.9541912078857422,
      "step": 700
    },
    {
      "epoch": 0.2804,
      "grad_norm": 1.0359190702438354,
      "learning_rate": 9.066666666666665e-07,
      "logits/chosen": -2.169443130493164,
      "logits/rejected": -2.739349365234375,
      "logps/chosen": -133.46334838867188,
      "logps/rejected": -175.77127075195312,
      "loss": 0.0155,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.947505235671997,
      "rewards/margins": 4.162461280822754,
      "rewards/rejected": -1.2149559259414673,
      "step": 701
    },
    {
      "epoch": 0.2808,
      "grad_norm": 5.130861759185791,
      "learning_rate": 9.065333333333332e-07,
      "logits/chosen": -1.7484537363052368,
      "logits/rejected": -2.090744733810425,
      "logps/chosen": -139.30291748046875,
      "logps/rejected": -85.24402618408203,
      "loss": 0.1175,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5690354108810425,
      "rewards/margins": 2.2631492614746094,
      "rewards/rejected": -0.6941137909889221,
      "step": 702
    },
    {
      "epoch": 0.2812,
      "grad_norm": 17.288455963134766,
      "learning_rate": 9.063999999999999e-07,
      "logits/chosen": -1.7741893529891968,
      "logits/rejected": -2.638237476348877,
      "logps/chosen": -93.26078796386719,
      "logps/rejected": -110.4891357421875,
      "loss": 0.3359,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7890422940254211,
      "rewards/margins": 1.1135822534561157,
      "rewards/rejected": -0.3245399594306946,
      "step": 703
    },
    {
      "epoch": 0.2816,
      "grad_norm": 1.1075966358184814,
      "learning_rate": 9.062666666666666e-07,
      "logits/chosen": -2.5189599990844727,
      "logits/rejected": -2.5780982971191406,
      "logps/chosen": -141.595458984375,
      "logps/rejected": -137.22235107421875,
      "loss": 0.0158,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2632498741149902,
      "rewards/margins": 4.139703750610352,
      "rewards/rejected": -0.8764537572860718,
      "step": 704
    },
    {
      "epoch": 0.282,
      "grad_norm": 2.4032938480377197,
      "learning_rate": 9.061333333333333e-07,
      "logits/chosen": -2.114861249923706,
      "logits/rejected": -2.4898624420166016,
      "logps/chosen": -111.38890075683594,
      "logps/rejected": -101.10686492919922,
      "loss": 0.0594,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.689931869506836,
      "rewards/margins": 2.815877914428711,
      "rewards/rejected": -1.125946044921875,
      "step": 705
    },
    {
      "epoch": 0.2824,
      "grad_norm": 5.115031719207764,
      "learning_rate": 9.06e-07,
      "logits/chosen": -2.285315752029419,
      "logits/rejected": -3.04237699508667,
      "logps/chosen": -128.91091918945312,
      "logps/rejected": -111.41766357421875,
      "loss": 0.0656,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9194157123565674,
      "rewards/margins": 2.9103543758392334,
      "rewards/rejected": -0.9909386038780212,
      "step": 706
    },
    {
      "epoch": 0.2828,
      "grad_norm": 2.706799268722534,
      "learning_rate": 9.058666666666667e-07,
      "logits/chosen": -2.126347541809082,
      "logits/rejected": -2.2493839263916016,
      "logps/chosen": -106.01085662841797,
      "logps/rejected": -131.20828247070312,
      "loss": 0.036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4623019695281982,
      "rewards/margins": 4.053959846496582,
      "rewards/rejected": -1.591658115386963,
      "step": 707
    },
    {
      "epoch": 0.2832,
      "grad_norm": 2.459059953689575,
      "learning_rate": 9.057333333333333e-07,
      "logits/chosen": -2.168837785720825,
      "logits/rejected": -2.3620994091033936,
      "logps/chosen": -122.36197662353516,
      "logps/rejected": -99.30758666992188,
      "loss": 0.0319,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0177712440490723,
      "rewards/margins": 3.8519043922424316,
      "rewards/rejected": -0.8341332077980042,
      "step": 708
    },
    {
      "epoch": 0.2836,
      "grad_norm": 3.9389822483062744,
      "learning_rate": 9.056e-07,
      "logits/chosen": -2.638233184814453,
      "logits/rejected": -2.368373394012451,
      "logps/chosen": -184.72738647460938,
      "logps/rejected": -121.1895751953125,
      "loss": 0.0666,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.024510145187378,
      "rewards/margins": 2.769768714904785,
      "rewards/rejected": -0.7452583312988281,
      "step": 709
    },
    {
      "epoch": 0.284,
      "grad_norm": 7.482361316680908,
      "learning_rate": 9.054666666666666e-07,
      "logits/chosen": -2.127319812774658,
      "logits/rejected": -2.2688112258911133,
      "logps/chosen": -124.47003936767578,
      "logps/rejected": -103.56033325195312,
      "loss": 0.1267,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2552640438079834,
      "rewards/margins": 2.6129980087280273,
      "rewards/rejected": -0.35773393511772156,
      "step": 710
    },
    {
      "epoch": 0.2844,
      "grad_norm": 1.8704215288162231,
      "learning_rate": 9.053333333333332e-07,
      "logits/chosen": -1.59938645362854,
      "logits/rejected": -1.9502882957458496,
      "logps/chosen": -86.23334503173828,
      "logps/rejected": -99.48023223876953,
      "loss": 0.0375,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.912318229675293,
      "rewards/margins": 3.78920578956604,
      "rewards/rejected": -0.8768875598907471,
      "step": 711
    },
    {
      "epoch": 0.2848,
      "grad_norm": 5.774497985839844,
      "learning_rate": 9.051999999999999e-07,
      "logits/chosen": -2.161914587020874,
      "logits/rejected": -2.7039270401000977,
      "logps/chosen": -131.48712158203125,
      "logps/rejected": -122.67481994628906,
      "loss": 0.0895,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7677910327911377,
      "rewards/margins": 2.8226373195648193,
      "rewards/rejected": -1.0548462867736816,
      "step": 712
    },
    {
      "epoch": 0.2852,
      "grad_norm": 2.2346787452697754,
      "learning_rate": 9.050666666666666e-07,
      "logits/chosen": -2.525317668914795,
      "logits/rejected": -1.5654237270355225,
      "logps/chosen": -171.7447967529297,
      "logps/rejected": -115.47383117675781,
      "loss": 0.0394,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5832629203796387,
      "rewards/margins": 3.5661139488220215,
      "rewards/rejected": 0.017148971557617188,
      "step": 713
    },
    {
      "epoch": 0.2856,
      "grad_norm": 4.082427024841309,
      "learning_rate": 9.049333333333333e-07,
      "logits/chosen": -1.9944519996643066,
      "logits/rejected": -2.8272178173065186,
      "logps/chosen": -121.58467864990234,
      "logps/rejected": -107.32672119140625,
      "loss": 0.0736,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.137239933013916,
      "rewards/margins": 2.641786575317383,
      "rewards/rejected": -0.5045467615127563,
      "step": 714
    },
    {
      "epoch": 0.286,
      "grad_norm": 0.723056435585022,
      "learning_rate": 9.048e-07,
      "logits/chosen": -2.503063201904297,
      "logits/rejected": -3.1876220703125,
      "logps/chosen": -143.3983154296875,
      "logps/rejected": -128.57920837402344,
      "loss": 0.0104,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.243669033050537,
      "rewards/margins": 4.605350494384766,
      "rewards/rejected": -1.3616809844970703,
      "step": 715
    },
    {
      "epoch": 0.2864,
      "grad_norm": 0.8177483081817627,
      "learning_rate": 9.046666666666666e-07,
      "logits/chosen": -2.110382556915283,
      "logits/rejected": -2.275439977645874,
      "logps/chosen": -125.21782684326172,
      "logps/rejected": -121.87430572509766,
      "loss": 0.0142,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.089587450027466,
      "rewards/margins": 4.274784564971924,
      "rewards/rejected": -1.185197114944458,
      "step": 716
    },
    {
      "epoch": 0.2868,
      "grad_norm": 1.6958924531936646,
      "learning_rate": 9.045333333333333e-07,
      "logits/chosen": -1.949837565422058,
      "logits/rejected": -2.5709266662597656,
      "logps/chosen": -73.17947387695312,
      "logps/rejected": -130.2543182373047,
      "loss": 0.0294,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.709179401397705,
      "rewards/margins": 3.540188789367676,
      "rewards/rejected": -0.8310093283653259,
      "step": 717
    },
    {
      "epoch": 0.2872,
      "grad_norm": 4.653999328613281,
      "learning_rate": 9.044e-07,
      "logits/chosen": -2.126430034637451,
      "logits/rejected": -2.507523536682129,
      "logps/chosen": -136.89865112304688,
      "logps/rejected": -90.82069396972656,
      "loss": 0.078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.578759789466858,
      "rewards/margins": 2.5154716968536377,
      "rewards/rejected": -0.9367119073867798,
      "step": 718
    },
    {
      "epoch": 0.2876,
      "grad_norm": 0.9006991386413574,
      "learning_rate": 9.042666666666667e-07,
      "logits/chosen": -2.4581491947174072,
      "logits/rejected": -3.022947311401367,
      "logps/chosen": -115.98406982421875,
      "logps/rejected": -126.71258544921875,
      "loss": 0.0159,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.912796974182129,
      "rewards/margins": 4.256859302520752,
      "rewards/rejected": -1.3440624475479126,
      "step": 719
    },
    {
      "epoch": 0.288,
      "grad_norm": 2.081514596939087,
      "learning_rate": 9.041333333333334e-07,
      "logits/chosen": -2.17229962348938,
      "logits/rejected": -2.412550449371338,
      "logps/chosen": -160.4269256591797,
      "logps/rejected": -114.46723937988281,
      "loss": 0.0337,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6066031455993652,
      "rewards/margins": 3.5370032787323,
      "rewards/rejected": -0.9304001331329346,
      "step": 720
    },
    {
      "epoch": 0.2884,
      "grad_norm": 1.8438290357589722,
      "learning_rate": 9.039999999999999e-07,
      "logits/chosen": -2.2387900352478027,
      "logits/rejected": -2.6363892555236816,
      "logps/chosen": -179.48861694335938,
      "logps/rejected": -116.30148315429688,
      "loss": 0.0245,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.369387149810791,
      "rewards/margins": 3.7642900943756104,
      "rewards/rejected": -1.3949028253555298,
      "step": 721
    },
    {
      "epoch": 0.2888,
      "grad_norm": 2.9005794525146484,
      "learning_rate": 9.038666666666666e-07,
      "logits/chosen": -2.3339664936065674,
      "logits/rejected": -2.1413326263427734,
      "logps/chosen": -119.53900146484375,
      "logps/rejected": -120.08074951171875,
      "loss": 0.0612,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6890385150909424,
      "rewards/margins": 3.2698116302490234,
      "rewards/rejected": -0.5807732343673706,
      "step": 722
    },
    {
      "epoch": 0.2892,
      "grad_norm": 1.4367810487747192,
      "learning_rate": 9.037333333333333e-07,
      "logits/chosen": -2.3146250247955322,
      "logits/rejected": -2.225048065185547,
      "logps/chosen": -108.14129638671875,
      "logps/rejected": -113.10029602050781,
      "loss": 0.0266,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5839996337890625,
      "rewards/margins": 3.6192848682403564,
      "rewards/rejected": -1.035285234451294,
      "step": 723
    },
    {
      "epoch": 0.2896,
      "grad_norm": 3.4309446811676025,
      "learning_rate": 9.035999999999999e-07,
      "logits/chosen": -2.2663955688476562,
      "logits/rejected": -2.420382261276245,
      "logps/chosen": -95.32463836669922,
      "logps/rejected": -116.83100891113281,
      "loss": 0.0532,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5904436111450195,
      "rewards/margins": 3.6232099533081055,
      "rewards/rejected": -1.032766342163086,
      "step": 724
    },
    {
      "epoch": 0.29,
      "grad_norm": 5.8699493408203125,
      "learning_rate": 9.034666666666666e-07,
      "logits/chosen": -2.030355453491211,
      "logits/rejected": -2.565328598022461,
      "logps/chosen": -80.6592788696289,
      "logps/rejected": -96.35013580322266,
      "loss": 0.0872,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.320810317993164,
      "rewards/margins": 2.994145154953003,
      "rewards/rejected": -0.6733348965644836,
      "step": 725
    },
    {
      "epoch": 0.2904,
      "grad_norm": 1.300604224205017,
      "learning_rate": 9.033333333333333e-07,
      "logits/chosen": -2.0951614379882812,
      "logits/rejected": -2.255030393600464,
      "logps/chosen": -108.65072631835938,
      "logps/rejected": -114.17637634277344,
      "loss": 0.0262,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.00056791305542,
      "rewards/margins": 3.6303744316101074,
      "rewards/rejected": -0.6298065185546875,
      "step": 726
    },
    {
      "epoch": 0.2908,
      "grad_norm": 2.538127899169922,
      "learning_rate": 9.032e-07,
      "logits/chosen": -2.6278159618377686,
      "logits/rejected": -2.3845415115356445,
      "logps/chosen": -218.7396240234375,
      "logps/rejected": -178.45338439941406,
      "loss": 0.0317,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6467409133911133,
      "rewards/margins": 3.488496780395508,
      "rewards/rejected": -0.8417561054229736,
      "step": 727
    },
    {
      "epoch": 0.2912,
      "grad_norm": 9.458392143249512,
      "learning_rate": 9.030666666666667e-07,
      "logits/chosen": -2.4893436431884766,
      "logits/rejected": -2.541158437728882,
      "logps/chosen": -197.35508728027344,
      "logps/rejected": -91.67109680175781,
      "loss": 0.1791,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1917061805725098,
      "rewards/margins": 2.3555564880371094,
      "rewards/rejected": -0.16385042667388916,
      "step": 728
    },
    {
      "epoch": 0.2916,
      "grad_norm": 6.341865539550781,
      "learning_rate": 9.029333333333334e-07,
      "logits/chosen": -2.3981335163116455,
      "logits/rejected": -1.4406447410583496,
      "logps/chosen": -94.79808044433594,
      "logps/rejected": -139.24778747558594,
      "loss": 0.0847,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0449728965759277,
      "rewards/margins": 2.4567480087280273,
      "rewards/rejected": -0.41177481412887573,
      "step": 729
    },
    {
      "epoch": 0.292,
      "grad_norm": 2.6327059268951416,
      "learning_rate": 9.028e-07,
      "logits/chosen": -2.207946300506592,
      "logits/rejected": -2.8325352668762207,
      "logps/chosen": -122.00862121582031,
      "logps/rejected": -88.17446899414062,
      "loss": 0.0549,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4676856994628906,
      "rewards/margins": 2.878955125808716,
      "rewards/rejected": -0.4112693667411804,
      "step": 730
    },
    {
      "epoch": 0.2924,
      "grad_norm": 3.9424993991851807,
      "learning_rate": 9.026666666666665e-07,
      "logits/chosen": -2.0962772369384766,
      "logits/rejected": -2.3903732299804688,
      "logps/chosen": -109.74455261230469,
      "logps/rejected": -99.18121337890625,
      "loss": 0.0714,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.408454418182373,
      "rewards/margins": 3.685676097869873,
      "rewards/rejected": -1.2772216796875,
      "step": 731
    },
    {
      "epoch": 0.2928,
      "grad_norm": 2.9431469440460205,
      "learning_rate": 9.025333333333332e-07,
      "logits/chosen": -2.0941412448883057,
      "logits/rejected": -3.117659091949463,
      "logps/chosen": -73.95130157470703,
      "logps/rejected": -96.18179321289062,
      "loss": 0.0631,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.243609666824341,
      "rewards/margins": 2.732860565185547,
      "rewards/rejected": -0.48925095796585083,
      "step": 732
    },
    {
      "epoch": 0.2932,
      "grad_norm": 2.267510414123535,
      "learning_rate": 9.023999999999999e-07,
      "logits/chosen": -2.5484423637390137,
      "logits/rejected": -2.651308536529541,
      "logps/chosen": -148.60751342773438,
      "logps/rejected": -89.69355773925781,
      "loss": 0.0364,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.960160493850708,
      "rewards/margins": 3.4691805839538574,
      "rewards/rejected": -0.5090199112892151,
      "step": 733
    },
    {
      "epoch": 0.2936,
      "grad_norm": 5.489495754241943,
      "learning_rate": 9.022666666666666e-07,
      "logits/chosen": -2.0923991203308105,
      "logits/rejected": -3.5363221168518066,
      "logps/chosen": -141.00257873535156,
      "logps/rejected": -131.50112915039062,
      "loss": 0.0765,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.758420944213867,
      "rewards/margins": 3.2720863819122314,
      "rewards/rejected": -0.5136653780937195,
      "step": 734
    },
    {
      "epoch": 0.294,
      "grad_norm": 14.111071586608887,
      "learning_rate": 9.021333333333333e-07,
      "logits/chosen": -2.058048725128174,
      "logits/rejected": -2.674834728240967,
      "logps/chosen": -111.19705200195312,
      "logps/rejected": -91.43190002441406,
      "loss": 0.3233,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4733664989471436,
      "rewards/margins": 1.6079524755477905,
      "rewards/rejected": -0.13458596169948578,
      "step": 735
    },
    {
      "epoch": 0.2944,
      "grad_norm": 1.464805245399475,
      "learning_rate": 9.02e-07,
      "logits/chosen": -2.164936065673828,
      "logits/rejected": -2.3672561645507812,
      "logps/chosen": -156.35430908203125,
      "logps/rejected": -115.66307067871094,
      "loss": 0.0291,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5030479431152344,
      "rewards/margins": 3.6380550861358643,
      "rewards/rejected": -1.1350071430206299,
      "step": 736
    },
    {
      "epoch": 0.2948,
      "grad_norm": 1.1279784440994263,
      "learning_rate": 9.018666666666667e-07,
      "logits/chosen": -2.409402370452881,
      "logits/rejected": -2.253572940826416,
      "logps/chosen": -128.97740173339844,
      "logps/rejected": -77.82020568847656,
      "loss": 0.0235,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9054603576660156,
      "rewards/margins": 3.747767448425293,
      "rewards/rejected": -0.8423069715499878,
      "step": 737
    },
    {
      "epoch": 0.2952,
      "grad_norm": 1.7111448049545288,
      "learning_rate": 9.017333333333334e-07,
      "logits/chosen": -1.851823091506958,
      "logits/rejected": -2.610039234161377,
      "logps/chosen": -79.3306655883789,
      "logps/rejected": -102.29829406738281,
      "loss": 0.0276,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.026906967163086,
      "rewards/margins": 3.5815348625183105,
      "rewards/rejected": -0.5546280145645142,
      "step": 738
    },
    {
      "epoch": 0.2956,
      "grad_norm": 1.5197844505310059,
      "learning_rate": 9.015999999999999e-07,
      "logits/chosen": -2.1800851821899414,
      "logits/rejected": -2.7711076736450195,
      "logps/chosen": -126.76219177246094,
      "logps/rejected": -147.8239288330078,
      "loss": 0.0276,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6638569831848145,
      "rewards/margins": 4.098533630371094,
      "rewards/rejected": -0.4346763491630554,
      "step": 739
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.36461684107780457,
      "learning_rate": 9.014666666666666e-07,
      "logits/chosen": -2.4132637977600098,
      "logits/rejected": -2.989797830581665,
      "logps/chosen": -163.66494750976562,
      "logps/rejected": -146.10064697265625,
      "loss": 0.0057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.625277042388916,
      "rewards/margins": 5.369462490081787,
      "rewards/rejected": -1.7441856861114502,
      "step": 740
    },
    {
      "epoch": 0.2964,
      "grad_norm": 2.9841723442077637,
      "learning_rate": 9.013333333333333e-07,
      "logits/chosen": -2.625972270965576,
      "logits/rejected": -3.0662927627563477,
      "logps/chosen": -169.06796264648438,
      "logps/rejected": -139.23617553710938,
      "loss": 0.0419,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.267624616622925,
      "rewards/margins": 3.8400137424468994,
      "rewards/rejected": -1.5723892450332642,
      "step": 741
    },
    {
      "epoch": 0.2968,
      "grad_norm": 1.2449610233306885,
      "learning_rate": 9.011999999999999e-07,
      "logits/chosen": -2.386064052581787,
      "logits/rejected": -2.1300430297851562,
      "logps/chosen": -175.6629180908203,
      "logps/rejected": -124.53763580322266,
      "loss": 0.0225,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0681869983673096,
      "rewards/margins": 4.329463958740234,
      "rewards/rejected": -1.2612769603729248,
      "step": 742
    },
    {
      "epoch": 0.2972,
      "grad_norm": 1.7274221181869507,
      "learning_rate": 9.010666666666666e-07,
      "logits/chosen": -2.692204475402832,
      "logits/rejected": -2.44508957862854,
      "logps/chosen": -192.81796264648438,
      "logps/rejected": -144.3341064453125,
      "loss": 0.0209,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.944934129714966,
      "rewards/margins": 3.93615460395813,
      "rewards/rejected": -0.9912204742431641,
      "step": 743
    },
    {
      "epoch": 0.2976,
      "grad_norm": 4.792261123657227,
      "learning_rate": 9.009333333333333e-07,
      "logits/chosen": -2.4652507305145264,
      "logits/rejected": -1.8573670387268066,
      "logps/chosen": -83.6668472290039,
      "logps/rejected": -75.30508422851562,
      "loss": 0.1021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8757224082946777,
      "rewards/margins": 2.9180362224578857,
      "rewards/rejected": -0.042313769459724426,
      "step": 744
    },
    {
      "epoch": 0.298,
      "grad_norm": 6.544372081756592,
      "learning_rate": 9.008e-07,
      "logits/chosen": -2.2554497718811035,
      "logits/rejected": -2.1043338775634766,
      "logps/chosen": -141.97312927246094,
      "logps/rejected": -80.85575866699219,
      "loss": 0.12,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8876789808273315,
      "rewards/margins": 2.251924514770508,
      "rewards/rejected": -0.36424559354782104,
      "step": 745
    },
    {
      "epoch": 0.2984,
      "grad_norm": 13.212539672851562,
      "learning_rate": 9.006666666666666e-07,
      "logits/chosen": -2.253730535507202,
      "logits/rejected": -2.5087385177612305,
      "logps/chosen": -96.00276184082031,
      "logps/rejected": -90.8216552734375,
      "loss": 0.2281,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3726966381072998,
      "rewards/margins": 1.724108099937439,
      "rewards/rejected": -0.35141146183013916,
      "step": 746
    },
    {
      "epoch": 0.2988,
      "grad_norm": 3.332308292388916,
      "learning_rate": 9.005333333333333e-07,
      "logits/chosen": -1.9225456714630127,
      "logits/rejected": -2.49967360496521,
      "logps/chosen": -98.956787109375,
      "logps/rejected": -122.79792785644531,
      "loss": 0.0546,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2998533248901367,
      "rewards/margins": 3.4828295707702637,
      "rewards/rejected": -1.182976484298706,
      "step": 747
    },
    {
      "epoch": 0.2992,
      "grad_norm": 1.5349642038345337,
      "learning_rate": 9.004e-07,
      "logits/chosen": -2.740598678588867,
      "logits/rejected": -2.694929599761963,
      "logps/chosen": -132.7092742919922,
      "logps/rejected": -95.14521026611328,
      "loss": 0.0261,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.100234031677246,
      "rewards/margins": 3.7445733547210693,
      "rewards/rejected": -0.644339382648468,
      "step": 748
    },
    {
      "epoch": 0.2996,
      "grad_norm": 1.5849775075912476,
      "learning_rate": 9.002666666666666e-07,
      "logits/chosen": -2.213322162628174,
      "logits/rejected": -2.7420239448547363,
      "logps/chosen": -161.78067016601562,
      "logps/rejected": -95.01495361328125,
      "loss": 0.0195,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.533281087875366,
      "rewards/margins": 4.083387851715088,
      "rewards/rejected": -0.5501068234443665,
      "step": 749
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.7914042472839355,
      "learning_rate": 9.001333333333333e-07,
      "logits/chosen": -2.293971538543701,
      "logits/rejected": -2.3802552223205566,
      "logps/chosen": -106.54293823242188,
      "logps/rejected": -87.96089172363281,
      "loss": 0.0528,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.641663074493408,
      "rewards/margins": 2.925349235534668,
      "rewards/rejected": -0.2836860716342926,
      "step": 750
    },
    {
      "epoch": 0.3004,
      "grad_norm": 7.010635852813721,
      "learning_rate": 9e-07,
      "logits/chosen": -1.8418651819229126,
      "logits/rejected": -3.0491185188293457,
      "logps/chosen": -118.12368774414062,
      "logps/rejected": -120.17146301269531,
      "loss": 0.1375,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.058911919593811,
      "rewards/margins": 2.003293991088867,
      "rewards/rejected": -0.9443821310997009,
      "step": 751
    },
    {
      "epoch": 0.3008,
      "grad_norm": 2.524777889251709,
      "learning_rate": 8.998666666666667e-07,
      "logits/chosen": -2.453357219696045,
      "logits/rejected": -1.7770874500274658,
      "logps/chosen": -146.688232421875,
      "logps/rejected": -117.24864196777344,
      "loss": 0.0282,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.400257110595703,
      "rewards/margins": 4.19193172454834,
      "rewards/rejected": -0.7916748523712158,
      "step": 752
    },
    {
      "epoch": 0.3012,
      "grad_norm": 0.47316116094589233,
      "learning_rate": 8.997333333333333e-07,
      "logits/chosen": -2.4130859375,
      "logits/rejected": -2.952833414077759,
      "logps/chosen": -128.2381591796875,
      "logps/rejected": -146.25082397460938,
      "loss": 0.0067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4075164794921875,
      "rewards/margins": 5.007711410522461,
      "rewards/rejected": -1.6001945734024048,
      "step": 753
    },
    {
      "epoch": 0.3016,
      "grad_norm": 1.247700572013855,
      "learning_rate": 8.995999999999999e-07,
      "logits/chosen": -2.5096969604492188,
      "logits/rejected": -2.910552501678467,
      "logps/chosen": -208.79978942871094,
      "logps/rejected": -146.68115234375,
      "loss": 0.0187,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.026628017425537,
      "rewards/margins": 4.283781051635742,
      "rewards/rejected": -1.257153034210205,
      "step": 754
    },
    {
      "epoch": 0.302,
      "grad_norm": 3.0421462059020996,
      "learning_rate": 8.994666666666666e-07,
      "logits/chosen": -2.746831178665161,
      "logits/rejected": -2.2243034839630127,
      "logps/chosen": -213.02572631835938,
      "logps/rejected": -136.348388671875,
      "loss": 0.0322,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2904725074768066,
      "rewards/margins": 3.992344617843628,
      "rewards/rejected": -1.7018723487854004,
      "step": 755
    },
    {
      "epoch": 0.3024,
      "grad_norm": 0.9353224635124207,
      "learning_rate": 8.993333333333333e-07,
      "logits/chosen": -2.179460287094116,
      "logits/rejected": -1.981523036956787,
      "logps/chosen": -135.25230407714844,
      "logps/rejected": -89.50272369384766,
      "loss": 0.015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7951102256774902,
      "rewards/margins": 4.437460899353027,
      "rewards/rejected": -1.642350435256958,
      "step": 756
    },
    {
      "epoch": 0.3028,
      "grad_norm": 0.6461456418037415,
      "learning_rate": 8.992e-07,
      "logits/chosen": -2.0039145946502686,
      "logits/rejected": -2.8236236572265625,
      "logps/chosen": -96.29644012451172,
      "logps/rejected": -148.1389617919922,
      "loss": 0.0093,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4814348220825195,
      "rewards/margins": 4.755762577056885,
      "rewards/rejected": -1.2743278741836548,
      "step": 757
    },
    {
      "epoch": 0.3032,
      "grad_norm": 0.4849247932434082,
      "learning_rate": 8.990666666666666e-07,
      "logits/chosen": -2.6036581993103027,
      "logits/rejected": -2.362868309020996,
      "logps/chosen": -164.10174560546875,
      "logps/rejected": -170.78469848632812,
      "loss": 0.0065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.137814998626709,
      "rewards/margins": 5.09195613861084,
      "rewards/rejected": -1.9541412591934204,
      "step": 758
    },
    {
      "epoch": 0.3036,
      "grad_norm": 1.9696834087371826,
      "learning_rate": 8.989333333333333e-07,
      "logits/chosen": -2.245577096939087,
      "logits/rejected": -2.8822450637817383,
      "logps/chosen": -175.5797119140625,
      "logps/rejected": -118.18766784667969,
      "loss": 0.0298,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5521364212036133,
      "rewards/margins": 3.597564220428467,
      "rewards/rejected": -1.045427680015564,
      "step": 759
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.6146087050437927,
      "learning_rate": 8.988e-07,
      "logits/chosen": -2.0122971534729004,
      "logits/rejected": -2.8989460468292236,
      "logps/chosen": -123.33549499511719,
      "logps/rejected": -148.4015655517578,
      "loss": 0.0085,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7617955207824707,
      "rewards/margins": 5.097466468811035,
      "rewards/rejected": -1.335670828819275,
      "step": 760
    },
    {
      "epoch": 0.3044,
      "grad_norm": 0.32467588782310486,
      "learning_rate": 8.986666666666666e-07,
      "logits/chosen": -2.4913763999938965,
      "logits/rejected": -2.301738739013672,
      "logps/chosen": -159.03762817382812,
      "logps/rejected": -221.5517578125,
      "loss": 0.0045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.2349443435668945,
      "rewards/margins": 5.405002593994141,
      "rewards/rejected": -1.1700584888458252,
      "step": 761
    },
    {
      "epoch": 0.3048,
      "grad_norm": 1.1502612829208374,
      "learning_rate": 8.985333333333333e-07,
      "logits/chosen": -2.2945797443389893,
      "logits/rejected": -2.315669059753418,
      "logps/chosen": -119.5354232788086,
      "logps/rejected": -136.07919311523438,
      "loss": 0.0173,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.227510929107666,
      "rewards/margins": 4.430871963500977,
      "rewards/rejected": -1.2033611536026,
      "step": 762
    },
    {
      "epoch": 0.3052,
      "grad_norm": 11.027819633483887,
      "learning_rate": 8.983999999999999e-07,
      "logits/chosen": -2.4695277214050293,
      "logits/rejected": -3.15946364402771,
      "logps/chosen": -126.40845489501953,
      "logps/rejected": -96.06217956542969,
      "loss": 0.2502,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2657066583633423,
      "rewards/margins": 1.5003483295440674,
      "rewards/rejected": -0.2346416562795639,
      "step": 763
    },
    {
      "epoch": 0.3056,
      "grad_norm": 0.4583013653755188,
      "learning_rate": 8.982666666666666e-07,
      "logits/chosen": -2.3427574634552,
      "logits/rejected": -3.0091259479522705,
      "logps/chosen": -202.0019989013672,
      "logps/rejected": -134.4701690673828,
      "loss": 0.0078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8469269275665283,
      "rewards/margins": 4.88568115234375,
      "rewards/rejected": -1.0387539863586426,
      "step": 764
    },
    {
      "epoch": 0.306,
      "grad_norm": 0.9329016208648682,
      "learning_rate": 8.981333333333333e-07,
      "logits/chosen": -2.3483734130859375,
      "logits/rejected": -2.5499143600463867,
      "logps/chosen": -129.04852294921875,
      "logps/rejected": -107.47587585449219,
      "loss": 0.0133,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6254451274871826,
      "rewards/margins": 4.4168219566345215,
      "rewards/rejected": -0.7913768887519836,
      "step": 765
    },
    {
      "epoch": 0.3064,
      "grad_norm": 5.387580394744873,
      "learning_rate": 8.98e-07,
      "logits/chosen": -2.1371099948883057,
      "logits/rejected": -2.618004560470581,
      "logps/chosen": -89.83863830566406,
      "logps/rejected": -117.11740112304688,
      "loss": 0.0818,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9604389667510986,
      "rewards/margins": 3.0887691974639893,
      "rewards/rejected": -1.1283302307128906,
      "step": 766
    },
    {
      "epoch": 0.3068,
      "grad_norm": 10.762910842895508,
      "learning_rate": 8.978666666666667e-07,
      "logits/chosen": -2.439697265625,
      "logits/rejected": -2.6753106117248535,
      "logps/chosen": -141.6194610595703,
      "logps/rejected": -130.701171875,
      "loss": 0.1846,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8703937530517578,
      "rewards/margins": 1.616841197013855,
      "rewards/rejected": -0.7464473843574524,
      "step": 767
    },
    {
      "epoch": 0.3072,
      "grad_norm": 1.070212483406067,
      "learning_rate": 8.977333333333333e-07,
      "logits/chosen": -2.2248432636260986,
      "logits/rejected": -1.6553691625595093,
      "logps/chosen": -90.31580352783203,
      "logps/rejected": -87.07117462158203,
      "loss": 0.0185,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.203350067138672,
      "rewards/margins": 4.124791145324707,
      "rewards/rejected": -0.9214408993721008,
      "step": 768
    },
    {
      "epoch": 0.3076,
      "grad_norm": 1.4016839265823364,
      "learning_rate": 8.975999999999999e-07,
      "logits/chosen": -2.176999092102051,
      "logits/rejected": -2.0974903106689453,
      "logps/chosen": -170.3798828125,
      "logps/rejected": -103.99959564208984,
      "loss": 0.021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.997016191482544,
      "rewards/margins": 3.857581377029419,
      "rewards/rejected": -0.860565185546875,
      "step": 769
    },
    {
      "epoch": 0.308,
      "grad_norm": 0.8604116439819336,
      "learning_rate": 8.974666666666666e-07,
      "logits/chosen": -2.202345132827759,
      "logits/rejected": -3.255316972732544,
      "logps/chosen": -107.87577819824219,
      "logps/rejected": -111.58007049560547,
      "loss": 0.0148,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6552929878234863,
      "rewards/margins": 4.302216053009033,
      "rewards/rejected": -0.6469230651855469,
      "step": 770
    },
    {
      "epoch": 0.3084,
      "grad_norm": 2.8755245208740234,
      "learning_rate": 8.973333333333333e-07,
      "logits/chosen": -1.8289899826049805,
      "logits/rejected": -2.795013666152954,
      "logps/chosen": -65.3798828125,
      "logps/rejected": -97.68152618408203,
      "loss": 0.0531,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.417426109313965,
      "rewards/margins": 3.058537721633911,
      "rewards/rejected": -0.6411117315292358,
      "step": 771
    },
    {
      "epoch": 0.3088,
      "grad_norm": 2.150043487548828,
      "learning_rate": 8.972e-07,
      "logits/chosen": -2.218122720718384,
      "logits/rejected": -2.407042980194092,
      "logps/chosen": -115.09114074707031,
      "logps/rejected": -121.50028991699219,
      "loss": 0.027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9148495197296143,
      "rewards/margins": 3.962176561355591,
      "rewards/rejected": -1.0473270416259766,
      "step": 772
    },
    {
      "epoch": 0.3092,
      "grad_norm": 3.774305820465088,
      "learning_rate": 8.970666666666667e-07,
      "logits/chosen": -2.073270320892334,
      "logits/rejected": -2.754878044128418,
      "logps/chosen": -86.31742858886719,
      "logps/rejected": -92.88706970214844,
      "loss": 0.0531,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.517519950866699,
      "rewards/margins": 3.285672664642334,
      "rewards/rejected": -0.7681525945663452,
      "step": 773
    },
    {
      "epoch": 0.3096,
      "grad_norm": 8.24389934539795,
      "learning_rate": 8.969333333333333e-07,
      "logits/chosen": -3.1189517974853516,
      "logits/rejected": -2.76361346244812,
      "logps/chosen": -139.96913146972656,
      "logps/rejected": -97.73430633544922,
      "loss": 0.1385,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.086879014968872,
      "rewards/margins": 1.9081478118896484,
      "rewards/rejected": 0.17873115837574005,
      "step": 774
    },
    {
      "epoch": 0.31,
      "grad_norm": 3.3499388694763184,
      "learning_rate": 8.968e-07,
      "logits/chosen": -2.198568820953369,
      "logits/rejected": -2.3885207176208496,
      "logps/chosen": -134.81153869628906,
      "logps/rejected": -122.0280990600586,
      "loss": 0.0497,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4380111694335938,
      "rewards/margins": 3.662269115447998,
      "rewards/rejected": -1.2242580652236938,
      "step": 775
    },
    {
      "epoch": 0.3104,
      "grad_norm": 1.8148291110992432,
      "learning_rate": 8.966666666666666e-07,
      "logits/chosen": -2.5462183952331543,
      "logits/rejected": -2.2380454540252686,
      "logps/chosen": -106.682861328125,
      "logps/rejected": -90.800537109375,
      "loss": 0.0227,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.242611885070801,
      "rewards/margins": 3.9034171104431152,
      "rewards/rejected": -0.6608055233955383,
      "step": 776
    },
    {
      "epoch": 0.3108,
      "grad_norm": 0.8915332555770874,
      "learning_rate": 8.965333333333332e-07,
      "logits/chosen": -2.276937484741211,
      "logits/rejected": -3.0411739349365234,
      "logps/chosen": -118.32014465332031,
      "logps/rejected": -139.54940795898438,
      "loss": 0.0131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.858062744140625,
      "rewards/margins": 4.539011001586914,
      "rewards/rejected": -1.6809478998184204,
      "step": 777
    },
    {
      "epoch": 0.3112,
      "grad_norm": 1.623048186302185,
      "learning_rate": 8.963999999999999e-07,
      "logits/chosen": -2.8049283027648926,
      "logits/rejected": -2.565147876739502,
      "logps/chosen": -128.2263641357422,
      "logps/rejected": -107.15559387207031,
      "loss": 0.0293,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5063843727111816,
      "rewards/margins": 3.559460163116455,
      "rewards/rejected": -1.0530757904052734,
      "step": 778
    },
    {
      "epoch": 0.3116,
      "grad_norm": 3.6667633056640625,
      "learning_rate": 8.962666666666666e-07,
      "logits/chosen": -2.460651397705078,
      "logits/rejected": -2.5908432006835938,
      "logps/chosen": -141.62916564941406,
      "logps/rejected": -103.74864196777344,
      "loss": 0.0498,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.588855266571045,
      "rewards/margins": 3.5969715118408203,
      "rewards/rejected": -1.0081161260604858,
      "step": 779
    },
    {
      "epoch": 0.312,
      "grad_norm": 1.384175419807434,
      "learning_rate": 8.961333333333333e-07,
      "logits/chosen": -2.065964937210083,
      "logits/rejected": -1.51295804977417,
      "logps/chosen": -96.91458892822266,
      "logps/rejected": -76.26074981689453,
      "loss": 0.0235,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.119208812713623,
      "rewards/margins": 3.7521233558654785,
      "rewards/rejected": -0.6329145431518555,
      "step": 780
    },
    {
      "epoch": 0.3124,
      "grad_norm": 1.203910231590271,
      "learning_rate": 8.96e-07,
      "logits/chosen": -2.130234718322754,
      "logits/rejected": -2.0894761085510254,
      "logps/chosen": -139.58204650878906,
      "logps/rejected": -103.94606018066406,
      "loss": 0.0214,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6158699989318848,
      "rewards/margins": 3.8671603202819824,
      "rewards/rejected": -1.2512900829315186,
      "step": 781
    },
    {
      "epoch": 0.3128,
      "grad_norm": 2.0236785411834717,
      "learning_rate": 8.958666666666667e-07,
      "logits/chosen": -2.056626319885254,
      "logits/rejected": -2.7698557376861572,
      "logps/chosen": -103.11468505859375,
      "logps/rejected": -115.16119384765625,
      "loss": 0.0248,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4660725593566895,
      "rewards/margins": 4.056765556335449,
      "rewards/rejected": -0.590692937374115,
      "step": 782
    },
    {
      "epoch": 0.3132,
      "grad_norm": 20.951173782348633,
      "learning_rate": 8.957333333333334e-07,
      "logits/chosen": -1.7704534530639648,
      "logits/rejected": -2.2317891120910645,
      "logps/chosen": -119.42454528808594,
      "logps/rejected": -89.52031707763672,
      "loss": 0.312,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5218902230262756,
      "rewards/margins": 1.1800575256347656,
      "rewards/rejected": -0.6581672430038452,
      "step": 783
    },
    {
      "epoch": 0.3136,
      "grad_norm": 1.266780138015747,
      "learning_rate": 8.955999999999999e-07,
      "logits/chosen": -2.569981575012207,
      "logits/rejected": -2.700136661529541,
      "logps/chosen": -155.70164489746094,
      "logps/rejected": -109.40281677246094,
      "loss": 0.0212,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.846662998199463,
      "rewards/margins": 4.092294216156006,
      "rewards/rejected": -1.2456309795379639,
      "step": 784
    },
    {
      "epoch": 0.314,
      "grad_norm": 2.433847665786743,
      "learning_rate": 8.954666666666666e-07,
      "logits/chosen": -2.2616562843322754,
      "logits/rejected": -2.6472089290618896,
      "logps/chosen": -79.11831665039062,
      "logps/rejected": -89.29237365722656,
      "loss": 0.0513,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0189361572265625,
      "rewards/margins": 3.050157070159912,
      "rewards/rejected": -1.0312206745147705,
      "step": 785
    },
    {
      "epoch": 0.3144,
      "grad_norm": 4.962613105773926,
      "learning_rate": 8.953333333333332e-07,
      "logits/chosen": -2.5943944454193115,
      "logits/rejected": -3.4688291549682617,
      "logps/chosen": -112.29634857177734,
      "logps/rejected": -190.42581176757812,
      "loss": 0.0442,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0733489990234375,
      "rewards/margins": 4.203968524932861,
      "rewards/rejected": -2.130619525909424,
      "step": 786
    },
    {
      "epoch": 0.3148,
      "grad_norm": 1.8777269124984741,
      "learning_rate": 8.951999999999999e-07,
      "logits/chosen": -2.358613967895508,
      "logits/rejected": -2.916337251663208,
      "logps/chosen": -176.43719482421875,
      "logps/rejected": -124.7771224975586,
      "loss": 0.0252,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.981060028076172,
      "rewards/margins": 4.02894401550293,
      "rewards/rejected": -1.0478839874267578,
      "step": 787
    },
    {
      "epoch": 0.3152,
      "grad_norm": 1.071423888206482,
      "learning_rate": 8.950666666666666e-07,
      "logits/chosen": -2.3596749305725098,
      "logits/rejected": -2.6312308311462402,
      "logps/chosen": -93.57471466064453,
      "logps/rejected": -197.58154296875,
      "loss": 0.0192,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0071113109588623,
      "rewards/margins": 4.316878318786621,
      "rewards/rejected": -1.3097668886184692,
      "step": 788
    },
    {
      "epoch": 0.3156,
      "grad_norm": 7.989108562469482,
      "learning_rate": 8.949333333333333e-07,
      "logits/chosen": -2.6538925170898438,
      "logits/rejected": -2.903766632080078,
      "logps/chosen": -236.46348571777344,
      "logps/rejected": -120.4380111694336,
      "loss": 0.0954,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.283616542816162,
      "rewards/margins": 3.234147787094116,
      "rewards/rejected": -0.950531005859375,
      "step": 789
    },
    {
      "epoch": 0.316,
      "grad_norm": 3.8513331413269043,
      "learning_rate": 8.948e-07,
      "logits/chosen": -1.8223698139190674,
      "logits/rejected": -2.488344192504883,
      "logps/chosen": -94.1585922241211,
      "logps/rejected": -183.72604370117188,
      "loss": 0.0389,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.116349935531616,
      "rewards/margins": 3.9152450561523438,
      "rewards/rejected": -1.7988953590393066,
      "step": 790
    },
    {
      "epoch": 0.3164,
      "grad_norm": 12.640743255615234,
      "learning_rate": 8.946666666666667e-07,
      "logits/chosen": -2.1420345306396484,
      "logits/rejected": -2.28462553024292,
      "logps/chosen": -98.6251220703125,
      "logps/rejected": -91.61013793945312,
      "loss": 0.2676,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.218601942062378,
      "rewards/margins": 2.6125948429107666,
      "rewards/rejected": -0.3939930200576782,
      "step": 791
    },
    {
      "epoch": 0.3168,
      "grad_norm": 3.378438949584961,
      "learning_rate": 8.945333333333333e-07,
      "logits/chosen": -2.0873618125915527,
      "logits/rejected": -2.5999512672424316,
      "logps/chosen": -150.55142211914062,
      "logps/rejected": -129.91529846191406,
      "loss": 0.0364,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2375876903533936,
      "rewards/margins": 3.7210769653320312,
      "rewards/rejected": -1.4834892749786377,
      "step": 792
    },
    {
      "epoch": 0.3172,
      "grad_norm": 1.0676642656326294,
      "learning_rate": 8.944e-07,
      "logits/chosen": -2.458928108215332,
      "logits/rejected": -3.6109907627105713,
      "logps/chosen": -139.55532836914062,
      "logps/rejected": -106.81173706054688,
      "loss": 0.014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.529690742492676,
      "rewards/margins": 4.481165885925293,
      "rewards/rejected": -0.951475203037262,
      "step": 793
    },
    {
      "epoch": 0.3176,
      "grad_norm": 0.7012012600898743,
      "learning_rate": 8.942666666666667e-07,
      "logits/chosen": -2.299588203430176,
      "logits/rejected": -2.5012714862823486,
      "logps/chosen": -143.48715209960938,
      "logps/rejected": -149.4267578125,
      "loss": 0.0089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.881040573120117,
      "rewards/margins": 4.947179794311523,
      "rewards/rejected": -1.0661388635635376,
      "step": 794
    },
    {
      "epoch": 0.318,
      "grad_norm": 10.060739517211914,
      "learning_rate": 8.941333333333333e-07,
      "logits/chosen": -2.769075393676758,
      "logits/rejected": -2.3331735134124756,
      "logps/chosen": -130.14205932617188,
      "logps/rejected": -82.25627136230469,
      "loss": 0.1433,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6993106603622437,
      "rewards/margins": 2.6302859783172607,
      "rewards/rejected": -0.9309753179550171,
      "step": 795
    },
    {
      "epoch": 0.3184,
      "grad_norm": 2.1081008911132812,
      "learning_rate": 8.939999999999999e-07,
      "logits/chosen": -2.2366456985473633,
      "logits/rejected": -2.1610710620880127,
      "logps/chosen": -146.458740234375,
      "logps/rejected": -114.4478759765625,
      "loss": 0.0394,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0528228282928467,
      "rewards/margins": 3.297722339630127,
      "rewards/rejected": -1.2448993921279907,
      "step": 796
    },
    {
      "epoch": 0.3188,
      "grad_norm": 8.540313720703125,
      "learning_rate": 8.938666666666666e-07,
      "logits/chosen": -1.9949531555175781,
      "logits/rejected": -2.6433615684509277,
      "logps/chosen": -83.91197204589844,
      "logps/rejected": -86.8432388305664,
      "loss": 0.2461,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6137924194335938,
      "rewards/margins": 1.3348416090011597,
      "rewards/rejected": -0.7210491299629211,
      "step": 797
    },
    {
      "epoch": 0.3192,
      "grad_norm": 2.029665470123291,
      "learning_rate": 8.937333333333333e-07,
      "logits/chosen": -2.098334312438965,
      "logits/rejected": -2.5081448554992676,
      "logps/chosen": -97.47026824951172,
      "logps/rejected": -100.45570373535156,
      "loss": 0.0282,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.133910894393921,
      "rewards/margins": 3.616145610809326,
      "rewards/rejected": -0.4822345972061157,
      "step": 798
    },
    {
      "epoch": 0.3196,
      "grad_norm": 4.12944221496582,
      "learning_rate": 8.935999999999999e-07,
      "logits/chosen": -2.204253911972046,
      "logits/rejected": -2.2451868057250977,
      "logps/chosen": -110.4699935913086,
      "logps/rejected": -122.26057434082031,
      "loss": 0.0707,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0360822677612305,
      "rewards/margins": 2.804030179977417,
      "rewards/rejected": -0.767947793006897,
      "step": 799
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6872997879981995,
      "learning_rate": 8.934666666666666e-07,
      "logits/chosen": -2.2026891708374023,
      "logits/rejected": -2.9530887603759766,
      "logps/chosen": -78.65464782714844,
      "logps/rejected": -104.75997924804688,
      "loss": 0.0094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.937812089920044,
      "rewards/margins": 5.1615824699401855,
      "rewards/rejected": -2.2237701416015625,
      "step": 800
    },
    {
      "epoch": 0.3204,
      "grad_norm": 4.517988204956055,
      "learning_rate": 8.933333333333333e-07,
      "logits/chosen": -2.1748127937316895,
      "logits/rejected": -3.047051429748535,
      "logps/chosen": -100.82695007324219,
      "logps/rejected": -106.10684204101562,
      "loss": 0.0519,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.05753755569458,
      "rewards/margins": 3.6844162940979004,
      "rewards/rejected": -0.6268787384033203,
      "step": 801
    },
    {
      "epoch": 0.3208,
      "grad_norm": 10.753323554992676,
      "learning_rate": 8.932e-07,
      "logits/chosen": -1.9807549715042114,
      "logits/rejected": -1.685462474822998,
      "logps/chosen": -85.24569702148438,
      "logps/rejected": -70.3848876953125,
      "loss": 0.1726,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1963610649108887,
      "rewards/margins": 2.0079143047332764,
      "rewards/rejected": 0.18844681978225708,
      "step": 802
    },
    {
      "epoch": 0.3212,
      "grad_norm": 0.425980806350708,
      "learning_rate": 8.930666666666667e-07,
      "logits/chosen": -2.3401477336883545,
      "logits/rejected": -2.9292545318603516,
      "logps/chosen": -114.03564453125,
      "logps/rejected": -105.29086303710938,
      "loss": 0.0078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.905242443084717,
      "rewards/margins": 4.912909507751465,
      "rewards/rejected": -1.0076671838760376,
      "step": 803
    },
    {
      "epoch": 0.3216,
      "grad_norm": 2.3754000663757324,
      "learning_rate": 8.929333333333334e-07,
      "logits/chosen": -2.4478492736816406,
      "logits/rejected": -2.3317112922668457,
      "logps/chosen": -166.0182647705078,
      "logps/rejected": -107.93126678466797,
      "loss": 0.0375,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6887569427490234,
      "rewards/margins": 3.548722505569458,
      "rewards/rejected": -0.8599655628204346,
      "step": 804
    },
    {
      "epoch": 0.322,
      "grad_norm": 2.870220422744751,
      "learning_rate": 8.928e-07,
      "logits/chosen": -2.0157785415649414,
      "logits/rejected": -1.6724956035614014,
      "logps/chosen": -96.07544708251953,
      "logps/rejected": -90.28720092773438,
      "loss": 0.0507,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5981345176696777,
      "rewards/margins": 3.182237148284912,
      "rewards/rejected": -0.5841026306152344,
      "step": 805
    },
    {
      "epoch": 0.3224,
      "grad_norm": 0.5676467418670654,
      "learning_rate": 8.926666666666666e-07,
      "logits/chosen": -2.1507906913757324,
      "logits/rejected": -2.703646659851074,
      "logps/chosen": -146.82691955566406,
      "logps/rejected": -121.77112579345703,
      "loss": 0.0083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4247565269470215,
      "rewards/margins": 4.801511764526367,
      "rewards/rejected": -1.3767552375793457,
      "step": 806
    },
    {
      "epoch": 0.3228,
      "grad_norm": 2.4314332008361816,
      "learning_rate": 8.925333333333332e-07,
      "logits/chosen": -2.047804355621338,
      "logits/rejected": -2.6963014602661133,
      "logps/chosen": -159.6792449951172,
      "logps/rejected": -111.93836975097656,
      "loss": 0.052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5022635459899902,
      "rewards/margins": 3.05499267578125,
      "rewards/rejected": -0.552729070186615,
      "step": 807
    },
    {
      "epoch": 0.3232,
      "grad_norm": 2.6704609394073486,
      "learning_rate": 8.923999999999999e-07,
      "logits/chosen": -1.9387717247009277,
      "logits/rejected": -1.5617411136627197,
      "logps/chosen": -116.40144348144531,
      "logps/rejected": -77.0108413696289,
      "loss": 0.0495,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1731042861938477,
      "rewards/margins": 3.0447678565979004,
      "rewards/rejected": -0.8716638684272766,
      "step": 808
    },
    {
      "epoch": 0.3236,
      "grad_norm": 1.984242558479309,
      "learning_rate": 8.922666666666666e-07,
      "logits/chosen": -2.71366810798645,
      "logits/rejected": -2.4580960273742676,
      "logps/chosen": -191.4305419921875,
      "logps/rejected": -138.6422576904297,
      "loss": 0.0262,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7609100341796875,
      "rewards/margins": 4.047698497772217,
      "rewards/rejected": -1.2867885828018188,
      "step": 809
    },
    {
      "epoch": 0.324,
      "grad_norm": 2.1393535137176514,
      "learning_rate": 8.921333333333333e-07,
      "logits/chosen": -2.0826926231384277,
      "logits/rejected": -3.4439697265625,
      "logps/chosen": -156.74078369140625,
      "logps/rejected": -144.24331665039062,
      "loss": 0.0303,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.783551812171936,
      "rewards/margins": 3.669999122619629,
      "rewards/rejected": -1.8864471912384033,
      "step": 810
    },
    {
      "epoch": 0.3244,
      "grad_norm": 1.1767504215240479,
      "learning_rate": 8.92e-07,
      "logits/chosen": -2.0991053581237793,
      "logits/rejected": -2.4393820762634277,
      "logps/chosen": -66.5164794921875,
      "logps/rejected": -103.59549713134766,
      "loss": 0.0212,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7729767560958862,
      "rewards/margins": 3.866176128387451,
      "rewards/rejected": -2.0931992530822754,
      "step": 811
    },
    {
      "epoch": 0.3248,
      "grad_norm": 0.8609403371810913,
      "learning_rate": 8.918666666666667e-07,
      "logits/chosen": -2.1425528526306152,
      "logits/rejected": -2.564800262451172,
      "logps/chosen": -88.95923614501953,
      "logps/rejected": -110.54081726074219,
      "loss": 0.0149,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.158205509185791,
      "rewards/margins": 4.327341079711914,
      "rewards/rejected": -1.1691356897354126,
      "step": 812
    },
    {
      "epoch": 0.3252,
      "grad_norm": 0.17998626828193665,
      "learning_rate": 8.917333333333334e-07,
      "logits/chosen": -2.2806015014648438,
      "logits/rejected": -2.391666889190674,
      "logps/chosen": -155.27577209472656,
      "logps/rejected": -137.16473388671875,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.114643573760986,
      "rewards/margins": 5.883709907531738,
      "rewards/rejected": -1.769066333770752,
      "step": 813
    },
    {
      "epoch": 0.3256,
      "grad_norm": 1.3810558319091797,
      "learning_rate": 8.915999999999999e-07,
      "logits/chosen": -2.039872407913208,
      "logits/rejected": -2.997816801071167,
      "logps/chosen": -138.361572265625,
      "logps/rejected": -193.64810180664062,
      "loss": 0.02,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.799039602279663,
      "rewards/margins": 3.9463469982147217,
      "rewards/rejected": -1.1473071575164795,
      "step": 814
    },
    {
      "epoch": 0.326,
      "grad_norm": 5.043862819671631,
      "learning_rate": 8.914666666666665e-07,
      "logits/chosen": -2.081573724746704,
      "logits/rejected": -2.921724796295166,
      "logps/chosen": -77.16655731201172,
      "logps/rejected": -102.86692810058594,
      "loss": 0.0837,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.113478183746338,
      "rewards/margins": 2.5927059650421143,
      "rewards/rejected": 0.5207721590995789,
      "step": 815
    },
    {
      "epoch": 0.3264,
      "grad_norm": 10.377603530883789,
      "learning_rate": 8.913333333333332e-07,
      "logits/chosen": -2.3603315353393555,
      "logits/rejected": -1.795809030532837,
      "logps/chosen": -107.91226196289062,
      "logps/rejected": -96.75129699707031,
      "loss": 0.2008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7955710887908936,
      "rewards/margins": 2.669872999191284,
      "rewards/rejected": -0.8743019104003906,
      "step": 816
    },
    {
      "epoch": 0.3268,
      "grad_norm": 2.2068803310394287,
      "learning_rate": 8.911999999999999e-07,
      "logits/chosen": -2.1881051063537598,
      "logits/rejected": -2.6564688682556152,
      "logps/chosen": -110.70321655273438,
      "logps/rejected": -124.21011352539062,
      "loss": 0.0396,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7030476331710815,
      "rewards/margins": 3.211836814880371,
      "rewards/rejected": -1.5087890625,
      "step": 817
    },
    {
      "epoch": 0.3272,
      "grad_norm": 1.9314175844192505,
      "learning_rate": 8.910666666666666e-07,
      "logits/chosen": -1.9081323146820068,
      "logits/rejected": -2.956308603286743,
      "logps/chosen": -79.89747619628906,
      "logps/rejected": -119.73229217529297,
      "loss": 0.0283,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9281814098358154,
      "rewards/margins": 4.15826416015625,
      "rewards/rejected": -1.2300827503204346,
      "step": 818
    },
    {
      "epoch": 0.3276,
      "grad_norm": 1.9245866537094116,
      "learning_rate": 8.909333333333333e-07,
      "logits/chosen": -2.4317140579223633,
      "logits/rejected": -2.5172290802001953,
      "logps/chosen": -115.2402572631836,
      "logps/rejected": -116.59526824951172,
      "loss": 0.0333,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6638758182525635,
      "rewards/margins": 3.9020066261291504,
      "rewards/rejected": -1.2381305694580078,
      "step": 819
    },
    {
      "epoch": 0.328,
      "grad_norm": 2.114412546157837,
      "learning_rate": 8.908e-07,
      "logits/chosen": -2.1739611625671387,
      "logits/rejected": -2.7165980339050293,
      "logps/chosen": -154.8603973388672,
      "logps/rejected": -127.94245910644531,
      "loss": 0.0368,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.120532274246216,
      "rewards/margins": 3.4652369022369385,
      "rewards/rejected": -1.3447043895721436,
      "step": 820
    },
    {
      "epoch": 0.3284,
      "grad_norm": 0.6676588654518127,
      "learning_rate": 8.906666666666667e-07,
      "logits/chosen": -2.479166030883789,
      "logits/rejected": -2.190455913543701,
      "logps/chosen": -91.43891906738281,
      "logps/rejected": -118.60624694824219,
      "loss": 0.0104,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.728607177734375,
      "rewards/margins": 5.0622711181640625,
      "rewards/rejected": -1.3336635828018188,
      "step": 821
    },
    {
      "epoch": 0.3288,
      "grad_norm": 1.743912696838379,
      "learning_rate": 8.905333333333333e-07,
      "logits/chosen": -2.3176417350769043,
      "logits/rejected": -2.7252461910247803,
      "logps/chosen": -102.71382904052734,
      "logps/rejected": -135.2818603515625,
      "loss": 0.0156,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.954738140106201,
      "rewards/margins": 4.563777923583984,
      "rewards/rejected": -1.609039306640625,
      "step": 822
    },
    {
      "epoch": 0.3292,
      "grad_norm": 0.5026206374168396,
      "learning_rate": 8.904e-07,
      "logits/chosen": -2.2321741580963135,
      "logits/rejected": -3.007467269897461,
      "logps/chosen": -102.57070922851562,
      "logps/rejected": -151.8827667236328,
      "loss": 0.0088,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7847228050231934,
      "rewards/margins": 5.020562171936035,
      "rewards/rejected": -1.2358391284942627,
      "step": 823
    },
    {
      "epoch": 0.3296,
      "grad_norm": 7.122845649719238,
      "learning_rate": 8.902666666666666e-07,
      "logits/chosen": -2.0521397590637207,
      "logits/rejected": -2.343379497528076,
      "logps/chosen": -95.44326782226562,
      "logps/rejected": -126.28777313232422,
      "loss": 0.1639,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1786086559295654,
      "rewards/margins": 1.7263282537460327,
      "rewards/rejected": -0.5477195978164673,
      "step": 824
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.767931580543518,
      "learning_rate": 8.901333333333333e-07,
      "logits/chosen": -2.297421455383301,
      "logits/rejected": -2.191300868988037,
      "logps/chosen": -92.88983154296875,
      "logps/rejected": -86.72848510742188,
      "loss": 0.0311,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7654805183410645,
      "rewards/margins": 3.4777109622955322,
      "rewards/rejected": -0.7122303247451782,
      "step": 825
    },
    {
      "epoch": 0.3304,
      "grad_norm": 2.9281606674194336,
      "learning_rate": 8.9e-07,
      "logits/chosen": -2.389708995819092,
      "logits/rejected": -1.8518917560577393,
      "logps/chosen": -110.49971008300781,
      "logps/rejected": -123.04203033447266,
      "loss": 0.0326,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.015735149383545,
      "rewards/margins": 4.062949180603027,
      "rewards/rejected": -1.0472137928009033,
      "step": 826
    },
    {
      "epoch": 0.3308,
      "grad_norm": 4.613772869110107,
      "learning_rate": 8.898666666666666e-07,
      "logits/chosen": -1.8721821308135986,
      "logits/rejected": -1.835613489151001,
      "logps/chosen": -138.39059448242188,
      "logps/rejected": -83.87528228759766,
      "loss": 0.0556,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.120154857635498,
      "rewards/margins": 3.814680576324463,
      "rewards/rejected": -0.6945257186889648,
      "step": 827
    },
    {
      "epoch": 0.3312,
      "grad_norm": 0.1921926587820053,
      "learning_rate": 8.897333333333333e-07,
      "logits/chosen": -1.9919633865356445,
      "logits/rejected": -3.056222438812256,
      "logps/chosen": -112.30611419677734,
      "logps/rejected": -184.66700744628906,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.285749912261963,
      "rewards/margins": 6.179891586303711,
      "rewards/rejected": -1.894141435623169,
      "step": 828
    },
    {
      "epoch": 0.3316,
      "grad_norm": 7.4077301025390625,
      "learning_rate": 8.895999999999999e-07,
      "logits/chosen": -1.7259577512741089,
      "logits/rejected": -2.2624902725219727,
      "logps/chosen": -67.17411041259766,
      "logps/rejected": -82.67288208007812,
      "loss": 0.1879,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.41274094581604,
      "rewards/margins": 2.1946218013763428,
      "rewards/rejected": 0.21811902523040771,
      "step": 829
    },
    {
      "epoch": 0.332,
      "grad_norm": 0.777452826499939,
      "learning_rate": 8.894666666666666e-07,
      "logits/chosen": -2.6819000244140625,
      "logits/rejected": -2.088336944580078,
      "logps/chosen": -258.20123291015625,
      "logps/rejected": -92.70182037353516,
      "loss": 0.0108,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8780322074890137,
      "rewards/margins": 4.858956336975098,
      "rewards/rejected": -0.9809242486953735,
      "step": 830
    },
    {
      "epoch": 0.3324,
      "grad_norm": 2.2969353199005127,
      "learning_rate": 8.893333333333333e-07,
      "logits/chosen": -2.608407974243164,
      "logits/rejected": -2.937574863433838,
      "logps/chosen": -125.88926696777344,
      "logps/rejected": -121.51696014404297,
      "loss": 0.0356,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.196072816848755,
      "rewards/margins": 3.936098575592041,
      "rewards/rejected": -1.7400257587432861,
      "step": 831
    },
    {
      "epoch": 0.3328,
      "grad_norm": 0.5416452884674072,
      "learning_rate": 8.892e-07,
      "logits/chosen": -2.161639928817749,
      "logits/rejected": -2.0754857063293457,
      "logps/chosen": -91.46189880371094,
      "logps/rejected": -99.40431213378906,
      "loss": 0.0087,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0704402923583984,
      "rewards/margins": 4.74195671081543,
      "rewards/rejected": -1.6715164184570312,
      "step": 832
    },
    {
      "epoch": 0.3332,
      "grad_norm": 3.5193135738372803,
      "learning_rate": 8.890666666666666e-07,
      "logits/chosen": -2.0504817962646484,
      "logits/rejected": -2.567875385284424,
      "logps/chosen": -90.51715087890625,
      "logps/rejected": -198.4585418701172,
      "loss": 0.0671,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7434794902801514,
      "rewards/margins": 4.0074381828308105,
      "rewards/rejected": -1.2639588117599487,
      "step": 833
    },
    {
      "epoch": 0.3336,
      "grad_norm": 0.9003880620002747,
      "learning_rate": 8.889333333333333e-07,
      "logits/chosen": -2.844499349594116,
      "logits/rejected": -1.6914443969726562,
      "logps/chosen": -152.29518127441406,
      "logps/rejected": -97.06120300292969,
      "loss": 0.0129,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6283202171325684,
      "rewards/margins": 4.346653461456299,
      "rewards/rejected": -0.7183330655097961,
      "step": 834
    },
    {
      "epoch": 0.334,
      "grad_norm": 1.3981313705444336,
      "learning_rate": 8.888e-07,
      "logits/chosen": -2.3355138301849365,
      "logits/rejected": -1.6559686660766602,
      "logps/chosen": -116.99127197265625,
      "logps/rejected": -112.30949401855469,
      "loss": 0.0255,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5547935962677,
      "rewards/margins": 3.947514057159424,
      "rewards/rejected": -0.39272040128707886,
      "step": 835
    },
    {
      "epoch": 0.3344,
      "grad_norm": 0.19672891497612,
      "learning_rate": 8.886666666666667e-07,
      "logits/chosen": -2.2957611083984375,
      "logits/rejected": -2.6988086700439453,
      "logps/chosen": -105.29034423828125,
      "logps/rejected": -136.52325439453125,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.894942283630371,
      "rewards/margins": 5.8761186599731445,
      "rewards/rejected": -1.9811763763427734,
      "step": 836
    },
    {
      "epoch": 0.3348,
      "grad_norm": 0.2789686620235443,
      "learning_rate": 8.885333333333332e-07,
      "logits/chosen": -2.1932945251464844,
      "logits/rejected": -2.9832167625427246,
      "logps/chosen": -115.87138366699219,
      "logps/rejected": -155.90640258789062,
      "loss": 0.0045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.78201961517334,
      "rewards/margins": 5.462213516235352,
      "rewards/rejected": -1.6801934242248535,
      "step": 837
    },
    {
      "epoch": 0.3352,
      "grad_norm": 0.758003294467926,
      "learning_rate": 8.883999999999999e-07,
      "logits/chosen": -2.460911273956299,
      "logits/rejected": -2.8378679752349854,
      "logps/chosen": -146.67007446289062,
      "logps/rejected": -98.50162506103516,
      "loss": 0.0109,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9335973262786865,
      "rewards/margins": 5.048765659332275,
      "rewards/rejected": -1.1151683330535889,
      "step": 838
    },
    {
      "epoch": 0.3356,
      "grad_norm": 5.777073383331299,
      "learning_rate": 8.882666666666666e-07,
      "logits/chosen": -2.398968458175659,
      "logits/rejected": -2.4592530727386475,
      "logps/chosen": -140.13465881347656,
      "logps/rejected": -79.05241394042969,
      "loss": 0.0958,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7077522277832031,
      "rewards/margins": 2.656909942626953,
      "rewards/rejected": -0.94915771484375,
      "step": 839
    },
    {
      "epoch": 0.336,
      "grad_norm": 1.5385912656784058,
      "learning_rate": 8.881333333333333e-07,
      "logits/chosen": -2.099606513977051,
      "logits/rejected": -2.755464553833008,
      "logps/chosen": -92.36392974853516,
      "logps/rejected": -104.26797485351562,
      "loss": 0.0224,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6163077354431152,
      "rewards/margins": 4.22487735748291,
      "rewards/rejected": -1.6085693836212158,
      "step": 840
    },
    {
      "epoch": 0.3364,
      "grad_norm": 2.392536163330078,
      "learning_rate": 8.88e-07,
      "logits/chosen": -2.231024742126465,
      "logits/rejected": -2.629868984222412,
      "logps/chosen": -97.71873474121094,
      "logps/rejected": -98.83311462402344,
      "loss": 0.0314,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5947964191436768,
      "rewards/margins": 3.8803014755249023,
      "rewards/rejected": -1.285504937171936,
      "step": 841
    },
    {
      "epoch": 0.3368,
      "grad_norm": 0.7736183404922485,
      "learning_rate": 8.878666666666667e-07,
      "logits/chosen": -2.7321863174438477,
      "logits/rejected": -2.6007957458496094,
      "logps/chosen": -149.83737182617188,
      "logps/rejected": -109.81175994873047,
      "loss": 0.0116,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4639945030212402,
      "rewards/margins": 4.895782470703125,
      "rewards/rejected": -1.4317874908447266,
      "step": 842
    },
    {
      "epoch": 0.3372,
      "grad_norm": 5.095176696777344,
      "learning_rate": 8.877333333333333e-07,
      "logits/chosen": -2.419353485107422,
      "logits/rejected": -3.0176682472229004,
      "logps/chosen": -106.70379638671875,
      "logps/rejected": -109.1944351196289,
      "loss": 0.0684,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8280510902404785,
      "rewards/margins": 3.8860321044921875,
      "rewards/rejected": -1.0579811334609985,
      "step": 843
    },
    {
      "epoch": 0.3376,
      "grad_norm": 15.218343734741211,
      "learning_rate": 8.875999999999999e-07,
      "logits/chosen": -1.7683169841766357,
      "logits/rejected": -2.3318309783935547,
      "logps/chosen": -78.357421875,
      "logps/rejected": -81.43385314941406,
      "loss": 0.191,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4673607349395752,
      "rewards/margins": 2.2970967292785645,
      "rewards/rejected": -0.8297359943389893,
      "step": 844
    },
    {
      "epoch": 0.338,
      "grad_norm": 0.5556968450546265,
      "learning_rate": 8.874666666666666e-07,
      "logits/chosen": -2.421030044555664,
      "logits/rejected": -2.857093334197998,
      "logps/chosen": -95.26863861083984,
      "logps/rejected": -120.22237396240234,
      "loss": 0.0091,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4985504150390625,
      "rewards/margins": 4.9412078857421875,
      "rewards/rejected": -1.442657470703125,
      "step": 845
    },
    {
      "epoch": 0.3384,
      "grad_norm": 3.8007121086120605,
      "learning_rate": 8.873333333333333e-07,
      "logits/chosen": -2.279721736907959,
      "logits/rejected": -2.4521090984344482,
      "logps/chosen": -84.45494079589844,
      "logps/rejected": -99.33006286621094,
      "loss": 0.0713,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6922597885131836,
      "rewards/margins": 2.9255785942077637,
      "rewards/rejected": -0.23331871628761292,
      "step": 846
    },
    {
      "epoch": 0.3388,
      "grad_norm": 4.216347694396973,
      "learning_rate": 8.872e-07,
      "logits/chosen": -2.06081485748291,
      "logits/rejected": -2.3576340675354004,
      "logps/chosen": -137.59048461914062,
      "logps/rejected": -100.10685729980469,
      "loss": 0.0611,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6669321060180664,
      "rewards/margins": 4.107517242431641,
      "rewards/rejected": -1.4405851364135742,
      "step": 847
    },
    {
      "epoch": 0.3392,
      "grad_norm": 2.992288112640381,
      "learning_rate": 8.870666666666666e-07,
      "logits/chosen": -2.534557580947876,
      "logits/rejected": -2.9391322135925293,
      "logps/chosen": -178.37405395507812,
      "logps/rejected": -145.50559997558594,
      "loss": 0.0486,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9140288829803467,
      "rewards/margins": 3.0201351642608643,
      "rewards/rejected": -1.1061062812805176,
      "step": 848
    },
    {
      "epoch": 0.3396,
      "grad_norm": 3.561558723449707,
      "learning_rate": 8.869333333333333e-07,
      "logits/chosen": -1.9580166339874268,
      "logits/rejected": -1.9905898571014404,
      "logps/chosen": -70.35733032226562,
      "logps/rejected": -89.26181030273438,
      "loss": 0.0533,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6955070495605469,
      "rewards/margins": 2.9564085006713867,
      "rewards/rejected": -1.2609012126922607,
      "step": 849
    },
    {
      "epoch": 0.34,
      "grad_norm": 25.44463539123535,
      "learning_rate": 8.868e-07,
      "logits/chosen": -2.145777702331543,
      "logits/rejected": -2.222597599029541,
      "logps/chosen": -83.45771789550781,
      "logps/rejected": -79.42788696289062,
      "loss": 0.5061,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 1.341888666152954,
      "rewards/margins": 1.493883728981018,
      "rewards/rejected": -0.15199506282806396,
      "step": 850
    },
    {
      "epoch": 0.3404,
      "grad_norm": 6.083514213562012,
      "learning_rate": 8.866666666666667e-07,
      "logits/chosen": -2.7904624938964844,
      "logits/rejected": -3.2834229469299316,
      "logps/chosen": -178.4914093017578,
      "logps/rejected": -133.19308471679688,
      "loss": 0.0599,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.442652702331543,
      "rewards/margins": 3.417977809906006,
      "rewards/rejected": -0.9753250479698181,
      "step": 851
    },
    {
      "epoch": 0.3408,
      "grad_norm": 0.512304425239563,
      "learning_rate": 8.865333333333332e-07,
      "logits/chosen": -2.5440168380737305,
      "logits/rejected": -2.985495090484619,
      "logps/chosen": -198.25991821289062,
      "logps/rejected": -153.76438903808594,
      "loss": 0.0057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.046684265136719,
      "rewards/margins": 5.231103897094727,
      "rewards/rejected": -1.1844192743301392,
      "step": 852
    },
    {
      "epoch": 0.3412,
      "grad_norm": 1.3507477045059204,
      "learning_rate": 8.863999999999999e-07,
      "logits/chosen": -2.1753828525543213,
      "logits/rejected": -2.5000786781311035,
      "logps/chosen": -115.08191680908203,
      "logps/rejected": -107.48090362548828,
      "loss": 0.0207,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1361169815063477,
      "rewards/margins": 3.866753101348877,
      "rewards/rejected": -0.7306362390518188,
      "step": 853
    },
    {
      "epoch": 0.3416,
      "grad_norm": 1.4234484434127808,
      "learning_rate": 8.862666666666666e-07,
      "logits/chosen": -2.3079004287719727,
      "logits/rejected": -2.765338897705078,
      "logps/chosen": -75.39707946777344,
      "logps/rejected": -91.97970581054688,
      "loss": 0.0237,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5789990425109863,
      "rewards/margins": 3.7809276580810547,
      "rewards/rejected": -1.201928734779358,
      "step": 854
    },
    {
      "epoch": 0.342,
      "grad_norm": 0.7049193382263184,
      "learning_rate": 8.861333333333333e-07,
      "logits/chosen": -2.3416748046875,
      "logits/rejected": -2.3254454135894775,
      "logps/chosen": -91.78579711914062,
      "logps/rejected": -114.45436096191406,
      "loss": 0.0094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7633891105651855,
      "rewards/margins": 4.9308061599731445,
      "rewards/rejected": -1.1674175262451172,
      "step": 855
    },
    {
      "epoch": 0.3424,
      "grad_norm": 1.103904366493225,
      "learning_rate": 8.86e-07,
      "logits/chosen": -2.199080467224121,
      "logits/rejected": -3.053528070449829,
      "logps/chosen": -115.43734741210938,
      "logps/rejected": -120.31016540527344,
      "loss": 0.0124,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6580474376678467,
      "rewards/margins": 5.062779426574707,
      "rewards/rejected": -1.40473210811615,
      "step": 856
    },
    {
      "epoch": 0.3428,
      "grad_norm": 0.6364588141441345,
      "learning_rate": 8.858666666666667e-07,
      "logits/chosen": -2.168372392654419,
      "logits/rejected": -2.669931411743164,
      "logps/chosen": -97.4451904296875,
      "logps/rejected": -128.6907196044922,
      "loss": 0.0114,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.118623733520508,
      "rewards/margins": 4.469459533691406,
      "rewards/rejected": -1.3508358001708984,
      "step": 857
    },
    {
      "epoch": 0.3432,
      "grad_norm": 1.2302404642105103,
      "learning_rate": 8.857333333333334e-07,
      "logits/chosen": -2.4763612747192383,
      "logits/rejected": -3.116987466812134,
      "logps/chosen": -200.47735595703125,
      "logps/rejected": -159.33071899414062,
      "loss": 0.0131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8222808837890625,
      "rewards/margins": 4.406981468200684,
      "rewards/rejected": -1.584700345993042,
      "step": 858
    },
    {
      "epoch": 0.3436,
      "grad_norm": 0.5875187516212463,
      "learning_rate": 8.856e-07,
      "logits/chosen": -2.184408187866211,
      "logits/rejected": -3.2400293350219727,
      "logps/chosen": -163.20770263671875,
      "logps/rejected": -106.66328430175781,
      "loss": 0.0084,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.3241801261901855,
      "rewards/margins": 4.782444953918457,
      "rewards/rejected": -0.4582653343677521,
      "step": 859
    },
    {
      "epoch": 0.344,
      "grad_norm": 2.824472188949585,
      "learning_rate": 8.854666666666666e-07,
      "logits/chosen": -2.4408607482910156,
      "logits/rejected": -2.0185317993164062,
      "logps/chosen": -114.72798919677734,
      "logps/rejected": -100.51312255859375,
      "loss": 0.0455,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8285317420959473,
      "rewards/margins": 3.1632137298583984,
      "rewards/rejected": -0.3346821069717407,
      "step": 860
    },
    {
      "epoch": 0.3444,
      "grad_norm": 1.6561843156814575,
      "learning_rate": 8.853333333333332e-07,
      "logits/chosen": -2.395325183868408,
      "logits/rejected": -2.9110279083251953,
      "logps/chosen": -98.91046142578125,
      "logps/rejected": -151.85385131835938,
      "loss": 0.0216,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.137296676635742,
      "rewards/margins": 4.072588920593262,
      "rewards/rejected": -0.93529212474823,
      "step": 861
    },
    {
      "epoch": 0.3448,
      "grad_norm": 0.9106718897819519,
      "learning_rate": 8.851999999999999e-07,
      "logits/chosen": -1.9229803085327148,
      "logits/rejected": -2.958369016647339,
      "logps/chosen": -70.09628295898438,
      "logps/rejected": -103.88026428222656,
      "loss": 0.0153,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3935041427612305,
      "rewards/margins": 4.503819942474365,
      "rewards/rejected": -1.1103157997131348,
      "step": 862
    },
    {
      "epoch": 0.3452,
      "grad_norm": 4.759724140167236,
      "learning_rate": 8.850666666666666e-07,
      "logits/chosen": -2.7100749015808105,
      "logits/rejected": -3.065910577774048,
      "logps/chosen": -171.2465362548828,
      "logps/rejected": -125.11653137207031,
      "loss": 0.0674,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9960968494415283,
      "rewards/margins": 3.529022216796875,
      "rewards/rejected": -1.5329253673553467,
      "step": 863
    },
    {
      "epoch": 0.3456,
      "grad_norm": 1.1635247468948364,
      "learning_rate": 8.849333333333333e-07,
      "logits/chosen": -2.166440010070801,
      "logits/rejected": -2.65462589263916,
      "logps/chosen": -145.34927368164062,
      "logps/rejected": -170.6249237060547,
      "loss": 0.0126,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0361413955688477,
      "rewards/margins": 5.086309432983398,
      "rewards/rejected": -2.0501677989959717,
      "step": 864
    },
    {
      "epoch": 0.346,
      "grad_norm": 0.42896825075149536,
      "learning_rate": 8.848e-07,
      "logits/chosen": -1.864673376083374,
      "logits/rejected": -2.519920825958252,
      "logps/chosen": -67.66694641113281,
      "logps/rejected": -97.79374694824219,
      "loss": 0.0069,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3970131874084473,
      "rewards/margins": 5.001409530639648,
      "rewards/rejected": -1.604396104812622,
      "step": 865
    },
    {
      "epoch": 0.3464,
      "grad_norm": 0.5232754349708557,
      "learning_rate": 8.846666666666667e-07,
      "logits/chosen": -2.185178518295288,
      "logits/rejected": -2.6338019371032715,
      "logps/chosen": -79.63853454589844,
      "logps/rejected": -115.90737915039062,
      "loss": 0.0072,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.479515552520752,
      "rewards/margins": 4.976128578186035,
      "rewards/rejected": -1.4966129064559937,
      "step": 866
    },
    {
      "epoch": 0.3468,
      "grad_norm": 0.8470064401626587,
      "learning_rate": 8.845333333333333e-07,
      "logits/chosen": -2.102217435836792,
      "logits/rejected": -1.9876564741134644,
      "logps/chosen": -94.93409729003906,
      "logps/rejected": -104.16300964355469,
      "loss": 0.012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3304104804992676,
      "rewards/margins": 4.418717384338379,
      "rewards/rejected": -2.0883071422576904,
      "step": 867
    },
    {
      "epoch": 0.3472,
      "grad_norm": 0.9724330306053162,
      "learning_rate": 8.844e-07,
      "logits/chosen": -2.2165794372558594,
      "logits/rejected": -2.4058902263641357,
      "logps/chosen": -113.5841064453125,
      "logps/rejected": -163.91018676757812,
      "loss": 0.0141,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.538698196411133,
      "rewards/margins": 4.932177543640137,
      "rewards/rejected": -1.393479585647583,
      "step": 868
    },
    {
      "epoch": 0.3476,
      "grad_norm": 6.082474231719971,
      "learning_rate": 8.842666666666666e-07,
      "logits/chosen": -1.4908487796783447,
      "logits/rejected": -2.3796963691711426,
      "logps/chosen": -116.43740844726562,
      "logps/rejected": -134.56393432617188,
      "loss": 0.0852,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4052035808563232,
      "rewards/margins": 3.6421597003936768,
      "rewards/rejected": -1.236956000328064,
      "step": 869
    },
    {
      "epoch": 0.348,
      "grad_norm": 1.1151636838912964,
      "learning_rate": 8.841333333333333e-07,
      "logits/chosen": -2.3375914096832275,
      "logits/rejected": -3.4069390296936035,
      "logps/chosen": -153.53387451171875,
      "logps/rejected": -165.39486694335938,
      "loss": 0.0181,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7180085182189941,
      "rewards/margins": 4.10216760635376,
      "rewards/rejected": -2.3841590881347656,
      "step": 870
    },
    {
      "epoch": 0.3484,
      "grad_norm": 0.49653905630111694,
      "learning_rate": 8.839999999999999e-07,
      "logits/chosen": -2.2950596809387207,
      "logits/rejected": -2.5230369567871094,
      "logps/chosen": -144.53262329101562,
      "logps/rejected": -121.90235900878906,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8074307441711426,
      "rewards/margins": 5.06284236907959,
      "rewards/rejected": -1.2554118633270264,
      "step": 871
    },
    {
      "epoch": 0.3488,
      "grad_norm": 0.51955646276474,
      "learning_rate": 8.838666666666666e-07,
      "logits/chosen": -2.41019344329834,
      "logits/rejected": -2.5512771606445312,
      "logps/chosen": -94.357421875,
      "logps/rejected": -98.88490295410156,
      "loss": 0.0099,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0930988788604736,
      "rewards/margins": 4.6302900314331055,
      "rewards/rejected": -1.537191390991211,
      "step": 872
    },
    {
      "epoch": 0.3492,
      "grad_norm": 2.2918264865875244,
      "learning_rate": 8.837333333333333e-07,
      "logits/chosen": -2.2886595726013184,
      "logits/rejected": -2.9691193103790283,
      "logps/chosen": -104.18736267089844,
      "logps/rejected": -110.66567993164062,
      "loss": 0.0369,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7842319011688232,
      "rewards/margins": 3.8768482208251953,
      "rewards/rejected": -1.092616319656372,
      "step": 873
    },
    {
      "epoch": 0.3496,
      "grad_norm": 7.432302474975586,
      "learning_rate": 8.836e-07,
      "logits/chosen": -2.050313949584961,
      "logits/rejected": -2.7624666690826416,
      "logps/chosen": -94.78654479980469,
      "logps/rejected": -128.82118225097656,
      "loss": 0.1098,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2826194763183594,
      "rewards/margins": 2.4228851795196533,
      "rewards/rejected": -1.1402655839920044,
      "step": 874
    },
    {
      "epoch": 0.35,
      "grad_norm": 12.013673782348633,
      "learning_rate": 8.834666666666666e-07,
      "logits/chosen": -2.6092376708984375,
      "logits/rejected": -3.005934238433838,
      "logps/chosen": -153.82943725585938,
      "logps/rejected": -147.46041870117188,
      "loss": 0.1994,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0723838806152344,
      "rewards/margins": 3.132290840148926,
      "rewards/rejected": -1.0599068403244019,
      "step": 875
    },
    {
      "epoch": 0.3504,
      "grad_norm": 1.3279967308044434,
      "learning_rate": 8.833333333333333e-07,
      "logits/chosen": -2.309670925140381,
      "logits/rejected": -2.554323196411133,
      "logps/chosen": -85.7931900024414,
      "logps/rejected": -78.12262725830078,
      "loss": 0.0215,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.069638729095459,
      "rewards/margins": 3.8883776664733887,
      "rewards/rejected": -0.8187389373779297,
      "step": 876
    },
    {
      "epoch": 0.3508,
      "grad_norm": 0.9132638573646545,
      "learning_rate": 8.832e-07,
      "logits/chosen": -2.035719871520996,
      "logits/rejected": -2.867403030395508,
      "logps/chosen": -66.60893249511719,
      "logps/rejected": -124.575439453125,
      "loss": 0.013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.647702932357788,
      "rewards/margins": 4.345724105834961,
      "rewards/rejected": -1.6980209350585938,
      "step": 877
    },
    {
      "epoch": 0.3512,
      "grad_norm": 0.6568717956542969,
      "learning_rate": 8.830666666666667e-07,
      "logits/chosen": -2.156785011291504,
      "logits/rejected": -1.8389700651168823,
      "logps/chosen": -90.63113403320312,
      "logps/rejected": -87.6791000366211,
      "loss": 0.0114,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3012959957122803,
      "rewards/margins": 4.55023193359375,
      "rewards/rejected": -1.2489360570907593,
      "step": 878
    },
    {
      "epoch": 0.3516,
      "grad_norm": 0.2165733128786087,
      "learning_rate": 8.829333333333334e-07,
      "logits/chosen": -2.1443028450012207,
      "logits/rejected": -2.7998714447021484,
      "logps/chosen": -152.88970947265625,
      "logps/rejected": -167.30859375,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.198339462280273,
      "rewards/margins": 6.048340797424316,
      "rewards/rejected": -1.850001573562622,
      "step": 879
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.36015331745147705,
      "learning_rate": 8.827999999999999e-07,
      "logits/chosen": -2.619823932647705,
      "logits/rejected": -2.6963953971862793,
      "logps/chosen": -188.76248168945312,
      "logps/rejected": -176.10357666015625,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.515622138977051,
      "rewards/margins": 5.781351089477539,
      "rewards/rejected": -2.2657291889190674,
      "step": 880
    },
    {
      "epoch": 0.3524,
      "grad_norm": 15.39952278137207,
      "learning_rate": 8.826666666666666e-07,
      "logits/chosen": -2.2639145851135254,
      "logits/rejected": -2.365785837173462,
      "logps/chosen": -147.4745330810547,
      "logps/rejected": -100.21082305908203,
      "loss": 0.2756,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.398685485124588,
      "rewards/margins": 1.1621837615966797,
      "rewards/rejected": -0.7634983062744141,
      "step": 881
    },
    {
      "epoch": 0.3528,
      "grad_norm": 0.8220419883728027,
      "learning_rate": 8.825333333333332e-07,
      "logits/chosen": -2.221325397491455,
      "logits/rejected": -3.34364652633667,
      "logps/chosen": -117.7776870727539,
      "logps/rejected": -135.71878051757812,
      "loss": 0.0117,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5357742309570312,
      "rewards/margins": 4.700972080230713,
      "rewards/rejected": -2.1651978492736816,
      "step": 882
    },
    {
      "epoch": 0.3532,
      "grad_norm": 3.9799816608428955,
      "learning_rate": 8.823999999999999e-07,
      "logits/chosen": -2.1073148250579834,
      "logits/rejected": -2.3850746154785156,
      "logps/chosen": -114.50975036621094,
      "logps/rejected": -103.12480926513672,
      "loss": 0.0652,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.727975606918335,
      "rewards/margins": 3.351803779602051,
      "rewards/rejected": -0.6238281726837158,
      "step": 883
    },
    {
      "epoch": 0.3536,
      "grad_norm": 1.267508625984192,
      "learning_rate": 8.822666666666666e-07,
      "logits/chosen": -2.122365951538086,
      "logits/rejected": -2.722792148590088,
      "logps/chosen": -108.13386535644531,
      "logps/rejected": -121.44935607910156,
      "loss": 0.0144,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.347060203552246,
      "rewards/margins": 4.64450740814209,
      "rewards/rejected": -1.2974472045898438,
      "step": 884
    },
    {
      "epoch": 0.354,
      "grad_norm": 0.15673035383224487,
      "learning_rate": 8.821333333333333e-07,
      "logits/chosen": -2.586277723312378,
      "logits/rejected": -2.708143472671509,
      "logps/chosen": -284.2630310058594,
      "logps/rejected": -149.38595581054688,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.947699069976807,
      "rewards/margins": 6.960450172424316,
      "rewards/rejected": -2.0127511024475098,
      "step": 885
    },
    {
      "epoch": 0.3544,
      "grad_norm": 0.10520278662443161,
      "learning_rate": 8.82e-07,
      "logits/chosen": -2.2914724349975586,
      "logits/rejected": -2.654284954071045,
      "logps/chosen": -157.473876953125,
      "logps/rejected": -139.12596130371094,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 5.013869285583496,
      "rewards/margins": 6.680793762207031,
      "rewards/rejected": -1.6669243574142456,
      "step": 886
    },
    {
      "epoch": 0.3548,
      "grad_norm": 0.9169249534606934,
      "learning_rate": 8.818666666666667e-07,
      "logits/chosen": -1.9253827333450317,
      "logits/rejected": -3.0617008209228516,
      "logps/chosen": -127.30502319335938,
      "logps/rejected": -125.77937316894531,
      "loss": 0.0124,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.050660610198975,
      "rewards/margins": 5.234200477600098,
      "rewards/rejected": -1.183539628982544,
      "step": 887
    },
    {
      "epoch": 0.3552,
      "grad_norm": 3.5739970207214355,
      "learning_rate": 8.817333333333334e-07,
      "logits/chosen": -2.007051944732666,
      "logits/rejected": -2.7731432914733887,
      "logps/chosen": -168.03176879882812,
      "logps/rejected": -104.1241455078125,
      "loss": 0.0487,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3066298961639404,
      "rewards/margins": 2.9984402656555176,
      "rewards/rejected": -1.6918103694915771,
      "step": 888
    },
    {
      "epoch": 0.3556,
      "grad_norm": 2.6579959392547607,
      "learning_rate": 8.816000000000001e-07,
      "logits/chosen": -2.1757283210754395,
      "logits/rejected": -2.8026511669158936,
      "logps/chosen": -141.8468475341797,
      "logps/rejected": -117.11779022216797,
      "loss": 0.0305,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.206937313079834,
      "rewards/margins": 4.779445648193359,
      "rewards/rejected": -1.5725082159042358,
      "step": 889
    },
    {
      "epoch": 0.356,
      "grad_norm": 3.939337730407715,
      "learning_rate": 8.814666666666665e-07,
      "logits/chosen": -2.3439788818359375,
      "logits/rejected": -2.304750442504883,
      "logps/chosen": -118.08889770507812,
      "logps/rejected": -95.19756317138672,
      "loss": 0.0763,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2186617851257324,
      "rewards/margins": 2.6627330780029297,
      "rewards/rejected": -0.4440712034702301,
      "step": 890
    },
    {
      "epoch": 0.3564,
      "grad_norm": 1.148431658744812,
      "learning_rate": 8.813333333333332e-07,
      "logits/chosen": -2.0069639682769775,
      "logits/rejected": -2.2123022079467773,
      "logps/chosen": -76.90491485595703,
      "logps/rejected": -105.94549560546875,
      "loss": 0.0163,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.10101318359375,
      "rewards/margins": 4.2972002029418945,
      "rewards/rejected": -2.1961872577667236,
      "step": 891
    },
    {
      "epoch": 0.3568,
      "grad_norm": 0.11259125173091888,
      "learning_rate": 8.811999999999999e-07,
      "logits/chosen": -2.5054500102996826,
      "logits/rejected": -2.7357935905456543,
      "logps/chosen": -106.74726104736328,
      "logps/rejected": -121.3192138671875,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4550156593322754,
      "rewards/margins": 6.316105365753174,
      "rewards/rejected": -2.8610897064208984,
      "step": 892
    },
    {
      "epoch": 0.3572,
      "grad_norm": 4.069399833679199,
      "learning_rate": 8.810666666666666e-07,
      "logits/chosen": -2.3295538425445557,
      "logits/rejected": -1.9579212665557861,
      "logps/chosen": -136.60269165039062,
      "logps/rejected": -164.30789184570312,
      "loss": 0.0706,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6884593963623047,
      "rewards/margins": 2.7965431213378906,
      "rewards/rejected": -1.108083724975586,
      "step": 893
    },
    {
      "epoch": 0.3576,
      "grad_norm": 0.4342983663082123,
      "learning_rate": 8.809333333333333e-07,
      "logits/chosen": -2.477869749069214,
      "logits/rejected": -2.5138745307922363,
      "logps/chosen": -129.8585205078125,
      "logps/rejected": -163.15679931640625,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.643235445022583,
      "rewards/margins": 5.340372085571289,
      "rewards/rejected": -1.6971367597579956,
      "step": 894
    },
    {
      "epoch": 0.358,
      "grad_norm": 0.07338424026966095,
      "learning_rate": 8.808e-07,
      "logits/chosen": -2.4253220558166504,
      "logits/rejected": -2.475712537765503,
      "logps/chosen": -139.29824829101562,
      "logps/rejected": -117.582275390625,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.9017014503479,
      "rewards/margins": 6.753366470336914,
      "rewards/rejected": -1.8516647815704346,
      "step": 895
    },
    {
      "epoch": 0.3584,
      "grad_norm": 0.2257143259048462,
      "learning_rate": 8.806666666666667e-07,
      "logits/chosen": -2.5352439880371094,
      "logits/rejected": -2.5803582668304443,
      "logps/chosen": -137.37191772460938,
      "logps/rejected": -132.83560180664062,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.071933746337891,
      "rewards/margins": 5.970492362976074,
      "rewards/rejected": -1.8985588550567627,
      "step": 896
    },
    {
      "epoch": 0.3588,
      "grad_norm": 1.6319419145584106,
      "learning_rate": 8.805333333333333e-07,
      "logits/chosen": -2.1593267917633057,
      "logits/rejected": -2.9646811485290527,
      "logps/chosen": -124.55751037597656,
      "logps/rejected": -123.99508666992188,
      "loss": 0.028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.657118558883667,
      "rewards/margins": 4.192355155944824,
      "rewards/rejected": -1.5352368354797363,
      "step": 897
    },
    {
      "epoch": 0.3592,
      "grad_norm": 1.784935712814331,
      "learning_rate": 8.804e-07,
      "logits/chosen": -2.247615337371826,
      "logits/rejected": -2.439605712890625,
      "logps/chosen": -195.52584838867188,
      "logps/rejected": -112.63807678222656,
      "loss": 0.0234,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1605920791625977,
      "rewards/margins": 4.494100570678711,
      "rewards/rejected": -1.3335083723068237,
      "step": 898
    },
    {
      "epoch": 0.3596,
      "grad_norm": 3.982699394226074,
      "learning_rate": 8.802666666666666e-07,
      "logits/chosen": -2.700985908508301,
      "logits/rejected": -2.685645818710327,
      "logps/chosen": -116.87405395507812,
      "logps/rejected": -115.51541137695312,
      "loss": 0.0521,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0621390342712402,
      "rewards/margins": 3.3258166313171387,
      "rewards/rejected": -1.2636775970458984,
      "step": 899
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.22945678234100342,
      "learning_rate": 8.801333333333332e-07,
      "logits/chosen": -2.5137484073638916,
      "logits/rejected": -3.411806106567383,
      "logps/chosen": -186.37197875976562,
      "logps/rejected": -116.92700958251953,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.611638069152832,
      "rewards/margins": 5.759393215179443,
      "rewards/rejected": -1.1477553844451904,
      "step": 900
    },
    {
      "epoch": 0.3604,
      "grad_norm": 0.935498058795929,
      "learning_rate": 8.799999999999999e-07,
      "logits/chosen": -2.3589138984680176,
      "logits/rejected": -2.9366087913513184,
      "logps/chosen": -127.11821746826172,
      "logps/rejected": -137.95382690429688,
      "loss": 0.0159,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9527900218963623,
      "rewards/margins": 4.350186347961426,
      "rewards/rejected": -1.3973965644836426,
      "step": 901
    },
    {
      "epoch": 0.3608,
      "grad_norm": 0.7515887022018433,
      "learning_rate": 8.798666666666666e-07,
      "logits/chosen": -2.0721054077148438,
      "logits/rejected": -2.796375274658203,
      "logps/chosen": -87.93319702148438,
      "logps/rejected": -120.72045135498047,
      "loss": 0.0101,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0524210929870605,
      "rewards/margins": 4.660200119018555,
      "rewards/rejected": -2.607779026031494,
      "step": 902
    },
    {
      "epoch": 0.3612,
      "grad_norm": 0.9702097773551941,
      "learning_rate": 8.797333333333333e-07,
      "logits/chosen": -2.4127087593078613,
      "logits/rejected": -2.904628276824951,
      "logps/chosen": -198.80990600585938,
      "logps/rejected": -133.9188232421875,
      "loss": 0.0079,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8812766075134277,
      "rewards/margins": 5.424795150756836,
      "rewards/rejected": -2.54351806640625,
      "step": 903
    },
    {
      "epoch": 0.3616,
      "grad_norm": 3.113576650619507,
      "learning_rate": 8.796e-07,
      "logits/chosen": -2.0203518867492676,
      "logits/rejected": -2.863724708557129,
      "logps/chosen": -107.77665710449219,
      "logps/rejected": -110.29999542236328,
      "loss": 0.0438,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4964637756347656,
      "rewards/margins": 3.3737680912017822,
      "rewards/rejected": -1.8773040771484375,
      "step": 904
    },
    {
      "epoch": 0.362,
      "grad_norm": 0.6972790956497192,
      "learning_rate": 8.794666666666666e-07,
      "logits/chosen": -2.7922723293304443,
      "logits/rejected": -2.9313182830810547,
      "logps/chosen": -195.00502014160156,
      "logps/rejected": -141.7165069580078,
      "loss": 0.0079,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.078359365463257,
      "rewards/margins": 5.25956916809082,
      "rewards/rejected": -2.1812095642089844,
      "step": 905
    },
    {
      "epoch": 0.3624,
      "grad_norm": 1.4919838905334473,
      "learning_rate": 8.793333333333333e-07,
      "logits/chosen": -2.253086566925049,
      "logits/rejected": -2.4002459049224854,
      "logps/chosen": -85.276123046875,
      "logps/rejected": -131.39117431640625,
      "loss": 0.0261,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2088942527770996,
      "rewards/margins": 3.635317802429199,
      "rewards/rejected": -1.4264233112335205,
      "step": 906
    },
    {
      "epoch": 0.3628,
      "grad_norm": 1.1419857740402222,
      "learning_rate": 8.792e-07,
      "logits/chosen": -2.267204761505127,
      "logits/rejected": -2.754969596862793,
      "logps/chosen": -170.79913330078125,
      "logps/rejected": -130.84521484375,
      "loss": 0.0192,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.325202226638794,
      "rewards/margins": 4.006586074829102,
      "rewards/rejected": -2.6813840866088867,
      "step": 907
    },
    {
      "epoch": 0.3632,
      "grad_norm": 9.029319763183594,
      "learning_rate": 8.790666666666666e-07,
      "logits/chosen": -1.9519243240356445,
      "logits/rejected": -2.7460989952087402,
      "logps/chosen": -66.86267852783203,
      "logps/rejected": -101.789306640625,
      "loss": 0.1389,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8573285341262817,
      "rewards/margins": 3.5138609409332275,
      "rewards/rejected": -1.6565322875976562,
      "step": 908
    },
    {
      "epoch": 0.3636,
      "grad_norm": 2.6672120094299316,
      "learning_rate": 8.789333333333333e-07,
      "logits/chosen": -2.7200684547424316,
      "logits/rejected": -3.2676639556884766,
      "logps/chosen": -153.9306640625,
      "logps/rejected": -136.94284057617188,
      "loss": 0.0303,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7191483974456787,
      "rewards/margins": 5.105963230133057,
      "rewards/rejected": -2.386814594268799,
      "step": 909
    },
    {
      "epoch": 0.364,
      "grad_norm": 3.944885492324829,
      "learning_rate": 8.788e-07,
      "logits/chosen": -2.2033636569976807,
      "logits/rejected": -2.761070728302002,
      "logps/chosen": -164.4838104248047,
      "logps/rejected": -109.11847686767578,
      "loss": 0.0418,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.585780382156372,
      "rewards/margins": 3.97127628326416,
      "rewards/rejected": -0.38549575209617615,
      "step": 910
    },
    {
      "epoch": 0.3644,
      "grad_norm": 0.1461348980665207,
      "learning_rate": 8.786666666666666e-07,
      "logits/chosen": -2.403510093688965,
      "logits/rejected": -3.040091037750244,
      "logps/chosen": -212.54322814941406,
      "logps/rejected": -138.00204467773438,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.087667942047119,
      "rewards/margins": 6.170294761657715,
      "rewards/rejected": -2.0826268196105957,
      "step": 911
    },
    {
      "epoch": 0.3648,
      "grad_norm": 0.7785078883171082,
      "learning_rate": 8.785333333333333e-07,
      "logits/chosen": -2.5697028636932373,
      "logits/rejected": -2.7624669075012207,
      "logps/chosen": -142.82066345214844,
      "logps/rejected": -238.0677490234375,
      "loss": 0.0072,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.2685956954956055,
      "rewards/margins": 5.582239151000977,
      "rewards/rejected": -1.3136433362960815,
      "step": 912
    },
    {
      "epoch": 0.3652,
      "grad_norm": 5.239083290100098,
      "learning_rate": 8.783999999999999e-07,
      "logits/chosen": -2.1477317810058594,
      "logits/rejected": -2.6741347312927246,
      "logps/chosen": -84.64513397216797,
      "logps/rejected": -99.28131866455078,
      "loss": 0.0656,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1485800743103027,
      "rewards/margins": 3.2265262603759766,
      "rewards/rejected": -1.0779460668563843,
      "step": 913
    },
    {
      "epoch": 0.3656,
      "grad_norm": 0.28821200132369995,
      "learning_rate": 8.782666666666666e-07,
      "logits/chosen": -2.2156262397766113,
      "logits/rejected": -2.749918222427368,
      "logps/chosen": -73.89797973632812,
      "logps/rejected": -133.52557373046875,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2710461616516113,
      "rewards/margins": 5.49123477935791,
      "rewards/rejected": -2.220188856124878,
      "step": 914
    },
    {
      "epoch": 0.366,
      "grad_norm": 0.9265820384025574,
      "learning_rate": 8.781333333333333e-07,
      "logits/chosen": -1.990908145904541,
      "logits/rejected": -2.1638026237487793,
      "logps/chosen": -67.50108337402344,
      "logps/rejected": -82.89474487304688,
      "loss": 0.0157,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.756049156188965,
      "rewards/margins": 4.416865348815918,
      "rewards/rejected": -0.6608161926269531,
      "step": 915
    },
    {
      "epoch": 0.3664,
      "grad_norm": 0.8596131801605225,
      "learning_rate": 8.78e-07,
      "logits/chosen": -2.088934898376465,
      "logits/rejected": -2.6664750576019287,
      "logps/chosen": -92.65727233886719,
      "logps/rejected": -144.2718505859375,
      "loss": 0.0113,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3570504188537598,
      "rewards/margins": 4.860579967498779,
      "rewards/rejected": -1.5035293102264404,
      "step": 916
    },
    {
      "epoch": 0.3668,
      "grad_norm": 1.1314600706100464,
      "learning_rate": 8.778666666666667e-07,
      "logits/chosen": -2.6154212951660156,
      "logits/rejected": -3.03096866607666,
      "logps/chosen": -211.6890411376953,
      "logps/rejected": -114.10147094726562,
      "loss": 0.0123,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3063366413116455,
      "rewards/margins": 5.787847518920898,
      "rewards/rejected": -2.481511116027832,
      "step": 917
    },
    {
      "epoch": 0.3672,
      "grad_norm": 2.6710846424102783,
      "learning_rate": 8.777333333333333e-07,
      "logits/chosen": -1.7407257556915283,
      "logits/rejected": -2.40986967086792,
      "logps/chosen": -97.62662506103516,
      "logps/rejected": -162.34298706054688,
      "loss": 0.0351,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3051040172576904,
      "rewards/margins": 3.967667579650879,
      "rewards/rejected": -1.6625633239746094,
      "step": 918
    },
    {
      "epoch": 0.3676,
      "grad_norm": 1.587469220161438,
      "learning_rate": 8.776e-07,
      "logits/chosen": -3.037346363067627,
      "logits/rejected": -2.785252094268799,
      "logps/chosen": -242.93130493164062,
      "logps/rejected": -143.9259796142578,
      "loss": 0.0184,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.049297332763672,
      "rewards/margins": 3.988391637802124,
      "rewards/rejected": -1.9390943050384521,
      "step": 919
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.6171916723251343,
      "learning_rate": 8.774666666666666e-07,
      "logits/chosen": -2.3785269260406494,
      "logits/rejected": -2.879246473312378,
      "logps/chosen": -119.95054626464844,
      "logps/rejected": -126.27638244628906,
      "loss": 0.0077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8790078163146973,
      "rewards/margins": 5.8735270500183105,
      "rewards/rejected": -1.9945194721221924,
      "step": 920
    },
    {
      "epoch": 0.3684,
      "grad_norm": 4.2291789054870605,
      "learning_rate": 8.773333333333332e-07,
      "logits/chosen": -2.0066232681274414,
      "logits/rejected": -2.6366636753082275,
      "logps/chosen": -78.04205322265625,
      "logps/rejected": -111.42103576660156,
      "loss": 0.059,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.559264063835144,
      "rewards/margins": 2.8813695907592773,
      "rewards/rejected": -1.3221054077148438,
      "step": 921
    },
    {
      "epoch": 0.3688,
      "grad_norm": 2.249873638153076,
      "learning_rate": 8.771999999999999e-07,
      "logits/chosen": -2.756678581237793,
      "logits/rejected": -2.8355283737182617,
      "logps/chosen": -310.49267578125,
      "logps/rejected": -168.1672821044922,
      "loss": 0.0241,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.438441514968872,
      "rewards/margins": 4.3569655418396,
      "rewards/rejected": -1.9185237884521484,
      "step": 922
    },
    {
      "epoch": 0.3692,
      "grad_norm": 0.8335833549499512,
      "learning_rate": 8.770666666666666e-07,
      "logits/chosen": -2.035412073135376,
      "logits/rejected": -2.720742702484131,
      "logps/chosen": -90.12281799316406,
      "logps/rejected": -104.66405487060547,
      "loss": 0.016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9729981422424316,
      "rewards/margins": 4.14409065246582,
      "rewards/rejected": -2.1710927486419678,
      "step": 923
    },
    {
      "epoch": 0.3696,
      "grad_norm": 8.476115226745605,
      "learning_rate": 8.769333333333333e-07,
      "logits/chosen": -2.9475607872009277,
      "logits/rejected": -2.924838066101074,
      "logps/chosen": -291.4437255859375,
      "logps/rejected": -136.28231811523438,
      "loss": 0.0975,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.310176134109497,
      "rewards/margins": 2.921942949295044,
      "rewards/rejected": -1.6117668151855469,
      "step": 924
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.446690082550049,
      "learning_rate": 8.768e-07,
      "logits/chosen": -2.630631446838379,
      "logits/rejected": -2.695394992828369,
      "logps/chosen": -109.2536392211914,
      "logps/rejected": -127.04269409179688,
      "loss": 0.0325,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.375211715698242,
      "rewards/margins": 4.248255729675293,
      "rewards/rejected": -1.8730437755584717,
      "step": 925
    },
    {
      "epoch": 0.3704,
      "grad_norm": 3.0159308910369873,
      "learning_rate": 8.766666666666667e-07,
      "logits/chosen": -2.341381072998047,
      "logits/rejected": -2.931980609893799,
      "logps/chosen": -171.73287963867188,
      "logps/rejected": -152.3045654296875,
      "loss": 0.0325,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.002239227294922,
      "rewards/margins": 3.66500186920166,
      "rewards/rejected": -1.6627625226974487,
      "step": 926
    },
    {
      "epoch": 0.3708,
      "grad_norm": 1.237661361694336,
      "learning_rate": 8.765333333333333e-07,
      "logits/chosen": -2.069611072540283,
      "logits/rejected": -2.4156529903411865,
      "logps/chosen": -64.79780578613281,
      "logps/rejected": -98.262451171875,
      "loss": 0.0163,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.944182872772217,
      "rewards/margins": 4.772252082824707,
      "rewards/rejected": -1.8280693292617798,
      "step": 927
    },
    {
      "epoch": 0.3712,
      "grad_norm": 1.4492697715759277,
      "learning_rate": 8.763999999999999e-07,
      "logits/chosen": -2.0623745918273926,
      "logits/rejected": -2.5018887519836426,
      "logps/chosen": -105.72285461425781,
      "logps/rejected": -146.84201049804688,
      "loss": 0.02,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0180420875549316,
      "rewards/margins": 4.037836074829102,
      "rewards/rejected": -2.019793748855591,
      "step": 928
    },
    {
      "epoch": 0.3716,
      "grad_norm": 2.4171085357666016,
      "learning_rate": 8.762666666666666e-07,
      "logits/chosen": -2.3338823318481445,
      "logits/rejected": -1.8990399837493896,
      "logps/chosen": -93.39051818847656,
      "logps/rejected": -100.71107482910156,
      "loss": 0.0343,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0294976234436035,
      "rewards/margins": 3.5542490482330322,
      "rewards/rejected": -0.5247513055801392,
      "step": 929
    },
    {
      "epoch": 0.372,
      "grad_norm": 0.07276073098182678,
      "learning_rate": 8.761333333333333e-07,
      "logits/chosen": -2.511284351348877,
      "logits/rejected": -3.428342342376709,
      "logps/chosen": -163.94137573242188,
      "logps/rejected": -151.0337677001953,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.423464298248291,
      "rewards/margins": 7.041274070739746,
      "rewards/rejected": -2.617809772491455,
      "step": 930
    },
    {
      "epoch": 0.3724,
      "grad_norm": 2.6238555908203125,
      "learning_rate": 8.76e-07,
      "logits/chosen": -1.9989675283432007,
      "logits/rejected": -2.2188515663146973,
      "logps/chosen": -64.919921875,
      "logps/rejected": -92.72505950927734,
      "loss": 0.0271,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8761134147644043,
      "rewards/margins": 4.164148330688477,
      "rewards/rejected": -1.2880349159240723,
      "step": 931
    },
    {
      "epoch": 0.3728,
      "grad_norm": 1.5379114151000977,
      "learning_rate": 8.758666666666666e-07,
      "logits/chosen": -2.229048252105713,
      "logits/rejected": -2.5269460678100586,
      "logps/chosen": -99.92932891845703,
      "logps/rejected": -168.4128875732422,
      "loss": 0.019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.122351884841919,
      "rewards/margins": 4.751825332641602,
      "rewards/rejected": -1.6294732093811035,
      "step": 932
    },
    {
      "epoch": 0.3732,
      "grad_norm": 0.7900665998458862,
      "learning_rate": 8.757333333333333e-07,
      "logits/chosen": -2.6363959312438965,
      "logits/rejected": -2.7033722400665283,
      "logps/chosen": -168.21188354492188,
      "logps/rejected": -191.33538818359375,
      "loss": 0.0119,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7696471214294434,
      "rewards/margins": 4.672415256500244,
      "rewards/rejected": -1.9027678966522217,
      "step": 933
    },
    {
      "epoch": 0.3736,
      "grad_norm": 0.8384228944778442,
      "learning_rate": 8.756e-07,
      "logits/chosen": -2.419572114944458,
      "logits/rejected": -2.5776290893554688,
      "logps/chosen": -141.12136840820312,
      "logps/rejected": -121.87490844726562,
      "loss": 0.0119,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5105679035186768,
      "rewards/margins": 5.164333343505859,
      "rewards/rejected": -1.6537652015686035,
      "step": 934
    },
    {
      "epoch": 0.374,
      "grad_norm": 0.9747537970542908,
      "learning_rate": 8.754666666666666e-07,
      "logits/chosen": -2.080491065979004,
      "logits/rejected": -2.6582484245300293,
      "logps/chosen": -184.55685424804688,
      "logps/rejected": -101.40476989746094,
      "loss": 0.0128,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9451904296875,
      "rewards/margins": 4.428072452545166,
      "rewards/rejected": -1.4828819036483765,
      "step": 935
    },
    {
      "epoch": 0.3744,
      "grad_norm": 2.3438408374786377,
      "learning_rate": 8.753333333333332e-07,
      "logits/chosen": -1.8803205490112305,
      "logits/rejected": -2.909499168395996,
      "logps/chosen": -67.12751770019531,
      "logps/rejected": -118.7498779296875,
      "loss": 0.0367,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8943085670471191,
      "rewards/margins": 3.324254035949707,
      "rewards/rejected": -1.4299453496932983,
      "step": 936
    },
    {
      "epoch": 0.3748,
      "grad_norm": 20.869163513183594,
      "learning_rate": 8.751999999999999e-07,
      "logits/chosen": -2.5574965476989746,
      "logits/rejected": -2.0812618732452393,
      "logps/chosen": -115.27861022949219,
      "logps/rejected": -113.478759765625,
      "loss": 0.3289,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8702725172042847,
      "rewards/margins": 1.5425081253051758,
      "rewards/rejected": -0.6722354888916016,
      "step": 937
    },
    {
      "epoch": 0.3752,
      "grad_norm": 0.5522946119308472,
      "learning_rate": 8.750666666666666e-07,
      "logits/chosen": -2.162093162536621,
      "logits/rejected": -2.624527931213379,
      "logps/chosen": -84.05149841308594,
      "logps/rejected": -122.66533660888672,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.998126983642578,
      "rewards/margins": 4.957696914672852,
      "rewards/rejected": -1.9595695734024048,
      "step": 938
    },
    {
      "epoch": 0.3756,
      "grad_norm": 4.546990394592285,
      "learning_rate": 8.749333333333333e-07,
      "logits/chosen": -2.458098888397217,
      "logits/rejected": -2.68223237991333,
      "logps/chosen": -114.61566162109375,
      "logps/rejected": -98.18072509765625,
      "loss": 0.0864,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.022247791290283,
      "rewards/margins": 3.138993263244629,
      "rewards/rejected": -0.11674537509679794,
      "step": 939
    },
    {
      "epoch": 0.376,
      "grad_norm": 1.999180555343628,
      "learning_rate": 8.748e-07,
      "logits/chosen": -2.136150598526001,
      "logits/rejected": -2.9759912490844727,
      "logps/chosen": -100.27769470214844,
      "logps/rejected": -128.2489013671875,
      "loss": 0.0243,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1559224128723145,
      "rewards/margins": 3.8278067111968994,
      "rewards/rejected": -1.6718841791152954,
      "step": 940
    },
    {
      "epoch": 0.3764,
      "grad_norm": 0.814444363117218,
      "learning_rate": 8.746666666666667e-07,
      "logits/chosen": -2.020580768585205,
      "logits/rejected": -3.047119140625,
      "logps/chosen": -131.12469482421875,
      "logps/rejected": -123.90474700927734,
      "loss": 0.0095,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.275148868560791,
      "rewards/margins": 4.656469345092773,
      "rewards/rejected": -2.3813202381134033,
      "step": 941
    },
    {
      "epoch": 0.3768,
      "grad_norm": 0.9333492517471313,
      "learning_rate": 8.745333333333334e-07,
      "logits/chosen": -2.2785067558288574,
      "logits/rejected": -2.7497048377990723,
      "logps/chosen": -113.82793426513672,
      "logps/rejected": -133.36488342285156,
      "loss": 0.0153,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.221661329269409,
      "rewards/margins": 4.183958053588867,
      "rewards/rejected": -1.962296724319458,
      "step": 942
    },
    {
      "epoch": 0.3772,
      "grad_norm": 0.4968250095844269,
      "learning_rate": 8.743999999999999e-07,
      "logits/chosen": -2.3946094512939453,
      "logits/rejected": -2.8601932525634766,
      "logps/chosen": -183.89735412597656,
      "logps/rejected": -157.21859741210938,
      "loss": 0.0048,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4398276805877686,
      "rewards/margins": 5.793123245239258,
      "rewards/rejected": -3.3532958030700684,
      "step": 943
    },
    {
      "epoch": 0.3776,
      "grad_norm": 0.31755536794662476,
      "learning_rate": 8.742666666666666e-07,
      "logits/chosen": -2.0307366847991943,
      "logits/rejected": -2.9735655784606934,
      "logps/chosen": -92.76373291015625,
      "logps/rejected": -127.58920288085938,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.020242691040039,
      "rewards/margins": 5.915635585784912,
      "rewards/rejected": -2.895392656326294,
      "step": 944
    },
    {
      "epoch": 0.378,
      "grad_norm": 2.2374789714813232,
      "learning_rate": 8.741333333333333e-07,
      "logits/chosen": -2.3474066257476807,
      "logits/rejected": -2.955836772918701,
      "logps/chosen": -138.79966735839844,
      "logps/rejected": -130.4871826171875,
      "loss": 0.0294,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4792027473449707,
      "rewards/margins": 4.356569290161133,
      "rewards/rejected": -2.877366781234741,
      "step": 945
    },
    {
      "epoch": 0.3784,
      "grad_norm": 1.34378981590271,
      "learning_rate": 8.739999999999999e-07,
      "logits/chosen": -2.4009032249450684,
      "logits/rejected": -2.51328706741333,
      "logps/chosen": -101.94027709960938,
      "logps/rejected": -195.03627014160156,
      "loss": 0.0136,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.550647258758545,
      "rewards/margins": 4.354678153991699,
      "rewards/rejected": -1.8040306568145752,
      "step": 946
    },
    {
      "epoch": 0.3788,
      "grad_norm": 1.8363722562789917,
      "learning_rate": 8.738666666666666e-07,
      "logits/chosen": -1.9883356094360352,
      "logits/rejected": -2.7993154525756836,
      "logps/chosen": -74.81178283691406,
      "logps/rejected": -101.70379638671875,
      "loss": 0.0301,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.17464542388916,
      "rewards/margins": 3.5164403915405273,
      "rewards/rejected": -1.3417949676513672,
      "step": 947
    },
    {
      "epoch": 0.3792,
      "grad_norm": 1.2563523054122925,
      "learning_rate": 8.737333333333333e-07,
      "logits/chosen": -2.4402761459350586,
      "logits/rejected": -3.3309850692749023,
      "logps/chosen": -153.65562438964844,
      "logps/rejected": -177.85922241210938,
      "loss": 0.0184,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.24306058883667,
      "rewards/margins": 4.086817741394043,
      "rewards/rejected": -1.8437573909759521,
      "step": 948
    },
    {
      "epoch": 0.3796,
      "grad_norm": 0.39228355884552,
      "learning_rate": 8.736e-07,
      "logits/chosen": -2.70979642868042,
      "logits/rejected": -3.1815192699432373,
      "logps/chosen": -131.9307403564453,
      "logps/rejected": -112.6888198852539,
      "loss": 0.0059,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9207425117492676,
      "rewards/margins": 5.129413604736328,
      "rewards/rejected": -2.2086710929870605,
      "step": 949
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3800564110279083,
      "learning_rate": 8.734666666666666e-07,
      "logits/chosen": -2.0499095916748047,
      "logits/rejected": -2.3441972732543945,
      "logps/chosen": -101.8538818359375,
      "logps/rejected": -99.42021179199219,
      "loss": 0.0065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.107797622680664,
      "rewards/margins": 5.238996505737305,
      "rewards/rejected": -1.1311988830566406,
      "step": 950
    },
    {
      "epoch": 0.3804,
      "grad_norm": 0.13035830855369568,
      "learning_rate": 8.733333333333333e-07,
      "logits/chosen": -2.4789810180664062,
      "logits/rejected": -3.1737890243530273,
      "logps/chosen": -178.1898956298828,
      "logps/rejected": -153.14654541015625,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.48189640045166,
      "rewards/margins": 6.504168510437012,
      "rewards/rejected": -3.0222725868225098,
      "step": 951
    },
    {
      "epoch": 0.3808,
      "grad_norm": 9.687320709228516,
      "learning_rate": 8.732e-07,
      "logits/chosen": -2.3038558959960938,
      "logits/rejected": -2.6573784351348877,
      "logps/chosen": -149.07199096679688,
      "logps/rejected": -103.52711486816406,
      "loss": 0.1442,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9826152920722961,
      "rewards/margins": 1.9323444366455078,
      "rewards/rejected": -0.9497291445732117,
      "step": 952
    },
    {
      "epoch": 0.3812,
      "grad_norm": 2.073533296585083,
      "learning_rate": 8.730666666666666e-07,
      "logits/chosen": -2.2249414920806885,
      "logits/rejected": -2.7114405632019043,
      "logps/chosen": -102.42149353027344,
      "logps/rejected": -128.9277801513672,
      "loss": 0.0267,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4195778369903564,
      "rewards/margins": 4.494503974914551,
      "rewards/rejected": -2.0749258995056152,
      "step": 953
    },
    {
      "epoch": 0.3816,
      "grad_norm": 0.7726842761039734,
      "learning_rate": 8.729333333333333e-07,
      "logits/chosen": -2.147294044494629,
      "logits/rejected": -2.802711009979248,
      "logps/chosen": -89.73674011230469,
      "logps/rejected": -116.78440856933594,
      "loss": 0.0135,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.417011022567749,
      "rewards/margins": 4.745630264282227,
      "rewards/rejected": -2.3286190032958984,
      "step": 954
    },
    {
      "epoch": 0.382,
      "grad_norm": 0.8981248140335083,
      "learning_rate": 8.728e-07,
      "logits/chosen": -2.3929238319396973,
      "logits/rejected": -2.523280143737793,
      "logps/chosen": -112.81680297851562,
      "logps/rejected": -105.49330139160156,
      "loss": 0.0111,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.173863410949707,
      "rewards/margins": 4.884181022644043,
      "rewards/rejected": -1.7103179693222046,
      "step": 955
    },
    {
      "epoch": 0.3824,
      "grad_norm": 1.061928391456604,
      "learning_rate": 8.726666666666666e-07,
      "logits/chosen": -1.8116729259490967,
      "logits/rejected": -2.910733222961426,
      "logps/chosen": -143.8711395263672,
      "logps/rejected": -139.57749938964844,
      "loss": 0.0128,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8304367065429688,
      "rewards/margins": 4.472309589385986,
      "rewards/rejected": -1.6418728828430176,
      "step": 956
    },
    {
      "epoch": 0.3828,
      "grad_norm": 7.781209468841553,
      "learning_rate": 8.725333333333333e-07,
      "logits/chosen": -2.322652816772461,
      "logits/rejected": -2.9421300888061523,
      "logps/chosen": -190.93154907226562,
      "logps/rejected": -141.89675903320312,
      "loss": 0.0783,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5701778531074524,
      "rewards/margins": 2.8031861782073975,
      "rewards/rejected": -2.2330081462860107,
      "step": 957
    },
    {
      "epoch": 0.3832,
      "grad_norm": 3.8858683109283447,
      "learning_rate": 8.723999999999999e-07,
      "logits/chosen": -1.9311003684997559,
      "logits/rejected": -2.322194814682007,
      "logps/chosen": -82.18095397949219,
      "logps/rejected": -103.64324188232422,
      "loss": 0.0585,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0289528369903564,
      "rewards/margins": 3.4749412536621094,
      "rewards/rejected": -1.445988416671753,
      "step": 958
    },
    {
      "epoch": 0.3836,
      "grad_norm": 0.5565708875656128,
      "learning_rate": 8.722666666666666e-07,
      "logits/chosen": -2.0031025409698486,
      "logits/rejected": -2.8466038703918457,
      "logps/chosen": -88.86783599853516,
      "logps/rejected": -152.16522216796875,
      "loss": 0.0063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.852806568145752,
      "rewards/margins": 5.878992557525635,
      "rewards/rejected": -2.026185989379883,
      "step": 959
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.5571703910827637,
      "learning_rate": 8.721333333333333e-07,
      "logits/chosen": -1.7840299606323242,
      "logits/rejected": -1.8926784992218018,
      "logps/chosen": -92.00601196289062,
      "logps/rejected": -106.33052825927734,
      "loss": 0.0077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.116795539855957,
      "rewards/margins": 4.876301288604736,
      "rewards/rejected": -1.7595058679580688,
      "step": 960
    },
    {
      "epoch": 0.3844,
      "grad_norm": 0.2815055847167969,
      "learning_rate": 8.72e-07,
      "logits/chosen": -1.948317050933838,
      "logits/rejected": -2.2849645614624023,
      "logps/chosen": -128.10308837890625,
      "logps/rejected": -100.96966552734375,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.724259376525879,
      "rewards/margins": 5.785791873931885,
      "rewards/rejected": -2.061532735824585,
      "step": 961
    },
    {
      "epoch": 0.3848,
      "grad_norm": 0.5266254544258118,
      "learning_rate": 8.718666666666667e-07,
      "logits/chosen": -2.385274887084961,
      "logits/rejected": -2.642113447189331,
      "logps/chosen": -123.26069641113281,
      "logps/rejected": -112.84477233886719,
      "loss": 0.0098,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.712599992752075,
      "rewards/margins": 4.64140510559082,
      "rewards/rejected": -1.9288051128387451,
      "step": 962
    },
    {
      "epoch": 0.3852,
      "grad_norm": 0.7816439867019653,
      "learning_rate": 8.717333333333334e-07,
      "logits/chosen": -2.3728737831115723,
      "logits/rejected": -1.9810783863067627,
      "logps/chosen": -106.51002502441406,
      "logps/rejected": -105.84587097167969,
      "loss": 0.0141,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.008235216140747,
      "rewards/margins": 4.588223457336426,
      "rewards/rejected": -1.5799881219863892,
      "step": 963
    },
    {
      "epoch": 0.3856,
      "grad_norm": 0.14558760821819305,
      "learning_rate": 8.716e-07,
      "logits/chosen": -2.4225692749023438,
      "logits/rejected": -2.4140875339508057,
      "logps/chosen": -127.2867202758789,
      "logps/rejected": -189.86224365234375,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3301901817321777,
      "rewards/margins": 6.422596454620361,
      "rewards/rejected": -3.0924062728881836,
      "step": 964
    },
    {
      "epoch": 0.386,
      "grad_norm": 0.5384384989738464,
      "learning_rate": 8.714666666666665e-07,
      "logits/chosen": -2.426486015319824,
      "logits/rejected": -3.3370044231414795,
      "logps/chosen": -92.09378051757812,
      "logps/rejected": -114.6192626953125,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.845000743865967,
      "rewards/margins": 5.0878777503967285,
      "rewards/rejected": -2.2428767681121826,
      "step": 965
    },
    {
      "epoch": 0.3864,
      "grad_norm": 1.5761382579803467,
      "learning_rate": 8.713333333333332e-07,
      "logits/chosen": -2.6234991550445557,
      "logits/rejected": -2.622318744659424,
      "logps/chosen": -101.04557037353516,
      "logps/rejected": -99.07182312011719,
      "loss": 0.0238,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6920886039733887,
      "rewards/margins": 4.352419376373291,
      "rewards/rejected": -1.6603306531906128,
      "step": 966
    },
    {
      "epoch": 0.3868,
      "grad_norm": 5.318860054016113,
      "learning_rate": 8.711999999999999e-07,
      "logits/chosen": -2.1525142192840576,
      "logits/rejected": -3.182133674621582,
      "logps/chosen": -146.8383026123047,
      "logps/rejected": -146.77593994140625,
      "loss": 0.0517,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.79842609167099,
      "rewards/margins": 3.922410726547241,
      "rewards/rejected": -3.1239845752716064,
      "step": 967
    },
    {
      "epoch": 0.3872,
      "grad_norm": 2.5346715450286865,
      "learning_rate": 8.710666666666666e-07,
      "logits/chosen": -1.9345033168792725,
      "logits/rejected": -2.456012487411499,
      "logps/chosen": -69.62310791015625,
      "logps/rejected": -94.54325103759766,
      "loss": 0.0475,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9178733825683594,
      "rewards/margins": 3.1003899574279785,
      "rewards/rejected": -1.1825164556503296,
      "step": 968
    },
    {
      "epoch": 0.3876,
      "grad_norm": 2.2149884700775146,
      "learning_rate": 8.709333333333333e-07,
      "logits/chosen": -2.2348363399505615,
      "logits/rejected": -2.8120007514953613,
      "logps/chosen": -140.53131103515625,
      "logps/rejected": -135.97427368164062,
      "loss": 0.0323,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2835137844085693,
      "rewards/margins": 4.627459526062012,
      "rewards/rejected": -2.3439457416534424,
      "step": 969
    },
    {
      "epoch": 0.388,
      "grad_norm": 10.010852813720703,
      "learning_rate": 8.708e-07,
      "logits/chosen": -2.4934706687927246,
      "logits/rejected": -3.070765495300293,
      "logps/chosen": -102.93695831298828,
      "logps/rejected": -108.57707977294922,
      "loss": 0.1869,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.258489966392517,
      "rewards/margins": 2.9979515075683594,
      "rewards/rejected": -1.7394615411758423,
      "step": 970
    },
    {
      "epoch": 0.3884,
      "grad_norm": 2.150981903076172,
      "learning_rate": 8.706666666666667e-07,
      "logits/chosen": -2.0627388954162598,
      "logits/rejected": -2.668959617614746,
      "logps/chosen": -128.1241912841797,
      "logps/rejected": -124.28498840332031,
      "loss": 0.0222,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5829172134399414,
      "rewards/margins": 4.661722183227539,
      "rewards/rejected": -2.0788047313690186,
      "step": 971
    },
    {
      "epoch": 0.3888,
      "grad_norm": 0.2588587999343872,
      "learning_rate": 8.705333333333334e-07,
      "logits/chosen": -2.339219093322754,
      "logits/rejected": -2.2001562118530273,
      "logps/chosen": -76.60599517822266,
      "logps/rejected": -105.0540771484375,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9877469539642334,
      "rewards/margins": 6.252224445343018,
      "rewards/rejected": -2.264477491378784,
      "step": 972
    },
    {
      "epoch": 0.3892,
      "grad_norm": 2.882620096206665,
      "learning_rate": 8.704e-07,
      "logits/chosen": -2.14888596534729,
      "logits/rejected": -2.786162853240967,
      "logps/chosen": -131.48101806640625,
      "logps/rejected": -157.780517578125,
      "loss": 0.0452,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2497503757476807,
      "rewards/margins": 3.7646496295928955,
      "rewards/rejected": -1.5148991346359253,
      "step": 973
    },
    {
      "epoch": 0.3896,
      "grad_norm": 0.6674132943153381,
      "learning_rate": 8.702666666666665e-07,
      "logits/chosen": -1.9475486278533936,
      "logits/rejected": -2.422900915145874,
      "logps/chosen": -75.44023895263672,
      "logps/rejected": -105.33550262451172,
      "loss": 0.0117,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2353761196136475,
      "rewards/margins": 4.457703590393066,
      "rewards/rejected": -2.222327709197998,
      "step": 974
    },
    {
      "epoch": 0.39,
      "grad_norm": 4.148820400238037,
      "learning_rate": 8.701333333333332e-07,
      "logits/chosen": -2.154099941253662,
      "logits/rejected": -2.8886373043060303,
      "logps/chosen": -100.24600219726562,
      "logps/rejected": -125.97048950195312,
      "loss": 0.0652,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7749683856964111,
      "rewards/margins": 3.936743974685669,
      "rewards/rejected": -2.161775588989258,
      "step": 975
    },
    {
      "epoch": 0.3904,
      "grad_norm": 0.31848230957984924,
      "learning_rate": 8.699999999999999e-07,
      "logits/chosen": -2.5082855224609375,
      "logits/rejected": -2.8296773433685303,
      "logps/chosen": -151.16587829589844,
      "logps/rejected": -105.66024780273438,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8130011558532715,
      "rewards/margins": 5.556972026824951,
      "rewards/rejected": -1.743970513343811,
      "step": 976
    },
    {
      "epoch": 0.3908,
      "grad_norm": 1.3037409782409668,
      "learning_rate": 8.698666666666666e-07,
      "logits/chosen": -1.8717299699783325,
      "logits/rejected": -2.6950221061706543,
      "logps/chosen": -84.71793365478516,
      "logps/rejected": -111.7591552734375,
      "loss": 0.0236,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6842819452285767,
      "rewards/margins": 3.7333805561065674,
      "rewards/rejected": -2.0490987300872803,
      "step": 977
    },
    {
      "epoch": 0.3912,
      "grad_norm": 0.23316791653633118,
      "learning_rate": 8.697333333333333e-07,
      "logits/chosen": -2.3468708992004395,
      "logits/rejected": -3.0426478385925293,
      "logps/chosen": -171.21560668945312,
      "logps/rejected": -165.32374572753906,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.336270809173584,
      "rewards/margins": 6.479382038116455,
      "rewards/rejected": -3.143111228942871,
      "step": 978
    },
    {
      "epoch": 0.3916,
      "grad_norm": 1.263386607170105,
      "learning_rate": 8.696e-07,
      "logits/chosen": -2.398583173751831,
      "logits/rejected": -2.8916547298431396,
      "logps/chosen": -108.14722442626953,
      "logps/rejected": -121.09867858886719,
      "loss": 0.0198,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3948302268981934,
      "rewards/margins": 5.2931132316589355,
      "rewards/rejected": -1.8982826471328735,
      "step": 979
    },
    {
      "epoch": 0.392,
      "grad_norm": 4.518253326416016,
      "learning_rate": 8.694666666666667e-07,
      "logits/chosen": -2.3916358947753906,
      "logits/rejected": -3.0782523155212402,
      "logps/chosen": -96.27892303466797,
      "logps/rejected": -117.26631164550781,
      "loss": 0.038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.521674394607544,
      "rewards/margins": 3.909822940826416,
      "rewards/rejected": -1.388148546218872,
      "step": 980
    },
    {
      "epoch": 0.3924,
      "grad_norm": 2.5991578102111816,
      "learning_rate": 8.693333333333333e-07,
      "logits/chosen": -2.221172571182251,
      "logits/rejected": -2.854746103286743,
      "logps/chosen": -109.83366394042969,
      "logps/rejected": -100.08705139160156,
      "loss": 0.0373,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8369007110595703,
      "rewards/margins": 3.272209882736206,
      "rewards/rejected": -1.4353091716766357,
      "step": 981
    },
    {
      "epoch": 0.3928,
      "grad_norm": 0.22498399019241333,
      "learning_rate": 8.692e-07,
      "logits/chosen": -1.9467889070510864,
      "logits/rejected": -3.0823442935943604,
      "logps/chosen": -62.05353546142578,
      "logps/rejected": -126.34654235839844,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.56634521484375,
      "rewards/margins": 6.074289321899414,
      "rewards/rejected": -2.5079445838928223,
      "step": 982
    },
    {
      "epoch": 0.3932,
      "grad_norm": 0.9438521862030029,
      "learning_rate": 8.690666666666667e-07,
      "logits/chosen": -1.9658613204956055,
      "logits/rejected": -2.6708574295043945,
      "logps/chosen": -97.75456237792969,
      "logps/rejected": -118.41079711914062,
      "loss": 0.0104,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6996490955352783,
      "rewards/margins": 4.967637062072754,
      "rewards/rejected": -2.2679877281188965,
      "step": 983
    },
    {
      "epoch": 0.3936,
      "grad_norm": 0.34886953234672546,
      "learning_rate": 8.689333333333333e-07,
      "logits/chosen": -1.918076753616333,
      "logits/rejected": -2.714293956756592,
      "logps/chosen": -77.1041259765625,
      "logps/rejected": -155.03817749023438,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1745457649230957,
      "rewards/margins": 5.427417755126953,
      "rewards/rejected": -2.2528717517852783,
      "step": 984
    },
    {
      "epoch": 0.394,
      "grad_norm": 4.965587615966797,
      "learning_rate": 8.687999999999999e-07,
      "logits/chosen": -2.126830577850342,
      "logits/rejected": -2.6070287227630615,
      "logps/chosen": -88.97698974609375,
      "logps/rejected": -119.51496124267578,
      "loss": 0.0821,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5545315146446228,
      "rewards/margins": 2.6952571868896484,
      "rewards/rejected": -2.140725612640381,
      "step": 985
    },
    {
      "epoch": 0.3944,
      "grad_norm": 0.4126344621181488,
      "learning_rate": 8.686666666666666e-07,
      "logits/chosen": -2.2384867668151855,
      "logits/rejected": -1.8828325271606445,
      "logps/chosen": -125.24364471435547,
      "logps/rejected": -170.60845947265625,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.4773850440979,
      "rewards/margins": 6.001396179199219,
      "rewards/rejected": -1.524011254310608,
      "step": 986
    },
    {
      "epoch": 0.3948,
      "grad_norm": 0.8499763607978821,
      "learning_rate": 8.685333333333333e-07,
      "logits/chosen": -2.4155373573303223,
      "logits/rejected": -2.3886454105377197,
      "logps/chosen": -77.94047546386719,
      "logps/rejected": -121.02239227294922,
      "loss": 0.0089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4227311611175537,
      "rewards/margins": 5.634485244750977,
      "rewards/rejected": -2.2117538452148438,
      "step": 987
    },
    {
      "epoch": 0.3952,
      "grad_norm": 12.908856391906738,
      "learning_rate": 8.683999999999999e-07,
      "logits/chosen": -2.122032403945923,
      "logits/rejected": -1.578774094581604,
      "logps/chosen": -88.35523223876953,
      "logps/rejected": -89.39095306396484,
      "loss": 0.1426,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.264065146446228,
      "rewards/margins": 2.5337777137756348,
      "rewards/rejected": -1.2697124481201172,
      "step": 988
    },
    {
      "epoch": 0.3956,
      "grad_norm": 0.2227674424648285,
      "learning_rate": 8.682666666666666e-07,
      "logits/chosen": -2.443783760070801,
      "logits/rejected": -3.3606514930725098,
      "logps/chosen": -209.03738403320312,
      "logps/rejected": -132.99417114257812,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.120485782623291,
      "rewards/margins": 6.412284851074219,
      "rewards/rejected": -2.2917990684509277,
      "step": 989
    },
    {
      "epoch": 0.396,
      "grad_norm": 3.5913453102111816,
      "learning_rate": 8.681333333333333e-07,
      "logits/chosen": -2.1934432983398438,
      "logits/rejected": -2.1949217319488525,
      "logps/chosen": -165.62249755859375,
      "logps/rejected": -165.56649780273438,
      "loss": 0.0392,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9380340576171875,
      "rewards/margins": 3.3305954933166504,
      "rewards/rejected": -1.3925613164901733,
      "step": 990
    },
    {
      "epoch": 0.3964,
      "grad_norm": 4.900576591491699,
      "learning_rate": 8.68e-07,
      "logits/chosen": -2.316140651702881,
      "logits/rejected": -2.8412537574768066,
      "logps/chosen": -99.42245483398438,
      "logps/rejected": -132.89813232421875,
      "loss": 0.0635,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6015434265136719,
      "rewards/margins": 2.9463143348693848,
      "rewards/rejected": -2.344770908355713,
      "step": 991
    },
    {
      "epoch": 0.3968,
      "grad_norm": 0.1827591210603714,
      "learning_rate": 8.678666666666667e-07,
      "logits/chosen": -2.539137363433838,
      "logits/rejected": -2.820176601409912,
      "logps/chosen": -207.3953857421875,
      "logps/rejected": -137.52723693847656,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.102987766265869,
      "rewards/margins": 6.698374271392822,
      "rewards/rejected": -2.595386505126953,
      "step": 992
    },
    {
      "epoch": 0.3972,
      "grad_norm": 0.7646521925926208,
      "learning_rate": 8.677333333333333e-07,
      "logits/chosen": -2.525925636291504,
      "logits/rejected": -3.244908094406128,
      "logps/chosen": -101.11213684082031,
      "logps/rejected": -119.61351013183594,
      "loss": 0.0102,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.058215856552124,
      "rewards/margins": 4.851947784423828,
      "rewards/rejected": -2.793732166290283,
      "step": 993
    },
    {
      "epoch": 0.3976,
      "grad_norm": 0.28200629353523254,
      "learning_rate": 8.676e-07,
      "logits/chosen": -2.50722074508667,
      "logits/rejected": -3.163666248321533,
      "logps/chosen": -114.4616470336914,
      "logps/rejected": -154.06211853027344,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4732255935668945,
      "rewards/margins": 6.492610454559326,
      "rewards/rejected": -3.0193848609924316,
      "step": 994
    },
    {
      "epoch": 0.398,
      "grad_norm": 8.720596313476562,
      "learning_rate": 8.674666666666667e-07,
      "logits/chosen": -2.08919620513916,
      "logits/rejected": -2.6588215827941895,
      "logps/chosen": -130.1461181640625,
      "logps/rejected": -191.20523071289062,
      "loss": 0.0928,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.275472640991211,
      "rewards/margins": 4.303889274597168,
      "rewards/rejected": -2.028416633605957,
      "step": 995
    },
    {
      "epoch": 0.3984,
      "grad_norm": 1.2231314182281494,
      "learning_rate": 8.673333333333332e-07,
      "logits/chosen": -2.2350480556488037,
      "logits/rejected": -1.8129289150238037,
      "logps/chosen": -81.36097717285156,
      "logps/rejected": -101.40266418457031,
      "loss": 0.0152,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.562382698059082,
      "rewards/margins": 4.206614017486572,
      "rewards/rejected": -0.6442314386367798,
      "step": 996
    },
    {
      "epoch": 0.3988,
      "grad_norm": 1.7127320766448975,
      "learning_rate": 8.671999999999999e-07,
      "logits/chosen": -2.0456881523132324,
      "logits/rejected": -2.589691638946533,
      "logps/chosen": -94.13610076904297,
      "logps/rejected": -133.49549865722656,
      "loss": 0.0243,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.357395648956299,
      "rewards/margins": 4.930874824523926,
      "rewards/rejected": -2.573479652404785,
      "step": 997
    },
    {
      "epoch": 0.3992,
      "grad_norm": 5.4353556632995605,
      "learning_rate": 8.670666666666666e-07,
      "logits/chosen": -2.219006061553955,
      "logits/rejected": -3.0967888832092285,
      "logps/chosen": -120.484130859375,
      "logps/rejected": -114.50829315185547,
      "loss": 0.0709,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2997708320617676,
      "rewards/margins": 3.794790029525757,
      "rewards/rejected": -1.4950191974639893,
      "step": 998
    },
    {
      "epoch": 0.3996,
      "grad_norm": 0.31021931767463684,
      "learning_rate": 8.669333333333333e-07,
      "logits/chosen": -2.209664821624756,
      "logits/rejected": -3.0207414627075195,
      "logps/chosen": -83.3301773071289,
      "logps/rejected": -152.84304809570312,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.262195587158203,
      "rewards/margins": 5.868431091308594,
      "rewards/rejected": -2.6062350273132324,
      "step": 999
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.240072101354599,
      "learning_rate": 8.668e-07,
      "logits/chosen": -2.2730631828308105,
      "logits/rejected": -3.060350179672241,
      "logps/chosen": -85.61474609375,
      "logps/rejected": -99.42426300048828,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4278955459594727,
      "rewards/margins": 5.702214241027832,
      "rewards/rejected": -2.2743186950683594,
      "step": 1000
    },
    {
      "epoch": 0.4004,
      "grad_norm": 0.8842854499816895,
      "learning_rate": 8.666666666666667e-07,
      "logits/chosen": -2.1260600090026855,
      "logits/rejected": -2.963569164276123,
      "logps/chosen": -103.3843765258789,
      "logps/rejected": -124.31617736816406,
      "loss": 0.0086,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0288541316986084,
      "rewards/margins": 4.75399923324585,
      "rewards/rejected": -2.725144863128662,
      "step": 1001
    },
    {
      "epoch": 0.4008,
      "grad_norm": 0.7786399722099304,
      "learning_rate": 8.665333333333334e-07,
      "logits/chosen": -1.77853524684906,
      "logits/rejected": -2.6751251220703125,
      "logps/chosen": -116.05855560302734,
      "logps/rejected": -122.10691833496094,
      "loss": 0.0128,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4968674182891846,
      "rewards/margins": 4.708100318908691,
      "rewards/rejected": -2.211233139038086,
      "step": 1002
    },
    {
      "epoch": 0.4012,
      "grad_norm": 3.005661964416504,
      "learning_rate": 8.663999999999999e-07,
      "logits/chosen": -1.893611192703247,
      "logits/rejected": -2.59089994430542,
      "logps/chosen": -123.05966186523438,
      "logps/rejected": -105.80560302734375,
      "loss": 0.0377,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.413954496383667,
      "rewards/margins": 3.260542869567871,
      "rewards/rejected": -1.846588134765625,
      "step": 1003
    },
    {
      "epoch": 0.4016,
      "grad_norm": 2.661505937576294,
      "learning_rate": 8.662666666666666e-07,
      "logits/chosen": -2.5958712100982666,
      "logits/rejected": -2.5922932624816895,
      "logps/chosen": -132.14389038085938,
      "logps/rejected": -104.84564208984375,
      "loss": 0.0395,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8957526683807373,
      "rewards/margins": 3.223254919052124,
      "rewards/rejected": -1.3275020122528076,
      "step": 1004
    },
    {
      "epoch": 0.402,
      "grad_norm": 1.6224191188812256,
      "learning_rate": 8.661333333333333e-07,
      "logits/chosen": -2.700407028198242,
      "logits/rejected": -2.4945590496063232,
      "logps/chosen": -141.54046630859375,
      "logps/rejected": -166.33860778808594,
      "loss": 0.0304,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4232211112976074,
      "rewards/margins": 4.528425693511963,
      "rewards/rejected": -1.1052043437957764,
      "step": 1005
    },
    {
      "epoch": 0.4024,
      "grad_norm": 0.5156925916671753,
      "learning_rate": 8.659999999999999e-07,
      "logits/chosen": -2.2669425010681152,
      "logits/rejected": -2.5350558757781982,
      "logps/chosen": -136.27816772460938,
      "logps/rejected": -157.43026733398438,
      "loss": 0.0067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4760255813598633,
      "rewards/margins": 5.587734699249268,
      "rewards/rejected": -2.1117091178894043,
      "step": 1006
    },
    {
      "epoch": 0.4028,
      "grad_norm": 0.5366275906562805,
      "learning_rate": 8.658666666666666e-07,
      "logits/chosen": -1.9516263008117676,
      "logits/rejected": -2.8757619857788086,
      "logps/chosen": -93.51016235351562,
      "logps/rejected": -115.2319107055664,
      "loss": 0.0063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2639191150665283,
      "rewards/margins": 5.148748874664307,
      "rewards/rejected": -1.8848297595977783,
      "step": 1007
    },
    {
      "epoch": 0.4032,
      "grad_norm": 0.31687793135643005,
      "learning_rate": 8.657333333333333e-07,
      "logits/chosen": -2.203947067260742,
      "logits/rejected": -2.671215057373047,
      "logps/chosen": -106.01278686523438,
      "logps/rejected": -278.59234619140625,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4457478523254395,
      "rewards/margins": 6.279669761657715,
      "rewards/rejected": -3.8339219093322754,
      "step": 1008
    },
    {
      "epoch": 0.4036,
      "grad_norm": 1.8821942806243896,
      "learning_rate": 8.656e-07,
      "logits/chosen": -2.091679573059082,
      "logits/rejected": -2.693296432495117,
      "logps/chosen": -100.66360473632812,
      "logps/rejected": -130.9735107421875,
      "loss": 0.0222,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3810226917266846,
      "rewards/margins": 4.178233623504639,
      "rewards/rejected": -1.797210693359375,
      "step": 1009
    },
    {
      "epoch": 0.404,
      "grad_norm": 1.323736548423767,
      "learning_rate": 8.654666666666667e-07,
      "logits/chosen": -2.2290592193603516,
      "logits/rejected": -2.306286096572876,
      "logps/chosen": -112.03424835205078,
      "logps/rejected": -109.89237213134766,
      "loss": 0.0194,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6030240058898926,
      "rewards/margins": 4.159843444824219,
      "rewards/rejected": -1.556819200515747,
      "step": 1010
    },
    {
      "epoch": 0.4044,
      "grad_norm": 1.5848212242126465,
      "learning_rate": 8.653333333333333e-07,
      "logits/chosen": -2.308234691619873,
      "logits/rejected": -2.670865535736084,
      "logps/chosen": -145.9526824951172,
      "logps/rejected": -125.33152770996094,
      "loss": 0.0185,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1416192054748535,
      "rewards/margins": 4.392412185668945,
      "rewards/rejected": -2.2507927417755127,
      "step": 1011
    },
    {
      "epoch": 0.4048,
      "grad_norm": 1.4510515928268433,
      "learning_rate": 8.651999999999999e-07,
      "logits/chosen": -2.3240785598754883,
      "logits/rejected": -2.7202141284942627,
      "logps/chosen": -87.87008666992188,
      "logps/rejected": -92.2452621459961,
      "loss": 0.0202,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4659996032714844,
      "rewards/margins": 3.891916513442993,
      "rewards/rejected": -1.4259166717529297,
      "step": 1012
    },
    {
      "epoch": 0.4052,
      "grad_norm": 1.4830573797225952,
      "learning_rate": 8.650666666666666e-07,
      "logits/chosen": -2.1654205322265625,
      "logits/rejected": -2.871220827102661,
      "logps/chosen": -113.05693054199219,
      "logps/rejected": -136.41604614257812,
      "loss": 0.0213,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4817192554473877,
      "rewards/margins": 4.114472389221191,
      "rewards/rejected": -1.6327533721923828,
      "step": 1013
    },
    {
      "epoch": 0.4056,
      "grad_norm": 0.3080388307571411,
      "learning_rate": 8.649333333333333e-07,
      "logits/chosen": -2.1435203552246094,
      "logits/rejected": -3.2566022872924805,
      "logps/chosen": -155.7700653076172,
      "logps/rejected": -141.91473388671875,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3439064025878906,
      "rewards/margins": 6.067607879638672,
      "rewards/rejected": -2.723701000213623,
      "step": 1014
    },
    {
      "epoch": 0.406,
      "grad_norm": 0.8067086935043335,
      "learning_rate": 8.648e-07,
      "logits/chosen": -2.562741279602051,
      "logits/rejected": -3.0902252197265625,
      "logps/chosen": -107.4393310546875,
      "logps/rejected": -104.75418090820312,
      "loss": 0.0094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.057420253753662,
      "rewards/margins": 4.691473960876465,
      "rewards/rejected": -1.6340539455413818,
      "step": 1015
    },
    {
      "epoch": 0.4064,
      "grad_norm": 2.7113394737243652,
      "learning_rate": 8.646666666666667e-07,
      "logits/chosen": -2.8126187324523926,
      "logits/rejected": -3.259218215942383,
      "logps/chosen": -151.8725128173828,
      "logps/rejected": -116.81107330322266,
      "loss": 0.0363,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.690305471420288,
      "rewards/margins": 3.68057918548584,
      "rewards/rejected": -1.9902737140655518,
      "step": 1016
    },
    {
      "epoch": 0.4068,
      "grad_norm": 0.13156019151210785,
      "learning_rate": 8.645333333333333e-07,
      "logits/chosen": -1.831816554069519,
      "logits/rejected": -2.4152631759643555,
      "logps/chosen": -103.55911254882812,
      "logps/rejected": -98.13970947265625,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.0894999504089355,
      "rewards/margins": 6.273180961608887,
      "rewards/rejected": -2.183680772781372,
      "step": 1017
    },
    {
      "epoch": 0.4072,
      "grad_norm": 0.858697772026062,
      "learning_rate": 8.643999999999999e-07,
      "logits/chosen": -2.196185350418091,
      "logits/rejected": -2.7959015369415283,
      "logps/chosen": -108.20857238769531,
      "logps/rejected": -113.61579895019531,
      "loss": 0.0089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0672767162323,
      "rewards/margins": 4.886825084686279,
      "rewards/rejected": -1.819548487663269,
      "step": 1018
    },
    {
      "epoch": 0.4076,
      "grad_norm": 1.0580192804336548,
      "learning_rate": 8.642666666666666e-07,
      "logits/chosen": -2.7912535667419434,
      "logits/rejected": -2.7041726112365723,
      "logps/chosen": -84.96633911132812,
      "logps/rejected": -121.49783325195312,
      "loss": 0.0183,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.698296308517456,
      "rewards/margins": 4.762690544128418,
      "rewards/rejected": -2.064394474029541,
      "step": 1019
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.46630340814590454,
      "learning_rate": 8.641333333333333e-07,
      "logits/chosen": -2.2624547481536865,
      "logits/rejected": -2.3177199363708496,
      "logps/chosen": -126.02127838134766,
      "logps/rejected": -111.806396484375,
      "loss": 0.0077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.185675859451294,
      "rewards/margins": 5.0597991943359375,
      "rewards/rejected": -1.8741233348846436,
      "step": 1020
    },
    {
      "epoch": 0.4084,
      "grad_norm": 0.8539828062057495,
      "learning_rate": 8.639999999999999e-07,
      "logits/chosen": -2.476044178009033,
      "logits/rejected": -2.948939800262451,
      "logps/chosen": -97.392578125,
      "logps/rejected": -153.11318969726562,
      "loss": 0.0107,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7673091888427734,
      "rewards/margins": 5.358187675476074,
      "rewards/rejected": -1.5908787250518799,
      "step": 1021
    },
    {
      "epoch": 0.4088,
      "grad_norm": 2.5036208629608154,
      "learning_rate": 8.638666666666666e-07,
      "logits/chosen": -1.9195904731750488,
      "logits/rejected": -2.2661824226379395,
      "logps/chosen": -125.5784683227539,
      "logps/rejected": -117.36776733398438,
      "loss": 0.0433,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2415955066680908,
      "rewards/margins": 3.131709575653076,
      "rewards/rejected": -1.8901143074035645,
      "step": 1022
    },
    {
      "epoch": 0.4092,
      "grad_norm": 1.2820932865142822,
      "learning_rate": 8.637333333333333e-07,
      "logits/chosen": -2.6274642944335938,
      "logits/rejected": -2.487095832824707,
      "logps/chosen": -109.51383972167969,
      "logps/rejected": -122.52584838867188,
      "loss": 0.0194,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4617791175842285,
      "rewards/margins": 4.271624565124512,
      "rewards/rejected": -1.8098456859588623,
      "step": 1023
    },
    {
      "epoch": 0.4096,
      "grad_norm": 5.042874336242676,
      "learning_rate": 8.636e-07,
      "logits/chosen": -2.083019733428955,
      "logits/rejected": -2.6830544471740723,
      "logps/chosen": -102.95611572265625,
      "logps/rejected": -132.67623901367188,
      "loss": 0.0639,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9346096515655518,
      "rewards/margins": 3.633317470550537,
      "rewards/rejected": -1.6987075805664062,
      "step": 1024
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.4822593927383423,
      "learning_rate": 8.634666666666667e-07,
      "logits/chosen": -2.20365309715271,
      "logits/rejected": -2.460941791534424,
      "logps/chosen": -138.73577880859375,
      "logps/rejected": -133.0948486328125,
      "loss": 0.0237,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.503134250640869,
      "rewards/margins": 4.081134796142578,
      "rewards/rejected": -1.5780003070831299,
      "step": 1025
    },
    {
      "epoch": 0.4104,
      "grad_norm": 0.24410219490528107,
      "learning_rate": 8.633333333333333e-07,
      "logits/chosen": -2.2589430809020996,
      "logits/rejected": -3.0077738761901855,
      "logps/chosen": -80.95280456542969,
      "logps/rejected": -117.94821166992188,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.329883098602295,
      "rewards/margins": 5.8088765144348145,
      "rewards/rejected": -2.4789934158325195,
      "step": 1026
    },
    {
      "epoch": 0.4108,
      "grad_norm": 0.29623091220855713,
      "learning_rate": 8.632e-07,
      "logits/chosen": -2.5409553050994873,
      "logits/rejected": -3.0371737480163574,
      "logps/chosen": -174.13494873046875,
      "logps/rejected": -121.84896850585938,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0474979877471924,
      "rewards/margins": 5.497432708740234,
      "rewards/rejected": -2.449934482574463,
      "step": 1027
    },
    {
      "epoch": 0.4112,
      "grad_norm": 0.9214242696762085,
      "learning_rate": 8.630666666666666e-07,
      "logits/chosen": -2.1434197425842285,
      "logits/rejected": -2.8684465885162354,
      "logps/chosen": -104.47509765625,
      "logps/rejected": -121.62916564941406,
      "loss": 0.0106,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.786569595336914,
      "rewards/margins": 4.75885534286499,
      "rewards/rejected": -1.9722858667373657,
      "step": 1028
    },
    {
      "epoch": 0.4116,
      "grad_norm": 0.963379979133606,
      "learning_rate": 8.629333333333333e-07,
      "logits/chosen": -2.024423837661743,
      "logits/rejected": -2.6412577629089355,
      "logps/chosen": -110.35528564453125,
      "logps/rejected": -179.41725158691406,
      "loss": 0.0146,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.428074598312378,
      "rewards/margins": 4.869866847991943,
      "rewards/rejected": -2.4417924880981445,
      "step": 1029
    },
    {
      "epoch": 0.412,
      "grad_norm": 0.07977204024791718,
      "learning_rate": 8.628e-07,
      "logits/chosen": -2.482992172241211,
      "logits/rejected": -2.691218376159668,
      "logps/chosen": -123.98773193359375,
      "logps/rejected": -120.18228149414062,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8915977478027344,
      "rewards/margins": 7.110053062438965,
      "rewards/rejected": -3.2184555530548096,
      "step": 1030
    },
    {
      "epoch": 0.4124,
      "grad_norm": 0.6464134454727173,
      "learning_rate": 8.626666666666666e-07,
      "logits/chosen": -2.2727155685424805,
      "logits/rejected": -2.681823492050171,
      "logps/chosen": -86.91963195800781,
      "logps/rejected": -115.55209350585938,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.419027805328369,
      "rewards/margins": 5.115616798400879,
      "rewards/rejected": -2.6965889930725098,
      "step": 1031
    },
    {
      "epoch": 0.4128,
      "grad_norm": 3.2408149242401123,
      "learning_rate": 8.625333333333333e-07,
      "logits/chosen": -2.4100136756896973,
      "logits/rejected": -2.6839160919189453,
      "logps/chosen": -72.87367248535156,
      "logps/rejected": -108.00997924804688,
      "loss": 0.0391,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.823197841644287,
      "rewards/margins": 3.9349753856658936,
      "rewards/rejected": -1.1117775440216064,
      "step": 1032
    },
    {
      "epoch": 0.4132,
      "grad_norm": 0.26561135053634644,
      "learning_rate": 8.624e-07,
      "logits/chosen": -2.430849075317383,
      "logits/rejected": -2.4531335830688477,
      "logps/chosen": -101.2646713256836,
      "logps/rejected": -99.99308013916016,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.522672176361084,
      "rewards/margins": 5.602697372436523,
      "rewards/rejected": -2.0800251960754395,
      "step": 1033
    },
    {
      "epoch": 0.4136,
      "grad_norm": 2.0908422470092773,
      "learning_rate": 8.622666666666666e-07,
      "logits/chosen": -2.197902202606201,
      "logits/rejected": -2.923936128616333,
      "logps/chosen": -156.6182861328125,
      "logps/rejected": -99.35963439941406,
      "loss": 0.0296,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.358208417892456,
      "rewards/margins": 3.7731552124023438,
      "rewards/rejected": -1.4149467945098877,
      "step": 1034
    },
    {
      "epoch": 0.414,
      "grad_norm": 1.2345536947250366,
      "learning_rate": 8.621333333333333e-07,
      "logits/chosen": -2.355591297149658,
      "logits/rejected": -2.827087879180908,
      "logps/chosen": -103.56782531738281,
      "logps/rejected": -125.1845703125,
      "loss": 0.0158,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9792797565460205,
      "rewards/margins": 4.630592346191406,
      "rewards/rejected": -2.6513123512268066,
      "step": 1035
    },
    {
      "epoch": 0.4144,
      "grad_norm": 0.28635233640670776,
      "learning_rate": 8.62e-07,
      "logits/chosen": -2.4418954849243164,
      "logits/rejected": -3.4668357372283936,
      "logps/chosen": -93.41773223876953,
      "logps/rejected": -151.166748046875,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9199531078338623,
      "rewards/margins": 5.688897132873535,
      "rewards/rejected": -2.7689437866210938,
      "step": 1036
    },
    {
      "epoch": 0.4148,
      "grad_norm": 0.44974255561828613,
      "learning_rate": 8.618666666666667e-07,
      "logits/chosen": -2.6144933700561523,
      "logits/rejected": -2.9906058311462402,
      "logps/chosen": -127.30211639404297,
      "logps/rejected": -127.6230239868164,
      "loss": 0.0045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1713690757751465,
      "rewards/margins": 6.110116958618164,
      "rewards/rejected": -2.9387478828430176,
      "step": 1037
    },
    {
      "epoch": 0.4152,
      "grad_norm": 1.1378974914550781,
      "learning_rate": 8.617333333333333e-07,
      "logits/chosen": -2.501605987548828,
      "logits/rejected": -2.9818100929260254,
      "logps/chosen": -170.39913940429688,
      "logps/rejected": -146.1743927001953,
      "loss": 0.0117,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.129732608795166,
      "rewards/margins": 4.683331489562988,
      "rewards/rejected": -2.5535988807678223,
      "step": 1038
    },
    {
      "epoch": 0.4156,
      "grad_norm": 6.268846035003662,
      "learning_rate": 8.616e-07,
      "logits/chosen": -2.4231605529785156,
      "logits/rejected": -2.800825834274292,
      "logps/chosen": -139.40061950683594,
      "logps/rejected": -113.44874572753906,
      "loss": 0.0527,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.753802537918091,
      "rewards/margins": 4.087385177612305,
      "rewards/rejected": -1.3335827589035034,
      "step": 1039
    },
    {
      "epoch": 0.416,
      "grad_norm": 3.2968082427978516,
      "learning_rate": 8.614666666666666e-07,
      "logits/chosen": -1.8115615844726562,
      "logits/rejected": -2.4503750801086426,
      "logps/chosen": -68.15545654296875,
      "logps/rejected": -97.32923889160156,
      "loss": 0.0586,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8193867206573486,
      "rewards/margins": 3.689134359359741,
      "rewards/rejected": -1.8697476387023926,
      "step": 1040
    },
    {
      "epoch": 0.4164,
      "grad_norm": 4.599780082702637,
      "learning_rate": 8.613333333333332e-07,
      "logits/chosen": -2.2474117279052734,
      "logits/rejected": -2.8834025859832764,
      "logps/chosen": -134.96267700195312,
      "logps/rejected": -122.98176574707031,
      "loss": 0.0529,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9016728401184082,
      "rewards/margins": 4.094318389892578,
      "rewards/rejected": -2.192645311355591,
      "step": 1041
    },
    {
      "epoch": 0.4168,
      "grad_norm": 1.6181727647781372,
      "learning_rate": 8.611999999999999e-07,
      "logits/chosen": -2.8591227531433105,
      "logits/rejected": -3.2320353984832764,
      "logps/chosen": -219.84918212890625,
      "logps/rejected": -263.54443359375,
      "loss": 0.0109,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5962324142456055,
      "rewards/margins": 5.441538333892822,
      "rewards/rejected": -1.8453056812286377,
      "step": 1042
    },
    {
      "epoch": 0.4172,
      "grad_norm": 1.4584323167800903,
      "learning_rate": 8.610666666666666e-07,
      "logits/chosen": -2.4723310470581055,
      "logits/rejected": -2.554797649383545,
      "logps/chosen": -146.60658264160156,
      "logps/rejected": -105.61026000976562,
      "loss": 0.0109,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.697341203689575,
      "rewards/margins": 4.722533226013184,
      "rewards/rejected": -2.0251922607421875,
      "step": 1043
    },
    {
      "epoch": 0.4176,
      "grad_norm": 0.14904175698757172,
      "learning_rate": 8.609333333333333e-07,
      "logits/chosen": -2.206291675567627,
      "logits/rejected": -2.567666530609131,
      "logps/chosen": -83.49813842773438,
      "logps/rejected": -102.76806640625,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.396444797515869,
      "rewards/margins": 6.144919395446777,
      "rewards/rejected": -1.74847412109375,
      "step": 1044
    },
    {
      "epoch": 0.418,
      "grad_norm": 0.34416231513023376,
      "learning_rate": 8.608e-07,
      "logits/chosen": -2.2372183799743652,
      "logits/rejected": -3.161571502685547,
      "logps/chosen": -98.79987335205078,
      "logps/rejected": -131.4824981689453,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.182989597320557,
      "rewards/margins": 5.468165874481201,
      "rewards/rejected": -1.2851765155792236,
      "step": 1045
    },
    {
      "epoch": 0.4184,
      "grad_norm": 6.363046646118164,
      "learning_rate": 8.606666666666667e-07,
      "logits/chosen": -2.6905517578125,
      "logits/rejected": -3.015843391418457,
      "logps/chosen": -197.23007202148438,
      "logps/rejected": -122.83070373535156,
      "loss": 0.0583,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.567833185195923,
      "rewards/margins": 4.4233808517456055,
      "rewards/rejected": -1.8555474281311035,
      "step": 1046
    },
    {
      "epoch": 0.4188,
      "grad_norm": 0.2848553955554962,
      "learning_rate": 8.605333333333334e-07,
      "logits/chosen": -2.3473339080810547,
      "logits/rejected": -2.996053695678711,
      "logps/chosen": -83.6697998046875,
      "logps/rejected": -162.19692993164062,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.40097713470459,
      "rewards/margins": 6.21665096282959,
      "rewards/rejected": -1.8156743049621582,
      "step": 1047
    },
    {
      "epoch": 0.4192,
      "grad_norm": 0.44545018672943115,
      "learning_rate": 8.604000000000001e-07,
      "logits/chosen": -2.316549062728882,
      "logits/rejected": -3.0319347381591797,
      "logps/chosen": -109.11323547363281,
      "logps/rejected": -145.17771911621094,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.523270845413208,
      "rewards/margins": 5.32705020904541,
      "rewards/rejected": -2.8037796020507812,
      "step": 1048
    },
    {
      "epoch": 0.4196,
      "grad_norm": 1.2946218252182007,
      "learning_rate": 8.602666666666665e-07,
      "logits/chosen": -2.304276466369629,
      "logits/rejected": -3.3554794788360596,
      "logps/chosen": -115.79572296142578,
      "logps/rejected": -123.75453186035156,
      "loss": 0.016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2892982959747314,
      "rewards/margins": 4.90504789352417,
      "rewards/rejected": -2.6157498359680176,
      "step": 1049
    },
    {
      "epoch": 0.42,
      "grad_norm": 9.811087608337402,
      "learning_rate": 8.601333333333332e-07,
      "logits/chosen": -1.4620884656906128,
      "logits/rejected": -2.705785036087036,
      "logps/chosen": -60.022117614746094,
      "logps/rejected": -110.9886474609375,
      "loss": 0.1144,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2701069116592407,
      "rewards/margins": 3.5314269065856934,
      "rewards/rejected": -2.261319875717163,
      "step": 1050
    },
    {
      "epoch": 0.4204,
      "grad_norm": 0.2613171935081482,
      "learning_rate": 8.599999999999999e-07,
      "logits/chosen": -2.225828170776367,
      "logits/rejected": -2.880286693572998,
      "logps/chosen": -88.60049438476562,
      "logps/rejected": -127.21794891357422,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9481887817382812,
      "rewards/margins": 6.098037242889404,
      "rewards/rejected": -2.149848222732544,
      "step": 1051
    },
    {
      "epoch": 0.4208,
      "grad_norm": 0.07561682909727097,
      "learning_rate": 8.598666666666666e-07,
      "logits/chosen": -2.0434513092041016,
      "logits/rejected": -2.759097099304199,
      "logps/chosen": -84.84440612792969,
      "logps/rejected": -128.14462280273438,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.884202003479004,
      "rewards/margins": 6.973846435546875,
      "rewards/rejected": -3.089644432067871,
      "step": 1052
    },
    {
      "epoch": 0.4212,
      "grad_norm": 0.8563008904457092,
      "learning_rate": 8.597333333333333e-07,
      "logits/chosen": -2.119539976119995,
      "logits/rejected": -2.904482841491699,
      "logps/chosen": -87.64542388916016,
      "logps/rejected": -107.6888427734375,
      "loss": 0.0077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5909667015075684,
      "rewards/margins": 5.16652774810791,
      "rewards/rejected": -1.5755611658096313,
      "step": 1053
    },
    {
      "epoch": 0.4216,
      "grad_norm": 0.7082684636116028,
      "learning_rate": 8.596e-07,
      "logits/chosen": -2.3925061225891113,
      "logits/rejected": -3.051478624343872,
      "logps/chosen": -129.24313354492188,
      "logps/rejected": -136.1741943359375,
      "loss": 0.0086,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0928659439086914,
      "rewards/margins": 5.686013221740723,
      "rewards/rejected": -3.5931472778320312,
      "step": 1054
    },
    {
      "epoch": 0.422,
      "grad_norm": 2.2868165969848633,
      "learning_rate": 8.594666666666667e-07,
      "logits/chosen": -1.830251932144165,
      "logits/rejected": -2.579132556915283,
      "logps/chosen": -73.2260971069336,
      "logps/rejected": -98.60513305664062,
      "loss": 0.0421,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2878963947296143,
      "rewards/margins": 3.1556601524353027,
      "rewards/rejected": -1.8677635192871094,
      "step": 1055
    },
    {
      "epoch": 0.4224,
      "grad_norm": 0.5721176266670227,
      "learning_rate": 8.593333333333333e-07,
      "logits/chosen": -2.176431894302368,
      "logits/rejected": -2.892824172973633,
      "logps/chosen": -68.6796875,
      "logps/rejected": -139.64630126953125,
      "loss": 0.0082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3587801456451416,
      "rewards/margins": 5.667481899261475,
      "rewards/rejected": -2.308701753616333,
      "step": 1056
    },
    {
      "epoch": 0.4228,
      "grad_norm": 0.7164557576179504,
      "learning_rate": 8.592e-07,
      "logits/chosen": -2.4639029502868652,
      "logits/rejected": -2.7360830307006836,
      "logps/chosen": -137.86322021484375,
      "logps/rejected": -135.9775390625,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7829689979553223,
      "rewards/margins": 5.340607166290283,
      "rewards/rejected": -1.557638168334961,
      "step": 1057
    },
    {
      "epoch": 0.4232,
      "grad_norm": 0.35354557633399963,
      "learning_rate": 8.590666666666667e-07,
      "logits/chosen": -2.5472733974456787,
      "logits/rejected": -2.4406332969665527,
      "logps/chosen": -111.0505599975586,
      "logps/rejected": -138.44815063476562,
      "loss": 0.0051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2219388484954834,
      "rewards/margins": 5.462066173553467,
      "rewards/rejected": -2.2401270866394043,
      "step": 1058
    },
    {
      "epoch": 0.4236,
      "grad_norm": 15.123385429382324,
      "learning_rate": 8.589333333333332e-07,
      "logits/chosen": -2.407724380493164,
      "logits/rejected": -2.676083564758301,
      "logps/chosen": -127.70516967773438,
      "logps/rejected": -105.83023834228516,
      "loss": 0.2012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7909278869628906,
      "rewards/margins": 3.66593861579895,
      "rewards/rejected": -0.8750106692314148,
      "step": 1059
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.2358095496892929,
      "learning_rate": 8.587999999999999e-07,
      "logits/chosen": -2.317336320877075,
      "logits/rejected": -3.111237049102783,
      "logps/chosen": -146.7809295654297,
      "logps/rejected": -115.3979721069336,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.655294418334961,
      "rewards/margins": 6.485620498657227,
      "rewards/rejected": -2.8303260803222656,
      "step": 1060
    },
    {
      "epoch": 0.4244,
      "grad_norm": 0.7439464330673218,
      "learning_rate": 8.586666666666666e-07,
      "logits/chosen": -1.807145357131958,
      "logits/rejected": -2.9189205169677734,
      "logps/chosen": -90.33810424804688,
      "logps/rejected": -114.26892852783203,
      "loss": 0.0078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.851022243499756,
      "rewards/margins": 4.9897003173828125,
      "rewards/rejected": -2.1386780738830566,
      "step": 1061
    },
    {
      "epoch": 0.4248,
      "grad_norm": 0.22232294082641602,
      "learning_rate": 8.585333333333333e-07,
      "logits/chosen": -2.246076822280884,
      "logits/rejected": -2.7811970710754395,
      "logps/chosen": -91.38372802734375,
      "logps/rejected": -123.48939514160156,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1287643909454346,
      "rewards/margins": 6.072168350219727,
      "rewards/rejected": -2.943404197692871,
      "step": 1062
    },
    {
      "epoch": 0.4252,
      "grad_norm": 1.1401629447937012,
      "learning_rate": 8.584e-07,
      "logits/chosen": -2.5668554306030273,
      "logits/rejected": -2.5241141319274902,
      "logps/chosen": -107.41609191894531,
      "logps/rejected": -86.72920227050781,
      "loss": 0.0169,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2637851238250732,
      "rewards/margins": 4.230061054229736,
      "rewards/rejected": -0.9662758111953735,
      "step": 1063
    },
    {
      "epoch": 0.4256,
      "grad_norm": 0.5076568722724915,
      "learning_rate": 8.582666666666666e-07,
      "logits/chosen": -2.091930866241455,
      "logits/rejected": -3.0478124618530273,
      "logps/chosen": -96.4588851928711,
      "logps/rejected": -152.227783203125,
      "loss": 0.006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5498130321502686,
      "rewards/margins": 6.2449798583984375,
      "rewards/rejected": -2.695166826248169,
      "step": 1064
    },
    {
      "epoch": 0.426,
      "grad_norm": 0.21163614094257355,
      "learning_rate": 8.581333333333333e-07,
      "logits/chosen": -2.221522808074951,
      "logits/rejected": -2.8089733123779297,
      "logps/chosen": -212.7317657470703,
      "logps/rejected": -155.13433837890625,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.847470283508301,
      "rewards/margins": 6.443218231201172,
      "rewards/rejected": -2.595747709274292,
      "step": 1065
    },
    {
      "epoch": 0.4264,
      "grad_norm": 7.334747791290283,
      "learning_rate": 8.58e-07,
      "logits/chosen": -2.649110794067383,
      "logits/rejected": -2.462256669998169,
      "logps/chosen": -127.20831298828125,
      "logps/rejected": -103.55496978759766,
      "loss": 0.037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.266122817993164,
      "rewards/margins": 4.229646682739258,
      "rewards/rejected": -1.9635238647460938,
      "step": 1066
    },
    {
      "epoch": 0.4268,
      "grad_norm": 0.24451041221618652,
      "learning_rate": 8.578666666666667e-07,
      "logits/chosen": -1.8257848024368286,
      "logits/rejected": -3.3001034259796143,
      "logps/chosen": -95.2626724243164,
      "logps/rejected": -164.20579528808594,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.633324146270752,
      "rewards/margins": 6.856321334838867,
      "rewards/rejected": -3.2229971885681152,
      "step": 1067
    },
    {
      "epoch": 0.4272,
      "grad_norm": 0.321053683757782,
      "learning_rate": 8.577333333333333e-07,
      "logits/chosen": -2.217118740081787,
      "logits/rejected": -2.795926332473755,
      "logps/chosen": -95.13259887695312,
      "logps/rejected": -115.03752899169922,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.355823040008545,
      "rewards/margins": 5.602191925048828,
      "rewards/rejected": -2.246368885040283,
      "step": 1068
    },
    {
      "epoch": 0.4276,
      "grad_norm": 3.294461488723755,
      "learning_rate": 8.576e-07,
      "logits/chosen": -2.2409844398498535,
      "logits/rejected": -3.07949161529541,
      "logps/chosen": -99.84115600585938,
      "logps/rejected": -101.86144256591797,
      "loss": 0.0423,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6456298828125,
      "rewards/margins": 3.353598117828369,
      "rewards/rejected": -1.7079682350158691,
      "step": 1069
    },
    {
      "epoch": 0.428,
      "grad_norm": 0.6929410099983215,
      "learning_rate": 8.574666666666666e-07,
      "logits/chosen": -2.345341682434082,
      "logits/rejected": -2.798013210296631,
      "logps/chosen": -184.4403076171875,
      "logps/rejected": -137.30259704589844,
      "loss": 0.0092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5969629287719727,
      "rewards/margins": 4.709571838378906,
      "rewards/rejected": -2.1126086711883545,
      "step": 1070
    },
    {
      "epoch": 0.4284,
      "grad_norm": 1.8489277362823486,
      "learning_rate": 8.573333333333332e-07,
      "logits/chosen": -2.6333236694335938,
      "logits/rejected": -2.359539031982422,
      "logps/chosen": -89.16944885253906,
      "logps/rejected": -92.06483459472656,
      "loss": 0.0232,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.69942045211792,
      "rewards/margins": 4.575656890869141,
      "rewards/rejected": -1.8762359619140625,
      "step": 1071
    },
    {
      "epoch": 0.4288,
      "grad_norm": 2.5370335578918457,
      "learning_rate": 8.571999999999999e-07,
      "logits/chosen": -2.115504264831543,
      "logits/rejected": -2.4362316131591797,
      "logps/chosen": -89.5761489868164,
      "logps/rejected": -131.19595336914062,
      "loss": 0.0226,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.249962091445923,
      "rewards/margins": 4.5640339851379395,
      "rewards/rejected": -2.3140716552734375,
      "step": 1072
    },
    {
      "epoch": 0.4292,
      "grad_norm": 0.918662428855896,
      "learning_rate": 8.570666666666666e-07,
      "logits/chosen": -2.520446538925171,
      "logits/rejected": -3.007762908935547,
      "logps/chosen": -182.38339233398438,
      "logps/rejected": -117.82496643066406,
      "loss": 0.0097,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9232261180877686,
      "rewards/margins": 5.5662312507629395,
      "rewards/rejected": -2.643004894256592,
      "step": 1073
    },
    {
      "epoch": 0.4296,
      "grad_norm": 0.8827731609344482,
      "learning_rate": 8.569333333333333e-07,
      "logits/chosen": -2.6688125133514404,
      "logits/rejected": -2.8011248111724854,
      "logps/chosen": -120.71054077148438,
      "logps/rejected": -136.00653076171875,
      "loss": 0.0116,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8360841274261475,
      "rewards/margins": 5.1663970947265625,
      "rewards/rejected": -1.3303132057189941,
      "step": 1074
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7582102417945862,
      "learning_rate": 8.568e-07,
      "logits/chosen": -2.1982288360595703,
      "logits/rejected": -2.2585926055908203,
      "logps/chosen": -109.75997161865234,
      "logps/rejected": -84.56463623046875,
      "loss": 0.0102,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0379478931427,
      "rewards/margins": 4.749809265136719,
      "rewards/rejected": -1.7118618488311768,
      "step": 1075
    },
    {
      "epoch": 0.4304,
      "grad_norm": 3.131563186645508,
      "learning_rate": 8.566666666666667e-07,
      "logits/chosen": -2.8532533645629883,
      "logits/rejected": -3.1531333923339844,
      "logps/chosen": -123.83399200439453,
      "logps/rejected": -136.8805389404297,
      "loss": 0.0274,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2941367626190186,
      "rewards/margins": 3.800529956817627,
      "rewards/rejected": -2.5063929557800293,
      "step": 1076
    },
    {
      "epoch": 0.4308,
      "grad_norm": 1.548867106437683,
      "learning_rate": 8.565333333333334e-07,
      "logits/chosen": -2.078381299972534,
      "logits/rejected": -2.774571180343628,
      "logps/chosen": -192.83514404296875,
      "logps/rejected": -149.2393798828125,
      "loss": 0.023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7363853454589844,
      "rewards/margins": 4.303017616271973,
      "rewards/rejected": -2.5666325092315674,
      "step": 1077
    },
    {
      "epoch": 0.4312,
      "grad_norm": 1.6052085161209106,
      "learning_rate": 8.564e-07,
      "logits/chosen": -2.205402135848999,
      "logits/rejected": -1.8970744609832764,
      "logps/chosen": -81.19064331054688,
      "logps/rejected": -153.73956298828125,
      "loss": 0.0129,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.70025634765625,
      "rewards/margins": 5.469536781311035,
      "rewards/rejected": -1.769280195236206,
      "step": 1078
    },
    {
      "epoch": 0.4316,
      "grad_norm": 0.24007152020931244,
      "learning_rate": 8.562666666666666e-07,
      "logits/chosen": -2.847217082977295,
      "logits/rejected": -3.1416616439819336,
      "logps/chosen": -152.9589385986328,
      "logps/rejected": -147.30856323242188,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.579561233520508,
      "rewards/margins": 5.813570022583008,
      "rewards/rejected": -3.234008550643921,
      "step": 1079
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.6255232095718384,
      "learning_rate": 8.561333333333332e-07,
      "logits/chosen": -2.0753679275512695,
      "logits/rejected": -2.571625232696533,
      "logps/chosen": -105.03964233398438,
      "logps/rejected": -114.88285827636719,
      "loss": 0.0114,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.682335376739502,
      "rewards/margins": 4.954667091369629,
      "rewards/rejected": -3.272332191467285,
      "step": 1080
    },
    {
      "epoch": 0.4324,
      "grad_norm": 0.22378917038440704,
      "learning_rate": 8.559999999999999e-07,
      "logits/chosen": -2.327416181564331,
      "logits/rejected": -2.749472141265869,
      "logps/chosen": -97.3907470703125,
      "logps/rejected": -104.8634033203125,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.383981466293335,
      "rewards/margins": 5.962656021118164,
      "rewards/rejected": -2.578674793243408,
      "step": 1081
    },
    {
      "epoch": 0.4328,
      "grad_norm": 0.7756544947624207,
      "learning_rate": 8.558666666666666e-07,
      "logits/chosen": -1.921020269393921,
      "logits/rejected": -3.142939567565918,
      "logps/chosen": -100.47828674316406,
      "logps/rejected": -155.9392852783203,
      "loss": 0.0085,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.751030683517456,
      "rewards/margins": 5.063791275024414,
      "rewards/rejected": -3.312760591506958,
      "step": 1082
    },
    {
      "epoch": 0.4332,
      "grad_norm": 1.3847041130065918,
      "learning_rate": 8.557333333333333e-07,
      "logits/chosen": -2.2158634662628174,
      "logits/rejected": -2.9073500633239746,
      "logps/chosen": -101.46617126464844,
      "logps/rejected": -117.80259704589844,
      "loss": 0.0218,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2776870727539062,
      "rewards/margins": 4.215941429138184,
      "rewards/rejected": -2.9382545948028564,
      "step": 1083
    },
    {
      "epoch": 0.4336,
      "grad_norm": 0.09263624995946884,
      "learning_rate": 8.556e-07,
      "logits/chosen": -2.78389835357666,
      "logits/rejected": -2.7325186729431152,
      "logps/chosen": -160.85658264160156,
      "logps/rejected": -134.88101196289062,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6434340476989746,
      "rewards/margins": 6.688164710998535,
      "rewards/rejected": -3.0447304248809814,
      "step": 1084
    },
    {
      "epoch": 0.434,
      "grad_norm": 0.17434634268283844,
      "learning_rate": 8.554666666666667e-07,
      "logits/chosen": -2.107311248779297,
      "logits/rejected": -2.6622707843780518,
      "logps/chosen": -52.923240661621094,
      "logps/rejected": -146.10894775390625,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.036219596862793,
      "rewards/margins": 6.430748462677002,
      "rewards/rejected": -3.394528865814209,
      "step": 1085
    },
    {
      "epoch": 0.4344,
      "grad_norm": 0.05645950883626938,
      "learning_rate": 8.553333333333333e-07,
      "logits/chosen": -2.3404035568237305,
      "logits/rejected": -3.1907081604003906,
      "logps/chosen": -117.41790008544922,
      "logps/rejected": -152.98809814453125,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.638932228088379,
      "rewards/margins": 7.124977111816406,
      "rewards/rejected": -3.4860448837280273,
      "step": 1086
    },
    {
      "epoch": 0.4348,
      "grad_norm": 0.10671361535787582,
      "learning_rate": 8.551999999999999e-07,
      "logits/chosen": -2.464721918106079,
      "logits/rejected": -2.8000361919403076,
      "logps/chosen": -97.01878356933594,
      "logps/rejected": -124.21553039550781,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.108425140380859,
      "rewards/margins": 6.3963727951049805,
      "rewards/rejected": -2.2879478931427,
      "step": 1087
    },
    {
      "epoch": 0.4352,
      "grad_norm": 6.737219333648682,
      "learning_rate": 8.550666666666666e-07,
      "logits/chosen": -2.2321369647979736,
      "logits/rejected": -2.340667247772217,
      "logps/chosen": -123.99313354492188,
      "logps/rejected": -96.72377014160156,
      "loss": 0.0786,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7108844518661499,
      "rewards/margins": 2.583162307739258,
      "rewards/rejected": -1.8722779750823975,
      "step": 1088
    },
    {
      "epoch": 0.4356,
      "grad_norm": 1.851807951927185,
      "learning_rate": 8.549333333333333e-07,
      "logits/chosen": -2.5419938564300537,
      "logits/rejected": -3.0396385192871094,
      "logps/chosen": -110.41107940673828,
      "logps/rejected": -104.66039276123047,
      "loss": 0.0281,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7775185108184814,
      "rewards/margins": 4.837185859680176,
      "rewards/rejected": -2.0596671104431152,
      "step": 1089
    },
    {
      "epoch": 0.436,
      "grad_norm": 1.737781047821045,
      "learning_rate": 8.548e-07,
      "logits/chosen": -2.7248921394348145,
      "logits/rejected": -2.825446605682373,
      "logps/chosen": -179.17153930664062,
      "logps/rejected": -110.37579345703125,
      "loss": 0.0253,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4922752380371094,
      "rewards/margins": 3.6640920639038086,
      "rewards/rejected": -2.17181658744812,
      "step": 1090
    },
    {
      "epoch": 0.4364,
      "grad_norm": 0.10069919377565384,
      "learning_rate": 8.546666666666666e-07,
      "logits/chosen": -2.042755126953125,
      "logits/rejected": -2.8159024715423584,
      "logps/chosen": -109.11576843261719,
      "logps/rejected": -127.59162902832031,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.234628677368164,
      "rewards/margins": 6.583517074584961,
      "rewards/rejected": -3.348888397216797,
      "step": 1091
    },
    {
      "epoch": 0.4368,
      "grad_norm": 0.4729370176792145,
      "learning_rate": 8.545333333333333e-07,
      "logits/chosen": -2.171630382537842,
      "logits/rejected": -3.3117260932922363,
      "logps/chosen": -139.21099853515625,
      "logps/rejected": -160.48358154296875,
      "loss": 0.0051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.379842519760132,
      "rewards/margins": 5.890273094177246,
      "rewards/rejected": -2.5104308128356934,
      "step": 1092
    },
    {
      "epoch": 0.4372,
      "grad_norm": 0.5133698582649231,
      "learning_rate": 8.544e-07,
      "logits/chosen": -2.674499273300171,
      "logits/rejected": -3.131991147994995,
      "logps/chosen": -226.53622436523438,
      "logps/rejected": -139.2229766845703,
      "loss": 0.0063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0981571674346924,
      "rewards/margins": 5.072744846343994,
      "rewards/rejected": -2.9745876789093018,
      "step": 1093
    },
    {
      "epoch": 0.4376,
      "grad_norm": 0.3839462995529175,
      "learning_rate": 8.542666666666666e-07,
      "logits/chosen": -2.3872885704040527,
      "logits/rejected": -2.7828476428985596,
      "logps/chosen": -108.00474548339844,
      "logps/rejected": -111.68836975097656,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.453246831893921,
      "rewards/margins": 6.160912990570068,
      "rewards/rejected": -2.7076663970947266,
      "step": 1094
    },
    {
      "epoch": 0.438,
      "grad_norm": 0.4042467474937439,
      "learning_rate": 8.541333333333333e-07,
      "logits/chosen": -2.0947365760803223,
      "logits/rejected": -3.229039192199707,
      "logps/chosen": -107.07288360595703,
      "logps/rejected": -137.9056396484375,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8818717002868652,
      "rewards/margins": 5.23902702331543,
      "rewards/rejected": -3.3571553230285645,
      "step": 1095
    },
    {
      "epoch": 0.4384,
      "grad_norm": 1.0287777185440063,
      "learning_rate": 8.539999999999999e-07,
      "logits/chosen": -2.3782358169555664,
      "logits/rejected": -2.8344573974609375,
      "logps/chosen": -174.2888641357422,
      "logps/rejected": -195.4410400390625,
      "loss": 0.0077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.693862199783325,
      "rewards/margins": 5.702510833740234,
      "rewards/rejected": -3.0086488723754883,
      "step": 1096
    },
    {
      "epoch": 0.4388,
      "grad_norm": 1.636803388595581,
      "learning_rate": 8.538666666666666e-07,
      "logits/chosen": -2.3744983673095703,
      "logits/rejected": -3.39389705657959,
      "logps/chosen": -94.65951538085938,
      "logps/rejected": -138.37203979492188,
      "loss": 0.0166,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.911214828491211,
      "rewards/margins": 6.001796245574951,
      "rewards/rejected": -4.09058141708374,
      "step": 1097
    },
    {
      "epoch": 0.4392,
      "grad_norm": 0.1798582822084427,
      "learning_rate": 8.537333333333333e-07,
      "logits/chosen": -2.544304370880127,
      "logits/rejected": -2.4381203651428223,
      "logps/chosen": -114.19638061523438,
      "logps/rejected": -110.1236343383789,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5823755264282227,
      "rewards/margins": 6.073442459106445,
      "rewards/rejected": -2.4910666942596436,
      "step": 1098
    },
    {
      "epoch": 0.4396,
      "grad_norm": 0.5353990197181702,
      "learning_rate": 8.536e-07,
      "logits/chosen": -2.3258790969848633,
      "logits/rejected": -3.2343573570251465,
      "logps/chosen": -120.94692993164062,
      "logps/rejected": -96.25936889648438,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.251126766204834,
      "rewards/margins": 5.1817851066589355,
      "rewards/rejected": -1.9306581020355225,
      "step": 1099
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.976406455039978,
      "learning_rate": 8.534666666666667e-07,
      "logits/chosen": -1.996948480606079,
      "logits/rejected": -2.8538618087768555,
      "logps/chosen": -92.79177856445312,
      "logps/rejected": -105.4939956665039,
      "loss": 0.0209,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9403433799743652,
      "rewards/margins": 4.945117950439453,
      "rewards/rejected": -2.004774570465088,
      "step": 1100
    },
    {
      "epoch": 0.4404,
      "grad_norm": 2.648000478744507,
      "learning_rate": 8.533333333333334e-07,
      "logits/chosen": -2.3108439445495605,
      "logits/rejected": -2.4994449615478516,
      "logps/chosen": -91.17076110839844,
      "logps/rejected": -140.24029541015625,
      "loss": 0.0267,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.984971761703491,
      "rewards/margins": 5.16025447845459,
      "rewards/rejected": -2.1752827167510986,
      "step": 1101
    },
    {
      "epoch": 0.4408,
      "grad_norm": 1.0820717811584473,
      "learning_rate": 8.531999999999999e-07,
      "logits/chosen": -1.883169412612915,
      "logits/rejected": -3.37162184715271,
      "logps/chosen": -94.78004455566406,
      "logps/rejected": -121.77140045166016,
      "loss": 0.011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.796849489212036,
      "rewards/margins": 4.962671279907227,
      "rewards/rejected": -2.1658217906951904,
      "step": 1102
    },
    {
      "epoch": 0.4412,
      "grad_norm": 2.7143335342407227,
      "learning_rate": 8.530666666666666e-07,
      "logits/chosen": -2.635200023651123,
      "logits/rejected": -2.820204257965088,
      "logps/chosen": -174.4458770751953,
      "logps/rejected": -122.45642852783203,
      "loss": 0.0399,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.166740894317627,
      "rewards/margins": 4.382011890411377,
      "rewards/rejected": -2.21527099609375,
      "step": 1103
    },
    {
      "epoch": 0.4416,
      "grad_norm": 0.7189952731132507,
      "learning_rate": 8.529333333333333e-07,
      "logits/chosen": -2.643861770629883,
      "logits/rejected": -3.250283718109131,
      "logps/chosen": -132.66720581054688,
      "logps/rejected": -121.514404296875,
      "loss": 0.0065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.751082420349121,
      "rewards/margins": 6.2091064453125,
      "rewards/rejected": -3.458024024963379,
      "step": 1104
    },
    {
      "epoch": 0.442,
      "grad_norm": 0.2800554633140564,
      "learning_rate": 8.528e-07,
      "logits/chosen": -1.7274930477142334,
      "logits/rejected": -3.2399425506591797,
      "logps/chosen": -103.69326782226562,
      "logps/rejected": -140.18551635742188,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.895744800567627,
      "rewards/margins": 6.605001449584961,
      "rewards/rejected": -3.709256649017334,
      "step": 1105
    },
    {
      "epoch": 0.4424,
      "grad_norm": 0.45133259892463684,
      "learning_rate": 8.526666666666666e-07,
      "logits/chosen": -1.7827670574188232,
      "logits/rejected": -2.990953207015991,
      "logps/chosen": -73.2272720336914,
      "logps/rejected": -129.8207244873047,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1407604217529297,
      "rewards/margins": 5.371891975402832,
      "rewards/rejected": -3.2311315536499023,
      "step": 1106
    },
    {
      "epoch": 0.4428,
      "grad_norm": 0.14609961211681366,
      "learning_rate": 8.525333333333333e-07,
      "logits/chosen": -2.8888497352600098,
      "logits/rejected": -3.0184144973754883,
      "logps/chosen": -163.11651611328125,
      "logps/rejected": -154.51214599609375,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.759899139404297,
      "rewards/margins": 6.797417640686035,
      "rewards/rejected": -3.0375187397003174,
      "step": 1107
    },
    {
      "epoch": 0.4432,
      "grad_norm": 0.6506882309913635,
      "learning_rate": 8.524e-07,
      "logits/chosen": -2.5612003803253174,
      "logits/rejected": -2.734370231628418,
      "logps/chosen": -173.68386840820312,
      "logps/rejected": -124.51103973388672,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4555230140686035,
      "rewards/margins": 5.259701251983643,
      "rewards/rejected": -2.804178237915039,
      "step": 1108
    },
    {
      "epoch": 0.4436,
      "grad_norm": 0.6661438345909119,
      "learning_rate": 8.522666666666666e-07,
      "logits/chosen": -2.3844640254974365,
      "logits/rejected": -3.2522318363189697,
      "logps/chosen": -110.58511352539062,
      "logps/rejected": -127.77584838867188,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4325673580169678,
      "rewards/margins": 4.885494232177734,
      "rewards/rejected": -2.4529266357421875,
      "step": 1109
    },
    {
      "epoch": 0.444,
      "grad_norm": 0.5448317527770996,
      "learning_rate": 8.521333333333333e-07,
      "logits/chosen": -2.8329923152923584,
      "logits/rejected": -2.508375644683838,
      "logps/chosen": -210.68807983398438,
      "logps/rejected": -100.57522583007812,
      "loss": 0.0057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.413886308670044,
      "rewards/margins": 5.287845611572266,
      "rewards/rejected": -1.873958945274353,
      "step": 1110
    },
    {
      "epoch": 0.4444,
      "grad_norm": 0.06556960940361023,
      "learning_rate": 8.52e-07,
      "logits/chosen": -2.4599838256835938,
      "logits/rejected": -2.989429473876953,
      "logps/chosen": -162.54379272460938,
      "logps/rejected": -173.1974334716797,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9015893936157227,
      "rewards/margins": 7.2174882888793945,
      "rewards/rejected": -3.31589937210083,
      "step": 1111
    },
    {
      "epoch": 0.4448,
      "grad_norm": 1.3887356519699097,
      "learning_rate": 8.518666666666666e-07,
      "logits/chosen": -2.0164623260498047,
      "logits/rejected": -2.9316389560699463,
      "logps/chosen": -79.13898468017578,
      "logps/rejected": -129.23793029785156,
      "loss": 0.013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.368931531906128,
      "rewards/margins": 4.61474609375,
      "rewards/rejected": -2.245814085006714,
      "step": 1112
    },
    {
      "epoch": 0.4452,
      "grad_norm": 0.5753272771835327,
      "learning_rate": 8.517333333333333e-07,
      "logits/chosen": -2.343658924102783,
      "logits/rejected": -3.0720105171203613,
      "logps/chosen": -141.05923461914062,
      "logps/rejected": -132.08148193359375,
      "loss": 0.0072,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7626142501831055,
      "rewards/margins": 5.527157783508301,
      "rewards/rejected": -2.764543294906616,
      "step": 1113
    },
    {
      "epoch": 0.4456,
      "grad_norm": 1.4188882112503052,
      "learning_rate": 8.516e-07,
      "logits/chosen": -2.699547290802002,
      "logits/rejected": -3.067544937133789,
      "logps/chosen": -141.87942504882812,
      "logps/rejected": -184.014404296875,
      "loss": 0.0115,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5237298011779785,
      "rewards/margins": 5.5197882652282715,
      "rewards/rejected": -2.996058464050293,
      "step": 1114
    },
    {
      "epoch": 0.446,
      "grad_norm": 0.20880360901355743,
      "learning_rate": 8.514666666666666e-07,
      "logits/chosen": -2.182849645614624,
      "logits/rejected": -2.031435489654541,
      "logps/chosen": -105.260986328125,
      "logps/rejected": -92.39543151855469,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.080613136291504,
      "rewards/margins": 5.845173358917236,
      "rewards/rejected": -1.7645602226257324,
      "step": 1115
    },
    {
      "epoch": 0.4464,
      "grad_norm": 0.7836132049560547,
      "learning_rate": 8.513333333333333e-07,
      "logits/chosen": -2.089369773864746,
      "logits/rejected": -2.583808422088623,
      "logps/chosen": -127.85711669921875,
      "logps/rejected": -190.9218292236328,
      "loss": 0.0073,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7433395385742188,
      "rewards/margins": 4.9358367919921875,
      "rewards/rejected": -2.1924972534179688,
      "step": 1116
    },
    {
      "epoch": 0.4468,
      "grad_norm": 1.9923053979873657,
      "learning_rate": 8.511999999999999e-07,
      "logits/chosen": -2.243405342102051,
      "logits/rejected": -2.522756576538086,
      "logps/chosen": -69.70514678955078,
      "logps/rejected": -92.20932006835938,
      "loss": 0.0306,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.711275100708008,
      "rewards/margins": 4.17728328704834,
      "rewards/rejected": -1.4660084247589111,
      "step": 1117
    },
    {
      "epoch": 0.4472,
      "grad_norm": 0.13489964604377747,
      "learning_rate": 8.510666666666666e-07,
      "logits/chosen": -2.339569091796875,
      "logits/rejected": -3.143958806991577,
      "logps/chosen": -88.61891174316406,
      "logps/rejected": -145.00198364257812,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0530223846435547,
      "rewards/margins": 6.146371841430664,
      "rewards/rejected": -3.093348979949951,
      "step": 1118
    },
    {
      "epoch": 0.4476,
      "grad_norm": 1.0169668197631836,
      "learning_rate": 8.509333333333333e-07,
      "logits/chosen": -2.3133063316345215,
      "logits/rejected": -3.344860553741455,
      "logps/chosen": -148.3380126953125,
      "logps/rejected": -135.4773406982422,
      "loss": 0.0083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.581678867340088,
      "rewards/margins": 4.796196937561035,
      "rewards/rejected": -2.2145180702209473,
      "step": 1119
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.38500455021858215,
      "learning_rate": 8.508e-07,
      "logits/chosen": -2.259507656097412,
      "logits/rejected": -3.3558099269866943,
      "logps/chosen": -133.5844268798828,
      "logps/rejected": -142.02267456054688,
      "loss": 0.0056,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8005175590515137,
      "rewards/margins": 5.219730377197266,
      "rewards/rejected": -2.4192123413085938,
      "step": 1120
    },
    {
      "epoch": 0.4484,
      "grad_norm": 0.8922356367111206,
      "learning_rate": 8.506666666666667e-07,
      "logits/chosen": -2.215946674346924,
      "logits/rejected": -2.307117462158203,
      "logps/chosen": -98.13612365722656,
      "logps/rejected": -86.67184448242188,
      "loss": 0.0094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.878783702850342,
      "rewards/margins": 4.758363246917725,
      "rewards/rejected": -1.8795793056488037,
      "step": 1121
    },
    {
      "epoch": 0.4488,
      "grad_norm": 0.5108032822608948,
      "learning_rate": 8.505333333333334e-07,
      "logits/chosen": -2.5217185020446777,
      "logits/rejected": -3.0599966049194336,
      "logps/chosen": -147.31884765625,
      "logps/rejected": -129.9339599609375,
      "loss": 0.0056,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6818318367004395,
      "rewards/margins": 5.787929058074951,
      "rewards/rejected": -3.1060972213745117,
      "step": 1122
    },
    {
      "epoch": 0.4492,
      "grad_norm": 0.04669588804244995,
      "learning_rate": 8.504e-07,
      "logits/chosen": -2.0893375873565674,
      "logits/rejected": -2.7000465393066406,
      "logps/chosen": -95.3854751586914,
      "logps/rejected": -135.68026733398438,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.577230453491211,
      "rewards/margins": 7.7247161865234375,
      "rewards/rejected": -3.1474857330322266,
      "step": 1123
    },
    {
      "epoch": 0.4496,
      "grad_norm": 1.139458179473877,
      "learning_rate": 8.502666666666665e-07,
      "logits/chosen": -2.135226249694824,
      "logits/rejected": -2.2914962768554688,
      "logps/chosen": -109.92355346679688,
      "logps/rejected": -127.00242614746094,
      "loss": 0.014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9413387775421143,
      "rewards/margins": 4.901872634887695,
      "rewards/rejected": -1.960533618927002,
      "step": 1124
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.199811577796936,
      "learning_rate": 8.501333333333332e-07,
      "logits/chosen": -2.196195125579834,
      "logits/rejected": -2.6085357666015625,
      "logps/chosen": -118.02581787109375,
      "logps/rejected": -109.92259216308594,
      "loss": 0.0195,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6500252485275269,
      "rewards/margins": 4.029621124267578,
      "rewards/rejected": -2.379595994949341,
      "step": 1125
    },
    {
      "epoch": 0.4504,
      "grad_norm": 10.827905654907227,
      "learning_rate": 8.499999999999999e-07,
      "logits/chosen": -2.499717950820923,
      "logits/rejected": -2.8513894081115723,
      "logps/chosen": -170.2755584716797,
      "logps/rejected": -107.19267272949219,
      "loss": 0.146,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.594140648841858,
      "rewards/margins": 3.628974437713623,
      "rewards/rejected": -2.0348339080810547,
      "step": 1126
    },
    {
      "epoch": 0.4508,
      "grad_norm": 0.6000107526779175,
      "learning_rate": 8.498666666666666e-07,
      "logits/chosen": -2.6909713745117188,
      "logits/rejected": -3.0462474822998047,
      "logps/chosen": -167.67562866210938,
      "logps/rejected": -136.70623779296875,
      "loss": 0.0073,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4730238914489746,
      "rewards/margins": 5.644964694976807,
      "rewards/rejected": -3.171940803527832,
      "step": 1127
    },
    {
      "epoch": 0.4512,
      "grad_norm": 0.15695783495903015,
      "learning_rate": 8.497333333333333e-07,
      "logits/chosen": -1.9699122905731201,
      "logits/rejected": -2.864086151123047,
      "logps/chosen": -114.32728576660156,
      "logps/rejected": -136.81573486328125,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3921313285827637,
      "rewards/margins": 6.59895658493042,
      "rewards/rejected": -3.206824779510498,
      "step": 1128
    },
    {
      "epoch": 0.4516,
      "grad_norm": 1.1337077617645264,
      "learning_rate": 8.496e-07,
      "logits/chosen": -2.2630608081817627,
      "logits/rejected": -2.194422721862793,
      "logps/chosen": -101.43923950195312,
      "logps/rejected": -100.48216247558594,
      "loss": 0.022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9332687854766846,
      "rewards/margins": 4.053693771362305,
      "rewards/rejected": -2.120424747467041,
      "step": 1129
    },
    {
      "epoch": 0.452,
      "grad_norm": 6.556703567504883,
      "learning_rate": 8.494666666666667e-07,
      "logits/chosen": -2.105656147003174,
      "logits/rejected": -2.480259418487549,
      "logps/chosen": -79.63032531738281,
      "logps/rejected": -107.42529296875,
      "loss": 0.0805,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1125552654266357,
      "rewards/margins": 4.360153675079346,
      "rewards/rejected": -2.24759840965271,
      "step": 1130
    },
    {
      "epoch": 0.4524,
      "grad_norm": 0.6061076521873474,
      "learning_rate": 8.493333333333334e-07,
      "logits/chosen": -2.393672466278076,
      "logits/rejected": -2.8610925674438477,
      "logps/chosen": -129.62991333007812,
      "logps/rejected": -164.88833618164062,
      "loss": 0.0073,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5920257568359375,
      "rewards/margins": 5.278134346008301,
      "rewards/rejected": -2.6861085891723633,
      "step": 1131
    },
    {
      "epoch": 0.4528,
      "grad_norm": 0.25976651906967163,
      "learning_rate": 8.492e-07,
      "logits/chosen": -2.662475347518921,
      "logits/rejected": -2.736456871032715,
      "logps/chosen": -159.13638305664062,
      "logps/rejected": -135.02268981933594,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8260016441345215,
      "rewards/margins": 6.694919109344482,
      "rewards/rejected": -2.868917226791382,
      "step": 1132
    },
    {
      "epoch": 0.4532,
      "grad_norm": 5.252460956573486,
      "learning_rate": 8.490666666666666e-07,
      "logits/chosen": -2.279024600982666,
      "logits/rejected": -2.445221424102783,
      "logps/chosen": -113.11271667480469,
      "logps/rejected": -85.57432556152344,
      "loss": 0.0516,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1047582626342773,
      "rewards/margins": 3.3435020446777344,
      "rewards/rejected": -1.2387440204620361,
      "step": 1133
    },
    {
      "epoch": 0.4536,
      "grad_norm": 0.2752933204174042,
      "learning_rate": 8.489333333333332e-07,
      "logits/chosen": -2.6636781692504883,
      "logits/rejected": -2.6951756477355957,
      "logps/chosen": -155.49676513671875,
      "logps/rejected": -134.15728759765625,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5333313941955566,
      "rewards/margins": 5.6307220458984375,
      "rewards/rejected": -3.097391128540039,
      "step": 1134
    },
    {
      "epoch": 0.454,
      "grad_norm": 0.12977540493011475,
      "learning_rate": 8.487999999999999e-07,
      "logits/chosen": -1.9896297454833984,
      "logits/rejected": -2.4078941345214844,
      "logps/chosen": -76.70378112792969,
      "logps/rejected": -120.20172119140625,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6950273513793945,
      "rewards/margins": 7.338471412658691,
      "rewards/rejected": -3.643444061279297,
      "step": 1135
    },
    {
      "epoch": 0.4544,
      "grad_norm": 0.7726789712905884,
      "learning_rate": 8.486666666666666e-07,
      "logits/chosen": -2.1167359352111816,
      "logits/rejected": -3.6272077560424805,
      "logps/chosen": -158.0750274658203,
      "logps/rejected": -138.47238159179688,
      "loss": 0.0102,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2662575244903564,
      "rewards/margins": 5.187443733215332,
      "rewards/rejected": -2.9211862087249756,
      "step": 1136
    },
    {
      "epoch": 0.4548,
      "grad_norm": 0.11290790885686874,
      "learning_rate": 8.485333333333333e-07,
      "logits/chosen": -2.24194598197937,
      "logits/rejected": -2.9049971103668213,
      "logps/chosen": -100.60031127929688,
      "logps/rejected": -185.39385986328125,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.910029649734497,
      "rewards/margins": 7.028423309326172,
      "rewards/rejected": -3.118393898010254,
      "step": 1137
    },
    {
      "epoch": 0.4552,
      "grad_norm": 0.4918477237224579,
      "learning_rate": 8.484e-07,
      "logits/chosen": -2.0478553771972656,
      "logits/rejected": -2.6150598526000977,
      "logps/chosen": -117.7969741821289,
      "logps/rejected": -159.64492797851562,
      "loss": 0.0063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6489639282226562,
      "rewards/margins": 5.063536643981934,
      "rewards/rejected": -2.4145729541778564,
      "step": 1138
    },
    {
      "epoch": 0.4556,
      "grad_norm": 0.6194621920585632,
      "learning_rate": 8.482666666666666e-07,
      "logits/chosen": -2.5861072540283203,
      "logits/rejected": -2.8204762935638428,
      "logps/chosen": -110.75212097167969,
      "logps/rejected": -146.75697326660156,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7934280633926392,
      "rewards/margins": 5.680166244506836,
      "rewards/rejected": -3.8867383003234863,
      "step": 1139
    },
    {
      "epoch": 0.456,
      "grad_norm": 2.510101556777954,
      "learning_rate": 8.481333333333333e-07,
      "logits/chosen": -2.550199031829834,
      "logits/rejected": -3.050227165222168,
      "logps/chosen": -150.8756561279297,
      "logps/rejected": -109.82000732421875,
      "loss": 0.0281,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.942572832107544,
      "rewards/margins": 4.3599700927734375,
      "rewards/rejected": -2.4173970222473145,
      "step": 1140
    },
    {
      "epoch": 0.4564,
      "grad_norm": 2.8262922763824463,
      "learning_rate": 8.48e-07,
      "logits/chosen": -2.4276881217956543,
      "logits/rejected": -2.742851734161377,
      "logps/chosen": -130.339111328125,
      "logps/rejected": -131.5236358642578,
      "loss": 0.0417,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.766377329826355,
      "rewards/margins": 5.1771159172058105,
      "rewards/rejected": -3.410738468170166,
      "step": 1141
    },
    {
      "epoch": 0.4568,
      "grad_norm": 0.4586805999279022,
      "learning_rate": 8.478666666666667e-07,
      "logits/chosen": -1.9300624132156372,
      "logits/rejected": -2.806605815887451,
      "logps/chosen": -104.2266845703125,
      "logps/rejected": -154.83041381835938,
      "loss": 0.006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4462170600891113,
      "rewards/margins": 5.114471912384033,
      "rewards/rejected": -2.668254852294922,
      "step": 1142
    },
    {
      "epoch": 0.4572,
      "grad_norm": 0.11055278778076172,
      "learning_rate": 8.477333333333332e-07,
      "logits/chosen": -2.317695140838623,
      "logits/rejected": -2.9032483100891113,
      "logps/chosen": -157.4061279296875,
      "logps/rejected": -143.653564453125,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5148086547851562,
      "rewards/margins": 6.386585235595703,
      "rewards/rejected": -2.871776580810547,
      "step": 1143
    },
    {
      "epoch": 0.4576,
      "grad_norm": 0.7500808835029602,
      "learning_rate": 8.475999999999999e-07,
      "logits/chosen": -2.5145716667175293,
      "logits/rejected": -3.137063980102539,
      "logps/chosen": -236.38800048828125,
      "logps/rejected": -139.396484375,
      "loss": 0.0065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3787360191345215,
      "rewards/margins": 6.501054286956787,
      "rewards/rejected": -3.1223182678222656,
      "step": 1144
    },
    {
      "epoch": 0.458,
      "grad_norm": 0.46675992012023926,
      "learning_rate": 8.474666666666666e-07,
      "logits/chosen": -2.0599565505981445,
      "logits/rejected": -3.0669538974761963,
      "logps/chosen": -80.11166381835938,
      "logps/rejected": -126.27342224121094,
      "loss": 0.0081,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.520545244216919,
      "rewards/margins": 5.07904577255249,
      "rewards/rejected": -2.5585007667541504,
      "step": 1145
    },
    {
      "epoch": 0.4584,
      "grad_norm": 12.309978485107422,
      "learning_rate": 8.473333333333333e-07,
      "logits/chosen": -2.7432971000671387,
      "logits/rejected": -3.01263427734375,
      "logps/chosen": -175.79425048828125,
      "logps/rejected": -124.49615478515625,
      "loss": 0.1515,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9051185846328735,
      "rewards/margins": 3.451115131378174,
      "rewards/rejected": -1.5459964275360107,
      "step": 1146
    },
    {
      "epoch": 0.4588,
      "grad_norm": 0.04592454805970192,
      "learning_rate": 8.471999999999999e-07,
      "logits/chosen": -2.4583115577697754,
      "logits/rejected": -2.9823460578918457,
      "logps/chosen": -144.72161865234375,
      "logps/rejected": -129.14141845703125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.685387134552002,
      "rewards/margins": 7.6575093269348145,
      "rewards/rejected": -3.9721221923828125,
      "step": 1147
    },
    {
      "epoch": 0.4592,
      "grad_norm": 3.448596954345703,
      "learning_rate": 8.470666666666666e-07,
      "logits/chosen": -2.992314100265503,
      "logits/rejected": -2.8302149772644043,
      "logps/chosen": -161.317626953125,
      "logps/rejected": -146.96383666992188,
      "loss": 0.0326,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4269485473632812,
      "rewards/margins": 4.628419876098633,
      "rewards/rejected": -3.2014710903167725,
      "step": 1148
    },
    {
      "epoch": 0.4596,
      "grad_norm": 0.019269825890660286,
      "learning_rate": 8.469333333333333e-07,
      "logits/chosen": -2.0932514667510986,
      "logits/rejected": -2.960777759552002,
      "logps/chosen": -105.58580780029297,
      "logps/rejected": -169.58389282226562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.649229526519775,
      "rewards/margins": 8.370944023132324,
      "rewards/rejected": -3.7217140197753906,
      "step": 1149
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.017595486715435982,
      "learning_rate": 8.468e-07,
      "logits/chosen": -2.014641523361206,
      "logits/rejected": -3.038898468017578,
      "logps/chosen": -110.22096252441406,
      "logps/rejected": -149.78900146484375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.212736129760742,
      "rewards/margins": 8.414013862609863,
      "rewards/rejected": -4.201277732849121,
      "step": 1150
    },
    {
      "epoch": 0.4604,
      "grad_norm": 0.4214557111263275,
      "learning_rate": 8.466666666666667e-07,
      "logits/chosen": -2.2750205993652344,
      "logits/rejected": -3.053307056427002,
      "logps/chosen": -113.01104736328125,
      "logps/rejected": -122.62979125976562,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.248877763748169,
      "rewards/margins": 5.395477771759033,
      "rewards/rejected": -2.1466000080108643,
      "step": 1151
    },
    {
      "epoch": 0.4608,
      "grad_norm": 0.7063553333282471,
      "learning_rate": 8.465333333333334e-07,
      "logits/chosen": -2.2433218955993652,
      "logits/rejected": -2.9356775283813477,
      "logps/chosen": -144.989013671875,
      "logps/rejected": -119.98484802246094,
      "loss": 0.0063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1862518787384033,
      "rewards/margins": 5.177833557128906,
      "rewards/rejected": -2.991581439971924,
      "step": 1152
    },
    {
      "epoch": 0.4612,
      "grad_norm": 0.10768558830022812,
      "learning_rate": 8.464e-07,
      "logits/chosen": -2.376471996307373,
      "logits/rejected": -2.9173359870910645,
      "logps/chosen": -183.14218139648438,
      "logps/rejected": -125.89025115966797,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.800726890563965,
      "rewards/margins": 7.203814506530762,
      "rewards/rejected": -2.403087615966797,
      "step": 1153
    },
    {
      "epoch": 0.4616,
      "grad_norm": 0.8827125430107117,
      "learning_rate": 8.462666666666665e-07,
      "logits/chosen": -2.5063579082489014,
      "logits/rejected": -2.8143415451049805,
      "logps/chosen": -124.90799713134766,
      "logps/rejected": -118.54403686523438,
      "loss": 0.0111,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6559693813323975,
      "rewards/margins": 4.786500453948975,
      "rewards/rejected": -2.130531072616577,
      "step": 1154
    },
    {
      "epoch": 0.462,
      "grad_norm": 4.063684463500977,
      "learning_rate": 8.461333333333332e-07,
      "logits/chosen": -2.6173267364501953,
      "logits/rejected": -3.1064200401306152,
      "logps/chosen": -90.64857482910156,
      "logps/rejected": -115.82921600341797,
      "loss": 0.0625,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6565884351730347,
      "rewards/margins": 3.812235116958618,
      "rewards/rejected": -2.155646562576294,
      "step": 1155
    },
    {
      "epoch": 0.4624,
      "grad_norm": 0.13672290742397308,
      "learning_rate": 8.459999999999999e-07,
      "logits/chosen": -2.4898009300231934,
      "logits/rejected": -2.403167963027954,
      "logps/chosen": -182.73199462890625,
      "logps/rejected": -130.2166290283203,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.45760440826416,
      "rewards/margins": 6.603767395019531,
      "rewards/rejected": -3.146162986755371,
      "step": 1156
    },
    {
      "epoch": 0.4628,
      "grad_norm": 0.46217766404151917,
      "learning_rate": 8.458666666666666e-07,
      "logits/chosen": -2.57071590423584,
      "logits/rejected": -3.7738723754882812,
      "logps/chosen": -104.47767639160156,
      "logps/rejected": -196.22447204589844,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.511416435241699,
      "rewards/margins": 5.71236515045166,
      "rewards/rejected": -3.200949192047119,
      "step": 1157
    },
    {
      "epoch": 0.4632,
      "grad_norm": 0.2407529503107071,
      "learning_rate": 8.457333333333333e-07,
      "logits/chosen": -2.642123222351074,
      "logits/rejected": -2.9359047412872314,
      "logps/chosen": -153.943115234375,
      "logps/rejected": -142.24411010742188,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9767723083496094,
      "rewards/margins": 6.140717506408691,
      "rewards/rejected": -3.163945436477661,
      "step": 1158
    },
    {
      "epoch": 0.4636,
      "grad_norm": 2.8161423206329346,
      "learning_rate": 8.456e-07,
      "logits/chosen": -2.298475742340088,
      "logits/rejected": -2.5422306060791016,
      "logps/chosen": -87.82106018066406,
      "logps/rejected": -95.15751647949219,
      "loss": 0.033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0615651607513428,
      "rewards/margins": 4.733338356018066,
      "rewards/rejected": -2.6717734336853027,
      "step": 1159
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.18619439005851746,
      "learning_rate": 8.454666666666667e-07,
      "logits/chosen": -2.0719592571258545,
      "logits/rejected": -2.8126726150512695,
      "logps/chosen": -99.29428100585938,
      "logps/rejected": -119.65364074707031,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.027164936065674,
      "rewards/margins": 6.272768974304199,
      "rewards/rejected": -3.2456040382385254,
      "step": 1160
    },
    {
      "epoch": 0.4644,
      "grad_norm": 0.1448793113231659,
      "learning_rate": 8.453333333333334e-07,
      "logits/chosen": -2.599289655685425,
      "logits/rejected": -3.4117984771728516,
      "logps/chosen": -150.87379455566406,
      "logps/rejected": -147.3308563232422,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.3456926345825195,
      "rewards/margins": 6.86362361907959,
      "rewards/rejected": -2.5179309844970703,
      "step": 1161
    },
    {
      "epoch": 0.4648,
      "grad_norm": 0.4975354075431824,
      "learning_rate": 8.451999999999999e-07,
      "logits/chosen": -2.4629554748535156,
      "logits/rejected": -2.3365867137908936,
      "logps/chosen": -103.43301391601562,
      "logps/rejected": -165.15609741210938,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7326016426086426,
      "rewards/margins": 5.7535881996154785,
      "rewards/rejected": -2.020986557006836,
      "step": 1162
    },
    {
      "epoch": 0.4652,
      "grad_norm": 1.2871915102005005,
      "learning_rate": 8.450666666666666e-07,
      "logits/chosen": -2.1620981693267822,
      "logits/rejected": -3.013684034347534,
      "logps/chosen": -156.89199829101562,
      "logps/rejected": -129.11386108398438,
      "loss": 0.013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8860230445861816,
      "rewards/margins": 5.046128273010254,
      "rewards/rejected": -3.1601052284240723,
      "step": 1163
    },
    {
      "epoch": 0.4656,
      "grad_norm": 0.3215360641479492,
      "learning_rate": 8.449333333333332e-07,
      "logits/chosen": -2.4615397453308105,
      "logits/rejected": -3.270293951034546,
      "logps/chosen": -130.52145385742188,
      "logps/rejected": -149.53451538085938,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.253800868988037,
      "rewards/margins": 6.889359474182129,
      "rewards/rejected": -2.635558605194092,
      "step": 1164
    },
    {
      "epoch": 0.466,
      "grad_norm": 0.5843353271484375,
      "learning_rate": 8.447999999999999e-07,
      "logits/chosen": -2.831329822540283,
      "logits/rejected": -3.1222195625305176,
      "logps/chosen": -175.29934692382812,
      "logps/rejected": -148.191162109375,
      "loss": 0.0056,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7617005109786987,
      "rewards/margins": 5.347483158111572,
      "rewards/rejected": -3.585782527923584,
      "step": 1165
    },
    {
      "epoch": 0.4664,
      "grad_norm": 0.21941137313842773,
      "learning_rate": 8.446666666666666e-07,
      "logits/chosen": -2.951871871948242,
      "logits/rejected": -3.280423641204834,
      "logps/chosen": -178.35134887695312,
      "logps/rejected": -168.67266845703125,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3473384380340576,
      "rewards/margins": 6.153267860412598,
      "rewards/rejected": -3.805929183959961,
      "step": 1166
    },
    {
      "epoch": 0.4668,
      "grad_norm": 1.9358830451965332,
      "learning_rate": 8.445333333333333e-07,
      "logits/chosen": -2.760929584503174,
      "logits/rejected": -3.0401158332824707,
      "logps/chosen": -145.89260864257812,
      "logps/rejected": -115.45069885253906,
      "loss": 0.0346,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.029669165611267,
      "rewards/margins": 3.580923318862915,
      "rewards/rejected": -2.5512540340423584,
      "step": 1167
    },
    {
      "epoch": 0.4672,
      "grad_norm": 1.3582448959350586,
      "learning_rate": 8.444e-07,
      "logits/chosen": -2.0438148975372314,
      "logits/rejected": -3.3731460571289062,
      "logps/chosen": -100.35346984863281,
      "logps/rejected": -117.30746459960938,
      "loss": 0.0085,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3661017417907715,
      "rewards/margins": 6.089666366577148,
      "rewards/rejected": -2.7235641479492188,
      "step": 1168
    },
    {
      "epoch": 0.4676,
      "grad_norm": 0.25944092869758606,
      "learning_rate": 8.442666666666667e-07,
      "logits/chosen": -1.903259515762329,
      "logits/rejected": -2.5651941299438477,
      "logps/chosen": -102.71669006347656,
      "logps/rejected": -96.09286499023438,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.001842498779297,
      "rewards/margins": 6.618264198303223,
      "rewards/rejected": -2.6164214611053467,
      "step": 1169
    },
    {
      "epoch": 0.468,
      "grad_norm": 0.5969776511192322,
      "learning_rate": 8.441333333333333e-07,
      "logits/chosen": -2.3903446197509766,
      "logits/rejected": -2.882307529449463,
      "logps/chosen": -116.3565673828125,
      "logps/rejected": -141.780029296875,
      "loss": 0.007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.904325246810913,
      "rewards/margins": 5.314353942871094,
      "rewards/rejected": -2.4100289344787598,
      "step": 1170
    },
    {
      "epoch": 0.4684,
      "grad_norm": 1.0597867965698242,
      "learning_rate": 8.439999999999999e-07,
      "logits/chosen": -2.5407931804656982,
      "logits/rejected": -2.3986873626708984,
      "logps/chosen": -105.58880615234375,
      "logps/rejected": -136.7283935546875,
      "loss": 0.014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3950743675231934,
      "rewards/margins": 4.259861469268799,
      "rewards/rejected": -1.864786982536316,
      "step": 1171
    },
    {
      "epoch": 0.4688,
      "grad_norm": 0.5720253586769104,
      "learning_rate": 8.438666666666666e-07,
      "logits/chosen": -2.6733016967773438,
      "logits/rejected": -2.860450267791748,
      "logps/chosen": -152.62509155273438,
      "logps/rejected": -132.77198791503906,
      "loss": 0.0067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0021355152130127,
      "rewards/margins": 5.260775566101074,
      "rewards/rejected": -2.2586400508880615,
      "step": 1172
    },
    {
      "epoch": 0.4692,
      "grad_norm": 0.4218292534351349,
      "learning_rate": 8.437333333333333e-07,
      "logits/chosen": -2.2941222190856934,
      "logits/rejected": -2.6964049339294434,
      "logps/chosen": -123.28681945800781,
      "logps/rejected": -141.0786895751953,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.132497787475586,
      "rewards/margins": 5.664209365844727,
      "rewards/rejected": -2.5317115783691406,
      "step": 1173
    },
    {
      "epoch": 0.4696,
      "grad_norm": 0.32179972529411316,
      "learning_rate": 8.436e-07,
      "logits/chosen": -2.267911434173584,
      "logits/rejected": -2.867000102996826,
      "logps/chosen": -146.1827392578125,
      "logps/rejected": -166.50811767578125,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3992958068847656,
      "rewards/margins": 5.528785705566406,
      "rewards/rejected": -3.129490375518799,
      "step": 1174
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.6112672090530396,
      "learning_rate": 8.434666666666666e-07,
      "logits/chosen": -2.507005214691162,
      "logits/rejected": -2.6650550365448,
      "logps/chosen": -109.54106140136719,
      "logps/rejected": -127.32085418701172,
      "loss": 0.0246,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.82653546333313,
      "rewards/margins": 5.233706474304199,
      "rewards/rejected": -2.4071712493896484,
      "step": 1175
    },
    {
      "epoch": 0.4704,
      "grad_norm": 0.07777849584817886,
      "learning_rate": 8.433333333333333e-07,
      "logits/chosen": -2.031147003173828,
      "logits/rejected": -3.3446130752563477,
      "logps/chosen": -128.24746704101562,
      "logps/rejected": -160.94586181640625,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9450697898864746,
      "rewards/margins": 7.276190757751465,
      "rewards/rejected": -3.3311209678649902,
      "step": 1176
    },
    {
      "epoch": 0.4708,
      "grad_norm": 0.8294489979743958,
      "learning_rate": 8.431999999999999e-07,
      "logits/chosen": -1.9029947519302368,
      "logits/rejected": -2.602130889892578,
      "logps/chosen": -63.07111358642578,
      "logps/rejected": -111.23313903808594,
      "loss": 0.0128,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.284255266189575,
      "rewards/margins": 4.776678085327148,
      "rewards/rejected": -2.4924230575561523,
      "step": 1177
    },
    {
      "epoch": 0.4712,
      "grad_norm": 4.548637390136719,
      "learning_rate": 8.430666666666666e-07,
      "logits/chosen": -1.8261966705322266,
      "logits/rejected": -3.058465003967285,
      "logps/chosen": -76.66316223144531,
      "logps/rejected": -125.64129638671875,
      "loss": 0.0337,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2083258628845215,
      "rewards/margins": 4.800291061401367,
      "rewards/rejected": -2.5919647216796875,
      "step": 1178
    },
    {
      "epoch": 0.4716,
      "grad_norm": 0.7756760120391846,
      "learning_rate": 8.429333333333333e-07,
      "logits/chosen": -2.056386709213257,
      "logits/rejected": -2.5232582092285156,
      "logps/chosen": -106.92015075683594,
      "logps/rejected": -112.40935516357422,
      "loss": 0.0117,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.37890625,
      "rewards/margins": 5.260143280029297,
      "rewards/rejected": -1.8812370300292969,
      "step": 1179
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.1353921741247177,
      "learning_rate": 8.428e-07,
      "logits/chosen": -2.589928150177002,
      "logits/rejected": -3.0295729637145996,
      "logps/chosen": -170.23629760742188,
      "logps/rejected": -143.17742919921875,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.348404884338379,
      "rewards/margins": 7.10567045211792,
      "rewards/rejected": -2.757265567779541,
      "step": 1180
    },
    {
      "epoch": 0.4724,
      "grad_norm": 8.765909194946289,
      "learning_rate": 8.426666666666666e-07,
      "logits/chosen": -2.0343570709228516,
      "logits/rejected": -2.699281692504883,
      "logps/chosen": -83.68953704833984,
      "logps/rejected": -96.15296936035156,
      "loss": 0.0663,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.177600145339966,
      "rewards/margins": 3.476490020751953,
      "rewards/rejected": -1.2988899946212769,
      "step": 1181
    },
    {
      "epoch": 0.4728,
      "grad_norm": 0.16273371875286102,
      "learning_rate": 8.425333333333333e-07,
      "logits/chosen": -2.2713756561279297,
      "logits/rejected": -2.485198497772217,
      "logps/chosen": -123.56329345703125,
      "logps/rejected": -131.17596435546875,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4953103065490723,
      "rewards/margins": 6.323049545288086,
      "rewards/rejected": -2.8277392387390137,
      "step": 1182
    },
    {
      "epoch": 0.4732,
      "grad_norm": 0.1337657868862152,
      "learning_rate": 8.424e-07,
      "logits/chosen": -2.581221342086792,
      "logits/rejected": -2.5697474479675293,
      "logps/chosen": -96.93516540527344,
      "logps/rejected": -130.13064575195312,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.3872880935668945,
      "rewards/margins": 7.535483360290527,
      "rewards/rejected": -3.148195266723633,
      "step": 1183
    },
    {
      "epoch": 0.4736,
      "grad_norm": 3.7209672927856445,
      "learning_rate": 8.422666666666667e-07,
      "logits/chosen": -2.353388547897339,
      "logits/rejected": -3.090226411819458,
      "logps/chosen": -150.38380432128906,
      "logps/rejected": -126.75653076171875,
      "loss": 0.0409,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.118757724761963,
      "rewards/margins": 4.454058647155762,
      "rewards/rejected": -2.335300922393799,
      "step": 1184
    },
    {
      "epoch": 0.474,
      "grad_norm": 20.755470275878906,
      "learning_rate": 8.421333333333333e-07,
      "logits/chosen": -2.6195812225341797,
      "logits/rejected": -1.9334226846694946,
      "logps/chosen": -132.50665283203125,
      "logps/rejected": -113.37269592285156,
      "loss": 0.2195,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8268646001815796,
      "rewards/margins": 2.336430072784424,
      "rewards/rejected": -0.5095653533935547,
      "step": 1185
    },
    {
      "epoch": 0.4744,
      "grad_norm": 0.6060892343521118,
      "learning_rate": 8.419999999999999e-07,
      "logits/chosen": -2.247678756713867,
      "logits/rejected": -2.9362335205078125,
      "logps/chosen": -73.64869689941406,
      "logps/rejected": -126.2586669921875,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.351801633834839,
      "rewards/margins": 6.507011413574219,
      "rewards/rejected": -3.15520977973938,
      "step": 1186
    },
    {
      "epoch": 0.4748,
      "grad_norm": 3.060743808746338,
      "learning_rate": 8.418666666666666e-07,
      "logits/chosen": -2.5511879920959473,
      "logits/rejected": -2.9310646057128906,
      "logps/chosen": -225.5057373046875,
      "logps/rejected": -139.0279083251953,
      "loss": 0.0377,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.26756972074508667,
      "rewards/margins": 3.296445369720459,
      "rewards/rejected": -3.0288758277893066,
      "step": 1187
    },
    {
      "epoch": 0.4752,
      "grad_norm": 2.0630440711975098,
      "learning_rate": 8.417333333333333e-07,
      "logits/chosen": -2.289618492126465,
      "logits/rejected": -3.1335792541503906,
      "logps/chosen": -153.68580627441406,
      "logps/rejected": -125.50846862792969,
      "loss": 0.0319,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2194008827209473,
      "rewards/margins": 5.646770477294922,
      "rewards/rejected": -3.4273695945739746,
      "step": 1188
    },
    {
      "epoch": 0.4756,
      "grad_norm": 0.6285253763198853,
      "learning_rate": 8.416e-07,
      "logits/chosen": -2.3522725105285645,
      "logits/rejected": -2.1211018562316895,
      "logps/chosen": -82.81944274902344,
      "logps/rejected": -142.33746337890625,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.7162933349609375,
      "rewards/margins": 6.909230709075928,
      "rewards/rejected": -2.1929373741149902,
      "step": 1189
    },
    {
      "epoch": 0.476,
      "grad_norm": 1.1851170063018799,
      "learning_rate": 8.414666666666667e-07,
      "logits/chosen": -2.9530277252197266,
      "logits/rejected": -2.7992100715637207,
      "logps/chosen": -260.91412353515625,
      "logps/rejected": -179.66079711914062,
      "loss": 0.0119,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.14575651288032532,
      "rewards/margins": 4.463274002075195,
      "rewards/rejected": -4.609030246734619,
      "step": 1190
    },
    {
      "epoch": 0.4764,
      "grad_norm": 0.02943662367761135,
      "learning_rate": 8.413333333333333e-07,
      "logits/chosen": -2.3432514667510986,
      "logits/rejected": -2.962221622467041,
      "logps/chosen": -137.83253479003906,
      "logps/rejected": -133.54718017578125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.739014625549316,
      "rewards/margins": 8.09170150756836,
      "rewards/rejected": -3.352687358856201,
      "step": 1191
    },
    {
      "epoch": 0.4768,
      "grad_norm": 8.08389949798584,
      "learning_rate": 8.411999999999999e-07,
      "logits/chosen": -2.390934944152832,
      "logits/rejected": -2.7414751052856445,
      "logps/chosen": -148.64068603515625,
      "logps/rejected": -114.86204528808594,
      "loss": 0.0867,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9334877729415894,
      "rewards/margins": 3.2015371322631836,
      "rewards/rejected": -2.2680492401123047,
      "step": 1192
    },
    {
      "epoch": 0.4772,
      "grad_norm": 1.0813839435577393,
      "learning_rate": 8.410666666666666e-07,
      "logits/chosen": -2.752838611602783,
      "logits/rejected": -2.95733642578125,
      "logps/chosen": -156.5286407470703,
      "logps/rejected": -225.33218383789062,
      "loss": 0.0085,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5372871160507202,
      "rewards/margins": 4.961703300476074,
      "rewards/rejected": -3.4244165420532227,
      "step": 1193
    },
    {
      "epoch": 0.4776,
      "grad_norm": 0.11948966979980469,
      "learning_rate": 8.409333333333333e-07,
      "logits/chosen": -2.113074779510498,
      "logits/rejected": -3.169255495071411,
      "logps/chosen": -143.012939453125,
      "logps/rejected": -172.46055603027344,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.094970703125,
      "rewards/margins": 6.668266773223877,
      "rewards/rejected": -3.5732955932617188,
      "step": 1194
    },
    {
      "epoch": 0.478,
      "grad_norm": 0.2661239206790924,
      "learning_rate": 8.408e-07,
      "logits/chosen": -2.194751262664795,
      "logits/rejected": -3.014176845550537,
      "logps/chosen": -122.49471282958984,
      "logps/rejected": -164.62307739257812,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8053452968597412,
      "rewards/margins": 6.083994388580322,
      "rewards/rejected": -4.27864933013916,
      "step": 1195
    },
    {
      "epoch": 0.4784,
      "grad_norm": 0.12422382086515427,
      "learning_rate": 8.406666666666667e-07,
      "logits/chosen": -2.3080902099609375,
      "logits/rejected": -2.908843994140625,
      "logps/chosen": -205.1843719482422,
      "logps/rejected": -130.86892700195312,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3979387283325195,
      "rewards/margins": 6.508759498596191,
      "rewards/rejected": -3.11082124710083,
      "step": 1196
    },
    {
      "epoch": 0.4788,
      "grad_norm": 1.533792495727539,
      "learning_rate": 8.405333333333333e-07,
      "logits/chosen": -2.3504061698913574,
      "logits/rejected": -3.1955952644348145,
      "logps/chosen": -103.57630157470703,
      "logps/rejected": -136.47259521484375,
      "loss": 0.0201,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0682331323623657,
      "rewards/margins": 3.904694080352783,
      "rewards/rejected": -2.836460828781128,
      "step": 1197
    },
    {
      "epoch": 0.4792,
      "grad_norm": 0.12577566504478455,
      "learning_rate": 8.404e-07,
      "logits/chosen": -2.491100788116455,
      "logits/rejected": -3.1400928497314453,
      "logps/chosen": -162.61373901367188,
      "logps/rejected": -170.32260131835938,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.398423194885254,
      "rewards/margins": 6.971128940582275,
      "rewards/rejected": -3.5727059841156006,
      "step": 1198
    },
    {
      "epoch": 0.4796,
      "grad_norm": 8.248403549194336,
      "learning_rate": 8.402666666666667e-07,
      "logits/chosen": -2.4627857208251953,
      "logits/rejected": -2.2545108795166016,
      "logps/chosen": -131.65213012695312,
      "logps/rejected": -108.08197021484375,
      "loss": 0.0808,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.774747133255005,
      "rewards/margins": 4.584525108337402,
      "rewards/rejected": -0.8097778558731079,
      "step": 1199
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.8313347101211548,
      "learning_rate": 8.401333333333332e-07,
      "logits/chosen": -2.4413795471191406,
      "logits/rejected": -2.4985783100128174,
      "logps/chosen": -165.51431274414062,
      "logps/rejected": -154.7100372314453,
      "loss": 0.0091,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9753406047821045,
      "rewards/margins": 4.707734107971191,
      "rewards/rejected": -2.732393741607666,
      "step": 1200
    },
    {
      "epoch": 0.4804,
      "grad_norm": 0.864094078540802,
      "learning_rate": 8.399999999999999e-07,
      "logits/chosen": -2.5000863075256348,
      "logits/rejected": -2.9188966751098633,
      "logps/chosen": -126.50509643554688,
      "logps/rejected": -125.25178527832031,
      "loss": 0.0094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7907527685165405,
      "rewards/margins": 5.045605659484863,
      "rewards/rejected": -3.254852771759033,
      "step": 1201
    },
    {
      "epoch": 0.4808,
      "grad_norm": 1.7173006534576416,
      "learning_rate": 8.398666666666666e-07,
      "logits/chosen": -2.3865814208984375,
      "logits/rejected": -2.5846927165985107,
      "logps/chosen": -89.78297424316406,
      "logps/rejected": -123.58578491210938,
      "loss": 0.024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2752647399902344,
      "rewards/margins": 5.759117126464844,
      "rewards/rejected": -3.4838523864746094,
      "step": 1202
    },
    {
      "epoch": 0.4812,
      "grad_norm": 0.37727636098861694,
      "learning_rate": 8.397333333333333e-07,
      "logits/chosen": -2.1835544109344482,
      "logits/rejected": -2.5704402923583984,
      "logps/chosen": -118.19779968261719,
      "logps/rejected": -131.93948364257812,
      "loss": 0.0045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2767062187194824,
      "rewards/margins": 6.207159042358398,
      "rewards/rejected": -2.930452823638916,
      "step": 1203
    },
    {
      "epoch": 0.4816,
      "grad_norm": 3.2855396270751953,
      "learning_rate": 8.396e-07,
      "logits/chosen": -2.019198417663574,
      "logits/rejected": -2.7761473655700684,
      "logps/chosen": -107.55986022949219,
      "logps/rejected": -128.3523712158203,
      "loss": 0.0441,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.465740203857422,
      "rewards/margins": 5.707036018371582,
      "rewards/rejected": -3.24129581451416,
      "step": 1204
    },
    {
      "epoch": 0.482,
      "grad_norm": 0.17028848826885223,
      "learning_rate": 8.394666666666667e-07,
      "logits/chosen": -2.1560544967651367,
      "logits/rejected": -3.0692925453186035,
      "logps/chosen": -106.83025360107422,
      "logps/rejected": -161.83802795410156,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.177896976470947,
      "rewards/margins": 6.893095016479492,
      "rewards/rejected": -2.715197801589966,
      "step": 1205
    },
    {
      "epoch": 0.4824,
      "grad_norm": 0.01536295935511589,
      "learning_rate": 8.393333333333334e-07,
      "logits/chosen": -2.0692176818847656,
      "logits/rejected": -3.1160078048706055,
      "logps/chosen": -91.46197509765625,
      "logps/rejected": -155.17489624023438,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.340932846069336,
      "rewards/margins": 8.730186462402344,
      "rewards/rejected": -4.389254093170166,
      "step": 1206
    },
    {
      "epoch": 0.4828,
      "grad_norm": 0.01554353442043066,
      "learning_rate": 8.391999999999999e-07,
      "logits/chosen": -2.4079649448394775,
      "logits/rejected": -3.241044521331787,
      "logps/chosen": -109.34037780761719,
      "logps/rejected": -161.71847534179688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 5.16245174407959,
      "rewards/margins": 8.563880920410156,
      "rewards/rejected": -3.4014294147491455,
      "step": 1207
    },
    {
      "epoch": 0.4832,
      "grad_norm": 0.37114179134368896,
      "learning_rate": 8.390666666666666e-07,
      "logits/chosen": -2.288907527923584,
      "logits/rejected": -2.895434856414795,
      "logps/chosen": -89.60716247558594,
      "logps/rejected": -127.02677917480469,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3076281547546387,
      "rewards/margins": 5.940998077392578,
      "rewards/rejected": -3.6333699226379395,
      "step": 1208
    },
    {
      "epoch": 0.4836,
      "grad_norm": 0.4281388521194458,
      "learning_rate": 8.389333333333332e-07,
      "logits/chosen": -1.9060723781585693,
      "logits/rejected": -2.8146982192993164,
      "logps/chosen": -104.92884063720703,
      "logps/rejected": -123.36564636230469,
      "loss": 0.0048,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7164818048477173,
      "rewards/margins": 5.910911560058594,
      "rewards/rejected": -4.194429874420166,
      "step": 1209
    },
    {
      "epoch": 0.484,
      "grad_norm": 12.733681678771973,
      "learning_rate": 8.387999999999999e-07,
      "logits/chosen": -1.8506319522857666,
      "logits/rejected": -2.665832757949829,
      "logps/chosen": -137.03753662109375,
      "logps/rejected": -106.67172241210938,
      "loss": 0.1556,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9441696405410767,
      "rewards/margins": 4.249591827392578,
      "rewards/rejected": -2.305421829223633,
      "step": 1210
    },
    {
      "epoch": 0.4844,
      "grad_norm": 0.7403209209442139,
      "learning_rate": 8.386666666666666e-07,
      "logits/chosen": -2.575909376144409,
      "logits/rejected": -2.3683037757873535,
      "logps/chosen": -112.70210266113281,
      "logps/rejected": -114.82342529296875,
      "loss": 0.0086,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.156741142272949,
      "rewards/margins": 6.261785984039307,
      "rewards/rejected": -2.1050448417663574,
      "step": 1211
    },
    {
      "epoch": 0.4848,
      "grad_norm": 0.041260555386543274,
      "learning_rate": 8.385333333333333e-07,
      "logits/chosen": -2.496464729309082,
      "logits/rejected": -3.0362658500671387,
      "logps/chosen": -84.9457015991211,
      "logps/rejected": -134.85470581054688,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.695786714553833,
      "rewards/margins": 7.6619954109191895,
      "rewards/rejected": -4.966208457946777,
      "step": 1212
    },
    {
      "epoch": 0.4852,
      "grad_norm": 0.11188101768493652,
      "learning_rate": 8.384e-07,
      "logits/chosen": -2.4100699424743652,
      "logits/rejected": -3.0200533866882324,
      "logps/chosen": -126.1397933959961,
      "logps/rejected": -191.55174255371094,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.609606981277466,
      "rewards/margins": 7.45789909362793,
      "rewards/rejected": -3.8482918739318848,
      "step": 1213
    },
    {
      "epoch": 0.4856,
      "grad_norm": 0.11270464956760406,
      "learning_rate": 8.382666666666667e-07,
      "logits/chosen": -2.33473801612854,
      "logits/rejected": -3.005765438079834,
      "logps/chosen": -128.74142456054688,
      "logps/rejected": -132.2066650390625,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6997077465057373,
      "rewards/margins": 7.2503204345703125,
      "rewards/rejected": -3.550612688064575,
      "step": 1214
    },
    {
      "epoch": 0.486,
      "grad_norm": 0.2172701507806778,
      "learning_rate": 8.381333333333333e-07,
      "logits/chosen": -2.1197073459625244,
      "logits/rejected": -2.969508647918701,
      "logps/chosen": -103.59430694580078,
      "logps/rejected": -125.80147552490234,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.760018825531006,
      "rewards/margins": 6.393975734710693,
      "rewards/rejected": -2.6339566707611084,
      "step": 1215
    },
    {
      "epoch": 0.4864,
      "grad_norm": 0.06675176322460175,
      "learning_rate": 8.38e-07,
      "logits/chosen": -2.141291618347168,
      "logits/rejected": -3.059492826461792,
      "logps/chosen": -112.03799438476562,
      "logps/rejected": -124.1690673828125,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.455023765563965,
      "rewards/margins": 7.470606803894043,
      "rewards/rejected": -3.01558256149292,
      "step": 1216
    },
    {
      "epoch": 0.4868,
      "grad_norm": 0.18411439657211304,
      "learning_rate": 8.378666666666667e-07,
      "logits/chosen": -2.081843376159668,
      "logits/rejected": -2.9936275482177734,
      "logps/chosen": -85.55133056640625,
      "logps/rejected": -106.80574035644531,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.385904312133789,
      "rewards/margins": 6.034163475036621,
      "rewards/rejected": -2.648259401321411,
      "step": 1217
    },
    {
      "epoch": 0.4872,
      "grad_norm": 5.847512722015381,
      "learning_rate": 8.377333333333333e-07,
      "logits/chosen": -2.7802653312683105,
      "logits/rejected": -3.0509448051452637,
      "logps/chosen": -172.20028686523438,
      "logps/rejected": -121.35086822509766,
      "loss": 0.0622,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8064624667167664,
      "rewards/margins": 3.5930538177490234,
      "rewards/rejected": -2.7865915298461914,
      "step": 1218
    },
    {
      "epoch": 0.4876,
      "grad_norm": 0.15940703451633453,
      "learning_rate": 8.375999999999999e-07,
      "logits/chosen": -2.3434882164001465,
      "logits/rejected": -2.3738932609558105,
      "logps/chosen": -133.91448974609375,
      "logps/rejected": -139.06927490234375,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6721959114074707,
      "rewards/margins": 6.73552942276001,
      "rewards/rejected": -3.063333511352539,
      "step": 1219
    },
    {
      "epoch": 0.488,
      "grad_norm": 1.812208652496338,
      "learning_rate": 8.374666666666666e-07,
      "logits/chosen": -2.310214042663574,
      "logits/rejected": -2.573463201522827,
      "logps/chosen": -135.5627899169922,
      "logps/rejected": -123.12985229492188,
      "loss": 0.0214,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.156365156173706,
      "rewards/margins": 3.8897476196289062,
      "rewards/rejected": -2.7333824634552,
      "step": 1220
    },
    {
      "epoch": 0.4884,
      "grad_norm": 2.8405213356018066,
      "learning_rate": 8.373333333333333e-07,
      "logits/chosen": -2.197807788848877,
      "logits/rejected": -2.806720495223999,
      "logps/chosen": -83.82852172851562,
      "logps/rejected": -110.94308471679688,
      "loss": 0.0212,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.972353458404541,
      "rewards/margins": 4.681127548217773,
      "rewards/rejected": -2.7087738513946533,
      "step": 1221
    },
    {
      "epoch": 0.4888,
      "grad_norm": 0.9760357737541199,
      "learning_rate": 8.372e-07,
      "logits/chosen": -2.2226450443267822,
      "logits/rejected": -2.982177972793579,
      "logps/chosen": -81.6799545288086,
      "logps/rejected": -126.22441101074219,
      "loss": 0.0138,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.578070878982544,
      "rewards/margins": 5.520532131195068,
      "rewards/rejected": -2.9424610137939453,
      "step": 1222
    },
    {
      "epoch": 0.4892,
      "grad_norm": 0.5039832592010498,
      "learning_rate": 8.370666666666666e-07,
      "logits/chosen": -2.0866293907165527,
      "logits/rejected": -2.3575406074523926,
      "logps/chosen": -168.13442993164062,
      "logps/rejected": -153.00328063964844,
      "loss": 0.0049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.357501268386841,
      "rewards/margins": 5.889082908630371,
      "rewards/rejected": -2.5315818786621094,
      "step": 1223
    },
    {
      "epoch": 0.4896,
      "grad_norm": 0.30100393295288086,
      "learning_rate": 8.369333333333333e-07,
      "logits/chosen": -2.47096848487854,
      "logits/rejected": -3.195054054260254,
      "logps/chosen": -172.49240112304688,
      "logps/rejected": -135.38729858398438,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0083017349243164,
      "rewards/margins": 6.6203532218933105,
      "rewards/rejected": -3.6120517253875732,
      "step": 1224
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6229120492935181,
      "learning_rate": 8.368e-07,
      "logits/chosen": -2.5309531688690186,
      "logits/rejected": -2.974377155303955,
      "logps/chosen": -135.63656616210938,
      "logps/rejected": -121.54103088378906,
      "loss": 0.0078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6682838201522827,
      "rewards/margins": 4.853989601135254,
      "rewards/rejected": -3.1857059001922607,
      "step": 1225
    },
    {
      "epoch": 0.4904,
      "grad_norm": 1.0822880268096924,
      "learning_rate": 8.366666666666667e-07,
      "logits/chosen": -3.002941370010376,
      "logits/rejected": -3.4683375358581543,
      "logps/chosen": -189.30548095703125,
      "logps/rejected": -196.04107666015625,
      "loss": 0.0132,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5544769763946533,
      "rewards/margins": 4.943378448486328,
      "rewards/rejected": -3.388901710510254,
      "step": 1226
    },
    {
      "epoch": 0.4908,
      "grad_norm": 2.1507794857025146,
      "learning_rate": 8.365333333333334e-07,
      "logits/chosen": -2.0369839668273926,
      "logits/rejected": -2.8573412895202637,
      "logps/chosen": -117.31446075439453,
      "logps/rejected": -126.61087036132812,
      "loss": 0.0248,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5134365558624268,
      "rewards/margins": 5.160345077514648,
      "rewards/rejected": -2.646908760070801,
      "step": 1227
    },
    {
      "epoch": 0.4912,
      "grad_norm": 0.9560794830322266,
      "learning_rate": 8.363999999999999e-07,
      "logits/chosen": -2.407045364379883,
      "logits/rejected": -3.141322374343872,
      "logps/chosen": -88.63706970214844,
      "logps/rejected": -129.54971313476562,
      "loss": 0.01,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1555659770965576,
      "rewards/margins": 5.7757463455200195,
      "rewards/rejected": -2.620180606842041,
      "step": 1228
    },
    {
      "epoch": 0.4916,
      "grad_norm": 0.17881087958812714,
      "learning_rate": 8.362666666666666e-07,
      "logits/chosen": -2.279672145843506,
      "logits/rejected": -2.172370433807373,
      "logps/chosen": -86.38658142089844,
      "logps/rejected": -103.56564331054688,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.855422258377075,
      "rewards/margins": 6.250973701477051,
      "rewards/rejected": -2.3955514430999756,
      "step": 1229
    },
    {
      "epoch": 0.492,
      "grad_norm": 0.8287453055381775,
      "learning_rate": 8.361333333333332e-07,
      "logits/chosen": -2.494147777557373,
      "logits/rejected": -2.9395103454589844,
      "logps/chosen": -176.67381286621094,
      "logps/rejected": -115.49447631835938,
      "loss": 0.0097,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7864999771118164,
      "rewards/margins": 5.432002067565918,
      "rewards/rejected": -2.6455025672912598,
      "step": 1230
    },
    {
      "epoch": 0.4924,
      "grad_norm": 0.25882983207702637,
      "learning_rate": 8.359999999999999e-07,
      "logits/chosen": -2.2803049087524414,
      "logits/rejected": -3.2233195304870605,
      "logps/chosen": -186.33737182617188,
      "logps/rejected": -153.22021484375,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.300153374671936,
      "rewards/margins": 5.992100715637207,
      "rewards/rejected": -4.691946983337402,
      "step": 1231
    },
    {
      "epoch": 0.4928,
      "grad_norm": 0.2825477421283722,
      "learning_rate": 8.358666666666666e-07,
      "logits/chosen": -2.219723701477051,
      "logits/rejected": -3.224374294281006,
      "logps/chosen": -109.88778686523438,
      "logps/rejected": -141.89556884765625,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7900121212005615,
      "rewards/margins": 6.1922125816345215,
      "rewards/rejected": -3.40220046043396,
      "step": 1232
    },
    {
      "epoch": 0.4932,
      "grad_norm": 2.260103702545166,
      "learning_rate": 8.357333333333333e-07,
      "logits/chosen": -2.147211790084839,
      "logits/rejected": -2.513561248779297,
      "logps/chosen": -79.09524536132812,
      "logps/rejected": -113.74441528320312,
      "loss": 0.0273,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6255297660827637,
      "rewards/margins": 4.157587051391602,
      "rewards/rejected": -1.532057523727417,
      "step": 1233
    },
    {
      "epoch": 0.4936,
      "grad_norm": 0.29941806197166443,
      "learning_rate": 8.356e-07,
      "logits/chosen": -1.8867309093475342,
      "logits/rejected": -1.7125645875930786,
      "logps/chosen": -99.33045959472656,
      "logps/rejected": -90.87980651855469,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.380589723587036,
      "rewards/margins": 5.82426643371582,
      "rewards/rejected": -2.443676710128784,
      "step": 1234
    },
    {
      "epoch": 0.494,
      "grad_norm": 0.8298376202583313,
      "learning_rate": 8.354666666666667e-07,
      "logits/chosen": -1.9963157176971436,
      "logits/rejected": -3.2047417163848877,
      "logps/chosen": -86.64887237548828,
      "logps/rejected": -123.40201568603516,
      "loss": 0.0116,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.987196445465088,
      "rewards/margins": 4.45364236831665,
      "rewards/rejected": -2.4664459228515625,
      "step": 1235
    },
    {
      "epoch": 0.4944,
      "grad_norm": 0.48087942600250244,
      "learning_rate": 8.353333333333334e-07,
      "logits/chosen": -2.2127389907836914,
      "logits/rejected": -3.130411148071289,
      "logps/chosen": -130.96133422851562,
      "logps/rejected": -192.20199584960938,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4002976417541504,
      "rewards/margins": 6.243194580078125,
      "rewards/rejected": -2.8428966999053955,
      "step": 1236
    },
    {
      "epoch": 0.4948,
      "grad_norm": 0.6528928875923157,
      "learning_rate": 8.352000000000001e-07,
      "logits/chosen": -2.111362934112549,
      "logits/rejected": -2.98051118850708,
      "logps/chosen": -90.88801574707031,
      "logps/rejected": -169.01870727539062,
      "loss": 0.0078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.794769287109375,
      "rewards/margins": 6.961976051330566,
      "rewards/rejected": -4.167206764221191,
      "step": 1237
    },
    {
      "epoch": 0.4952,
      "grad_norm": 0.20932425558567047,
      "learning_rate": 8.350666666666665e-07,
      "logits/chosen": -2.1367688179016113,
      "logits/rejected": -3.3172550201416016,
      "logps/chosen": -97.28581237792969,
      "logps/rejected": -124.12884521484375,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.691096067428589,
      "rewards/margins": 6.35205078125,
      "rewards/rejected": -2.660954713821411,
      "step": 1238
    },
    {
      "epoch": 0.4956,
      "grad_norm": 1.0399318933486938,
      "learning_rate": 8.349333333333332e-07,
      "logits/chosen": -2.4228272438049316,
      "logits/rejected": -2.911680221557617,
      "logps/chosen": -147.008056640625,
      "logps/rejected": -120.74823760986328,
      "loss": 0.0134,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.117147922515869,
      "rewards/margins": 4.616870880126953,
      "rewards/rejected": -2.499722957611084,
      "step": 1239
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.20680472254753113,
      "learning_rate": 8.347999999999999e-07,
      "logits/chosen": -2.354222536087036,
      "logits/rejected": -3.309695243835449,
      "logps/chosen": -124.8944091796875,
      "logps/rejected": -157.36587524414062,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.004957675933838,
      "rewards/margins": 6.49143123626709,
      "rewards/rejected": -4.486473560333252,
      "step": 1240
    },
    {
      "epoch": 0.4964,
      "grad_norm": 0.2839202582836151,
      "learning_rate": 8.346666666666666e-07,
      "logits/chosen": -1.9607558250427246,
      "logits/rejected": -3.0544443130493164,
      "logps/chosen": -85.12083435058594,
      "logps/rejected": -113.65931701660156,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9200968742370605,
      "rewards/margins": 5.666479110717773,
      "rewards/rejected": -1.7463825941085815,
      "step": 1241
    },
    {
      "epoch": 0.4968,
      "grad_norm": 0.07382311671972275,
      "learning_rate": 8.345333333333333e-07,
      "logits/chosen": -2.3732008934020996,
      "logits/rejected": -2.4571421146392822,
      "logps/chosen": -70.01224517822266,
      "logps/rejected": -129.367919921875,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.931007146835327,
      "rewards/margins": 7.061123847961426,
      "rewards/rejected": -3.1301167011260986,
      "step": 1242
    },
    {
      "epoch": 0.4972,
      "grad_norm": 0.15814249217510223,
      "learning_rate": 8.344e-07,
      "logits/chosen": -1.9499075412750244,
      "logits/rejected": -3.3741724491119385,
      "logps/chosen": -124.67587280273438,
      "logps/rejected": -169.7624053955078,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4895496368408203,
      "rewards/margins": 7.373357772827148,
      "rewards/rejected": -3.88380765914917,
      "step": 1243
    },
    {
      "epoch": 0.4976,
      "grad_norm": 1.0925129652023315,
      "learning_rate": 8.342666666666667e-07,
      "logits/chosen": -2.640403985977173,
      "logits/rejected": -2.80159854888916,
      "logps/chosen": -140.50277709960938,
      "logps/rejected": -122.19766235351562,
      "loss": 0.0122,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4126884937286377,
      "rewards/margins": 4.5343217849731445,
      "rewards/rejected": -3.121633529663086,
      "step": 1244
    },
    {
      "epoch": 0.498,
      "grad_norm": 0.49004554748535156,
      "learning_rate": 8.341333333333333e-07,
      "logits/chosen": -2.1206889152526855,
      "logits/rejected": -3.004836320877075,
      "logps/chosen": -102.28132629394531,
      "logps/rejected": -157.10211181640625,
      "loss": 0.0062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.826495885848999,
      "rewards/margins": 6.836208343505859,
      "rewards/rejected": -3.0097124576568604,
      "step": 1245
    },
    {
      "epoch": 0.4984,
      "grad_norm": 0.055634912103414536,
      "learning_rate": 8.34e-07,
      "logits/chosen": -2.497620105743408,
      "logits/rejected": -3.361804485321045,
      "logps/chosen": -118.97634887695312,
      "logps/rejected": -144.75723266601562,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6014983654022217,
      "rewards/margins": 7.6058807373046875,
      "rewards/rejected": -4.004382610321045,
      "step": 1246
    },
    {
      "epoch": 0.4988,
      "grad_norm": 0.24168387055397034,
      "learning_rate": 8.338666666666666e-07,
      "logits/chosen": -2.4528005123138428,
      "logits/rejected": -2.239286422729492,
      "logps/chosen": -73.66847229003906,
      "logps/rejected": -98.86322021484375,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6750102043151855,
      "rewards/margins": 5.98013973236084,
      "rewards/rejected": -2.3051295280456543,
      "step": 1247
    },
    {
      "epoch": 0.4992,
      "grad_norm": 0.42758283019065857,
      "learning_rate": 8.337333333333333e-07,
      "logits/chosen": -2.4702296257019043,
      "logits/rejected": -2.775946855545044,
      "logps/chosen": -100.66687774658203,
      "logps/rejected": -128.64012145996094,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7257497310638428,
      "rewards/margins": 5.871822357177734,
      "rewards/rejected": -4.146072864532471,
      "step": 1248
    },
    {
      "epoch": 0.4996,
      "grad_norm": 0.8961630463600159,
      "learning_rate": 8.335999999999999e-07,
      "logits/chosen": -2.4635424613952637,
      "logits/rejected": -2.149160861968994,
      "logps/chosen": -80.24744415283203,
      "logps/rejected": -144.1299285888672,
      "loss": 0.0081,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2519619464874268,
      "rewards/margins": 4.816882610321045,
      "rewards/rejected": -2.5649209022521973,
      "step": 1249
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.1517016887664795,
      "learning_rate": 8.334666666666666e-07,
      "logits/chosen": -2.676281452178955,
      "logits/rejected": -3.1975560188293457,
      "logps/chosen": -130.20706176757812,
      "logps/rejected": -146.43988037109375,
      "loss": 0.0105,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5905739068984985,
      "rewards/margins": 4.705410957336426,
      "rewards/rejected": -3.1148369312286377,
      "step": 1250
    },
    {
      "epoch": 0.5004,
      "grad_norm": 0.050112444907426834,
      "learning_rate": 8.333333333333333e-07,
      "logits/chosen": -2.447385549545288,
      "logits/rejected": -2.7724251747131348,
      "logps/chosen": -76.14097595214844,
      "logps/rejected": -119.43571472167969,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.154806137084961,
      "rewards/margins": 7.538768291473389,
      "rewards/rejected": -3.3839619159698486,
      "step": 1251
    },
    {
      "epoch": 0.5008,
      "grad_norm": 1.5123906135559082,
      "learning_rate": 8.332e-07,
      "logits/chosen": -2.456660747528076,
      "logits/rejected": -3.052358627319336,
      "logps/chosen": -174.5110321044922,
      "logps/rejected": -135.81808471679688,
      "loss": 0.0131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.484978199005127,
      "rewards/margins": 5.515201568603516,
      "rewards/rejected": -3.0302236080169678,
      "step": 1252
    },
    {
      "epoch": 0.5012,
      "grad_norm": 0.9763529300689697,
      "learning_rate": 8.330666666666666e-07,
      "logits/chosen": -2.570453405380249,
      "logits/rejected": -3.4320168495178223,
      "logps/chosen": -116.34793853759766,
      "logps/rejected": -143.60128784179688,
      "loss": 0.0089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4694843292236328,
      "rewards/margins": 5.431690692901611,
      "rewards/rejected": -3.9622063636779785,
      "step": 1253
    },
    {
      "epoch": 0.5016,
      "grad_norm": 2.013646125793457,
      "learning_rate": 8.329333333333333e-07,
      "logits/chosen": -1.7194437980651855,
      "logits/rejected": -3.129237174987793,
      "logps/chosen": -85.72981262207031,
      "logps/rejected": -119.15008544921875,
      "loss": 0.0112,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1667404174804688,
      "rewards/margins": 4.916688919067383,
      "rewards/rejected": -2.749948501586914,
      "step": 1254
    },
    {
      "epoch": 0.502,
      "grad_norm": 3.621666193008423,
      "learning_rate": 8.328e-07,
      "logits/chosen": -1.974958896636963,
      "logits/rejected": -2.3376305103302,
      "logps/chosen": -98.02134704589844,
      "logps/rejected": -97.42698669433594,
      "loss": 0.0696,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0859057903289795,
      "rewards/margins": 3.6125404834747314,
      "rewards/rejected": -2.526634693145752,
      "step": 1255
    },
    {
      "epoch": 0.5024,
      "grad_norm": 0.11424964666366577,
      "learning_rate": 8.326666666666666e-07,
      "logits/chosen": -2.027514696121216,
      "logits/rejected": -2.95833420753479,
      "logps/chosen": -156.11065673828125,
      "logps/rejected": -175.28900146484375,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.909834861755371,
      "rewards/margins": 6.995649337768555,
      "rewards/rejected": -3.0858147144317627,
      "step": 1256
    },
    {
      "epoch": 0.5028,
      "grad_norm": 0.37878158688545227,
      "learning_rate": 8.325333333333333e-07,
      "logits/chosen": -2.0313737392425537,
      "logits/rejected": -3.669679880142212,
      "logps/chosen": -89.28863525390625,
      "logps/rejected": -151.1627197265625,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5048255920410156,
      "rewards/margins": 7.08597469329834,
      "rewards/rejected": -4.581149101257324,
      "step": 1257
    },
    {
      "epoch": 0.5032,
      "grad_norm": 0.2981053590774536,
      "learning_rate": 8.324e-07,
      "logits/chosen": -2.257173776626587,
      "logits/rejected": -3.317039966583252,
      "logps/chosen": -131.87213134765625,
      "logps/rejected": -158.91098022460938,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.610464572906494,
      "rewards/margins": 6.5067138671875,
      "rewards/rejected": -3.896249532699585,
      "step": 1258
    },
    {
      "epoch": 0.5036,
      "grad_norm": 0.45224568247795105,
      "learning_rate": 8.322666666666667e-07,
      "logits/chosen": -2.3931725025177,
      "logits/rejected": -3.042015790939331,
      "logps/chosen": -104.52590942382812,
      "logps/rejected": -128.7017059326172,
      "loss": 0.0051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2803890705108643,
      "rewards/margins": 5.362212181091309,
      "rewards/rejected": -4.081823348999023,
      "step": 1259
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.7406005263328552,
      "learning_rate": 8.321333333333332e-07,
      "logits/chosen": -2.6364598274230957,
      "logits/rejected": -3.1029932498931885,
      "logps/chosen": -169.8434600830078,
      "logps/rejected": -140.3264617919922,
      "loss": 0.0094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.088045597076416,
      "rewards/margins": 4.669247627258301,
      "rewards/rejected": -2.581202268600464,
      "step": 1260
    },
    {
      "epoch": 0.5044,
      "grad_norm": 1.0830801725387573,
      "learning_rate": 8.319999999999999e-07,
      "logits/chosen": -2.5240726470947266,
      "logits/rejected": -2.971282720565796,
      "logps/chosen": -144.43441772460938,
      "logps/rejected": -170.8912811279297,
      "loss": 0.0106,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0818276405334473,
      "rewards/margins": 5.270963668823242,
      "rewards/rejected": -3.189135789871216,
      "step": 1261
    },
    {
      "epoch": 0.5048,
      "grad_norm": 0.5701231360435486,
      "learning_rate": 8.318666666666666e-07,
      "logits/chosen": -2.202529191970825,
      "logits/rejected": -2.353672981262207,
      "logps/chosen": -113.52902221679688,
      "logps/rejected": -101.05123901367188,
      "loss": 0.0102,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0861618518829346,
      "rewards/margins": 4.751427173614502,
      "rewards/rejected": -2.6652653217315674,
      "step": 1262
    },
    {
      "epoch": 0.5052,
      "grad_norm": 0.7973072528839111,
      "learning_rate": 8.317333333333333e-07,
      "logits/chosen": -2.3946890830993652,
      "logits/rejected": -3.19399356842041,
      "logps/chosen": -126.68939208984375,
      "logps/rejected": -156.64651489257812,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9681196212768555,
      "rewards/margins": 5.4362945556640625,
      "rewards/rejected": -2.468175172805786,
      "step": 1263
    },
    {
      "epoch": 0.5056,
      "grad_norm": 0.6933305263519287,
      "learning_rate": 8.316e-07,
      "logits/chosen": -2.2964019775390625,
      "logits/rejected": -2.8997292518615723,
      "logps/chosen": -63.65898132324219,
      "logps/rejected": -116.5440902709961,
      "loss": 0.0119,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.062952756881714,
      "rewards/margins": 4.425601959228516,
      "rewards/rejected": -2.362649440765381,
      "step": 1264
    },
    {
      "epoch": 0.506,
      "grad_norm": 0.14170874655246735,
      "learning_rate": 8.314666666666667e-07,
      "logits/chosen": -2.4059133529663086,
      "logits/rejected": -3.3612289428710938,
      "logps/chosen": -134.9783477783203,
      "logps/rejected": -138.4615936279297,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5875110626220703,
      "rewards/margins": 6.4832305908203125,
      "rewards/rejected": -3.895719528198242,
      "step": 1265
    },
    {
      "epoch": 0.5064,
      "grad_norm": 0.8568979501724243,
      "learning_rate": 8.313333333333333e-07,
      "logits/chosen": -2.3201985359191895,
      "logits/rejected": -2.9009222984313965,
      "logps/chosen": -147.24295043945312,
      "logps/rejected": -130.29324340820312,
      "loss": 0.0106,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9694794416427612,
      "rewards/margins": 4.640720367431641,
      "rewards/rejected": -3.671241044998169,
      "step": 1266
    },
    {
      "epoch": 0.5068,
      "grad_norm": 0.07618732005357742,
      "learning_rate": 8.312e-07,
      "logits/chosen": -2.443554401397705,
      "logits/rejected": -3.0268702507019043,
      "logps/chosen": -104.55006408691406,
      "logps/rejected": -165.7503204345703,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.116328239440918,
      "rewards/margins": 7.232289791107178,
      "rewards/rejected": -3.1159615516662598,
      "step": 1267
    },
    {
      "epoch": 0.5072,
      "grad_norm": 1.1745954751968384,
      "learning_rate": 8.310666666666666e-07,
      "logits/chosen": -2.4875833988189697,
      "logits/rejected": -2.7131333351135254,
      "logps/chosen": -113.2845230102539,
      "logps/rejected": -94.62452697753906,
      "loss": 0.0152,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5360610485076904,
      "rewards/margins": 4.285592079162598,
      "rewards/rejected": -1.7495307922363281,
      "step": 1268
    },
    {
      "epoch": 0.5076,
      "grad_norm": 0.5092080235481262,
      "learning_rate": 8.309333333333333e-07,
      "logits/chosen": -2.3304638862609863,
      "logits/rejected": -2.6454272270202637,
      "logps/chosen": -115.101806640625,
      "logps/rejected": -166.76800537109375,
      "loss": 0.0052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3255410194396973,
      "rewards/margins": 5.343541622161865,
      "rewards/rejected": -3.018000602722168,
      "step": 1269
    },
    {
      "epoch": 0.508,
      "grad_norm": 18.661401748657227,
      "learning_rate": 8.308e-07,
      "logits/chosen": -2.215064764022827,
      "logits/rejected": -2.4655542373657227,
      "logps/chosen": -94.959228515625,
      "logps/rejected": -93.80792236328125,
      "loss": 0.2423,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6705868244171143,
      "rewards/margins": 4.075664043426514,
      "rewards/rejected": -1.4050769805908203,
      "step": 1270
    },
    {
      "epoch": 0.5084,
      "grad_norm": 1.5211105346679688,
      "learning_rate": 8.306666666666666e-07,
      "logits/chosen": -2.119194984436035,
      "logits/rejected": -2.2537546157836914,
      "logps/chosen": -104.94819641113281,
      "logps/rejected": -112.74757385253906,
      "loss": 0.0241,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4431099891662598,
      "rewards/margins": 5.227058410644531,
      "rewards/rejected": -1.783948540687561,
      "step": 1271
    },
    {
      "epoch": 0.5088,
      "grad_norm": 5.151634216308594,
      "learning_rate": 8.305333333333333e-07,
      "logits/chosen": -2.5159618854522705,
      "logits/rejected": -3.123335361480713,
      "logps/chosen": -129.87051391601562,
      "logps/rejected": -155.28164672851562,
      "loss": 0.0456,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9986705780029297,
      "rewards/margins": 5.738535404205322,
      "rewards/rejected": -3.7398648262023926,
      "step": 1272
    },
    {
      "epoch": 0.5092,
      "grad_norm": 0.6200929880142212,
      "learning_rate": 8.304e-07,
      "logits/chosen": -2.187171697616577,
      "logits/rejected": -3.307765245437622,
      "logps/chosen": -101.25990295410156,
      "logps/rejected": -142.92132568359375,
      "loss": 0.0057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3367061614990234,
      "rewards/margins": 5.8284783363342285,
      "rewards/rejected": -4.491772174835205,
      "step": 1273
    },
    {
      "epoch": 0.5096,
      "grad_norm": 0.11065883934497833,
      "learning_rate": 8.302666666666667e-07,
      "logits/chosen": -2.155651807785034,
      "logits/rejected": -3.362438678741455,
      "logps/chosen": -136.66061401367188,
      "logps/rejected": -145.61178588867188,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2807507514953613,
      "rewards/margins": 6.6153669357299805,
      "rewards/rejected": -3.334616184234619,
      "step": 1274
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.28462880849838257,
      "learning_rate": 8.301333333333332e-07,
      "logits/chosen": -2.107011318206787,
      "logits/rejected": -2.7680892944335938,
      "logps/chosen": -83.25334930419922,
      "logps/rejected": -114.59144592285156,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.392117977142334,
      "rewards/margins": 5.586739540100098,
      "rewards/rejected": -3.1946215629577637,
      "step": 1275
    },
    {
      "epoch": 0.5104,
      "grad_norm": 0.18897385895252228,
      "learning_rate": 8.299999999999999e-07,
      "logits/chosen": -2.1114678382873535,
      "logits/rejected": -3.162687301635742,
      "logps/chosen": -83.29129028320312,
      "logps/rejected": -147.98529052734375,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.0999531745910645,
      "rewards/margins": 7.054199695587158,
      "rewards/rejected": -2.9542465209960938,
      "step": 1276
    },
    {
      "epoch": 0.5108,
      "grad_norm": 0.1776031106710434,
      "learning_rate": 8.298666666666666e-07,
      "logits/chosen": -2.1987602710723877,
      "logits/rejected": -3.3145623207092285,
      "logps/chosen": -88.66625213623047,
      "logps/rejected": -172.04635620117188,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2730093002319336,
      "rewards/margins": 6.989470481872559,
      "rewards/rejected": -3.716461658477783,
      "step": 1277
    },
    {
      "epoch": 0.5112,
      "grad_norm": 0.09824801236391068,
      "learning_rate": 8.297333333333333e-07,
      "logits/chosen": -2.451274871826172,
      "logits/rejected": -2.6376729011535645,
      "logps/chosen": -183.75148010253906,
      "logps/rejected": -154.8017578125,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7691736221313477,
      "rewards/margins": 7.390280246734619,
      "rewards/rejected": -3.6211066246032715,
      "step": 1278
    },
    {
      "epoch": 0.5116,
      "grad_norm": 2.3704562187194824,
      "learning_rate": 8.296e-07,
      "logits/chosen": -1.9810190200805664,
      "logits/rejected": -3.132857084274292,
      "logps/chosen": -103.10258483886719,
      "logps/rejected": -117.77074432373047,
      "loss": 0.031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2357220649719238,
      "rewards/margins": 5.048701286315918,
      "rewards/rejected": -3.812979221343994,
      "step": 1279
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.19456715881824493,
      "learning_rate": 8.294666666666667e-07,
      "logits/chosen": -2.7976512908935547,
      "logits/rejected": -2.751817226409912,
      "logps/chosen": -89.78753662109375,
      "logps/rejected": -131.95777893066406,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9385533332824707,
      "rewards/margins": 6.201714515686035,
      "rewards/rejected": -3.2631614208221436,
      "step": 1280
    },
    {
      "epoch": 0.5124,
      "grad_norm": 1.0948535203933716,
      "learning_rate": 8.293333333333333e-07,
      "logits/chosen": -2.627387046813965,
      "logits/rejected": -3.10384464263916,
      "logps/chosen": -121.3003158569336,
      "logps/rejected": -126.82774353027344,
      "loss": 0.0108,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8414589166641235,
      "rewards/margins": 4.945775985717773,
      "rewards/rejected": -4.1043171882629395,
      "step": 1281
    },
    {
      "epoch": 0.5128,
      "grad_norm": 0.3177645802497864,
      "learning_rate": 8.292e-07,
      "logits/chosen": -1.994201421737671,
      "logits/rejected": -3.1043319702148438,
      "logps/chosen": -125.22270202636719,
      "logps/rejected": -122.93045043945312,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2631826400756836,
      "rewards/margins": 5.372437000274658,
      "rewards/rejected": -3.1092545986175537,
      "step": 1282
    },
    {
      "epoch": 0.5132,
      "grad_norm": 1.0246137380599976,
      "learning_rate": 8.290666666666666e-07,
      "logits/chosen": -2.34373140335083,
      "logits/rejected": -2.8508639335632324,
      "logps/chosen": -106.0748291015625,
      "logps/rejected": -153.2535400390625,
      "loss": 0.0117,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9406704902648926,
      "rewards/margins": 5.852156162261963,
      "rewards/rejected": -3.9114856719970703,
      "step": 1283
    },
    {
      "epoch": 0.5136,
      "grad_norm": 0.06711193919181824,
      "learning_rate": 8.289333333333332e-07,
      "logits/chosen": -2.0497593879699707,
      "logits/rejected": -2.6351914405822754,
      "logps/chosen": -111.89932250976562,
      "logps/rejected": -127.31898498535156,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.04343843460083,
      "rewards/margins": 7.045785903930664,
      "rewards/rejected": -3.002347230911255,
      "step": 1284
    },
    {
      "epoch": 0.514,
      "grad_norm": 6.134422302246094,
      "learning_rate": 8.287999999999999e-07,
      "logits/chosen": -2.515855312347412,
      "logits/rejected": -3.4972739219665527,
      "logps/chosen": -121.10094451904297,
      "logps/rejected": -130.8553009033203,
      "loss": 0.0884,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7476356625556946,
      "rewards/margins": 3.426823616027832,
      "rewards/rejected": -2.679187774658203,
      "step": 1285
    },
    {
      "epoch": 0.5144,
      "grad_norm": 1.5961085557937622,
      "learning_rate": 8.286666666666666e-07,
      "logits/chosen": -2.7860212326049805,
      "logits/rejected": -2.86091947555542,
      "logps/chosen": -129.09332275390625,
      "logps/rejected": -166.32778930664062,
      "loss": 0.0114,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1831891536712646,
      "rewards/margins": 5.539083957672119,
      "rewards/rejected": -3.3558950424194336,
      "step": 1286
    },
    {
      "epoch": 0.5148,
      "grad_norm": 4.268334865570068,
      "learning_rate": 8.285333333333333e-07,
      "logits/chosen": -2.5700106620788574,
      "logits/rejected": -3.4671640396118164,
      "logps/chosen": -174.08224487304688,
      "logps/rejected": -133.61007690429688,
      "loss": 0.0463,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7507064938545227,
      "rewards/margins": 3.1828513145446777,
      "rewards/rejected": -3.9335575103759766,
      "step": 1287
    },
    {
      "epoch": 0.5152,
      "grad_norm": 0.16779853403568268,
      "learning_rate": 8.284e-07,
      "logits/chosen": -2.1299829483032227,
      "logits/rejected": -2.516303539276123,
      "logps/chosen": -102.18936157226562,
      "logps/rejected": -127.63648223876953,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.1675848960876465,
      "rewards/margins": 7.144835472106934,
      "rewards/rejected": -2.977250576019287,
      "step": 1288
    },
    {
      "epoch": 0.5156,
      "grad_norm": 0.036496393382549286,
      "learning_rate": 8.282666666666667e-07,
      "logits/chosen": -2.282072067260742,
      "logits/rejected": -3.0978894233703613,
      "logps/chosen": -155.00868225097656,
      "logps/rejected": -142.22811889648438,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.148282051086426,
      "rewards/margins": 7.837909698486328,
      "rewards/rejected": -4.689627647399902,
      "step": 1289
    },
    {
      "epoch": 0.516,
      "grad_norm": 0.35642769932746887,
      "learning_rate": 8.281333333333334e-07,
      "logits/chosen": -2.0576515197753906,
      "logits/rejected": -3.026160955429077,
      "logps/chosen": -108.52674102783203,
      "logps/rejected": -137.23355102539062,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0537288188934326,
      "rewards/margins": 6.085196495056152,
      "rewards/rejected": -4.031467437744141,
      "step": 1290
    },
    {
      "epoch": 0.5164,
      "grad_norm": 1.4124279022216797,
      "learning_rate": 8.28e-07,
      "logits/chosen": -2.479128837585449,
      "logits/rejected": -3.2752225399017334,
      "logps/chosen": -89.91690063476562,
      "logps/rejected": -147.1763458251953,
      "loss": 0.0127,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7563294172286987,
      "rewards/margins": 4.8582868576049805,
      "rewards/rejected": -3.101957321166992,
      "step": 1291
    },
    {
      "epoch": 0.5168,
      "grad_norm": 0.024303879588842392,
      "learning_rate": 8.278666666666666e-07,
      "logits/chosen": -2.23960542678833,
      "logits/rejected": -3.293578863143921,
      "logps/chosen": -104.90815734863281,
      "logps/rejected": -153.95213317871094,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7755117416381836,
      "rewards/margins": 8.234973907470703,
      "rewards/rejected": -4.459462642669678,
      "step": 1292
    },
    {
      "epoch": 0.5172,
      "grad_norm": 0.1593656688928604,
      "learning_rate": 8.277333333333333e-07,
      "logits/chosen": -2.1984734535217285,
      "logits/rejected": -3.2617201805114746,
      "logps/chosen": -156.60939025878906,
      "logps/rejected": -128.86279296875,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.421222686767578,
      "rewards/margins": 6.504275798797607,
      "rewards/rejected": -3.08305287361145,
      "step": 1293
    },
    {
      "epoch": 0.5176,
      "grad_norm": 4.555875778198242,
      "learning_rate": 8.275999999999999e-07,
      "logits/chosen": -2.033501625061035,
      "logits/rejected": -2.1745898723602295,
      "logps/chosen": -126.07547760009766,
      "logps/rejected": -128.75990295410156,
      "loss": 0.0423,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5803205966949463,
      "rewards/margins": 5.3385701179504395,
      "rewards/rejected": -2.758249282836914,
      "step": 1294
    },
    {
      "epoch": 0.518,
      "grad_norm": 0.2948347330093384,
      "learning_rate": 8.274666666666666e-07,
      "logits/chosen": -2.7269206047058105,
      "logits/rejected": -2.914405107498169,
      "logps/chosen": -154.3231201171875,
      "logps/rejected": -138.9078369140625,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.859243869781494,
      "rewards/margins": 6.5763092041015625,
      "rewards/rejected": -3.7170655727386475,
      "step": 1295
    },
    {
      "epoch": 0.5184,
      "grad_norm": 0.16230928897857666,
      "learning_rate": 8.273333333333333e-07,
      "logits/chosen": -2.290898084640503,
      "logits/rejected": -3.550358295440674,
      "logps/chosen": -111.14788818359375,
      "logps/rejected": -193.9827880859375,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5493078231811523,
      "rewards/margins": 6.742731094360352,
      "rewards/rejected": -3.1934235095977783,
      "step": 1296
    },
    {
      "epoch": 0.5188,
      "grad_norm": 0.4882347583770752,
      "learning_rate": 8.272e-07,
      "logits/chosen": -2.495490074157715,
      "logits/rejected": -3.221627712249756,
      "logps/chosen": -90.35444641113281,
      "logps/rejected": -152.2492218017578,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.875162124633789,
      "rewards/margins": 5.557273864746094,
      "rewards/rejected": -3.682112216949463,
      "step": 1297
    },
    {
      "epoch": 0.5192,
      "grad_norm": 0.1908750981092453,
      "learning_rate": 8.270666666666666e-07,
      "logits/chosen": -2.409113883972168,
      "logits/rejected": -2.9491565227508545,
      "logps/chosen": -126.30908966064453,
      "logps/rejected": -231.99026489257812,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6683969497680664,
      "rewards/margins": 7.310066223144531,
      "rewards/rejected": -3.641669511795044,
      "step": 1298
    },
    {
      "epoch": 0.5196,
      "grad_norm": 0.08332928270101547,
      "learning_rate": 8.269333333333333e-07,
      "logits/chosen": -2.2500405311584473,
      "logits/rejected": -3.0832629203796387,
      "logps/chosen": -114.58883666992188,
      "logps/rejected": -146.8128662109375,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.273374080657959,
      "rewards/margins": 7.038362503051758,
      "rewards/rejected": -3.7649879455566406,
      "step": 1299
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.18386846780776978,
      "learning_rate": 8.268e-07,
      "logits/chosen": -2.567660331726074,
      "logits/rejected": -2.77705717086792,
      "logps/chosen": -129.0362548828125,
      "logps/rejected": -151.7320556640625,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6495959758758545,
      "rewards/margins": 6.338932991027832,
      "rewards/rejected": -3.6893372535705566,
      "step": 1300
    },
    {
      "epoch": 0.5204,
      "grad_norm": 0.04337890073657036,
      "learning_rate": 8.266666666666667e-07,
      "logits/chosen": -2.4303669929504395,
      "logits/rejected": -3.420424461364746,
      "logps/chosen": -186.58499145507812,
      "logps/rejected": -143.89971923828125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.862851619720459,
      "rewards/margins": 7.640806674957275,
      "rewards/rejected": -3.7779550552368164,
      "step": 1301
    },
    {
      "epoch": 0.5208,
      "grad_norm": 0.15924319624900818,
      "learning_rate": 8.265333333333333e-07,
      "logits/chosen": -1.8579730987548828,
      "logits/rejected": -3.034221649169922,
      "logps/chosen": -70.36038970947266,
      "logps/rejected": -139.32603454589844,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.817974328994751,
      "rewards/margins": 6.454792022705078,
      "rewards/rejected": -3.636817693710327,
      "step": 1302
    },
    {
      "epoch": 0.5212,
      "grad_norm": 0.40316447615623474,
      "learning_rate": 8.263999999999999e-07,
      "logits/chosen": -2.32204532623291,
      "logits/rejected": -3.0069925785064697,
      "logps/chosen": -122.36856842041016,
      "logps/rejected": -148.60748291015625,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.107769012451172,
      "rewards/margins": 6.3983917236328125,
      "rewards/rejected": -3.2906222343444824,
      "step": 1303
    },
    {
      "epoch": 0.5216,
      "grad_norm": 0.3909183144569397,
      "learning_rate": 8.262666666666666e-07,
      "logits/chosen": -2.6809580326080322,
      "logits/rejected": -3.532278060913086,
      "logps/chosen": -126.20773315429688,
      "logps/rejected": -159.58010864257812,
      "loss": 0.0052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.18339309096336365,
      "rewards/margins": 5.25493049621582,
      "rewards/rejected": -5.438323020935059,
      "step": 1304
    },
    {
      "epoch": 0.522,
      "grad_norm": 2.25710391998291,
      "learning_rate": 8.261333333333333e-07,
      "logits/chosen": -2.131713390350342,
      "logits/rejected": -2.711003541946411,
      "logps/chosen": -104.65315246582031,
      "logps/rejected": -154.55801391601562,
      "loss": 0.0301,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2656636238098145,
      "rewards/margins": 4.906295299530029,
      "rewards/rejected": -2.640631914138794,
      "step": 1305
    },
    {
      "epoch": 0.5224,
      "grad_norm": 0.2883557677268982,
      "learning_rate": 8.259999999999999e-07,
      "logits/chosen": -2.699509859085083,
      "logits/rejected": -2.974609136581421,
      "logps/chosen": -143.09146118164062,
      "logps/rejected": -142.63153076171875,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.20089054107666,
      "rewards/margins": 7.398258686065674,
      "rewards/rejected": -3.1973679065704346,
      "step": 1306
    },
    {
      "epoch": 0.5228,
      "grad_norm": 0.5871666073799133,
      "learning_rate": 8.258666666666666e-07,
      "logits/chosen": -2.552638530731201,
      "logits/rejected": -3.2953948974609375,
      "logps/chosen": -182.39651489257812,
      "logps/rejected": -126.7783203125,
      "loss": 0.006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5665626525878906,
      "rewards/margins": 5.574920177459717,
      "rewards/rejected": -3.008357286453247,
      "step": 1307
    },
    {
      "epoch": 0.5232,
      "grad_norm": 0.07304667681455612,
      "learning_rate": 8.257333333333333e-07,
      "logits/chosen": -2.437375068664551,
      "logits/rejected": -3.2042582035064697,
      "logps/chosen": -82.31475830078125,
      "logps/rejected": -157.8261260986328,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4264333248138428,
      "rewards/margins": 7.599878787994385,
      "rewards/rejected": -5.173445701599121,
      "step": 1308
    },
    {
      "epoch": 0.5236,
      "grad_norm": 0.999708354473114,
      "learning_rate": 8.256e-07,
      "logits/chosen": -1.693085789680481,
      "logits/rejected": -3.0305819511413574,
      "logps/chosen": -94.58738708496094,
      "logps/rejected": -159.05368041992188,
      "loss": 0.0081,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5775058269500732,
      "rewards/margins": 6.068147659301758,
      "rewards/rejected": -3.4906420707702637,
      "step": 1309
    },
    {
      "epoch": 0.524,
      "grad_norm": 0.2705634534358978,
      "learning_rate": 8.254666666666667e-07,
      "logits/chosen": -2.447718381881714,
      "logits/rejected": -3.224684715270996,
      "logps/chosen": -73.17884063720703,
      "logps/rejected": -140.7873077392578,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4637928009033203,
      "rewards/margins": 5.659445285797119,
      "rewards/rejected": -3.195652484893799,
      "step": 1310
    },
    {
      "epoch": 0.5244,
      "grad_norm": 0.09511527419090271,
      "learning_rate": 8.253333333333334e-07,
      "logits/chosen": -2.092543601989746,
      "logits/rejected": -2.3824918270111084,
      "logps/chosen": -100.54585266113281,
      "logps/rejected": -130.26287841796875,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.366461277008057,
      "rewards/margins": 7.562255382537842,
      "rewards/rejected": -3.1957945823669434,
      "step": 1311
    },
    {
      "epoch": 0.5248,
      "grad_norm": 0.1566864550113678,
      "learning_rate": 8.252000000000001e-07,
      "logits/chosen": -2.3638346195220947,
      "logits/rejected": -2.890626907348633,
      "logps/chosen": -73.01896667480469,
      "logps/rejected": -122.89269256591797,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.999235153198242,
      "rewards/margins": 6.307770729064941,
      "rewards/rejected": -2.3085358142852783,
      "step": 1312
    },
    {
      "epoch": 0.5252,
      "grad_norm": 0.1714099496603012,
      "learning_rate": 8.250666666666665e-07,
      "logits/chosen": -2.3920087814331055,
      "logits/rejected": -2.568953037261963,
      "logps/chosen": -112.77333068847656,
      "logps/rejected": -115.01102447509766,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.747832775115967,
      "rewards/margins": 5.909042835235596,
      "rewards/rejected": -2.161210060119629,
      "step": 1313
    },
    {
      "epoch": 0.5256,
      "grad_norm": 0.05088496208190918,
      "learning_rate": 8.249333333333332e-07,
      "logits/chosen": -2.663397789001465,
      "logits/rejected": -3.4324278831481934,
      "logps/chosen": -155.3348846435547,
      "logps/rejected": -149.76490783691406,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5291638374328613,
      "rewards/margins": 7.503973484039307,
      "rewards/rejected": -4.974809646606445,
      "step": 1314
    },
    {
      "epoch": 0.526,
      "grad_norm": 0.19319768249988556,
      "learning_rate": 8.247999999999999e-07,
      "logits/chosen": -2.0544893741607666,
      "logits/rejected": -3.6404478549957275,
      "logps/chosen": -109.01546478271484,
      "logps/rejected": -142.55413818359375,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.869248390197754,
      "rewards/margins": 7.023534774780273,
      "rewards/rejected": -4.1542863845825195,
      "step": 1315
    },
    {
      "epoch": 0.5264,
      "grad_norm": 0.03956567868590355,
      "learning_rate": 8.246666666666666e-07,
      "logits/chosen": -2.397494316101074,
      "logits/rejected": -3.1357898712158203,
      "logps/chosen": -184.89633178710938,
      "logps/rejected": -184.65310668945312,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.113325595855713,
      "rewards/margins": 8.004415512084961,
      "rewards/rejected": -4.891090393066406,
      "step": 1316
    },
    {
      "epoch": 0.5268,
      "grad_norm": 0.09526045620441437,
      "learning_rate": 8.245333333333333e-07,
      "logits/chosen": -2.1940114498138428,
      "logits/rejected": -3.211029291152954,
      "logps/chosen": -115.05432891845703,
      "logps/rejected": -161.17279052734375,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0933151245117188,
      "rewards/margins": 7.123518466949463,
      "rewards/rejected": -5.030203342437744,
      "step": 1317
    },
    {
      "epoch": 0.5272,
      "grad_norm": 0.7200462818145752,
      "learning_rate": 8.244e-07,
      "logits/chosen": -2.427044630050659,
      "logits/rejected": -3.0453686714172363,
      "logps/chosen": -98.99311828613281,
      "logps/rejected": -126.1367416381836,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4768781661987305,
      "rewards/margins": 5.623455047607422,
      "rewards/rejected": -3.1465771198272705,
      "step": 1318
    },
    {
      "epoch": 0.5276,
      "grad_norm": 7.550698757171631,
      "learning_rate": 8.242666666666667e-07,
      "logits/chosen": -2.298208236694336,
      "logits/rejected": -2.269282341003418,
      "logps/chosen": -70.53868865966797,
      "logps/rejected": -98.6155776977539,
      "loss": 0.0807,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7108392715454102,
      "rewards/margins": 4.085910797119141,
      "rewards/rejected": -2.3750715255737305,
      "step": 1319
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.39750704169273376,
      "learning_rate": 8.241333333333334e-07,
      "logits/chosen": -2.477109909057617,
      "logits/rejected": -3.0630617141723633,
      "logps/chosen": -119.44910430908203,
      "logps/rejected": -122.68846130371094,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0126161575317383,
      "rewards/margins": 6.303346157073975,
      "rewards/rejected": -3.2907299995422363,
      "step": 1320
    },
    {
      "epoch": 0.5284,
      "grad_norm": 0.29296085238456726,
      "learning_rate": 8.24e-07,
      "logits/chosen": -2.6395301818847656,
      "logits/rejected": -3.0413317680358887,
      "logps/chosen": -146.10452270507812,
      "logps/rejected": -117.763671875,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9772602319717407,
      "rewards/margins": 5.4144978523254395,
      "rewards/rejected": -3.4372377395629883,
      "step": 1321
    },
    {
      "epoch": 0.5288,
      "grad_norm": 0.7296185493469238,
      "learning_rate": 8.238666666666666e-07,
      "logits/chosen": -2.225363254547119,
      "logits/rejected": -2.1082310676574707,
      "logps/chosen": -104.50192260742188,
      "logps/rejected": -114.5511245727539,
      "loss": 0.0065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.193722724914551,
      "rewards/margins": 6.077485084533691,
      "rewards/rejected": -2.883762836456299,
      "step": 1322
    },
    {
      "epoch": 0.5292,
      "grad_norm": 1.655897617340088,
      "learning_rate": 8.237333333333332e-07,
      "logits/chosen": -2.4790518283843994,
      "logits/rejected": -2.299082040786743,
      "logps/chosen": -132.4713592529297,
      "logps/rejected": -105.47952270507812,
      "loss": 0.0158,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3870809078216553,
      "rewards/margins": 5.075725555419922,
      "rewards/rejected": -2.6886444091796875,
      "step": 1323
    },
    {
      "epoch": 0.5296,
      "grad_norm": 0.04737954959273338,
      "learning_rate": 8.235999999999999e-07,
      "logits/chosen": -2.5167839527130127,
      "logits/rejected": -3.0571460723876953,
      "logps/chosen": -185.8928680419922,
      "logps/rejected": -148.6611328125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6868577003479004,
      "rewards/margins": 7.715926647186279,
      "rewards/rejected": -4.029068946838379,
      "step": 1324
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.11177660524845123,
      "learning_rate": 8.234666666666666e-07,
      "logits/chosen": -2.7464168071746826,
      "logits/rejected": -2.692476511001587,
      "logps/chosen": -204.4783477783203,
      "logps/rejected": -131.1650390625,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.432375431060791,
      "rewards/margins": 7.388131141662598,
      "rewards/rejected": -3.9557557106018066,
      "step": 1325
    },
    {
      "epoch": 0.5304,
      "grad_norm": 0.18596063554286957,
      "learning_rate": 8.233333333333333e-07,
      "logits/chosen": -2.0546035766601562,
      "logits/rejected": -2.2523303031921387,
      "logps/chosen": -62.815650939941406,
      "logps/rejected": -95.36996459960938,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.1226983070373535,
      "rewards/margins": 5.930617332458496,
      "rewards/rejected": -1.8079190254211426,
      "step": 1326
    },
    {
      "epoch": 0.5308,
      "grad_norm": 0.03639296442270279,
      "learning_rate": 8.232e-07,
      "logits/chosen": -2.6529650688171387,
      "logits/rejected": -3.0548176765441895,
      "logps/chosen": -151.13009643554688,
      "logps/rejected": -154.6731719970703,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.471747398376465,
      "rewards/margins": 8.115663528442383,
      "rewards/rejected": -3.643915891647339,
      "step": 1327
    },
    {
      "epoch": 0.5312,
      "grad_norm": 0.07899145781993866,
      "learning_rate": 8.230666666666666e-07,
      "logits/chosen": -2.207818031311035,
      "logits/rejected": -2.920560359954834,
      "logps/chosen": -115.09910583496094,
      "logps/rejected": -234.17605590820312,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.123518466949463,
      "rewards/margins": 7.879699230194092,
      "rewards/rejected": -3.756180763244629,
      "step": 1328
    },
    {
      "epoch": 0.5316,
      "grad_norm": 3.3615782260894775,
      "learning_rate": 8.229333333333333e-07,
      "logits/chosen": -2.9145960807800293,
      "logits/rejected": -3.1365256309509277,
      "logps/chosen": -259.09295654296875,
      "logps/rejected": -172.349853515625,
      "loss": 0.0364,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0539100170135498,
      "rewards/margins": 3.424896240234375,
      "rewards/rejected": -2.370986223220825,
      "step": 1329
    },
    {
      "epoch": 0.532,
      "grad_norm": 0.7509462237358093,
      "learning_rate": 8.228e-07,
      "logits/chosen": -2.656926393508911,
      "logits/rejected": -2.895658016204834,
      "logps/chosen": -160.8792724609375,
      "logps/rejected": -176.77224731445312,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9821381568908691,
      "rewards/margins": 6.095464706420898,
      "rewards/rejected": -4.113326549530029,
      "step": 1330
    },
    {
      "epoch": 0.5324,
      "grad_norm": 0.09762454777956009,
      "learning_rate": 8.226666666666666e-07,
      "logits/chosen": -2.076150894165039,
      "logits/rejected": -2.891835927963257,
      "logps/chosen": -133.66136169433594,
      "logps/rejected": -147.7758026123047,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1462185382843018,
      "rewards/margins": 7.030421257019043,
      "rewards/rejected": -3.884202480316162,
      "step": 1331
    },
    {
      "epoch": 0.5328,
      "grad_norm": 0.499004989862442,
      "learning_rate": 8.225333333333333e-07,
      "logits/chosen": -2.3221092224121094,
      "logits/rejected": -2.9471564292907715,
      "logps/chosen": -159.75405883789062,
      "logps/rejected": -115.01242065429688,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0438485145568848,
      "rewards/margins": 5.629015922546387,
      "rewards/rejected": -2.585167407989502,
      "step": 1332
    },
    {
      "epoch": 0.5332,
      "grad_norm": 0.06255802512168884,
      "learning_rate": 8.224e-07,
      "logits/chosen": -2.427093029022217,
      "logits/rejected": -3.0153493881225586,
      "logps/chosen": -100.9781723022461,
      "logps/rejected": -157.71255493164062,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5714173316955566,
      "rewards/margins": 7.2996907234191895,
      "rewards/rejected": -3.728273391723633,
      "step": 1333
    },
    {
      "epoch": 0.5336,
      "grad_norm": 3.0702500343322754,
      "learning_rate": 8.222666666666666e-07,
      "logits/chosen": -1.9864510297775269,
      "logits/rejected": -2.9882354736328125,
      "logps/chosen": -87.02499389648438,
      "logps/rejected": -145.00848388671875,
      "loss": 0.0363,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2702629566192627,
      "rewards/margins": 4.7161784172058105,
      "rewards/rejected": -3.4459152221679688,
      "step": 1334
    },
    {
      "epoch": 0.534,
      "grad_norm": 0.42982542514801025,
      "learning_rate": 8.221333333333333e-07,
      "logits/chosen": -1.4573628902435303,
      "logits/rejected": -2.986238956451416,
      "logps/chosen": -97.03833770751953,
      "logps/rejected": -119.7531509399414,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.036963701248169,
      "rewards/margins": 6.243045806884766,
      "rewards/rejected": -3.206082582473755,
      "step": 1335
    },
    {
      "epoch": 0.5344,
      "grad_norm": 1.701074242591858,
      "learning_rate": 8.219999999999999e-07,
      "logits/chosen": -2.7553813457489014,
      "logits/rejected": -2.980724811553955,
      "logps/chosen": -203.34197998046875,
      "logps/rejected": -154.6084442138672,
      "loss": 0.0197,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9768310785293579,
      "rewards/margins": 3.9593758583068848,
      "rewards/rejected": -2.9825446605682373,
      "step": 1336
    },
    {
      "epoch": 0.5348,
      "grad_norm": 0.92960524559021,
      "learning_rate": 8.218666666666666e-07,
      "logits/chosen": -2.367095470428467,
      "logits/rejected": -2.689181089401245,
      "logps/chosen": -146.16526794433594,
      "logps/rejected": -117.8543930053711,
      "loss": 0.013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.238130569458008,
      "rewards/margins": 4.839771270751953,
      "rewards/rejected": -2.6016411781311035,
      "step": 1337
    },
    {
      "epoch": 0.5352,
      "grad_norm": 8.070682525634766,
      "learning_rate": 8.217333333333333e-07,
      "logits/chosen": -1.9570820331573486,
      "logits/rejected": -3.3243470191955566,
      "logps/chosen": -94.24105072021484,
      "logps/rejected": -115.52113342285156,
      "loss": 0.1325,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3163493871688843,
      "rewards/margins": 4.474077224731445,
      "rewards/rejected": -3.1577279567718506,
      "step": 1338
    },
    {
      "epoch": 0.5356,
      "grad_norm": 0.06368836015462875,
      "learning_rate": 8.216e-07,
      "logits/chosen": -2.668957233428955,
      "logits/rejected": -2.8477210998535156,
      "logps/chosen": -108.0386734008789,
      "logps/rejected": -144.23300170898438,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.615945339202881,
      "rewards/margins": 7.28568696975708,
      "rewards/rejected": -3.669741630554199,
      "step": 1339
    },
    {
      "epoch": 0.536,
      "grad_norm": 1.0362937450408936,
      "learning_rate": 8.214666666666667e-07,
      "logits/chosen": -2.399512767791748,
      "logits/rejected": -3.186471700668335,
      "logps/chosen": -160.76889038085938,
      "logps/rejected": -156.6409912109375,
      "loss": 0.0074,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.890416145324707,
      "rewards/margins": 5.801139831542969,
      "rewards/rejected": -2.910723924636841,
      "step": 1340
    },
    {
      "epoch": 0.5364,
      "grad_norm": 0.6625850200653076,
      "learning_rate": 8.213333333333333e-07,
      "logits/chosen": -2.3062057495117188,
      "logits/rejected": -3.3735880851745605,
      "logps/chosen": -85.9689712524414,
      "logps/rejected": -132.42788696289062,
      "loss": 0.0079,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9906593561172485,
      "rewards/margins": 4.933499813079834,
      "rewards/rejected": -3.942840576171875,
      "step": 1341
    },
    {
      "epoch": 0.5368,
      "grad_norm": 0.09731549769639969,
      "learning_rate": 8.212e-07,
      "logits/chosen": -2.1631112098693848,
      "logits/rejected": -3.1926965713500977,
      "logps/chosen": -66.12409210205078,
      "logps/rejected": -116.41078186035156,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.580920457839966,
      "rewards/margins": 7.017314434051514,
      "rewards/rejected": -3.4363937377929688,
      "step": 1342
    },
    {
      "epoch": 0.5372,
      "grad_norm": 0.16247141361236572,
      "learning_rate": 8.210666666666666e-07,
      "logits/chosen": -2.308887243270874,
      "logits/rejected": -3.485948324203491,
      "logps/chosen": -110.35379028320312,
      "logps/rejected": -131.04498291015625,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2150399684906006,
      "rewards/margins": 6.461182594299316,
      "rewards/rejected": -3.246142625808716,
      "step": 1343
    },
    {
      "epoch": 0.5376,
      "grad_norm": 0.6305299997329712,
      "learning_rate": 8.209333333333332e-07,
      "logits/chosen": -2.0756325721740723,
      "logits/rejected": -3.2229361534118652,
      "logps/chosen": -159.07843017578125,
      "logps/rejected": -145.82066345214844,
      "loss": 0.0072,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1878743171691895,
      "rewards/margins": 5.944703102111816,
      "rewards/rejected": -3.756829261779785,
      "step": 1344
    },
    {
      "epoch": 0.538,
      "grad_norm": 0.251577228307724,
      "learning_rate": 8.207999999999999e-07,
      "logits/chosen": -1.9193346500396729,
      "logits/rejected": -2.794644355773926,
      "logps/chosen": -117.43905639648438,
      "logps/rejected": -147.17115783691406,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8819007873535156,
      "rewards/margins": 6.306256294250488,
      "rewards/rejected": -4.424355506896973,
      "step": 1345
    },
    {
      "epoch": 0.5384,
      "grad_norm": 0.7076241970062256,
      "learning_rate": 8.206666666666666e-07,
      "logits/chosen": -2.169893741607666,
      "logits/rejected": -2.937532424926758,
      "logps/chosen": -108.05215454101562,
      "logps/rejected": -139.36123657226562,
      "loss": 0.0086,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0877166986465454,
      "rewards/margins": 5.437198638916016,
      "rewards/rejected": -4.34948205947876,
      "step": 1346
    },
    {
      "epoch": 0.5388,
      "grad_norm": 0.9271373748779297,
      "learning_rate": 8.205333333333333e-07,
      "logits/chosen": -2.442003011703491,
      "logits/rejected": -2.775324821472168,
      "logps/chosen": -97.32540130615234,
      "logps/rejected": -108.31016540527344,
      "loss": 0.012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0722997188568115,
      "rewards/margins": 4.818957328796387,
      "rewards/rejected": -2.7466578483581543,
      "step": 1347
    },
    {
      "epoch": 0.5392,
      "grad_norm": 0.12805473804473877,
      "learning_rate": 8.204e-07,
      "logits/chosen": -2.021817922592163,
      "logits/rejected": -2.821074962615967,
      "logps/chosen": -95.4549560546875,
      "logps/rejected": -231.40342712402344,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8971805572509766,
      "rewards/margins": 6.824271202087402,
      "rewards/rejected": -2.927090644836426,
      "step": 1348
    },
    {
      "epoch": 0.5396,
      "grad_norm": 0.06165897101163864,
      "learning_rate": 8.202666666666667e-07,
      "logits/chosen": -2.2269480228424072,
      "logits/rejected": -2.440136194229126,
      "logps/chosen": -83.16543579101562,
      "logps/rejected": -167.41587829589844,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7195215225219727,
      "rewards/margins": 7.282905578613281,
      "rewards/rejected": -3.5633842945098877,
      "step": 1349
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.28803759813308716,
      "learning_rate": 8.201333333333333e-07,
      "logits/chosen": -2.1842164993286133,
      "logits/rejected": -2.509521007537842,
      "logps/chosen": -100.85420227050781,
      "logps/rejected": -117.31717681884766,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.435211181640625,
      "rewards/margins": 5.956225395202637,
      "rewards/rejected": -3.5210142135620117,
      "step": 1350
    },
    {
      "epoch": 0.5404,
      "grad_norm": 3.610896110534668,
      "learning_rate": 8.199999999999999e-07,
      "logits/chosen": -2.303467273712158,
      "logits/rejected": -3.2842326164245605,
      "logps/chosen": -89.35572814941406,
      "logps/rejected": -139.26361083984375,
      "loss": 0.0313,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8552417755126953,
      "rewards/margins": 5.629733562469482,
      "rewards/rejected": -2.774491548538208,
      "step": 1351
    },
    {
      "epoch": 0.5408,
      "grad_norm": 0.19920147955417633,
      "learning_rate": 8.198666666666666e-07,
      "logits/chosen": -2.0682244300842285,
      "logits/rejected": -2.8038434982299805,
      "logps/chosen": -100.34957885742188,
      "logps/rejected": -141.3238525390625,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4161806106567383,
      "rewards/margins": 7.024672031402588,
      "rewards/rejected": -4.608491897583008,
      "step": 1352
    },
    {
      "epoch": 0.5412,
      "grad_norm": 2.061075210571289,
      "learning_rate": 8.197333333333333e-07,
      "logits/chosen": -2.2605409622192383,
      "logits/rejected": -2.735137462615967,
      "logps/chosen": -132.8876495361328,
      "logps/rejected": -121.7732162475586,
      "loss": 0.0223,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.113848090171814,
      "rewards/margins": 3.901989459991455,
      "rewards/rejected": -2.7881412506103516,
      "step": 1353
    },
    {
      "epoch": 0.5416,
      "grad_norm": 0.15410932898521423,
      "learning_rate": 8.196e-07,
      "logits/chosen": -2.2947609424591064,
      "logits/rejected": -3.242522954940796,
      "logps/chosen": -143.3863983154297,
      "logps/rejected": -177.40574645996094,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.981688976287842,
      "rewards/margins": 6.403347015380859,
      "rewards/rejected": -3.4216575622558594,
      "step": 1354
    },
    {
      "epoch": 0.542,
      "grad_norm": 0.11263065785169601,
      "learning_rate": 8.194666666666666e-07,
      "logits/chosen": -2.365091323852539,
      "logits/rejected": -3.1051502227783203,
      "logps/chosen": -82.48260498046875,
      "logps/rejected": -122.67082214355469,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.161205768585205,
      "rewards/margins": 6.750385284423828,
      "rewards/rejected": -3.589179515838623,
      "step": 1355
    },
    {
      "epoch": 0.5424,
      "grad_norm": 0.1455507129430771,
      "learning_rate": 8.193333333333333e-07,
      "logits/chosen": -2.154873847961426,
      "logits/rejected": -2.381171703338623,
      "logps/chosen": -71.252197265625,
      "logps/rejected": -118.08757781982422,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1374974250793457,
      "rewards/margins": 6.399870872497559,
      "rewards/rejected": -3.262373447418213,
      "step": 1356
    },
    {
      "epoch": 0.5428,
      "grad_norm": 0.7005122900009155,
      "learning_rate": 8.192e-07,
      "logits/chosen": -1.8309073448181152,
      "logits/rejected": -2.8765926361083984,
      "logps/chosen": -110.71001434326172,
      "logps/rejected": -107.49496459960938,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9659104347229004,
      "rewards/margins": 5.901630878448486,
      "rewards/rejected": -2.935720443725586,
      "step": 1357
    },
    {
      "epoch": 0.5432,
      "grad_norm": 0.5202021598815918,
      "learning_rate": 8.190666666666667e-07,
      "logits/chosen": -2.1417603492736816,
      "logits/rejected": -3.080000638961792,
      "logps/chosen": -97.86113739013672,
      "logps/rejected": -163.7994384765625,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.071310043334961,
      "rewards/margins": 6.669565200805664,
      "rewards/rejected": -4.598254680633545,
      "step": 1358
    },
    {
      "epoch": 0.5436,
      "grad_norm": 0.1434997171163559,
      "learning_rate": 8.189333333333332e-07,
      "logits/chosen": -2.1784050464630127,
      "logits/rejected": -2.6853270530700684,
      "logps/chosen": -94.52436065673828,
      "logps/rejected": -134.47140502929688,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.99517560005188,
      "rewards/margins": 6.516786575317383,
      "rewards/rejected": -3.521610736846924,
      "step": 1359
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.03557053953409195,
      "learning_rate": 8.187999999999999e-07,
      "logits/chosen": -2.105827808380127,
      "logits/rejected": -3.026546001434326,
      "logps/chosen": -147.09310913085938,
      "logps/rejected": -213.32925415039062,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.376239776611328,
      "rewards/margins": 7.890561103820801,
      "rewards/rejected": -4.514321327209473,
      "step": 1360
    },
    {
      "epoch": 0.5444,
      "grad_norm": 2.5729644298553467,
      "learning_rate": 8.186666666666666e-07,
      "logits/chosen": -2.0363950729370117,
      "logits/rejected": -2.667754888534546,
      "logps/chosen": -102.37330627441406,
      "logps/rejected": -133.1470947265625,
      "loss": 0.0298,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8594971299171448,
      "rewards/margins": 5.398479461669922,
      "rewards/rejected": -4.538982391357422,
      "step": 1361
    },
    {
      "epoch": 0.5448,
      "grad_norm": 0.3612530529499054,
      "learning_rate": 8.185333333333333e-07,
      "logits/chosen": -2.0426864624023438,
      "logits/rejected": -2.8954458236694336,
      "logps/chosen": -104.20401000976562,
      "logps/rejected": -109.69401550292969,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5409313440322876,
      "rewards/margins": 5.438925743103027,
      "rewards/rejected": -3.8979947566986084,
      "step": 1362
    },
    {
      "epoch": 0.5452,
      "grad_norm": 0.8076857328414917,
      "learning_rate": 8.184e-07,
      "logits/chosen": -2.216151237487793,
      "logits/rejected": -3.2398715019226074,
      "logps/chosen": -181.66970825195312,
      "logps/rejected": -127.74678039550781,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2493081092834473,
      "rewards/margins": 5.391735076904297,
      "rewards/rejected": -3.1424269676208496,
      "step": 1363
    },
    {
      "epoch": 0.5456,
      "grad_norm": 0.0997445359826088,
      "learning_rate": 8.182666666666667e-07,
      "logits/chosen": -2.3965537548065186,
      "logits/rejected": -2.816533327102661,
      "logps/chosen": -78.377685546875,
      "logps/rejected": -137.10533142089844,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5847904682159424,
      "rewards/margins": 7.824341773986816,
      "rewards/rejected": -4.239551067352295,
      "step": 1364
    },
    {
      "epoch": 0.546,
      "grad_norm": 0.3541145920753479,
      "learning_rate": 8.181333333333334e-07,
      "logits/chosen": -2.2662925720214844,
      "logits/rejected": -2.9441914558410645,
      "logps/chosen": -106.84696960449219,
      "logps/rejected": -141.57620239257812,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.089759588241577,
      "rewards/margins": 6.7758989334106445,
      "rewards/rejected": -3.6861393451690674,
      "step": 1365
    },
    {
      "epoch": 0.5464,
      "grad_norm": 1.1763834953308105,
      "learning_rate": 8.179999999999999e-07,
      "logits/chosen": -2.8006701469421387,
      "logits/rejected": -3.3335049152374268,
      "logps/chosen": -148.5935821533203,
      "logps/rejected": -198.18994140625,
      "loss": 0.0096,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.514315605163574,
      "rewards/margins": 6.145716667175293,
      "rewards/rejected": -2.6314010620117188,
      "step": 1366
    },
    {
      "epoch": 0.5468,
      "grad_norm": 2.0106008052825928,
      "learning_rate": 8.178666666666666e-07,
      "logits/chosen": -2.5332999229431152,
      "logits/rejected": -2.861604690551758,
      "logps/chosen": -110.98637390136719,
      "logps/rejected": -126.48281860351562,
      "loss": 0.0258,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2900123596191406,
      "rewards/margins": 3.7320785522460938,
      "rewards/rejected": -2.442066192626953,
      "step": 1367
    },
    {
      "epoch": 0.5472,
      "grad_norm": 0.23037460446357727,
      "learning_rate": 8.177333333333333e-07,
      "logits/chosen": -2.410067319869995,
      "logits/rejected": -3.4129910469055176,
      "logps/chosen": -169.6265869140625,
      "logps/rejected": -147.62579345703125,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1711151599884033,
      "rewards/margins": 6.636329174041748,
      "rewards/rejected": -4.465214252471924,
      "step": 1368
    },
    {
      "epoch": 0.5476,
      "grad_norm": 0.8442983627319336,
      "learning_rate": 8.175999999999999e-07,
      "logits/chosen": -2.3718795776367188,
      "logits/rejected": -2.9297027587890625,
      "logps/chosen": -132.6585235595703,
      "logps/rejected": -222.70748901367188,
      "loss": 0.0077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.088104248046875,
      "rewards/margins": 5.01609992980957,
      "rewards/rejected": -3.927995443344116,
      "step": 1369
    },
    {
      "epoch": 0.548,
      "grad_norm": 0.20189696550369263,
      "learning_rate": 8.174666666666666e-07,
      "logits/chosen": -2.3081612586975098,
      "logits/rejected": -2.7394907474517822,
      "logps/chosen": -63.18353271484375,
      "logps/rejected": -124.9476318359375,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.504112958908081,
      "rewards/margins": 6.252042770385742,
      "rewards/rejected": -3.747929573059082,
      "step": 1370
    },
    {
      "epoch": 0.5484,
      "grad_norm": 0.28983595967292786,
      "learning_rate": 8.173333333333333e-07,
      "logits/chosen": -1.9263051748275757,
      "logits/rejected": -3.053603172302246,
      "logps/chosen": -123.00804138183594,
      "logps/rejected": -176.78347778320312,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.580955982208252,
      "rewards/margins": 6.051331043243408,
      "rewards/rejected": -4.470375061035156,
      "step": 1371
    },
    {
      "epoch": 0.5488,
      "grad_norm": 0.9548665881156921,
      "learning_rate": 8.172e-07,
      "logits/chosen": -2.009714126586914,
      "logits/rejected": -2.922085762023926,
      "logps/chosen": -101.52427673339844,
      "logps/rejected": -125.75798797607422,
      "loss": 0.0125,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8519485592842102,
      "rewards/margins": 4.607800006866455,
      "rewards/rejected": -3.7558512687683105,
      "step": 1372
    },
    {
      "epoch": 0.5492,
      "grad_norm": 0.044025175273418427,
      "learning_rate": 8.170666666666667e-07,
      "logits/chosen": -2.3513166904449463,
      "logits/rejected": -3.2787351608276367,
      "logps/chosen": -150.37692260742188,
      "logps/rejected": -150.4435272216797,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9694933891296387,
      "rewards/margins": 7.992666244506836,
      "rewards/rejected": -4.0231733322143555,
      "step": 1373
    },
    {
      "epoch": 0.5496,
      "grad_norm": 1.6517668962478638,
      "learning_rate": 8.169333333333333e-07,
      "logits/chosen": -2.0736870765686035,
      "logits/rejected": -3.026808261871338,
      "logps/chosen": -146.355224609375,
      "logps/rejected": -117.0868148803711,
      "loss": 0.0163,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6938045620918274,
      "rewards/margins": 4.224743366241455,
      "rewards/rejected": -3.5309388637542725,
      "step": 1374
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.12779726088047028,
      "learning_rate": 8.168e-07,
      "logits/chosen": -2.8381595611572266,
      "logits/rejected": -2.6602911949157715,
      "logps/chosen": -117.0439224243164,
      "logps/rejected": -126.33016204833984,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.639261245727539,
      "rewards/margins": 6.6705322265625,
      "rewards/rejected": -4.031270503997803,
      "step": 1375
    },
    {
      "epoch": 0.5504,
      "grad_norm": 0.06759074330329895,
      "learning_rate": 8.166666666666666e-07,
      "logits/chosen": -2.2767529487609863,
      "logits/rejected": -3.25278902053833,
      "logps/chosen": -170.27679443359375,
      "logps/rejected": -149.09242248535156,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.0398712158203125,
      "rewards/margins": 7.327136993408203,
      "rewards/rejected": -3.287266254425049,
      "step": 1376
    },
    {
      "epoch": 0.5508,
      "grad_norm": 0.08464404195547104,
      "learning_rate": 8.165333333333333e-07,
      "logits/chosen": -2.2517571449279785,
      "logits/rejected": -2.9243316650390625,
      "logps/chosen": -62.91513442993164,
      "logps/rejected": -108.596435546875,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.594916820526123,
      "rewards/margins": 7.003890037536621,
      "rewards/rejected": -3.408972978591919,
      "step": 1377
    },
    {
      "epoch": 0.5512,
      "grad_norm": 0.44083279371261597,
      "learning_rate": 8.163999999999999e-07,
      "logits/chosen": -2.0934324264526367,
      "logits/rejected": -2.8070197105407715,
      "logps/chosen": -104.92501831054688,
      "logps/rejected": -127.420654296875,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.659029960632324,
      "rewards/margins": 5.827817440032959,
      "rewards/rejected": -3.1687874794006348,
      "step": 1378
    },
    {
      "epoch": 0.5516,
      "grad_norm": 0.4690041244029999,
      "learning_rate": 8.162666666666666e-07,
      "logits/chosen": -1.8038146495819092,
      "logits/rejected": -3.1772589683532715,
      "logps/chosen": -83.13636779785156,
      "logps/rejected": -132.4525909423828,
      "loss": 0.0059,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5195510387420654,
      "rewards/margins": 5.154632568359375,
      "rewards/rejected": -3.6350810527801514,
      "step": 1379
    },
    {
      "epoch": 0.552,
      "grad_norm": 0.1549840122461319,
      "learning_rate": 8.161333333333333e-07,
      "logits/chosen": -2.719332695007324,
      "logits/rejected": -2.6808485984802246,
      "logps/chosen": -121.72164154052734,
      "logps/rejected": -116.14988708496094,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8383727073669434,
      "rewards/margins": 6.328452110290527,
      "rewards/rejected": -3.490079402923584,
      "step": 1380
    },
    {
      "epoch": 0.5524,
      "grad_norm": 1.3442764282226562,
      "learning_rate": 8.159999999999999e-07,
      "logits/chosen": -2.1217293739318848,
      "logits/rejected": -3.3284716606140137,
      "logps/chosen": -95.83027648925781,
      "logps/rejected": -137.57894897460938,
      "loss": 0.0205,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.207891821861267,
      "rewards/margins": 4.189959526062012,
      "rewards/rejected": -2.9820680618286133,
      "step": 1381
    },
    {
      "epoch": 0.5528,
      "grad_norm": 0.5712348818778992,
      "learning_rate": 8.158666666666666e-07,
      "logits/chosen": -2.2055482864379883,
      "logits/rejected": -2.982642650604248,
      "logps/chosen": -95.56420135498047,
      "logps/rejected": -136.50958251953125,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.698094129562378,
      "rewards/margins": 6.082461833953857,
      "rewards/rejected": -3.3843674659729004,
      "step": 1382
    },
    {
      "epoch": 0.5532,
      "grad_norm": 2.594291925430298,
      "learning_rate": 8.157333333333333e-07,
      "logits/chosen": -2.333428382873535,
      "logits/rejected": -3.221005439758301,
      "logps/chosen": -118.37870025634766,
      "logps/rejected": -142.1295166015625,
      "loss": 0.018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.802874743938446,
      "rewards/margins": 4.756659507751465,
      "rewards/rejected": -3.953784704208374,
      "step": 1383
    },
    {
      "epoch": 0.5536,
      "grad_norm": 0.169491246342659,
      "learning_rate": 8.156e-07,
      "logits/chosen": -2.333202838897705,
      "logits/rejected": -2.874831438064575,
      "logps/chosen": -104.50300598144531,
      "logps/rejected": -127.77046203613281,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.95940899848938,
      "rewards/margins": 6.565345764160156,
      "rewards/rejected": -3.6059370040893555,
      "step": 1384
    },
    {
      "epoch": 0.554,
      "grad_norm": 0.6751608848571777,
      "learning_rate": 8.154666666666667e-07,
      "logits/chosen": -2.4680287837982178,
      "logits/rejected": -3.041289806365967,
      "logps/chosen": -95.09580993652344,
      "logps/rejected": -136.72024536132812,
      "loss": 0.0072,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1369545459747314,
      "rewards/margins": 5.265592575073242,
      "rewards/rejected": -4.128637790679932,
      "step": 1385
    },
    {
      "epoch": 0.5544,
      "grad_norm": 2.8705127239227295,
      "learning_rate": 8.153333333333334e-07,
      "logits/chosen": -2.0426056385040283,
      "logits/rejected": -2.491199493408203,
      "logps/chosen": -102.38643646240234,
      "logps/rejected": -150.42800903320312,
      "loss": 0.0209,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6123520135879517,
      "rewards/margins": 4.055596351623535,
      "rewards/rejected": -3.443244457244873,
      "step": 1386
    },
    {
      "epoch": 0.5548,
      "grad_norm": 0.5458569526672363,
      "learning_rate": 8.152e-07,
      "logits/chosen": -2.4167556762695312,
      "logits/rejected": -2.5664591789245605,
      "logps/chosen": -105.6480484008789,
      "logps/rejected": -106.80630493164062,
      "loss": 0.0059,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0350940227508545,
      "rewards/margins": 5.766817092895508,
      "rewards/rejected": -3.7317230701446533,
      "step": 1387
    },
    {
      "epoch": 0.5552,
      "grad_norm": 3.0896239280700684,
      "learning_rate": 8.150666666666666e-07,
      "logits/chosen": -2.155428647994995,
      "logits/rejected": -2.342444658279419,
      "logps/chosen": -83.52989959716797,
      "logps/rejected": -110.36243438720703,
      "loss": 0.0393,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9375519752502441,
      "rewards/margins": 4.504535675048828,
      "rewards/rejected": -2.566983461380005,
      "step": 1388
    },
    {
      "epoch": 0.5556,
      "grad_norm": 0.02249857783317566,
      "learning_rate": 8.149333333333332e-07,
      "logits/chosen": -2.3275249004364014,
      "logits/rejected": -2.646376132965088,
      "logps/chosen": -124.03237915039062,
      "logps/rejected": -165.39776611328125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1814627647399902,
      "rewards/margins": 8.582880973815918,
      "rewards/rejected": -5.401418209075928,
      "step": 1389
    },
    {
      "epoch": 0.556,
      "grad_norm": 0.18056058883666992,
      "learning_rate": 8.147999999999999e-07,
      "logits/chosen": -2.434542655944824,
      "logits/rejected": -2.9815196990966797,
      "logps/chosen": -134.02320861816406,
      "logps/rejected": -148.74624633789062,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1533687114715576,
      "rewards/margins": 6.200014114379883,
      "rewards/rejected": -3.046645402908325,
      "step": 1390
    },
    {
      "epoch": 0.5564,
      "grad_norm": 8.26070785522461,
      "learning_rate": 8.146666666666666e-07,
      "logits/chosen": -2.1717538833618164,
      "logits/rejected": -3.209113121032715,
      "logps/chosen": -188.623291015625,
      "logps/rejected": -130.9550018310547,
      "loss": 0.0967,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6799991726875305,
      "rewards/margins": 3.0692455768585205,
      "rewards/rejected": -3.7492446899414062,
      "step": 1391
    },
    {
      "epoch": 0.5568,
      "grad_norm": 0.349500447511673,
      "learning_rate": 8.145333333333333e-07,
      "logits/chosen": -2.1023008823394775,
      "logits/rejected": -3.2557621002197266,
      "logps/chosen": -150.33065795898438,
      "logps/rejected": -204.556396484375,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3347800970077515,
      "rewards/margins": 5.593705177307129,
      "rewards/rejected": -4.258924961090088,
      "step": 1392
    },
    {
      "epoch": 0.5572,
      "grad_norm": 0.19294944405555725,
      "learning_rate": 8.144e-07,
      "logits/chosen": -2.185462236404419,
      "logits/rejected": -3.6023969650268555,
      "logps/chosen": -85.9786376953125,
      "logps/rejected": -127.56790924072266,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9816346168518066,
      "rewards/margins": 6.315155506134033,
      "rewards/rejected": -3.3335208892822266,
      "step": 1393
    },
    {
      "epoch": 0.5576,
      "grad_norm": 0.47243764996528625,
      "learning_rate": 8.142666666666667e-07,
      "logits/chosen": -2.6760246753692627,
      "logits/rejected": -2.7510809898376465,
      "logps/chosen": -189.44003295898438,
      "logps/rejected": -128.54556274414062,
      "loss": 0.0049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9698593616485596,
      "rewards/margins": 5.396262168884277,
      "rewards/rejected": -2.426403045654297,
      "step": 1394
    },
    {
      "epoch": 0.558,
      "grad_norm": 1.241945505142212,
      "learning_rate": 8.141333333333334e-07,
      "logits/chosen": -1.9059460163116455,
      "logits/rejected": -3.054417848587036,
      "logps/chosen": -77.4175033569336,
      "logps/rejected": -134.20596313476562,
      "loss": 0.016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.55022394657135,
      "rewards/margins": 5.584228515625,
      "rewards/rejected": -4.0340046882629395,
      "step": 1395
    },
    {
      "epoch": 0.5584,
      "grad_norm": 5.184137344360352,
      "learning_rate": 8.14e-07,
      "logits/chosen": -2.0288944244384766,
      "logits/rejected": -2.604325532913208,
      "logps/chosen": -82.32173156738281,
      "logps/rejected": -112.41671752929688,
      "loss": 0.0566,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22813528776168823,
      "rewards/margins": 3.34941029548645,
      "rewards/rejected": -3.121274948120117,
      "step": 1396
    },
    {
      "epoch": 0.5588,
      "grad_norm": 0.10346592962741852,
      "learning_rate": 8.138666666666665e-07,
      "logits/chosen": -1.9775903224945068,
      "logits/rejected": -2.9775002002716064,
      "logps/chosen": -128.81202697753906,
      "logps/rejected": -165.85629272460938,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9114826917648315,
      "rewards/margins": 6.861816883087158,
      "rewards/rejected": -4.950334548950195,
      "step": 1397
    },
    {
      "epoch": 0.5592,
      "grad_norm": 0.5358392000198364,
      "learning_rate": 8.137333333333332e-07,
      "logits/chosen": -2.2901835441589355,
      "logits/rejected": -2.9359166622161865,
      "logps/chosen": -82.63034057617188,
      "logps/rejected": -136.5924530029297,
      "loss": 0.0051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.841862201690674,
      "rewards/margins": 6.388023853302002,
      "rewards/rejected": -3.546161651611328,
      "step": 1398
    },
    {
      "epoch": 0.5596,
      "grad_norm": 0.6096543073654175,
      "learning_rate": 8.135999999999999e-07,
      "logits/chosen": -1.8596992492675781,
      "logits/rejected": -2.7796380519866943,
      "logps/chosen": -132.63458251953125,
      "logps/rejected": -145.13230895996094,
      "loss": 0.0075,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8279004096984863,
      "rewards/margins": 6.076992034912109,
      "rewards/rejected": -2.249091386795044,
      "step": 1399
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.24943837523460388,
      "learning_rate": 8.134666666666666e-07,
      "logits/chosen": -2.1107797622680664,
      "logits/rejected": -3.063664436340332,
      "logps/chosen": -142.32766723632812,
      "logps/rejected": -195.04373168945312,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.243781328201294,
      "rewards/margins": 7.949974536895752,
      "rewards/rejected": -5.706192970275879,
      "step": 1400
    },
    {
      "epoch": 0.5604,
      "grad_norm": 0.06037570536136627,
      "learning_rate": 8.133333333333333e-07,
      "logits/chosen": -2.4821102619171143,
      "logits/rejected": -3.0928940773010254,
      "logps/chosen": -166.77293395996094,
      "logps/rejected": -148.46080017089844,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.34548807144165,
      "rewards/margins": 7.979382038116455,
      "rewards/rejected": -3.6338939666748047,
      "step": 1401
    },
    {
      "epoch": 0.5608,
      "grad_norm": 0.1963835209608078,
      "learning_rate": 8.132e-07,
      "logits/chosen": -2.440861225128174,
      "logits/rejected": -3.331449031829834,
      "logps/chosen": -113.3202133178711,
      "logps/rejected": -131.869384765625,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7533655166625977,
      "rewards/margins": 6.181339740753174,
      "rewards/rejected": -3.4279744625091553,
      "step": 1402
    },
    {
      "epoch": 0.5612,
      "grad_norm": 0.41276952624320984,
      "learning_rate": 8.130666666666667e-07,
      "logits/chosen": -2.069911479949951,
      "logits/rejected": -3.049759864807129,
      "logps/chosen": -102.7514877319336,
      "logps/rejected": -127.79585266113281,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.851311683654785,
      "rewards/margins": 6.112323760986328,
      "rewards/rejected": -3.261012077331543,
      "step": 1403
    },
    {
      "epoch": 0.5616,
      "grad_norm": 1.0714350938796997,
      "learning_rate": 8.129333333333333e-07,
      "logits/chosen": -2.548649787902832,
      "logits/rejected": -2.878201484680176,
      "logps/chosen": -103.06436157226562,
      "logps/rejected": -113.90949249267578,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7885184288024902,
      "rewards/margins": 7.1585164070129395,
      "rewards/rejected": -3.36999773979187,
      "step": 1404
    },
    {
      "epoch": 0.562,
      "grad_norm": 0.12366432696580887,
      "learning_rate": 8.128e-07,
      "logits/chosen": -2.4356515407562256,
      "logits/rejected": -2.1302151679992676,
      "logps/chosen": -115.99898529052734,
      "logps/rejected": -123.76464080810547,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.110992431640625,
      "rewards/margins": 6.718920707702637,
      "rewards/rejected": -3.60792875289917,
      "step": 1405
    },
    {
      "epoch": 0.5624,
      "grad_norm": 0.8873561024665833,
      "learning_rate": 8.126666666666666e-07,
      "logits/chosen": -2.1022350788116455,
      "logits/rejected": -2.7320199012756348,
      "logps/chosen": -82.03731536865234,
      "logps/rejected": -122.22348022460938,
      "loss": 0.007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0244879722595215,
      "rewards/margins": 5.3747687339782715,
      "rewards/rejected": -3.35028076171875,
      "step": 1406
    },
    {
      "epoch": 0.5628,
      "grad_norm": 0.165993332862854,
      "learning_rate": 8.125333333333333e-07,
      "logits/chosen": -2.1022136211395264,
      "logits/rejected": -2.8427114486694336,
      "logps/chosen": -131.35018920898438,
      "logps/rejected": -182.08709716796875,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8625895977020264,
      "rewards/margins": 6.701104164123535,
      "rewards/rejected": -3.838514804840088,
      "step": 1407
    },
    {
      "epoch": 0.5632,
      "grad_norm": 0.022947467863559723,
      "learning_rate": 8.123999999999999e-07,
      "logits/chosen": -2.569672107696533,
      "logits/rejected": -2.808469295501709,
      "logps/chosen": -123.01006317138672,
      "logps/rejected": -162.17379760742188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.401764869689941,
      "rewards/margins": 8.75935173034668,
      "rewards/rejected": -4.357586860656738,
      "step": 1408
    },
    {
      "epoch": 0.5636,
      "grad_norm": 30.425310134887695,
      "learning_rate": 8.122666666666666e-07,
      "logits/chosen": -2.2423088550567627,
      "logits/rejected": -2.263758659362793,
      "logps/chosen": -129.98696899414062,
      "logps/rejected": -114.80706024169922,
      "loss": 0.2016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1325943022966385,
      "rewards/margins": 2.6813695430755615,
      "rewards/rejected": -2.5487751960754395,
      "step": 1409
    },
    {
      "epoch": 0.564,
      "grad_norm": 0.1418197602033615,
      "learning_rate": 8.121333333333333e-07,
      "logits/chosen": -2.5181736946105957,
      "logits/rejected": -3.0138795375823975,
      "logps/chosen": -124.31654357910156,
      "logps/rejected": -137.4385986328125,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6284573078155518,
      "rewards/margins": 6.953444004058838,
      "rewards/rejected": -3.324986696243286,
      "step": 1410
    },
    {
      "epoch": 0.5644,
      "grad_norm": 0.12287309020757675,
      "learning_rate": 8.12e-07,
      "logits/chosen": -2.2452890872955322,
      "logits/rejected": -3.3128750324249268,
      "logps/chosen": -74.86231231689453,
      "logps/rejected": -142.83990478515625,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.10054612159729,
      "rewards/margins": 7.199059963226318,
      "rewards/rejected": -4.098513603210449,
      "step": 1411
    },
    {
      "epoch": 0.5648,
      "grad_norm": 0.009746219031512737,
      "learning_rate": 8.118666666666666e-07,
      "logits/chosen": -2.3849081993103027,
      "logits/rejected": -3.3089685440063477,
      "logps/chosen": -116.71521759033203,
      "logps/rejected": -162.02723693847656,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.017916202545166,
      "rewards/margins": 9.081097602844238,
      "rewards/rejected": -5.063181400299072,
      "step": 1412
    },
    {
      "epoch": 0.5652,
      "grad_norm": 1.4521028995513916,
      "learning_rate": 8.117333333333333e-07,
      "logits/chosen": -2.2124409675598145,
      "logits/rejected": -2.9437355995178223,
      "logps/chosen": -130.9766082763672,
      "logps/rejected": -157.53555297851562,
      "loss": 0.0103,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.934652328491211,
      "rewards/margins": 5.796454429626465,
      "rewards/rejected": -3.861802101135254,
      "step": 1413
    },
    {
      "epoch": 0.5656,
      "grad_norm": 0.2307768017053604,
      "learning_rate": 8.116e-07,
      "logits/chosen": -2.620824098587036,
      "logits/rejected": -3.042008638381958,
      "logps/chosen": -132.6708526611328,
      "logps/rejected": -156.22369384765625,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2399094104766846,
      "rewards/margins": 6.921675682067871,
      "rewards/rejected": -4.681766510009766,
      "step": 1414
    },
    {
      "epoch": 0.566,
      "grad_norm": 0.6399866342544556,
      "learning_rate": 8.114666666666667e-07,
      "logits/chosen": -2.370759963989258,
      "logits/rejected": -2.789923667907715,
      "logps/chosen": -136.47677612304688,
      "logps/rejected": -144.26145935058594,
      "loss": 0.0072,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4413719177246094,
      "rewards/margins": 5.151664733886719,
      "rewards/rejected": -3.710292339324951,
      "step": 1415
    },
    {
      "epoch": 0.5664,
      "grad_norm": 4.041889667510986,
      "learning_rate": 8.113333333333333e-07,
      "logits/chosen": -2.903606414794922,
      "logits/rejected": -3.4427428245544434,
      "logps/chosen": -168.0550079345703,
      "logps/rejected": -116.00105285644531,
      "loss": 0.0379,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8348149061203003,
      "rewards/margins": 4.989677429199219,
      "rewards/rejected": -3.154862403869629,
      "step": 1416
    },
    {
      "epoch": 0.5668,
      "grad_norm": 0.7177549004554749,
      "learning_rate": 8.112e-07,
      "logits/chosen": -2.408535957336426,
      "logits/rejected": -3.314708709716797,
      "logps/chosen": -79.31867980957031,
      "logps/rejected": -155.98526000976562,
      "loss": 0.0061,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6596755981445312,
      "rewards/margins": 6.44870138168335,
      "rewards/rejected": -3.7890255451202393,
      "step": 1417
    },
    {
      "epoch": 0.5672,
      "grad_norm": 1.2545392513275146,
      "learning_rate": 8.110666666666667e-07,
      "logits/chosen": -2.471045970916748,
      "logits/rejected": -2.9411253929138184,
      "logps/chosen": -117.83527374267578,
      "logps/rejected": -141.546875,
      "loss": 0.0092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.072779893875122,
      "rewards/margins": 5.737468719482422,
      "rewards/rejected": -3.6646885871887207,
      "step": 1418
    },
    {
      "epoch": 0.5676,
      "grad_norm": 0.08686299622058868,
      "learning_rate": 8.109333333333332e-07,
      "logits/chosen": -1.8181973695755005,
      "logits/rejected": -2.312307357788086,
      "logps/chosen": -70.2554931640625,
      "logps/rejected": -109.8953857421875,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2858188152313232,
      "rewards/margins": 6.8268723487854,
      "rewards/rejected": -3.541053295135498,
      "step": 1419
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.34345680475234985,
      "learning_rate": 8.107999999999999e-07,
      "logits/chosen": -1.6504366397857666,
      "logits/rejected": -2.3786067962646484,
      "logps/chosen": -110.55117797851562,
      "logps/rejected": -105.35038757324219,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8477375507354736,
      "rewards/margins": 5.900060176849365,
      "rewards/rejected": -3.0523228645324707,
      "step": 1420
    },
    {
      "epoch": 0.5684,
      "grad_norm": 1.0612998008728027,
      "learning_rate": 8.106666666666666e-07,
      "logits/chosen": -2.3805038928985596,
      "logits/rejected": -2.808913230895996,
      "logps/chosen": -140.8147735595703,
      "logps/rejected": -169.42446899414062,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.034045696258545,
      "rewards/margins": 4.932064056396484,
      "rewards/rejected": -2.8980178833007812,
      "step": 1421
    },
    {
      "epoch": 0.5688,
      "grad_norm": 0.1565454602241516,
      "learning_rate": 8.105333333333333e-07,
      "logits/chosen": -2.585771083831787,
      "logits/rejected": -2.9281504154205322,
      "logps/chosen": -136.53079223632812,
      "logps/rejected": -131.70965576171875,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7636306285858154,
      "rewards/margins": 6.238153457641602,
      "rewards/rejected": -4.474522590637207,
      "step": 1422
    },
    {
      "epoch": 0.5692,
      "grad_norm": 0.3850236237049103,
      "learning_rate": 8.104e-07,
      "logits/chosen": -2.1331546306610107,
      "logits/rejected": -2.783714532852173,
      "logps/chosen": -143.24090576171875,
      "logps/rejected": -160.90200805664062,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.55561900138855,
      "rewards/margins": 5.787209987640381,
      "rewards/rejected": -3.231590986251831,
      "step": 1423
    },
    {
      "epoch": 0.5696,
      "grad_norm": 1.1486936807632446,
      "learning_rate": 8.102666666666667e-07,
      "logits/chosen": -2.584484577178955,
      "logits/rejected": -3.621924877166748,
      "logps/chosen": -178.27732849121094,
      "logps/rejected": -130.43362426757812,
      "loss": 0.0108,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4243083000183105,
      "rewards/margins": 6.874740123748779,
      "rewards/rejected": -3.4504318237304688,
      "step": 1424
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.020536640658974648,
      "learning_rate": 8.101333333333334e-07,
      "logits/chosen": -2.4696712493896484,
      "logits/rejected": -2.7165074348449707,
      "logps/chosen": -114.12322235107422,
      "logps/rejected": -184.78848266601562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.415921211242676,
      "rewards/margins": 8.411701202392578,
      "rewards/rejected": -4.995779037475586,
      "step": 1425
    },
    {
      "epoch": 0.5704,
      "grad_norm": 0.8608390092849731,
      "learning_rate": 8.1e-07,
      "logits/chosen": -2.418928384780884,
      "logits/rejected": -3.424034595489502,
      "logps/chosen": -133.12246704101562,
      "logps/rejected": -146.70655822753906,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.220506429672241,
      "rewards/margins": 6.064222812652588,
      "rewards/rejected": -3.8437161445617676,
      "step": 1426
    },
    {
      "epoch": 0.5708,
      "grad_norm": 0.020473118871450424,
      "learning_rate": 8.098666666666666e-07,
      "logits/chosen": -2.28671932220459,
      "logits/rejected": -3.1506199836730957,
      "logps/chosen": -165.18121337890625,
      "logps/rejected": -159.1195068359375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.260343074798584,
      "rewards/margins": 8.582880973815918,
      "rewards/rejected": -4.322537422180176,
      "step": 1427
    },
    {
      "epoch": 0.5712,
      "grad_norm": 0.46394675970077515,
      "learning_rate": 8.097333333333333e-07,
      "logits/chosen": -2.0790064334869385,
      "logits/rejected": -3.1746695041656494,
      "logps/chosen": -152.03802490234375,
      "logps/rejected": -219.97361755371094,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1704063415527344,
      "rewards/margins": 5.907146453857422,
      "rewards/rejected": -3.7367396354675293,
      "step": 1428
    },
    {
      "epoch": 0.5716,
      "grad_norm": 3.702688694000244,
      "learning_rate": 8.095999999999999e-07,
      "logits/chosen": -2.544482707977295,
      "logits/rejected": -3.164294958114624,
      "logps/chosen": -140.77957153320312,
      "logps/rejected": -145.7736053466797,
      "loss": 0.0326,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0077636241912842,
      "rewards/margins": 3.686836004257202,
      "rewards/rejected": -4.694599628448486,
      "step": 1429
    },
    {
      "epoch": 0.572,
      "grad_norm": 0.14396759867668152,
      "learning_rate": 8.094666666666666e-07,
      "logits/chosen": -2.2745282649993896,
      "logits/rejected": -2.750945568084717,
      "logps/chosen": -98.32865905761719,
      "logps/rejected": -120.48497772216797,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.098345994949341,
      "rewards/margins": 6.412298202514648,
      "rewards/rejected": -4.3139519691467285,
      "step": 1430
    },
    {
      "epoch": 0.5724,
      "grad_norm": 0.2511109411716461,
      "learning_rate": 8.093333333333333e-07,
      "logits/chosen": -2.3597874641418457,
      "logits/rejected": -2.760014295578003,
      "logps/chosen": -156.64273071289062,
      "logps/rejected": -105.6834716796875,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7073020935058594,
      "rewards/margins": 6.100115776062012,
      "rewards/rejected": -3.3928136825561523,
      "step": 1431
    },
    {
      "epoch": 0.5728,
      "grad_norm": 1.540626049041748,
      "learning_rate": 8.092e-07,
      "logits/chosen": -2.09210467338562,
      "logits/rejected": -3.0713682174682617,
      "logps/chosen": -109.13885498046875,
      "logps/rejected": -145.48391723632812,
      "loss": 0.012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8557018041610718,
      "rewards/margins": 5.19179630279541,
      "rewards/rejected": -3.336094856262207,
      "step": 1432
    },
    {
      "epoch": 0.5732,
      "grad_norm": 0.7031272053718567,
      "learning_rate": 8.090666666666667e-07,
      "logits/chosen": -2.2283453941345215,
      "logits/rejected": -3.4604339599609375,
      "logps/chosen": -167.51278686523438,
      "logps/rejected": -200.93765258789062,
      "loss": 0.0064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2240066528320312,
      "rewards/margins": 5.830786228179932,
      "rewards/rejected": -4.6067795753479,
      "step": 1433
    },
    {
      "epoch": 0.5736,
      "grad_norm": 0.44514307379722595,
      "learning_rate": 8.089333333333333e-07,
      "logits/chosen": -1.8581721782684326,
      "logits/rejected": -2.1653709411621094,
      "logps/chosen": -122.38770294189453,
      "logps/rejected": -129.61770629882812,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.147916793823242,
      "rewards/margins": 5.325597286224365,
      "rewards/rejected": -2.177680730819702,
      "step": 1434
    },
    {
      "epoch": 0.574,
      "grad_norm": 0.8002324104309082,
      "learning_rate": 8.087999999999999e-07,
      "logits/chosen": -2.1934807300567627,
      "logits/rejected": -3.5208559036254883,
      "logps/chosen": -83.32239532470703,
      "logps/rejected": -144.64163208007812,
      "loss": 0.0064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1091949939727783,
      "rewards/margins": 5.8018927574157715,
      "rewards/rejected": -3.692697525024414,
      "step": 1435
    },
    {
      "epoch": 0.5744,
      "grad_norm": 0.04721732437610626,
      "learning_rate": 8.086666666666666e-07,
      "logits/chosen": -2.204834222793579,
      "logits/rejected": -2.990945339202881,
      "logps/chosen": -114.1139144897461,
      "logps/rejected": -156.73675537109375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8744277954101562,
      "rewards/margins": 7.931584358215332,
      "rewards/rejected": -4.057156562805176,
      "step": 1436
    },
    {
      "epoch": 0.5748,
      "grad_norm": 0.015235322527587414,
      "learning_rate": 8.085333333333333e-07,
      "logits/chosen": -2.0979456901550293,
      "logits/rejected": -2.744560718536377,
      "logps/chosen": -103.54415893554688,
      "logps/rejected": -166.68017578125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7884552478790283,
      "rewards/margins": 8.635028839111328,
      "rewards/rejected": -4.846573829650879,
      "step": 1437
    },
    {
      "epoch": 0.5752,
      "grad_norm": 0.0670328438282013,
      "learning_rate": 8.084e-07,
      "logits/chosen": -2.4459598064422607,
      "logits/rejected": -2.838188886642456,
      "logps/chosen": -125.88882446289062,
      "logps/rejected": -164.45494079589844,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.087299823760986,
      "rewards/margins": 7.340952396392822,
      "rewards/rejected": -3.2536520957946777,
      "step": 1438
    },
    {
      "epoch": 0.5756,
      "grad_norm": 1.3871337175369263,
      "learning_rate": 8.082666666666667e-07,
      "logits/chosen": -2.0879008769989014,
      "logits/rejected": -2.4958560466766357,
      "logps/chosen": -130.92401123046875,
      "logps/rejected": -171.68753051757812,
      "loss": 0.0169,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.701803684234619,
      "rewards/margins": 4.593260765075684,
      "rewards/rejected": -1.8914573192596436,
      "step": 1439
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.41663023829460144,
      "learning_rate": 8.081333333333333e-07,
      "logits/chosen": -2.0638961791992188,
      "logits/rejected": -2.894864082336426,
      "logps/chosen": -71.99911499023438,
      "logps/rejected": -118.76962280273438,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.18636417388916,
      "rewards/margins": 6.181209564208984,
      "rewards/rejected": -2.994845390319824,
      "step": 1440
    },
    {
      "epoch": 0.5764,
      "grad_norm": 0.25500017404556274,
      "learning_rate": 8.08e-07,
      "logits/chosen": -2.4917163848876953,
      "logits/rejected": -2.980083465576172,
      "logps/chosen": -97.83539581298828,
      "logps/rejected": -172.39390563964844,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5915658473968506,
      "rewards/margins": 7.757344722747803,
      "rewards/rejected": -5.165779113769531,
      "step": 1441
    },
    {
      "epoch": 0.5768,
      "grad_norm": 0.24428454041481018,
      "learning_rate": 8.078666666666666e-07,
      "logits/chosen": -2.4383740425109863,
      "logits/rejected": -3.2380130290985107,
      "logps/chosen": -127.57970428466797,
      "logps/rejected": -125.53582000732422,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8320512771606445,
      "rewards/margins": 6.950620174407959,
      "rewards/rejected": -4.118569374084473,
      "step": 1442
    },
    {
      "epoch": 0.5772,
      "grad_norm": 0.2631043493747711,
      "learning_rate": 8.077333333333333e-07,
      "logits/chosen": -2.419729232788086,
      "logits/rejected": -3.4337453842163086,
      "logps/chosen": -128.61056518554688,
      "logps/rejected": -150.41612243652344,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6517159938812256,
      "rewards/margins": 7.463291645050049,
      "rewards/rejected": -4.811575412750244,
      "step": 1443
    },
    {
      "epoch": 0.5776,
      "grad_norm": 0.6884620189666748,
      "learning_rate": 8.075999999999999e-07,
      "logits/chosen": -2.1739187240600586,
      "logits/rejected": -2.7721729278564453,
      "logps/chosen": -86.99357604980469,
      "logps/rejected": -109.616943359375,
      "loss": 0.0097,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0581204891204834,
      "rewards/margins": 4.940797805786133,
      "rewards/rejected": -2.8826777935028076,
      "step": 1444
    },
    {
      "epoch": 0.578,
      "grad_norm": 2.327791213989258,
      "learning_rate": 8.074666666666666e-07,
      "logits/chosen": -2.1844372749328613,
      "logits/rejected": -2.6933178901672363,
      "logps/chosen": -142.98538208007812,
      "logps/rejected": -103.43428802490234,
      "loss": 0.0313,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5710220336914062,
      "rewards/margins": 3.6415300369262695,
      "rewards/rejected": -3.0705080032348633,
      "step": 1445
    },
    {
      "epoch": 0.5784,
      "grad_norm": 0.15849971771240234,
      "learning_rate": 8.073333333333333e-07,
      "logits/chosen": -1.9882781505584717,
      "logits/rejected": -2.9735798835754395,
      "logps/chosen": -84.68745422363281,
      "logps/rejected": -126.0217056274414,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2863075733184814,
      "rewards/margins": 7.036451816558838,
      "rewards/rejected": -3.7501444816589355,
      "step": 1446
    },
    {
      "epoch": 0.5788,
      "grad_norm": 0.9490106105804443,
      "learning_rate": 8.072e-07,
      "logits/chosen": -2.494473457336426,
      "logits/rejected": -3.0023353099823,
      "logps/chosen": -125.43944549560547,
      "logps/rejected": -126.60884094238281,
      "loss": 0.0103,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3504250049591064,
      "rewards/margins": 4.629581451416016,
      "rewards/rejected": -3.27915620803833,
      "step": 1447
    },
    {
      "epoch": 0.5792,
      "grad_norm": 3.509965419769287,
      "learning_rate": 8.070666666666667e-07,
      "logits/chosen": -1.8351953029632568,
      "logits/rejected": -2.3844079971313477,
      "logps/chosen": -118.59474182128906,
      "logps/rejected": -111.81045532226562,
      "loss": 0.0225,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4364070892333984,
      "rewards/margins": 5.648932456970215,
      "rewards/rejected": -3.2125253677368164,
      "step": 1448
    },
    {
      "epoch": 0.5796,
      "grad_norm": 0.07240763306617737,
      "learning_rate": 8.069333333333333e-07,
      "logits/chosen": -2.4602713584899902,
      "logits/rejected": -2.8980250358581543,
      "logps/chosen": -142.47509765625,
      "logps/rejected": -139.17318725585938,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8109054565429688,
      "rewards/margins": 8.160367012023926,
      "rewards/rejected": -4.349461555480957,
      "step": 1449
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.06312092393636703,
      "learning_rate": 8.067999999999999e-07,
      "logits/chosen": -2.271472454071045,
      "logits/rejected": -3.2108922004699707,
      "logps/chosen": -207.97091674804688,
      "logps/rejected": -175.01388549804688,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6881890296936035,
      "rewards/margins": 7.850480079650879,
      "rewards/rejected": -6.162291526794434,
      "step": 1450
    },
    {
      "epoch": 0.5804,
      "grad_norm": 2.083397388458252,
      "learning_rate": 8.066666666666666e-07,
      "logits/chosen": -2.4848742485046387,
      "logits/rejected": -3.135239601135254,
      "logps/chosen": -100.35978698730469,
      "logps/rejected": -129.2379150390625,
      "loss": 0.0231,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8924083709716797,
      "rewards/margins": 4.504242897033691,
      "rewards/rejected": -3.6118342876434326,
      "step": 1451
    },
    {
      "epoch": 0.5808,
      "grad_norm": 3.7200446128845215,
      "learning_rate": 8.065333333333333e-07,
      "logits/chosen": -2.668041229248047,
      "logits/rejected": -2.530031681060791,
      "logps/chosen": -229.1495819091797,
      "logps/rejected": -136.1616973876953,
      "loss": 0.0262,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7333152294158936,
      "rewards/margins": 5.122823715209961,
      "rewards/rejected": -3.3895084857940674,
      "step": 1452
    },
    {
      "epoch": 0.5812,
      "grad_norm": 1.0949172973632812,
      "learning_rate": 8.064e-07,
      "logits/chosen": -2.624824047088623,
      "logits/rejected": -2.6960887908935547,
      "logps/chosen": -229.97085571289062,
      "logps/rejected": -143.014892578125,
      "loss": 0.0115,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.714514970779419,
      "rewards/margins": 4.730788707733154,
      "rewards/rejected": -2.0162734985351562,
      "step": 1453
    },
    {
      "epoch": 0.5816,
      "grad_norm": 0.7888593673706055,
      "learning_rate": 8.062666666666666e-07,
      "logits/chosen": -2.077165126800537,
      "logits/rejected": -3.434432029724121,
      "logps/chosen": -90.43135833740234,
      "logps/rejected": -151.18467712402344,
      "loss": 0.0092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3399059474468231,
      "rewards/margins": 4.752970218658447,
      "rewards/rejected": -5.092876434326172,
      "step": 1454
    },
    {
      "epoch": 0.582,
      "grad_norm": 0.24284550547599792,
      "learning_rate": 8.061333333333333e-07,
      "logits/chosen": -2.373811721801758,
      "logits/rejected": -3.5254006385803223,
      "logps/chosen": -141.43605041503906,
      "logps/rejected": -167.51145935058594,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7078800201416016,
      "rewards/margins": 6.518720626831055,
      "rewards/rejected": -2.810840606689453,
      "step": 1455
    },
    {
      "epoch": 0.5824,
      "grad_norm": 0.05921309441328049,
      "learning_rate": 8.06e-07,
      "logits/chosen": -1.9769376516342163,
      "logits/rejected": -3.1807188987731934,
      "logps/chosen": -133.215576171875,
      "logps/rejected": -155.664794921875,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8439559936523438,
      "rewards/margins": 8.517232894897461,
      "rewards/rejected": -4.673276901245117,
      "step": 1456
    },
    {
      "epoch": 0.5828,
      "grad_norm": 1.7392709255218506,
      "learning_rate": 8.058666666666666e-07,
      "logits/chosen": -2.2625842094421387,
      "logits/rejected": -2.81691837310791,
      "logps/chosen": -137.76983642578125,
      "logps/rejected": -130.4996337890625,
      "loss": 0.0186,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7421700954437256,
      "rewards/margins": 5.599038124084473,
      "rewards/rejected": -3.856867790222168,
      "step": 1457
    },
    {
      "epoch": 0.5832,
      "grad_norm": 0.2482825368642807,
      "learning_rate": 8.057333333333333e-07,
      "logits/chosen": -1.872104287147522,
      "logits/rejected": -3.0136473178863525,
      "logps/chosen": -108.71188354492188,
      "logps/rejected": -136.3902587890625,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4539059400558472,
      "rewards/margins": 6.454010963439941,
      "rewards/rejected": -5.000104904174805,
      "step": 1458
    },
    {
      "epoch": 0.5836,
      "grad_norm": 0.71074378490448,
      "learning_rate": 8.056e-07,
      "logits/chosen": -2.547703742980957,
      "logits/rejected": -2.8918776512145996,
      "logps/chosen": -140.4224090576172,
      "logps/rejected": -154.44712829589844,
      "loss": 0.0062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2925498485565186,
      "rewards/margins": 7.105434417724609,
      "rewards/rejected": -4.812884330749512,
      "step": 1459
    },
    {
      "epoch": 0.584,
      "grad_norm": 0.3468582332134247,
      "learning_rate": 8.054666666666667e-07,
      "logits/chosen": -1.969536304473877,
      "logits/rejected": -3.3033857345581055,
      "logps/chosen": -78.61708068847656,
      "logps/rejected": -127.6502685546875,
      "loss": 0.005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2929630279541016,
      "rewards/margins": 5.677745342254639,
      "rewards/rejected": -3.384782314300537,
      "step": 1460
    },
    {
      "epoch": 0.5844,
      "grad_norm": 0.15899530053138733,
      "learning_rate": 8.053333333333333e-07,
      "logits/chosen": -2.380575656890869,
      "logits/rejected": -2.5824570655822754,
      "logps/chosen": -110.49059295654297,
      "logps/rejected": -106.27642822265625,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.363827705383301,
      "rewards/margins": 6.803566932678223,
      "rewards/rejected": -3.439739227294922,
      "step": 1461
    },
    {
      "epoch": 0.5848,
      "grad_norm": 0.9498111009597778,
      "learning_rate": 8.052e-07,
      "logits/chosen": -2.6074934005737305,
      "logits/rejected": -3.1734459400177,
      "logps/chosen": -192.62060546875,
      "logps/rejected": -214.81768798828125,
      "loss": 0.0082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.324942111968994,
      "rewards/margins": 5.711398601531982,
      "rewards/rejected": -3.3864564895629883,
      "step": 1462
    },
    {
      "epoch": 0.5852,
      "grad_norm": 0.19546036422252655,
      "learning_rate": 8.050666666666666e-07,
      "logits/chosen": -2.5171337127685547,
      "logits/rejected": -2.7555735111236572,
      "logps/chosen": -118.43854522705078,
      "logps/rejected": -145.03366088867188,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3465957641601562,
      "rewards/margins": 6.744515419006348,
      "rewards/rejected": -3.3979196548461914,
      "step": 1463
    },
    {
      "epoch": 0.5856,
      "grad_norm": 0.028441213071346283,
      "learning_rate": 8.049333333333332e-07,
      "logits/chosen": -2.505469799041748,
      "logits/rejected": -3.0077667236328125,
      "logps/chosen": -103.76396179199219,
      "logps/rejected": -162.44183349609375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3517372608184814,
      "rewards/margins": 8.119405746459961,
      "rewards/rejected": -4.767668724060059,
      "step": 1464
    },
    {
      "epoch": 0.586,
      "grad_norm": 0.5257797241210938,
      "learning_rate": 8.047999999999999e-07,
      "logits/chosen": -1.7976984977722168,
      "logits/rejected": -1.6997497081756592,
      "logps/chosen": -74.68382263183594,
      "logps/rejected": -92.28651428222656,
      "loss": 0.0064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7902560234069824,
      "rewards/margins": 5.103218078613281,
      "rewards/rejected": -2.312962055206299,
      "step": 1465
    },
    {
      "epoch": 0.5864,
      "grad_norm": 0.06253549456596375,
      "learning_rate": 8.046666666666666e-07,
      "logits/chosen": -2.0450639724731445,
      "logits/rejected": -2.4375221729278564,
      "logps/chosen": -109.87469482421875,
      "logps/rejected": -127.46501159667969,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0669612884521484,
      "rewards/margins": 7.144220352172852,
      "rewards/rejected": -4.077259540557861,
      "step": 1466
    },
    {
      "epoch": 0.5868,
      "grad_norm": 0.18602199852466583,
      "learning_rate": 8.045333333333333e-07,
      "logits/chosen": -1.998112678527832,
      "logits/rejected": -3.061596393585205,
      "logps/chosen": -69.14292907714844,
      "logps/rejected": -125.61817169189453,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.112602710723877,
      "rewards/margins": 6.051634311676025,
      "rewards/rejected": -3.9390316009521484,
      "step": 1467
    },
    {
      "epoch": 0.5872,
      "grad_norm": 0.1346173882484436,
      "learning_rate": 8.044e-07,
      "logits/chosen": -1.9650132656097412,
      "logits/rejected": -3.2007691860198975,
      "logps/chosen": -64.59576416015625,
      "logps/rejected": -127.43424987792969,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9866620302200317,
      "rewards/margins": 6.136902809143066,
      "rewards/rejected": -4.150240898132324,
      "step": 1468
    },
    {
      "epoch": 0.5876,
      "grad_norm": 1.3260730504989624,
      "learning_rate": 8.042666666666667e-07,
      "logits/chosen": -2.487698554992676,
      "logits/rejected": -3.578169345855713,
      "logps/chosen": -193.73995971679688,
      "logps/rejected": -108.97579956054688,
      "loss": 0.0138,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.238314151763916,
      "rewards/margins": 4.507101058959961,
      "rewards/rejected": -2.268786668777466,
      "step": 1469
    },
    {
      "epoch": 0.588,
      "grad_norm": 0.9564722776412964,
      "learning_rate": 8.041333333333334e-07,
      "logits/chosen": -2.3227972984313965,
      "logits/rejected": -3.496717929840088,
      "logps/chosen": -98.38040161132812,
      "logps/rejected": -147.26742553710938,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9670257568359375,
      "rewards/margins": 5.685808181762695,
      "rewards/rejected": -4.718782424926758,
      "step": 1470
    },
    {
      "epoch": 0.5884,
      "grad_norm": 1.105922818183899,
      "learning_rate": 8.04e-07,
      "logits/chosen": -3.010284900665283,
      "logits/rejected": -3.511028289794922,
      "logps/chosen": -300.1108093261719,
      "logps/rejected": -168.0399169921875,
      "loss": 0.0074,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8872292041778564,
      "rewards/margins": 6.452001571655273,
      "rewards/rejected": -4.564772129058838,
      "step": 1471
    },
    {
      "epoch": 0.5888,
      "grad_norm": 0.010532877407968044,
      "learning_rate": 8.038666666666665e-07,
      "logits/chosen": -2.284883975982666,
      "logits/rejected": -3.3580074310302734,
      "logps/chosen": -111.93983459472656,
      "logps/rejected": -154.15298461914062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.377716541290283,
      "rewards/margins": 9.02884292602539,
      "rewards/rejected": -4.651126861572266,
      "step": 1472
    },
    {
      "epoch": 0.5892,
      "grad_norm": 0.693286657333374,
      "learning_rate": 8.037333333333332e-07,
      "logits/chosen": -2.2581124305725098,
      "logits/rejected": -2.2767856121063232,
      "logps/chosen": -114.9168701171875,
      "logps/rejected": -111.84442901611328,
      "loss": 0.005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4166059494018555,
      "rewards/margins": 5.877175331115723,
      "rewards/rejected": -2.460569381713867,
      "step": 1473
    },
    {
      "epoch": 0.5896,
      "grad_norm": 2.4350929260253906,
      "learning_rate": 8.035999999999999e-07,
      "logits/chosen": -2.4578020572662354,
      "logits/rejected": -2.6873443126678467,
      "logps/chosen": -141.9727325439453,
      "logps/rejected": -151.68821716308594,
      "loss": 0.0264,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1567203998565674,
      "rewards/margins": 4.352604866027832,
      "rewards/rejected": -3.1958842277526855,
      "step": 1474
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.986609697341919,
      "learning_rate": 8.034666666666666e-07,
      "logits/chosen": -2.5642800331115723,
      "logits/rejected": -2.610184669494629,
      "logps/chosen": -100.65420532226562,
      "logps/rejected": -108.35789489746094,
      "loss": 0.0368,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38618773221969604,
      "rewards/margins": 4.109541893005371,
      "rewards/rejected": -3.7233543395996094,
      "step": 1475
    },
    {
      "epoch": 0.5904,
      "grad_norm": 0.5255550146102905,
      "learning_rate": 8.033333333333333e-07,
      "logits/chosen": -2.623591661453247,
      "logits/rejected": -2.9361977577209473,
      "logps/chosen": -178.17344665527344,
      "logps/rejected": -146.3112335205078,
      "loss": 0.0068,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9402153491973877,
      "rewards/margins": 7.128429412841797,
      "rewards/rejected": -5.18821382522583,
      "step": 1476
    },
    {
      "epoch": 0.5908,
      "grad_norm": 0.812605619430542,
      "learning_rate": 8.032e-07,
      "logits/chosen": -1.5834338665008545,
      "logits/rejected": -2.6932504177093506,
      "logps/chosen": -88.59780883789062,
      "logps/rejected": -110.61004638671875,
      "loss": 0.0097,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6020350456237793,
      "rewards/margins": 4.650925636291504,
      "rewards/rejected": -3.0488905906677246,
      "step": 1477
    },
    {
      "epoch": 0.5912,
      "grad_norm": 3.3006362915039062,
      "learning_rate": 8.030666666666667e-07,
      "logits/chosen": -2.5249786376953125,
      "logits/rejected": -2.5799918174743652,
      "logps/chosen": -136.8280792236328,
      "logps/rejected": -132.0389404296875,
      "loss": 0.0319,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8011718988418579,
      "rewards/margins": 4.069931983947754,
      "rewards/rejected": -3.2687602043151855,
      "step": 1478
    },
    {
      "epoch": 0.5916,
      "grad_norm": 0.3716278672218323,
      "learning_rate": 8.029333333333334e-07,
      "logits/chosen": -2.376903772354126,
      "logits/rejected": -2.9591004848480225,
      "logps/chosen": -116.14147186279297,
      "logps/rejected": -213.92654418945312,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2876782417297363,
      "rewards/margins": 8.374687194824219,
      "rewards/rejected": -5.087008476257324,
      "step": 1479
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.7180634140968323,
      "learning_rate": 8.028e-07,
      "logits/chosen": -2.021841049194336,
      "logits/rejected": -3.1689987182617188,
      "logps/chosen": -78.91912841796875,
      "logps/rejected": -131.85873413085938,
      "loss": 0.0071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3065173625946045,
      "rewards/margins": 5.866982460021973,
      "rewards/rejected": -3.5604653358459473,
      "step": 1480
    },
    {
      "epoch": 0.5924,
      "grad_norm": 0.8898426294326782,
      "learning_rate": 8.026666666666667e-07,
      "logits/chosen": -2.3517303466796875,
      "logits/rejected": -3.3495941162109375,
      "logps/chosen": -114.11119079589844,
      "logps/rejected": -136.10830688476562,
      "loss": 0.0094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.107487201690674,
      "rewards/margins": 7.002821445465088,
      "rewards/rejected": -3.895334005355835,
      "step": 1481
    },
    {
      "epoch": 0.5928,
      "grad_norm": 0.046031493693590164,
      "learning_rate": 8.025333333333332e-07,
      "logits/chosen": -2.5622658729553223,
      "logits/rejected": -3.425830841064453,
      "logps/chosen": -144.1149139404297,
      "logps/rejected": -172.93356323242188,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1274075508117676,
      "rewards/margins": 8.412914276123047,
      "rewards/rejected": -5.2855072021484375,
      "step": 1482
    },
    {
      "epoch": 0.5932,
      "grad_norm": 0.22632066905498505,
      "learning_rate": 8.023999999999999e-07,
      "logits/chosen": -1.9878671169281006,
      "logits/rejected": -3.0679359436035156,
      "logps/chosen": -120.2923583984375,
      "logps/rejected": -152.70855712890625,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.458059310913086,
      "rewards/margins": 6.589698791503906,
      "rewards/rejected": -4.1316399574279785,
      "step": 1483
    },
    {
      "epoch": 0.5936,
      "grad_norm": 0.08215666562318802,
      "learning_rate": 8.022666666666666e-07,
      "logits/chosen": -1.9668569564819336,
      "logits/rejected": -3.4383015632629395,
      "logps/chosen": -80.34062194824219,
      "logps/rejected": -139.5098419189453,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.257984161376953,
      "rewards/margins": 8.39072322845459,
      "rewards/rejected": -4.1327385902404785,
      "step": 1484
    },
    {
      "epoch": 0.594,
      "grad_norm": 0.8670967817306519,
      "learning_rate": 8.021333333333333e-07,
      "logits/chosen": -2.0107767581939697,
      "logits/rejected": -2.8926939964294434,
      "logps/chosen": -113.2335433959961,
      "logps/rejected": -142.02679443359375,
      "loss": 0.0131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.543098211288452,
      "rewards/margins": 5.4193806648254395,
      "rewards/rejected": -2.8762826919555664,
      "step": 1485
    },
    {
      "epoch": 0.5944,
      "grad_norm": 1.5152865648269653,
      "learning_rate": 8.02e-07,
      "logits/chosen": -2.7841858863830566,
      "logits/rejected": -2.476029872894287,
      "logps/chosen": -145.2806396484375,
      "logps/rejected": -116.08213806152344,
      "loss": 0.016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.127955675125122,
      "rewards/margins": 6.219552993774414,
      "rewards/rejected": -3.091597080230713,
      "step": 1486
    },
    {
      "epoch": 0.5948,
      "grad_norm": 0.11296942085027695,
      "learning_rate": 8.018666666666666e-07,
      "logits/chosen": -2.650925636291504,
      "logits/rejected": -2.7273740768432617,
      "logps/chosen": -111.28141784667969,
      "logps/rejected": -127.98637390136719,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.547696113586426,
      "rewards/margins": 7.385541915893555,
      "rewards/rejected": -3.837845802307129,
      "step": 1487
    },
    {
      "epoch": 0.5952,
      "grad_norm": 0.16481101512908936,
      "learning_rate": 8.017333333333333e-07,
      "logits/chosen": -2.3738667964935303,
      "logits/rejected": -3.401392936706543,
      "logps/chosen": -91.08158874511719,
      "logps/rejected": -161.40676879882812,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7146965265274048,
      "rewards/margins": 7.725730895996094,
      "rewards/rejected": -6.01103401184082,
      "step": 1488
    },
    {
      "epoch": 0.5956,
      "grad_norm": 0.5443803071975708,
      "learning_rate": 8.016e-07,
      "logits/chosen": -1.8986157178878784,
      "logits/rejected": -2.8112947940826416,
      "logps/chosen": -142.75997924804688,
      "logps/rejected": -136.36505126953125,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.958078384399414,
      "rewards/margins": 5.829462051391602,
      "rewards/rejected": -3.8713834285736084,
      "step": 1489
    },
    {
      "epoch": 0.596,
      "grad_norm": 0.1748451590538025,
      "learning_rate": 8.014666666666667e-07,
      "logits/chosen": -2.341381072998047,
      "logits/rejected": -3.3917112350463867,
      "logps/chosen": -178.42884826660156,
      "logps/rejected": -157.84341430664062,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6296448707580566,
      "rewards/margins": 7.147287845611572,
      "rewards/rejected": -4.517642974853516,
      "step": 1490
    },
    {
      "epoch": 0.5964,
      "grad_norm": 0.2402382493019104,
      "learning_rate": 8.013333333333333e-07,
      "logits/chosen": -2.2556309700012207,
      "logits/rejected": -3.088392734527588,
      "logps/chosen": -149.8101806640625,
      "logps/rejected": -140.04034423828125,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.007254123687744,
      "rewards/margins": 6.429914474487305,
      "rewards/rejected": -3.4226601123809814,
      "step": 1491
    },
    {
      "epoch": 0.5968,
      "grad_norm": 0.6315672397613525,
      "learning_rate": 8.012e-07,
      "logits/chosen": -2.636082649230957,
      "logits/rejected": -3.3587889671325684,
      "logps/chosen": -70.73580932617188,
      "logps/rejected": -135.4864959716797,
      "loss": 0.0088,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5639885663986206,
      "rewards/margins": 4.903811931610107,
      "rewards/rejected": -3.3398232460021973,
      "step": 1492
    },
    {
      "epoch": 0.5972,
      "grad_norm": 0.7656000256538391,
      "learning_rate": 8.010666666666666e-07,
      "logits/chosen": -1.7592661380767822,
      "logits/rejected": -2.121061086654663,
      "logps/chosen": -96.78163146972656,
      "logps/rejected": -96.50973510742188,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.716141700744629,
      "rewards/margins": 5.337562561035156,
      "rewards/rejected": -2.6214210987091064,
      "step": 1493
    },
    {
      "epoch": 0.5976,
      "grad_norm": 0.9404783844947815,
      "learning_rate": 8.009333333333333e-07,
      "logits/chosen": -2.4326462745666504,
      "logits/rejected": -3.152350664138794,
      "logps/chosen": -113.47028350830078,
      "logps/rejected": -119.69042205810547,
      "loss": 0.0161,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7669914960861206,
      "rewards/margins": 4.122465133666992,
      "rewards/rejected": -3.355473518371582,
      "step": 1494
    },
    {
      "epoch": 0.598,
      "grad_norm": 0.14317114651203156,
      "learning_rate": 8.007999999999999e-07,
      "logits/chosen": -2.325611114501953,
      "logits/rejected": -2.40767502784729,
      "logps/chosen": -96.22843933105469,
      "logps/rejected": -164.82801818847656,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9934582710266113,
      "rewards/margins": 6.924204349517822,
      "rewards/rejected": -3.930746555328369,
      "step": 1495
    },
    {
      "epoch": 0.5984,
      "grad_norm": 0.10862676799297333,
      "learning_rate": 8.006666666666666e-07,
      "logits/chosen": -1.9279588460922241,
      "logits/rejected": -2.7845633029937744,
      "logps/chosen": -90.39739990234375,
      "logps/rejected": -97.3083267211914,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.408052921295166,
      "rewards/margins": 6.757503986358643,
      "rewards/rejected": -3.3494510650634766,
      "step": 1496
    },
    {
      "epoch": 0.5988,
      "grad_norm": 10.994245529174805,
      "learning_rate": 8.005333333333333e-07,
      "logits/chosen": -2.3812673091888428,
      "logits/rejected": -3.012450695037842,
      "logps/chosen": -92.04023742675781,
      "logps/rejected": -125.92884826660156,
      "loss": 0.1201,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6172165870666504,
      "rewards/margins": 3.902728796005249,
      "rewards/rejected": -2.2855122089385986,
      "step": 1497
    },
    {
      "epoch": 0.5992,
      "grad_norm": 1.79697585105896,
      "learning_rate": 8.004e-07,
      "logits/chosen": -2.2560904026031494,
      "logits/rejected": -2.93792724609375,
      "logps/chosen": -153.01339721679688,
      "logps/rejected": -124.2825927734375,
      "loss": 0.0185,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9817123413085938,
      "rewards/margins": 4.519020080566406,
      "rewards/rejected": -3.5373077392578125,
      "step": 1498
    },
    {
      "epoch": 0.5996,
      "grad_norm": 0.7314362525939941,
      "learning_rate": 8.002666666666667e-07,
      "logits/chosen": -2.724212408065796,
      "logits/rejected": -2.799896717071533,
      "logps/chosen": -123.97003173828125,
      "logps/rejected": -133.94107055664062,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.39078688621521,
      "rewards/margins": 5.830481052398682,
      "rewards/rejected": -3.439694404602051,
      "step": 1499
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.040768858045339584,
      "learning_rate": 8.001333333333334e-07,
      "logits/chosen": -2.3448472023010254,
      "logits/rejected": -3.6931257247924805,
      "logps/chosen": -104.85884857177734,
      "logps/rejected": -148.01412963867188,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8513827323913574,
      "rewards/margins": 7.584356784820557,
      "rewards/rejected": -3.732974052429199,
      "step": 1500
    },
    {
      "epoch": 0.6004,
      "grad_norm": 2.050213575363159,
      "learning_rate": 8e-07,
      "logits/chosen": -1.9122645854949951,
      "logits/rejected": -2.9843122959136963,
      "logps/chosen": -114.20175170898438,
      "logps/rejected": -136.84371948242188,
      "loss": 0.022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1695812940597534,
      "rewards/margins": 4.332303047180176,
      "rewards/rejected": -3.162722110748291,
      "step": 1501
    },
    {
      "epoch": 0.6008,
      "grad_norm": 0.24245156347751617,
      "learning_rate": 7.998666666666665e-07,
      "logits/chosen": -2.3558554649353027,
      "logits/rejected": -3.025040626525879,
      "logps/chosen": -124.45036315917969,
      "logps/rejected": -160.33956909179688,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0925137996673584,
      "rewards/margins": 7.377338409423828,
      "rewards/rejected": -4.284824848175049,
      "step": 1502
    },
    {
      "epoch": 0.6012,
      "grad_norm": 0.15940341353416443,
      "learning_rate": 7.997333333333332e-07,
      "logits/chosen": -2.30430269241333,
      "logits/rejected": -3.474785804748535,
      "logps/chosen": -81.76558685302734,
      "logps/rejected": -152.5533447265625,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2428562641143799,
      "rewards/margins": 6.290988922119141,
      "rewards/rejected": -5.04813289642334,
      "step": 1503
    },
    {
      "epoch": 0.6016,
      "grad_norm": 0.054867956787347794,
      "learning_rate": 7.995999999999999e-07,
      "logits/chosen": -2.0936930179595947,
      "logits/rejected": -2.636770725250244,
      "logps/chosen": -117.81547546386719,
      "logps/rejected": -147.1496124267578,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5756373405456543,
      "rewards/margins": 7.4491801261901855,
      "rewards/rejected": -3.8735427856445312,
      "step": 1504
    },
    {
      "epoch": 0.602,
      "grad_norm": 0.8060466647148132,
      "learning_rate": 7.994666666666666e-07,
      "logits/chosen": -2.3280892372131348,
      "logits/rejected": -2.729287624359131,
      "logps/chosen": -181.63116455078125,
      "logps/rejected": -142.48788452148438,
      "loss": 0.0074,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.644068956375122,
      "rewards/margins": 5.258903503417969,
      "rewards/rejected": -3.6148345470428467,
      "step": 1505
    },
    {
      "epoch": 0.6024,
      "grad_norm": 0.06240799278020859,
      "learning_rate": 7.993333333333333e-07,
      "logits/chosen": -2.2483725547790527,
      "logits/rejected": -3.8500242233276367,
      "logps/chosen": -75.02313232421875,
      "logps/rejected": -140.05859375,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1695306301116943,
      "rewards/margins": 8.256500244140625,
      "rewards/rejected": -5.086969375610352,
      "step": 1506
    },
    {
      "epoch": 0.6028,
      "grad_norm": 0.2045820653438568,
      "learning_rate": 7.992e-07,
      "logits/chosen": -2.445990562438965,
      "logits/rejected": -2.9976415634155273,
      "logps/chosen": -134.5965576171875,
      "logps/rejected": -151.653564453125,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.64158296585083,
      "rewards/margins": 5.984616756439209,
      "rewards/rejected": -4.343033790588379,
      "step": 1507
    },
    {
      "epoch": 0.6032,
      "grad_norm": 0.8535957336425781,
      "learning_rate": 7.990666666666667e-07,
      "logits/chosen": -2.2483129501342773,
      "logits/rejected": -3.1731410026550293,
      "logps/chosen": -138.13558959960938,
      "logps/rejected": -145.92678833007812,
      "loss": 0.0091,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0225563049316406,
      "rewards/margins": 6.047582626342773,
      "rewards/rejected": -4.025026321411133,
      "step": 1508
    },
    {
      "epoch": 0.6036,
      "grad_norm": 0.2796647250652313,
      "learning_rate": 7.989333333333334e-07,
      "logits/chosen": -2.3568668365478516,
      "logits/rejected": -3.079349994659424,
      "logps/chosen": -146.2170867919922,
      "logps/rejected": -195.5679168701172,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8558883666992188,
      "rewards/margins": 6.8184309005737305,
      "rewards/rejected": -4.962542533874512,
      "step": 1509
    },
    {
      "epoch": 0.604,
      "grad_norm": 0.7867849469184875,
      "learning_rate": 7.987999999999999e-07,
      "logits/chosen": -1.9670518636703491,
      "logits/rejected": -2.483529806137085,
      "logps/chosen": -143.73953247070312,
      "logps/rejected": -148.7789306640625,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0848109722137451,
      "rewards/margins": 5.870145797729492,
      "rewards/rejected": -4.785334587097168,
      "step": 1510
    },
    {
      "epoch": 0.6044,
      "grad_norm": 0.41151684522628784,
      "learning_rate": 7.986666666666666e-07,
      "logits/chosen": -2.423337936401367,
      "logits/rejected": -2.9952054023742676,
      "logps/chosen": -116.33302307128906,
      "logps/rejected": -133.61614990234375,
      "loss": 0.0049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.321922779083252,
      "rewards/margins": 5.820713520050049,
      "rewards/rejected": -3.498790740966797,
      "step": 1511
    },
    {
      "epoch": 0.6048,
      "grad_norm": 0.09067461639642715,
      "learning_rate": 7.985333333333333e-07,
      "logits/chosen": -2.341672897338867,
      "logits/rejected": -3.4729559421539307,
      "logps/chosen": -129.20608520507812,
      "logps/rejected": -142.21282958984375,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9523167610168457,
      "rewards/margins": 6.664656162261963,
      "rewards/rejected": -3.712339401245117,
      "step": 1512
    },
    {
      "epoch": 0.6052,
      "grad_norm": 1.7695097923278809,
      "learning_rate": 7.984e-07,
      "logits/chosen": -2.1325325965881348,
      "logits/rejected": -2.435530662536621,
      "logps/chosen": -119.9722900390625,
      "logps/rejected": -123.21090698242188,
      "loss": 0.0235,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.936906099319458,
      "rewards/margins": 6.225142955780029,
      "rewards/rejected": -4.28823709487915,
      "step": 1513
    },
    {
      "epoch": 0.6056,
      "grad_norm": 0.2925688922405243,
      "learning_rate": 7.982666666666666e-07,
      "logits/chosen": -2.069838523864746,
      "logits/rejected": -2.459101438522339,
      "logps/chosen": -133.968505859375,
      "logps/rejected": -133.14463806152344,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4674431085586548,
      "rewards/margins": 5.552956581115723,
      "rewards/rejected": -4.085513591766357,
      "step": 1514
    },
    {
      "epoch": 0.606,
      "grad_norm": 0.009734469465911388,
      "learning_rate": 7.981333333333333e-07,
      "logits/chosen": -2.006037712097168,
      "logits/rejected": -3.187622547149658,
      "logps/chosen": -85.0361328125,
      "logps/rejected": -166.16018676757812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.166364669799805,
      "rewards/margins": 9.12157917022705,
      "rewards/rejected": -4.955214023590088,
      "step": 1515
    },
    {
      "epoch": 0.6064,
      "grad_norm": 0.1786152571439743,
      "learning_rate": 7.98e-07,
      "logits/chosen": -2.505237102508545,
      "logits/rejected": -2.981072187423706,
      "logps/chosen": -133.16726684570312,
      "logps/rejected": -142.5060272216797,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5177788734436035,
      "rewards/margins": 7.325465679168701,
      "rewards/rejected": -4.807686805725098,
      "step": 1516
    },
    {
      "epoch": 0.6068,
      "grad_norm": 0.13697971403598785,
      "learning_rate": 7.978666666666666e-07,
      "logits/chosen": -2.440553903579712,
      "logits/rejected": -3.0997958183288574,
      "logps/chosen": -65.98797607421875,
      "logps/rejected": -137.38229370117188,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.276059627532959,
      "rewards/margins": 7.573041915893555,
      "rewards/rejected": -4.2969818115234375,
      "step": 1517
    },
    {
      "epoch": 0.6072,
      "grad_norm": 1.8780598640441895,
      "learning_rate": 7.977333333333333e-07,
      "logits/chosen": -2.11838960647583,
      "logits/rejected": -3.067483901977539,
      "logps/chosen": -113.5423812866211,
      "logps/rejected": -119.9410629272461,
      "loss": 0.0167,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4556984901428223,
      "rewards/margins": 6.097740173339844,
      "rewards/rejected": -3.6420419216156006,
      "step": 1518
    },
    {
      "epoch": 0.6076,
      "grad_norm": 0.2859410047531128,
      "learning_rate": 7.975999999999999e-07,
      "logits/chosen": -2.6441309452056885,
      "logits/rejected": -2.7966084480285645,
      "logps/chosen": -172.62899780273438,
      "logps/rejected": -162.8141632080078,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0836776494979858,
      "rewards/margins": 5.685493469238281,
      "rewards/rejected": -4.601816177368164,
      "step": 1519
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.054154302924871445,
      "learning_rate": 7.974666666666666e-07,
      "logits/chosen": -2.616407871246338,
      "logits/rejected": -3.4451491832733154,
      "logps/chosen": -201.25961303710938,
      "logps/rejected": -152.9423828125,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.418191432952881,
      "rewards/margins": 7.628907680511475,
      "rewards/rejected": -4.210716247558594,
      "step": 1520
    },
    {
      "epoch": 0.6084,
      "grad_norm": 0.5739803314208984,
      "learning_rate": 7.973333333333333e-07,
      "logits/chosen": -2.1208858489990234,
      "logits/rejected": -2.9273762702941895,
      "logps/chosen": -93.45928955078125,
      "logps/rejected": -137.77261352539062,
      "loss": 0.0059,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9817013144493103,
      "rewards/margins": 5.725839614868164,
      "rewards/rejected": -4.744138717651367,
      "step": 1521
    },
    {
      "epoch": 0.6088,
      "grad_norm": 0.3723940849304199,
      "learning_rate": 7.972e-07,
      "logits/chosen": -2.1229605674743652,
      "logits/rejected": -2.951587677001953,
      "logps/chosen": -110.72147369384766,
      "logps/rejected": -222.45169067382812,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2644968032836914,
      "rewards/margins": 7.105758190155029,
      "rewards/rejected": -4.841261386871338,
      "step": 1522
    },
    {
      "epoch": 0.6092,
      "grad_norm": 0.9282848834991455,
      "learning_rate": 7.970666666666667e-07,
      "logits/chosen": -2.3937129974365234,
      "logits/rejected": -2.5465903282165527,
      "logps/chosen": -160.19024658203125,
      "logps/rejected": -170.35769653320312,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3465614318847656,
      "rewards/margins": 7.121482849121094,
      "rewards/rejected": -4.774921417236328,
      "step": 1523
    },
    {
      "epoch": 0.6096,
      "grad_norm": 0.44736143946647644,
      "learning_rate": 7.969333333333333e-07,
      "logits/chosen": -2.749143123626709,
      "logits/rejected": -3.329061985015869,
      "logps/chosen": -143.21096801757812,
      "logps/rejected": -125.57453918457031,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.572721242904663,
      "rewards/margins": 6.2512030601501465,
      "rewards/rejected": -3.6784815788269043,
      "step": 1524
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.01666877418756485,
      "learning_rate": 7.967999999999999e-07,
      "logits/chosen": -1.874964952468872,
      "logits/rejected": -3.2726731300354004,
      "logps/chosen": -84.82675170898438,
      "logps/rejected": -141.097900390625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.765305519104004,
      "rewards/margins": 8.945616722106934,
      "rewards/rejected": -5.18031120300293,
      "step": 1525
    },
    {
      "epoch": 0.6104,
      "grad_norm": 0.2907528579235077,
      "learning_rate": 7.966666666666666e-07,
      "logits/chosen": -2.0799922943115234,
      "logits/rejected": -3.0344090461730957,
      "logps/chosen": -97.87250518798828,
      "logps/rejected": -159.02288818359375,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0168004035949707,
      "rewards/margins": 7.983427047729492,
      "rewards/rejected": -4.96662712097168,
      "step": 1526
    },
    {
      "epoch": 0.6108,
      "grad_norm": 0.029177993535995483,
      "learning_rate": 7.965333333333333e-07,
      "logits/chosen": -2.1043167114257812,
      "logits/rejected": -3.585493564605713,
      "logps/chosen": -104.83477020263672,
      "logps/rejected": -169.98025512695312,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5236434936523438,
      "rewards/margins": 8.065840721130371,
      "rewards/rejected": -4.542196750640869,
      "step": 1527
    },
    {
      "epoch": 0.6112,
      "grad_norm": 0.07704643905162811,
      "learning_rate": 7.964e-07,
      "logits/chosen": -1.803406000137329,
      "logits/rejected": -2.6036417484283447,
      "logps/chosen": -64.59496307373047,
      "logps/rejected": -119.61334228515625,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.173398971557617,
      "rewards/margins": 7.341790199279785,
      "rewards/rejected": -4.168391227722168,
      "step": 1528
    },
    {
      "epoch": 0.6116,
      "grad_norm": 0.0078104594722390175,
      "learning_rate": 7.962666666666666e-07,
      "logits/chosen": -2.1991872787475586,
      "logits/rejected": -3.271679162979126,
      "logps/chosen": -126.96553802490234,
      "logps/rejected": -201.6377410888672,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.43276834487915,
      "rewards/margins": 9.491961479187012,
      "rewards/rejected": -5.059193134307861,
      "step": 1529
    },
    {
      "epoch": 0.612,
      "grad_norm": 0.16984105110168457,
      "learning_rate": 7.961333333333333e-07,
      "logits/chosen": -2.8928205966949463,
      "logits/rejected": -3.0331168174743652,
      "logps/chosen": -242.34779357910156,
      "logps/rejected": -153.78662109375,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5681710243225098,
      "rewards/margins": 6.701467037200928,
      "rewards/rejected": -4.133296012878418,
      "step": 1530
    },
    {
      "epoch": 0.6124,
      "grad_norm": 0.07384578883647919,
      "learning_rate": 7.96e-07,
      "logits/chosen": -2.3860368728637695,
      "logits/rejected": -3.244126081466675,
      "logps/chosen": -133.4102325439453,
      "logps/rejected": -139.5097198486328,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.529664516448975,
      "rewards/margins": 7.548016548156738,
      "rewards/rejected": -3.0183517932891846,
      "step": 1531
    },
    {
      "epoch": 0.6128,
      "grad_norm": 0.7965008616447449,
      "learning_rate": 7.958666666666666e-07,
      "logits/chosen": -2.192946672439575,
      "logits/rejected": -2.1332149505615234,
      "logps/chosen": -154.44970703125,
      "logps/rejected": -144.30685424804688,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0416507720947266,
      "rewards/margins": 5.017163276672363,
      "rewards/rejected": -2.975512742996216,
      "step": 1532
    },
    {
      "epoch": 0.6132,
      "grad_norm": 0.3919503688812256,
      "learning_rate": 7.957333333333333e-07,
      "logits/chosen": -1.4481875896453857,
      "logits/rejected": -3.3974337577819824,
      "logps/chosen": -140.1405792236328,
      "logps/rejected": -149.33859252929688,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5339069366455078,
      "rewards/margins": 6.047146320343018,
      "rewards/rejected": -4.51323938369751,
      "step": 1533
    },
    {
      "epoch": 0.6136,
      "grad_norm": 0.06616470217704773,
      "learning_rate": 7.956e-07,
      "logits/chosen": -2.5704028606414795,
      "logits/rejected": -2.6969447135925293,
      "logps/chosen": -142.97103881835938,
      "logps/rejected": -146.38058471679688,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.816864490509033,
      "rewards/margins": 7.236557960510254,
      "rewards/rejected": -3.419693946838379,
      "step": 1534
    },
    {
      "epoch": 0.614,
      "grad_norm": 0.11702582985162735,
      "learning_rate": 7.954666666666666e-07,
      "logits/chosen": -1.8682619333267212,
      "logits/rejected": -2.435830593109131,
      "logps/chosen": -91.97186279296875,
      "logps/rejected": -146.799072265625,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.532351016998291,
      "rewards/margins": 7.798611640930176,
      "rewards/rejected": -4.266261100769043,
      "step": 1535
    },
    {
      "epoch": 0.6144,
      "grad_norm": 2.4350435733795166,
      "learning_rate": 7.953333333333333e-07,
      "logits/chosen": -1.9905518293380737,
      "logits/rejected": -3.326824903488159,
      "logps/chosen": -145.00054931640625,
      "logps/rejected": -118.40626525878906,
      "loss": 0.0156,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6218704581260681,
      "rewards/margins": 4.752135276794434,
      "rewards/rejected": -4.130265235900879,
      "step": 1536
    },
    {
      "epoch": 0.6148,
      "grad_norm": 0.3090739846229553,
      "learning_rate": 7.952e-07,
      "logits/chosen": -2.678349018096924,
      "logits/rejected": -3.8191585540771484,
      "logps/chosen": -155.80812072753906,
      "logps/rejected": -195.44284057617188,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3426861763000488,
      "rewards/margins": 7.750007629394531,
      "rewards/rejected": -6.407320976257324,
      "step": 1537
    },
    {
      "epoch": 0.6152,
      "grad_norm": 3.385390281677246,
      "learning_rate": 7.950666666666666e-07,
      "logits/chosen": -2.2068419456481934,
      "logits/rejected": -3.265225410461426,
      "logps/chosen": -88.56892395019531,
      "logps/rejected": -142.76861572265625,
      "loss": 0.049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6084384918212891,
      "rewards/margins": 3.519289255142212,
      "rewards/rejected": -4.127727508544922,
      "step": 1538
    },
    {
      "epoch": 0.6156,
      "grad_norm": 2.0250461101531982,
      "learning_rate": 7.949333333333333e-07,
      "logits/chosen": -1.9612927436828613,
      "logits/rejected": -3.043050527572632,
      "logps/chosen": -133.3063201904297,
      "logps/rejected": -137.8739471435547,
      "loss": 0.0187,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3931221961975098,
      "rewards/margins": 4.939553260803223,
      "rewards/rejected": -3.546431541442871,
      "step": 1539
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.05256149172782898,
      "learning_rate": 7.947999999999999e-07,
      "logits/chosen": -2.1518523693084717,
      "logits/rejected": -2.6977176666259766,
      "logps/chosen": -210.51663208007812,
      "logps/rejected": -194.42666625976562,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3699593544006348,
      "rewards/margins": 9.104583740234375,
      "rewards/rejected": -5.734624862670898,
      "step": 1540
    },
    {
      "epoch": 0.6164,
      "grad_norm": 1.1779810190200806,
      "learning_rate": 7.946666666666666e-07,
      "logits/chosen": -2.422163486480713,
      "logits/rejected": -3.338022232055664,
      "logps/chosen": -199.96975708007812,
      "logps/rejected": -159.96044921875,
      "loss": 0.0104,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1625664234161377,
      "rewards/margins": 5.999659061431885,
      "rewards/rejected": -4.837092399597168,
      "step": 1541
    },
    {
      "epoch": 0.6168,
      "grad_norm": 0.4186166524887085,
      "learning_rate": 7.945333333333333e-07,
      "logits/chosen": -2.197965383529663,
      "logits/rejected": -2.0772409439086914,
      "logps/chosen": -101.46517181396484,
      "logps/rejected": -106.26412963867188,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9145348072052002,
      "rewards/margins": 5.153853416442871,
      "rewards/rejected": -3.239318370819092,
      "step": 1542
    },
    {
      "epoch": 0.6172,
      "grad_norm": 0.0735931321978569,
      "learning_rate": 7.944e-07,
      "logits/chosen": -1.9173846244812012,
      "logits/rejected": -3.6222991943359375,
      "logps/chosen": -98.71491241455078,
      "logps/rejected": -167.12255859375,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.677534580230713,
      "rewards/margins": 7.568990230560303,
      "rewards/rejected": -5.89145565032959,
      "step": 1543
    },
    {
      "epoch": 0.6176,
      "grad_norm": 0.12933090329170227,
      "learning_rate": 7.942666666666667e-07,
      "logits/chosen": -2.374333143234253,
      "logits/rejected": -2.659658432006836,
      "logps/chosen": -211.3031005859375,
      "logps/rejected": -146.24818420410156,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8913583755493164,
      "rewards/margins": 7.721796989440918,
      "rewards/rejected": -3.8304386138916016,
      "step": 1544
    },
    {
      "epoch": 0.618,
      "grad_norm": 4.958609580993652,
      "learning_rate": 7.941333333333334e-07,
      "logits/chosen": -2.4233198165893555,
      "logits/rejected": -2.8730626106262207,
      "logps/chosen": -187.04547119140625,
      "logps/rejected": -132.61712646484375,
      "loss": 0.0442,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7990440130233765,
      "rewards/margins": 5.243068695068359,
      "rewards/rejected": -3.4440245628356934,
      "step": 1545
    },
    {
      "epoch": 0.6184,
      "grad_norm": 3.01629900932312,
      "learning_rate": 7.94e-07,
      "logits/chosen": -2.266495704650879,
      "logits/rejected": -3.1897006034851074,
      "logps/chosen": -158.11422729492188,
      "logps/rejected": -163.164794921875,
      "loss": 0.0385,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7916629910469055,
      "rewards/margins": 4.376358985900879,
      "rewards/rejected": -5.168022155761719,
      "step": 1546
    },
    {
      "epoch": 0.6188,
      "grad_norm": 24.04617691040039,
      "learning_rate": 7.938666666666667e-07,
      "logits/chosen": -3.2223777770996094,
      "logits/rejected": -3.4198176860809326,
      "logps/chosen": -253.7622528076172,
      "logps/rejected": -157.63226318359375,
      "loss": 0.2388,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9119614362716675,
      "rewards/margins": 2.443063735961914,
      "rewards/rejected": -4.355025291442871,
      "step": 1547
    },
    {
      "epoch": 0.6192,
      "grad_norm": 0.1211041584610939,
      "learning_rate": 7.937333333333332e-07,
      "logits/chosen": -1.9301868677139282,
      "logits/rejected": -3.3914756774902344,
      "logps/chosen": -79.09440612792969,
      "logps/rejected": -130.501220703125,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.388213634490967,
      "rewards/margins": 6.698213577270508,
      "rewards/rejected": -4.309999942779541,
      "step": 1548
    },
    {
      "epoch": 0.6196,
      "grad_norm": 0.01586451567709446,
      "learning_rate": 7.935999999999999e-07,
      "logits/chosen": -2.3391880989074707,
      "logits/rejected": -3.209902763366699,
      "logps/chosen": -133.61767578125,
      "logps/rejected": -186.6527862548828,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.201633453369141,
      "rewards/margins": 9.001436233520508,
      "rewards/rejected": -4.799802780151367,
      "step": 1549
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.5420079231262207,
      "learning_rate": 7.934666666666666e-07,
      "logits/chosen": -1.5033013820648193,
      "logits/rejected": -2.5937294960021973,
      "logps/chosen": -101.3107681274414,
      "logps/rejected": -130.79298400878906,
      "loss": 0.0182,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.653713583946228,
      "rewards/margins": 4.110278129577637,
      "rewards/rejected": -3.4565649032592773,
      "step": 1550
    },
    {
      "epoch": 0.6204,
      "grad_norm": 0.10366273671388626,
      "learning_rate": 7.933333333333333e-07,
      "logits/chosen": -1.672980785369873,
      "logits/rejected": -2.9456515312194824,
      "logps/chosen": -232.32376098632812,
      "logps/rejected": -175.63653564453125,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.357989549636841,
      "rewards/margins": 7.050318241119385,
      "rewards/rejected": -4.692328453063965,
      "step": 1551
    },
    {
      "epoch": 0.6208,
      "grad_norm": 0.047393180429935455,
      "learning_rate": 7.932e-07,
      "logits/chosen": -2.315779685974121,
      "logits/rejected": -3.0620198249816895,
      "logps/chosen": -139.64508056640625,
      "logps/rejected": -234.89610290527344,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.287562370300293,
      "rewards/margins": 7.892148017883301,
      "rewards/rejected": -4.604585647583008,
      "step": 1552
    },
    {
      "epoch": 0.6212,
      "grad_norm": 0.35723990201950073,
      "learning_rate": 7.930666666666667e-07,
      "logits/chosen": -2.2963027954101562,
      "logits/rejected": -2.5578880310058594,
      "logps/chosen": -154.72634887695312,
      "logps/rejected": -200.0771484375,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8674559593200684,
      "rewards/margins": 5.741772651672363,
      "rewards/rejected": -2.874316453933716,
      "step": 1553
    },
    {
      "epoch": 0.6216,
      "grad_norm": 0.0478944256901741,
      "learning_rate": 7.929333333333334e-07,
      "logits/chosen": -1.9995465278625488,
      "logits/rejected": -2.7226850986480713,
      "logps/chosen": -92.45176696777344,
      "logps/rejected": -128.65182495117188,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.833430528640747,
      "rewards/margins": 7.48835563659668,
      "rewards/rejected": -4.654925346374512,
      "step": 1554
    },
    {
      "epoch": 0.622,
      "grad_norm": 0.061221372336149216,
      "learning_rate": 7.928e-07,
      "logits/chosen": -2.4512438774108887,
      "logits/rejected": -2.7432827949523926,
      "logps/chosen": -122.74456787109375,
      "logps/rejected": -143.13589477539062,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.235611915588379,
      "rewards/margins": 7.19222354888916,
      "rewards/rejected": -2.9566116333007812,
      "step": 1555
    },
    {
      "epoch": 0.6224,
      "grad_norm": 4.955804347991943,
      "learning_rate": 7.926666666666666e-07,
      "logits/chosen": -2.5069124698638916,
      "logits/rejected": -2.642001152038574,
      "logps/chosen": -115.99723052978516,
      "logps/rejected": -170.8712615966797,
      "loss": 0.0501,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.686846971511841,
      "rewards/margins": 5.445432662963867,
      "rewards/rejected": -2.7585854530334473,
      "step": 1556
    },
    {
      "epoch": 0.6228,
      "grad_norm": 0.03696054220199585,
      "learning_rate": 7.925333333333332e-07,
      "logits/chosen": -2.0765645503997803,
      "logits/rejected": -2.848823070526123,
      "logps/chosen": -91.79147338867188,
      "logps/rejected": -136.75491333007812,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9312806129455566,
      "rewards/margins": 8.088327407836914,
      "rewards/rejected": -4.157047271728516,
      "step": 1557
    },
    {
      "epoch": 0.6232,
      "grad_norm": 1.1893956661224365,
      "learning_rate": 7.923999999999999e-07,
      "logits/chosen": -2.405730724334717,
      "logits/rejected": -3.1871843338012695,
      "logps/chosen": -141.72589111328125,
      "logps/rejected": -162.8897705078125,
      "loss": 0.0104,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7154076099395752,
      "rewards/margins": 5.495388984680176,
      "rewards/rejected": -3.7799813747406006,
      "step": 1558
    },
    {
      "epoch": 0.6236,
      "grad_norm": 0.06655307114124298,
      "learning_rate": 7.922666666666666e-07,
      "logits/chosen": -2.229243278503418,
      "logits/rejected": -3.301142692565918,
      "logps/chosen": -192.869384765625,
      "logps/rejected": -145.81602478027344,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.469700336456299,
      "rewards/margins": 7.360440254211426,
      "rewards/rejected": -3.890739917755127,
      "step": 1559
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.213801771402359,
      "learning_rate": 7.921333333333333e-07,
      "logits/chosen": -2.5992908477783203,
      "logits/rejected": -2.9937644004821777,
      "logps/chosen": -192.08746337890625,
      "logps/rejected": -203.28924560546875,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8226014375686646,
      "rewards/margins": 6.320549011230469,
      "rewards/rejected": -4.497947692871094,
      "step": 1560
    },
    {
      "epoch": 0.6244,
      "grad_norm": 0.42551684379577637,
      "learning_rate": 7.92e-07,
      "logits/chosen": -1.9515219926834106,
      "logits/rejected": -3.0014331340789795,
      "logps/chosen": -144.76361083984375,
      "logps/rejected": -146.76690673828125,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2544312477111816,
      "rewards/margins": 6.447182655334473,
      "rewards/rejected": -4.192751407623291,
      "step": 1561
    },
    {
      "epoch": 0.6248,
      "grad_norm": 0.1929008513689041,
      "learning_rate": 7.918666666666667e-07,
      "logits/chosen": -2.515385627746582,
      "logits/rejected": -3.5920467376708984,
      "logps/chosen": -209.6860809326172,
      "logps/rejected": -220.3995819091797,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.084372043609619,
      "rewards/margins": 7.969316482543945,
      "rewards/rejected": -5.884944915771484,
      "step": 1562
    },
    {
      "epoch": 0.6252,
      "grad_norm": 0.3338682949542999,
      "learning_rate": 7.917333333333333e-07,
      "logits/chosen": -2.2687458992004395,
      "logits/rejected": -2.8585264682769775,
      "logps/chosen": -101.20549011230469,
      "logps/rejected": -155.6092529296875,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7565953731536865,
      "rewards/margins": 7.65223503112793,
      "rewards/rejected": -3.895639419555664,
      "step": 1563
    },
    {
      "epoch": 0.6256,
      "grad_norm": 0.5135201215744019,
      "learning_rate": 7.916e-07,
      "logits/chosen": -2.4614346027374268,
      "logits/rejected": -3.2689194679260254,
      "logps/chosen": -72.74989318847656,
      "logps/rejected": -132.89236450195312,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9740262031555176,
      "rewards/margins": 6.82614803314209,
      "rewards/rejected": -3.8521220684051514,
      "step": 1564
    },
    {
      "epoch": 0.626,
      "grad_norm": 0.05827812850475311,
      "learning_rate": 7.914666666666667e-07,
      "logits/chosen": -2.6219143867492676,
      "logits/rejected": -3.9338912963867188,
      "logps/chosen": -151.75347900390625,
      "logps/rejected": -154.90101623535156,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.214980125427246,
      "rewards/margins": 7.533608913421631,
      "rewards/rejected": -4.318628787994385,
      "step": 1565
    },
    {
      "epoch": 0.6264,
      "grad_norm": 2.0713045597076416,
      "learning_rate": 7.913333333333332e-07,
      "logits/chosen": -2.641010046005249,
      "logits/rejected": -3.4381518363952637,
      "logps/chosen": -119.06370544433594,
      "logps/rejected": -149.64688110351562,
      "loss": 0.0248,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6009784936904907,
      "rewards/margins": 6.488199234008789,
      "rewards/rejected": -4.887220859527588,
      "step": 1566
    },
    {
      "epoch": 0.6268,
      "grad_norm": 0.018065854907035828,
      "learning_rate": 7.911999999999999e-07,
      "logits/chosen": -2.183898448944092,
      "logits/rejected": -3.137289047241211,
      "logps/chosen": -79.08447265625,
      "logps/rejected": -160.84719848632812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.059545993804932,
      "rewards/margins": 8.96738338470459,
      "rewards/rejected": -4.907837867736816,
      "step": 1567
    },
    {
      "epoch": 0.6272,
      "grad_norm": 1.3750388622283936,
      "learning_rate": 7.910666666666666e-07,
      "logits/chosen": -2.5625524520874023,
      "logits/rejected": -2.8855371475219727,
      "logps/chosen": -124.79821014404297,
      "logps/rejected": -120.34967041015625,
      "loss": 0.0149,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3550231456756592,
      "rewards/margins": 4.647022247314453,
      "rewards/rejected": -3.291999101638794,
      "step": 1568
    },
    {
      "epoch": 0.6276,
      "grad_norm": 0.430742472410202,
      "learning_rate": 7.909333333333333e-07,
      "logits/chosen": -2.208235740661621,
      "logits/rejected": -2.72255802154541,
      "logps/chosen": -80.20172882080078,
      "logps/rejected": -116.47337341308594,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1037163734436035,
      "rewards/margins": 6.380946159362793,
      "rewards/rejected": -3.2772293090820312,
      "step": 1569
    },
    {
      "epoch": 0.628,
      "grad_norm": 0.21994903683662415,
      "learning_rate": 7.907999999999999e-07,
      "logits/chosen": -2.420802116394043,
      "logits/rejected": -2.5013625621795654,
      "logps/chosen": -96.92461395263672,
      "logps/rejected": -144.89999389648438,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.518082618713379,
      "rewards/margins": 6.89613151550293,
      "rewards/rejected": -3.378048896789551,
      "step": 1570
    },
    {
      "epoch": 0.6284,
      "grad_norm": 0.17957636713981628,
      "learning_rate": 7.906666666666666e-07,
      "logits/chosen": -1.9695738554000854,
      "logits/rejected": -2.729278564453125,
      "logps/chosen": -71.92924499511719,
      "logps/rejected": -144.9795379638672,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8899643421173096,
      "rewards/margins": 6.9251708984375,
      "rewards/rejected": -4.035206317901611,
      "step": 1571
    },
    {
      "epoch": 0.6288,
      "grad_norm": 0.7017395496368408,
      "learning_rate": 7.905333333333333e-07,
      "logits/chosen": -2.2193551063537598,
      "logits/rejected": -2.6662206649780273,
      "logps/chosen": -106.32633972167969,
      "logps/rejected": -148.92311096191406,
      "loss": 0.0062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5566768646240234,
      "rewards/margins": 5.1753644943237305,
      "rewards/rejected": -2.618687629699707,
      "step": 1572
    },
    {
      "epoch": 0.6292,
      "grad_norm": 0.044721439480781555,
      "learning_rate": 7.904e-07,
      "logits/chosen": -2.6664345264434814,
      "logits/rejected": -3.419724941253662,
      "logps/chosen": -123.29898071289062,
      "logps/rejected": -152.73863220214844,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.241128921508789,
      "rewards/margins": 7.783413887023926,
      "rewards/rejected": -4.542284965515137,
      "step": 1573
    },
    {
      "epoch": 0.6296,
      "grad_norm": 0.1266334354877472,
      "learning_rate": 7.902666666666667e-07,
      "logits/chosen": -1.4399982690811157,
      "logits/rejected": -2.756537914276123,
      "logps/chosen": -65.25965118408203,
      "logps/rejected": -114.04112243652344,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.606719493865967,
      "rewards/margins": 6.558257102966309,
      "rewards/rejected": -2.951537609100342,
      "step": 1574
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.646323561668396,
      "learning_rate": 7.901333333333334e-07,
      "logits/chosen": -1.9297850131988525,
      "logits/rejected": -2.8362669944763184,
      "logps/chosen": -103.69438934326172,
      "logps/rejected": -134.06759643554688,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8204094171524048,
      "rewards/margins": 5.868105888366699,
      "rewards/rejected": -4.047696113586426,
      "step": 1575
    },
    {
      "epoch": 0.6304,
      "grad_norm": 0.018929289653897285,
      "learning_rate": 7.9e-07,
      "logits/chosen": -2.315476179122925,
      "logits/rejected": -3.4235732555389404,
      "logps/chosen": -121.0666732788086,
      "logps/rejected": -204.03863525390625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.480924606323242,
      "rewards/margins": 8.673095703125,
      "rewards/rejected": -4.1921706199646,
      "step": 1576
    },
    {
      "epoch": 0.6308,
      "grad_norm": 0.13892945647239685,
      "learning_rate": 7.898666666666666e-07,
      "logits/chosen": -2.0771431922912598,
      "logits/rejected": -3.0743143558502197,
      "logps/chosen": -173.62730407714844,
      "logps/rejected": -138.4644775390625,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1758084297180176,
      "rewards/margins": 6.699117660522461,
      "rewards/rejected": -4.523309707641602,
      "step": 1577
    },
    {
      "epoch": 0.6312,
      "grad_norm": 0.5519231557846069,
      "learning_rate": 7.897333333333332e-07,
      "logits/chosen": -2.0722761154174805,
      "logits/rejected": -3.0804014205932617,
      "logps/chosen": -90.09217834472656,
      "logps/rejected": -122.62159729003906,
      "loss": 0.0062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6938531398773193,
      "rewards/margins": 6.508637428283691,
      "rewards/rejected": -3.814784049987793,
      "step": 1578
    },
    {
      "epoch": 0.6316,
      "grad_norm": 10.25706958770752,
      "learning_rate": 7.895999999999999e-07,
      "logits/chosen": -1.9885600805282593,
      "logits/rejected": -2.7719802856445312,
      "logps/chosen": -84.82178497314453,
      "logps/rejected": -122.12275695800781,
      "loss": 0.0741,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0652122497558594,
      "rewards/margins": 4.109532356262207,
      "rewards/rejected": -3.0443201065063477,
      "step": 1579
    },
    {
      "epoch": 0.632,
      "grad_norm": 0.05598660558462143,
      "learning_rate": 7.894666666666666e-07,
      "logits/chosen": -2.0198233127593994,
      "logits/rejected": -3.169504404067993,
      "logps/chosen": -127.68301391601562,
      "logps/rejected": -153.97735595703125,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.251366376876831,
      "rewards/margins": 7.374128818511963,
      "rewards/rejected": -4.122762680053711,
      "step": 1580
    },
    {
      "epoch": 0.6324,
      "grad_norm": 4.589612007141113,
      "learning_rate": 7.893333333333333e-07,
      "logits/chosen": -2.5622453689575195,
      "logits/rejected": -2.6397814750671387,
      "logps/chosen": -122.16292572021484,
      "logps/rejected": -172.41268920898438,
      "loss": 0.0281,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2403770685195923,
      "rewards/margins": 5.815713882446289,
      "rewards/rejected": -4.575336456298828,
      "step": 1581
    },
    {
      "epoch": 0.6328,
      "grad_norm": 0.5677971243858337,
      "learning_rate": 7.892e-07,
      "logits/chosen": -2.1932456493377686,
      "logits/rejected": -2.677598476409912,
      "logps/chosen": -168.47140502929688,
      "logps/rejected": -159.70291137695312,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8693368434906006,
      "rewards/margins": 7.251967430114746,
      "rewards/rejected": -4.382630825042725,
      "step": 1582
    },
    {
      "epoch": 0.6332,
      "grad_norm": 0.5374950766563416,
      "learning_rate": 7.890666666666667e-07,
      "logits/chosen": -2.3693621158599854,
      "logits/rejected": -2.8921895027160645,
      "logps/chosen": -138.5672149658203,
      "logps/rejected": -162.67039489746094,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6655800342559814,
      "rewards/margins": 6.698243141174316,
      "rewards/rejected": -5.032662868499756,
      "step": 1583
    },
    {
      "epoch": 0.6336,
      "grad_norm": 1.190477967262268,
      "learning_rate": 7.889333333333334e-07,
      "logits/chosen": -2.377748489379883,
      "logits/rejected": -3.037367105484009,
      "logps/chosen": -183.39190673828125,
      "logps/rejected": -121.78076171875,
      "loss": 0.0107,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9629204273223877,
      "rewards/margins": 4.7939653396606445,
      "rewards/rejected": -3.831044912338257,
      "step": 1584
    },
    {
      "epoch": 0.634,
      "grad_norm": 0.5250198841094971,
      "learning_rate": 7.887999999999999e-07,
      "logits/chosen": -1.9454630613327026,
      "logits/rejected": -3.1451449394226074,
      "logps/chosen": -78.67239379882812,
      "logps/rejected": -168.71746826171875,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.318364381790161,
      "rewards/margins": 7.775082588195801,
      "rewards/rejected": -5.456718444824219,
      "step": 1585
    },
    {
      "epoch": 0.6344,
      "grad_norm": 0.020364243537187576,
      "learning_rate": 7.886666666666666e-07,
      "logits/chosen": -2.6160941123962402,
      "logits/rejected": -3.2065067291259766,
      "logps/chosen": -194.92349243164062,
      "logps/rejected": -156.15907287597656,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.844738006591797,
      "rewards/margins": 9.510110855102539,
      "rewards/rejected": -4.665372848510742,
      "step": 1586
    },
    {
      "epoch": 0.6348,
      "grad_norm": 2.5462253093719482,
      "learning_rate": 7.885333333333332e-07,
      "logits/chosen": -2.2889199256896973,
      "logits/rejected": -2.4463136196136475,
      "logps/chosen": -101.16079711914062,
      "logps/rejected": -131.96881103515625,
      "loss": 0.0189,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1158173084259033,
      "rewards/margins": 4.786218166351318,
      "rewards/rejected": -3.670401096343994,
      "step": 1587
    },
    {
      "epoch": 0.6352,
      "grad_norm": 0.3137862980365753,
      "learning_rate": 7.883999999999999e-07,
      "logits/chosen": -2.367701768875122,
      "logits/rejected": -3.481576442718506,
      "logps/chosen": -142.6498565673828,
      "logps/rejected": -154.94874572753906,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.98028564453125,
      "rewards/margins": 6.745401382446289,
      "rewards/rejected": -4.765115737915039,
      "step": 1588
    },
    {
      "epoch": 0.6356,
      "grad_norm": 0.030250566080212593,
      "learning_rate": 7.882666666666666e-07,
      "logits/chosen": -2.28436541557312,
      "logits/rejected": -3.1536664962768555,
      "logps/chosen": -137.32662963867188,
      "logps/rejected": -178.40338134765625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.574488639831543,
      "rewards/margins": 8.570706367492676,
      "rewards/rejected": -4.996217727661133,
      "step": 1589
    },
    {
      "epoch": 0.636,
      "grad_norm": 0.057932049036026,
      "learning_rate": 7.881333333333333e-07,
      "logits/chosen": -2.522709369659424,
      "logits/rejected": -2.792727470397949,
      "logps/chosen": -112.53129577636719,
      "logps/rejected": -135.7243194580078,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.032048225402832,
      "rewards/margins": 7.383513450622559,
      "rewards/rejected": -4.351465702056885,
      "step": 1590
    },
    {
      "epoch": 0.6364,
      "grad_norm": 0.02990899421274662,
      "learning_rate": 7.88e-07,
      "logits/chosen": -2.2327253818511963,
      "logits/rejected": -3.268206834793091,
      "logps/chosen": -65.15328979492188,
      "logps/rejected": -158.57015991210938,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.455152988433838,
      "rewards/margins": 8.603668212890625,
      "rewards/rejected": -5.148514747619629,
      "step": 1591
    },
    {
      "epoch": 0.6368,
      "grad_norm": 0.003264587139710784,
      "learning_rate": 7.878666666666667e-07,
      "logits/chosen": -2.3488426208496094,
      "logits/rejected": -3.6066925525665283,
      "logps/chosen": -121.07254791259766,
      "logps/rejected": -182.84657287597656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9811761379241943,
      "rewards/margins": 10.514650344848633,
      "rewards/rejected": -6.533473968505859,
      "step": 1592
    },
    {
      "epoch": 0.6372,
      "grad_norm": 0.03880119323730469,
      "learning_rate": 7.877333333333333e-07,
      "logits/chosen": -1.6354047060012817,
      "logits/rejected": -3.2881503105163574,
      "logps/chosen": -72.3244400024414,
      "logps/rejected": -124.61744689941406,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1216366291046143,
      "rewards/margins": 7.760680198669434,
      "rewards/rejected": -4.639042854309082,
      "step": 1593
    },
    {
      "epoch": 0.6376,
      "grad_norm": 0.2308884561061859,
      "learning_rate": 7.875999999999999e-07,
      "logits/chosen": -2.5424342155456543,
      "logits/rejected": -3.350409984588623,
      "logps/chosen": -232.85032653808594,
      "logps/rejected": -168.31832885742188,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4325287342071533,
      "rewards/margins": 6.244478225708008,
      "rewards/rejected": -4.811949253082275,
      "step": 1594
    },
    {
      "epoch": 0.638,
      "grad_norm": 0.09231563657522202,
      "learning_rate": 7.874666666666666e-07,
      "logits/chosen": -2.7308502197265625,
      "logits/rejected": -3.091668128967285,
      "logps/chosen": -153.1441192626953,
      "logps/rejected": -179.34010314941406,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.235600471496582,
      "rewards/margins": 8.721534729003906,
      "rewards/rejected": -4.485934257507324,
      "step": 1595
    },
    {
      "epoch": 0.6384,
      "grad_norm": 0.5422954559326172,
      "learning_rate": 7.873333333333333e-07,
      "logits/chosen": -2.154623031616211,
      "logits/rejected": -2.580955743789673,
      "logps/chosen": -127.77793884277344,
      "logps/rejected": -161.71502685546875,
      "loss": 0.0056,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4042507410049438,
      "rewards/margins": 5.34681510925293,
      "rewards/rejected": -3.9425644874572754,
      "step": 1596
    },
    {
      "epoch": 0.6388,
      "grad_norm": 0.2542083263397217,
      "learning_rate": 7.872e-07,
      "logits/chosen": -2.0338664054870605,
      "logits/rejected": -2.7311623096466064,
      "logps/chosen": -106.29275512695312,
      "logps/rejected": -153.6135711669922,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6131470203399658,
      "rewards/margins": 6.987654685974121,
      "rewards/rejected": -5.374507904052734,
      "step": 1597
    },
    {
      "epoch": 0.6392,
      "grad_norm": 0.6033085584640503,
      "learning_rate": 7.870666666666666e-07,
      "logits/chosen": -1.7910314798355103,
      "logits/rejected": -3.0472517013549805,
      "logps/chosen": -144.40084838867188,
      "logps/rejected": -145.8977813720703,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0222053527832031,
      "rewards/margins": 6.18092155456543,
      "rewards/rejected": -5.158716201782227,
      "step": 1598
    },
    {
      "epoch": 0.6396,
      "grad_norm": 0.09282515943050385,
      "learning_rate": 7.869333333333333e-07,
      "logits/chosen": -2.051300525665283,
      "logits/rejected": -3.296970844268799,
      "logps/chosen": -100.43417358398438,
      "logps/rejected": -157.45523071289062,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9220685958862305,
      "rewards/margins": 8.542108535766602,
      "rewards/rejected": -5.620039939880371,
      "step": 1599
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.02650490030646324,
      "learning_rate": 7.868e-07,
      "logits/chosen": -2.5586092472076416,
      "logits/rejected": -2.491722345352173,
      "logps/chosen": -129.0724639892578,
      "logps/rejected": -157.77651977539062,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.513080596923828,
      "rewards/margins": 8.622560501098633,
      "rewards/rejected": -5.109479904174805,
      "step": 1600
    },
    {
      "epoch": 0.6404,
      "grad_norm": 6.9535980224609375,
      "learning_rate": 7.866666666666666e-07,
      "logits/chosen": -2.5805587768554688,
      "logits/rejected": -3.0354931354522705,
      "logps/chosen": -166.01150512695312,
      "logps/rejected": -172.9395294189453,
      "loss": 0.0679,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.930182695388794,
      "rewards/margins": 5.606607437133789,
      "rewards/rejected": -4.676424980163574,
      "step": 1601
    },
    {
      "epoch": 0.6408,
      "grad_norm": 0.34227535128593445,
      "learning_rate": 7.865333333333333e-07,
      "logits/chosen": -2.1469674110412598,
      "logits/rejected": -3.0724258422851562,
      "logps/chosen": -178.9408721923828,
      "logps/rejected": -143.86062622070312,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1185593605041504,
      "rewards/margins": 5.896983623504639,
      "rewards/rejected": -3.7784245014190674,
      "step": 1602
    },
    {
      "epoch": 0.6412,
      "grad_norm": 1.66141939163208,
      "learning_rate": 7.864e-07,
      "logits/chosen": -2.7147603034973145,
      "logits/rejected": -2.7906289100646973,
      "logps/chosen": -176.73814392089844,
      "logps/rejected": -181.93283081054688,
      "loss": 0.0189,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23337440192699432,
      "rewards/margins": 4.454707145690918,
      "rewards/rejected": -4.221332550048828,
      "step": 1603
    },
    {
      "epoch": 0.6416,
      "grad_norm": 0.10329046845436096,
      "learning_rate": 7.862666666666666e-07,
      "logits/chosen": -2.08359432220459,
      "logits/rejected": -2.7035272121429443,
      "logps/chosen": -99.45061492919922,
      "logps/rejected": -142.649658203125,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9657554626464844,
      "rewards/margins": 7.194572448730469,
      "rewards/rejected": -4.228816509246826,
      "step": 1604
    },
    {
      "epoch": 0.642,
      "grad_norm": 0.0681878849864006,
      "learning_rate": 7.861333333333333e-07,
      "logits/chosen": -2.7269811630249023,
      "logits/rejected": -3.6437835693359375,
      "logps/chosen": -228.1355743408203,
      "logps/rejected": -194.88809204101562,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1752586364746094,
      "rewards/margins": 9.974377632141113,
      "rewards/rejected": -6.799118995666504,
      "step": 1605
    },
    {
      "epoch": 0.6424,
      "grad_norm": 0.14194989204406738,
      "learning_rate": 7.86e-07,
      "logits/chosen": -2.575348377227783,
      "logits/rejected": -3.136813163757324,
      "logps/chosen": -94.927001953125,
      "logps/rejected": -138.05238342285156,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0396649837493896,
      "rewards/margins": 6.7759175300598145,
      "rewards/rejected": -3.736252784729004,
      "step": 1606
    },
    {
      "epoch": 0.6428,
      "grad_norm": 0.11678028851747513,
      "learning_rate": 7.858666666666667e-07,
      "logits/chosen": -2.8817038536071777,
      "logits/rejected": -3.4084343910217285,
      "logps/chosen": -224.00709533691406,
      "logps/rejected": -176.2484893798828,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8883476257324219,
      "rewards/margins": 6.792982578277588,
      "rewards/rejected": -4.904634952545166,
      "step": 1607
    },
    {
      "epoch": 0.6432,
      "grad_norm": 0.24873891472816467,
      "learning_rate": 7.857333333333332e-07,
      "logits/chosen": -2.29109787940979,
      "logits/rejected": -2.9381051063537598,
      "logps/chosen": -137.6481170654297,
      "logps/rejected": -148.50230407714844,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0167808532714844,
      "rewards/margins": 7.059087753295898,
      "rewards/rejected": -5.042306900024414,
      "step": 1608
    },
    {
      "epoch": 0.6436,
      "grad_norm": 0.0843677967786789,
      "learning_rate": 7.855999999999999e-07,
      "logits/chosen": -2.433979034423828,
      "logits/rejected": -3.0939548015594482,
      "logps/chosen": -121.8953857421875,
      "logps/rejected": -146.4505615234375,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.031970500946045,
      "rewards/margins": 7.721534252166748,
      "rewards/rejected": -4.689563751220703,
      "step": 1609
    },
    {
      "epoch": 0.644,
      "grad_norm": 0.20095877349376678,
      "learning_rate": 7.854666666666666e-07,
      "logits/chosen": -2.184723138809204,
      "logits/rejected": -2.933082103729248,
      "logps/chosen": -116.76594543457031,
      "logps/rejected": -148.9056396484375,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3914215564727783,
      "rewards/margins": 6.365671634674072,
      "rewards/rejected": -4.974249839782715,
      "step": 1610
    },
    {
      "epoch": 0.6444,
      "grad_norm": 2.281687021255493,
      "learning_rate": 7.853333333333333e-07,
      "logits/chosen": -2.0240845680236816,
      "logits/rejected": -3.297111988067627,
      "logps/chosen": -106.97563171386719,
      "logps/rejected": -144.77569580078125,
      "loss": 0.02,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.43450090289115906,
      "rewards/margins": 4.386601448059082,
      "rewards/rejected": -4.821102619171143,
      "step": 1611
    },
    {
      "epoch": 0.6448,
      "grad_norm": 0.6521690487861633,
      "learning_rate": 7.852e-07,
      "logits/chosen": -2.4479551315307617,
      "logits/rejected": -3.3762903213500977,
      "logps/chosen": -138.98211669921875,
      "logps/rejected": -137.34190368652344,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4384751319885254,
      "rewards/margins": 4.940835952758789,
      "rewards/rejected": -3.5023605823516846,
      "step": 1612
    },
    {
      "epoch": 0.6452,
      "grad_norm": 0.013054137118160725,
      "learning_rate": 7.850666666666666e-07,
      "logits/chosen": -2.337937831878662,
      "logits/rejected": -3.5406012535095215,
      "logps/chosen": -153.61666870117188,
      "logps/rejected": -161.7715606689453,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.668495178222656,
      "rewards/margins": 8.79440689086914,
      "rewards/rejected": -4.125911712646484,
      "step": 1613
    },
    {
      "epoch": 0.6456,
      "grad_norm": 0.9141188263893127,
      "learning_rate": 7.849333333333333e-07,
      "logits/chosen": -1.7601008415222168,
      "logits/rejected": -2.718410015106201,
      "logps/chosen": -134.6009521484375,
      "logps/rejected": -133.56170654296875,
      "loss": 0.0052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.799503207206726,
      "rewards/margins": 6.454705238342285,
      "rewards/rejected": -4.655202388763428,
      "step": 1614
    },
    {
      "epoch": 0.646,
      "grad_norm": 0.016366969794034958,
      "learning_rate": 7.848e-07,
      "logits/chosen": -2.389364719390869,
      "logits/rejected": -3.2731847763061523,
      "logps/chosen": -132.86741638183594,
      "logps/rejected": -158.52621459960938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.483217716217041,
      "rewards/margins": 8.52614688873291,
      "rewards/rejected": -5.042928695678711,
      "step": 1615
    },
    {
      "epoch": 0.6464,
      "grad_norm": 2.1394333839416504,
      "learning_rate": 7.846666666666666e-07,
      "logits/chosen": -2.5083398818969727,
      "logits/rejected": -2.0603909492492676,
      "logps/chosen": -184.029296875,
      "logps/rejected": -142.61038208007812,
      "loss": 0.0145,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.597287178039551,
      "rewards/margins": 5.763444900512695,
      "rewards/rejected": -3.1661577224731445,
      "step": 1616
    },
    {
      "epoch": 0.6468,
      "grad_norm": 0.10211930423974991,
      "learning_rate": 7.845333333333333e-07,
      "logits/chosen": -1.852926254272461,
      "logits/rejected": -2.131366014480591,
      "logps/chosen": -129.22569274902344,
      "logps/rejected": -141.66400146484375,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.637702465057373,
      "rewards/margins": 7.0046067237854,
      "rewards/rejected": -4.366904258728027,
      "step": 1617
    },
    {
      "epoch": 0.6472,
      "grad_norm": 0.022590164095163345,
      "learning_rate": 7.844e-07,
      "logits/chosen": -2.442006826400757,
      "logits/rejected": -3.227863073348999,
      "logps/chosen": -136.72193908691406,
      "logps/rejected": -135.95358276367188,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5900590419769287,
      "rewards/margins": 8.531402587890625,
      "rewards/rejected": -4.941344261169434,
      "step": 1618
    },
    {
      "epoch": 0.6476,
      "grad_norm": 0.09894166141748428,
      "learning_rate": 7.842666666666666e-07,
      "logits/chosen": -2.4693775177001953,
      "logits/rejected": -2.5095090866088867,
      "logps/chosen": -84.91609191894531,
      "logps/rejected": -150.0957794189453,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9398746490478516,
      "rewards/margins": 7.879208564758301,
      "rewards/rejected": -3.93933367729187,
      "step": 1619
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.47411826252937317,
      "learning_rate": 7.841333333333333e-07,
      "logits/chosen": -2.7315926551818848,
      "logits/rejected": -3.794908285140991,
      "logps/chosen": -161.62457275390625,
      "logps/rejected": -139.3594970703125,
      "loss": 0.0059,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40397873520851135,
      "rewards/margins": 5.397985458374023,
      "rewards/rejected": -4.994006633758545,
      "step": 1620
    },
    {
      "epoch": 0.6484,
      "grad_norm": 0.13645613193511963,
      "learning_rate": 7.84e-07,
      "logits/chosen": -2.0339198112487793,
      "logits/rejected": -2.7922892570495605,
      "logps/chosen": -119.09935760498047,
      "logps/rejected": -167.9035186767578,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3304283618927,
      "rewards/margins": 7.735671043395996,
      "rewards/rejected": -4.405242919921875,
      "step": 1621
    },
    {
      "epoch": 0.6488,
      "grad_norm": 0.1178516373038292,
      "learning_rate": 7.838666666666667e-07,
      "logits/chosen": -2.0678658485412598,
      "logits/rejected": -3.6082091331481934,
      "logps/chosen": -125.75416564941406,
      "logps/rejected": -190.98825073242188,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0463309288024902,
      "rewards/margins": 8.589930534362793,
      "rewards/rejected": -5.543599605560303,
      "step": 1622
    },
    {
      "epoch": 0.6492,
      "grad_norm": 1.9633028507232666,
      "learning_rate": 7.837333333333332e-07,
      "logits/chosen": -2.0459437370300293,
      "logits/rejected": -3.340182304382324,
      "logps/chosen": -76.03822326660156,
      "logps/rejected": -151.31546020507812,
      "loss": 0.0142,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2046971321105957,
      "rewards/margins": 5.722200870513916,
      "rewards/rejected": -3.5175037384033203,
      "step": 1623
    },
    {
      "epoch": 0.6496,
      "grad_norm": 0.17402160167694092,
      "learning_rate": 7.835999999999999e-07,
      "logits/chosen": -1.9860762357711792,
      "logits/rejected": -2.7396059036254883,
      "logps/chosen": -72.14045715332031,
      "logps/rejected": -142.5001220703125,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2727012634277344,
      "rewards/margins": 7.424153804779053,
      "rewards/rejected": -4.151452541351318,
      "step": 1624
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.4877704381942749,
      "learning_rate": 7.834666666666666e-07,
      "logits/chosen": -1.6962820291519165,
      "logits/rejected": -3.2241711616516113,
      "logps/chosen": -127.45362091064453,
      "logps/rejected": -194.31808471679688,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5466866493225098,
      "rewards/margins": 6.992578506469727,
      "rewards/rejected": -5.445892333984375,
      "step": 1625
    },
    {
      "epoch": 0.6504,
      "grad_norm": 0.004760621581226587,
      "learning_rate": 7.833333333333333e-07,
      "logits/chosen": -2.3441545963287354,
      "logits/rejected": -3.1514813899993896,
      "logps/chosen": -118.860595703125,
      "logps/rejected": -222.7657470703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.870718002319336,
      "rewards/margins": 10.294673919677734,
      "rewards/rejected": -6.423956394195557,
      "step": 1626
    },
    {
      "epoch": 0.6508,
      "grad_norm": 0.011230726726353168,
      "learning_rate": 7.832e-07,
      "logits/chosen": -2.1964640617370605,
      "logits/rejected": -2.924053192138672,
      "logps/chosen": -117.86634826660156,
      "logps/rejected": -147.11062622070312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.468371391296387,
      "rewards/margins": 9.199590682983398,
      "rewards/rejected": -4.7312188148498535,
      "step": 1627
    },
    {
      "epoch": 0.6512,
      "grad_norm": 0.22401948273181915,
      "learning_rate": 7.830666666666667e-07,
      "logits/chosen": -2.6643619537353516,
      "logits/rejected": -2.32889986038208,
      "logps/chosen": -119.28306579589844,
      "logps/rejected": -111.4485092163086,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.092806339263916,
      "rewards/margins": 6.29434871673584,
      "rewards/rejected": -3.2015421390533447,
      "step": 1628
    },
    {
      "epoch": 0.6516,
      "grad_norm": 1.4091233015060425,
      "learning_rate": 7.829333333333334e-07,
      "logits/chosen": -2.3002841472625732,
      "logits/rejected": -3.581714391708374,
      "logps/chosen": -242.4056854248047,
      "logps/rejected": -153.24917602539062,
      "loss": 0.0113,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4070793092250824,
      "rewards/margins": 4.6653852462768555,
      "rewards/rejected": -5.072464466094971,
      "step": 1629
    },
    {
      "epoch": 0.652,
      "grad_norm": 0.02757025510072708,
      "learning_rate": 7.828e-07,
      "logits/chosen": -2.214744806289673,
      "logits/rejected": -3.6324896812438965,
      "logps/chosen": -65.07907104492188,
      "logps/rejected": -158.55807495117188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8033344745635986,
      "rewards/margins": 9.04654598236084,
      "rewards/rejected": -5.24321174621582,
      "step": 1630
    },
    {
      "epoch": 0.6524,
      "grad_norm": 0.0627841204404831,
      "learning_rate": 7.826666666666666e-07,
      "logits/chosen": -2.5286805629730225,
      "logits/rejected": -2.650869369506836,
      "logps/chosen": -147.39108276367188,
      "logps/rejected": -192.80035400390625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.033937931060791,
      "rewards/margins": 7.495713233947754,
      "rewards/rejected": -5.461775302886963,
      "step": 1631
    },
    {
      "epoch": 0.6528,
      "grad_norm": 0.07879886031150818,
      "learning_rate": 7.825333333333332e-07,
      "logits/chosen": -1.9841489791870117,
      "logits/rejected": -2.564124584197998,
      "logps/chosen": -72.71775817871094,
      "logps/rejected": -136.04718017578125,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6156253814697266,
      "rewards/margins": 8.362557411193848,
      "rewards/rejected": -4.746932029724121,
      "step": 1632
    },
    {
      "epoch": 0.6532,
      "grad_norm": 0.03315444663167,
      "learning_rate": 7.823999999999999e-07,
      "logits/chosen": -1.8146419525146484,
      "logits/rejected": -3.15981388092041,
      "logps/chosen": -88.42250061035156,
      "logps/rejected": -155.5806884765625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.897284507751465,
      "rewards/margins": 9.203786849975586,
      "rewards/rejected": -5.306501865386963,
      "step": 1633
    },
    {
      "epoch": 0.6536,
      "grad_norm": 0.12381255626678467,
      "learning_rate": 7.822666666666666e-07,
      "logits/chosen": -2.252689838409424,
      "logits/rejected": -3.039522171020508,
      "logps/chosen": -66.8321533203125,
      "logps/rejected": -136.58514404296875,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.587573289871216,
      "rewards/margins": 6.719754695892334,
      "rewards/rejected": -4.132181167602539,
      "step": 1634
    },
    {
      "epoch": 0.654,
      "grad_norm": 2.7642757892608643,
      "learning_rate": 7.821333333333333e-07,
      "logits/chosen": -1.8781417608261108,
      "logits/rejected": -3.122058868408203,
      "logps/chosen": -88.10910034179688,
      "logps/rejected": -125.7797622680664,
      "loss": 0.0306,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5120040774345398,
      "rewards/margins": 3.491986036300659,
      "rewards/rejected": -2.9799818992614746,
      "step": 1635
    },
    {
      "epoch": 0.6544,
      "grad_norm": 0.037841737270355225,
      "learning_rate": 7.82e-07,
      "logits/chosen": -1.7782163619995117,
      "logits/rejected": -3.116879940032959,
      "logps/chosen": -124.59231567382812,
      "logps/rejected": -157.84954833984375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.823862075805664,
      "rewards/margins": 8.302428245544434,
      "rewards/rejected": -4.4785661697387695,
      "step": 1636
    },
    {
      "epoch": 0.6548,
      "grad_norm": 0.857978105545044,
      "learning_rate": 7.818666666666667e-07,
      "logits/chosen": -1.974729061126709,
      "logits/rejected": -2.675748348236084,
      "logps/chosen": -74.71407318115234,
      "logps/rejected": -120.92118835449219,
      "loss": 0.0078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5435066223144531,
      "rewards/margins": 4.848196983337402,
      "rewards/rejected": -4.304690361022949,
      "step": 1637
    },
    {
      "epoch": 0.6552,
      "grad_norm": 0.017218466848134995,
      "learning_rate": 7.817333333333333e-07,
      "logits/chosen": -2.3128790855407715,
      "logits/rejected": -3.4534263610839844,
      "logps/chosen": -87.68852233886719,
      "logps/rejected": -169.55511474609375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.964827060699463,
      "rewards/margins": 8.748693466186523,
      "rewards/rejected": -5.783866882324219,
      "step": 1638
    },
    {
      "epoch": 0.6556,
      "grad_norm": 0.6922194361686707,
      "learning_rate": 7.816e-07,
      "logits/chosen": -2.1327552795410156,
      "logits/rejected": -2.5283031463623047,
      "logps/chosen": -100.01567077636719,
      "logps/rejected": -227.48121643066406,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.511775493621826,
      "rewards/margins": 6.112485885620117,
      "rewards/rejected": -3.600709915161133,
      "step": 1639
    },
    {
      "epoch": 0.656,
      "grad_norm": 1.4447259902954102,
      "learning_rate": 7.814666666666666e-07,
      "logits/chosen": -2.256683588027954,
      "logits/rejected": -2.8944015502929688,
      "logps/chosen": -125.63274383544922,
      "logps/rejected": -118.74714660644531,
      "loss": 0.0122,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.64732825756073,
      "rewards/margins": 5.574462890625,
      "rewards/rejected": -3.9271347522735596,
      "step": 1640
    },
    {
      "epoch": 0.6564,
      "grad_norm": 0.01417080219835043,
      "learning_rate": 7.813333333333332e-07,
      "logits/chosen": -2.5065219402313232,
      "logits/rejected": -3.5684213638305664,
      "logps/chosen": -137.47894287109375,
      "logps/rejected": -162.81253051757812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.627887725830078,
      "rewards/margins": 8.823881149291992,
      "rewards/rejected": -5.195993423461914,
      "step": 1641
    },
    {
      "epoch": 0.6568,
      "grad_norm": 0.09935501962900162,
      "learning_rate": 7.811999999999999e-07,
      "logits/chosen": -2.243257522583008,
      "logits/rejected": -3.0896010398864746,
      "logps/chosen": -75.5925521850586,
      "logps/rejected": -118.12019348144531,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3531126976013184,
      "rewards/margins": 7.573737144470215,
      "rewards/rejected": -4.220623970031738,
      "step": 1642
    },
    {
      "epoch": 0.6572,
      "grad_norm": 0.3160841763019562,
      "learning_rate": 7.810666666666666e-07,
      "logits/chosen": -2.6856865882873535,
      "logits/rejected": -3.4428772926330566,
      "logps/chosen": -198.75726318359375,
      "logps/rejected": -162.51124572753906,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9307701587677002,
      "rewards/margins": 5.774322509765625,
      "rewards/rejected": -4.843552589416504,
      "step": 1643
    },
    {
      "epoch": 0.6576,
      "grad_norm": 0.180815652012825,
      "learning_rate": 7.809333333333333e-07,
      "logits/chosen": -2.4585530757904053,
      "logits/rejected": -2.3197779655456543,
      "logps/chosen": -90.29425048828125,
      "logps/rejected": -129.80850219726562,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0155866146087646,
      "rewards/margins": 7.379302024841309,
      "rewards/rejected": -4.363715171813965,
      "step": 1644
    },
    {
      "epoch": 0.658,
      "grad_norm": 0.9483364224433899,
      "learning_rate": 7.808e-07,
      "logits/chosen": -2.448298454284668,
      "logits/rejected": -2.914353609085083,
      "logps/chosen": -108.19003295898438,
      "logps/rejected": -127.95740509033203,
      "loss": 0.0067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5296499729156494,
      "rewards/margins": 6.468925476074219,
      "rewards/rejected": -3.9392757415771484,
      "step": 1645
    },
    {
      "epoch": 0.6584,
      "grad_norm": 0.053976353257894516,
      "learning_rate": 7.806666666666666e-07,
      "logits/chosen": -2.406883716583252,
      "logits/rejected": -3.515089511871338,
      "logps/chosen": -118.71038055419922,
      "logps/rejected": -159.47378540039062,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7954845428466797,
      "rewards/margins": 7.601095199584961,
      "rewards/rejected": -5.805610179901123,
      "step": 1646
    },
    {
      "epoch": 0.6588,
      "grad_norm": 0.1431543231010437,
      "learning_rate": 7.805333333333333e-07,
      "logits/chosen": -2.391329526901245,
      "logits/rejected": -3.189436674118042,
      "logps/chosen": -174.47860717773438,
      "logps/rejected": -142.7582244873047,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9483181238174438,
      "rewards/margins": 7.019730091094971,
      "rewards/rejected": -5.071412086486816,
      "step": 1647
    },
    {
      "epoch": 0.6592,
      "grad_norm": 0.7263720631599426,
      "learning_rate": 7.804e-07,
      "logits/chosen": -2.724196434020996,
      "logits/rejected": -3.3155155181884766,
      "logps/chosen": -204.82777404785156,
      "logps/rejected": -139.51568603515625,
      "loss": 0.0067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1747055053710938,
      "rewards/margins": 5.565354824066162,
      "rewards/rejected": -3.3906493186950684,
      "step": 1648
    },
    {
      "epoch": 0.6596,
      "grad_norm": 0.127239391207695,
      "learning_rate": 7.802666666666667e-07,
      "logits/chosen": -2.193514823913574,
      "logits/rejected": -2.8222923278808594,
      "logps/chosen": -79.27296447753906,
      "logps/rejected": -142.66854858398438,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6620213985443115,
      "rewards/margins": 7.215683937072754,
      "rewards/rejected": -4.553662300109863,
      "step": 1649
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.41838735342025757,
      "learning_rate": 7.801333333333334e-07,
      "logits/chosen": -2.101771593093872,
      "logits/rejected": -2.724825382232666,
      "logps/chosen": -104.4151611328125,
      "logps/rejected": -118.35940551757812,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5656135082244873,
      "rewards/margins": 6.388290882110596,
      "rewards/rejected": -3.8226771354675293,
      "step": 1650
    },
    {
      "epoch": 0.6604,
      "grad_norm": 0.3373362421989441,
      "learning_rate": 7.799999999999999e-07,
      "logits/chosen": -2.405599594116211,
      "logits/rejected": -2.968543529510498,
      "logps/chosen": -106.83419799804688,
      "logps/rejected": -117.97721862792969,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2206201553344727,
      "rewards/margins": 7.851889610290527,
      "rewards/rejected": -4.631269454956055,
      "step": 1651
    },
    {
      "epoch": 0.6608,
      "grad_norm": 0.2679584324359894,
      "learning_rate": 7.798666666666666e-07,
      "logits/chosen": -2.2158989906311035,
      "logits/rejected": -3.1942901611328125,
      "logps/chosen": -97.32315063476562,
      "logps/rejected": -183.55831909179688,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8441959619522095,
      "rewards/margins": 6.713624477386475,
      "rewards/rejected": -5.869428634643555,
      "step": 1652
    },
    {
      "epoch": 0.6612,
      "grad_norm": 0.17044992744922638,
      "learning_rate": 7.797333333333332e-07,
      "logits/chosen": -2.3832902908325195,
      "logits/rejected": -3.2653748989105225,
      "logps/chosen": -123.5593490600586,
      "logps/rejected": -122.39752197265625,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0723118782043457,
      "rewards/margins": 7.038197040557861,
      "rewards/rejected": -3.9658851623535156,
      "step": 1653
    },
    {
      "epoch": 0.6616,
      "grad_norm": 0.7765957713127136,
      "learning_rate": 7.795999999999999e-07,
      "logits/chosen": -2.764435291290283,
      "logits/rejected": -3.12054443359375,
      "logps/chosen": -144.6914825439453,
      "logps/rejected": -144.52816772460938,
      "loss": 0.0078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0156128406524658,
      "rewards/margins": 5.4547119140625,
      "rewards/rejected": -4.439098834991455,
      "step": 1654
    },
    {
      "epoch": 0.662,
      "grad_norm": 0.05132583528757095,
      "learning_rate": 7.794666666666666e-07,
      "logits/chosen": -1.9417117834091187,
      "logits/rejected": -3.345527410507202,
      "logps/chosen": -71.64856719970703,
      "logps/rejected": -121.20915985107422,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.566222667694092,
      "rewards/margins": 7.949080944061279,
      "rewards/rejected": -4.3828582763671875,
      "step": 1655
    },
    {
      "epoch": 0.6624,
      "grad_norm": 0.5083946585655212,
      "learning_rate": 7.793333333333333e-07,
      "logits/chosen": -2.3451812267303467,
      "logits/rejected": -3.087789535522461,
      "logps/chosen": -132.19940185546875,
      "logps/rejected": -173.3503875732422,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5767813920974731,
      "rewards/margins": 6.517077445983887,
      "rewards/rejected": -4.940296173095703,
      "step": 1656
    },
    {
      "epoch": 0.6628,
      "grad_norm": 0.3299896717071533,
      "learning_rate": 7.792e-07,
      "logits/chosen": -2.2201006412506104,
      "logits/rejected": -3.2190299034118652,
      "logps/chosen": -168.6922607421875,
      "logps/rejected": -150.89122009277344,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1878219842910767,
      "rewards/margins": 6.320207595825195,
      "rewards/rejected": -5.13238525390625,
      "step": 1657
    },
    {
      "epoch": 0.6632,
      "grad_norm": 18.111032485961914,
      "learning_rate": 7.790666666666667e-07,
      "logits/chosen": -2.5378048419952393,
      "logits/rejected": -2.7144017219543457,
      "logps/chosen": -185.03366088867188,
      "logps/rejected": -107.88408660888672,
      "loss": 0.141,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07719874382019043,
      "rewards/margins": 3.1730244159698486,
      "rewards/rejected": -3.095825672149658,
      "step": 1658
    },
    {
      "epoch": 0.6636,
      "grad_norm": 0.1947418600320816,
      "learning_rate": 7.789333333333334e-07,
      "logits/chosen": -1.8764426708221436,
      "logits/rejected": -3.0986948013305664,
      "logps/chosen": -92.34091186523438,
      "logps/rejected": -150.38365173339844,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9609241485595703,
      "rewards/margins": 7.317155838012695,
      "rewards/rejected": -5.356231689453125,
      "step": 1659
    },
    {
      "epoch": 0.664,
      "grad_norm": 1.355668067932129,
      "learning_rate": 7.788000000000001e-07,
      "logits/chosen": -2.1970410346984863,
      "logits/rejected": -3.054539203643799,
      "logps/chosen": -164.06439208984375,
      "logps/rejected": -150.69448852539062,
      "loss": 0.0141,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3274040222167969,
      "rewards/margins": 5.631516456604004,
      "rewards/rejected": -4.304112434387207,
      "step": 1660
    },
    {
      "epoch": 0.6644,
      "grad_norm": 0.01983722299337387,
      "learning_rate": 7.786666666666665e-07,
      "logits/chosen": -2.385721206665039,
      "logits/rejected": -3.172213315963745,
      "logps/chosen": -82.275634765625,
      "logps/rejected": -147.86260986328125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.883851051330566,
      "rewards/margins": 9.29470443725586,
      "rewards/rejected": -4.410852432250977,
      "step": 1661
    },
    {
      "epoch": 0.6648,
      "grad_norm": 0.028262147679924965,
      "learning_rate": 7.785333333333332e-07,
      "logits/chosen": -2.057861566543579,
      "logits/rejected": -3.0221176147460938,
      "logps/chosen": -69.04029846191406,
      "logps/rejected": -121.64869689941406,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.777655839920044,
      "rewards/margins": 8.084125518798828,
      "rewards/rejected": -4.306469440460205,
      "step": 1662
    },
    {
      "epoch": 0.6652,
      "grad_norm": 3.3300063610076904,
      "learning_rate": 7.783999999999999e-07,
      "logits/chosen": -2.035388946533203,
      "logits/rejected": -3.0292282104492188,
      "logps/chosen": -139.0419464111328,
      "logps/rejected": -127.63134765625,
      "loss": 0.0261,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.49055445194244385,
      "rewards/margins": 4.061976432800293,
      "rewards/rejected": -3.5714218616485596,
      "step": 1663
    },
    {
      "epoch": 0.6656,
      "grad_norm": 0.4516476094722748,
      "learning_rate": 7.782666666666666e-07,
      "logits/chosen": -2.341928005218506,
      "logits/rejected": -3.2521121501922607,
      "logps/chosen": -152.9445343017578,
      "logps/rejected": -155.42782592773438,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.186811923980713,
      "rewards/margins": 7.31027889251709,
      "rewards/rejected": -5.123466968536377,
      "step": 1664
    },
    {
      "epoch": 0.666,
      "grad_norm": 0.02701679803431034,
      "learning_rate": 7.781333333333333e-07,
      "logits/chosen": -2.9348442554473877,
      "logits/rejected": -3.680130958557129,
      "logps/chosen": -188.50103759765625,
      "logps/rejected": -167.59634399414062,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1751770973205566,
      "rewards/margins": 8.30111026763916,
      "rewards/rejected": -5.1259331703186035,
      "step": 1665
    },
    {
      "epoch": 0.6664,
      "grad_norm": 2.2578911781311035,
      "learning_rate": 7.78e-07,
      "logits/chosen": -2.950505018234253,
      "logits/rejected": -3.3045847415924072,
      "logps/chosen": -166.005615234375,
      "logps/rejected": -151.97525024414062,
      "loss": 0.0187,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0026390552520752,
      "rewards/margins": 5.302482604980469,
      "rewards/rejected": -4.2998433113098145,
      "step": 1666
    },
    {
      "epoch": 0.6668,
      "grad_norm": 0.03647501394152641,
      "learning_rate": 7.778666666666667e-07,
      "logits/chosen": -2.0617940425872803,
      "logits/rejected": -2.6663994789123535,
      "logps/chosen": -157.70416259765625,
      "logps/rejected": -202.50689697265625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5933220386505127,
      "rewards/margins": 8.940571784973145,
      "rewards/rejected": -7.347249507904053,
      "step": 1667
    },
    {
      "epoch": 0.6672,
      "grad_norm": 0.048642467707395554,
      "learning_rate": 7.777333333333334e-07,
      "logits/chosen": -1.6022429466247559,
      "logits/rejected": -2.7412288188934326,
      "logps/chosen": -51.78916549682617,
      "logps/rejected": -115.58712005615234,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.001575469970703,
      "rewards/margins": 7.561555862426758,
      "rewards/rejected": -3.559980869293213,
      "step": 1668
    },
    {
      "epoch": 0.6676,
      "grad_norm": 0.08893756568431854,
      "learning_rate": 7.776e-07,
      "logits/chosen": -2.565876007080078,
      "logits/rejected": -2.9830541610717773,
      "logps/chosen": -159.02700805664062,
      "logps/rejected": -158.79205322265625,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9319849014282227,
      "rewards/margins": 7.356407642364502,
      "rewards/rejected": -4.4244232177734375,
      "step": 1669
    },
    {
      "epoch": 0.668,
      "grad_norm": 0.1050974503159523,
      "learning_rate": 7.774666666666666e-07,
      "logits/chosen": -2.752436399459839,
      "logits/rejected": -3.0169780254364014,
      "logps/chosen": -182.35830688476562,
      "logps/rejected": -190.84812927246094,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.103186845779419,
      "rewards/margins": 7.865735054016113,
      "rewards/rejected": -5.762548446655273,
      "step": 1670
    },
    {
      "epoch": 0.6684,
      "grad_norm": 0.06676384806632996,
      "learning_rate": 7.773333333333333e-07,
      "logits/chosen": -2.286705732345581,
      "logits/rejected": -3.1062021255493164,
      "logps/chosen": -162.662353515625,
      "logps/rejected": -167.5512237548828,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.57509708404541,
      "rewards/margins": 8.288423538208008,
      "rewards/rejected": -5.713326454162598,
      "step": 1671
    },
    {
      "epoch": 0.6688,
      "grad_norm": 0.13251358270645142,
      "learning_rate": 7.771999999999999e-07,
      "logits/chosen": -1.9400923252105713,
      "logits/rejected": -3.0150463581085205,
      "logps/chosen": -90.18043518066406,
      "logps/rejected": -129.6532440185547,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9696838855743408,
      "rewards/margins": 6.9412736892700195,
      "rewards/rejected": -4.971589088439941,
      "step": 1672
    },
    {
      "epoch": 0.6692,
      "grad_norm": 0.44935524463653564,
      "learning_rate": 7.770666666666666e-07,
      "logits/chosen": -2.1395318508148193,
      "logits/rejected": -2.546384334564209,
      "logps/chosen": -70.34144592285156,
      "logps/rejected": -119.34503173828125,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3588993549346924,
      "rewards/margins": 6.889975070953369,
      "rewards/rejected": -4.531075954437256,
      "step": 1673
    },
    {
      "epoch": 0.6696,
      "grad_norm": 0.1283394992351532,
      "learning_rate": 7.769333333333333e-07,
      "logits/chosen": -2.18225359916687,
      "logits/rejected": -3.458904266357422,
      "logps/chosen": -116.33403015136719,
      "logps/rejected": -185.1268310546875,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8534579873085022,
      "rewards/margins": 6.76873779296875,
      "rewards/rejected": -5.915279865264893,
      "step": 1674
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.20606741309165955,
      "learning_rate": 7.768e-07,
      "logits/chosen": -1.7690082788467407,
      "logits/rejected": -2.870728015899658,
      "logps/chosen": -134.23764038085938,
      "logps/rejected": -161.36270141601562,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.933073878288269,
      "rewards/margins": 6.877630233764648,
      "rewards/rejected": -4.944556713104248,
      "step": 1675
    },
    {
      "epoch": 0.6704,
      "grad_norm": 0.388211727142334,
      "learning_rate": 7.766666666666666e-07,
      "logits/chosen": -2.5685462951660156,
      "logits/rejected": -3.0781140327453613,
      "logps/chosen": -111.0574951171875,
      "logps/rejected": -142.78807067871094,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.445720911026001,
      "rewards/margins": 6.225537300109863,
      "rewards/rejected": -3.7798166275024414,
      "step": 1676
    },
    {
      "epoch": 0.6708,
      "grad_norm": 3.4261505603790283,
      "learning_rate": 7.765333333333333e-07,
      "logits/chosen": -2.3610668182373047,
      "logits/rejected": -2.1420435905456543,
      "logps/chosen": -149.05369567871094,
      "logps/rejected": -128.94308471679688,
      "loss": 0.0287,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2632591128349304,
      "rewards/margins": 4.689440727233887,
      "rewards/rejected": -4.952700138092041,
      "step": 1677
    },
    {
      "epoch": 0.6712,
      "grad_norm": 0.6772450804710388,
      "learning_rate": 7.764e-07,
      "logits/chosen": -2.3528494834899902,
      "logits/rejected": -2.7267138957977295,
      "logps/chosen": -199.06094360351562,
      "logps/rejected": -142.15501403808594,
      "loss": 0.0075,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8732507228851318,
      "rewards/margins": 4.899517059326172,
      "rewards/rejected": -3.026266098022461,
      "step": 1678
    },
    {
      "epoch": 0.6716,
      "grad_norm": 1.9406459331512451,
      "learning_rate": 7.762666666666666e-07,
      "logits/chosen": -2.7968499660491943,
      "logits/rejected": -3.348564386367798,
      "logps/chosen": -223.798583984375,
      "logps/rejected": -136.7270965576172,
      "loss": 0.0173,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9330864548683167,
      "rewards/margins": 5.049017906188965,
      "rewards/rejected": -4.115931510925293,
      "step": 1679
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.04715009406208992,
      "learning_rate": 7.761333333333333e-07,
      "logits/chosen": -2.2152178287506104,
      "logits/rejected": -3.3208580017089844,
      "logps/chosen": -140.89813232421875,
      "logps/rejected": -161.80767822265625,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.489441394805908,
      "rewards/margins": 7.588922023773193,
      "rewards/rejected": -5.099480628967285,
      "step": 1680
    },
    {
      "epoch": 0.6724,
      "grad_norm": 0.5751269459724426,
      "learning_rate": 7.76e-07,
      "logits/chosen": -2.1894516944885254,
      "logits/rejected": -3.5541746616363525,
      "logps/chosen": -138.3654327392578,
      "logps/rejected": -157.53285217285156,
      "loss": 0.0067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9977371692657471,
      "rewards/margins": 5.248218059539795,
      "rewards/rejected": -4.250481128692627,
      "step": 1681
    },
    {
      "epoch": 0.6728,
      "grad_norm": 0.58514004945755,
      "learning_rate": 7.758666666666667e-07,
      "logits/chosen": -2.0727715492248535,
      "logits/rejected": -2.8433659076690674,
      "logps/chosen": -96.4144515991211,
      "logps/rejected": -130.25967407226562,
      "loss": 0.0049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.052638292312622,
      "rewards/margins": 5.453490257263184,
      "rewards/rejected": -3.4008517265319824,
      "step": 1682
    },
    {
      "epoch": 0.6732,
      "grad_norm": 1.004526972770691,
      "learning_rate": 7.757333333333333e-07,
      "logits/chosen": -2.5580222606658936,
      "logits/rejected": -4.106906890869141,
      "logps/chosen": -238.94532775878906,
      "logps/rejected": -173.46212768554688,
      "loss": 0.0115,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8233924508094788,
      "rewards/margins": 5.943251609802246,
      "rewards/rejected": -5.11985969543457,
      "step": 1683
    },
    {
      "epoch": 0.6736,
      "grad_norm": 1.7113628387451172,
      "learning_rate": 7.755999999999999e-07,
      "logits/chosen": -2.08933162689209,
      "logits/rejected": -2.858919620513916,
      "logps/chosen": -99.50758361816406,
      "logps/rejected": -117.48294830322266,
      "loss": 0.0203,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7704654932022095,
      "rewards/margins": 4.567752361297607,
      "rewards/rejected": -3.7972867488861084,
      "step": 1684
    },
    {
      "epoch": 0.674,
      "grad_norm": 0.45393189787864685,
      "learning_rate": 7.754666666666666e-07,
      "logits/chosen": -2.2888431549072266,
      "logits/rejected": -3.3088011741638184,
      "logps/chosen": -137.89486694335938,
      "logps/rejected": -173.4217987060547,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1529542207717896,
      "rewards/margins": 6.847062587738037,
      "rewards/rejected": -5.694108009338379,
      "step": 1685
    },
    {
      "epoch": 0.6744,
      "grad_norm": 0.3423803746700287,
      "learning_rate": 7.753333333333333e-07,
      "logits/chosen": -2.6201815605163574,
      "logits/rejected": -3.1357836723327637,
      "logps/chosen": -125.28517150878906,
      "logps/rejected": -154.9192657470703,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.297478675842285,
      "rewards/margins": 6.289106369018555,
      "rewards/rejected": -2.9916276931762695,
      "step": 1686
    },
    {
      "epoch": 0.6748,
      "grad_norm": 0.10773692280054092,
      "learning_rate": 7.752e-07,
      "logits/chosen": -2.396240472793579,
      "logits/rejected": -2.9906368255615234,
      "logps/chosen": -131.03237915039062,
      "logps/rejected": -231.9273681640625,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9044806957244873,
      "rewards/margins": 8.684650421142578,
      "rewards/rejected": -5.780170440673828,
      "step": 1687
    },
    {
      "epoch": 0.6752,
      "grad_norm": 0.047141630202531815,
      "learning_rate": 7.750666666666667e-07,
      "logits/chosen": -2.423048257827759,
      "logits/rejected": -2.991793155670166,
      "logps/chosen": -225.9501953125,
      "logps/rejected": -140.0639190673828,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.829934597015381,
      "rewards/margins": 7.799135208129883,
      "rewards/rejected": -4.969200134277344,
      "step": 1688
    },
    {
      "epoch": 0.6756,
      "grad_norm": 6.018564224243164,
      "learning_rate": 7.749333333333333e-07,
      "logits/chosen": -1.930124282836914,
      "logits/rejected": -2.9510397911071777,
      "logps/chosen": -101.66926574707031,
      "logps/rejected": -111.83617401123047,
      "loss": 0.043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2835559844970703,
      "rewards/margins": 4.805098533630371,
      "rewards/rejected": -3.52154278755188,
      "step": 1689
    },
    {
      "epoch": 0.676,
      "grad_norm": 0.40942099690437317,
      "learning_rate": 7.748e-07,
      "logits/chosen": -1.7459993362426758,
      "logits/rejected": -3.591679096221924,
      "logps/chosen": -120.76473999023438,
      "logps/rejected": -160.2813262939453,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.345280170440674,
      "rewards/margins": 7.698883056640625,
      "rewards/rejected": -5.353603363037109,
      "step": 1690
    },
    {
      "epoch": 0.6764,
      "grad_norm": 0.35635653138160706,
      "learning_rate": 7.746666666666666e-07,
      "logits/chosen": -2.1719579696655273,
      "logits/rejected": -3.031372547149658,
      "logps/chosen": -114.41127014160156,
      "logps/rejected": -145.4789276123047,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1590218544006348,
      "rewards/margins": 5.574959754943848,
      "rewards/rejected": -3.415937900543213,
      "step": 1691
    },
    {
      "epoch": 0.6768,
      "grad_norm": 0.049987051635980606,
      "learning_rate": 7.745333333333333e-07,
      "logits/chosen": -1.367135763168335,
      "logits/rejected": -3.473323345184326,
      "logps/chosen": -77.5490493774414,
      "logps/rejected": -155.27999877929688,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9307498931884766,
      "rewards/margins": 8.282011985778809,
      "rewards/rejected": -5.351262092590332,
      "step": 1692
    },
    {
      "epoch": 0.6772,
      "grad_norm": 0.03120533563196659,
      "learning_rate": 7.743999999999999e-07,
      "logits/chosen": -2.1283040046691895,
      "logits/rejected": -3.5662097930908203,
      "logps/chosen": -194.77734375,
      "logps/rejected": -145.45204162597656,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.158640384674072,
      "rewards/margins": 8.963018417358398,
      "rewards/rejected": -4.804378509521484,
      "step": 1693
    },
    {
      "epoch": 0.6776,
      "grad_norm": 0.18684495985507965,
      "learning_rate": 7.742666666666666e-07,
      "logits/chosen": -1.8952617645263672,
      "logits/rejected": -4.041790962219238,
      "logps/chosen": -97.85244750976562,
      "logps/rejected": -152.06593322753906,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9352684020996094,
      "rewards/margins": 7.341174125671387,
      "rewards/rejected": -5.405905723571777,
      "step": 1694
    },
    {
      "epoch": 0.678,
      "grad_norm": 0.1783580482006073,
      "learning_rate": 7.741333333333333e-07,
      "logits/chosen": -2.1149790287017822,
      "logits/rejected": -2.9106252193450928,
      "logps/chosen": -104.29463195800781,
      "logps/rejected": -133.89126586914062,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.145059108734131,
      "rewards/margins": 6.686383247375488,
      "rewards/rejected": -4.541323661804199,
      "step": 1695
    },
    {
      "epoch": 0.6784,
      "grad_norm": 0.03243347629904747,
      "learning_rate": 7.74e-07,
      "logits/chosen": -2.2389800548553467,
      "logits/rejected": -3.046998977661133,
      "logps/chosen": -130.175537109375,
      "logps/rejected": -146.6099395751953,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.219326972961426,
      "rewards/margins": 7.92462158203125,
      "rewards/rejected": -4.705294609069824,
      "step": 1696
    },
    {
      "epoch": 0.6788,
      "grad_norm": 0.016522899270057678,
      "learning_rate": 7.738666666666667e-07,
      "logits/chosen": -2.395629405975342,
      "logits/rejected": -2.586517810821533,
      "logps/chosen": -140.5134735107422,
      "logps/rejected": -153.81884765625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3843681812286377,
      "rewards/margins": 8.878250122070312,
      "rewards/rejected": -5.4938812255859375,
      "step": 1697
    },
    {
      "epoch": 0.6792,
      "grad_norm": 0.013479702174663544,
      "learning_rate": 7.737333333333333e-07,
      "logits/chosen": -2.461648464202881,
      "logits/rejected": -3.251767635345459,
      "logps/chosen": -148.85617065429688,
      "logps/rejected": -179.12574768066406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.927093505859375,
      "rewards/margins": 9.093276023864746,
      "rewards/rejected": -5.166182518005371,
      "step": 1698
    },
    {
      "epoch": 0.6796,
      "grad_norm": 0.23650918900966644,
      "learning_rate": 7.735999999999999e-07,
      "logits/chosen": -2.5078988075256348,
      "logits/rejected": -3.5501794815063477,
      "logps/chosen": -147.1337890625,
      "logps/rejected": -194.0235595703125,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1613197326660156,
      "rewards/margins": 8.060464859008789,
      "rewards/rejected": -6.899145126342773,
      "step": 1699
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.020771773532032967,
      "learning_rate": 7.734666666666666e-07,
      "logits/chosen": -2.4102044105529785,
      "logits/rejected": -2.830634117126465,
      "logps/chosen": -145.348388671875,
      "logps/rejected": -199.59498596191406,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5853018760681152,
      "rewards/margins": 8.559510231018066,
      "rewards/rejected": -4.974208354949951,
      "step": 1700
    },
    {
      "epoch": 0.6804,
      "grad_norm": 0.9913546442985535,
      "learning_rate": 7.733333333333333e-07,
      "logits/chosen": -1.9600706100463867,
      "logits/rejected": -2.351149559020996,
      "logps/chosen": -89.03399658203125,
      "logps/rejected": -131.69334411621094,
      "loss": 0.0077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9336986541748047,
      "rewards/margins": 6.46804141998291,
      "rewards/rejected": -4.534343242645264,
      "step": 1701
    },
    {
      "epoch": 0.6808,
      "grad_norm": 0.6391534209251404,
      "learning_rate": 7.732e-07,
      "logits/chosen": -2.1711010932922363,
      "logits/rejected": -2.8048832416534424,
      "logps/chosen": -121.26219177246094,
      "logps/rejected": -149.01583862304688,
      "loss": 0.0062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8867884874343872,
      "rewards/margins": 5.943362236022949,
      "rewards/rejected": -5.056573867797852,
      "step": 1702
    },
    {
      "epoch": 0.6812,
      "grad_norm": 0.026302605867385864,
      "learning_rate": 7.730666666666667e-07,
      "logits/chosen": -2.4868319034576416,
      "logits/rejected": -3.432804584503174,
      "logps/chosen": -104.40080261230469,
      "logps/rejected": -186.26434326171875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.919724941253662,
      "rewards/margins": 8.865161895751953,
      "rewards/rejected": -4.945437431335449,
      "step": 1703
    },
    {
      "epoch": 0.6816,
      "grad_norm": 0.11900916695594788,
      "learning_rate": 7.729333333333333e-07,
      "logits/chosen": -2.7280592918395996,
      "logits/rejected": -3.2933285236358643,
      "logps/chosen": -167.67002868652344,
      "logps/rejected": -131.93331909179688,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9256486892700195,
      "rewards/margins": 7.353374481201172,
      "rewards/rejected": -3.4277255535125732,
      "step": 1704
    },
    {
      "epoch": 0.682,
      "grad_norm": 0.1231059655547142,
      "learning_rate": 7.728e-07,
      "logits/chosen": -2.4851598739624023,
      "logits/rejected": -3.290649175643921,
      "logps/chosen": -144.4374237060547,
      "logps/rejected": -148.70718383789062,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8200607299804688,
      "rewards/margins": 6.97769832611084,
      "rewards/rejected": -4.157637596130371,
      "step": 1705
    },
    {
      "epoch": 0.6824,
      "grad_norm": 0.2719235420227051,
      "learning_rate": 7.726666666666666e-07,
      "logits/chosen": -2.7337446212768555,
      "logits/rejected": -3.4661622047424316,
      "logps/chosen": -177.7454071044922,
      "logps/rejected": -160.58328247070312,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7877098321914673,
      "rewards/margins": 6.272551536560059,
      "rewards/rejected": -5.484841346740723,
      "step": 1706
    },
    {
      "epoch": 0.6828,
      "grad_norm": 0.009807956404983997,
      "learning_rate": 7.725333333333332e-07,
      "logits/chosen": -2.6772661209106445,
      "logits/rejected": -3.2333078384399414,
      "logps/chosen": -133.09701538085938,
      "logps/rejected": -212.740478515625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.490880012512207,
      "rewards/margins": 9.570700645446777,
      "rewards/rejected": -5.07982063293457,
      "step": 1707
    },
    {
      "epoch": 0.6832,
      "grad_norm": 3.671356201171875,
      "learning_rate": 7.723999999999999e-07,
      "logits/chosen": -2.2608461380004883,
      "logits/rejected": -2.7273309230804443,
      "logps/chosen": -120.41322326660156,
      "logps/rejected": -113.48828887939453,
      "loss": 0.0396,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1178600788116455,
      "rewards/margins": 4.133201599121094,
      "rewards/rejected": -3.0153417587280273,
      "step": 1708
    },
    {
      "epoch": 0.6836,
      "grad_norm": 0.010376556776463985,
      "learning_rate": 7.722666666666666e-07,
      "logits/chosen": -2.0427727699279785,
      "logits/rejected": -2.543288230895996,
      "logps/chosen": -88.70684051513672,
      "logps/rejected": -199.20245361328125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.239686012268066,
      "rewards/margins": 9.824579238891602,
      "rewards/rejected": -5.584892749786377,
      "step": 1709
    },
    {
      "epoch": 0.684,
      "grad_norm": 0.07697370648384094,
      "learning_rate": 7.721333333333333e-07,
      "logits/chosen": -2.2888596057891846,
      "logits/rejected": -2.7312004566192627,
      "logps/chosen": -83.48712158203125,
      "logps/rejected": -124.87745666503906,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8186678886413574,
      "rewards/margins": 7.9283647537231445,
      "rewards/rejected": -5.109696388244629,
      "step": 1710
    },
    {
      "epoch": 0.6844,
      "grad_norm": 0.7417539358139038,
      "learning_rate": 7.72e-07,
      "logits/chosen": -2.486520290374756,
      "logits/rejected": -2.289293050765991,
      "logps/chosen": -129.16366577148438,
      "logps/rejected": -129.005859375,
      "loss": 0.0071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.45145845413208,
      "rewards/margins": 5.602722644805908,
      "rewards/rejected": -3.151264190673828,
      "step": 1711
    },
    {
      "epoch": 0.6848,
      "grad_norm": 0.01677669771015644,
      "learning_rate": 7.718666666666667e-07,
      "logits/chosen": -2.4202516078948975,
      "logits/rejected": -3.3007912635803223,
      "logps/chosen": -173.26925659179688,
      "logps/rejected": -162.97616577148438,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.72257137298584,
      "rewards/margins": 8.70923137664795,
      "rewards/rejected": -3.986659526824951,
      "step": 1712
    },
    {
      "epoch": 0.6852,
      "grad_norm": 0.06502419710159302,
      "learning_rate": 7.717333333333334e-07,
      "logits/chosen": -2.4478442668914795,
      "logits/rejected": -2.828488826751709,
      "logps/chosen": -103.25625610351562,
      "logps/rejected": -129.0594940185547,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0849735736846924,
      "rewards/margins": 7.333743572235107,
      "rewards/rejected": -4.248769760131836,
      "step": 1713
    },
    {
      "epoch": 0.6856,
      "grad_norm": 0.009998276829719543,
      "learning_rate": 7.716e-07,
      "logits/chosen": -1.8704042434692383,
      "logits/rejected": -3.1098976135253906,
      "logps/chosen": -98.86444854736328,
      "logps/rejected": -156.6175079345703,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2720422744750977,
      "rewards/margins": 9.458674430847168,
      "rewards/rejected": -6.18663215637207,
      "step": 1714
    },
    {
      "epoch": 0.686,
      "grad_norm": 0.534099817276001,
      "learning_rate": 7.714666666666666e-07,
      "logits/chosen": -2.744767189025879,
      "logits/rejected": -2.5165491104125977,
      "logps/chosen": -112.62823486328125,
      "logps/rejected": -130.35665893554688,
      "loss": 0.005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.05495548248291,
      "rewards/margins": 7.0241899490356445,
      "rewards/rejected": -3.9692344665527344,
      "step": 1715
    },
    {
      "epoch": 0.6864,
      "grad_norm": 2.151482105255127,
      "learning_rate": 7.713333333333333e-07,
      "logits/chosen": -2.6329493522644043,
      "logits/rejected": -2.858464002609253,
      "logps/chosen": -236.38674926757812,
      "logps/rejected": -131.9765625,
      "loss": 0.0158,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.47031325101852417,
      "rewards/margins": 4.834916591644287,
      "rewards/rejected": -4.364603042602539,
      "step": 1716
    },
    {
      "epoch": 0.6868,
      "grad_norm": 0.8679258823394775,
      "learning_rate": 7.711999999999999e-07,
      "logits/chosen": -2.042534589767456,
      "logits/rejected": -2.8055825233459473,
      "logps/chosen": -96.97993469238281,
      "logps/rejected": -125.59402465820312,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.007810592651367,
      "rewards/margins": 6.723690986633301,
      "rewards/rejected": -4.715880393981934,
      "step": 1717
    },
    {
      "epoch": 0.6872,
      "grad_norm": 2.5166938304901123,
      "learning_rate": 7.710666666666666e-07,
      "logits/chosen": -2.7788820266723633,
      "logits/rejected": -3.4923384189605713,
      "logps/chosen": -140.11578369140625,
      "logps/rejected": -151.40447998046875,
      "loss": 0.0364,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04288288950920105,
      "rewards/margins": 4.4746413230896,
      "rewards/rejected": -4.431758403778076,
      "step": 1718
    },
    {
      "epoch": 0.6876,
      "grad_norm": 0.2583521902561188,
      "learning_rate": 7.709333333333333e-07,
      "logits/chosen": -2.2546286582946777,
      "logits/rejected": -3.2420473098754883,
      "logps/chosen": -142.22080993652344,
      "logps/rejected": -237.41241455078125,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.239319324493408,
      "rewards/margins": 6.356091499328613,
      "rewards/rejected": -4.116772651672363,
      "step": 1719
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.3121475875377655,
      "learning_rate": 7.708e-07,
      "logits/chosen": -3.03840970993042,
      "logits/rejected": -3.015176773071289,
      "logps/chosen": -166.22647094726562,
      "logps/rejected": -150.51258850097656,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42796555161476135,
      "rewards/margins": 5.697541236877441,
      "rewards/rejected": -5.269576072692871,
      "step": 1720
    },
    {
      "epoch": 0.6884,
      "grad_norm": 0.15256300568580627,
      "learning_rate": 7.706666666666667e-07,
      "logits/chosen": -2.316906452178955,
      "logits/rejected": -2.4441490173339844,
      "logps/chosen": -130.44300842285156,
      "logps/rejected": -149.246337890625,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8398911952972412,
      "rewards/margins": 6.577963829040527,
      "rewards/rejected": -4.738072395324707,
      "step": 1721
    },
    {
      "epoch": 0.6888,
      "grad_norm": 0.011792137287557125,
      "learning_rate": 7.705333333333333e-07,
      "logits/chosen": -2.5071237087249756,
      "logits/rejected": -3.3239076137542725,
      "logps/chosen": -232.04588317871094,
      "logps/rejected": -191.85086059570312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.278432607650757,
      "rewards/margins": 9.883861541748047,
      "rewards/rejected": -7.605428695678711,
      "step": 1722
    },
    {
      "epoch": 0.6892,
      "grad_norm": 0.09864829480648041,
      "learning_rate": 7.704e-07,
      "logits/chosen": -1.849735140800476,
      "logits/rejected": -3.893742561340332,
      "logps/chosen": -109.69702911376953,
      "logps/rejected": -135.28326416015625,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4293158054351807,
      "rewards/margins": 6.910819053649902,
      "rewards/rejected": -4.481503486633301,
      "step": 1723
    },
    {
      "epoch": 0.6896,
      "grad_norm": 0.04909677430987358,
      "learning_rate": 7.702666666666667e-07,
      "logits/chosen": -2.09679913520813,
      "logits/rejected": -3.3057775497436523,
      "logps/chosen": -150.60105895996094,
      "logps/rejected": -146.94761657714844,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5579278469085693,
      "rewards/margins": 7.55296516418457,
      "rewards/rejected": -3.995037078857422,
      "step": 1724
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.10707336664199829,
      "learning_rate": 7.701333333333333e-07,
      "logits/chosen": -2.3988196849823,
      "logits/rejected": -3.195596694946289,
      "logps/chosen": -165.57174682617188,
      "logps/rejected": -193.82241821289062,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6899399757385254,
      "rewards/margins": 8.56689453125,
      "rewards/rejected": -5.876955032348633,
      "step": 1725
    },
    {
      "epoch": 0.6904,
      "grad_norm": 0.019563868641853333,
      "learning_rate": 7.699999999999999e-07,
      "logits/chosen": -2.4364676475524902,
      "logits/rejected": -3.62697434425354,
      "logps/chosen": -155.2420654296875,
      "logps/rejected": -156.27452087402344,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.0028977394104,
      "rewards/margins": 8.798561096191406,
      "rewards/rejected": -4.795663833618164,
      "step": 1726
    },
    {
      "epoch": 0.6908,
      "grad_norm": 1.621819257736206,
      "learning_rate": 7.698666666666666e-07,
      "logits/chosen": -2.603128433227539,
      "logits/rejected": -3.0881118774414062,
      "logps/chosen": -133.98284912109375,
      "logps/rejected": -126.50811767578125,
      "loss": 0.0193,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27673569321632385,
      "rewards/margins": 4.235991477966309,
      "rewards/rejected": -3.9592556953430176,
      "step": 1727
    },
    {
      "epoch": 0.6912,
      "grad_norm": 0.4305039644241333,
      "learning_rate": 7.697333333333333e-07,
      "logits/chosen": -2.247897148132324,
      "logits/rejected": -3.0909018516540527,
      "logps/chosen": -96.43557739257812,
      "logps/rejected": -114.04496765136719,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4032864570617676,
      "rewards/margins": 5.796142578125,
      "rewards/rejected": -3.3928561210632324,
      "step": 1728
    },
    {
      "epoch": 0.6916,
      "grad_norm": 0.07241451740264893,
      "learning_rate": 7.695999999999999e-07,
      "logits/chosen": -2.088197708129883,
      "logits/rejected": -3.085258960723877,
      "logps/chosen": -159.389404296875,
      "logps/rejected": -175.22705078125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.221726179122925,
      "rewards/margins": 9.077190399169922,
      "rewards/rejected": -6.855463981628418,
      "step": 1729
    },
    {
      "epoch": 0.692,
      "grad_norm": 0.02358311228454113,
      "learning_rate": 7.694666666666666e-07,
      "logits/chosen": -2.5750465393066406,
      "logits/rejected": -3.4734582901000977,
      "logps/chosen": -129.17361450195312,
      "logps/rejected": -171.58724975585938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.752549648284912,
      "rewards/margins": 8.317564964294434,
      "rewards/rejected": -5.5650153160095215,
      "step": 1730
    },
    {
      "epoch": 0.6924,
      "grad_norm": 7.524443626403809,
      "learning_rate": 7.693333333333333e-07,
      "logits/chosen": -1.5916728973388672,
      "logits/rejected": -2.8273391723632812,
      "logps/chosen": -87.03962707519531,
      "logps/rejected": -121.52774047851562,
      "loss": 0.0533,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3131039142608643,
      "rewards/margins": 5.231511116027832,
      "rewards/rejected": -3.9184072017669678,
      "step": 1731
    },
    {
      "epoch": 0.6928,
      "grad_norm": 0.038546886295080185,
      "learning_rate": 7.692e-07,
      "logits/chosen": -2.1754794120788574,
      "logits/rejected": -3.343029022216797,
      "logps/chosen": -101.46171569824219,
      "logps/rejected": -210.77175903320312,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2869906425476074,
      "rewards/margins": 8.011051177978516,
      "rewards/rejected": -4.724060535430908,
      "step": 1732
    },
    {
      "epoch": 0.6932,
      "grad_norm": 1.1268644332885742,
      "learning_rate": 7.690666666666667e-07,
      "logits/chosen": -2.031263828277588,
      "logits/rejected": -2.8949780464172363,
      "logps/chosen": -92.23828887939453,
      "logps/rejected": -137.55239868164062,
      "loss": 0.0112,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4941855669021606,
      "rewards/margins": 5.822783470153809,
      "rewards/rejected": -4.3285980224609375,
      "step": 1733
    },
    {
      "epoch": 0.6936,
      "grad_norm": 1.1663262844085693,
      "learning_rate": 7.689333333333334e-07,
      "logits/chosen": -2.130680561065674,
      "logits/rejected": -3.081584930419922,
      "logps/chosen": -86.86956787109375,
      "logps/rejected": -166.11964416503906,
      "loss": 0.0092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4756224155426025,
      "rewards/margins": 6.872236251831055,
      "rewards/rejected": -5.396613597869873,
      "step": 1734
    },
    {
      "epoch": 0.694,
      "grad_norm": 0.07069151848554611,
      "learning_rate": 7.688000000000001e-07,
      "logits/chosen": -2.1031312942504883,
      "logits/rejected": -3.422226905822754,
      "logps/chosen": -167.01211547851562,
      "logps/rejected": -145.70736694335938,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7429957389831543,
      "rewards/margins": 8.436006546020508,
      "rewards/rejected": -4.6930108070373535,
      "step": 1735
    },
    {
      "epoch": 0.6944,
      "grad_norm": 0.15496686100959778,
      "learning_rate": 7.686666666666666e-07,
      "logits/chosen": -1.7136330604553223,
      "logits/rejected": -3.431580066680908,
      "logps/chosen": -136.11309814453125,
      "logps/rejected": -185.32327270507812,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7515449523925781,
      "rewards/margins": 6.935798168182373,
      "rewards/rejected": -6.184253215789795,
      "step": 1736
    },
    {
      "epoch": 0.6948,
      "grad_norm": 0.06270929425954819,
      "learning_rate": 7.685333333333332e-07,
      "logits/chosen": -2.3003714084625244,
      "logits/rejected": -3.253471851348877,
      "logps/chosen": -123.77911376953125,
      "logps/rejected": -148.63369750976562,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0667736530303955,
      "rewards/margins": 7.700394630432129,
      "rewards/rejected": -4.6336212158203125,
      "step": 1737
    },
    {
      "epoch": 0.6952,
      "grad_norm": 0.06057961285114288,
      "learning_rate": 7.683999999999999e-07,
      "logits/chosen": -2.131828784942627,
      "logits/rejected": -2.917224884033203,
      "logps/chosen": -84.01780700683594,
      "logps/rejected": -128.80685424804688,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.852275848388672,
      "rewards/margins": 7.191326141357422,
      "rewards/rejected": -4.339050769805908,
      "step": 1738
    },
    {
      "epoch": 0.6956,
      "grad_norm": 0.21321254968643188,
      "learning_rate": 7.682666666666666e-07,
      "logits/chosen": -1.7145190238952637,
      "logits/rejected": -2.9052958488464355,
      "logps/chosen": -95.42796325683594,
      "logps/rejected": -127.9964828491211,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.450232982635498,
      "rewards/margins": 5.933995246887207,
      "rewards/rejected": -3.483762264251709,
      "step": 1739
    },
    {
      "epoch": 0.696,
      "grad_norm": 2.65112042427063,
      "learning_rate": 7.681333333333333e-07,
      "logits/chosen": -2.365774631500244,
      "logits/rejected": -2.7070014476776123,
      "logps/chosen": -78.93663024902344,
      "logps/rejected": -102.82470703125,
      "loss": 0.0384,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2122879028320312,
      "rewards/margins": 6.506765842437744,
      "rewards/rejected": -3.294477939605713,
      "step": 1740
    },
    {
      "epoch": 0.6964,
      "grad_norm": 0.20394256711006165,
      "learning_rate": 7.68e-07,
      "logits/chosen": -2.188070774078369,
      "logits/rejected": -3.2576656341552734,
      "logps/chosen": -101.97801208496094,
      "logps/rejected": -165.13955688476562,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.339359760284424,
      "rewards/margins": 7.108590126037598,
      "rewards/rejected": -4.769230365753174,
      "step": 1741
    },
    {
      "epoch": 0.6968,
      "grad_norm": 0.15726403892040253,
      "learning_rate": 7.678666666666667e-07,
      "logits/chosen": -1.914780616760254,
      "logits/rejected": -2.9035868644714355,
      "logps/chosen": -207.95960998535156,
      "logps/rejected": -161.1311798095703,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5359723567962646,
      "rewards/margins": 6.993534088134766,
      "rewards/rejected": -4.457561492919922,
      "step": 1742
    },
    {
      "epoch": 0.6972,
      "grad_norm": 0.7386451959609985,
      "learning_rate": 7.677333333333334e-07,
      "logits/chosen": -1.6931266784667969,
      "logits/rejected": -2.694887161254883,
      "logps/chosen": -98.13130950927734,
      "logps/rejected": -114.6755142211914,
      "loss": 0.0071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0912747383117676,
      "rewards/margins": 5.0269670486450195,
      "rewards/rejected": -3.93569278717041,
      "step": 1743
    },
    {
      "epoch": 0.6976,
      "grad_norm": 0.2108416110277176,
      "learning_rate": 7.676e-07,
      "logits/chosen": -1.8205287456512451,
      "logits/rejected": -2.6950185298919678,
      "logps/chosen": -152.46951293945312,
      "logps/rejected": -165.1590576171875,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.337644577026367,
      "rewards/margins": 8.482475280761719,
      "rewards/rejected": -6.14483118057251,
      "step": 1744
    },
    {
      "epoch": 0.698,
      "grad_norm": 0.217279851436615,
      "learning_rate": 7.674666666666666e-07,
      "logits/chosen": -2.2244672775268555,
      "logits/rejected": -2.850987434387207,
      "logps/chosen": -79.32510375976562,
      "logps/rejected": -145.62147521972656,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6816799640655518,
      "rewards/margins": 6.994091987609863,
      "rewards/rejected": -3.3124125003814697,
      "step": 1745
    },
    {
      "epoch": 0.6984,
      "grad_norm": 2.685962438583374,
      "learning_rate": 7.673333333333332e-07,
      "logits/chosen": -2.2687108516693115,
      "logits/rejected": -2.943162202835083,
      "logps/chosen": -100.5166015625,
      "logps/rejected": -137.37620544433594,
      "loss": 0.0197,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.46615299582481384,
      "rewards/margins": 4.419386863708496,
      "rewards/rejected": -4.885540008544922,
      "step": 1746
    },
    {
      "epoch": 0.6988,
      "grad_norm": 0.1234717071056366,
      "learning_rate": 7.671999999999999e-07,
      "logits/chosen": -2.417178153991699,
      "logits/rejected": -3.5784835815429688,
      "logps/chosen": -167.38253784179688,
      "logps/rejected": -153.71932983398438,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4420876502990723,
      "rewards/margins": 6.830132484436035,
      "rewards/rejected": -4.388044834136963,
      "step": 1747
    },
    {
      "epoch": 0.6992,
      "grad_norm": 1.0973656177520752,
      "learning_rate": 7.670666666666666e-07,
      "logits/chosen": -1.9635114669799805,
      "logits/rejected": -3.097904682159424,
      "logps/chosen": -172.7927703857422,
      "logps/rejected": -179.6182098388672,
      "loss": 0.011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0572361946105957,
      "rewards/margins": 6.590753555297852,
      "rewards/rejected": -4.533516883850098,
      "step": 1748
    },
    {
      "epoch": 0.6996,
      "grad_norm": 0.6991702914237976,
      "learning_rate": 7.669333333333333e-07,
      "logits/chosen": -1.8136118650436401,
      "logits/rejected": -3.012695550918579,
      "logps/chosen": -109.52256774902344,
      "logps/rejected": -135.57577514648438,
      "loss": 0.0069,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3676180839538574,
      "rewards/margins": 5.278740406036377,
      "rewards/rejected": -2.9111223220825195,
      "step": 1749
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.01858731359243393,
      "learning_rate": 7.668e-07,
      "logits/chosen": -2.5128977298736572,
      "logits/rejected": -2.8528528213500977,
      "logps/chosen": -206.65164184570312,
      "logps/rejected": -148.60690307617188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.433799743652344,
      "rewards/margins": 8.640361785888672,
      "rewards/rejected": -4.20656156539917,
      "step": 1750
    },
    {
      "epoch": 0.7004,
      "grad_norm": 0.11095655709505081,
      "learning_rate": 7.666666666666667e-07,
      "logits/chosen": -1.5390434265136719,
      "logits/rejected": -3.2500855922698975,
      "logps/chosen": -65.97669219970703,
      "logps/rejected": -144.3024444580078,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2320151329040527,
      "rewards/margins": 7.603386878967285,
      "rewards/rejected": -4.371371746063232,
      "step": 1751
    },
    {
      "epoch": 0.7008,
      "grad_norm": 0.8861795663833618,
      "learning_rate": 7.665333333333333e-07,
      "logits/chosen": -2.647365093231201,
      "logits/rejected": -2.7752914428710938,
      "logps/chosen": -138.55941772460938,
      "logps/rejected": -161.74801635742188,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4825761318206787,
      "rewards/margins": 7.019496440887451,
      "rewards/rejected": -4.536920547485352,
      "step": 1752
    },
    {
      "epoch": 0.7012,
      "grad_norm": 0.017273476347327232,
      "learning_rate": 7.664e-07,
      "logits/chosen": -1.9638795852661133,
      "logits/rejected": -3.4854135513305664,
      "logps/chosen": -96.88797760009766,
      "logps/rejected": -196.4097900390625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.487628221511841,
      "rewards/margins": 8.850221633911133,
      "rewards/rejected": -6.362593173980713,
      "step": 1753
    },
    {
      "epoch": 0.7016,
      "grad_norm": 0.3131779730319977,
      "learning_rate": 7.662666666666666e-07,
      "logits/chosen": -2.101505994796753,
      "logits/rejected": -3.0463290214538574,
      "logps/chosen": -67.36639404296875,
      "logps/rejected": -148.24209594726562,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1573383808135986,
      "rewards/margins": 6.398609161376953,
      "rewards/rejected": -4.241271018981934,
      "step": 1754
    },
    {
      "epoch": 0.702,
      "grad_norm": 1.9039212465286255,
      "learning_rate": 7.661333333333333e-07,
      "logits/chosen": -2.1465001106262207,
      "logits/rejected": -3.0944530963897705,
      "logps/chosen": -106.08968353271484,
      "logps/rejected": -149.3438720703125,
      "loss": 0.0214,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.986620306968689,
      "rewards/margins": 6.741198539733887,
      "rewards/rejected": -5.754578113555908,
      "step": 1755
    },
    {
      "epoch": 0.7024,
      "grad_norm": 0.14873582124710083,
      "learning_rate": 7.66e-07,
      "logits/chosen": -2.3077609539031982,
      "logits/rejected": -2.9040732383728027,
      "logps/chosen": -123.37158203125,
      "logps/rejected": -163.3900146484375,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.397599220275879,
      "rewards/margins": 7.886192321777344,
      "rewards/rejected": -5.488593101501465,
      "step": 1756
    },
    {
      "epoch": 0.7028,
      "grad_norm": 0.20659089088439941,
      "learning_rate": 7.658666666666666e-07,
      "logits/chosen": -1.9556230306625366,
      "logits/rejected": -2.7885990142822266,
      "logps/chosen": -82.21620178222656,
      "logps/rejected": -141.1275634765625,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2507660388946533,
      "rewards/margins": 7.20674991607666,
      "rewards/rejected": -4.955984115600586,
      "step": 1757
    },
    {
      "epoch": 0.7032,
      "grad_norm": 0.7193794846534729,
      "learning_rate": 7.657333333333333e-07,
      "logits/chosen": -2.3094377517700195,
      "logits/rejected": -3.4178466796875,
      "logps/chosen": -154.61802673339844,
      "logps/rejected": -186.65725708007812,
      "loss": 0.0084,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9170093536376953,
      "rewards/margins": 4.772886276245117,
      "rewards/rejected": -3.855876922607422,
      "step": 1758
    },
    {
      "epoch": 0.7036,
      "grad_norm": 1.444579839706421,
      "learning_rate": 7.655999999999999e-07,
      "logits/chosen": -2.168032646179199,
      "logits/rejected": -3.4501793384552,
      "logps/chosen": -60.41530990600586,
      "logps/rejected": -131.30755615234375,
      "loss": 0.0086,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1447510719299316,
      "rewards/margins": 6.9975905418396,
      "rewards/rejected": -4.852839469909668,
      "step": 1759
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.32620924711227417,
      "learning_rate": 7.654666666666666e-07,
      "logits/chosen": -2.1085872650146484,
      "logits/rejected": -2.2679688930511475,
      "logps/chosen": -81.02749633789062,
      "logps/rejected": -115.15674591064453,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3064632415771484,
      "rewards/margins": 6.394089698791504,
      "rewards/rejected": -4.087625980377197,
      "step": 1760
    },
    {
      "epoch": 0.7044,
      "grad_norm": 0.053411439061164856,
      "learning_rate": 7.653333333333333e-07,
      "logits/chosen": -2.4602770805358887,
      "logits/rejected": -3.0039639472961426,
      "logps/chosen": -113.33351135253906,
      "logps/rejected": -170.08554077148438,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.70326042175293,
      "rewards/margins": 8.761785507202148,
      "rewards/rejected": -4.058525085449219,
      "step": 1761
    },
    {
      "epoch": 0.7048,
      "grad_norm": 7.313350677490234,
      "learning_rate": 7.652e-07,
      "logits/chosen": -2.25657320022583,
      "logits/rejected": -3.0500073432922363,
      "logps/chosen": -115.98544311523438,
      "logps/rejected": -143.78118896484375,
      "loss": 0.0487,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12425994873046875,
      "rewards/margins": 5.976048469543457,
      "rewards/rejected": -5.851788520812988,
      "step": 1762
    },
    {
      "epoch": 0.7052,
      "grad_norm": 0.2503880560398102,
      "learning_rate": 7.650666666666667e-07,
      "logits/chosen": -2.4017982482910156,
      "logits/rejected": -2.7863736152648926,
      "logps/chosen": -162.56735229492188,
      "logps/rejected": -122.7481460571289,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5085368156433105,
      "rewards/margins": 6.3742804527282715,
      "rewards/rejected": -3.8657431602478027,
      "step": 1763
    },
    {
      "epoch": 0.7056,
      "grad_norm": 0.04714333638548851,
      "learning_rate": 7.649333333333333e-07,
      "logits/chosen": -2.4358339309692383,
      "logits/rejected": -2.9269275665283203,
      "logps/chosen": -95.13327026367188,
      "logps/rejected": -158.10678100585938,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.414236068725586,
      "rewards/margins": 9.868181228637695,
      "rewards/rejected": -5.453945636749268,
      "step": 1764
    },
    {
      "epoch": 0.706,
      "grad_norm": 0.6404719948768616,
      "learning_rate": 7.648e-07,
      "logits/chosen": -2.0960707664489746,
      "logits/rejected": -2.6984894275665283,
      "logps/chosen": -113.7760009765625,
      "logps/rejected": -138.926025390625,
      "loss": 0.0062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5360569953918457,
      "rewards/margins": 6.640542030334473,
      "rewards/rejected": -4.104484558105469,
      "step": 1765
    },
    {
      "epoch": 0.7064,
      "grad_norm": 0.7201524972915649,
      "learning_rate": 7.646666666666667e-07,
      "logits/chosen": -2.344172477722168,
      "logits/rejected": -3.458568572998047,
      "logps/chosen": -127.3160400390625,
      "logps/rejected": -154.57040405273438,
      "loss": 0.0052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0133308172225952,
      "rewards/margins": 6.360858917236328,
      "rewards/rejected": -5.347527980804443,
      "step": 1766
    },
    {
      "epoch": 0.7068,
      "grad_norm": 0.028901755809783936,
      "learning_rate": 7.645333333333332e-07,
      "logits/chosen": -2.1593754291534424,
      "logits/rejected": -3.5634422302246094,
      "logps/chosen": -145.51522827148438,
      "logps/rejected": -167.02938842773438,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.690624237060547,
      "rewards/margins": 8.77660083770752,
      "rewards/rejected": -6.085976600646973,
      "step": 1767
    },
    {
      "epoch": 0.7072,
      "grad_norm": 0.3699217140674591,
      "learning_rate": 7.643999999999999e-07,
      "logits/chosen": -1.5726990699768066,
      "logits/rejected": -3.2935009002685547,
      "logps/chosen": -105.30226135253906,
      "logps/rejected": -164.64776611328125,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9816563129425049,
      "rewards/margins": 6.584169387817383,
      "rewards/rejected": -4.602513313293457,
      "step": 1768
    },
    {
      "epoch": 0.7076,
      "grad_norm": 0.10831227898597717,
      "learning_rate": 7.642666666666666e-07,
      "logits/chosen": -1.9265635013580322,
      "logits/rejected": -2.714550018310547,
      "logps/chosen": -202.6377716064453,
      "logps/rejected": -183.4951171875,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.080350637435913,
      "rewards/margins": 7.070729732513428,
      "rewards/rejected": -4.990379333496094,
      "step": 1769
    },
    {
      "epoch": 0.708,
      "grad_norm": 0.0879887267947197,
      "learning_rate": 7.641333333333333e-07,
      "logits/chosen": -2.210602045059204,
      "logits/rejected": -3.585496187210083,
      "logps/chosen": -113.72919464111328,
      "logps/rejected": -152.04129028320312,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5807759761810303,
      "rewards/margins": 8.404088973999023,
      "rewards/rejected": -5.823312759399414,
      "step": 1770
    },
    {
      "epoch": 0.7084,
      "grad_norm": 1.0870018005371094,
      "learning_rate": 7.64e-07,
      "logits/chosen": -1.992945909500122,
      "logits/rejected": -3.0831730365753174,
      "logps/chosen": -98.52281951904297,
      "logps/rejected": -125.78694152832031,
      "loss": 0.0133,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.193455219268799,
      "rewards/margins": 6.767597198486328,
      "rewards/rejected": -4.574141979217529,
      "step": 1771
    },
    {
      "epoch": 0.7088,
      "grad_norm": 0.017910700291395187,
      "learning_rate": 7.638666666666667e-07,
      "logits/chosen": -2.3778092861175537,
      "logits/rejected": -2.6483633518218994,
      "logps/chosen": -112.92557525634766,
      "logps/rejected": -147.47096252441406,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4578776359558105,
      "rewards/margins": 8.638334274291992,
      "rewards/rejected": -5.180456161499023,
      "step": 1772
    },
    {
      "epoch": 0.7092,
      "grad_norm": 0.01690504513680935,
      "learning_rate": 7.637333333333333e-07,
      "logits/chosen": -2.444291114807129,
      "logits/rejected": -3.4004650115966797,
      "logps/chosen": -131.47926330566406,
      "logps/rejected": -225.67747497558594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6318683624267578,
      "rewards/margins": 8.891180992126465,
      "rewards/rejected": -7.259312629699707,
      "step": 1773
    },
    {
      "epoch": 0.7096,
      "grad_norm": 0.03528397157788277,
      "learning_rate": 7.635999999999999e-07,
      "logits/chosen": -1.963165283203125,
      "logits/rejected": -3.5939016342163086,
      "logps/chosen": -84.5936279296875,
      "logps/rejected": -184.24392700195312,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.43658185005188,
      "rewards/margins": 9.016559600830078,
      "rewards/rejected": -6.579977512359619,
      "step": 1774
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.5709987878799438,
      "learning_rate": 7.634666666666666e-07,
      "logits/chosen": -2.3700170516967773,
      "logits/rejected": -2.7393386363983154,
      "logps/chosen": -178.35498046875,
      "logps/rejected": -204.39840698242188,
      "loss": 0.0169,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8817664980888367,
      "rewards/margins": 4.251344203948975,
      "rewards/rejected": -5.133111000061035,
      "step": 1775
    },
    {
      "epoch": 0.7104,
      "grad_norm": 0.6764405369758606,
      "learning_rate": 7.633333333333333e-07,
      "logits/chosen": -2.799483299255371,
      "logits/rejected": -3.2254109382629395,
      "logps/chosen": -113.61799621582031,
      "logps/rejected": -134.3315887451172,
      "loss": 0.0064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.386077404022217,
      "rewards/margins": 5.815038681030273,
      "rewards/rejected": -2.4289612770080566,
      "step": 1776
    },
    {
      "epoch": 0.7108,
      "grad_norm": 0.07982783019542694,
      "learning_rate": 7.632e-07,
      "logits/chosen": -2.1412594318389893,
      "logits/rejected": -3.293732166290283,
      "logps/chosen": -118.48463439941406,
      "logps/rejected": -144.97251892089844,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0880637168884277,
      "rewards/margins": 7.430383205413818,
      "rewards/rejected": -5.342319488525391,
      "step": 1777
    },
    {
      "epoch": 0.7112,
      "grad_norm": 0.11185603588819504,
      "learning_rate": 7.630666666666666e-07,
      "logits/chosen": -2.0250556468963623,
      "logits/rejected": -3.303934097290039,
      "logps/chosen": -125.16154479980469,
      "logps/rejected": -180.2789306640625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.979400634765625,
      "rewards/margins": 8.955669403076172,
      "rewards/rejected": -6.976268768310547,
      "step": 1778
    },
    {
      "epoch": 0.7116,
      "grad_norm": 0.0042245169170200825,
      "learning_rate": 7.629333333333333e-07,
      "logits/chosen": -2.1272637844085693,
      "logits/rejected": -3.3044321537017822,
      "logps/chosen": -92.84030151367188,
      "logps/rejected": -156.13467407226562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4621124267578125,
      "rewards/margins": 11.006641387939453,
      "rewards/rejected": -7.544528961181641,
      "step": 1779
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.11695357412099838,
      "learning_rate": 7.628e-07,
      "logits/chosen": -2.4187963008880615,
      "logits/rejected": -2.7849907875061035,
      "logps/chosen": -100.52984619140625,
      "logps/rejected": -136.42996215820312,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.918367862701416,
      "rewards/margins": 6.525782585144043,
      "rewards/rejected": -4.607415199279785,
      "step": 1780
    },
    {
      "epoch": 0.7124,
      "grad_norm": 0.007252165116369724,
      "learning_rate": 7.626666666666667e-07,
      "logits/chosen": -2.2368991374969482,
      "logits/rejected": -3.707357883453369,
      "logps/chosen": -180.8966064453125,
      "logps/rejected": -207.9166259765625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.642279863357544,
      "rewards/margins": 9.615543365478516,
      "rewards/rejected": -5.973263740539551,
      "step": 1781
    },
    {
      "epoch": 0.7128,
      "grad_norm": 0.18541745841503143,
      "learning_rate": 7.625333333333332e-07,
      "logits/chosen": -1.761113166809082,
      "logits/rejected": -3.214381694793701,
      "logps/chosen": -87.85140991210938,
      "logps/rejected": -122.86083984375,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6160426139831543,
      "rewards/margins": 6.7205095291137695,
      "rewards/rejected": -3.104466676712036,
      "step": 1782
    },
    {
      "epoch": 0.7132,
      "grad_norm": 0.08879028260707855,
      "learning_rate": 7.623999999999999e-07,
      "logits/chosen": -1.7378219366073608,
      "logits/rejected": -3.0122389793395996,
      "logps/chosen": -103.36625671386719,
      "logps/rejected": -141.2521514892578,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.32574462890625,
      "rewards/margins": 7.3708696365356445,
      "rewards/rejected": -5.0451250076293945,
      "step": 1783
    },
    {
      "epoch": 0.7136,
      "grad_norm": 8.900458335876465,
      "learning_rate": 7.622666666666666e-07,
      "logits/chosen": -2.166823387145996,
      "logits/rejected": -3.2315611839294434,
      "logps/chosen": -95.64425659179688,
      "logps/rejected": -189.6907958984375,
      "loss": 0.0476,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3623641729354858,
      "rewards/margins": 6.008179187774658,
      "rewards/rejected": -4.645815372467041,
      "step": 1784
    },
    {
      "epoch": 0.714,
      "grad_norm": 0.04398276284337044,
      "learning_rate": 7.621333333333333e-07,
      "logits/chosen": -2.4611096382141113,
      "logits/rejected": -2.585031032562256,
      "logps/chosen": -170.53857421875,
      "logps/rejected": -124.00254821777344,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.094036102294922,
      "rewards/margins": 7.856054306030273,
      "rewards/rejected": -4.762018203735352,
      "step": 1785
    },
    {
      "epoch": 0.7144,
      "grad_norm": 0.05600292235612869,
      "learning_rate": 7.62e-07,
      "logits/chosen": -1.7454601526260376,
      "logits/rejected": -2.7964398860931396,
      "logps/chosen": -82.49546813964844,
      "logps/rejected": -119.74626159667969,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9823238849639893,
      "rewards/margins": 7.335912227630615,
      "rewards/rejected": -4.353588581085205,
      "step": 1786
    },
    {
      "epoch": 0.7148,
      "grad_norm": 6.9156951904296875,
      "learning_rate": 7.618666666666667e-07,
      "logits/chosen": -2.9900918006896973,
      "logits/rejected": -3.6380209922790527,
      "logps/chosen": -240.85806274414062,
      "logps/rejected": -167.96624755859375,
      "loss": 0.0321,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5632407665252686,
      "rewards/margins": 6.5564284324646,
      "rewards/rejected": -4.99318790435791,
      "step": 1787
    },
    {
      "epoch": 0.7152,
      "grad_norm": 1.8514349460601807,
      "learning_rate": 7.617333333333334e-07,
      "logits/chosen": -2.2260189056396484,
      "logits/rejected": -3.007110118865967,
      "logps/chosen": -102.25820922851562,
      "logps/rejected": -121.55062103271484,
      "loss": 0.0256,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8501439094543457,
      "rewards/margins": 5.250157356262207,
      "rewards/rejected": -3.4000139236450195,
      "step": 1788
    },
    {
      "epoch": 0.7156,
      "grad_norm": 0.15423829853534698,
      "learning_rate": 7.616e-07,
      "logits/chosen": -2.2599754333496094,
      "logits/rejected": -3.03961443901062,
      "logps/chosen": -139.74209594726562,
      "logps/rejected": -143.8114013671875,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0341174602508545,
      "rewards/margins": 7.026308059692383,
      "rewards/rejected": -3.9921908378601074,
      "step": 1789
    },
    {
      "epoch": 0.716,
      "grad_norm": 0.06531693786382675,
      "learning_rate": 7.614666666666666e-07,
      "logits/chosen": -2.7099952697753906,
      "logits/rejected": -2.9577879905700684,
      "logps/chosen": -152.9845733642578,
      "logps/rejected": -186.8420867919922,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9235260486602783,
      "rewards/margins": 8.495759010314941,
      "rewards/rejected": -5.572233200073242,
      "step": 1790
    },
    {
      "epoch": 0.7164,
      "grad_norm": 0.1835479587316513,
      "learning_rate": 7.613333333333333e-07,
      "logits/chosen": -2.4492850303649902,
      "logits/rejected": -3.534839630126953,
      "logps/chosen": -151.21258544921875,
      "logps/rejected": -177.39503479003906,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10304147005081177,
      "rewards/margins": 6.325226783752441,
      "rewards/rejected": -6.222185134887695,
      "step": 1791
    },
    {
      "epoch": 0.7168,
      "grad_norm": 0.11047238111495972,
      "learning_rate": 7.611999999999999e-07,
      "logits/chosen": -1.908341884613037,
      "logits/rejected": -3.1541333198547363,
      "logps/chosen": -125.76158142089844,
      "logps/rejected": -166.54541015625,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8937934637069702,
      "rewards/margins": 6.73982048034668,
      "rewards/rejected": -4.846027374267578,
      "step": 1792
    },
    {
      "epoch": 0.7172,
      "grad_norm": 0.003846030216664076,
      "learning_rate": 7.610666666666666e-07,
      "logits/chosen": -2.1541547775268555,
      "logits/rejected": -2.7844038009643555,
      "logps/chosen": -112.17320251464844,
      "logps/rejected": -166.55892944335938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.0680766105651855,
      "rewards/margins": 10.180370330810547,
      "rewards/rejected": -6.1122941970825195,
      "step": 1793
    },
    {
      "epoch": 0.7176,
      "grad_norm": 0.4899400770664215,
      "learning_rate": 7.609333333333333e-07,
      "logits/chosen": -2.1451668739318848,
      "logits/rejected": -2.994389533996582,
      "logps/chosen": -162.84054565429688,
      "logps/rejected": -135.5325469970703,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.674877166748047,
      "rewards/margins": 5.265164375305176,
      "rewards/rejected": -2.590287446975708,
      "step": 1794
    },
    {
      "epoch": 0.718,
      "grad_norm": 0.06883785128593445,
      "learning_rate": 7.608e-07,
      "logits/chosen": -1.847445011138916,
      "logits/rejected": -2.9210729598999023,
      "logps/chosen": -120.96469116210938,
      "logps/rejected": -149.98585510253906,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.713442802429199,
      "rewards/margins": 8.72630786895752,
      "rewards/rejected": -6.01286506652832,
      "step": 1795
    },
    {
      "epoch": 0.7184,
      "grad_norm": 0.010360724292695522,
      "learning_rate": 7.606666666666667e-07,
      "logits/chosen": -2.6159796714782715,
      "logits/rejected": -3.2389016151428223,
      "logps/chosen": -76.37246704101562,
      "logps/rejected": -134.88027954101562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.817972183227539,
      "rewards/margins": 9.119083404541016,
      "rewards/rejected": -4.301111698150635,
      "step": 1796
    },
    {
      "epoch": 0.7188,
      "grad_norm": 0.23184433579444885,
      "learning_rate": 7.605333333333333e-07,
      "logits/chosen": -2.1079282760620117,
      "logits/rejected": -2.9255928993225098,
      "logps/chosen": -100.03424072265625,
      "logps/rejected": -139.06759643554688,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2187641859054565,
      "rewards/margins": 5.75742244720459,
      "rewards/rejected": -4.538658142089844,
      "step": 1797
    },
    {
      "epoch": 0.7192,
      "grad_norm": 19.018497467041016,
      "learning_rate": 7.604e-07,
      "logits/chosen": -2.335641860961914,
      "logits/rejected": -2.7073798179626465,
      "logps/chosen": -154.55393981933594,
      "logps/rejected": -218.32415771484375,
      "loss": 0.1756,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27382469177246094,
      "rewards/margins": 4.454596042633057,
      "rewards/rejected": -4.180771350860596,
      "step": 1798
    },
    {
      "epoch": 0.7196,
      "grad_norm": 0.021080009639263153,
      "learning_rate": 7.602666666666666e-07,
      "logits/chosen": -2.485518455505371,
      "logits/rejected": -3.4883430004119873,
      "logps/chosen": -108.15179443359375,
      "logps/rejected": -148.10594177246094,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.482283115386963,
      "rewards/margins": 8.585441589355469,
      "rewards/rejected": -5.103158950805664,
      "step": 1799
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6025546193122864,
      "learning_rate": 7.601333333333333e-07,
      "logits/chosen": -2.2379398345947266,
      "logits/rejected": -3.609185218811035,
      "logps/chosen": -105.8026123046875,
      "logps/rejected": -165.2725830078125,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.267587184906006,
      "rewards/margins": 6.938727378845215,
      "rewards/rejected": -4.671139717102051,
      "step": 1800
    },
    {
      "epoch": 0.7204,
      "grad_norm": 0.03350432962179184,
      "learning_rate": 7.599999999999999e-07,
      "logits/chosen": -2.4702041149139404,
      "logits/rejected": -2.9982235431671143,
      "logps/chosen": -109.21942901611328,
      "logps/rejected": -153.47802734375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.579329013824463,
      "rewards/margins": 8.650690078735352,
      "rewards/rejected": -5.071361541748047,
      "step": 1801
    },
    {
      "epoch": 0.7208,
      "grad_norm": 0.10843107104301453,
      "learning_rate": 7.598666666666666e-07,
      "logits/chosen": -2.49955415725708,
      "logits/rejected": -3.412824869155884,
      "logps/chosen": -167.04574584960938,
      "logps/rejected": -149.45767211914062,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.127307891845703,
      "rewards/margins": 6.884220123291016,
      "rewards/rejected": -4.7569122314453125,
      "step": 1802
    },
    {
      "epoch": 0.7212,
      "grad_norm": 0.09143281728029251,
      "learning_rate": 7.597333333333333e-07,
      "logits/chosen": -2.426072597503662,
      "logits/rejected": -3.1270737648010254,
      "logps/chosen": -133.4606475830078,
      "logps/rejected": -148.2056884765625,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5589287281036377,
      "rewards/margins": 8.163227081298828,
      "rewards/rejected": -5.6042985916137695,
      "step": 1803
    },
    {
      "epoch": 0.7216,
      "grad_norm": 0.07335170358419418,
      "learning_rate": 7.596e-07,
      "logits/chosen": -2.0900464057922363,
      "logits/rejected": -2.9631128311157227,
      "logps/chosen": -110.37289428710938,
      "logps/rejected": -154.660888671875,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.482657432556152,
      "rewards/margins": 8.820028305053711,
      "rewards/rejected": -4.337370872497559,
      "step": 1804
    },
    {
      "epoch": 0.722,
      "grad_norm": 0.12452983111143112,
      "learning_rate": 7.594666666666666e-07,
      "logits/chosen": -2.7933859825134277,
      "logits/rejected": -3.28200101852417,
      "logps/chosen": -201.51492309570312,
      "logps/rejected": -186.47914123535156,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5761871337890625,
      "rewards/margins": 7.166316986083984,
      "rewards/rejected": -5.590129852294922,
      "step": 1805
    },
    {
      "epoch": 0.7224,
      "grad_norm": 0.21904876828193665,
      "learning_rate": 7.593333333333333e-07,
      "logits/chosen": -2.2928354740142822,
      "logits/rejected": -2.879028081893921,
      "logps/chosen": -74.93534851074219,
      "logps/rejected": -126.06542205810547,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.539618730545044,
      "rewards/margins": 7.529446125030518,
      "rewards/rejected": -3.9898273944854736,
      "step": 1806
    },
    {
      "epoch": 0.7228,
      "grad_norm": 0.025677623227238655,
      "learning_rate": 7.592e-07,
      "logits/chosen": -2.519160270690918,
      "logits/rejected": -2.930992603302002,
      "logps/chosen": -145.36962890625,
      "logps/rejected": -160.36517333984375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.943326950073242,
      "rewards/margins": 8.341806411743164,
      "rewards/rejected": -5.398478984832764,
      "step": 1807
    },
    {
      "epoch": 0.7232,
      "grad_norm": 0.04929323494434357,
      "learning_rate": 7.590666666666667e-07,
      "logits/chosen": -2.141268253326416,
      "logits/rejected": -3.1057052612304688,
      "logps/chosen": -83.79496765136719,
      "logps/rejected": -134.41665649414062,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6224069595336914,
      "rewards/margins": 8.115055084228516,
      "rewards/rejected": -4.492648124694824,
      "step": 1808
    },
    {
      "epoch": 0.7236,
      "grad_norm": 0.0015495922416448593,
      "learning_rate": 7.589333333333334e-07,
      "logits/chosen": -2.0436577796936035,
      "logits/rejected": -3.451204299926758,
      "logps/chosen": -106.56509399414062,
      "logps/rejected": -176.18795776367188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.340929985046387,
      "rewards/margins": 11.190508842468262,
      "rewards/rejected": -6.849577903747559,
      "step": 1809
    },
    {
      "epoch": 0.724,
      "grad_norm": 0.31527426838874817,
      "learning_rate": 7.588e-07,
      "logits/chosen": -1.730268120765686,
      "logits/rejected": -3.2332763671875,
      "logps/chosen": -126.32627868652344,
      "logps/rejected": -153.30526733398438,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7548531293869019,
      "rewards/margins": 6.848780155181885,
      "rewards/rejected": -5.093927383422852,
      "step": 1810
    },
    {
      "epoch": 0.7244,
      "grad_norm": 0.5698728561401367,
      "learning_rate": 7.586666666666666e-07,
      "logits/chosen": -1.7045719623565674,
      "logits/rejected": -3.0678606033325195,
      "logps/chosen": -126.70437622070312,
      "logps/rejected": -152.9966278076172,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.881865382194519,
      "rewards/margins": 6.589306831359863,
      "rewards/rejected": -4.707441329956055,
      "step": 1811
    },
    {
      "epoch": 0.7248,
      "grad_norm": 0.6357083320617676,
      "learning_rate": 7.585333333333332e-07,
      "logits/chosen": -2.3624558448791504,
      "logits/rejected": -2.512634515762329,
      "logps/chosen": -140.06175231933594,
      "logps/rejected": -223.51109313964844,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.537633180618286,
      "rewards/margins": 6.591004371643066,
      "rewards/rejected": -3.0533711910247803,
      "step": 1812
    },
    {
      "epoch": 0.7252,
      "grad_norm": 0.6576436161994934,
      "learning_rate": 7.583999999999999e-07,
      "logits/chosen": -2.549435615539551,
      "logits/rejected": -2.8838062286376953,
      "logps/chosen": -145.71627807617188,
      "logps/rejected": -179.6444854736328,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4000396728515625,
      "rewards/margins": 7.514806747436523,
      "rewards/rejected": -4.114767551422119,
      "step": 1813
    },
    {
      "epoch": 0.7256,
      "grad_norm": 0.051248520612716675,
      "learning_rate": 7.582666666666666e-07,
      "logits/chosen": -2.3224329948425293,
      "logits/rejected": -3.289151668548584,
      "logps/chosen": -119.17108154296875,
      "logps/rejected": -138.4046630859375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4980556964874268,
      "rewards/margins": 7.952149391174316,
      "rewards/rejected": -4.454093933105469,
      "step": 1814
    },
    {
      "epoch": 0.726,
      "grad_norm": 0.06549655646085739,
      "learning_rate": 7.581333333333333e-07,
      "logits/chosen": -2.060800790786743,
      "logits/rejected": -2.7860164642333984,
      "logps/chosen": -146.95974731445312,
      "logps/rejected": -162.37942504882812,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1079964637756348,
      "rewards/margins": 7.751723289489746,
      "rewards/rejected": -4.6437273025512695,
      "step": 1815
    },
    {
      "epoch": 0.7264,
      "grad_norm": 0.027804743498563766,
      "learning_rate": 7.58e-07,
      "logits/chosen": -2.5316667556762695,
      "logits/rejected": -3.3218164443969727,
      "logps/chosen": -139.7788543701172,
      "logps/rejected": -226.8495330810547,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.193337917327881,
      "rewards/margins": 9.928789138793945,
      "rewards/rejected": -6.735450744628906,
      "step": 1816
    },
    {
      "epoch": 0.7268,
      "grad_norm": 0.19545920193195343,
      "learning_rate": 7.578666666666667e-07,
      "logits/chosen": -1.9333388805389404,
      "logits/rejected": -3.226912260055542,
      "logps/chosen": -78.8597640991211,
      "logps/rejected": -134.89498901367188,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.58937931060791,
      "rewards/margins": 6.362163543701172,
      "rewards/rejected": -3.772784471511841,
      "step": 1817
    },
    {
      "epoch": 0.7272,
      "grad_norm": 0.17912054061889648,
      "learning_rate": 7.577333333333334e-07,
      "logits/chosen": -1.6073224544525146,
      "logits/rejected": -2.7890710830688477,
      "logps/chosen": -84.90835571289062,
      "logps/rejected": -145.05929565429688,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6058716773986816,
      "rewards/margins": 6.733458995819092,
      "rewards/rejected": -4.12758731842041,
      "step": 1818
    },
    {
      "epoch": 0.7276,
      "grad_norm": 0.004660635255277157,
      "learning_rate": 7.576000000000001e-07,
      "logits/chosen": -2.5634093284606934,
      "logits/rejected": -3.1576828956604004,
      "logps/chosen": -117.38138580322266,
      "logps/rejected": -180.65261840820312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.29145622253418,
      "rewards/margins": 10.337966918945312,
      "rewards/rejected": -6.046510696411133,
      "step": 1819
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.05719158798456192,
      "learning_rate": 7.574666666666665e-07,
      "logits/chosen": -2.31990385055542,
      "logits/rejected": -3.3279621601104736,
      "logps/chosen": -144.51914978027344,
      "logps/rejected": -128.56414794921875,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.102621078491211,
      "rewards/margins": 7.160551071166992,
      "rewards/rejected": -4.057929992675781,
      "step": 1820
    },
    {
      "epoch": 0.7284,
      "grad_norm": 0.056500427424907684,
      "learning_rate": 7.573333333333332e-07,
      "logits/chosen": -2.2976553440093994,
      "logits/rejected": -2.949876308441162,
      "logps/chosen": -112.41742706298828,
      "logps/rejected": -127.97236633300781,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5537562370300293,
      "rewards/margins": 7.615106105804443,
      "rewards/rejected": -5.061349868774414,
      "step": 1821
    },
    {
      "epoch": 0.7288,
      "grad_norm": 0.17322969436645508,
      "learning_rate": 7.571999999999999e-07,
      "logits/chosen": -2.377868175506592,
      "logits/rejected": -3.3953728675842285,
      "logps/chosen": -170.60208129882812,
      "logps/rejected": -185.10072326660156,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.30674436688423157,
      "rewards/margins": 6.383975982666016,
      "rewards/rejected": -6.690720558166504,
      "step": 1822
    },
    {
      "epoch": 0.7292,
      "grad_norm": 0.640737771987915,
      "learning_rate": 7.570666666666666e-07,
      "logits/chosen": -1.9246044158935547,
      "logits/rejected": -3.3050990104675293,
      "logps/chosen": -176.4619903564453,
      "logps/rejected": -147.94757080078125,
      "loss": 0.0055,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7332401275634766,
      "rewards/margins": 5.947168827056885,
      "rewards/rejected": -5.213928699493408,
      "step": 1823
    },
    {
      "epoch": 0.7296,
      "grad_norm": 0.584365963935852,
      "learning_rate": 7.569333333333333e-07,
      "logits/chosen": -2.498661994934082,
      "logits/rejected": -3.4867422580718994,
      "logps/chosen": -107.54020690917969,
      "logps/rejected": -165.27549743652344,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6575367450714111,
      "rewards/margins": 7.029404640197754,
      "rewards/rejected": -5.371868133544922,
      "step": 1824
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.08408941328525543,
      "learning_rate": 7.568e-07,
      "logits/chosen": -2.2974438667297363,
      "logits/rejected": -3.2932162284851074,
      "logps/chosen": -103.03132629394531,
      "logps/rejected": -143.89207458496094,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7355237007141113,
      "rewards/margins": 8.084331512451172,
      "rewards/rejected": -5.348807334899902,
      "step": 1825
    },
    {
      "epoch": 0.7304,
      "grad_norm": 0.9783997535705566,
      "learning_rate": 7.566666666666667e-07,
      "logits/chosen": -2.7068047523498535,
      "logits/rejected": -3.4406275749206543,
      "logps/chosen": -93.54161071777344,
      "logps/rejected": -157.95120239257812,
      "loss": 0.0064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08859863877296448,
      "rewards/margins": 5.463591575622559,
      "rewards/rejected": -5.374992847442627,
      "step": 1826
    },
    {
      "epoch": 0.7308,
      "grad_norm": 0.08532893657684326,
      "learning_rate": 7.565333333333333e-07,
      "logits/chosen": -2.072294235229492,
      "logits/rejected": -2.4922499656677246,
      "logps/chosen": -113.50877380371094,
      "logps/rejected": -127.31552124023438,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.472510814666748,
      "rewards/margins": 7.135926246643066,
      "rewards/rejected": -3.6634154319763184,
      "step": 1827
    },
    {
      "epoch": 0.7312,
      "grad_norm": 0.974138617515564,
      "learning_rate": 7.564e-07,
      "logits/chosen": -1.9312493801116943,
      "logits/rejected": -2.977849006652832,
      "logps/chosen": -108.37362670898438,
      "logps/rejected": -130.09213256835938,
      "loss": 0.0101,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8733363747596741,
      "rewards/margins": 5.62010383605957,
      "rewards/rejected": -4.746767520904541,
      "step": 1828
    },
    {
      "epoch": 0.7316,
      "grad_norm": 0.02042534202337265,
      "learning_rate": 7.562666666666666e-07,
      "logits/chosen": -2.2660422325134277,
      "logits/rejected": -3.3465328216552734,
      "logps/chosen": -80.11656951904297,
      "logps/rejected": -151.94564819335938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7341630458831787,
      "rewards/margins": 9.608826637268066,
      "rewards/rejected": -5.874663829803467,
      "step": 1829
    },
    {
      "epoch": 0.732,
      "grad_norm": 0.07394466549158096,
      "learning_rate": 7.561333333333332e-07,
      "logits/chosen": -2.2727322578430176,
      "logits/rejected": -3.350160598754883,
      "logps/chosen": -83.14866638183594,
      "logps/rejected": -151.8743896484375,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.202301263809204,
      "rewards/margins": 7.463517665863037,
      "rewards/rejected": -6.261216163635254,
      "step": 1830
    },
    {
      "epoch": 0.7324,
      "grad_norm": 0.9526703953742981,
      "learning_rate": 7.559999999999999e-07,
      "logits/chosen": -2.3981876373291016,
      "logits/rejected": -2.9036617279052734,
      "logps/chosen": -137.77365112304688,
      "logps/rejected": -140.07603454589844,
      "loss": 0.0123,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3232818841934204,
      "rewards/margins": 5.54649543762207,
      "rewards/rejected": -5.223213195800781,
      "step": 1831
    },
    {
      "epoch": 0.7328,
      "grad_norm": 0.03976179286837578,
      "learning_rate": 7.558666666666666e-07,
      "logits/chosen": -2.4530506134033203,
      "logits/rejected": -3.367664337158203,
      "logps/chosen": -199.55203247070312,
      "logps/rejected": -189.48086547851562,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.63057804107666,
      "rewards/margins": 8.003952026367188,
      "rewards/rejected": -5.3733744621276855,
      "step": 1832
    },
    {
      "epoch": 0.7332,
      "grad_norm": 1.1482176780700684,
      "learning_rate": 7.557333333333333e-07,
      "logits/chosen": -2.2980105876922607,
      "logits/rejected": -1.8625348806381226,
      "logps/chosen": -105.79852294921875,
      "logps/rejected": -145.90585327148438,
      "loss": 0.0147,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7538173198699951,
      "rewards/margins": 6.198849201202393,
      "rewards/rejected": -4.445031642913818,
      "step": 1833
    },
    {
      "epoch": 0.7336,
      "grad_norm": 0.03482387587428093,
      "learning_rate": 7.556e-07,
      "logits/chosen": -2.289764165878296,
      "logits/rejected": -2.969827651977539,
      "logps/chosen": -109.45658111572266,
      "logps/rejected": -136.92239379882812,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.513240098953247,
      "rewards/margins": 8.010478973388672,
      "rewards/rejected": -4.497239589691162,
      "step": 1834
    },
    {
      "epoch": 0.734,
      "grad_norm": 0.007632522378116846,
      "learning_rate": 7.554666666666666e-07,
      "logits/chosen": -2.302349090576172,
      "logits/rejected": -3.072763681411743,
      "logps/chosen": -115.22149658203125,
      "logps/rejected": -195.95901489257812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.465843677520752,
      "rewards/margins": 10.920580863952637,
      "rewards/rejected": -7.454737186431885,
      "step": 1835
    },
    {
      "epoch": 0.7344,
      "grad_norm": 0.01830531284213066,
      "learning_rate": 7.553333333333333e-07,
      "logits/chosen": -2.2979869842529297,
      "logits/rejected": -2.853226661682129,
      "logps/chosen": -98.753173828125,
      "logps/rejected": -166.4287872314453,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1451010704040527,
      "rewards/margins": 10.260980606079102,
      "rewards/rejected": -7.115879058837891,
      "step": 1836
    },
    {
      "epoch": 0.7348,
      "grad_norm": 0.022102627903223038,
      "learning_rate": 7.552e-07,
      "logits/chosen": -2.3070011138916016,
      "logits/rejected": -3.3172645568847656,
      "logps/chosen": -84.40013885498047,
      "logps/rejected": -152.52565002441406,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0337772369384766,
      "rewards/margins": 8.617498397827148,
      "rewards/rejected": -5.583721160888672,
      "step": 1837
    },
    {
      "epoch": 0.7352,
      "grad_norm": 0.3984682261943817,
      "learning_rate": 7.550666666666667e-07,
      "logits/chosen": -2.73656964302063,
      "logits/rejected": -3.2456178665161133,
      "logps/chosen": -266.05206298828125,
      "logps/rejected": -170.20663452148438,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1348915100097656,
      "rewards/margins": 6.220278263092041,
      "rewards/rejected": -5.085386753082275,
      "step": 1838
    },
    {
      "epoch": 0.7356,
      "grad_norm": 0.06516524404287338,
      "learning_rate": 7.549333333333333e-07,
      "logits/chosen": -2.204418659210205,
      "logits/rejected": -3.006861448287964,
      "logps/chosen": -91.66407775878906,
      "logps/rejected": -146.35336303710938,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.363948106765747,
      "rewards/margins": 8.45945930480957,
      "rewards/rejected": -5.095511436462402,
      "step": 1839
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.09387798607349396,
      "learning_rate": 7.548e-07,
      "logits/chosen": -2.026496410369873,
      "logits/rejected": -3.2701058387756348,
      "logps/chosen": -134.37387084960938,
      "logps/rejected": -166.83486938476562,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6763694286346436,
      "rewards/margins": 8.406543731689453,
      "rewards/rejected": -5.7301740646362305,
      "step": 1840
    },
    {
      "epoch": 0.7364,
      "grad_norm": 0.191945418715477,
      "learning_rate": 7.546666666666666e-07,
      "logits/chosen": -2.3973608016967773,
      "logits/rejected": -3.151843547821045,
      "logps/chosen": -118.220703125,
      "logps/rejected": -133.85682678222656,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7357555627822876,
      "rewards/margins": 6.9350690841674805,
      "rewards/rejected": -5.199313163757324,
      "step": 1841
    },
    {
      "epoch": 0.7368,
      "grad_norm": 0.43695029616355896,
      "learning_rate": 7.545333333333332e-07,
      "logits/chosen": -2.0657947063446045,
      "logits/rejected": -3.606693744659424,
      "logps/chosen": -160.05435180664062,
      "logps/rejected": -154.6946563720703,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3196632862091064,
      "rewards/margins": 6.92411994934082,
      "rewards/rejected": -5.604456901550293,
      "step": 1842
    },
    {
      "epoch": 0.7372,
      "grad_norm": 0.018040399998426437,
      "learning_rate": 7.543999999999999e-07,
      "logits/chosen": -2.260716199874878,
      "logits/rejected": -2.9810681343078613,
      "logps/chosen": -105.058837890625,
      "logps/rejected": -132.14089965820312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.1533989906311035,
      "rewards/margins": 8.511487007141113,
      "rewards/rejected": -4.35808801651001,
      "step": 1843
    },
    {
      "epoch": 0.7376,
      "grad_norm": 0.4097062349319458,
      "learning_rate": 7.542666666666666e-07,
      "logits/chosen": -1.9844496250152588,
      "logits/rejected": -3.1704177856445312,
      "logps/chosen": -65.40974426269531,
      "logps/rejected": -143.25302124023438,
      "loss": 0.0052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1979604959487915,
      "rewards/margins": 5.831459999084473,
      "rewards/rejected": -4.633499622344971,
      "step": 1844
    },
    {
      "epoch": 0.738,
      "grad_norm": 0.23811551928520203,
      "learning_rate": 7.541333333333333e-07,
      "logits/chosen": -1.9356060028076172,
      "logits/rejected": -2.9470889568328857,
      "logps/chosen": -129.83473205566406,
      "logps/rejected": -159.53509521484375,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1913914680480957,
      "rewards/margins": 7.32703971862793,
      "rewards/rejected": -5.135648250579834,
      "step": 1845
    },
    {
      "epoch": 0.7384,
      "grad_norm": 0.008987599983811378,
      "learning_rate": 7.54e-07,
      "logits/chosen": -2.457977056503296,
      "logits/rejected": -2.6352505683898926,
      "logps/chosen": -172.15811157226562,
      "logps/rejected": -176.0017547607422,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5119667053222656,
      "rewards/margins": 9.527467727661133,
      "rewards/rejected": -6.015501022338867,
      "step": 1846
    },
    {
      "epoch": 0.7388,
      "grad_norm": 0.019084010273218155,
      "learning_rate": 7.538666666666667e-07,
      "logits/chosen": -2.340545177459717,
      "logits/rejected": -3.149512529373169,
      "logps/chosen": -141.08132934570312,
      "logps/rejected": -163.478515625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.492602586746216,
      "rewards/margins": 8.987505912780762,
      "rewards/rejected": -5.494903564453125,
      "step": 1847
    },
    {
      "epoch": 0.7392,
      "grad_norm": 0.16539721190929413,
      "learning_rate": 7.537333333333333e-07,
      "logits/chosen": -2.203472137451172,
      "logits/rejected": -2.775421619415283,
      "logps/chosen": -135.9778289794922,
      "logps/rejected": -233.79421997070312,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6880134344100952,
      "rewards/margins": 6.489200592041016,
      "rewards/rejected": -5.801187515258789,
      "step": 1848
    },
    {
      "epoch": 0.7396,
      "grad_norm": 0.05798422917723656,
      "learning_rate": 7.536e-07,
      "logits/chosen": -1.7579079866409302,
      "logits/rejected": -2.960749387741089,
      "logps/chosen": -114.73056030273438,
      "logps/rejected": -135.97647094726562,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8237900733947754,
      "rewards/margins": 7.74915885925293,
      "rewards/rejected": -3.9253687858581543,
      "step": 1849
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.15818260610103607,
      "learning_rate": 7.534666666666666e-07,
      "logits/chosen": -2.3392739295959473,
      "logits/rejected": -3.275266647338867,
      "logps/chosen": -68.41461181640625,
      "logps/rejected": -125.14601135253906,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4005074501037598,
      "rewards/margins": 7.0660200119018555,
      "rewards/rejected": -3.6655125617980957,
      "step": 1850
    },
    {
      "epoch": 0.7404,
      "grad_norm": 0.49931657314300537,
      "learning_rate": 7.533333333333332e-07,
      "logits/chosen": -2.595003604888916,
      "logits/rejected": -3.212453842163086,
      "logps/chosen": -137.7366180419922,
      "logps/rejected": -123.99966430664062,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6591289043426514,
      "rewards/margins": 6.143085479736328,
      "rewards/rejected": -4.483956336975098,
      "step": 1851
    },
    {
      "epoch": 0.7408,
      "grad_norm": 0.04836731031537056,
      "learning_rate": 7.531999999999999e-07,
      "logits/chosen": -2.1901144981384277,
      "logits/rejected": -2.7548468112945557,
      "logps/chosen": -77.68296813964844,
      "logps/rejected": -186.83750915527344,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.792611598968506,
      "rewards/margins": 9.797060012817383,
      "rewards/rejected": -7.004448890686035,
      "step": 1852
    },
    {
      "epoch": 0.7412,
      "grad_norm": 0.3063547909259796,
      "learning_rate": 7.530666666666666e-07,
      "logits/chosen": -2.4496474266052246,
      "logits/rejected": -3.133021354675293,
      "logps/chosen": -83.78041076660156,
      "logps/rejected": -150.52175903320312,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.200515031814575,
      "rewards/margins": 8.142921447753906,
      "rewards/rejected": -5.94240665435791,
      "step": 1853
    },
    {
      "epoch": 0.7416,
      "grad_norm": 0.025231890380382538,
      "learning_rate": 7.529333333333333e-07,
      "logits/chosen": -1.9188700914382935,
      "logits/rejected": -2.9629483222961426,
      "logps/chosen": -113.27119445800781,
      "logps/rejected": -184.40225219726562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7791383266448975,
      "rewards/margins": 8.434585571289062,
      "rewards/rejected": -5.655447483062744,
      "step": 1854
    },
    {
      "epoch": 0.742,
      "grad_norm": 0.2534777820110321,
      "learning_rate": 7.528e-07,
      "logits/chosen": -2.2820427417755127,
      "logits/rejected": -3.0018489360809326,
      "logps/chosen": -135.75393676757812,
      "logps/rejected": -172.40487670898438,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1271206140518188,
      "rewards/margins": 5.874980926513672,
      "rewards/rejected": -4.747859954833984,
      "step": 1855
    },
    {
      "epoch": 0.7424,
      "grad_norm": 0.035204023122787476,
      "learning_rate": 7.526666666666667e-07,
      "logits/chosen": -2.2175657749176025,
      "logits/rejected": -3.958143711090088,
      "logps/chosen": -150.91595458984375,
      "logps/rejected": -154.3173370361328,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8820929527282715,
      "rewards/margins": 8.021233558654785,
      "rewards/rejected": -4.139140605926514,
      "step": 1856
    },
    {
      "epoch": 0.7428,
      "grad_norm": 1.5630277395248413,
      "learning_rate": 7.525333333333334e-07,
      "logits/chosen": -2.602478504180908,
      "logits/rejected": -3.1946306228637695,
      "logps/chosen": -167.078125,
      "logps/rejected": -150.47872924804688,
      "loss": 0.0207,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.861709713935852,
      "rewards/margins": 6.658857822418213,
      "rewards/rejected": -4.79714822769165,
      "step": 1857
    },
    {
      "epoch": 0.7432,
      "grad_norm": 0.06998956203460693,
      "learning_rate": 7.523999999999999e-07,
      "logits/chosen": -2.1926658153533936,
      "logits/rejected": -3.005682945251465,
      "logps/chosen": -106.43359375,
      "logps/rejected": -126.67083740234375,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.946018695831299,
      "rewards/margins": 7.903485298156738,
      "rewards/rejected": -3.9574666023254395,
      "step": 1858
    },
    {
      "epoch": 0.7436,
      "grad_norm": 3.4628517627716064,
      "learning_rate": 7.522666666666666e-07,
      "logits/chosen": -2.510707378387451,
      "logits/rejected": -3.358616352081299,
      "logps/chosen": -179.68003845214844,
      "logps/rejected": -179.46121215820312,
      "loss": 0.0239,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3840019404888153,
      "rewards/margins": 4.103598594665527,
      "rewards/rejected": -4.487600326538086,
      "step": 1859
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.8805884122848511,
      "learning_rate": 7.521333333333333e-07,
      "logits/chosen": -2.683375120162964,
      "logits/rejected": -2.9616966247558594,
      "logps/chosen": -105.99568939208984,
      "logps/rejected": -141.34918212890625,
      "loss": 0.0095,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38222619891166687,
      "rewards/margins": 4.930874824523926,
      "rewards/rejected": -4.548648834228516,
      "step": 1860
    },
    {
      "epoch": 0.7444,
      "grad_norm": 0.12802216410636902,
      "learning_rate": 7.52e-07,
      "logits/chosen": -1.9485645294189453,
      "logits/rejected": -3.5843753814697266,
      "logps/chosen": -175.21495056152344,
      "logps/rejected": -207.13735961914062,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2612216472625732,
      "rewards/margins": 6.961954116821289,
      "rewards/rejected": -5.700732231140137,
      "step": 1861
    },
    {
      "epoch": 0.7448,
      "grad_norm": 113.32215881347656,
      "learning_rate": 7.518666666666666e-07,
      "logits/chosen": -0.9399471282958984,
      "logits/rejected": -2.7052507400512695,
      "logps/chosen": -244.14254760742188,
      "logps/rejected": -127.55695343017578,
      "loss": 0.3919,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.3293067216873169,
      "rewards/margins": 3.7210335731506348,
      "rewards/rejected": -4.050340175628662,
      "step": 1862
    },
    {
      "epoch": 0.7452,
      "grad_norm": 0.07497673481702805,
      "learning_rate": 7.517333333333333e-07,
      "logits/chosen": -1.888498306274414,
      "logits/rejected": -3.6821818351745605,
      "logps/chosen": -134.67417907714844,
      "logps/rejected": -174.8464813232422,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3515114784240723,
      "rewards/margins": 7.505548477172852,
      "rewards/rejected": -5.154036998748779,
      "step": 1863
    },
    {
      "epoch": 0.7456,
      "grad_norm": 0.024332232773303986,
      "learning_rate": 7.516e-07,
      "logits/chosen": -2.346834182739258,
      "logits/rejected": -3.0478646755218506,
      "logps/chosen": -152.1710205078125,
      "logps/rejected": -186.74069213867188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.52130126953125,
      "rewards/margins": 8.374567985534668,
      "rewards/rejected": -4.853266716003418,
      "step": 1864
    },
    {
      "epoch": 0.746,
      "grad_norm": 0.0022916796151548624,
      "learning_rate": 7.514666666666666e-07,
      "logits/chosen": -2.163076877593994,
      "logits/rejected": -3.0464401245117188,
      "logps/chosen": -119.71717071533203,
      "logps/rejected": -172.68374633789062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.515564918518066,
      "rewards/margins": 10.879822731018066,
      "rewards/rejected": -6.3642578125,
      "step": 1865
    },
    {
      "epoch": 0.7464,
      "grad_norm": 0.1332446187734604,
      "learning_rate": 7.513333333333333e-07,
      "logits/chosen": -2.6917519569396973,
      "logits/rejected": -3.380755662918091,
      "logps/chosen": -166.5966339111328,
      "logps/rejected": -158.10665893554688,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2948689460754395,
      "rewards/margins": 7.927395820617676,
      "rewards/rejected": -4.632526874542236,
      "step": 1866
    },
    {
      "epoch": 0.7468,
      "grad_norm": 0.37564870715141296,
      "learning_rate": 7.511999999999999e-07,
      "logits/chosen": -2.2516419887542725,
      "logits/rejected": -2.747039318084717,
      "logps/chosen": -78.07218933105469,
      "logps/rejected": -124.32611083984375,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7401689291000366,
      "rewards/margins": 6.426654815673828,
      "rewards/rejected": -4.686485767364502,
      "step": 1867
    },
    {
      "epoch": 0.7472,
      "grad_norm": 0.49832549691200256,
      "learning_rate": 7.510666666666666e-07,
      "logits/chosen": -2.5996246337890625,
      "logits/rejected": -3.0246291160583496,
      "logps/chosen": -195.57931518554688,
      "logps/rejected": -186.68557739257812,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19524914026260376,
      "rewards/margins": 6.750492095947266,
      "rewards/rejected": -6.555243015289307,
      "step": 1868
    },
    {
      "epoch": 0.7476,
      "grad_norm": 0.1165120080113411,
      "learning_rate": 7.509333333333333e-07,
      "logits/chosen": -2.771463632583618,
      "logits/rejected": -3.391296148300171,
      "logps/chosen": -176.44305419921875,
      "logps/rejected": -134.64553833007812,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8337295055389404,
      "rewards/margins": 6.629153251647949,
      "rewards/rejected": -4.79542350769043,
      "step": 1869
    },
    {
      "epoch": 0.748,
      "grad_norm": 0.2933099865913391,
      "learning_rate": 7.508e-07,
      "logits/chosen": -1.9504790306091309,
      "logits/rejected": -3.1023621559143066,
      "logps/chosen": -89.41503143310547,
      "logps/rejected": -204.0164337158203,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2013275623321533,
      "rewards/margins": 7.574007034301758,
      "rewards/rejected": -6.372679233551025,
      "step": 1870
    },
    {
      "epoch": 0.7484,
      "grad_norm": 1.6249428987503052,
      "learning_rate": 7.506666666666667e-07,
      "logits/chosen": -3.1524758338928223,
      "logits/rejected": -3.642458915710449,
      "logps/chosen": -147.15106201171875,
      "logps/rejected": -238.7769775390625,
      "loss": 0.0182,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.203626275062561,
      "rewards/margins": 7.142204284667969,
      "rewards/rejected": -5.938578128814697,
      "step": 1871
    },
    {
      "epoch": 0.7488,
      "grad_norm": 0.203450009226799,
      "learning_rate": 7.505333333333334e-07,
      "logits/chosen": -2.574277400970459,
      "logits/rejected": -3.110200881958008,
      "logps/chosen": -93.50450134277344,
      "logps/rejected": -137.91348266601562,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0767383575439453,
      "rewards/margins": 6.255891799926758,
      "rewards/rejected": -5.1791534423828125,
      "step": 1872
    },
    {
      "epoch": 0.7492,
      "grad_norm": 0.046583376824855804,
      "learning_rate": 7.503999999999999e-07,
      "logits/chosen": -2.6109766960144043,
      "logits/rejected": -3.363365650177002,
      "logps/chosen": -229.25399780273438,
      "logps/rejected": -180.26902770996094,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.398465156555176,
      "rewards/margins": 8.275619506835938,
      "rewards/rejected": -5.87715482711792,
      "step": 1873
    },
    {
      "epoch": 0.7496,
      "grad_norm": 0.18926411867141724,
      "learning_rate": 7.502666666666666e-07,
      "logits/chosen": -2.068274974822998,
      "logits/rejected": -3.376396894454956,
      "logps/chosen": -126.35747528076172,
      "logps/rejected": -146.5570068359375,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7389194965362549,
      "rewards/margins": 6.253115653991699,
      "rewards/rejected": -4.514195919036865,
      "step": 1874
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.002933397190645337,
      "learning_rate": 7.501333333333333e-07,
      "logits/chosen": -1.9713268280029297,
      "logits/rejected": -3.1430211067199707,
      "logps/chosen": -158.54847717285156,
      "logps/rejected": -177.35459899902344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.887728214263916,
      "rewards/margins": 10.887555122375488,
      "rewards/rejected": -6.9998273849487305,
      "step": 1875
    },
    {
      "epoch": 0.7504,
      "grad_norm": 0.20804156363010406,
      "learning_rate": 7.5e-07,
      "logits/chosen": -2.5253043174743652,
      "logits/rejected": -2.669362783432007,
      "logps/chosen": -181.9683074951172,
      "logps/rejected": -141.51593017578125,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0702760219573975,
      "rewards/margins": 6.58725643157959,
      "rewards/rejected": -4.5169806480407715,
      "step": 1876
    },
    {
      "epoch": 0.7508,
      "grad_norm": 0.23812441527843475,
      "learning_rate": 7.498666666666666e-07,
      "logits/chosen": -2.013650894165039,
      "logits/rejected": -3.179166793823242,
      "logps/chosen": -83.8204574584961,
      "logps/rejected": -177.91387939453125,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0359959602355957,
      "rewards/margins": 8.807598114013672,
      "rewards/rejected": -6.771601676940918,
      "step": 1877
    },
    {
      "epoch": 0.7512,
      "grad_norm": 0.013670642860233784,
      "learning_rate": 7.497333333333333e-07,
      "logits/chosen": -2.616886615753174,
      "logits/rejected": -3.6647226810455322,
      "logps/chosen": -159.49624633789062,
      "logps/rejected": -181.757568359375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.03027081489563,
      "rewards/margins": 9.450799942016602,
      "rewards/rejected": -6.420529365539551,
      "step": 1878
    },
    {
      "epoch": 0.7516,
      "grad_norm": 0.2480558454990387,
      "learning_rate": 7.496e-07,
      "logits/chosen": -2.2872157096862793,
      "logits/rejected": -2.853574752807617,
      "logps/chosen": -120.66242980957031,
      "logps/rejected": -154.3688507080078,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7428274154663086,
      "rewards/margins": 7.412096977233887,
      "rewards/rejected": -5.669269561767578,
      "step": 1879
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.024184247478842735,
      "learning_rate": 7.494666666666666e-07,
      "logits/chosen": -2.3725240230560303,
      "logits/rejected": -3.0781917572021484,
      "logps/chosen": -123.11767578125,
      "logps/rejected": -218.2134552001953,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.803353309631348,
      "rewards/margins": 9.400790214538574,
      "rewards/rejected": -4.597436904907227,
      "step": 1880
    },
    {
      "epoch": 0.7524,
      "grad_norm": 0.10134975612163544,
      "learning_rate": 7.493333333333333e-07,
      "logits/chosen": -2.2423810958862305,
      "logits/rejected": -3.1311638355255127,
      "logps/chosen": -197.7117462158203,
      "logps/rejected": -153.40167236328125,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9480366706848145,
      "rewards/margins": 7.492277145385742,
      "rewards/rejected": -5.5442399978637695,
      "step": 1881
    },
    {
      "epoch": 0.7528,
      "grad_norm": 0.47208836674690247,
      "learning_rate": 7.492e-07,
      "logits/chosen": -1.821549415588379,
      "logits/rejected": -2.832858085632324,
      "logps/chosen": -126.55619812011719,
      "logps/rejected": -116.22122192382812,
      "loss": 0.0048,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2562339305877686,
      "rewards/margins": 5.870779991149902,
      "rewards/rejected": -3.6145458221435547,
      "step": 1882
    },
    {
      "epoch": 0.7532,
      "grad_norm": 0.13199451565742493,
      "learning_rate": 7.490666666666667e-07,
      "logits/chosen": -2.029165267944336,
      "logits/rejected": -3.4172239303588867,
      "logps/chosen": -123.72129821777344,
      "logps/rejected": -175.54043579101562,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9913746118545532,
      "rewards/margins": 6.907853126525879,
      "rewards/rejected": -5.916478157043457,
      "step": 1883
    },
    {
      "epoch": 0.7536,
      "grad_norm": 0.07317253202199936,
      "learning_rate": 7.489333333333333e-07,
      "logits/chosen": -2.2253804206848145,
      "logits/rejected": -2.863377571105957,
      "logps/chosen": -148.90646362304688,
      "logps/rejected": -161.00485229492188,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.625518798828125,
      "rewards/margins": 7.88173246383667,
      "rewards/rejected": -5.256213665008545,
      "step": 1884
    },
    {
      "epoch": 0.754,
      "grad_norm": 0.48468509316444397,
      "learning_rate": 7.488e-07,
      "logits/chosen": -1.9928841590881348,
      "logits/rejected": -2.9875648021698,
      "logps/chosen": -143.05099487304688,
      "logps/rejected": -134.939697265625,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0386513471603394,
      "rewards/margins": 6.557432174682617,
      "rewards/rejected": -5.5187811851501465,
      "step": 1885
    },
    {
      "epoch": 0.7544,
      "grad_norm": 0.7317161560058594,
      "learning_rate": 7.486666666666666e-07,
      "logits/chosen": -2.644465923309326,
      "logits/rejected": -3.2680914402008057,
      "logps/chosen": -113.081298828125,
      "logps/rejected": -139.12124633789062,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8319569826126099,
      "rewards/margins": 6.938724517822266,
      "rewards/rejected": -5.106767654418945,
      "step": 1886
    },
    {
      "epoch": 0.7548,
      "grad_norm": 0.01810602843761444,
      "learning_rate": 7.485333333333333e-07,
      "logits/chosen": -2.587890386581421,
      "logits/rejected": -3.628899335861206,
      "logps/chosen": -109.86087799072266,
      "logps/rejected": -186.60203552246094,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2687950134277344,
      "rewards/margins": 9.351441383361816,
      "rewards/rejected": -6.082646369934082,
      "step": 1887
    },
    {
      "epoch": 0.7552,
      "grad_norm": 0.07709472626447678,
      "learning_rate": 7.483999999999999e-07,
      "logits/chosen": -2.337306499481201,
      "logits/rejected": -3.652963638305664,
      "logps/chosen": -82.76950073242188,
      "logps/rejected": -153.42498779296875,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8921408653259277,
      "rewards/margins": 8.345161437988281,
      "rewards/rejected": -5.453021049499512,
      "step": 1888
    },
    {
      "epoch": 0.7556,
      "grad_norm": 0.010158700868487358,
      "learning_rate": 7.482666666666666e-07,
      "logits/chosen": -2.0867807865142822,
      "logits/rejected": -2.7724499702453613,
      "logps/chosen": -80.27352142333984,
      "logps/rejected": -153.97311401367188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.395293712615967,
      "rewards/margins": 10.308219909667969,
      "rewards/rejected": -6.91292667388916,
      "step": 1889
    },
    {
      "epoch": 0.756,
      "grad_norm": 0.7982025146484375,
      "learning_rate": 7.481333333333333e-07,
      "logits/chosen": -2.2869396209716797,
      "logits/rejected": -2.995100975036621,
      "logps/chosen": -122.75120544433594,
      "logps/rejected": -140.87924194335938,
      "loss": 0.0086,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6211876273155212,
      "rewards/margins": 5.075077533721924,
      "rewards/rejected": -4.453889846801758,
      "step": 1890
    },
    {
      "epoch": 0.7564,
      "grad_norm": 0.4043554663658142,
      "learning_rate": 7.48e-07,
      "logits/chosen": -2.9148411750793457,
      "logits/rejected": -2.8680028915405273,
      "logps/chosen": -122.22280883789062,
      "logps/rejected": -145.39678955078125,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3270022869110107,
      "rewards/margins": 6.844956398010254,
      "rewards/rejected": -4.517953395843506,
      "step": 1891
    },
    {
      "epoch": 0.7568,
      "grad_norm": 0.44043952226638794,
      "learning_rate": 7.478666666666667e-07,
      "logits/chosen": -1.8733916282653809,
      "logits/rejected": -3.18068790435791,
      "logps/chosen": -168.28814697265625,
      "logps/rejected": -179.3385009765625,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4840202331542969,
      "rewards/margins": 8.297975540161133,
      "rewards/rejected": -6.813955307006836,
      "step": 1892
    },
    {
      "epoch": 0.7572,
      "grad_norm": 0.02976890839636326,
      "learning_rate": 7.477333333333334e-07,
      "logits/chosen": -2.3055803775787354,
      "logits/rejected": -2.7870683670043945,
      "logps/chosen": -165.72467041015625,
      "logps/rejected": -180.73782348632812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.095745086669922,
      "rewards/margins": 8.896512985229492,
      "rewards/rejected": -5.80076789855957,
      "step": 1893
    },
    {
      "epoch": 0.7576,
      "grad_norm": 1.258142113685608,
      "learning_rate": 7.476e-07,
      "logits/chosen": -2.7497024536132812,
      "logits/rejected": -3.562612533569336,
      "logps/chosen": -159.96340942382812,
      "logps/rejected": -168.0134735107422,
      "loss": 0.009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.486871361732483,
      "rewards/margins": 5.772517204284668,
      "rewards/rejected": -4.285645961761475,
      "step": 1894
    },
    {
      "epoch": 0.758,
      "grad_norm": 0.08564826101064682,
      "learning_rate": 7.474666666666665e-07,
      "logits/chosen": -2.1857595443725586,
      "logits/rejected": -2.9837846755981445,
      "logps/chosen": -103.77812194824219,
      "logps/rejected": -183.64767456054688,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3500614166259766,
      "rewards/margins": 7.457569122314453,
      "rewards/rejected": -5.107507705688477,
      "step": 1895
    },
    {
      "epoch": 0.7584,
      "grad_norm": 1.3085565567016602,
      "learning_rate": 7.473333333333332e-07,
      "logits/chosen": -2.0589799880981445,
      "logits/rejected": -2.8987441062927246,
      "logps/chosen": -149.3647003173828,
      "logps/rejected": -131.7489471435547,
      "loss": 0.0161,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11129951477050781,
      "rewards/margins": 4.126482009887695,
      "rewards/rejected": -4.0151824951171875,
      "step": 1896
    },
    {
      "epoch": 0.7588,
      "grad_norm": 0.13144049048423767,
      "learning_rate": 7.471999999999999e-07,
      "logits/chosen": -2.0094218254089355,
      "logits/rejected": -2.5975399017333984,
      "logps/chosen": -124.82632446289062,
      "logps/rejected": -138.18087768554688,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5710513591766357,
      "rewards/margins": 7.3474836349487305,
      "rewards/rejected": -4.776432037353516,
      "step": 1897
    },
    {
      "epoch": 0.7592,
      "grad_norm": 0.017261074855923653,
      "learning_rate": 7.470666666666666e-07,
      "logits/chosen": -2.4337382316589355,
      "logits/rejected": -3.4349865913391113,
      "logps/chosen": -123.66610717773438,
      "logps/rejected": -172.03892517089844,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.756937026977539,
      "rewards/margins": 9.302200317382812,
      "rewards/rejected": -5.545262336730957,
      "step": 1898
    },
    {
      "epoch": 0.7596,
      "grad_norm": 0.01841713860630989,
      "learning_rate": 7.469333333333333e-07,
      "logits/chosen": -2.652803421020508,
      "logits/rejected": -3.1517062187194824,
      "logps/chosen": -155.22567749023438,
      "logps/rejected": -189.10317993164062,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.453601121902466,
      "rewards/margins": 8.68887710571289,
      "rewards/rejected": -5.235276222229004,
      "step": 1899
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.009797156788408756,
      "learning_rate": 7.468e-07,
      "logits/chosen": -2.5756843090057373,
      "logits/rejected": -2.7082698345184326,
      "logps/chosen": -99.41424560546875,
      "logps/rejected": -208.7714385986328,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.791012287139893,
      "rewards/margins": 9.852371215820312,
      "rewards/rejected": -5.061358451843262,
      "step": 1900
    },
    {
      "epoch": 0.7604,
      "grad_norm": 0.170979306101799,
      "learning_rate": 7.466666666666667e-07,
      "logits/chosen": -1.8710086345672607,
      "logits/rejected": -3.062407970428467,
      "logps/chosen": -98.88650512695312,
      "logps/rejected": -133.49615478515625,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5362367630004883,
      "rewards/margins": 6.563610076904297,
      "rewards/rejected": -4.027373313903809,
      "step": 1901
    },
    {
      "epoch": 0.7608,
      "grad_norm": 0.06643948704004288,
      "learning_rate": 7.465333333333334e-07,
      "logits/chosen": -2.2929065227508545,
      "logits/rejected": -3.3389124870300293,
      "logps/chosen": -97.10799407958984,
      "logps/rejected": -138.36013793945312,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9198460578918457,
      "rewards/margins": 8.26102066040039,
      "rewards/rejected": -4.341174602508545,
      "step": 1902
    },
    {
      "epoch": 0.7612,
      "grad_norm": 0.08949197083711624,
      "learning_rate": 7.464e-07,
      "logits/chosen": -1.933159589767456,
      "logits/rejected": -2.8857903480529785,
      "logps/chosen": -116.08193969726562,
      "logps/rejected": -196.34703063964844,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9279247522354126,
      "rewards/margins": 7.41929292678833,
      "rewards/rejected": -5.491368293762207,
      "step": 1903
    },
    {
      "epoch": 0.7616,
      "grad_norm": 0.279868483543396,
      "learning_rate": 7.462666666666667e-07,
      "logits/chosen": -1.866959810256958,
      "logits/rejected": -2.6314239501953125,
      "logps/chosen": -117.7615737915039,
      "logps/rejected": -134.6890869140625,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9511650800704956,
      "rewards/margins": 6.74877405166626,
      "rewards/rejected": -4.797608852386475,
      "step": 1904
    },
    {
      "epoch": 0.762,
      "grad_norm": 0.04707631468772888,
      "learning_rate": 7.461333333333332e-07,
      "logits/chosen": -2.4057440757751465,
      "logits/rejected": -3.530454397201538,
      "logps/chosen": -146.1305694580078,
      "logps/rejected": -187.13427734375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.044586181640625,
      "rewards/margins": 8.133681297302246,
      "rewards/rejected": -5.089095115661621,
      "step": 1905
    },
    {
      "epoch": 0.7624,
      "grad_norm": 0.14011338353157043,
      "learning_rate": 7.459999999999999e-07,
      "logits/chosen": -2.3325066566467285,
      "logits/rejected": -3.540274143218994,
      "logps/chosen": -102.10325622558594,
      "logps/rejected": -154.26370239257812,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4998817443847656,
      "rewards/margins": 6.649867057800293,
      "rewards/rejected": -5.149985313415527,
      "step": 1906
    },
    {
      "epoch": 0.7628,
      "grad_norm": 0.027490127831697464,
      "learning_rate": 7.458666666666666e-07,
      "logits/chosen": -2.2053675651550293,
      "logits/rejected": -3.198456287384033,
      "logps/chosen": -110.89927673339844,
      "logps/rejected": -203.55702209472656,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.302172899246216,
      "rewards/margins": 10.43259048461914,
      "rewards/rejected": -7.130417823791504,
      "step": 1907
    },
    {
      "epoch": 0.7632,
      "grad_norm": 0.02295099012553692,
      "learning_rate": 7.457333333333333e-07,
      "logits/chosen": -2.00608491897583,
      "logits/rejected": -2.950960397720337,
      "logps/chosen": -77.7720718383789,
      "logps/rejected": -151.43389892578125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6629819869995117,
      "rewards/margins": 8.450782775878906,
      "rewards/rejected": -4.787801265716553,
      "step": 1908
    },
    {
      "epoch": 0.7636,
      "grad_norm": 0.16871212422847748,
      "learning_rate": 7.456e-07,
      "logits/chosen": -2.755075216293335,
      "logits/rejected": -3.102203369140625,
      "logps/chosen": -164.42935180664062,
      "logps/rejected": -153.78167724609375,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.403881788253784,
      "rewards/margins": 6.821394920349121,
      "rewards/rejected": -4.417513370513916,
      "step": 1909
    },
    {
      "epoch": 0.764,
      "grad_norm": 0.6340078711509705,
      "learning_rate": 7.454666666666667e-07,
      "logits/chosen": -2.412614345550537,
      "logits/rejected": -2.987622022628784,
      "logps/chosen": -174.48985290527344,
      "logps/rejected": -176.43365478515625,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2454540729522705,
      "rewards/margins": 8.017799377441406,
      "rewards/rejected": -5.772345542907715,
      "step": 1910
    },
    {
      "epoch": 0.7644,
      "grad_norm": 5.743634223937988,
      "learning_rate": 7.453333333333333e-07,
      "logits/chosen": -2.821756601333618,
      "logits/rejected": -3.3678674697875977,
      "logps/chosen": -157.02806091308594,
      "logps/rejected": -176.06573486328125,
      "loss": 0.0542,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2962658405303955,
      "rewards/margins": 5.914890766143799,
      "rewards/rejected": -5.618624687194824,
      "step": 1911
    },
    {
      "epoch": 0.7648,
      "grad_norm": 0.005109846591949463,
      "learning_rate": 7.452e-07,
      "logits/chosen": -2.8906960487365723,
      "logits/rejected": -3.4109458923339844,
      "logps/chosen": -120.89558410644531,
      "logps/rejected": -194.156494140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5074071884155273,
      "rewards/margins": 10.230318069458008,
      "rewards/rejected": -6.722910404205322,
      "step": 1912
    },
    {
      "epoch": 0.7652,
      "grad_norm": 0.2597619593143463,
      "learning_rate": 7.450666666666667e-07,
      "logits/chosen": -2.049095392227173,
      "logits/rejected": -2.6256237030029297,
      "logps/chosen": -94.45278930664062,
      "logps/rejected": -171.2255859375,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.326841115951538,
      "rewards/margins": 6.0807695388793945,
      "rewards/rejected": -3.7539284229278564,
      "step": 1913
    },
    {
      "epoch": 0.7656,
      "grad_norm": 0.05921415612101555,
      "learning_rate": 7.449333333333333e-07,
      "logits/chosen": -1.787508249282837,
      "logits/rejected": -2.554114818572998,
      "logps/chosen": -161.95989990234375,
      "logps/rejected": -158.9586639404297,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.67647123336792,
      "rewards/margins": 7.624472618103027,
      "rewards/rejected": -4.948000907897949,
      "step": 1914
    },
    {
      "epoch": 0.766,
      "grad_norm": 0.14163357019424438,
      "learning_rate": 7.447999999999999e-07,
      "logits/chosen": -2.547637939453125,
      "logits/rejected": -2.68228816986084,
      "logps/chosen": -171.5996551513672,
      "logps/rejected": -158.58445739746094,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4458484649658203,
      "rewards/margins": 6.791413307189941,
      "rewards/rejected": -4.345564842224121,
      "step": 1915
    },
    {
      "epoch": 0.7664,
      "grad_norm": 0.08247459679841995,
      "learning_rate": 7.446666666666666e-07,
      "logits/chosen": -2.1643800735473633,
      "logits/rejected": -2.914193630218506,
      "logps/chosen": -102.77250671386719,
      "logps/rejected": -167.0628204345703,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5811574459075928,
      "rewards/margins": 7.803396224975586,
      "rewards/rejected": -4.222238540649414,
      "step": 1916
    },
    {
      "epoch": 0.7668,
      "grad_norm": 0.08435924351215363,
      "learning_rate": 7.445333333333333e-07,
      "logits/chosen": -2.4073562622070312,
      "logits/rejected": -3.1982882022857666,
      "logps/chosen": -127.1390609741211,
      "logps/rejected": -196.117431640625,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5274338722229004,
      "rewards/margins": 8.31303596496582,
      "rewards/rejected": -5.78560209274292,
      "step": 1917
    },
    {
      "epoch": 0.7672,
      "grad_norm": 0.08940009027719498,
      "learning_rate": 7.443999999999999e-07,
      "logits/chosen": -2.2863831520080566,
      "logits/rejected": -3.3620691299438477,
      "logps/chosen": -121.0732192993164,
      "logps/rejected": -136.32492065429688,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.413039445877075,
      "rewards/margins": 7.3447957038879395,
      "rewards/rejected": -4.931756019592285,
      "step": 1918
    },
    {
      "epoch": 0.7676,
      "grad_norm": 0.7486031651496887,
      "learning_rate": 7.442666666666666e-07,
      "logits/chosen": -2.175199508666992,
      "logits/rejected": -3.5978102684020996,
      "logps/chosen": -124.51849365234375,
      "logps/rejected": -149.13278198242188,
      "loss": 0.0069,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8137286901473999,
      "rewards/margins": 5.20670223236084,
      "rewards/rejected": -4.392972946166992,
      "step": 1919
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.45013076066970825,
      "learning_rate": 7.441333333333333e-07,
      "logits/chosen": -2.153046131134033,
      "logits/rejected": -2.9654483795166016,
      "logps/chosen": -95.65806579589844,
      "logps/rejected": -175.585205078125,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9728443622589111,
      "rewards/margins": 6.733717918395996,
      "rewards/rejected": -4.760873317718506,
      "step": 1920
    },
    {
      "epoch": 0.7684,
      "grad_norm": 0.613192081451416,
      "learning_rate": 7.44e-07,
      "logits/chosen": -1.7124733924865723,
      "logits/rejected": -3.004638671875,
      "logps/chosen": -138.93658447265625,
      "logps/rejected": -144.13990783691406,
      "loss": 0.007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08803711831569672,
      "rewards/margins": 5.078248023986816,
      "rewards/rejected": -5.166285514831543,
      "step": 1921
    },
    {
      "epoch": 0.7688,
      "grad_norm": 0.017617160454392433,
      "learning_rate": 7.438666666666667e-07,
      "logits/chosen": -2.306281566619873,
      "logits/rejected": -3.3169760704040527,
      "logps/chosen": -125.18873596191406,
      "logps/rejected": -183.61184692382812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.776390552520752,
      "rewards/margins": 9.145583152770996,
      "rewards/rejected": -5.369192123413086,
      "step": 1922
    },
    {
      "epoch": 0.7692,
      "grad_norm": 1.6894875764846802,
      "learning_rate": 7.437333333333334e-07,
      "logits/chosen": -2.7222652435302734,
      "logits/rejected": -2.9553980827331543,
      "logps/chosen": -182.490966796875,
      "logps/rejected": -138.972412109375,
      "loss": 0.0188,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10484810173511505,
      "rewards/margins": 4.220090866088867,
      "rewards/rejected": -4.324938774108887,
      "step": 1923
    },
    {
      "epoch": 0.7696,
      "grad_norm": 0.024105237796902657,
      "learning_rate": 7.436e-07,
      "logits/chosen": -2.741741180419922,
      "logits/rejected": -3.142049551010132,
      "logps/chosen": -118.74617004394531,
      "logps/rejected": -167.37130737304688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1570253372192383,
      "rewards/margins": 8.903133392333984,
      "rewards/rejected": -5.746108055114746,
      "step": 1924
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.02529035694897175,
      "learning_rate": 7.434666666666667e-07,
      "logits/chosen": -2.354973554611206,
      "logits/rejected": -3.2399020195007324,
      "logps/chosen": -129.41119384765625,
      "logps/rejected": -169.03245544433594,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6252760887145996,
      "rewards/margins": 9.596136093139648,
      "rewards/rejected": -5.970860004425049,
      "step": 1925
    },
    {
      "epoch": 0.7704,
      "grad_norm": 0.06215489283204079,
      "learning_rate": 7.433333333333332e-07,
      "logits/chosen": -2.0216312408447266,
      "logits/rejected": -2.5713000297546387,
      "logps/chosen": -112.36616516113281,
      "logps/rejected": -152.52589416503906,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7802876234054565,
      "rewards/margins": 7.634012222290039,
      "rewards/rejected": -5.853724479675293,
      "step": 1926
    },
    {
      "epoch": 0.7708,
      "grad_norm": 1.1773416996002197,
      "learning_rate": 7.431999999999999e-07,
      "logits/chosen": -1.9792829751968384,
      "logits/rejected": -2.9088587760925293,
      "logps/chosen": -110.52947998046875,
      "logps/rejected": -167.42906188964844,
      "loss": 0.0122,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.601260781288147,
      "rewards/margins": 5.432578086853027,
      "rewards/rejected": -6.033838748931885,
      "step": 1927
    },
    {
      "epoch": 0.7712,
      "grad_norm": 0.04424517601728439,
      "learning_rate": 7.430666666666666e-07,
      "logits/chosen": -2.066735029220581,
      "logits/rejected": -3.3193979263305664,
      "logps/chosen": -125.858642578125,
      "logps/rejected": -170.86392211914062,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9030699729919434,
      "rewards/margins": 7.709678649902344,
      "rewards/rejected": -4.8066086769104,
      "step": 1928
    },
    {
      "epoch": 0.7716,
      "grad_norm": 0.059688497334718704,
      "learning_rate": 7.429333333333333e-07,
      "logits/chosen": -2.585672378540039,
      "logits/rejected": -2.8905861377716064,
      "logps/chosen": -178.27835083007812,
      "logps/rejected": -157.4463348388672,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4488234519958496,
      "rewards/margins": 9.178731918334961,
      "rewards/rejected": -6.729907989501953,
      "step": 1929
    },
    {
      "epoch": 0.772,
      "grad_norm": 0.47005340456962585,
      "learning_rate": 7.428e-07,
      "logits/chosen": -2.1212830543518066,
      "logits/rejected": -3.2100398540496826,
      "logps/chosen": -122.20265197753906,
      "logps/rejected": -130.81980895996094,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.967922568321228,
      "rewards/margins": 5.183041572570801,
      "rewards/rejected": -4.215119361877441,
      "step": 1930
    },
    {
      "epoch": 0.7724,
      "grad_norm": 0.03643283620476723,
      "learning_rate": 7.426666666666667e-07,
      "logits/chosen": -2.2482242584228516,
      "logits/rejected": -3.318735122680664,
      "logps/chosen": -115.53965759277344,
      "logps/rejected": -185.9447021484375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7089734077453613,
      "rewards/margins": 8.642017364501953,
      "rewards/rejected": -5.933043479919434,
      "step": 1931
    },
    {
      "epoch": 0.7728,
      "grad_norm": 1.435496211051941,
      "learning_rate": 7.425333333333334e-07,
      "logits/chosen": -2.2816991806030273,
      "logits/rejected": -2.908255100250244,
      "logps/chosen": -121.37213134765625,
      "logps/rejected": -127.40506744384766,
      "loss": 0.0178,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.48372724652290344,
      "rewards/margins": 4.281705856323242,
      "rewards/rejected": -3.797978401184082,
      "step": 1932
    },
    {
      "epoch": 0.7732,
      "grad_norm": 0.039961956441402435,
      "learning_rate": 7.423999999999999e-07,
      "logits/chosen": -2.611467123031616,
      "logits/rejected": -3.444610118865967,
      "logps/chosen": -184.02838134765625,
      "logps/rejected": -175.25848388671875,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8212761878967285,
      "rewards/margins": 7.8085174560546875,
      "rewards/rejected": -4.987241268157959,
      "step": 1933
    },
    {
      "epoch": 0.7736,
      "grad_norm": 0.11341537535190582,
      "learning_rate": 7.422666666666666e-07,
      "logits/chosen": -2.5996642112731934,
      "logits/rejected": -3.5437324047088623,
      "logps/chosen": -94.98110961914062,
      "logps/rejected": -167.65444946289062,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.876943588256836,
      "rewards/margins": 7.2510833740234375,
      "rewards/rejected": -5.374139785766602,
      "step": 1934
    },
    {
      "epoch": 0.774,
      "grad_norm": 0.0035784554202109575,
      "learning_rate": 7.421333333333333e-07,
      "logits/chosen": -1.996020793914795,
      "logits/rejected": -3.048161029815674,
      "logps/chosen": -138.49685668945312,
      "logps/rejected": -157.60968017578125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4384260177612305,
      "rewards/margins": 10.108255386352539,
      "rewards/rejected": -6.66982889175415,
      "step": 1935
    },
    {
      "epoch": 0.7744,
      "grad_norm": 0.7364325523376465,
      "learning_rate": 7.42e-07,
      "logits/chosen": -1.6864985227584839,
      "logits/rejected": -2.953949451446533,
      "logps/chosen": -128.6228790283203,
      "logps/rejected": -161.82077026367188,
      "loss": 0.0077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8602913022041321,
      "rewards/margins": 5.716145038604736,
      "rewards/rejected": -4.855854034423828,
      "step": 1936
    },
    {
      "epoch": 0.7748,
      "grad_norm": 0.012722264043986797,
      "learning_rate": 7.418666666666666e-07,
      "logits/chosen": -2.1642661094665527,
      "logits/rejected": -3.0380096435546875,
      "logps/chosen": -102.05683898925781,
      "logps/rejected": -172.70294189453125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.566788196563721,
      "rewards/margins": 9.677655220031738,
      "rewards/rejected": -5.110867500305176,
      "step": 1937
    },
    {
      "epoch": 0.7752,
      "grad_norm": 0.04536427557468414,
      "learning_rate": 7.417333333333333e-07,
      "logits/chosen": -1.9858312606811523,
      "logits/rejected": -3.2420668601989746,
      "logps/chosen": -129.17263793945312,
      "logps/rejected": -156.448974609375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2911252975463867,
      "rewards/margins": 8.427664756774902,
      "rewards/rejected": -5.136539459228516,
      "step": 1938
    },
    {
      "epoch": 0.7756,
      "grad_norm": 0.028285078704357147,
      "learning_rate": 7.416e-07,
      "logits/chosen": -2.183459520339966,
      "logits/rejected": -3.246582508087158,
      "logps/chosen": -85.27574157714844,
      "logps/rejected": -146.18118286132812,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6020150184631348,
      "rewards/margins": 8.217269897460938,
      "rewards/rejected": -5.615255355834961,
      "step": 1939
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.15902352333068848,
      "learning_rate": 7.414666666666667e-07,
      "logits/chosen": -2.0597360134124756,
      "logits/rejected": -2.29367733001709,
      "logps/chosen": -88.10116577148438,
      "logps/rejected": -148.271484375,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.657635688781738,
      "rewards/margins": 7.858752250671387,
      "rewards/rejected": -3.2011163234710693,
      "step": 1940
    },
    {
      "epoch": 0.7764,
      "grad_norm": 0.03690721467137337,
      "learning_rate": 7.413333333333333e-07,
      "logits/chosen": -2.3189687728881836,
      "logits/rejected": -3.5116872787475586,
      "logps/chosen": -118.88507080078125,
      "logps/rejected": -172.94073486328125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9041953086853027,
      "rewards/margins": 9.440786361694336,
      "rewards/rejected": -6.536590576171875,
      "step": 1941
    },
    {
      "epoch": 0.7768,
      "grad_norm": 0.1520835906267166,
      "learning_rate": 7.411999999999999e-07,
      "logits/chosen": -2.1351702213287354,
      "logits/rejected": -2.5880913734436035,
      "logps/chosen": -133.58897399902344,
      "logps/rejected": -190.62478637695312,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8368306159973145,
      "rewards/margins": 8.532188415527344,
      "rewards/rejected": -4.695357322692871,
      "step": 1942
    },
    {
      "epoch": 0.7772,
      "grad_norm": 0.549598217010498,
      "learning_rate": 7.410666666666666e-07,
      "logits/chosen": -3.1621336936950684,
      "logits/rejected": -3.3268208503723145,
      "logps/chosen": -154.6827850341797,
      "logps/rejected": -127.59739685058594,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.343902587890625,
      "rewards/margins": 5.871066093444824,
      "rewards/rejected": -4.527163982391357,
      "step": 1943
    },
    {
      "epoch": 0.7776,
      "grad_norm": 0.3376791775226593,
      "learning_rate": 7.409333333333333e-07,
      "logits/chosen": -3.2631850242614746,
      "logits/rejected": -3.4672627449035645,
      "logps/chosen": -167.5145721435547,
      "logps/rejected": -159.37892150878906,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8370258808135986,
      "rewards/margins": 7.085928440093994,
      "rewards/rejected": -5.248902797698975,
      "step": 1944
    },
    {
      "epoch": 0.778,
      "grad_norm": 0.08748690038919449,
      "learning_rate": 7.408e-07,
      "logits/chosen": -2.342970371246338,
      "logits/rejected": -3.451470375061035,
      "logps/chosen": -83.32183837890625,
      "logps/rejected": -139.2376708984375,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5866408348083496,
      "rewards/margins": 8.113643646240234,
      "rewards/rejected": -4.527002334594727,
      "step": 1945
    },
    {
      "epoch": 0.7784,
      "grad_norm": 0.13537319004535675,
      "learning_rate": 7.406666666666667e-07,
      "logits/chosen": -2.6879725456237793,
      "logits/rejected": -2.9123244285583496,
      "logps/chosen": -116.64029693603516,
      "logps/rejected": -140.1047821044922,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1091365814208984,
      "rewards/margins": 6.6559247970581055,
      "rewards/rejected": -4.546787738800049,
      "step": 1946
    },
    {
      "epoch": 0.7788,
      "grad_norm": 0.0011389877181500196,
      "learning_rate": 7.405333333333333e-07,
      "logits/chosen": -2.525395393371582,
      "logits/rejected": -3.009105682373047,
      "logps/chosen": -162.862060546875,
      "logps/rejected": -157.0176239013672,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 5.638396263122559,
      "rewards/margins": 11.84634780883789,
      "rewards/rejected": -6.207951545715332,
      "step": 1947
    },
    {
      "epoch": 0.7792,
      "grad_norm": 1.915661096572876,
      "learning_rate": 7.403999999999999e-07,
      "logits/chosen": -2.295609951019287,
      "logits/rejected": -3.0268282890319824,
      "logps/chosen": -159.98240661621094,
      "logps/rejected": -151.0193328857422,
      "loss": 0.0107,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.742558240890503,
      "rewards/margins": 6.911489963531494,
      "rewards/rejected": -5.168931484222412,
      "step": 1948
    },
    {
      "epoch": 0.7796,
      "grad_norm": 0.04778605327010155,
      "learning_rate": 7.402666666666666e-07,
      "logits/chosen": -2.046776056289673,
      "logits/rejected": -3.1804416179656982,
      "logps/chosen": -69.31510925292969,
      "logps/rejected": -160.765625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.238129138946533,
      "rewards/margins": 8.913318634033203,
      "rewards/rejected": -5.675189971923828,
      "step": 1949
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.04004066437482834,
      "learning_rate": 7.401333333333333e-07,
      "logits/chosen": -2.113107919692993,
      "logits/rejected": -3.3121442794799805,
      "logps/chosen": -98.93780517578125,
      "logps/rejected": -169.9886932373047,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2592310905456543,
      "rewards/margins": 8.706317901611328,
      "rewards/rejected": -5.447086334228516,
      "step": 1950
    },
    {
      "epoch": 0.7804,
      "grad_norm": 1.7191590070724487,
      "learning_rate": 7.4e-07,
      "logits/chosen": -1.8358721733093262,
      "logits/rejected": -2.623755931854248,
      "logps/chosen": -141.6778106689453,
      "logps/rejected": -124.54354858398438,
      "loss": 0.018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.21000710129737854,
      "rewards/margins": 4.218407154083252,
      "rewards/rejected": -4.428414344787598,
      "step": 1951
    },
    {
      "epoch": 0.7808,
      "grad_norm": 0.41376301646232605,
      "learning_rate": 7.398666666666666e-07,
      "logits/chosen": -2.4186737537384033,
      "logits/rejected": -2.5496277809143066,
      "logps/chosen": -108.95188903808594,
      "logps/rejected": -126.76675415039062,
      "loss": 0.0045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.116060733795166,
      "rewards/margins": 7.525426387786865,
      "rewards/rejected": -4.409365653991699,
      "step": 1952
    },
    {
      "epoch": 0.7812,
      "grad_norm": 0.020159052684903145,
      "learning_rate": 7.397333333333333e-07,
      "logits/chosen": -2.458920955657959,
      "logits/rejected": -2.791165351867676,
      "logps/chosen": -121.70053100585938,
      "logps/rejected": -169.06382751464844,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2763452529907227,
      "rewards/margins": 8.511636734008789,
      "rewards/rejected": -5.235291004180908,
      "step": 1953
    },
    {
      "epoch": 0.7816,
      "grad_norm": 0.17166581749916077,
      "learning_rate": 7.396e-07,
      "logits/chosen": -2.2509636878967285,
      "logits/rejected": -2.6264090538024902,
      "logps/chosen": -112.22537231445312,
      "logps/rejected": -123.7654037475586,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8315387964248657,
      "rewards/margins": 6.058815002441406,
      "rewards/rejected": -4.22727632522583,
      "step": 1954
    },
    {
      "epoch": 0.782,
      "grad_norm": 7.655786037445068,
      "learning_rate": 7.394666666666667e-07,
      "logits/chosen": -2.192183494567871,
      "logits/rejected": -3.2131524085998535,
      "logps/chosen": -110.954345703125,
      "logps/rejected": -166.57872009277344,
      "loss": 0.0628,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0016666650772095,
      "rewards/margins": 3.8111300468444824,
      "rewards/rejected": -4.812796592712402,
      "step": 1955
    },
    {
      "epoch": 0.7824,
      "grad_norm": 0.08834926038980484,
      "learning_rate": 7.393333333333333e-07,
      "logits/chosen": -2.44618558883667,
      "logits/rejected": -2.930819511413574,
      "logps/chosen": -185.8160400390625,
      "logps/rejected": -173.38092041015625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.684731960296631,
      "rewards/margins": 8.340450286865234,
      "rewards/rejected": -4.655717849731445,
      "step": 1956
    },
    {
      "epoch": 0.7828,
      "grad_norm": 0.5739191770553589,
      "learning_rate": 7.392e-07,
      "logits/chosen": -1.745039701461792,
      "logits/rejected": -2.894425868988037,
      "logps/chosen": -101.88394165039062,
      "logps/rejected": -128.79116821289062,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38857537508010864,
      "rewards/margins": 5.051902770996094,
      "rewards/rejected": -4.663327217102051,
      "step": 1957
    },
    {
      "epoch": 0.7832,
      "grad_norm": 1.8687018156051636,
      "learning_rate": 7.390666666666666e-07,
      "logits/chosen": -2.288362741470337,
      "logits/rejected": -2.6099295616149902,
      "logps/chosen": -92.52244567871094,
      "logps/rejected": -124.01876831054688,
      "loss": 0.0209,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12331163883209229,
      "rewards/margins": 4.853666305541992,
      "rewards/rejected": -4.730354309082031,
      "step": 1958
    },
    {
      "epoch": 0.7836,
      "grad_norm": 0.00394646218046546,
      "learning_rate": 7.389333333333333e-07,
      "logits/chosen": -2.4233484268188477,
      "logits/rejected": -3.409111499786377,
      "logps/chosen": -157.23684692382812,
      "logps/rejected": -168.14112854003906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4422364234924316,
      "rewards/margins": 10.534185409545898,
      "rewards/rejected": -7.091948986053467,
      "step": 1959
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.10468918830156326,
      "learning_rate": 7.388e-07,
      "logits/chosen": -2.5287299156188965,
      "logits/rejected": -3.5974483489990234,
      "logps/chosen": -100.01876831054688,
      "logps/rejected": -184.02774047851562,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6393080949783325,
      "rewards/margins": 6.933823108673096,
      "rewards/rejected": -5.294515132904053,
      "step": 1960
    },
    {
      "epoch": 0.7844,
      "grad_norm": 0.10826602578163147,
      "learning_rate": 7.386666666666666e-07,
      "logits/chosen": -2.4027609825134277,
      "logits/rejected": -3.0990986824035645,
      "logps/chosen": -124.49641418457031,
      "logps/rejected": -179.13467407226562,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7730808258056641,
      "rewards/margins": 7.0114545822143555,
      "rewards/rejected": -6.238373756408691,
      "step": 1961
    },
    {
      "epoch": 0.7848,
      "grad_norm": 0.5355828404426575,
      "learning_rate": 7.385333333333333e-07,
      "logits/chosen": -2.714799404144287,
      "logits/rejected": -3.2755298614501953,
      "logps/chosen": -181.81527709960938,
      "logps/rejected": -141.57577514648438,
      "loss": 0.0055,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1590416431427,
      "rewards/margins": 6.283014297485352,
      "rewards/rejected": -4.123972415924072,
      "step": 1962
    },
    {
      "epoch": 0.7852,
      "grad_norm": 0.8386468291282654,
      "learning_rate": 7.383999999999999e-07,
      "logits/chosen": -2.1247425079345703,
      "logits/rejected": -3.300966262817383,
      "logps/chosen": -155.129638671875,
      "logps/rejected": -175.46839904785156,
      "loss": 0.0071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.49102330207824707,
      "rewards/margins": 6.517979145050049,
      "rewards/rejected": -6.026955604553223,
      "step": 1963
    },
    {
      "epoch": 0.7856,
      "grad_norm": 0.023816054686903954,
      "learning_rate": 7.382666666666666e-07,
      "logits/chosen": -2.352694034576416,
      "logits/rejected": -2.878390312194824,
      "logps/chosen": -129.06866455078125,
      "logps/rejected": -158.7012176513672,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8615684509277344,
      "rewards/margins": 8.606023788452148,
      "rewards/rejected": -5.744455337524414,
      "step": 1964
    },
    {
      "epoch": 0.786,
      "grad_norm": 0.5426878929138184,
      "learning_rate": 7.381333333333333e-07,
      "logits/chosen": -2.041121482849121,
      "logits/rejected": -3.6370506286621094,
      "logps/chosen": -84.69799041748047,
      "logps/rejected": -187.30392456054688,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4080820083618164,
      "rewards/margins": 7.577579498291016,
      "rewards/rejected": -6.169497489929199,
      "step": 1965
    },
    {
      "epoch": 0.7864,
      "grad_norm": 0.06211621314287186,
      "learning_rate": 7.38e-07,
      "logits/chosen": -2.1237411499023438,
      "logits/rejected": -2.496863842010498,
      "logps/chosen": -141.15835571289062,
      "logps/rejected": -132.2823944091797,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3980050086975098,
      "rewards/margins": 7.339271068572998,
      "rewards/rejected": -4.941266059875488,
      "step": 1966
    },
    {
      "epoch": 0.7868,
      "grad_norm": 0.43068772554397583,
      "learning_rate": 7.378666666666667e-07,
      "logits/chosen": -2.2953057289123535,
      "logits/rejected": -3.2124288082122803,
      "logps/chosen": -130.22775268554688,
      "logps/rejected": -186.17996215820312,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3174927234649658,
      "rewards/margins": 6.880537033081055,
      "rewards/rejected": -5.563044548034668,
      "step": 1967
    },
    {
      "epoch": 0.7872,
      "grad_norm": 0.025295685976743698,
      "learning_rate": 7.377333333333333e-07,
      "logits/chosen": -2.285109281539917,
      "logits/rejected": -2.921896457672119,
      "logps/chosen": -90.416259765625,
      "logps/rejected": -140.96051025390625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8248496055603027,
      "rewards/margins": 8.342208862304688,
      "rewards/rejected": -5.517359256744385,
      "step": 1968
    },
    {
      "epoch": 0.7876,
      "grad_norm": 0.1019236296415329,
      "learning_rate": 7.376e-07,
      "logits/chosen": -2.276610851287842,
      "logits/rejected": -2.7392115592956543,
      "logps/chosen": -87.68232727050781,
      "logps/rejected": -144.71438598632812,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9129276275634766,
      "rewards/margins": 8.788036346435547,
      "rewards/rejected": -4.87510871887207,
      "step": 1969
    },
    {
      "epoch": 0.788,
      "grad_norm": 0.010739208199083805,
      "learning_rate": 7.374666666666667e-07,
      "logits/chosen": -1.9697482585906982,
      "logits/rejected": -3.1072263717651367,
      "logps/chosen": -69.07892608642578,
      "logps/rejected": -130.14407348632812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.573922157287598,
      "rewards/margins": 9.221382141113281,
      "rewards/rejected": -4.647459030151367,
      "step": 1970
    },
    {
      "epoch": 0.7884,
      "grad_norm": 0.3010532259941101,
      "learning_rate": 7.373333333333332e-07,
      "logits/chosen": -2.171337127685547,
      "logits/rejected": -3.3527913093566895,
      "logps/chosen": -152.55307006835938,
      "logps/rejected": -146.20480346679688,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.378706455230713,
      "rewards/margins": 6.821237564086914,
      "rewards/rejected": -5.442531585693359,
      "step": 1971
    },
    {
      "epoch": 0.7888,
      "grad_norm": 0.0059476676397025585,
      "learning_rate": 7.371999999999999e-07,
      "logits/chosen": -2.2725234031677246,
      "logits/rejected": -3.391958475112915,
      "logps/chosen": -131.5640411376953,
      "logps/rejected": -177.14251708984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.387304306030273,
      "rewards/margins": 10.46902084350586,
      "rewards/rejected": -6.081716537475586,
      "step": 1972
    },
    {
      "epoch": 0.7892,
      "grad_norm": 1.7975444793701172,
      "learning_rate": 7.370666666666666e-07,
      "logits/chosen": -1.5757098197937012,
      "logits/rejected": -2.5924155712127686,
      "logps/chosen": -93.46513366699219,
      "logps/rejected": -120.48873901367188,
      "loss": 0.0281,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03488272428512573,
      "rewards/margins": 4.48020601272583,
      "rewards/rejected": -4.4453229904174805,
      "step": 1973
    },
    {
      "epoch": 0.7896,
      "grad_norm": 0.10950271040201187,
      "learning_rate": 7.369333333333333e-07,
      "logits/chosen": -2.0356605052948,
      "logits/rejected": -2.8282008171081543,
      "logps/chosen": -153.8505859375,
      "logps/rejected": -141.13851928710938,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4970054626464844,
      "rewards/margins": 7.627423286437988,
      "rewards/rejected": -4.130417346954346,
      "step": 1974
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.09672345966100693,
      "learning_rate": 7.368e-07,
      "logits/chosen": -2.6493825912475586,
      "logits/rejected": -3.156951427459717,
      "logps/chosen": -114.66905975341797,
      "logps/rejected": -164.47207641601562,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7207329273223877,
      "rewards/margins": 6.989654541015625,
      "rewards/rejected": -5.268921852111816,
      "step": 1975
    },
    {
      "epoch": 0.7904,
      "grad_norm": 2.237366199493408,
      "learning_rate": 7.366666666666667e-07,
      "logits/chosen": -2.323435068130493,
      "logits/rejected": -2.8153796195983887,
      "logps/chosen": -83.11956787109375,
      "logps/rejected": -108.5725326538086,
      "loss": 0.0249,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.273129463195801,
      "rewards/margins": 5.548264026641846,
      "rewards/rejected": -3.275134563446045,
      "step": 1976
    },
    {
      "epoch": 0.7908,
      "grad_norm": 1.138264775276184,
      "learning_rate": 7.365333333333334e-07,
      "logits/chosen": -2.2817931175231934,
      "logits/rejected": -2.980194091796875,
      "logps/chosen": -195.3453369140625,
      "logps/rejected": -160.6095733642578,
      "loss": 0.0074,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.189944863319397,
      "rewards/margins": 5.920859336853027,
      "rewards/rejected": -4.730914115905762,
      "step": 1977
    },
    {
      "epoch": 0.7912,
      "grad_norm": 0.11653321981430054,
      "learning_rate": 7.364000000000001e-07,
      "logits/chosen": -3.264587879180908,
      "logits/rejected": -3.576718330383301,
      "logps/chosen": -127.40200805664062,
      "logps/rejected": -174.61627197265625,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.572557806968689,
      "rewards/margins": 7.54696798324585,
      "rewards/rejected": -6.974410057067871,
      "step": 1978
    },
    {
      "epoch": 0.7916,
      "grad_norm": 0.21927767992019653,
      "learning_rate": 7.362666666666666e-07,
      "logits/chosen": -2.3045668601989746,
      "logits/rejected": -3.5653159618377686,
      "logps/chosen": -254.8009490966797,
      "logps/rejected": -169.24725341796875,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4433731138706207,
      "rewards/margins": 6.176644802093506,
      "rewards/rejected": -5.733271598815918,
      "step": 1979
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.14574529230594635,
      "learning_rate": 7.361333333333332e-07,
      "logits/chosen": -2.2629051208496094,
      "logits/rejected": -2.9300875663757324,
      "logps/chosen": -79.39657592773438,
      "logps/rejected": -133.18014526367188,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8043996095657349,
      "rewards/margins": 6.47493839263916,
      "rewards/rejected": -4.670538902282715,
      "step": 1980
    },
    {
      "epoch": 0.7924,
      "grad_norm": 0.24621567130088806,
      "learning_rate": 7.359999999999999e-07,
      "logits/chosen": -2.5971243381500244,
      "logits/rejected": -3.2971160411834717,
      "logps/chosen": -181.1005401611328,
      "logps/rejected": -174.36668395996094,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1182382106781006,
      "rewards/margins": 6.44706916809082,
      "rewards/rejected": -4.328831195831299,
      "step": 1981
    },
    {
      "epoch": 0.7928,
      "grad_norm": 2.6137709617614746,
      "learning_rate": 7.358666666666666e-07,
      "logits/chosen": -2.14176607131958,
      "logits/rejected": -3.449357032775879,
      "logps/chosen": -125.05116271972656,
      "logps/rejected": -133.3697052001953,
      "loss": 0.0284,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7580578327178955,
      "rewards/margins": 3.6573305130004883,
      "rewards/rejected": -4.415388584136963,
      "step": 1982
    },
    {
      "epoch": 0.7932,
      "grad_norm": 0.06785650551319122,
      "learning_rate": 7.357333333333333e-07,
      "logits/chosen": -2.605907917022705,
      "logits/rejected": -3.419556140899658,
      "logps/chosen": -176.93601989746094,
      "logps/rejected": -169.69293212890625,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.799395799636841,
      "rewards/margins": 7.640946388244629,
      "rewards/rejected": -4.841550827026367,
      "step": 1983
    },
    {
      "epoch": 0.7936,
      "grad_norm": 0.8006277680397034,
      "learning_rate": 7.356e-07,
      "logits/chosen": -2.438754081726074,
      "logits/rejected": -3.093543291091919,
      "logps/chosen": -134.2016143798828,
      "logps/rejected": -146.58224487304688,
      "loss": 0.0051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7350212335586548,
      "rewards/margins": 6.851954936981201,
      "rewards/rejected": -5.116933822631836,
      "step": 1984
    },
    {
      "epoch": 0.794,
      "grad_norm": 0.41908201575279236,
      "learning_rate": 7.354666666666667e-07,
      "logits/chosen": -2.360875129699707,
      "logits/rejected": -3.367379665374756,
      "logps/chosen": -181.95510864257812,
      "logps/rejected": -143.14674377441406,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9167076349258423,
      "rewards/margins": 5.810413360595703,
      "rewards/rejected": -4.893706321716309,
      "step": 1985
    },
    {
      "epoch": 0.7944,
      "grad_norm": 0.05489202216267586,
      "learning_rate": 7.353333333333333e-07,
      "logits/chosen": -2.1729965209960938,
      "logits/rejected": -2.9992966651916504,
      "logps/chosen": -87.24252319335938,
      "logps/rejected": -124.96593475341797,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.337596893310547,
      "rewards/margins": 7.721405506134033,
      "rewards/rejected": -4.383808612823486,
      "step": 1986
    },
    {
      "epoch": 0.7948,
      "grad_norm": 0.00883351918309927,
      "learning_rate": 7.352e-07,
      "logits/chosen": -2.1110527515411377,
      "logits/rejected": -3.4081430435180664,
      "logps/chosen": -87.91511535644531,
      "logps/rejected": -177.3359375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5435612201690674,
      "rewards/margins": 9.278838157653809,
      "rewards/rejected": -6.735276699066162,
      "step": 1987
    },
    {
      "epoch": 0.7952,
      "grad_norm": 0.757159948348999,
      "learning_rate": 7.350666666666667e-07,
      "logits/chosen": -2.5762715339660645,
      "logits/rejected": -3.184216260910034,
      "logps/chosen": -96.66304779052734,
      "logps/rejected": -126.6583480834961,
      "loss": 0.0063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5404610633850098,
      "rewards/margins": 7.132810115814209,
      "rewards/rejected": -4.592349529266357,
      "step": 1988
    },
    {
      "epoch": 0.7956,
      "grad_norm": 0.19039694964885712,
      "learning_rate": 7.349333333333332e-07,
      "logits/chosen": -1.6073942184448242,
      "logits/rejected": -3.043844223022461,
      "logps/chosen": -112.43907928466797,
      "logps/rejected": -137.0368194580078,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0550804138183594,
      "rewards/margins": 6.171274185180664,
      "rewards/rejected": -5.116193771362305,
      "step": 1989
    },
    {
      "epoch": 0.796,
      "grad_norm": 0.08943501114845276,
      "learning_rate": 7.347999999999999e-07,
      "logits/chosen": -2.3177878856658936,
      "logits/rejected": -3.077800750732422,
      "logps/chosen": -103.88460540771484,
      "logps/rejected": -172.29051208496094,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.44633150100708,
      "rewards/margins": 8.620248794555664,
      "rewards/rejected": -6.173917293548584,
      "step": 1990
    },
    {
      "epoch": 0.7964,
      "grad_norm": 0.016040092334151268,
      "learning_rate": 7.346666666666666e-07,
      "logits/chosen": -1.9961422681808472,
      "logits/rejected": -3.080451011657715,
      "logps/chosen": -128.4978790283203,
      "logps/rejected": -166.67481994628906,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3177592754364014,
      "rewards/margins": 9.226921081542969,
      "rewards/rejected": -5.9091620445251465,
      "step": 1991
    },
    {
      "epoch": 0.7968,
      "grad_norm": 0.016848107799887657,
      "learning_rate": 7.345333333333333e-07,
      "logits/chosen": -2.2821576595306396,
      "logits/rejected": -3.1796939373016357,
      "logps/chosen": -121.78172302246094,
      "logps/rejected": -173.88665771484375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9370243549346924,
      "rewards/margins": 8.958661079406738,
      "rewards/rejected": -6.021636962890625,
      "step": 1992
    },
    {
      "epoch": 0.7972,
      "grad_norm": 0.19044627249240875,
      "learning_rate": 7.344e-07,
      "logits/chosen": -2.271655559539795,
      "logits/rejected": -3.3363137245178223,
      "logps/chosen": -148.82858276367188,
      "logps/rejected": -144.75936889648438,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2419688701629639,
      "rewards/margins": 7.522228240966797,
      "rewards/rejected": -6.280259132385254,
      "step": 1993
    },
    {
      "epoch": 0.7976,
      "grad_norm": 0.00707982387393713,
      "learning_rate": 7.342666666666666e-07,
      "logits/chosen": -2.258533477783203,
      "logits/rejected": -3.0246763229370117,
      "logps/chosen": -169.6448211669922,
      "logps/rejected": -210.97476196289062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.354672908782959,
      "rewards/margins": 9.758291244506836,
      "rewards/rejected": -7.403618812561035,
      "step": 1994
    },
    {
      "epoch": 0.798,
      "grad_norm": 4.054647445678711,
      "learning_rate": 7.341333333333333e-07,
      "logits/chosen": -2.812711715698242,
      "logits/rejected": -3.817938804626465,
      "logps/chosen": -234.84396362304688,
      "logps/rejected": -238.3766632080078,
      "loss": 0.0352,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01144111156463623,
      "rewards/margins": 6.54117488861084,
      "rewards/rejected": -6.529733657836914,
      "step": 1995
    },
    {
      "epoch": 0.7984,
      "grad_norm": 0.032830819487571716,
      "learning_rate": 7.34e-07,
      "logits/chosen": -2.0153679847717285,
      "logits/rejected": -3.1012122631073,
      "logps/chosen": -101.1314468383789,
      "logps/rejected": -163.65231323242188,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7350454330444336,
      "rewards/margins": 8.620991706848145,
      "rewards/rejected": -5.885946273803711,
      "step": 1996
    },
    {
      "epoch": 0.7988,
      "grad_norm": 0.03334909677505493,
      "learning_rate": 7.338666666666667e-07,
      "logits/chosen": -2.453378915786743,
      "logits/rejected": -2.3565287590026855,
      "logps/chosen": -119.52887725830078,
      "logps/rejected": -149.79005432128906,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.083410739898682,
      "rewards/margins": 8.538305282592773,
      "rewards/rejected": -4.45489501953125,
      "step": 1997
    },
    {
      "epoch": 0.7992,
      "grad_norm": 0.025282379239797592,
      "learning_rate": 7.337333333333334e-07,
      "logits/chosen": -2.306584358215332,
      "logits/rejected": -3.0812697410583496,
      "logps/chosen": -74.88768768310547,
      "logps/rejected": -148.66342163085938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5253868103027344,
      "rewards/margins": 9.045654296875,
      "rewards/rejected": -5.520267486572266,
      "step": 1998
    },
    {
      "epoch": 0.7996,
      "grad_norm": 2.143547296524048,
      "learning_rate": 7.336e-07,
      "logits/chosen": -2.4469428062438965,
      "logits/rejected": -3.039076805114746,
      "logps/chosen": -119.77661895751953,
      "logps/rejected": -120.88721466064453,
      "loss": 0.0261,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0029800385236740112,
      "rewards/margins": 4.025445461273193,
      "rewards/rejected": -4.028425693511963,
      "step": 1999
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.1436588019132614,
      "learning_rate": 7.334666666666666e-07,
      "logits/chosen": -2.1027956008911133,
      "logits/rejected": -2.86155366897583,
      "logps/chosen": -100.92118835449219,
      "logps/rejected": -152.76779174804688,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.430696487426758,
      "rewards/margins": 7.585379600524902,
      "rewards/rejected": -4.1546831130981445,
      "step": 2000
    },
    {
      "epoch": 0.8004,
      "grad_norm": 3.7302818298339844,
      "learning_rate": 7.333333333333332e-07,
      "logits/chosen": -2.1929993629455566,
      "logits/rejected": -3.0227651596069336,
      "logps/chosen": -110.97144317626953,
      "logps/rejected": -144.5474090576172,
      "loss": 0.0246,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5305656790733337,
      "rewards/margins": 5.146407127380371,
      "rewards/rejected": -5.676972389221191,
      "step": 2001
    },
    {
      "epoch": 0.8008,
      "grad_norm": 0.457937628030777,
      "learning_rate": 7.331999999999999e-07,
      "logits/chosen": -1.91951584815979,
      "logits/rejected": -3.1999382972717285,
      "logps/chosen": -105.24873352050781,
      "logps/rejected": -150.8958740234375,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2832660675048828,
      "rewards/margins": 7.146393299102783,
      "rewards/rejected": -5.8631272315979,
      "step": 2002
    },
    {
      "epoch": 0.8012,
      "grad_norm": 0.08825628459453583,
      "learning_rate": 7.330666666666666e-07,
      "logits/chosen": -2.8431646823883057,
      "logits/rejected": -3.339456558227539,
      "logps/chosen": -140.20098876953125,
      "logps/rejected": -172.16653442382812,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.506631851196289,
      "rewards/margins": 7.337732315063477,
      "rewards/rejected": -5.8311004638671875,
      "step": 2003
    },
    {
      "epoch": 0.8016,
      "grad_norm": 4.899322509765625,
      "learning_rate": 7.329333333333333e-07,
      "logits/chosen": -2.3279991149902344,
      "logits/rejected": -3.127732515335083,
      "logps/chosen": -130.71563720703125,
      "logps/rejected": -135.4180908203125,
      "loss": 0.044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8613929748535156,
      "rewards/margins": 5.809908866882324,
      "rewards/rejected": -3.9485158920288086,
      "step": 2004
    },
    {
      "epoch": 0.802,
      "grad_norm": 4.49344539642334,
      "learning_rate": 7.328e-07,
      "logits/chosen": -2.4089198112487793,
      "logits/rejected": -3.2813868522644043,
      "logps/chosen": -93.25806427001953,
      "logps/rejected": -127.17262268066406,
      "loss": 0.0367,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5870251655578613,
      "rewards/margins": 6.893237113952637,
      "rewards/rejected": -6.306211948394775,
      "step": 2005
    },
    {
      "epoch": 0.8024,
      "grad_norm": 0.3638381063938141,
      "learning_rate": 7.326666666666667e-07,
      "logits/chosen": -2.2278683185577393,
      "logits/rejected": -2.4873998165130615,
      "logps/chosen": -145.24237060546875,
      "logps/rejected": -138.06741333007812,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0785938501358032,
      "rewards/margins": 6.11899471282959,
      "rewards/rejected": -5.040400505065918,
      "step": 2006
    },
    {
      "epoch": 0.8028,
      "grad_norm": 0.007500834763050079,
      "learning_rate": 7.325333333333334e-07,
      "logits/chosen": -2.497124195098877,
      "logits/rejected": -3.434302568435669,
      "logps/chosen": -182.57203674316406,
      "logps/rejected": -262.7179870605469,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4888789653778076,
      "rewards/margins": 9.782344818115234,
      "rewards/rejected": -7.293466567993164,
      "step": 2007
    },
    {
      "epoch": 0.8032,
      "grad_norm": 0.06212484836578369,
      "learning_rate": 7.324e-07,
      "logits/chosen": -2.2980458736419678,
      "logits/rejected": -2.8500514030456543,
      "logps/chosen": -151.24107360839844,
      "logps/rejected": -149.65957641601562,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.365368366241455,
      "rewards/margins": 8.139185905456543,
      "rewards/rejected": -4.773818016052246,
      "step": 2008
    },
    {
      "epoch": 0.8036,
      "grad_norm": 0.15462736785411835,
      "learning_rate": 7.322666666666666e-07,
      "logits/chosen": -1.9290854930877686,
      "logits/rejected": -3.2551767826080322,
      "logps/chosen": -127.35888671875,
      "logps/rejected": -183.68356323242188,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7868560552597046,
      "rewards/margins": 6.841374397277832,
      "rewards/rejected": -6.054518222808838,
      "step": 2009
    },
    {
      "epoch": 0.804,
      "grad_norm": 0.02268155664205551,
      "learning_rate": 7.321333333333332e-07,
      "logits/chosen": -2.037736654281616,
      "logits/rejected": -3.4596810340881348,
      "logps/chosen": -135.8175048828125,
      "logps/rejected": -163.67953491210938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4229393005371094,
      "rewards/margins": 8.630169868469238,
      "rewards/rejected": -6.207230091094971,
      "step": 2010
    },
    {
      "epoch": 0.8044,
      "grad_norm": 0.08190689980983734,
      "learning_rate": 7.319999999999999e-07,
      "logits/chosen": -1.8412196636199951,
      "logits/rejected": -3.5732994079589844,
      "logps/chosen": -90.89889526367188,
      "logps/rejected": -161.14700317382812,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7142642736434937,
      "rewards/margins": 7.448951244354248,
      "rewards/rejected": -5.734686851501465,
      "step": 2011
    },
    {
      "epoch": 0.8048,
      "grad_norm": 0.1657206416130066,
      "learning_rate": 7.318666666666666e-07,
      "logits/chosen": -1.9960119724273682,
      "logits/rejected": -3.180572986602783,
      "logps/chosen": -152.52694702148438,
      "logps/rejected": -146.62167358398438,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2253899574279785,
      "rewards/margins": 8.09796142578125,
      "rewards/rejected": -4.872570991516113,
      "step": 2012
    },
    {
      "epoch": 0.8052,
      "grad_norm": 0.21442610025405884,
      "learning_rate": 7.317333333333333e-07,
      "logits/chosen": -2.6531624794006348,
      "logits/rejected": -3.182102680206299,
      "logps/chosen": -193.7029266357422,
      "logps/rejected": -168.5861358642578,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9865715503692627,
      "rewards/margins": 8.138303756713867,
      "rewards/rejected": -6.151731967926025,
      "step": 2013
    },
    {
      "epoch": 0.8056,
      "grad_norm": 0.6596077084541321,
      "learning_rate": 7.316e-07,
      "logits/chosen": -2.330336570739746,
      "logits/rejected": -3.221269130706787,
      "logps/chosen": -156.95938110351562,
      "logps/rejected": -153.37918090820312,
      "loss": 0.0051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5516555309295654,
      "rewards/margins": 7.137112140655518,
      "rewards/rejected": -4.585456848144531,
      "step": 2014
    },
    {
      "epoch": 0.806,
      "grad_norm": 0.18364447355270386,
      "learning_rate": 7.314666666666667e-07,
      "logits/chosen": -2.329219341278076,
      "logits/rejected": -3.404886484146118,
      "logps/chosen": -155.56549072265625,
      "logps/rejected": -154.81210327148438,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.466217279434204,
      "rewards/margins": 8.526437759399414,
      "rewards/rejected": -6.060220718383789,
      "step": 2015
    },
    {
      "epoch": 0.8064,
      "grad_norm": 1.0864149332046509,
      "learning_rate": 7.313333333333333e-07,
      "logits/chosen": -2.338123083114624,
      "logits/rejected": -3.09010910987854,
      "logps/chosen": -102.59487915039062,
      "logps/rejected": -189.7576141357422,
      "loss": 0.0107,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3252289295196533,
      "rewards/margins": 7.103982925415039,
      "rewards/rejected": -4.778753757476807,
      "step": 2016
    },
    {
      "epoch": 0.8068,
      "grad_norm": 0.047536950558423996,
      "learning_rate": 7.311999999999999e-07,
      "logits/chosen": -2.342679023742676,
      "logits/rejected": -3.5421996116638184,
      "logps/chosen": -118.0730209350586,
      "logps/rejected": -154.81439208984375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6216676235198975,
      "rewards/margins": 7.671916961669922,
      "rewards/rejected": -4.050249099731445,
      "step": 2017
    },
    {
      "epoch": 0.8072,
      "grad_norm": 0.005593979265540838,
      "learning_rate": 7.310666666666666e-07,
      "logits/chosen": -1.950852632522583,
      "logits/rejected": -3.065220832824707,
      "logps/chosen": -134.086181640625,
      "logps/rejected": -151.7860107421875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.853771209716797,
      "rewards/margins": 9.912103652954102,
      "rewards/rejected": -6.058332443237305,
      "step": 2018
    },
    {
      "epoch": 0.8076,
      "grad_norm": 0.41227132081985474,
      "learning_rate": 7.309333333333333e-07,
      "logits/chosen": -2.222238540649414,
      "logits/rejected": -2.769594430923462,
      "logps/chosen": -170.62437438964844,
      "logps/rejected": -130.28085327148438,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6824586391448975,
      "rewards/margins": 5.623382568359375,
      "rewards/rejected": -3.9409241676330566,
      "step": 2019
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.01136134285479784,
      "learning_rate": 7.308e-07,
      "logits/chosen": -2.2337112426757812,
      "logits/rejected": -3.1081204414367676,
      "logps/chosen": -135.1879425048828,
      "logps/rejected": -180.30838012695312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.038434982299805,
      "rewards/margins": 9.214926719665527,
      "rewards/rejected": -5.176491737365723,
      "step": 2020
    },
    {
      "epoch": 0.8084,
      "grad_norm": 0.1878744214773178,
      "learning_rate": 7.306666666666666e-07,
      "logits/chosen": -2.1421101093292236,
      "logits/rejected": -2.4848427772521973,
      "logps/chosen": -80.13829040527344,
      "logps/rejected": -117.86701965332031,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2073395252227783,
      "rewards/margins": 6.881916046142578,
      "rewards/rejected": -4.674576759338379,
      "step": 2021
    },
    {
      "epoch": 0.8088,
      "grad_norm": 0.05793152004480362,
      "learning_rate": 7.305333333333333e-07,
      "logits/chosen": -2.22180438041687,
      "logits/rejected": -2.73957896232605,
      "logps/chosen": -136.49935913085938,
      "logps/rejected": -206.66513061523438,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9683494567871094,
      "rewards/margins": 8.664510726928711,
      "rewards/rejected": -4.696161270141602,
      "step": 2022
    },
    {
      "epoch": 0.8092,
      "grad_norm": 0.1384723037481308,
      "learning_rate": 7.304e-07,
      "logits/chosen": -2.489401340484619,
      "logits/rejected": -3.1717453002929688,
      "logps/chosen": -195.1037139892578,
      "logps/rejected": -216.58126831054688,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8503353595733643,
      "rewards/margins": 7.995223045349121,
      "rewards/rejected": -6.144887447357178,
      "step": 2023
    },
    {
      "epoch": 0.8096,
      "grad_norm": 1.3860045671463013,
      "learning_rate": 7.302666666666666e-07,
      "logits/chosen": -2.021641969680786,
      "logits/rejected": -3.209176778793335,
      "logps/chosen": -104.08282470703125,
      "logps/rejected": -120.90489196777344,
      "loss": 0.0251,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3816051483154297,
      "rewards/margins": 3.676647186279297,
      "rewards/rejected": -3.295042037963867,
      "step": 2024
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.029933620244264603,
      "learning_rate": 7.301333333333333e-07,
      "logits/chosen": -2.278907537460327,
      "logits/rejected": -3.2988216876983643,
      "logps/chosen": -170.8638458251953,
      "logps/rejected": -160.8858642578125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3063392639160156,
      "rewards/margins": 8.380751609802246,
      "rewards/rejected": -6.0744123458862305,
      "step": 2025
    },
    {
      "epoch": 0.8104,
      "grad_norm": 0.0716085135936737,
      "learning_rate": 7.3e-07,
      "logits/chosen": -2.5918402671813965,
      "logits/rejected": -2.7902164459228516,
      "logps/chosen": -143.16329956054688,
      "logps/rejected": -146.95384216308594,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7775869369506836,
      "rewards/margins": 8.19398021697998,
      "rewards/rejected": -4.416393756866455,
      "step": 2026
    },
    {
      "epoch": 0.8108,
      "grad_norm": 0.004537233617156744,
      "learning_rate": 7.298666666666666e-07,
      "logits/chosen": -2.4421660900115967,
      "logits/rejected": -3.3090343475341797,
      "logps/chosen": -116.18252563476562,
      "logps/rejected": -166.60079956054688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.548649787902832,
      "rewards/margins": 10.164958000183105,
      "rewards/rejected": -5.616308212280273,
      "step": 2027
    },
    {
      "epoch": 0.8112,
      "grad_norm": 0.22524021565914154,
      "learning_rate": 7.297333333333333e-07,
      "logits/chosen": -1.8383667469024658,
      "logits/rejected": -2.896376609802246,
      "logps/chosen": -107.83157348632812,
      "logps/rejected": -121.12272644042969,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3929858207702637,
      "rewards/margins": 7.368831634521484,
      "rewards/rejected": -4.9758453369140625,
      "step": 2028
    },
    {
      "epoch": 0.8116,
      "grad_norm": 0.3478519320487976,
      "learning_rate": 7.296e-07,
      "logits/chosen": -2.3942596912384033,
      "logits/rejected": -3.320798397064209,
      "logps/chosen": -114.6794204711914,
      "logps/rejected": -178.5965118408203,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4949902296066284,
      "rewards/margins": 8.361289978027344,
      "rewards/rejected": -6.866299629211426,
      "step": 2029
    },
    {
      "epoch": 0.812,
      "grad_norm": 0.5179818868637085,
      "learning_rate": 7.294666666666667e-07,
      "logits/chosen": -2.297186851501465,
      "logits/rejected": -3.0185813903808594,
      "logps/chosen": -94.68064880371094,
      "logps/rejected": -135.5928955078125,
      "loss": 0.0065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.449266195297241,
      "rewards/margins": 6.836730003356934,
      "rewards/rejected": -4.387463569641113,
      "step": 2030
    },
    {
      "epoch": 0.8124,
      "grad_norm": 0.07995748519897461,
      "learning_rate": 7.293333333333332e-07,
      "logits/chosen": -2.720353126525879,
      "logits/rejected": -3.222888708114624,
      "logps/chosen": -259.0653076171875,
      "logps/rejected": -159.5015869140625,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3429665565490723,
      "rewards/margins": 7.2697672843933105,
      "rewards/rejected": -5.926800727844238,
      "step": 2031
    },
    {
      "epoch": 0.8128,
      "grad_norm": 0.02718808501958847,
      "learning_rate": 7.291999999999999e-07,
      "logits/chosen": -2.4819042682647705,
      "logits/rejected": -3.179323196411133,
      "logps/chosen": -77.87434387207031,
      "logps/rejected": -170.78829956054688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.155150890350342,
      "rewards/margins": 9.714447021484375,
      "rewards/rejected": -6.559296607971191,
      "step": 2032
    },
    {
      "epoch": 0.8132,
      "grad_norm": 0.06806143373250961,
      "learning_rate": 7.290666666666666e-07,
      "logits/chosen": -2.216029405593872,
      "logits/rejected": -2.7333831787109375,
      "logps/chosen": -103.04576110839844,
      "logps/rejected": -143.7733917236328,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.273073196411133,
      "rewards/margins": 7.418676376342773,
      "rewards/rejected": -5.145603179931641,
      "step": 2033
    },
    {
      "epoch": 0.8136,
      "grad_norm": 0.03231013938784599,
      "learning_rate": 7.289333333333333e-07,
      "logits/chosen": -2.5747334957122803,
      "logits/rejected": -3.5798959732055664,
      "logps/chosen": -207.90032958984375,
      "logps/rejected": -168.1468048095703,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.940479278564453,
      "rewards/margins": 8.568265914916992,
      "rewards/rejected": -4.627786636352539,
      "step": 2034
    },
    {
      "epoch": 0.814,
      "grad_norm": 0.019877348095178604,
      "learning_rate": 7.288e-07,
      "logits/chosen": -2.3765058517456055,
      "logits/rejected": -3.612295150756836,
      "logps/chosen": -103.95404052734375,
      "logps/rejected": -229.46409606933594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.655117988586426,
      "rewards/margins": 9.986555099487305,
      "rewards/rejected": -7.3314361572265625,
      "step": 2035
    },
    {
      "epoch": 0.8144,
      "grad_norm": 0.2896023690700531,
      "learning_rate": 7.286666666666666e-07,
      "logits/chosen": -1.7601853609085083,
      "logits/rejected": -2.5861799716949463,
      "logps/chosen": -133.25222778320312,
      "logps/rejected": -149.1905059814453,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5944507718086243,
      "rewards/margins": 7.492672920227051,
      "rewards/rejected": -6.898221969604492,
      "step": 2036
    },
    {
      "epoch": 0.8148,
      "grad_norm": 0.012936553917825222,
      "learning_rate": 7.285333333333333e-07,
      "logits/chosen": -2.331000804901123,
      "logits/rejected": -3.217291831970215,
      "logps/chosen": -84.4053726196289,
      "logps/rejected": -164.62911987304688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.163315773010254,
      "rewards/margins": 9.060503959655762,
      "rewards/rejected": -4.897188186645508,
      "step": 2037
    },
    {
      "epoch": 0.8152,
      "grad_norm": 0.03707044571638107,
      "learning_rate": 7.284e-07,
      "logits/chosen": -2.7305140495300293,
      "logits/rejected": -3.2854461669921875,
      "logps/chosen": -206.541259765625,
      "logps/rejected": -164.2650909423828,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2901909351348877,
      "rewards/margins": 8.707000732421875,
      "rewards/rejected": -5.41680908203125,
      "step": 2038
    },
    {
      "epoch": 0.8156,
      "grad_norm": 0.013089773245155811,
      "learning_rate": 7.282666666666666e-07,
      "logits/chosen": -2.346799373626709,
      "logits/rejected": -2.9758434295654297,
      "logps/chosen": -164.93759155273438,
      "logps/rejected": -180.04763793945312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3956918716430664,
      "rewards/margins": 9.329753875732422,
      "rewards/rejected": -5.9340620040893555,
      "step": 2039
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.15412987768650055,
      "learning_rate": 7.281333333333333e-07,
      "logits/chosen": -2.4721906185150146,
      "logits/rejected": -2.9862489700317383,
      "logps/chosen": -130.05111694335938,
      "logps/rejected": -149.40066528320312,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.496655225753784,
      "rewards/margins": 6.933384895324707,
      "rewards/rejected": -4.436729907989502,
      "step": 2040
    },
    {
      "epoch": 0.8164,
      "grad_norm": 0.2825670838356018,
      "learning_rate": 7.28e-07,
      "logits/chosen": -2.090428352355957,
      "logits/rejected": -3.0195701122283936,
      "logps/chosen": -120.71508026123047,
      "logps/rejected": -163.967529296875,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.270034074783325,
      "rewards/margins": 6.6923699378967285,
      "rewards/rejected": -4.422335624694824,
      "step": 2041
    },
    {
      "epoch": 0.8168,
      "grad_norm": 0.07970105856657028,
      "learning_rate": 7.278666666666666e-07,
      "logits/chosen": -2.18106746673584,
      "logits/rejected": -2.9683523178100586,
      "logps/chosen": -178.0334930419922,
      "logps/rejected": -154.9132080078125,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.383635997772217,
      "rewards/margins": 7.532651901245117,
      "rewards/rejected": -4.1490159034729,
      "step": 2042
    },
    {
      "epoch": 0.8172,
      "grad_norm": 0.007044652942568064,
      "learning_rate": 7.277333333333333e-07,
      "logits/chosen": -1.8936431407928467,
      "logits/rejected": -2.6344494819641113,
      "logps/chosen": -94.39578247070312,
      "logps/rejected": -165.70404052734375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3402013778686523,
      "rewards/margins": 9.680173873901367,
      "rewards/rejected": -7.339972496032715,
      "step": 2043
    },
    {
      "epoch": 0.8176,
      "grad_norm": 0.5300168991088867,
      "learning_rate": 7.276e-07,
      "logits/chosen": -2.563864231109619,
      "logits/rejected": -3.359492778778076,
      "logps/chosen": -175.50823974609375,
      "logps/rejected": -138.33755493164062,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9215099215507507,
      "rewards/margins": 5.963015556335449,
      "rewards/rejected": -5.041505336761475,
      "step": 2044
    },
    {
      "epoch": 0.818,
      "grad_norm": 0.005230950657278299,
      "learning_rate": 7.274666666666667e-07,
      "logits/chosen": -2.483095645904541,
      "logits/rejected": -3.3282580375671387,
      "logps/chosen": -135.18011474609375,
      "logps/rejected": -186.79916381835938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.159276008605957,
      "rewards/margins": 9.730245590209961,
      "rewards/rejected": -5.570969104766846,
      "step": 2045
    },
    {
      "epoch": 0.8184,
      "grad_norm": 0.04197850450873375,
      "learning_rate": 7.273333333333333e-07,
      "logits/chosen": -2.106095790863037,
      "logits/rejected": -2.6633713245391846,
      "logps/chosen": -141.83053588867188,
      "logps/rejected": -256.3140563964844,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6961700916290283,
      "rewards/margins": 8.209098815917969,
      "rewards/rejected": -5.5129289627075195,
      "step": 2046
    },
    {
      "epoch": 0.8188,
      "grad_norm": 0.2825341820716858,
      "learning_rate": 7.271999999999999e-07,
      "logits/chosen": -2.1353135108947754,
      "logits/rejected": -3.211698055267334,
      "logps/chosen": -104.33000183105469,
      "logps/rejected": -178.18736267089844,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0786919593811035,
      "rewards/margins": 6.873938083648682,
      "rewards/rejected": -5.795246124267578,
      "step": 2047
    },
    {
      "epoch": 0.8192,
      "grad_norm": 13.508248329162598,
      "learning_rate": 7.270666666666666e-07,
      "logits/chosen": -2.7808189392089844,
      "logits/rejected": -3.264603614807129,
      "logps/chosen": -173.86489868164062,
      "logps/rejected": -129.65325927734375,
      "loss": 0.1011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1926482915878296,
      "rewards/margins": 4.970518112182617,
      "rewards/rejected": -3.777869701385498,
      "step": 2048
    },
    {
      "epoch": 0.8196,
      "grad_norm": 0.3510120213031769,
      "learning_rate": 7.269333333333333e-07,
      "logits/chosen": -1.986743450164795,
      "logits/rejected": -3.27616024017334,
      "logps/chosen": -95.54298400878906,
      "logps/rejected": -201.0083770751953,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5075936317443848,
      "rewards/margins": 5.592685699462891,
      "rewards/rejected": -3.0850918292999268,
      "step": 2049
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.014037084765732288,
      "learning_rate": 7.268e-07,
      "logits/chosen": -2.4736380577087402,
      "logits/rejected": -3.2982945442199707,
      "logps/chosen": -111.8674545288086,
      "logps/rejected": -181.41622924804688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.331010341644287,
      "rewards/margins": 9.160094261169434,
      "rewards/rejected": -5.829083442687988,
      "step": 2050
    },
    {
      "epoch": 0.8204,
      "grad_norm": 0.00627545453608036,
      "learning_rate": 7.266666666666667e-07,
      "logits/chosen": -2.1691408157348633,
      "logits/rejected": -3.6509227752685547,
      "logps/chosen": -154.64266967773438,
      "logps/rejected": -198.75518798828125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.07094669342041,
      "rewards/margins": 10.022928237915039,
      "rewards/rejected": -5.951982498168945,
      "step": 2051
    },
    {
      "epoch": 0.8208,
      "grad_norm": 0.010838896967470646,
      "learning_rate": 7.265333333333334e-07,
      "logits/chosen": -2.1655681133270264,
      "logits/rejected": -3.0305089950561523,
      "logps/chosen": -100.32772827148438,
      "logps/rejected": -212.81993103027344,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.87477970123291,
      "rewards/margins": 10.17490005493164,
      "rewards/rejected": -7.300120830535889,
      "step": 2052
    },
    {
      "epoch": 0.8212,
      "grad_norm": 0.45464861392974854,
      "learning_rate": 7.264e-07,
      "logits/chosen": -2.1105599403381348,
      "logits/rejected": -2.537017822265625,
      "logps/chosen": -123.04537200927734,
      "logps/rejected": -109.9251708984375,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5903311967849731,
      "rewards/margins": 5.548661231994629,
      "rewards/rejected": -3.9583301544189453,
      "step": 2053
    },
    {
      "epoch": 0.8216,
      "grad_norm": 35.091861724853516,
      "learning_rate": 7.262666666666666e-07,
      "logits/chosen": -2.0596041679382324,
      "logits/rejected": -2.8597965240478516,
      "logps/chosen": -86.96630096435547,
      "logps/rejected": -112.8471450805664,
      "loss": 0.5041,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.14467203617095947,
      "rewards/margins": 3.3622961044311523,
      "rewards/rejected": -3.2176239490509033,
      "step": 2054
    },
    {
      "epoch": 0.822,
      "grad_norm": 0.493607759475708,
      "learning_rate": 7.261333333333332e-07,
      "logits/chosen": -2.1895322799682617,
      "logits/rejected": -3.3540921211242676,
      "logps/chosen": -128.1400146484375,
      "logps/rejected": -153.7774658203125,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.44159966707229614,
      "rewards/margins": 6.218915939331055,
      "rewards/rejected": -5.777316093444824,
      "step": 2055
    },
    {
      "epoch": 0.8224,
      "grad_norm": 0.08220769464969635,
      "learning_rate": 7.259999999999999e-07,
      "logits/chosen": -2.7768077850341797,
      "logits/rejected": -2.8429133892059326,
      "logps/chosen": -165.94105529785156,
      "logps/rejected": -147.2458953857422,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8208099603652954,
      "rewards/margins": 7.139915466308594,
      "rewards/rejected": -5.31910514831543,
      "step": 2056
    },
    {
      "epoch": 0.8228,
      "grad_norm": 0.014149848371744156,
      "learning_rate": 7.258666666666666e-07,
      "logits/chosen": -2.311047077178955,
      "logits/rejected": -3.3179831504821777,
      "logps/chosen": -121.51908874511719,
      "logps/rejected": -156.9288330078125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.095361709594727,
      "rewards/margins": 8.588592529296875,
      "rewards/rejected": -4.493230819702148,
      "step": 2057
    },
    {
      "epoch": 0.8232,
      "grad_norm": 0.5390204787254333,
      "learning_rate": 7.257333333333333e-07,
      "logits/chosen": -2.8541383743286133,
      "logits/rejected": -3.198784112930298,
      "logps/chosen": -133.01797485351562,
      "logps/rejected": -115.51036071777344,
      "loss": 0.0065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2742462158203125,
      "rewards/margins": 5.210640907287598,
      "rewards/rejected": -2.9363949298858643,
      "step": 2058
    },
    {
      "epoch": 0.8236,
      "grad_norm": 2.431135416030884,
      "learning_rate": 7.256e-07,
      "logits/chosen": -2.1815624237060547,
      "logits/rejected": -2.644771099090576,
      "logps/chosen": -192.06997680664062,
      "logps/rejected": -156.33839416503906,
      "loss": 0.0207,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2983726263046265,
      "rewards/margins": 5.4779558181762695,
      "rewards/rejected": -4.179583549499512,
      "step": 2059
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.062195174396038055,
      "learning_rate": 7.254666666666667e-07,
      "logits/chosen": -1.8113293647766113,
      "logits/rejected": -3.616389274597168,
      "logps/chosen": -62.05147171020508,
      "logps/rejected": -160.23794555664062,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1427364349365234,
      "rewards/margins": 7.528604507446289,
      "rewards/rejected": -5.385868072509766,
      "step": 2060
    },
    {
      "epoch": 0.8244,
      "grad_norm": 0.01029650866985321,
      "learning_rate": 7.253333333333334e-07,
      "logits/chosen": -1.9413831233978271,
      "logits/rejected": -3.59323787689209,
      "logps/chosen": -139.474853515625,
      "logps/rejected": -154.0756378173828,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.217634677886963,
      "rewards/margins": 9.468375205993652,
      "rewards/rejected": -7.2507405281066895,
      "step": 2061
    },
    {
      "epoch": 0.8248,
      "grad_norm": 0.04287586733698845,
      "learning_rate": 7.252e-07,
      "logits/chosen": -2.5814640522003174,
      "logits/rejected": -3.1891984939575195,
      "logps/chosen": -168.17852783203125,
      "logps/rejected": -139.8725128173828,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1814780235290527,
      "rewards/margins": 8.236993789672852,
      "rewards/rejected": -5.055515289306641,
      "step": 2062
    },
    {
      "epoch": 0.8252,
      "grad_norm": 0.0843287780880928,
      "learning_rate": 7.250666666666666e-07,
      "logits/chosen": -2.1792869567871094,
      "logits/rejected": -2.9997811317443848,
      "logps/chosen": -153.36961364746094,
      "logps/rejected": -157.27655029296875,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.934539556503296,
      "rewards/margins": 7.112905025482178,
      "rewards/rejected": -5.178365707397461,
      "step": 2063
    },
    {
      "epoch": 0.8256,
      "grad_norm": 0.024620965123176575,
      "learning_rate": 7.249333333333332e-07,
      "logits/chosen": -2.883737087249756,
      "logits/rejected": -3.39492130279541,
      "logps/chosen": -197.34925842285156,
      "logps/rejected": -194.3761444091797,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1895365715026855,
      "rewards/margins": 8.745857238769531,
      "rewards/rejected": -5.556321144104004,
      "step": 2064
    },
    {
      "epoch": 0.826,
      "grad_norm": 1.0569701194763184,
      "learning_rate": 7.247999999999999e-07,
      "logits/chosen": -2.1354925632476807,
      "logits/rejected": -3.133502721786499,
      "logps/chosen": -132.5045166015625,
      "logps/rejected": -172.92742919921875,
      "loss": 0.0137,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8650264739990234,
      "rewards/margins": 7.115322113037109,
      "rewards/rejected": -5.250296115875244,
      "step": 2065
    },
    {
      "epoch": 0.8264,
      "grad_norm": 0.020963648334145546,
      "learning_rate": 7.246666666666666e-07,
      "logits/chosen": -1.8781442642211914,
      "logits/rejected": -3.255870819091797,
      "logps/chosen": -138.910400390625,
      "logps/rejected": -172.1749725341797,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.725278615951538,
      "rewards/margins": 8.418596267700195,
      "rewards/rejected": -6.693317413330078,
      "step": 2066
    },
    {
      "epoch": 0.8268,
      "grad_norm": 0.5839645266532898,
      "learning_rate": 7.245333333333333e-07,
      "logits/chosen": -1.919102430343628,
      "logits/rejected": -3.030971050262451,
      "logps/chosen": -117.66613006591797,
      "logps/rejected": -144.9873504638672,
      "loss": 0.0052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7534255981445312,
      "rewards/margins": 7.663887977600098,
      "rewards/rejected": -4.910462379455566,
      "step": 2067
    },
    {
      "epoch": 0.8272,
      "grad_norm": 0.1848231703042984,
      "learning_rate": 7.244e-07,
      "logits/chosen": -1.967153787612915,
      "logits/rejected": -3.420264482498169,
      "logps/chosen": -150.7670135498047,
      "logps/rejected": -192.46658325195312,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1386516094207764,
      "rewards/margins": 7.667369842529297,
      "rewards/rejected": -5.528717994689941,
      "step": 2068
    },
    {
      "epoch": 0.8276,
      "grad_norm": 0.07588589191436768,
      "learning_rate": 7.242666666666666e-07,
      "logits/chosen": -1.9796068668365479,
      "logits/rejected": -2.8736767768859863,
      "logps/chosen": -97.39485931396484,
      "logps/rejected": -159.97909545898438,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9259984493255615,
      "rewards/margins": 7.215798854827881,
      "rewards/rejected": -5.289800643920898,
      "step": 2069
    },
    {
      "epoch": 0.828,
      "grad_norm": 0.10182762145996094,
      "learning_rate": 7.241333333333333e-07,
      "logits/chosen": -2.0979371070861816,
      "logits/rejected": -2.9068055152893066,
      "logps/chosen": -89.21752166748047,
      "logps/rejected": -144.39767456054688,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3045458793640137,
      "rewards/margins": 6.644903659820557,
      "rewards/rejected": -4.340357780456543,
      "step": 2070
    },
    {
      "epoch": 0.8284,
      "grad_norm": 0.01033917535096407,
      "learning_rate": 7.24e-07,
      "logits/chosen": -2.3215389251708984,
      "logits/rejected": -3.258525848388672,
      "logps/chosen": -86.3365478515625,
      "logps/rejected": -136.68817138671875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.195339679718018,
      "rewards/margins": 9.174501419067383,
      "rewards/rejected": -4.979162216186523,
      "step": 2071
    },
    {
      "epoch": 0.8288,
      "grad_norm": 0.30496400594711304,
      "learning_rate": 7.238666666666667e-07,
      "logits/chosen": -2.6739532947540283,
      "logits/rejected": -3.252037525177002,
      "logps/chosen": -206.68438720703125,
      "logps/rejected": -186.15640258789062,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.675743579864502,
      "rewards/margins": 8.579534530639648,
      "rewards/rejected": -5.903791427612305,
      "step": 2072
    },
    {
      "epoch": 0.8292,
      "grad_norm": 0.06330033391714096,
      "learning_rate": 7.237333333333334e-07,
      "logits/chosen": -1.9381191730499268,
      "logits/rejected": -2.461886405944824,
      "logps/chosen": -72.06851196289062,
      "logps/rejected": -123.01355743408203,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.29276967048645,
      "rewards/margins": 7.925257682800293,
      "rewards/rejected": -4.632487773895264,
      "step": 2073
    },
    {
      "epoch": 0.8296,
      "grad_norm": 0.053904201835393906,
      "learning_rate": 7.235999999999999e-07,
      "logits/chosen": -2.3744957447052,
      "logits/rejected": -3.095306873321533,
      "logps/chosen": -159.478515625,
      "logps/rejected": -159.62596130371094,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.371675968170166,
      "rewards/margins": 8.385147094726562,
      "rewards/rejected": -6.013471603393555,
      "step": 2074
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.4935993254184723,
      "learning_rate": 7.234666666666666e-07,
      "logits/chosen": -2.2218942642211914,
      "logits/rejected": -2.6709396839141846,
      "logps/chosen": -102.82577514648438,
      "logps/rejected": -169.37933349609375,
      "loss": 0.0048,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6710119247436523,
      "rewards/margins": 7.2710466384887695,
      "rewards/rejected": -4.600035190582275,
      "step": 2075
    },
    {
      "epoch": 0.8304,
      "grad_norm": 0.6673961877822876,
      "learning_rate": 7.233333333333333e-07,
      "logits/chosen": -2.3308162689208984,
      "logits/rejected": -2.8560142517089844,
      "logps/chosen": -147.920166015625,
      "logps/rejected": -193.41831970214844,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5122146606445312,
      "rewards/margins": 8.252166748046875,
      "rewards/rejected": -5.7399516105651855,
      "step": 2076
    },
    {
      "epoch": 0.8308,
      "grad_norm": 0.1904277801513672,
      "learning_rate": 7.231999999999999e-07,
      "logits/chosen": -1.8557647466659546,
      "logits/rejected": -3.145977020263672,
      "logps/chosen": -112.39671325683594,
      "logps/rejected": -160.8363494873047,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4294044971466064,
      "rewards/margins": 7.905463218688965,
      "rewards/rejected": -6.476058006286621,
      "step": 2077
    },
    {
      "epoch": 0.8312,
      "grad_norm": 0.040802229195833206,
      "learning_rate": 7.230666666666666e-07,
      "logits/chosen": -1.9015488624572754,
      "logits/rejected": -3.167186737060547,
      "logps/chosen": -92.89175415039062,
      "logps/rejected": -165.7765655517578,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.98301362991333,
      "rewards/margins": 8.902872085571289,
      "rewards/rejected": -5.919858932495117,
      "step": 2078
    },
    {
      "epoch": 0.8316,
      "grad_norm": 0.027926530689001083,
      "learning_rate": 7.229333333333333e-07,
      "logits/chosen": -2.038088798522949,
      "logits/rejected": -3.1336283683776855,
      "logps/chosen": -151.10165405273438,
      "logps/rejected": -169.71739196777344,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7994279861450195,
      "rewards/margins": 9.294370651245117,
      "rewards/rejected": -6.4949421882629395,
      "step": 2079
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.019823895767331123,
      "learning_rate": 7.228e-07,
      "logits/chosen": -2.451575517654419,
      "logits/rejected": -3.4874634742736816,
      "logps/chosen": -81.2077865600586,
      "logps/rejected": -133.2215118408203,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7406692504882812,
      "rewards/margins": 8.310701370239258,
      "rewards/rejected": -4.570032119750977,
      "step": 2080
    },
    {
      "epoch": 0.8324,
      "grad_norm": 0.025836238637566566,
      "learning_rate": 7.226666666666667e-07,
      "logits/chosen": -2.322348117828369,
      "logits/rejected": -3.0582756996154785,
      "logps/chosen": -93.46029663085938,
      "logps/rejected": -125.64389038085938,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5165963172912598,
      "rewards/margins": 8.403618812561035,
      "rewards/rejected": -4.887022495269775,
      "step": 2081
    },
    {
      "epoch": 0.8328,
      "grad_norm": 0.006587618961930275,
      "learning_rate": 7.225333333333334e-07,
      "logits/chosen": -1.8472349643707275,
      "logits/rejected": -2.835202693939209,
      "logps/chosen": -200.8995819091797,
      "logps/rejected": -280.5631408691406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.973654270172119,
      "rewards/margins": 11.303662300109863,
      "rewards/rejected": -7.330008506774902,
      "step": 2082
    },
    {
      "epoch": 0.8332,
      "grad_norm": 0.25428542494773865,
      "learning_rate": 7.224e-07,
      "logits/chosen": -2.369262933731079,
      "logits/rejected": -3.131704568862915,
      "logps/chosen": -145.74256896972656,
      "logps/rejected": -265.55810546875,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4468917846679688,
      "rewards/margins": 7.584820747375488,
      "rewards/rejected": -5.1379289627075195,
      "step": 2083
    },
    {
      "epoch": 0.8336,
      "grad_norm": 0.048411451280117035,
      "learning_rate": 7.222666666666665e-07,
      "logits/chosen": -2.5805373191833496,
      "logits/rejected": -2.842881202697754,
      "logps/chosen": -118.80679321289062,
      "logps/rejected": -196.67007446289062,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.050422191619873,
      "rewards/margins": 8.193719863891602,
      "rewards/rejected": -5.1432976722717285,
      "step": 2084
    },
    {
      "epoch": 0.834,
      "grad_norm": 1.8577090501785278,
      "learning_rate": 7.221333333333332e-07,
      "logits/chosen": -2.255676746368408,
      "logits/rejected": -2.9825873374938965,
      "logps/chosen": -102.64140319824219,
      "logps/rejected": -153.46939086914062,
      "loss": 0.01,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.662853479385376,
      "rewards/margins": 7.365786552429199,
      "rewards/rejected": -5.702932834625244,
      "step": 2085
    },
    {
      "epoch": 0.8344,
      "grad_norm": 0.08043143153190613,
      "learning_rate": 7.219999999999999e-07,
      "logits/chosen": -2.2151565551757812,
      "logits/rejected": -2.9202864170074463,
      "logps/chosen": -113.52566528320312,
      "logps/rejected": -148.0102996826172,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.990551471710205,
      "rewards/margins": 7.979440689086914,
      "rewards/rejected": -5.988889694213867,
      "step": 2086
    },
    {
      "epoch": 0.8348,
      "grad_norm": 0.23509693145751953,
      "learning_rate": 7.218666666666666e-07,
      "logits/chosen": -2.2157278060913086,
      "logits/rejected": -3.7219738960266113,
      "logps/chosen": -112.63214111328125,
      "logps/rejected": -154.38821411132812,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.138331651687622,
      "rewards/margins": 7.477415084838867,
      "rewards/rejected": -5.339083671569824,
      "step": 2087
    },
    {
      "epoch": 0.8352,
      "grad_norm": 0.3430801331996918,
      "learning_rate": 7.217333333333333e-07,
      "logits/chosen": -2.5176851749420166,
      "logits/rejected": -2.9704248905181885,
      "logps/chosen": -212.6205596923828,
      "logps/rejected": -140.11465454101562,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1621193885803223,
      "rewards/margins": 6.900064468383789,
      "rewards/rejected": -5.737945556640625,
      "step": 2088
    },
    {
      "epoch": 0.8356,
      "grad_norm": 2.0277504920959473,
      "learning_rate": 7.216e-07,
      "logits/chosen": -2.1665198802948,
      "logits/rejected": -2.861588478088379,
      "logps/chosen": -134.21200561523438,
      "logps/rejected": -136.75393676757812,
      "loss": 0.01,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6106598377227783,
      "rewards/margins": 6.261435508728027,
      "rewards/rejected": -3.650775909423828,
      "step": 2089
    },
    {
      "epoch": 0.836,
      "grad_norm": 0.3892325460910797,
      "learning_rate": 7.214666666666667e-07,
      "logits/chosen": -2.567126989364624,
      "logits/rejected": -2.5492939949035645,
      "logps/chosen": -124.90318298339844,
      "logps/rejected": -117.43717956542969,
      "loss": 0.0057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6468746662139893,
      "rewards/margins": 5.335170745849609,
      "rewards/rejected": -3.688295841217041,
      "step": 2090
    },
    {
      "epoch": 0.8364,
      "grad_norm": 0.14623214304447174,
      "learning_rate": 7.213333333333334e-07,
      "logits/chosen": -1.743947148323059,
      "logits/rejected": -3.006793260574341,
      "logps/chosen": -81.08946990966797,
      "logps/rejected": -157.5113525390625,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6645199060440063,
      "rewards/margins": 7.249054431915283,
      "rewards/rejected": -5.584534645080566,
      "step": 2091
    },
    {
      "epoch": 0.8368,
      "grad_norm": 0.22209645807743073,
      "learning_rate": 7.211999999999999e-07,
      "logits/chosen": -2.153064012527466,
      "logits/rejected": -3.4555819034576416,
      "logps/chosen": -138.96484375,
      "logps/rejected": -149.771728515625,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.354238986968994,
      "rewards/margins": 7.276924133300781,
      "rewards/rejected": -4.922685623168945,
      "step": 2092
    },
    {
      "epoch": 0.8372,
      "grad_norm": 0.07421964406967163,
      "learning_rate": 7.210666666666666e-07,
      "logits/chosen": -1.965416669845581,
      "logits/rejected": -2.8706283569335938,
      "logps/chosen": -91.47808837890625,
      "logps/rejected": -125.61763000488281,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9506301879882812,
      "rewards/margins": 7.982441425323486,
      "rewards/rejected": -5.031811237335205,
      "step": 2093
    },
    {
      "epoch": 0.8376,
      "grad_norm": 0.09550692141056061,
      "learning_rate": 7.209333333333333e-07,
      "logits/chosen": -2.4894862174987793,
      "logits/rejected": -2.690781593322754,
      "logps/chosen": -90.23861694335938,
      "logps/rejected": -187.76602172851562,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8280200958251953,
      "rewards/margins": 8.431100845336914,
      "rewards/rejected": -4.6030802726745605,
      "step": 2094
    },
    {
      "epoch": 0.838,
      "grad_norm": 0.0041077327914536,
      "learning_rate": 7.207999999999999e-07,
      "logits/chosen": -2.035670042037964,
      "logits/rejected": -2.905832529067993,
      "logps/chosen": -144.2915496826172,
      "logps/rejected": -168.24998474121094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.153909683227539,
      "rewards/margins": 10.221540451049805,
      "rewards/rejected": -6.067630767822266,
      "step": 2095
    },
    {
      "epoch": 0.8384,
      "grad_norm": 0.007911616936326027,
      "learning_rate": 7.206666666666666e-07,
      "logits/chosen": -1.5800414085388184,
      "logits/rejected": -3.808541774749756,
      "logps/chosen": -95.77165222167969,
      "logps/rejected": -200.9261474609375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.009280204772949,
      "rewards/margins": 9.629997253417969,
      "rewards/rejected": -5.6207170486450195,
      "step": 2096
    },
    {
      "epoch": 0.8388,
      "grad_norm": 1.5734120607376099,
      "learning_rate": 7.205333333333333e-07,
      "logits/chosen": -1.9407529830932617,
      "logits/rejected": -3.45515775680542,
      "logps/chosen": -115.9686279296875,
      "logps/rejected": -209.8317108154297,
      "loss": 0.0083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3532695472240448,
      "rewards/margins": 6.160867691040039,
      "rewards/rejected": -6.514137268066406,
      "step": 2097
    },
    {
      "epoch": 0.8392,
      "grad_norm": 0.30694520473480225,
      "learning_rate": 7.204e-07,
      "logits/chosen": -2.308140277862549,
      "logits/rejected": -3.0310840606689453,
      "logps/chosen": -119.3799057006836,
      "logps/rejected": -133.5887451171875,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9798249006271362,
      "rewards/margins": 6.263829231262207,
      "rewards/rejected": -4.2840046882629395,
      "step": 2098
    },
    {
      "epoch": 0.8396,
      "grad_norm": 0.45013442635536194,
      "learning_rate": 7.202666666666667e-07,
      "logits/chosen": -2.581207752227783,
      "logits/rejected": -3.325648784637451,
      "logps/chosen": -151.13363647460938,
      "logps/rejected": -130.70571899414062,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1080026626586914,
      "rewards/margins": 6.166454315185547,
      "rewards/rejected": -4.0584516525268555,
      "step": 2099
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.28142720460891724,
      "learning_rate": 7.201333333333333e-07,
      "logits/chosen": -1.8336000442504883,
      "logits/rejected": -2.4984731674194336,
      "logps/chosen": -93.22216796875,
      "logps/rejected": -116.59281158447266,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8569507598876953,
      "rewards/margins": 7.711945056915283,
      "rewards/rejected": -3.854994297027588,
      "step": 2100
    },
    {
      "epoch": 0.8404,
      "grad_norm": 0.008694957010447979,
      "learning_rate": 7.2e-07,
      "logits/chosen": -2.1527669429779053,
      "logits/rejected": -2.771078586578369,
      "logps/chosen": -104.73391723632812,
      "logps/rejected": -144.1501007080078,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.451578140258789,
      "rewards/margins": 9.422074317932129,
      "rewards/rejected": -5.97049617767334,
      "step": 2101
    },
    {
      "epoch": 0.8408,
      "grad_norm": 0.17619958519935608,
      "learning_rate": 7.198666666666666e-07,
      "logits/chosen": -2.254082202911377,
      "logits/rejected": -3.328056812286377,
      "logps/chosen": -81.87913513183594,
      "logps/rejected": -158.14450073242188,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.739081621170044,
      "rewards/margins": 7.38714599609375,
      "rewards/rejected": -5.648064613342285,
      "step": 2102
    },
    {
      "epoch": 0.8412,
      "grad_norm": 0.010290687903761864,
      "learning_rate": 7.197333333333333e-07,
      "logits/chosen": -2.1459460258483887,
      "logits/rejected": -3.420071601867676,
      "logps/chosen": -112.37513732910156,
      "logps/rejected": -237.50643920898438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6939005851745605,
      "rewards/margins": 9.61220932006836,
      "rewards/rejected": -5.918308258056641,
      "step": 2103
    },
    {
      "epoch": 0.8416,
      "grad_norm": 0.12076128274202347,
      "learning_rate": 7.196e-07,
      "logits/chosen": -2.2691776752471924,
      "logits/rejected": -3.1406943798065186,
      "logps/chosen": -96.40489196777344,
      "logps/rejected": -139.1816864013672,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.635535717010498,
      "rewards/margins": 7.9404706954956055,
      "rewards/rejected": -5.304934501647949,
      "step": 2104
    },
    {
      "epoch": 0.842,
      "grad_norm": 0.04224838688969612,
      "learning_rate": 7.194666666666667e-07,
      "logits/chosen": -1.9207878112792969,
      "logits/rejected": -3.1026790142059326,
      "logps/chosen": -122.94583892822266,
      "logps/rejected": -138.7127685546875,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.360093116760254,
      "rewards/margins": 8.263069152832031,
      "rewards/rejected": -4.902975559234619,
      "step": 2105
    },
    {
      "epoch": 0.8424,
      "grad_norm": 0.08417552709579468,
      "learning_rate": 7.193333333333333e-07,
      "logits/chosen": -2.1589484214782715,
      "logits/rejected": -2.899758815765381,
      "logps/chosen": -206.99659729003906,
      "logps/rejected": -142.2993621826172,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.012329578399658,
      "rewards/margins": 7.169094085693359,
      "rewards/rejected": -5.156764030456543,
      "step": 2106
    },
    {
      "epoch": 0.8428,
      "grad_norm": 0.7772648334503174,
      "learning_rate": 7.191999999999999e-07,
      "logits/chosen": -1.9733675718307495,
      "logits/rejected": -2.798327922821045,
      "logps/chosen": -116.39383697509766,
      "logps/rejected": -129.37155151367188,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0991477966308594,
      "rewards/margins": 7.167072296142578,
      "rewards/rejected": -5.067924499511719,
      "step": 2107
    },
    {
      "epoch": 0.8432,
      "grad_norm": 0.043077245354652405,
      "learning_rate": 7.190666666666666e-07,
      "logits/chosen": -2.095726490020752,
      "logits/rejected": -2.4253082275390625,
      "logps/chosen": -80.3134994506836,
      "logps/rejected": -116.98780822753906,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.572086811065674,
      "rewards/margins": 7.725781440734863,
      "rewards/rejected": -5.1536946296691895,
      "step": 2108
    },
    {
      "epoch": 0.8436,
      "grad_norm": 0.23584148287773132,
      "learning_rate": 7.189333333333333e-07,
      "logits/chosen": -2.769896984100342,
      "logits/rejected": -3.202239513397217,
      "logps/chosen": -239.28793334960938,
      "logps/rejected": -174.0440673828125,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.695014238357544,
      "rewards/margins": 6.072197914123535,
      "rewards/rejected": -4.377183437347412,
      "step": 2109
    },
    {
      "epoch": 0.844,
      "grad_norm": 0.15140122175216675,
      "learning_rate": 7.188e-07,
      "logits/chosen": -1.4703679084777832,
      "logits/rejected": -2.4402971267700195,
      "logps/chosen": -74.15546417236328,
      "logps/rejected": -118.79138946533203,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7555932998657227,
      "rewards/margins": 7.099039077758789,
      "rewards/rejected": -4.343445777893066,
      "step": 2110
    },
    {
      "epoch": 0.8444,
      "grad_norm": 0.10094933211803436,
      "learning_rate": 7.186666666666667e-07,
      "logits/chosen": -2.3436365127563477,
      "logits/rejected": -2.895754814147949,
      "logps/chosen": -84.43287658691406,
      "logps/rejected": -130.3055419921875,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.163630723953247,
      "rewards/margins": 7.0375847816467285,
      "rewards/rejected": -4.873953819274902,
      "step": 2111
    },
    {
      "epoch": 0.8448,
      "grad_norm": 0.031852561980485916,
      "learning_rate": 7.185333333333333e-07,
      "logits/chosen": -2.1664271354675293,
      "logits/rejected": -3.004020929336548,
      "logps/chosen": -135.66468811035156,
      "logps/rejected": -138.45529174804688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1996281147003174,
      "rewards/margins": 8.396610260009766,
      "rewards/rejected": -5.196982383728027,
      "step": 2112
    },
    {
      "epoch": 0.8452,
      "grad_norm": 0.050164852291345596,
      "learning_rate": 7.184e-07,
      "logits/chosen": -2.0537357330322266,
      "logits/rejected": -3.1679728031158447,
      "logps/chosen": -132.90060424804688,
      "logps/rejected": -149.3570098876953,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3039498329162598,
      "rewards/margins": 8.19347095489502,
      "rewards/rejected": -5.88952112197876,
      "step": 2113
    },
    {
      "epoch": 0.8456,
      "grad_norm": 0.023362111300230026,
      "learning_rate": 7.182666666666667e-07,
      "logits/chosen": -1.7836058139801025,
      "logits/rejected": -3.2258362770080566,
      "logps/chosen": -93.6331558227539,
      "logps/rejected": -163.85433959960938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3281418085098267,
      "rewards/margins": 8.640440940856934,
      "rewards/rejected": -7.3122992515563965,
      "step": 2114
    },
    {
      "epoch": 0.846,
      "grad_norm": 0.04920775815844536,
      "learning_rate": 7.181333333333333e-07,
      "logits/chosen": -2.4607067108154297,
      "logits/rejected": -2.3932526111602783,
      "logps/chosen": -130.16574096679688,
      "logps/rejected": -184.1229705810547,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.323791742324829,
      "rewards/margins": 9.983369827270508,
      "rewards/rejected": -7.6595778465271,
      "step": 2115
    },
    {
      "epoch": 0.8464,
      "grad_norm": 0.3975047171115875,
      "learning_rate": 7.179999999999999e-07,
      "logits/chosen": -1.875230312347412,
      "logits/rejected": -3.279385566711426,
      "logps/chosen": -57.45616912841797,
      "logps/rejected": -145.62750244140625,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8839631080627441,
      "rewards/margins": 6.622353553771973,
      "rewards/rejected": -4.7383904457092285,
      "step": 2116
    },
    {
      "epoch": 0.8468,
      "grad_norm": 4.867856979370117,
      "learning_rate": 7.178666666666666e-07,
      "logits/chosen": -2.618870735168457,
      "logits/rejected": -3.2019429206848145,
      "logps/chosen": -156.677978515625,
      "logps/rejected": -149.34751892089844,
      "loss": 0.0415,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3533637523651123,
      "rewards/margins": 5.7668023109436035,
      "rewards/rejected": -5.41343879699707,
      "step": 2117
    },
    {
      "epoch": 0.8472,
      "grad_norm": 0.03771436959505081,
      "learning_rate": 7.177333333333333e-07,
      "logits/chosen": -2.607640504837036,
      "logits/rejected": -3.0817971229553223,
      "logps/chosen": -112.12017059326172,
      "logps/rejected": -163.96707153320312,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.195377826690674,
      "rewards/margins": 8.389351844787598,
      "rewards/rejected": -6.193974494934082,
      "step": 2118
    },
    {
      "epoch": 0.8476,
      "grad_norm": 0.1256408542394638,
      "learning_rate": 7.176e-07,
      "logits/chosen": -2.028512954711914,
      "logits/rejected": -3.6363301277160645,
      "logps/chosen": -122.89030456542969,
      "logps/rejected": -188.20809936523438,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.756784439086914,
      "rewards/margins": 8.53812026977539,
      "rewards/rejected": -5.781335830688477,
      "step": 2119
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.19019833207130432,
      "learning_rate": 7.174666666666667e-07,
      "logits/chosen": -1.8932952880859375,
      "logits/rejected": -3.136693000793457,
      "logps/chosen": -91.18070220947266,
      "logps/rejected": -155.3094940185547,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.665761709213257,
      "rewards/margins": 8.09739875793457,
      "rewards/rejected": -5.431637763977051,
      "step": 2120
    },
    {
      "epoch": 0.8484,
      "grad_norm": 0.0029107891023159027,
      "learning_rate": 7.173333333333333e-07,
      "logits/chosen": -2.1260251998901367,
      "logits/rejected": -3.1105432510375977,
      "logps/chosen": -131.67037963867188,
      "logps/rejected": -194.14199829101562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.201526641845703,
      "rewards/margins": 10.595134735107422,
      "rewards/rejected": -6.393608093261719,
      "step": 2121
    },
    {
      "epoch": 0.8488,
      "grad_norm": 0.025475123897194862,
      "learning_rate": 7.171999999999999e-07,
      "logits/chosen": -1.9533145427703857,
      "logits/rejected": -2.972355365753174,
      "logps/chosen": -88.98311614990234,
      "logps/rejected": -171.07778930664062,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5747365951538086,
      "rewards/margins": 9.457805633544922,
      "rewards/rejected": -5.883069038391113,
      "step": 2122
    },
    {
      "epoch": 0.8492,
      "grad_norm": 0.12452400475740433,
      "learning_rate": 7.170666666666666e-07,
      "logits/chosen": -2.6143064498901367,
      "logits/rejected": -3.0572712421417236,
      "logps/chosen": -130.181640625,
      "logps/rejected": -118.40571594238281,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.040271520614624,
      "rewards/margins": 6.5123209953308105,
      "rewards/rejected": -4.472049713134766,
      "step": 2123
    },
    {
      "epoch": 0.8496,
      "grad_norm": 0.008374682627618313,
      "learning_rate": 7.169333333333333e-07,
      "logits/chosen": -1.9605759382247925,
      "logits/rejected": -3.3422837257385254,
      "logps/chosen": -114.59236145019531,
      "logps/rejected": -152.1580810546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.095828533172607,
      "rewards/margins": 9.758773803710938,
      "rewards/rejected": -5.662945747375488,
      "step": 2124
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.23591919243335724,
      "learning_rate": 7.168e-07,
      "logits/chosen": -1.5972115993499756,
      "logits/rejected": -3.0839004516601562,
      "logps/chosen": -179.937255859375,
      "logps/rejected": -159.1043701171875,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2051589488983154,
      "rewards/margins": 7.715899467468262,
      "rewards/rejected": -5.510740756988525,
      "step": 2125
    },
    {
      "epoch": 0.8504,
      "grad_norm": 0.003620623843744397,
      "learning_rate": 7.166666666666667e-07,
      "logits/chosen": -2.525972843170166,
      "logits/rejected": -3.102775812149048,
      "logps/chosen": -139.37667846679688,
      "logps/rejected": -150.63162231445312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.129482746124268,
      "rewards/margins": 10.127684593200684,
      "rewards/rejected": -5.998201847076416,
      "step": 2126
    },
    {
      "epoch": 0.8508,
      "grad_norm": 0.14872027933597565,
      "learning_rate": 7.165333333333333e-07,
      "logits/chosen": -2.415347099304199,
      "logits/rejected": -3.3480417728424072,
      "logps/chosen": -112.18206024169922,
      "logps/rejected": -241.8856201171875,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1663966178894043,
      "rewards/margins": 6.679014205932617,
      "rewards/rejected": -4.512617111206055,
      "step": 2127
    },
    {
      "epoch": 0.8512,
      "grad_norm": 3.0619451999664307,
      "learning_rate": 7.164e-07,
      "logits/chosen": -2.1941075325012207,
      "logits/rejected": -3.0612449645996094,
      "logps/chosen": -173.70689392089844,
      "logps/rejected": -306.33673095703125,
      "loss": 0.0302,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6421764492988586,
      "rewards/margins": 6.316934585571289,
      "rewards/rejected": -5.674757957458496,
      "step": 2128
    },
    {
      "epoch": 0.8516,
      "grad_norm": 0.254525750875473,
      "learning_rate": 7.162666666666667e-07,
      "logits/chosen": -1.9643850326538086,
      "logits/rejected": -2.5416762828826904,
      "logps/chosen": -109.74192810058594,
      "logps/rejected": -123.40292358398438,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6971927881240845,
      "rewards/margins": 6.029294013977051,
      "rewards/rejected": -4.332101345062256,
      "step": 2129
    },
    {
      "epoch": 0.852,
      "grad_norm": 0.08849568665027618,
      "learning_rate": 7.161333333333332e-07,
      "logits/chosen": -2.393533706665039,
      "logits/rejected": -2.9041357040405273,
      "logps/chosen": -78.88885498046875,
      "logps/rejected": -153.66366577148438,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.35615873336792,
      "rewards/margins": 7.8348612785339355,
      "rewards/rejected": -4.478702545166016,
      "step": 2130
    },
    {
      "epoch": 0.8524,
      "grad_norm": 0.013176267966628075,
      "learning_rate": 7.159999999999999e-07,
      "logits/chosen": -2.6014668941497803,
      "logits/rejected": -3.3242287635803223,
      "logps/chosen": -128.90939331054688,
      "logps/rejected": -192.0370635986328,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1815288066864014,
      "rewards/margins": 9.08798599243164,
      "rewards/rejected": -5.906457424163818,
      "step": 2131
    },
    {
      "epoch": 0.8528,
      "grad_norm": 11.399519920349121,
      "learning_rate": 7.158666666666666e-07,
      "logits/chosen": -1.8024401664733887,
      "logits/rejected": -2.467653751373291,
      "logps/chosen": -103.71896362304688,
      "logps/rejected": -123.24262237548828,
      "loss": 0.0728,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.05669105052947998,
      "rewards/margins": 4.716607093811035,
      "rewards/rejected": -4.773298263549805,
      "step": 2132
    },
    {
      "epoch": 0.8532,
      "grad_norm": 0.4177187979221344,
      "learning_rate": 7.157333333333333e-07,
      "logits/chosen": -2.0927734375,
      "logits/rejected": -3.4738874435424805,
      "logps/chosen": -87.43971252441406,
      "logps/rejected": -138.96817016601562,
      "loss": 0.005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8061295747756958,
      "rewards/margins": 6.655747413635254,
      "rewards/rejected": -4.849617958068848,
      "step": 2133
    },
    {
      "epoch": 0.8536,
      "grad_norm": 0.09940945357084274,
      "learning_rate": 7.156e-07,
      "logits/chosen": -1.8202886581420898,
      "logits/rejected": -3.0390217304229736,
      "logps/chosen": -134.884033203125,
      "logps/rejected": -175.18161010742188,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0716034173965454,
      "rewards/margins": 7.338186264038086,
      "rewards/rejected": -6.26658296585083,
      "step": 2134
    },
    {
      "epoch": 0.854,
      "grad_norm": 1.114751935005188,
      "learning_rate": 7.154666666666667e-07,
      "logits/chosen": -2.0665371417999268,
      "logits/rejected": -2.6359002590179443,
      "logps/chosen": -117.08416748046875,
      "logps/rejected": -217.32582092285156,
      "loss": 0.0111,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4321987628936768,
      "rewards/margins": 5.404543876647949,
      "rewards/rejected": -3.9723448753356934,
      "step": 2135
    },
    {
      "epoch": 0.8544,
      "grad_norm": 8.758878707885742,
      "learning_rate": 7.153333333333334e-07,
      "logits/chosen": -2.242377996444702,
      "logits/rejected": -2.4995951652526855,
      "logps/chosen": -103.25286865234375,
      "logps/rejected": -93.99790954589844,
      "loss": 0.1019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6915683746337891,
      "rewards/margins": 2.393165111541748,
      "rewards/rejected": -1.7015968561172485,
      "step": 2136
    },
    {
      "epoch": 0.8548,
      "grad_norm": 11.511646270751953,
      "learning_rate": 7.151999999999999e-07,
      "logits/chosen": -2.644698143005371,
      "logits/rejected": -2.9352922439575195,
      "logps/chosen": -162.14291381835938,
      "logps/rejected": -147.68148803710938,
      "loss": 0.083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9389320611953735,
      "rewards/margins": 3.5320167541503906,
      "rewards/rejected": -4.470948696136475,
      "step": 2137
    },
    {
      "epoch": 0.8552,
      "grad_norm": 0.07285735756158829,
      "learning_rate": 7.150666666666666e-07,
      "logits/chosen": -2.2672908306121826,
      "logits/rejected": -2.678589344024658,
      "logps/chosen": -172.67381286621094,
      "logps/rejected": -179.54164123535156,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6733551025390625,
      "rewards/margins": 9.254141807556152,
      "rewards/rejected": -5.58078670501709,
      "step": 2138
    },
    {
      "epoch": 0.8556,
      "grad_norm": 0.014012307859957218,
      "learning_rate": 7.149333333333333e-07,
      "logits/chosen": -2.5724987983703613,
      "logits/rejected": -3.276869297027588,
      "logps/chosen": -86.32523345947266,
      "logps/rejected": -150.2854461669922,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3644556999206543,
      "rewards/margins": 8.864405632019043,
      "rewards/rejected": -5.4999494552612305,
      "step": 2139
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.5977694988250732,
      "learning_rate": 7.147999999999999e-07,
      "logits/chosen": -2.466115951538086,
      "logits/rejected": -2.7461657524108887,
      "logps/chosen": -111.18753051757812,
      "logps/rejected": -159.90060424804688,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0184929370880127,
      "rewards/margins": 6.879000663757324,
      "rewards/rejected": -3.8605074882507324,
      "step": 2140
    },
    {
      "epoch": 0.8564,
      "grad_norm": 0.09519024193286896,
      "learning_rate": 7.146666666666666e-07,
      "logits/chosen": -1.9289462566375732,
      "logits/rejected": -3.1240639686584473,
      "logps/chosen": -128.23818969726562,
      "logps/rejected": -148.54359436035156,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3771480321884155,
      "rewards/margins": 7.128905296325684,
      "rewards/rejected": -5.7517571449279785,
      "step": 2141
    },
    {
      "epoch": 0.8568,
      "grad_norm": 0.10426799952983856,
      "learning_rate": 7.145333333333333e-07,
      "logits/chosen": -2.8960747718811035,
      "logits/rejected": -3.0248823165893555,
      "logps/chosen": -226.31826782226562,
      "logps/rejected": -194.61279296875,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.207717180252075,
      "rewards/margins": 7.6804962158203125,
      "rewards/rejected": -5.4727783203125,
      "step": 2142
    },
    {
      "epoch": 0.8572,
      "grad_norm": 6.540618896484375,
      "learning_rate": 7.144e-07,
      "logits/chosen": -2.3312668800354004,
      "logits/rejected": -3.3924779891967773,
      "logps/chosen": -125.79633331298828,
      "logps/rejected": -157.6482391357422,
      "loss": 0.0531,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0447803735733032,
      "rewards/margins": 6.785694599151611,
      "rewards/rejected": -5.7409138679504395,
      "step": 2143
    },
    {
      "epoch": 0.8576,
      "grad_norm": 0.12511824071407318,
      "learning_rate": 7.142666666666667e-07,
      "logits/chosen": -2.557077169418335,
      "logits/rejected": -2.810739040374756,
      "logps/chosen": -194.20285034179688,
      "logps/rejected": -215.69778442382812,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5393424034118652,
      "rewards/margins": 7.354389190673828,
      "rewards/rejected": -4.815046787261963,
      "step": 2144
    },
    {
      "epoch": 0.858,
      "grad_norm": 0.09589685499668121,
      "learning_rate": 7.141333333333333e-07,
      "logits/chosen": -2.3081576824188232,
      "logits/rejected": -3.193775177001953,
      "logps/chosen": -83.990966796875,
      "logps/rejected": -136.02523803710938,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4518680572509766,
      "rewards/margins": 8.661892890930176,
      "rewards/rejected": -6.210024833679199,
      "step": 2145
    },
    {
      "epoch": 0.8584,
      "grad_norm": 0.2374386489391327,
      "learning_rate": 7.14e-07,
      "logits/chosen": -2.388990640640259,
      "logits/rejected": -2.201857328414917,
      "logps/chosen": -107.64186096191406,
      "logps/rejected": -121.61367797851562,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9459571838378906,
      "rewards/margins": 7.41785192489624,
      "rewards/rejected": -4.471894264221191,
      "step": 2146
    },
    {
      "epoch": 0.8588,
      "grad_norm": 0.040097229182720184,
      "learning_rate": 7.138666666666667e-07,
      "logits/chosen": -2.0286571979522705,
      "logits/rejected": -3.052861213684082,
      "logps/chosen": -133.96444702148438,
      "logps/rejected": -166.73793029785156,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.712786912918091,
      "rewards/margins": 9.633402824401855,
      "rewards/rejected": -5.920616149902344,
      "step": 2147
    },
    {
      "epoch": 0.8592,
      "grad_norm": 0.06289202719926834,
      "learning_rate": 7.137333333333333e-07,
      "logits/chosen": -2.1190989017486572,
      "logits/rejected": -2.9718732833862305,
      "logps/chosen": -114.08098602294922,
      "logps/rejected": -166.54312133789062,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1763482093811035,
      "rewards/margins": 8.194884300231934,
      "rewards/rejected": -5.01853609085083,
      "step": 2148
    },
    {
      "epoch": 0.8596,
      "grad_norm": 0.1065393015742302,
      "learning_rate": 7.135999999999999e-07,
      "logits/chosen": -2.341019630432129,
      "logits/rejected": -3.220200777053833,
      "logps/chosen": -133.25131225585938,
      "logps/rejected": -157.900146484375,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0112377405166626,
      "rewards/margins": 6.835244178771973,
      "rewards/rejected": -5.824006080627441,
      "step": 2149
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.944279134273529,
      "learning_rate": 7.134666666666666e-07,
      "logits/chosen": -2.2080235481262207,
      "logits/rejected": -3.0098085403442383,
      "logps/chosen": -104.4478988647461,
      "logps/rejected": -180.569091796875,
      "loss": 0.0084,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.496649146080017,
      "rewards/margins": 5.987672805786133,
      "rewards/rejected": -4.491023540496826,
      "step": 2150
    },
    {
      "epoch": 0.8604,
      "grad_norm": 0.10041401535272598,
      "learning_rate": 7.133333333333333e-07,
      "logits/chosen": -1.8117629289627075,
      "logits/rejected": -3.22851300239563,
      "logps/chosen": -101.43772888183594,
      "logps/rejected": -150.19052124023438,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4361492395401,
      "rewards/margins": 7.311648368835449,
      "rewards/rejected": -5.875499725341797,
      "step": 2151
    },
    {
      "epoch": 0.8608,
      "grad_norm": 0.11107593029737473,
      "learning_rate": 7.131999999999999e-07,
      "logits/chosen": -2.703138828277588,
      "logits/rejected": -2.7039599418640137,
      "logps/chosen": -105.4543228149414,
      "logps/rejected": -129.06077575683594,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6594229936599731,
      "rewards/margins": 7.192424774169922,
      "rewards/rejected": -5.533001899719238,
      "step": 2152
    },
    {
      "epoch": 0.8612,
      "grad_norm": 0.5697186589241028,
      "learning_rate": 7.130666666666666e-07,
      "logits/chosen": -1.7435851097106934,
      "logits/rejected": -3.3060896396636963,
      "logps/chosen": -131.8433837890625,
      "logps/rejected": -193.64010620117188,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0034599304199219,
      "rewards/margins": 5.969841957092285,
      "rewards/rejected": -4.966382026672363,
      "step": 2153
    },
    {
      "epoch": 0.8616,
      "grad_norm": 0.0027495825197547674,
      "learning_rate": 7.129333333333333e-07,
      "logits/chosen": -2.896080255508423,
      "logits/rejected": -3.323126792907715,
      "logps/chosen": -140.86134338378906,
      "logps/rejected": -153.4039764404297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.6479172706604,
      "rewards/margins": 10.52740478515625,
      "rewards/rejected": -5.879487991333008,
      "step": 2154
    },
    {
      "epoch": 0.862,
      "grad_norm": 0.017213402315974236,
      "learning_rate": 7.128e-07,
      "logits/chosen": -2.112151622772217,
      "logits/rejected": -2.8016276359558105,
      "logps/chosen": -118.52433776855469,
      "logps/rejected": -165.47926330566406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0009994506835938,
      "rewards/margins": 9.018512725830078,
      "rewards/rejected": -6.017513275146484,
      "step": 2155
    },
    {
      "epoch": 0.8624,
      "grad_norm": 0.01215366180986166,
      "learning_rate": 7.126666666666667e-07,
      "logits/chosen": -2.572373390197754,
      "logits/rejected": -3.2515268325805664,
      "logps/chosen": -111.72688293457031,
      "logps/rejected": -161.7183837890625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.100968599319458,
      "rewards/margins": 9.073785781860352,
      "rewards/rejected": -5.972817420959473,
      "step": 2156
    },
    {
      "epoch": 0.8628,
      "grad_norm": 0.8723729252815247,
      "learning_rate": 7.125333333333334e-07,
      "logits/chosen": -2.8331265449523926,
      "logits/rejected": -2.868368148803711,
      "logps/chosen": -227.75997924804688,
      "logps/rejected": -241.3045196533203,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0918054580688477,
      "rewards/margins": 7.385537624359131,
      "rewards/rejected": -5.293732166290283,
      "step": 2157
    },
    {
      "epoch": 0.8632,
      "grad_norm": 0.2187870442867279,
      "learning_rate": 7.124e-07,
      "logits/chosen": -1.8621983528137207,
      "logits/rejected": -3.085507392883301,
      "logps/chosen": -132.85772705078125,
      "logps/rejected": -165.3190155029297,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4132039546966553,
      "rewards/margins": 8.20506763458252,
      "rewards/rejected": -5.791863441467285,
      "step": 2158
    },
    {
      "epoch": 0.8636,
      "grad_norm": 0.12127511948347092,
      "learning_rate": 7.122666666666666e-07,
      "logits/chosen": -2.290736198425293,
      "logits/rejected": -3.2263741493225098,
      "logps/chosen": -113.34461212158203,
      "logps/rejected": -151.91062927246094,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8434253931045532,
      "rewards/margins": 7.02313232421875,
      "rewards/rejected": -6.179706573486328,
      "step": 2159
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.37487077713012695,
      "learning_rate": 7.121333333333332e-07,
      "logits/chosen": -2.2616000175476074,
      "logits/rejected": -3.4034600257873535,
      "logps/chosen": -123.64085388183594,
      "logps/rejected": -146.62242126464844,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7886577248573303,
      "rewards/margins": 7.497016906738281,
      "rewards/rejected": -6.708359241485596,
      "step": 2160
    },
    {
      "epoch": 0.8644,
      "grad_norm": 0.011069552041590214,
      "learning_rate": 7.119999999999999e-07,
      "logits/chosen": -2.7444839477539062,
      "logits/rejected": -3.4694995880126953,
      "logps/chosen": -143.60720825195312,
      "logps/rejected": -179.666259765625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9883289337158203,
      "rewards/margins": 9.320289611816406,
      "rewards/rejected": -5.331960678100586,
      "step": 2161
    },
    {
      "epoch": 0.8648,
      "grad_norm": 0.2268988937139511,
      "learning_rate": 7.118666666666666e-07,
      "logits/chosen": -2.1545114517211914,
      "logits/rejected": -3.4676458835601807,
      "logps/chosen": -121.47142028808594,
      "logps/rejected": -178.16476440429688,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0664299726486206,
      "rewards/margins": 9.541900634765625,
      "rewards/rejected": -8.475469589233398,
      "step": 2162
    },
    {
      "epoch": 0.8652,
      "grad_norm": 2.42441463470459,
      "learning_rate": 7.117333333333333e-07,
      "logits/chosen": -3.008723258972168,
      "logits/rejected": -2.6529154777526855,
      "logps/chosen": -129.05657958984375,
      "logps/rejected": -142.29336547851562,
      "loss": 0.0183,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3329906463623047,
      "rewards/margins": 6.942631721496582,
      "rewards/rejected": -4.609641075134277,
      "step": 2163
    },
    {
      "epoch": 0.8656,
      "grad_norm": 0.005448879674077034,
      "learning_rate": 7.116e-07,
      "logits/chosen": -2.2299675941467285,
      "logits/rejected": -3.7817506790161133,
      "logps/chosen": -144.8860321044922,
      "logps/rejected": -251.38113403320312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7906813621520996,
      "rewards/margins": 10.651047706604004,
      "rewards/rejected": -7.860365867614746,
      "step": 2164
    },
    {
      "epoch": 0.866,
      "grad_norm": 0.007921095937490463,
      "learning_rate": 7.114666666666667e-07,
      "logits/chosen": -2.0429909229278564,
      "logits/rejected": -2.869271993637085,
      "logps/chosen": -104.54595947265625,
      "logps/rejected": -170.9861602783203,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5010581016540527,
      "rewards/margins": 9.653678894042969,
      "rewards/rejected": -6.152621269226074,
      "step": 2165
    },
    {
      "epoch": 0.8664,
      "grad_norm": 0.5889561772346497,
      "learning_rate": 7.113333333333334e-07,
      "logits/chosen": -2.6002349853515625,
      "logits/rejected": -2.919302225112915,
      "logps/chosen": -157.17567443847656,
      "logps/rejected": -137.4412078857422,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3366315364837646,
      "rewards/margins": 6.291695594787598,
      "rewards/rejected": -3.955063819885254,
      "step": 2166
    },
    {
      "epoch": 0.8668,
      "grad_norm": 0.10209497809410095,
      "learning_rate": 7.112000000000001e-07,
      "logits/chosen": -1.886624813079834,
      "logits/rejected": -3.852963447570801,
      "logps/chosen": -100.59825897216797,
      "logps/rejected": -190.50413513183594,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0706650018692017,
      "rewards/margins": 7.8043413162231445,
      "rewards/rejected": -6.733676433563232,
      "step": 2167
    },
    {
      "epoch": 0.8672,
      "grad_norm": 0.19285914301872253,
      "learning_rate": 7.110666666666665e-07,
      "logits/chosen": -2.2466437816619873,
      "logits/rejected": -2.9039883613586426,
      "logps/chosen": -98.19255065917969,
      "logps/rejected": -165.744873046875,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.255155563354492,
      "rewards/margins": 9.073369979858398,
      "rewards/rejected": -6.818213939666748,
      "step": 2168
    },
    {
      "epoch": 0.8676,
      "grad_norm": 0.3214268684387207,
      "learning_rate": 7.109333333333332e-07,
      "logits/chosen": -2.621614456176758,
      "logits/rejected": -3.6144957542419434,
      "logps/chosen": -153.619873046875,
      "logps/rejected": -163.46438598632812,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.971783399581909,
      "rewards/margins": 8.133442878723145,
      "rewards/rejected": -5.161659240722656,
      "step": 2169
    },
    {
      "epoch": 0.868,
      "grad_norm": 0.03315483033657074,
      "learning_rate": 7.107999999999999e-07,
      "logits/chosen": -1.9311633110046387,
      "logits/rejected": -2.657381057739258,
      "logps/chosen": -106.32748413085938,
      "logps/rejected": -225.14639282226562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0070672035217285,
      "rewards/margins": 8.644393920898438,
      "rewards/rejected": -5.637326240539551,
      "step": 2170
    },
    {
      "epoch": 0.8684,
      "grad_norm": 0.011811251752078533,
      "learning_rate": 7.106666666666666e-07,
      "logits/chosen": -2.358513116836548,
      "logits/rejected": -3.4045543670654297,
      "logps/chosen": -109.78213500976562,
      "logps/rejected": -156.88002014160156,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6556382179260254,
      "rewards/margins": 9.429895401000977,
      "rewards/rejected": -5.774258136749268,
      "step": 2171
    },
    {
      "epoch": 0.8688,
      "grad_norm": 0.10420844703912735,
      "learning_rate": 7.105333333333333e-07,
      "logits/chosen": -1.7890623807907104,
      "logits/rejected": -2.2222342491149902,
      "logps/chosen": -95.91496276855469,
      "logps/rejected": -118.96871948242188,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7902092933654785,
      "rewards/margins": 7.040805816650391,
      "rewards/rejected": -5.25059700012207,
      "step": 2172
    },
    {
      "epoch": 0.8692,
      "grad_norm": 0.020809341222047806,
      "learning_rate": 7.104e-07,
      "logits/chosen": -1.8714265823364258,
      "logits/rejected": -2.7549567222595215,
      "logps/chosen": -109.05506134033203,
      "logps/rejected": -167.24200439453125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3179383277893066,
      "rewards/margins": 9.111559867858887,
      "rewards/rejected": -5.793621063232422,
      "step": 2173
    },
    {
      "epoch": 0.8696,
      "grad_norm": 3.58246111869812,
      "learning_rate": 7.102666666666667e-07,
      "logits/chosen": -3.2458653450012207,
      "logits/rejected": -2.8752036094665527,
      "logps/chosen": -126.2142333984375,
      "logps/rejected": -143.98141479492188,
      "loss": 0.0291,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2559452056884766,
      "rewards/margins": 5.767532825469971,
      "rewards/rejected": -4.511587619781494,
      "step": 2174
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.3451421558856964,
      "learning_rate": 7.101333333333333e-07,
      "logits/chosen": -1.9885996580123901,
      "logits/rejected": -2.85113525390625,
      "logps/chosen": -102.94830322265625,
      "logps/rejected": -132.33340454101562,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3916163444519043,
      "rewards/margins": 7.368892669677734,
      "rewards/rejected": -3.97727632522583,
      "step": 2175
    },
    {
      "epoch": 0.8704,
      "grad_norm": 0.21677911281585693,
      "learning_rate": 7.1e-07,
      "logits/chosen": -2.167320489883423,
      "logits/rejected": -2.8924245834350586,
      "logps/chosen": -141.93603515625,
      "logps/rejected": -139.14450073242188,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7325806617736816,
      "rewards/margins": 7.2420759201049805,
      "rewards/rejected": -4.509495735168457,
      "step": 2176
    },
    {
      "epoch": 0.8708,
      "grad_norm": 0.13341915607452393,
      "learning_rate": 7.098666666666666e-07,
      "logits/chosen": -2.3983166217803955,
      "logits/rejected": -2.518270492553711,
      "logps/chosen": -277.91015625,
      "logps/rejected": -213.88539123535156,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8200950622558594,
      "rewards/margins": 8.220474243164062,
      "rewards/rejected": -4.400378227233887,
      "step": 2177
    },
    {
      "epoch": 0.8712,
      "grad_norm": 0.00783336441963911,
      "learning_rate": 7.097333333333333e-07,
      "logits/chosen": -2.3613405227661133,
      "logits/rejected": -3.2682113647460938,
      "logps/chosen": -192.77719116210938,
      "logps/rejected": -198.9151153564453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.377633571624756,
      "rewards/margins": 10.296713829040527,
      "rewards/rejected": -6.9190802574157715,
      "step": 2178
    },
    {
      "epoch": 0.8716,
      "grad_norm": 0.229421928524971,
      "learning_rate": 7.096e-07,
      "logits/chosen": -2.2366676330566406,
      "logits/rejected": -3.143308639526367,
      "logps/chosen": -147.39630126953125,
      "logps/rejected": -162.42721557617188,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8723541498184204,
      "rewards/margins": 6.985722541809082,
      "rewards/rejected": -5.113368034362793,
      "step": 2179
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.3051559329032898,
      "learning_rate": 7.094666666666666e-07,
      "logits/chosen": -2.6709628105163574,
      "logits/rejected": -3.4998202323913574,
      "logps/chosen": -192.32667541503906,
      "logps/rejected": -157.76821899414062,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45800474286079407,
      "rewards/margins": 5.715619087219238,
      "rewards/rejected": -5.257614612579346,
      "step": 2180
    },
    {
      "epoch": 0.8724,
      "grad_norm": 0.017603717744350433,
      "learning_rate": 7.093333333333333e-07,
      "logits/chosen": -2.527933120727539,
      "logits/rejected": -3.5742130279541016,
      "logps/chosen": -172.45272827148438,
      "logps/rejected": -193.58193969726562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5965847969055176,
      "rewards/margins": 9.036528587341309,
      "rewards/rejected": -7.439943790435791,
      "step": 2181
    },
    {
      "epoch": 0.8728,
      "grad_norm": 0.43476051092147827,
      "learning_rate": 7.092e-07,
      "logits/chosen": -2.3199424743652344,
      "logits/rejected": -3.365691661834717,
      "logps/chosen": -110.53030395507812,
      "logps/rejected": -133.22332763671875,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9437122344970703,
      "rewards/margins": 5.236547470092773,
      "rewards/rejected": -4.292835235595703,
      "step": 2182
    },
    {
      "epoch": 0.8732,
      "grad_norm": 0.005761230364441872,
      "learning_rate": 7.090666666666666e-07,
      "logits/chosen": -1.6630024909973145,
      "logits/rejected": -4.025460243225098,
      "logps/chosen": -62.83917999267578,
      "logps/rejected": -194.10977172851562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7916033267974854,
      "rewards/margins": 10.141274452209473,
      "rewards/rejected": -7.349671363830566,
      "step": 2183
    },
    {
      "epoch": 0.8736,
      "grad_norm": 0.024716947227716446,
      "learning_rate": 7.089333333333333e-07,
      "logits/chosen": -2.903831720352173,
      "logits/rejected": -3.5370728969573975,
      "logps/chosen": -117.58800506591797,
      "logps/rejected": -199.439208984375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.99153995513916,
      "rewards/margins": 11.093568801879883,
      "rewards/rejected": -7.102029323577881,
      "step": 2184
    },
    {
      "epoch": 0.874,
      "grad_norm": 0.23885641992092133,
      "learning_rate": 7.088e-07,
      "logits/chosen": -2.324045181274414,
      "logits/rejected": -3.018580198287964,
      "logps/chosen": -141.10205078125,
      "logps/rejected": -141.28482055664062,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7698814868927002,
      "rewards/margins": 5.91362190246582,
      "rewards/rejected": -4.143740177154541,
      "step": 2185
    },
    {
      "epoch": 0.8744,
      "grad_norm": 0.009184113703668118,
      "learning_rate": 7.086666666666667e-07,
      "logits/chosen": -2.148500919342041,
      "logits/rejected": -3.7218761444091797,
      "logps/chosen": -81.27890014648438,
      "logps/rejected": -161.37615966796875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3870186805725098,
      "rewards/margins": 9.422708511352539,
      "rewards/rejected": -6.035689353942871,
      "step": 2186
    },
    {
      "epoch": 0.8748,
      "grad_norm": 0.13524048030376434,
      "learning_rate": 7.085333333333333e-07,
      "logits/chosen": -1.9388394355773926,
      "logits/rejected": -3.2280168533325195,
      "logps/chosen": -176.3175506591797,
      "logps/rejected": -130.75357055664062,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.978963613510132,
      "rewards/margins": 6.815360069274902,
      "rewards/rejected": -3.8363964557647705,
      "step": 2187
    },
    {
      "epoch": 0.8752,
      "grad_norm": 1.9769344329833984,
      "learning_rate": 7.084e-07,
      "logits/chosen": -1.7348891496658325,
      "logits/rejected": -2.7804760932922363,
      "logps/chosen": -130.4860076904297,
      "logps/rejected": -116.05039978027344,
      "loss": 0.0241,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.36418724060058594,
      "rewards/margins": 4.029339790344238,
      "rewards/rejected": -4.393527507781982,
      "step": 2188
    },
    {
      "epoch": 0.8756,
      "grad_norm": 0.03499886393547058,
      "learning_rate": 7.082666666666667e-07,
      "logits/chosen": -1.7435836791992188,
      "logits/rejected": -2.809434413909912,
      "logps/chosen": -124.76079559326172,
      "logps/rejected": -148.46426391601562,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.792736530303955,
      "rewards/margins": 8.496088027954102,
      "rewards/rejected": -4.703351020812988,
      "step": 2189
    },
    {
      "epoch": 0.876,
      "grad_norm": 0.16305068135261536,
      "learning_rate": 7.081333333333332e-07,
      "logits/chosen": -2.1667613983154297,
      "logits/rejected": -2.7795839309692383,
      "logps/chosen": -96.44021606445312,
      "logps/rejected": -137.9489288330078,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6029529571533203,
      "rewards/margins": 7.556764125823975,
      "rewards/rejected": -5.9538116455078125,
      "step": 2190
    },
    {
      "epoch": 0.8764,
      "grad_norm": 0.04638426750898361,
      "learning_rate": 7.079999999999999e-07,
      "logits/chosen": -2.5467138290405273,
      "logits/rejected": -3.1091442108154297,
      "logps/chosen": -157.9820556640625,
      "logps/rejected": -145.52642822265625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2144203186035156,
      "rewards/margins": 8.347074508666992,
      "rewards/rejected": -5.132654190063477,
      "step": 2191
    },
    {
      "epoch": 0.8768,
      "grad_norm": 0.08852844685316086,
      "learning_rate": 7.078666666666666e-07,
      "logits/chosen": -2.1806280612945557,
      "logits/rejected": -2.820620059967041,
      "logps/chosen": -121.29901123046875,
      "logps/rejected": -159.36386108398438,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8239154815673828,
      "rewards/margins": 7.917473793029785,
      "rewards/rejected": -6.093558311462402,
      "step": 2192
    },
    {
      "epoch": 0.8772,
      "grad_norm": 0.2386011928319931,
      "learning_rate": 7.077333333333333e-07,
      "logits/chosen": -1.9392058849334717,
      "logits/rejected": -3.2805967330932617,
      "logps/chosen": -118.89224243164062,
      "logps/rejected": -145.5284423828125,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1887741088867188,
      "rewards/margins": 6.979792594909668,
      "rewards/rejected": -5.791018009185791,
      "step": 2193
    },
    {
      "epoch": 0.8776,
      "grad_norm": 0.005429273005574942,
      "learning_rate": 7.076e-07,
      "logits/chosen": -2.0354714393615723,
      "logits/rejected": -3.2158970832824707,
      "logps/chosen": -100.8954849243164,
      "logps/rejected": -226.558837890625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4164700508117676,
      "rewards/margins": 10.373296737670898,
      "rewards/rejected": -6.956827163696289,
      "step": 2194
    },
    {
      "epoch": 0.878,
      "grad_norm": 0.41531550884246826,
      "learning_rate": 7.074666666666667e-07,
      "logits/chosen": -2.468519926071167,
      "logits/rejected": -2.955872058868408,
      "logps/chosen": -200.83184814453125,
      "logps/rejected": -148.5011444091797,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4345120191574097,
      "rewards/margins": 5.73709774017334,
      "rewards/rejected": -4.302585601806641,
      "step": 2195
    },
    {
      "epoch": 0.8784,
      "grad_norm": 0.04802975058555603,
      "learning_rate": 7.073333333333333e-07,
      "logits/chosen": -2.6806118488311768,
      "logits/rejected": -3.6678318977355957,
      "logps/chosen": -121.22941589355469,
      "logps/rejected": -182.602783203125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.757933497428894,
      "rewards/margins": 8.29983139038086,
      "rewards/rejected": -6.541898727416992,
      "step": 2196
    },
    {
      "epoch": 0.8788,
      "grad_norm": 0.39436066150665283,
      "learning_rate": 7.072e-07,
      "logits/chosen": -2.2496066093444824,
      "logits/rejected": -3.243741989135742,
      "logps/chosen": -135.98023986816406,
      "logps/rejected": -137.0192108154297,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0543065071105957,
      "rewards/margins": 7.386585712432861,
      "rewards/rejected": -4.332279205322266,
      "step": 2197
    },
    {
      "epoch": 0.8792,
      "grad_norm": 0.1264246553182602,
      "learning_rate": 7.070666666666666e-07,
      "logits/chosen": -2.506706953048706,
      "logits/rejected": -3.128962516784668,
      "logps/chosen": -97.89324188232422,
      "logps/rejected": -170.5733642578125,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2949615716934204,
      "rewards/margins": 7.643112659454346,
      "rewards/rejected": -6.348151206970215,
      "step": 2198
    },
    {
      "epoch": 0.8796,
      "grad_norm": 0.07084047794342041,
      "learning_rate": 7.069333333333333e-07,
      "logits/chosen": -2.1194446086883545,
      "logits/rejected": -2.7811689376831055,
      "logps/chosen": -130.69964599609375,
      "logps/rejected": -123.16465759277344,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3314857482910156,
      "rewards/margins": 7.528147220611572,
      "rewards/rejected": -5.196661472320557,
      "step": 2199
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.0032087676227092743,
      "learning_rate": 7.068e-07,
      "logits/chosen": -2.072519063949585,
      "logits/rejected": -3.2777042388916016,
      "logps/chosen": -126.77143096923828,
      "logps/rejected": -161.1476287841797,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.1044816970825195,
      "rewards/margins": 10.756433486938477,
      "rewards/rejected": -6.651951789855957,
      "step": 2200
    },
    {
      "epoch": 0.8804,
      "grad_norm": 0.01346501987427473,
      "learning_rate": 7.066666666666666e-07,
      "logits/chosen": -2.1220688819885254,
      "logits/rejected": -3.2449259757995605,
      "logps/chosen": -152.4923553466797,
      "logps/rejected": -187.12689208984375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8269410133361816,
      "rewards/margins": 9.946547508239746,
      "rewards/rejected": -6.1196064949035645,
      "step": 2201
    },
    {
      "epoch": 0.8808,
      "grad_norm": 2.134033203125,
      "learning_rate": 7.065333333333333e-07,
      "logits/chosen": -1.851266860961914,
      "logits/rejected": -2.9727299213409424,
      "logps/chosen": -133.66259765625,
      "logps/rejected": -142.0332489013672,
      "loss": 0.0293,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.011250317096710205,
      "rewards/margins": 4.82269287109375,
      "rewards/rejected": -4.8339433670043945,
      "step": 2202
    },
    {
      "epoch": 0.8812,
      "grad_norm": 0.5364342927932739,
      "learning_rate": 7.064e-07,
      "logits/chosen": -2.130248546600342,
      "logits/rejected": -3.256974697113037,
      "logps/chosen": -138.85751342773438,
      "logps/rejected": -164.64608764648438,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0889296531677246,
      "rewards/margins": 6.844178676605225,
      "rewards/rejected": -5.7552490234375,
      "step": 2203
    },
    {
      "epoch": 0.8816,
      "grad_norm": 0.5853009223937988,
      "learning_rate": 7.062666666666667e-07,
      "logits/chosen": -2.16256046295166,
      "logits/rejected": -3.225555896759033,
      "logps/chosen": -126.18833923339844,
      "logps/rejected": -147.0494384765625,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4390000104904175,
      "rewards/margins": 6.51739501953125,
      "rewards/rejected": -6.078394889831543,
      "step": 2204
    },
    {
      "epoch": 0.882,
      "grad_norm": 0.06008777767419815,
      "learning_rate": 7.061333333333332e-07,
      "logits/chosen": -2.2508606910705566,
      "logits/rejected": -2.9518842697143555,
      "logps/chosen": -199.08546447753906,
      "logps/rejected": -165.08779907226562,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.174372911453247,
      "rewards/margins": 7.277864456176758,
      "rewards/rejected": -6.10349178314209,
      "step": 2205
    },
    {
      "epoch": 0.8824,
      "grad_norm": 0.4133131206035614,
      "learning_rate": 7.059999999999999e-07,
      "logits/chosen": -2.2486467361450195,
      "logits/rejected": -3.2269883155822754,
      "logps/chosen": -121.10501861572266,
      "logps/rejected": -127.60598754882812,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.484610080718994,
      "rewards/margins": 6.882988929748535,
      "rewards/rejected": -4.398378849029541,
      "step": 2206
    },
    {
      "epoch": 0.8828,
      "grad_norm": 0.008221650496125221,
      "learning_rate": 7.058666666666666e-07,
      "logits/chosen": -2.2284586429595947,
      "logits/rejected": -3.110236167907715,
      "logps/chosen": -109.02412414550781,
      "logps/rejected": -157.2748565673828,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6361148357391357,
      "rewards/margins": 9.569663047790527,
      "rewards/rejected": -5.9335479736328125,
      "step": 2207
    },
    {
      "epoch": 0.8832,
      "grad_norm": 6.376903057098389,
      "learning_rate": 7.057333333333333e-07,
      "logits/chosen": -1.9450435638427734,
      "logits/rejected": -3.119727611541748,
      "logps/chosen": -214.8318328857422,
      "logps/rejected": -129.48138427734375,
      "loss": 0.0465,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.509901523590088,
      "rewards/margins": 6.078988075256348,
      "rewards/rejected": -4.56908655166626,
      "step": 2208
    },
    {
      "epoch": 0.8836,
      "grad_norm": 0.030188245698809624,
      "learning_rate": 7.056e-07,
      "logits/chosen": -2.449969530105591,
      "logits/rejected": -3.1639649868011475,
      "logps/chosen": -205.82406616210938,
      "logps/rejected": -210.6341552734375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7319130897521973,
      "rewards/margins": 9.013738632202148,
      "rewards/rejected": -6.281826019287109,
      "step": 2209
    },
    {
      "epoch": 0.884,
      "grad_norm": 0.00832702498883009,
      "learning_rate": 7.054666666666667e-07,
      "logits/chosen": -2.5188450813293457,
      "logits/rejected": -3.244765281677246,
      "logps/chosen": -125.1212158203125,
      "logps/rejected": -187.3660888671875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.950428009033203,
      "rewards/margins": 9.606523513793945,
      "rewards/rejected": -6.656095504760742,
      "step": 2210
    },
    {
      "epoch": 0.8844,
      "grad_norm": 0.21191728115081787,
      "learning_rate": 7.053333333333333e-07,
      "logits/chosen": -2.5672736167907715,
      "logits/rejected": -3.390285015106201,
      "logps/chosen": -185.44985961914062,
      "logps/rejected": -170.5615234375,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1531531810760498,
      "rewards/margins": 8.873271942138672,
      "rewards/rejected": -7.720118522644043,
      "step": 2211
    },
    {
      "epoch": 0.8848,
      "grad_norm": 0.04329805448651314,
      "learning_rate": 7.052e-07,
      "logits/chosen": -2.1667580604553223,
      "logits/rejected": -3.769899368286133,
      "logps/chosen": -103.71559143066406,
      "logps/rejected": -185.8719482421875,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8919880390167236,
      "rewards/margins": 8.280981063842773,
      "rewards/rejected": -6.388992786407471,
      "step": 2212
    },
    {
      "epoch": 0.8852,
      "grad_norm": 0.054438214749097824,
      "learning_rate": 7.050666666666666e-07,
      "logits/chosen": -2.1716322898864746,
      "logits/rejected": -3.0511887073516846,
      "logps/chosen": -127.96176147460938,
      "logps/rejected": -168.0404510498047,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4837563037872314,
      "rewards/margins": 7.710366725921631,
      "rewards/rejected": -4.2266106605529785,
      "step": 2213
    },
    {
      "epoch": 0.8856,
      "grad_norm": 0.09367147833108902,
      "learning_rate": 7.049333333333333e-07,
      "logits/chosen": -2.030606985092163,
      "logits/rejected": -2.8177967071533203,
      "logps/chosen": -115.1824951171875,
      "logps/rejected": -146.45016479492188,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4815654754638672,
      "rewards/margins": 7.62003231048584,
      "rewards/rejected": -6.138466835021973,
      "step": 2214
    },
    {
      "epoch": 0.886,
      "grad_norm": 0.353722482919693,
      "learning_rate": 7.047999999999999e-07,
      "logits/chosen": -2.268099308013916,
      "logits/rejected": -2.707247734069824,
      "logps/chosen": -97.22076416015625,
      "logps/rejected": -136.2556610107422,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4782719612121582,
      "rewards/margins": 7.222609996795654,
      "rewards/rejected": -5.744338035583496,
      "step": 2215
    },
    {
      "epoch": 0.8864,
      "grad_norm": 0.004667892120778561,
      "learning_rate": 7.046666666666666e-07,
      "logits/chosen": -2.0916895866394043,
      "logits/rejected": -2.985637903213501,
      "logps/chosen": -92.72842407226562,
      "logps/rejected": -159.33505249023438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.09097957611084,
      "rewards/margins": 10.112628936767578,
      "rewards/rejected": -6.021649360656738,
      "step": 2216
    },
    {
      "epoch": 0.8868,
      "grad_norm": 0.5854437947273254,
      "learning_rate": 7.045333333333333e-07,
      "logits/chosen": -2.4747328758239746,
      "logits/rejected": -3.416396141052246,
      "logps/chosen": -99.17644500732422,
      "logps/rejected": -152.66525268554688,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2454830408096313,
      "rewards/margins": 7.515469551086426,
      "rewards/rejected": -6.269986152648926,
      "step": 2217
    },
    {
      "epoch": 0.8872,
      "grad_norm": 0.013215476647019386,
      "learning_rate": 7.044e-07,
      "logits/chosen": -2.136220693588257,
      "logits/rejected": -2.9310383796691895,
      "logps/chosen": -101.32449340820312,
      "logps/rejected": -141.37686157226562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5064024925231934,
      "rewards/margins": 9.081451416015625,
      "rewards/rejected": -5.575048446655273,
      "step": 2218
    },
    {
      "epoch": 0.8876,
      "grad_norm": 0.6735912561416626,
      "learning_rate": 7.042666666666667e-07,
      "logits/chosen": -1.6407798528671265,
      "logits/rejected": -3.5035557746887207,
      "logps/chosen": -65.60861206054688,
      "logps/rejected": -164.1824951171875,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7385196685791016,
      "rewards/margins": 8.11470890045166,
      "rewards/rejected": -6.376189231872559,
      "step": 2219
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.2611224353313446,
      "learning_rate": 7.041333333333334e-07,
      "logits/chosen": -2.170858383178711,
      "logits/rejected": -2.61384916305542,
      "logps/chosen": -97.08111572265625,
      "logps/rejected": -141.86029052734375,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4215009212493896,
      "rewards/margins": 7.4243974685668945,
      "rewards/rejected": -5.002896308898926,
      "step": 2220
    },
    {
      "epoch": 0.8884,
      "grad_norm": 0.13550059497356415,
      "learning_rate": 7.04e-07,
      "logits/chosen": -2.1388964653015137,
      "logits/rejected": -3.3008525371551514,
      "logps/chosen": -164.82232666015625,
      "logps/rejected": -198.16455078125,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.545975923538208,
      "rewards/margins": 6.675487995147705,
      "rewards/rejected": -5.129511833190918,
      "step": 2221
    },
    {
      "epoch": 0.8888,
      "grad_norm": 0.049536678940057755,
      "learning_rate": 7.038666666666666e-07,
      "logits/chosen": -2.515557289123535,
      "logits/rejected": -3.370077133178711,
      "logps/chosen": -125.58475494384766,
      "logps/rejected": -149.64163208007812,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.499105930328369,
      "rewards/margins": 9.076448440551758,
      "rewards/rejected": -5.5773420333862305,
      "step": 2222
    },
    {
      "epoch": 0.8892,
      "grad_norm": 2.551081895828247,
      "learning_rate": 7.037333333333333e-07,
      "logits/chosen": -2.208319664001465,
      "logits/rejected": -2.6573753356933594,
      "logps/chosen": -119.64205932617188,
      "logps/rejected": -130.1544647216797,
      "loss": 0.0333,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0687167644500732,
      "rewards/margins": 7.526712894439697,
      "rewards/rejected": -4.457995891571045,
      "step": 2223
    },
    {
      "epoch": 0.8896,
      "grad_norm": 0.17670008540153503,
      "learning_rate": 7.035999999999999e-07,
      "logits/chosen": -2.3156185150146484,
      "logits/rejected": -3.151601791381836,
      "logps/chosen": -133.42031860351562,
      "logps/rejected": -169.2801513671875,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6636803150177002,
      "rewards/margins": 7.268027305603027,
      "rewards/rejected": -5.604347229003906,
      "step": 2224
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.0033797097858041525,
      "learning_rate": 7.034666666666666e-07,
      "logits/chosen": -2.289895534515381,
      "logits/rejected": -3.3085107803344727,
      "logps/chosen": -106.45519256591797,
      "logps/rejected": -165.66314697265625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4686927795410156,
      "rewards/margins": 10.435819625854492,
      "rewards/rejected": -6.967126846313477,
      "step": 2225
    },
    {
      "epoch": 0.8904,
      "grad_norm": 0.047182634472846985,
      "learning_rate": 7.033333333333333e-07,
      "logits/chosen": -1.837748646736145,
      "logits/rejected": -2.8881137371063232,
      "logps/chosen": -67.12368774414062,
      "logps/rejected": -144.01205444335938,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3314058780670166,
      "rewards/margins": 8.03862476348877,
      "rewards/rejected": -4.707219123840332,
      "step": 2226
    },
    {
      "epoch": 0.8908,
      "grad_norm": 0.0477362684905529,
      "learning_rate": 7.032e-07,
      "logits/chosen": -2.6244397163391113,
      "logits/rejected": -3.1473922729492188,
      "logps/chosen": -118.5342788696289,
      "logps/rejected": -161.89947509765625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6129646301269531,
      "rewards/margins": 7.922279357910156,
      "rewards/rejected": -6.309314250946045,
      "step": 2227
    },
    {
      "epoch": 0.8912,
      "grad_norm": 0.17445175349712372,
      "learning_rate": 7.030666666666666e-07,
      "logits/chosen": -2.0697572231292725,
      "logits/rejected": -2.7577767372131348,
      "logps/chosen": -97.21592712402344,
      "logps/rejected": -121.5372314453125,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7959041595458984,
      "rewards/margins": 6.651115894317627,
      "rewards/rejected": -4.8552117347717285,
      "step": 2228
    },
    {
      "epoch": 0.8916,
      "grad_norm": 0.04546821862459183,
      "learning_rate": 7.029333333333333e-07,
      "logits/chosen": -2.307976245880127,
      "logits/rejected": -3.894071102142334,
      "logps/chosen": -93.598876953125,
      "logps/rejected": -164.19699096679688,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9656245708465576,
      "rewards/margins": 8.363870620727539,
      "rewards/rejected": -6.398245811462402,
      "step": 2229
    },
    {
      "epoch": 0.892,
      "grad_norm": 0.5042212009429932,
      "learning_rate": 7.028e-07,
      "logits/chosen": -2.4925267696380615,
      "logits/rejected": -3.4259390830993652,
      "logps/chosen": -189.9931640625,
      "logps/rejected": -153.49942016601562,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9853695034980774,
      "rewards/margins": 5.912287712097168,
      "rewards/rejected": -4.926918029785156,
      "step": 2230
    },
    {
      "epoch": 0.8924,
      "grad_norm": 0.04843263700604439,
      "learning_rate": 7.026666666666667e-07,
      "logits/chosen": -2.4699249267578125,
      "logits/rejected": -3.362154722213745,
      "logps/chosen": -126.70440673828125,
      "logps/rejected": -139.90353393554688,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8228988647460938,
      "rewards/margins": 7.645176887512207,
      "rewards/rejected": -4.822278022766113,
      "step": 2231
    },
    {
      "epoch": 0.8928,
      "grad_norm": 0.8141261339187622,
      "learning_rate": 7.025333333333334e-07,
      "logits/chosen": -1.7815608978271484,
      "logits/rejected": -2.9163169860839844,
      "logps/chosen": -67.85214233398438,
      "logps/rejected": -111.74073791503906,
      "loss": 0.0052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.65922212600708,
      "rewards/margins": 6.5031585693359375,
      "rewards/rejected": -3.8439364433288574,
      "step": 2232
    },
    {
      "epoch": 0.8932,
      "grad_norm": 0.11353901028633118,
      "learning_rate": 7.024e-07,
      "logits/chosen": -2.389484405517578,
      "logits/rejected": -2.9390385150909424,
      "logps/chosen": -199.71739196777344,
      "logps/rejected": -180.92237854003906,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7257308959960938,
      "rewards/margins": 8.914321899414062,
      "rewards/rejected": -6.188591480255127,
      "step": 2233
    },
    {
      "epoch": 0.8936,
      "grad_norm": 0.03097589686512947,
      "learning_rate": 7.022666666666666e-07,
      "logits/chosen": -2.223269462585449,
      "logits/rejected": -3.9529590606689453,
      "logps/chosen": -99.61044311523438,
      "logps/rejected": -201.98068237304688,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.175588607788086,
      "rewards/margins": 8.247238159179688,
      "rewards/rejected": -5.071648597717285,
      "step": 2234
    },
    {
      "epoch": 0.894,
      "grad_norm": 0.07032160460948944,
      "learning_rate": 7.021333333333333e-07,
      "logits/chosen": -2.6447906494140625,
      "logits/rejected": -3.296213150024414,
      "logps/chosen": -121.93632507324219,
      "logps/rejected": -160.13601684570312,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0887444019317627,
      "rewards/margins": 7.548274517059326,
      "rewards/rejected": -6.459530353546143,
      "step": 2235
    },
    {
      "epoch": 0.8944,
      "grad_norm": 0.023773949593305588,
      "learning_rate": 7.019999999999999e-07,
      "logits/chosen": -2.967604160308838,
      "logits/rejected": -3.0527493953704834,
      "logps/chosen": -110.33712768554688,
      "logps/rejected": -163.21945190429688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0901942253112793,
      "rewards/margins": 8.468194007873535,
      "rewards/rejected": -6.377999305725098,
      "step": 2236
    },
    {
      "epoch": 0.8948,
      "grad_norm": 0.01656801998615265,
      "learning_rate": 7.018666666666666e-07,
      "logits/chosen": -2.0820460319519043,
      "logits/rejected": -2.9834752082824707,
      "logps/chosen": -114.482666015625,
      "logps/rejected": -174.11459350585938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8551208972930908,
      "rewards/margins": 9.19390869140625,
      "rewards/rejected": -7.338788032531738,
      "step": 2237
    },
    {
      "epoch": 0.8952,
      "grad_norm": 0.02012573927640915,
      "learning_rate": 7.017333333333333e-07,
      "logits/chosen": -2.182868003845215,
      "logits/rejected": -3.16542387008667,
      "logps/chosen": -108.78976440429688,
      "logps/rejected": -162.96273803710938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9833555221557617,
      "rewards/margins": 9.464900970458984,
      "rewards/rejected": -5.481545448303223,
      "step": 2238
    },
    {
      "epoch": 0.8956,
      "grad_norm": 0.3296869993209839,
      "learning_rate": 7.016e-07,
      "logits/chosen": -2.480045795440674,
      "logits/rejected": -2.665471315383911,
      "logps/chosen": -160.24896240234375,
      "logps/rejected": -162.6687774658203,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6679824590682983,
      "rewards/margins": 7.7109527587890625,
      "rewards/rejected": -6.042970657348633,
      "step": 2239
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.020789949223399162,
      "learning_rate": 7.014666666666667e-07,
      "logits/chosen": -1.6871755123138428,
      "logits/rejected": -3.1911799907684326,
      "logps/chosen": -122.6614761352539,
      "logps/rejected": -157.73825073242188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2077488899230957,
      "rewards/margins": 8.905379295349121,
      "rewards/rejected": -5.697630405426025,
      "step": 2240
    },
    {
      "epoch": 0.8964,
      "grad_norm": 0.2277364879846573,
      "learning_rate": 7.013333333333334e-07,
      "logits/chosen": -1.5800824165344238,
      "logits/rejected": -3.8272669315338135,
      "logps/chosen": -99.81696319580078,
      "logps/rejected": -167.3865203857422,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6526062488555908,
      "rewards/margins": 7.2258405685424805,
      "rewards/rejected": -5.573234558105469,
      "step": 2241
    },
    {
      "epoch": 0.8968,
      "grad_norm": 0.44196605682373047,
      "learning_rate": 7.012000000000001e-07,
      "logits/chosen": -2.202608346939087,
      "logits/rejected": -3.1024680137634277,
      "logps/chosen": -87.263427734375,
      "logps/rejected": -130.621337890625,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4675934314727783,
      "rewards/margins": 5.938898086547852,
      "rewards/rejected": -4.471304416656494,
      "step": 2242
    },
    {
      "epoch": 0.8972,
      "grad_norm": 0.021360520273447037,
      "learning_rate": 7.010666666666665e-07,
      "logits/chosen": -2.4716713428497314,
      "logits/rejected": -3.426684856414795,
      "logps/chosen": -128.41351318359375,
      "logps/rejected": -160.87342834472656,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2500336170196533,
      "rewards/margins": 8.492012023925781,
      "rewards/rejected": -6.241978645324707,
      "step": 2243
    },
    {
      "epoch": 0.8976,
      "grad_norm": 0.061243124306201935,
      "learning_rate": 7.009333333333332e-07,
      "logits/chosen": -2.0186607837677,
      "logits/rejected": -2.6930394172668457,
      "logps/chosen": -67.51213073730469,
      "logps/rejected": -119.62067413330078,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3882155418395996,
      "rewards/margins": 7.542871475219727,
      "rewards/rejected": -4.154655933380127,
      "step": 2244
    },
    {
      "epoch": 0.898,
      "grad_norm": 0.4554857313632965,
      "learning_rate": 7.007999999999999e-07,
      "logits/chosen": -2.20544171333313,
      "logits/rejected": -3.268876075744629,
      "logps/chosen": -127.85096740722656,
      "logps/rejected": -143.46920776367188,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9936493635177612,
      "rewards/margins": 6.6723127365112305,
      "rewards/rejected": -5.678663730621338,
      "step": 2245
    },
    {
      "epoch": 0.8984,
      "grad_norm": 4.743954658508301,
      "learning_rate": 7.006666666666666e-07,
      "logits/chosen": -2.3440423011779785,
      "logits/rejected": -3.444948673248291,
      "logps/chosen": -203.85035705566406,
      "logps/rejected": -196.20571899414062,
      "loss": 0.0359,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0932273864746094,
      "rewards/margins": 4.709404945373535,
      "rewards/rejected": -5.8026323318481445,
      "step": 2246
    },
    {
      "epoch": 0.8988,
      "grad_norm": 0.0072396788746118546,
      "learning_rate": 7.005333333333333e-07,
      "logits/chosen": -2.4335741996765137,
      "logits/rejected": -3.036461353302002,
      "logps/chosen": -179.13961791992188,
      "logps/rejected": -185.41896057128906,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.363530158996582,
      "rewards/margins": 10.522520065307617,
      "rewards/rejected": -7.158990859985352,
      "step": 2247
    },
    {
      "epoch": 0.8992,
      "grad_norm": 2.177001714706421,
      "learning_rate": 7.004e-07,
      "logits/chosen": -2.396202325820923,
      "logits/rejected": -3.469144582748413,
      "logps/chosen": -122.32223510742188,
      "logps/rejected": -147.8547821044922,
      "loss": 0.0184,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6930458545684814,
      "rewards/margins": 6.8342742919921875,
      "rewards/rejected": -5.141228199005127,
      "step": 2248
    },
    {
      "epoch": 0.8996,
      "grad_norm": 0.018850160762667656,
      "learning_rate": 7.002666666666667e-07,
      "logits/chosen": -2.3759608268737793,
      "logits/rejected": -3.648637294769287,
      "logps/chosen": -82.93095397949219,
      "logps/rejected": -166.64752197265625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.261584758758545,
      "rewards/margins": 9.189836502075195,
      "rewards/rejected": -6.928251266479492,
      "step": 2249
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.10902184993028641,
      "learning_rate": 7.001333333333334e-07,
      "logits/chosen": -1.9555881023406982,
      "logits/rejected": -2.804469585418701,
      "logps/chosen": -117.95606994628906,
      "logps/rejected": -205.59100341796875,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.857873558998108,
      "rewards/margins": 6.778933048248291,
      "rewards/rejected": -4.921059608459473,
      "step": 2250
    },
    {
      "epoch": 0.9004,
      "grad_norm": 0.035451408475637436,
      "learning_rate": 7e-07,
      "logits/chosen": -2.0134730339050293,
      "logits/rejected": -2.970553398132324,
      "logps/chosen": -93.40202331542969,
      "logps/rejected": -184.33612060546875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2311935424804688,
      "rewards/margins": 8.232755661010742,
      "rewards/rejected": -7.001562595367432,
      "step": 2251
    },
    {
      "epoch": 0.9008,
      "grad_norm": 0.04373570904135704,
      "learning_rate": 6.998666666666666e-07,
      "logits/chosen": -2.5874247550964355,
      "logits/rejected": -3.3182363510131836,
      "logps/chosen": -115.71626281738281,
      "logps/rejected": -150.70361328125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3640060424804688,
      "rewards/margins": 7.853560924530029,
      "rewards/rejected": -6.489554405212402,
      "step": 2252
    },
    {
      "epoch": 0.9012,
      "grad_norm": 9.086993217468262,
      "learning_rate": 6.997333333333332e-07,
      "logits/chosen": -2.5602216720581055,
      "logits/rejected": -3.1386361122131348,
      "logps/chosen": -156.3778533935547,
      "logps/rejected": -143.8133544921875,
      "loss": 0.1077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.00614166259765625,
      "rewards/margins": 4.992031097412109,
      "rewards/rejected": -4.998172760009766,
      "step": 2253
    },
    {
      "epoch": 0.9016,
      "grad_norm": 2.781137704849243,
      "learning_rate": 6.995999999999999e-07,
      "logits/chosen": -2.9364733695983887,
      "logits/rejected": -2.970754623413086,
      "logps/chosen": -203.99729919433594,
      "logps/rejected": -275.2266540527344,
      "loss": 0.019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5466201901435852,
      "rewards/margins": 4.5067138671875,
      "rewards/rejected": -5.0533342361450195,
      "step": 2254
    },
    {
      "epoch": 0.902,
      "grad_norm": 0.012531126849353313,
      "learning_rate": 6.994666666666666e-07,
      "logits/chosen": -2.541149616241455,
      "logits/rejected": -3.21608304977417,
      "logps/chosen": -153.69065856933594,
      "logps/rejected": -204.8504638671875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5409317016601562,
      "rewards/margins": 10.75230598449707,
      "rewards/rejected": -7.211374282836914,
      "step": 2255
    },
    {
      "epoch": 0.9024,
      "grad_norm": 0.14485950767993927,
      "learning_rate": 6.993333333333333e-07,
      "logits/chosen": -2.8661255836486816,
      "logits/rejected": -2.9897818565368652,
      "logps/chosen": -221.51443481445312,
      "logps/rejected": -175.89288330078125,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0745460987091064,
      "rewards/margins": 7.087125301361084,
      "rewards/rejected": -6.012578964233398,
      "step": 2256
    },
    {
      "epoch": 0.9028,
      "grad_norm": 0.05098958685994148,
      "learning_rate": 6.992e-07,
      "logits/chosen": -2.4808077812194824,
      "logits/rejected": -3.5126733779907227,
      "logps/chosen": -168.9813995361328,
      "logps/rejected": -166.8772735595703,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6189637184143066,
      "rewards/margins": 7.7644853591918945,
      "rewards/rejected": -5.14552116394043,
      "step": 2257
    },
    {
      "epoch": 0.9032,
      "grad_norm": 0.2752719521522522,
      "learning_rate": 6.990666666666666e-07,
      "logits/chosen": -1.9298570156097412,
      "logits/rejected": -2.5726373195648193,
      "logps/chosen": -145.3185577392578,
      "logps/rejected": -142.60244750976562,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6293659210205078,
      "rewards/margins": 6.008251190185547,
      "rewards/rejected": -5.378885269165039,
      "step": 2258
    },
    {
      "epoch": 0.9036,
      "grad_norm": 0.0028057743329554796,
      "learning_rate": 6.989333333333333e-07,
      "logits/chosen": -2.512162446975708,
      "logits/rejected": -3.2178657054901123,
      "logps/chosen": -94.26307678222656,
      "logps/rejected": -200.7686767578125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.601956367492676,
      "rewards/margins": 11.161832809448242,
      "rewards/rejected": -6.559876441955566,
      "step": 2259
    },
    {
      "epoch": 0.904,
      "grad_norm": 2.6963798999786377,
      "learning_rate": 6.988e-07,
      "logits/chosen": -2.385272264480591,
      "logits/rejected": -2.96519136428833,
      "logps/chosen": -108.23815155029297,
      "logps/rejected": -139.47894287109375,
      "loss": 0.0217,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.817063570022583,
      "rewards/margins": 7.15451717376709,
      "rewards/rejected": -4.337453842163086,
      "step": 2260
    },
    {
      "epoch": 0.9044,
      "grad_norm": 6.006587028503418,
      "learning_rate": 6.986666666666667e-07,
      "logits/chosen": -2.3542540073394775,
      "logits/rejected": -2.8401260375976562,
      "logps/chosen": -143.8843994140625,
      "logps/rejected": -136.1962890625,
      "loss": 0.0426,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.17425692081451416,
      "rewards/margins": 5.551322937011719,
      "rewards/rejected": -5.725579261779785,
      "step": 2261
    },
    {
      "epoch": 0.9048,
      "grad_norm": 0.032554056495428085,
      "learning_rate": 6.985333333333333e-07,
      "logits/chosen": -2.147226095199585,
      "logits/rejected": -3.0972533226013184,
      "logps/chosen": -122.62383270263672,
      "logps/rejected": -162.12803649902344,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2931151390075684,
      "rewards/margins": 8.327919006347656,
      "rewards/rejected": -6.034804344177246,
      "step": 2262
    },
    {
      "epoch": 0.9052,
      "grad_norm": 0.1465328335762024,
      "learning_rate": 6.984e-07,
      "logits/chosen": -2.003157615661621,
      "logits/rejected": -2.8256778717041016,
      "logps/chosen": -118.35948944091797,
      "logps/rejected": -145.42552185058594,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.716794013977051,
      "rewards/margins": 8.270027160644531,
      "rewards/rejected": -4.553234100341797,
      "step": 2263
    },
    {
      "epoch": 0.9056,
      "grad_norm": 0.18757203221321106,
      "learning_rate": 6.982666666666666e-07,
      "logits/chosen": -2.29862904548645,
      "logits/rejected": -2.97127628326416,
      "logps/chosen": -96.02870178222656,
      "logps/rejected": -137.92739868164062,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.310424327850342,
      "rewards/margins": 7.6525702476501465,
      "rewards/rejected": -5.342145919799805,
      "step": 2264
    },
    {
      "epoch": 0.906,
      "grad_norm": 0.00649124663323164,
      "learning_rate": 6.981333333333333e-07,
      "logits/chosen": -2.1409122943878174,
      "logits/rejected": -3.7489542961120605,
      "logps/chosen": -88.84806060791016,
      "logps/rejected": -186.89039611816406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.264683485031128,
      "rewards/margins": 10.053960800170898,
      "rewards/rejected": -6.789276599884033,
      "step": 2265
    },
    {
      "epoch": 0.9064,
      "grad_norm": 0.08115831017494202,
      "learning_rate": 6.979999999999999e-07,
      "logits/chosen": -2.128674030303955,
      "logits/rejected": -2.5551390647888184,
      "logps/chosen": -75.5509033203125,
      "logps/rejected": -118.19937133789062,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6621522903442383,
      "rewards/margins": 7.309062957763672,
      "rewards/rejected": -4.646910667419434,
      "step": 2266
    },
    {
      "epoch": 0.9068,
      "grad_norm": 0.08757045865058899,
      "learning_rate": 6.978666666666666e-07,
      "logits/chosen": -1.975314736366272,
      "logits/rejected": -3.3673791885375977,
      "logps/chosen": -114.44034576416016,
      "logps/rejected": -151.77862548828125,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9591900706291199,
      "rewards/margins": 7.385563850402832,
      "rewards/rejected": -6.426373481750488,
      "step": 2267
    },
    {
      "epoch": 0.9072,
      "grad_norm": 0.041103970259428024,
      "learning_rate": 6.977333333333333e-07,
      "logits/chosen": -2.082186222076416,
      "logits/rejected": -2.98458194732666,
      "logps/chosen": -149.574951171875,
      "logps/rejected": -156.65159606933594,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.956059455871582,
      "rewards/margins": 9.295571327209473,
      "rewards/rejected": -5.339511871337891,
      "step": 2268
    },
    {
      "epoch": 0.9076,
      "grad_norm": 0.004431560635566711,
      "learning_rate": 6.976e-07,
      "logits/chosen": -2.106125593185425,
      "logits/rejected": -3.034592628479004,
      "logps/chosen": -86.24446868896484,
      "logps/rejected": -202.7021484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.027371406555176,
      "rewards/margins": 10.457748413085938,
      "rewards/rejected": -6.43037748336792,
      "step": 2269
    },
    {
      "epoch": 0.908,
      "grad_norm": 1.0616517066955566,
      "learning_rate": 6.974666666666667e-07,
      "logits/chosen": -2.278550148010254,
      "logits/rejected": -2.863748550415039,
      "logps/chosen": -89.826904296875,
      "logps/rejected": -144.4639892578125,
      "loss": 0.0123,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4491157531738281,
      "rewards/margins": 6.534964561462402,
      "rewards/rejected": -5.085848808288574,
      "step": 2270
    },
    {
      "epoch": 0.9084,
      "grad_norm": 0.006797339767217636,
      "learning_rate": 6.973333333333333e-07,
      "logits/chosen": -2.486292839050293,
      "logits/rejected": -3.3989486694335938,
      "logps/chosen": -131.1087646484375,
      "logps/rejected": -212.09814453125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.854518175125122,
      "rewards/margins": 10.126413345336914,
      "rewards/rejected": -6.271895408630371,
      "step": 2271
    },
    {
      "epoch": 0.9088,
      "grad_norm": 0.032672155648469925,
      "learning_rate": 6.972e-07,
      "logits/chosen": -2.3638405799865723,
      "logits/rejected": -2.8519492149353027,
      "logps/chosen": -181.1370849609375,
      "logps/rejected": -238.5245819091797,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7364044189453125,
      "rewards/margins": 9.374768257141113,
      "rewards/rejected": -5.638363838195801,
      "step": 2272
    },
    {
      "epoch": 0.9092,
      "grad_norm": 0.023003077134490013,
      "learning_rate": 6.970666666666666e-07,
      "logits/chosen": -2.086517095565796,
      "logits/rejected": -3.347646951675415,
      "logps/chosen": -96.80696105957031,
      "logps/rejected": -178.36282348632812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8785791397094727,
      "rewards/margins": 9.460785865783691,
      "rewards/rejected": -6.582206726074219,
      "step": 2273
    },
    {
      "epoch": 0.9096,
      "grad_norm": 3.569899320602417,
      "learning_rate": 6.969333333333332e-07,
      "logits/chosen": -2.9628500938415527,
      "logits/rejected": -2.472994327545166,
      "logps/chosen": -152.6266632080078,
      "logps/rejected": -154.76295471191406,
      "loss": 0.0176,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.17278176546096802,
      "rewards/margins": 5.475379467010498,
      "rewards/rejected": -5.648160934448242,
      "step": 2274
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.08425857871770859,
      "learning_rate": 6.967999999999999e-07,
      "logits/chosen": -2.192422389984131,
      "logits/rejected": -2.846142292022705,
      "logps/chosen": -80.85079956054688,
      "logps/rejected": -151.9709014892578,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.660820960998535,
      "rewards/margins": 9.280150413513184,
      "rewards/rejected": -5.619329929351807,
      "step": 2275
    },
    {
      "epoch": 0.9104,
      "grad_norm": 0.03207678347826004,
      "learning_rate": 6.966666666666666e-07,
      "logits/chosen": -2.5495548248291016,
      "logits/rejected": -3.2231743335723877,
      "logps/chosen": -178.8694610595703,
      "logps/rejected": -147.18658447265625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7253894805908203,
      "rewards/margins": 8.544290542602539,
      "rewards/rejected": -5.8189005851745605,
      "step": 2276
    },
    {
      "epoch": 0.9108,
      "grad_norm": 0.07437628507614136,
      "learning_rate": 6.965333333333333e-07,
      "logits/chosen": -3.2270238399505615,
      "logits/rejected": -2.9752302169799805,
      "logps/chosen": -235.17958068847656,
      "logps/rejected": -191.66848754882812,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.658639669418335,
      "rewards/margins": 7.452466011047363,
      "rewards/rejected": -5.793826103210449,
      "step": 2277
    },
    {
      "epoch": 0.9112,
      "grad_norm": 0.18219877779483795,
      "learning_rate": 6.964e-07,
      "logits/chosen": -2.617457866668701,
      "logits/rejected": -3.064822196960449,
      "logps/chosen": -189.59756469726562,
      "logps/rejected": -158.78521728515625,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7152191400527954,
      "rewards/margins": 6.603024482727051,
      "rewards/rejected": -4.887805938720703,
      "step": 2278
    },
    {
      "epoch": 0.9116,
      "grad_norm": 0.1343955546617508,
      "learning_rate": 6.962666666666667e-07,
      "logits/chosen": -2.1785495281219482,
      "logits/rejected": -3.4723105430603027,
      "logps/chosen": -232.76560974121094,
      "logps/rejected": -161.29550170898438,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.656023383140564,
      "rewards/margins": 7.06927490234375,
      "rewards/rejected": -5.413251876831055,
      "step": 2279
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.2934489846229553,
      "learning_rate": 6.961333333333334e-07,
      "logits/chosen": -2.0106983184814453,
      "logits/rejected": -2.7904772758483887,
      "logps/chosen": -81.87406921386719,
      "logps/rejected": -159.7347412109375,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.155881404876709,
      "rewards/margins": 7.581387996673584,
      "rewards/rejected": -5.425506591796875,
      "step": 2280
    },
    {
      "epoch": 0.9124,
      "grad_norm": 0.11469109356403351,
      "learning_rate": 6.959999999999999e-07,
      "logits/chosen": -2.754232883453369,
      "logits/rejected": -3.6225204467773438,
      "logps/chosen": -168.01651000976562,
      "logps/rejected": -174.014892578125,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0389366149902344,
      "rewards/margins": 8.518699645996094,
      "rewards/rejected": -5.479762554168701,
      "step": 2281
    },
    {
      "epoch": 0.9128,
      "grad_norm": 0.0012269985163584352,
      "learning_rate": 6.958666666666666e-07,
      "logits/chosen": -2.5238375663757324,
      "logits/rejected": -3.7729544639587402,
      "logps/chosen": -107.53828430175781,
      "logps/rejected": -191.15074157714844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.509270191192627,
      "rewards/margins": 11.41836166381836,
      "rewards/rejected": -6.909090995788574,
      "step": 2282
    },
    {
      "epoch": 0.9132,
      "grad_norm": 0.004550907760858536,
      "learning_rate": 6.957333333333333e-07,
      "logits/chosen": -2.5445573329925537,
      "logits/rejected": -3.0473198890686035,
      "logps/chosen": -172.48931884765625,
      "logps/rejected": -170.33261108398438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.478672027587891,
      "rewards/margins": 10.9805269241333,
      "rewards/rejected": -6.50185489654541,
      "step": 2283
    },
    {
      "epoch": 0.9136,
      "grad_norm": 0.09876719117164612,
      "learning_rate": 6.956e-07,
      "logits/chosen": -2.265801429748535,
      "logits/rejected": -3.430178642272949,
      "logps/chosen": -111.32902526855469,
      "logps/rejected": -159.77279663085938,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5696690082550049,
      "rewards/margins": 8.203035354614258,
      "rewards/rejected": -6.633365631103516,
      "step": 2284
    },
    {
      "epoch": 0.914,
      "grad_norm": 0.07543006539344788,
      "learning_rate": 6.954666666666666e-07,
      "logits/chosen": -2.3239705562591553,
      "logits/rejected": -3.259444236755371,
      "logps/chosen": -134.99484252929688,
      "logps/rejected": -170.78958129882812,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9480526447296143,
      "rewards/margins": 9.254171371459961,
      "rewards/rejected": -6.306118965148926,
      "step": 2285
    },
    {
      "epoch": 0.9144,
      "grad_norm": 0.07619946449995041,
      "learning_rate": 6.953333333333333e-07,
      "logits/chosen": -2.3737874031066895,
      "logits/rejected": -3.081770420074463,
      "logps/chosen": -161.29470825195312,
      "logps/rejected": -145.7581787109375,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7698235511779785,
      "rewards/margins": 7.455856800079346,
      "rewards/rejected": -4.686033248901367,
      "step": 2286
    },
    {
      "epoch": 0.9148,
      "grad_norm": 0.058333754539489746,
      "learning_rate": 6.952e-07,
      "logits/chosen": -2.1238555908203125,
      "logits/rejected": -2.920506000518799,
      "logps/chosen": -100.3043212890625,
      "logps/rejected": -163.305908203125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1169097423553467,
      "rewards/margins": 8.095719337463379,
      "rewards/rejected": -4.978809356689453,
      "step": 2287
    },
    {
      "epoch": 0.9152,
      "grad_norm": 0.010724115185439587,
      "learning_rate": 6.950666666666667e-07,
      "logits/chosen": -2.0741987228393555,
      "logits/rejected": -3.4075541496276855,
      "logps/chosen": -84.5709228515625,
      "logps/rejected": -168.2048797607422,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.194080114364624,
      "rewards/margins": 9.250246047973633,
      "rewards/rejected": -6.05616569519043,
      "step": 2288
    },
    {
      "epoch": 0.9156,
      "grad_norm": 0.25588753819465637,
      "learning_rate": 6.949333333333333e-07,
      "logits/chosen": -1.733028531074524,
      "logits/rejected": -2.7392847537994385,
      "logps/chosen": -103.71926879882812,
      "logps/rejected": -200.93968200683594,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.451566696166992,
      "rewards/margins": 9.03390884399414,
      "rewards/rejected": -5.582342624664307,
      "step": 2289
    },
    {
      "epoch": 0.916,
      "grad_norm": 0.9663800597190857,
      "learning_rate": 6.947999999999999e-07,
      "logits/chosen": -2.3254706859588623,
      "logits/rejected": -3.1455187797546387,
      "logps/chosen": -140.565673828125,
      "logps/rejected": -151.95144653320312,
      "loss": 0.0093,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4296364188194275,
      "rewards/margins": 4.922124862670898,
      "rewards/rejected": -5.351761341094971,
      "step": 2290
    },
    {
      "epoch": 0.9164,
      "grad_norm": 0.005049953702837229,
      "learning_rate": 6.946666666666666e-07,
      "logits/chosen": -1.6247515678405762,
      "logits/rejected": -2.93412446975708,
      "logps/chosen": -97.0936050415039,
      "logps/rejected": -175.77581787109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.710421085357666,
      "rewards/margins": 10.46270751953125,
      "rewards/rejected": -7.752285957336426,
      "step": 2291
    },
    {
      "epoch": 0.9168,
      "grad_norm": 0.06188785284757614,
      "learning_rate": 6.945333333333333e-07,
      "logits/chosen": -2.3011927604675293,
      "logits/rejected": -3.1674914360046387,
      "logps/chosen": -207.9693603515625,
      "logps/rejected": -146.82669067382812,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1605262756347656,
      "rewards/margins": 7.513263702392578,
      "rewards/rejected": -5.3527374267578125,
      "step": 2292
    },
    {
      "epoch": 0.9172,
      "grad_norm": 0.27499091625213623,
      "learning_rate": 6.944e-07,
      "logits/chosen": -1.9767940044403076,
      "logits/rejected": -3.140411853790283,
      "logps/chosen": -103.37313079833984,
      "logps/rejected": -148.5960235595703,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.084912896156311,
      "rewards/margins": 6.340502738952637,
      "rewards/rejected": -5.255589485168457,
      "step": 2293
    },
    {
      "epoch": 0.9176,
      "grad_norm": 0.006458422634750605,
      "learning_rate": 6.942666666666667e-07,
      "logits/chosen": -2.468710422515869,
      "logits/rejected": -3.455718517303467,
      "logps/chosen": -76.29447174072266,
      "logps/rejected": -152.8096466064453,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.831632614135742,
      "rewards/margins": 9.853050231933594,
      "rewards/rejected": -6.021417617797852,
      "step": 2294
    },
    {
      "epoch": 0.918,
      "grad_norm": 0.16780687868595123,
      "learning_rate": 6.941333333333334e-07,
      "logits/chosen": -1.748690128326416,
      "logits/rejected": -3.7313480377197266,
      "logps/chosen": -93.27323913574219,
      "logps/rejected": -176.2093505859375,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4053211510181427,
      "rewards/margins": 7.258064270019531,
      "rewards/rejected": -6.852743148803711,
      "step": 2295
    },
    {
      "epoch": 0.9184,
      "grad_norm": 0.21908706426620483,
      "learning_rate": 6.939999999999999e-07,
      "logits/chosen": -1.9781858921051025,
      "logits/rejected": -3.2288548946380615,
      "logps/chosen": -72.73987579345703,
      "logps/rejected": -139.2681427001953,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0878727436065674,
      "rewards/margins": 7.055403709411621,
      "rewards/rejected": -3.9675307273864746,
      "step": 2296
    },
    {
      "epoch": 0.9188,
      "grad_norm": 0.16351135075092316,
      "learning_rate": 6.938666666666666e-07,
      "logits/chosen": -2.1967110633850098,
      "logits/rejected": -2.6761302947998047,
      "logps/chosen": -142.65817260742188,
      "logps/rejected": -134.02896118164062,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2627357244491577,
      "rewards/margins": 6.613351345062256,
      "rewards/rejected": -5.350615501403809,
      "step": 2297
    },
    {
      "epoch": 0.9192,
      "grad_norm": 0.07136930525302887,
      "learning_rate": 6.937333333333333e-07,
      "logits/chosen": -2.600269317626953,
      "logits/rejected": -3.376828193664551,
      "logps/chosen": -137.0059814453125,
      "logps/rejected": -167.02903747558594,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.121894121170044,
      "rewards/margins": 8.154158592224121,
      "rewards/rejected": -6.032264709472656,
      "step": 2298
    },
    {
      "epoch": 0.9196,
      "grad_norm": 2.5778727531433105,
      "learning_rate": 6.935999999999999e-07,
      "logits/chosen": -1.8609142303466797,
      "logits/rejected": -3.02256441116333,
      "logps/chosen": -128.47500610351562,
      "logps/rejected": -187.54905700683594,
      "loss": 0.0225,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5363884568214417,
      "rewards/margins": 5.879053115844727,
      "rewards/rejected": -5.34266471862793,
      "step": 2299
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.031001882627606392,
      "learning_rate": 6.934666666666666e-07,
      "logits/chosen": -2.505375385284424,
      "logits/rejected": -3.2434380054473877,
      "logps/chosen": -103.66442108154297,
      "logps/rejected": -194.4322052001953,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0063374042510986,
      "rewards/margins": 9.015983581542969,
      "rewards/rejected": -7.009646415710449,
      "step": 2300
    },
    {
      "epoch": 0.9204,
      "grad_norm": 0.0014473228948190808,
      "learning_rate": 6.933333333333333e-07,
      "logits/chosen": -2.035615921020508,
      "logits/rejected": -3.4547085762023926,
      "logps/chosen": -95.10186004638672,
      "logps/rejected": -158.55059814453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.664370059967041,
      "rewards/margins": 11.305370330810547,
      "rewards/rejected": -6.640999794006348,
      "step": 2301
    },
    {
      "epoch": 0.9208,
      "grad_norm": 0.47052451968193054,
      "learning_rate": 6.932e-07,
      "logits/chosen": -2.6738967895507812,
      "logits/rejected": -3.587881565093994,
      "logps/chosen": -103.35576629638672,
      "logps/rejected": -134.3961639404297,
      "loss": 0.0052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.095393657684326,
      "rewards/margins": 6.5521240234375,
      "rewards/rejected": -4.456730365753174,
      "step": 2302
    },
    {
      "epoch": 0.9212,
      "grad_norm": 0.04174390435218811,
      "learning_rate": 6.930666666666667e-07,
      "logits/chosen": -2.337608814239502,
      "logits/rejected": -3.462286949157715,
      "logps/chosen": -121.81440734863281,
      "logps/rejected": -158.8795166015625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6633849143981934,
      "rewards/margins": 9.541690826416016,
      "rewards/rejected": -6.878305912017822,
      "step": 2303
    },
    {
      "epoch": 0.9216,
      "grad_norm": 0.013595697470009327,
      "learning_rate": 6.929333333333333e-07,
      "logits/chosen": -2.1830544471740723,
      "logits/rejected": -3.2713208198547363,
      "logps/chosen": -118.1462173461914,
      "logps/rejected": -171.1597900390625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6337389945983887,
      "rewards/margins": 8.932514190673828,
      "rewards/rejected": -5.298775672912598,
      "step": 2304
    },
    {
      "epoch": 0.922,
      "grad_norm": 0.11683931201696396,
      "learning_rate": 6.928e-07,
      "logits/chosen": -2.3887739181518555,
      "logits/rejected": -2.7242836952209473,
      "logps/chosen": -144.7977294921875,
      "logps/rejected": -208.79965209960938,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8456702828407288,
      "rewards/margins": 6.869497299194336,
      "rewards/rejected": -6.023827075958252,
      "step": 2305
    },
    {
      "epoch": 0.9224,
      "grad_norm": 0.006338325794786215,
      "learning_rate": 6.926666666666666e-07,
      "logits/chosen": -2.417886734008789,
      "logits/rejected": -3.3032450675964355,
      "logps/chosen": -101.67584228515625,
      "logps/rejected": -168.37088012695312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.176656723022461,
      "rewards/margins": 11.05659294128418,
      "rewards/rejected": -6.879936218261719,
      "step": 2306
    },
    {
      "epoch": 0.9228,
      "grad_norm": 0.007531343027949333,
      "learning_rate": 6.925333333333333e-07,
      "logits/chosen": -2.305847406387329,
      "logits/rejected": -3.260249376296997,
      "logps/chosen": -122.07398986816406,
      "logps/rejected": -217.65719604492188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7172558307647705,
      "rewards/margins": 10.36661148071289,
      "rewards/rejected": -7.649355411529541,
      "step": 2307
    },
    {
      "epoch": 0.9232,
      "grad_norm": 0.7950069904327393,
      "learning_rate": 6.924e-07,
      "logits/chosen": -2.2286057472229004,
      "logits/rejected": -3.197326183319092,
      "logps/chosen": -101.5661392211914,
      "logps/rejected": -146.220947265625,
      "loss": 0.0071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0434257984161377,
      "rewards/margins": 5.806056022644043,
      "rewards/rejected": -4.762630462646484,
      "step": 2308
    },
    {
      "epoch": 0.9236,
      "grad_norm": 0.07675673067569733,
      "learning_rate": 6.922666666666666e-07,
      "logits/chosen": -2.4441936016082764,
      "logits/rejected": -3.7652029991149902,
      "logps/chosen": -114.34844207763672,
      "logps/rejected": -180.18182373046875,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4110866785049438,
      "rewards/margins": 9.017730712890625,
      "rewards/rejected": -7.6066436767578125,
      "step": 2309
    },
    {
      "epoch": 0.924,
      "grad_norm": 2.507341146469116,
      "learning_rate": 6.921333333333333e-07,
      "logits/chosen": -2.4875454902648926,
      "logits/rejected": -3.334641933441162,
      "logps/chosen": -133.78915405273438,
      "logps/rejected": -180.02371215820312,
      "loss": 0.0139,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2226043939590454,
      "rewards/margins": 6.166192054748535,
      "rewards/rejected": -5.9435882568359375,
      "step": 2310
    },
    {
      "epoch": 0.9244,
      "grad_norm": 0.030444849282503128,
      "learning_rate": 6.919999999999999e-07,
      "logits/chosen": -2.0908188819885254,
      "logits/rejected": -3.2889037132263184,
      "logps/chosen": -84.67357635498047,
      "logps/rejected": -161.56732177734375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.168938636779785,
      "rewards/margins": 8.874551773071289,
      "rewards/rejected": -5.705613613128662,
      "step": 2311
    },
    {
      "epoch": 0.9248,
      "grad_norm": 0.0880507379770279,
      "learning_rate": 6.918666666666666e-07,
      "logits/chosen": -2.320577621459961,
      "logits/rejected": -2.9622232913970947,
      "logps/chosen": -163.1790313720703,
      "logps/rejected": -151.80372619628906,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4968388080596924,
      "rewards/margins": 7.814304351806641,
      "rewards/rejected": -5.317465782165527,
      "step": 2312
    },
    {
      "epoch": 0.9252,
      "grad_norm": 0.020232433453202248,
      "learning_rate": 6.917333333333333e-07,
      "logits/chosen": -1.9142910242080688,
      "logits/rejected": -3.648036479949951,
      "logps/chosen": -156.7085723876953,
      "logps/rejected": -201.4310302734375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.930645704269409,
      "rewards/margins": 9.011509895324707,
      "rewards/rejected": -6.080863952636719,
      "step": 2313
    },
    {
      "epoch": 0.9256,
      "grad_norm": 14.392733573913574,
      "learning_rate": 6.916e-07,
      "logits/chosen": -2.5763497352600098,
      "logits/rejected": -2.9951353073120117,
      "logps/chosen": -131.7490997314453,
      "logps/rejected": -131.40560913085938,
      "loss": 0.0675,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.11044919490814209,
      "rewards/margins": 5.436036109924316,
      "rewards/rejected": -5.54648494720459,
      "step": 2314
    },
    {
      "epoch": 0.926,
      "grad_norm": 1.2195943593978882,
      "learning_rate": 6.914666666666667e-07,
      "logits/chosen": -1.9067944288253784,
      "logits/rejected": -2.8031699657440186,
      "logps/chosen": -102.68460845947266,
      "logps/rejected": -105.5086669921875,
      "loss": 0.0159,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9424377679824829,
      "rewards/margins": 4.223090171813965,
      "rewards/rejected": -3.2806522846221924,
      "step": 2315
    },
    {
      "epoch": 0.9264,
      "grad_norm": 0.029975375160574913,
      "learning_rate": 6.913333333333334e-07,
      "logits/chosen": -1.8231675624847412,
      "logits/rejected": -3.084230661392212,
      "logps/chosen": -94.95008850097656,
      "logps/rejected": -142.99887084960938,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.767150402069092,
      "rewards/margins": 8.200166702270508,
      "rewards/rejected": -5.433016300201416,
      "step": 2316
    },
    {
      "epoch": 0.9268,
      "grad_norm": 0.012602078728377819,
      "learning_rate": 6.912e-07,
      "logits/chosen": -2.151176929473877,
      "logits/rejected": -3.4629769325256348,
      "logps/chosen": -148.17572021484375,
      "logps/rejected": -177.16510009765625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.407214164733887,
      "rewards/margins": 9.424653053283691,
      "rewards/rejected": -5.017438888549805,
      "step": 2317
    },
    {
      "epoch": 0.9272,
      "grad_norm": 0.3464704751968384,
      "learning_rate": 6.910666666666666e-07,
      "logits/chosen": -2.5247440338134766,
      "logits/rejected": -3.5114173889160156,
      "logps/chosen": -101.79986572265625,
      "logps/rejected": -172.12982177734375,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6895653009414673,
      "rewards/margins": 6.358715057373047,
      "rewards/rejected": -4.669149875640869,
      "step": 2318
    },
    {
      "epoch": 0.9276,
      "grad_norm": 0.45342200994491577,
      "learning_rate": 6.909333333333332e-07,
      "logits/chosen": -1.9633243083953857,
      "logits/rejected": -3.8004794120788574,
      "logps/chosen": -91.49031066894531,
      "logps/rejected": -168.9766845703125,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7485436201095581,
      "rewards/margins": 6.814903736114502,
      "rewards/rejected": -6.0663604736328125,
      "step": 2319
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.557835042476654,
      "learning_rate": 6.907999999999999e-07,
      "logits/chosen": -2.9199154376983643,
      "logits/rejected": -3.1851704120635986,
      "logps/chosen": -130.52108764648438,
      "logps/rejected": -160.27500915527344,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0601773262023926,
      "rewards/margins": 7.526828765869141,
      "rewards/rejected": -5.466651439666748,
      "step": 2320
    },
    {
      "epoch": 0.9284,
      "grad_norm": 0.09076947718858719,
      "learning_rate": 6.906666666666666e-07,
      "logits/chosen": -2.107971668243408,
      "logits/rejected": -3.108401298522949,
      "logps/chosen": -126.09393310546875,
      "logps/rejected": -155.60821533203125,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.434908628463745,
      "rewards/margins": 8.561800003051758,
      "rewards/rejected": -5.12689208984375,
      "step": 2321
    },
    {
      "epoch": 0.9288,
      "grad_norm": 0.006380920298397541,
      "learning_rate": 6.905333333333333e-07,
      "logits/chosen": -2.2272965908050537,
      "logits/rejected": -3.648346424102783,
      "logps/chosen": -124.84109497070312,
      "logps/rejected": -165.07752990722656,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7727789878845215,
      "rewards/margins": 9.970209121704102,
      "rewards/rejected": -6.197430610656738,
      "step": 2322
    },
    {
      "epoch": 0.9292,
      "grad_norm": 0.10817437618970871,
      "learning_rate": 6.904e-07,
      "logits/chosen": -2.559077739715576,
      "logits/rejected": -3.357832431793213,
      "logps/chosen": -104.03715515136719,
      "logps/rejected": -177.70242309570312,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.447942018508911,
      "rewards/margins": 7.671427249908447,
      "rewards/rejected": -5.223484992980957,
      "step": 2323
    },
    {
      "epoch": 0.9296,
      "grad_norm": 0.04013579338788986,
      "learning_rate": 6.902666666666667e-07,
      "logits/chosen": -2.126467704772949,
      "logits/rejected": -3.0930044651031494,
      "logps/chosen": -156.58602905273438,
      "logps/rejected": -156.07440185546875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5559067726135254,
      "rewards/margins": 8.123835563659668,
      "rewards/rejected": -4.567928791046143,
      "step": 2324
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.03145534172654152,
      "learning_rate": 6.901333333333334e-07,
      "logits/chosen": -1.8671050071716309,
      "logits/rejected": -2.8566689491271973,
      "logps/chosen": -65.15709686279297,
      "logps/rejected": -117.64500427246094,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.832273244857788,
      "rewards/margins": 8.130270004272461,
      "rewards/rejected": -4.297996997833252,
      "step": 2325
    },
    {
      "epoch": 0.9304,
      "grad_norm": 0.0794462040066719,
      "learning_rate": 6.9e-07,
      "logits/chosen": -2.3958780765533447,
      "logits/rejected": -3.093543767929077,
      "logps/chosen": -131.71493530273438,
      "logps/rejected": -164.57363891601562,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7613646984100342,
      "rewards/margins": 7.624098777770996,
      "rewards/rejected": -5.862733840942383,
      "step": 2326
    },
    {
      "epoch": 0.9308,
      "grad_norm": 0.6510060429573059,
      "learning_rate": 6.898666666666665e-07,
      "logits/chosen": -2.8015997409820557,
      "logits/rejected": -3.449260711669922,
      "logps/chosen": -194.26199340820312,
      "logps/rejected": -169.5972900390625,
      "loss": 0.005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.096734046936035,
      "rewards/margins": 8.620798110961914,
      "rewards/rejected": -6.524064064025879,
      "step": 2327
    },
    {
      "epoch": 0.9312,
      "grad_norm": 1.5900206565856934,
      "learning_rate": 6.897333333333332e-07,
      "logits/chosen": -1.9560946226119995,
      "logits/rejected": -2.893655776977539,
      "logps/chosen": -155.3261260986328,
      "logps/rejected": -129.65518188476562,
      "loss": 0.0165,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6504795551300049,
      "rewards/margins": 4.099851608276367,
      "rewards/rejected": -4.750331401824951,
      "step": 2328
    },
    {
      "epoch": 0.9316,
      "grad_norm": 0.16174431145191193,
      "learning_rate": 6.895999999999999e-07,
      "logits/chosen": -2.300410747528076,
      "logits/rejected": -3.4887402057647705,
      "logps/chosen": -95.02472686767578,
      "logps/rejected": -165.82562255859375,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3774051666259766,
      "rewards/margins": 7.513991832733154,
      "rewards/rejected": -6.1365861892700195,
      "step": 2329
    },
    {
      "epoch": 0.932,
      "grad_norm": 0.44532138109207153,
      "learning_rate": 6.894666666666666e-07,
      "logits/chosen": -2.0627427101135254,
      "logits/rejected": -2.352548599243164,
      "logps/chosen": -122.60400390625,
      "logps/rejected": -124.80377197265625,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.79771888256073,
      "rewards/margins": 6.439420700073242,
      "rewards/rejected": -4.641701698303223,
      "step": 2330
    },
    {
      "epoch": 0.9324,
      "grad_norm": 0.08238810300827026,
      "learning_rate": 6.893333333333333e-07,
      "logits/chosen": -2.502985954284668,
      "logits/rejected": -2.21254301071167,
      "logps/chosen": -165.68788146972656,
      "logps/rejected": -166.74310302734375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4676568508148193,
      "rewards/margins": 7.801943778991699,
      "rewards/rejected": -4.334287166595459,
      "step": 2331
    },
    {
      "epoch": 0.9328,
      "grad_norm": 0.061402685940265656,
      "learning_rate": 6.892e-07,
      "logits/chosen": -1.8891187906265259,
      "logits/rejected": -3.2932119369506836,
      "logps/chosen": -113.83837127685547,
      "logps/rejected": -179.38555908203125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6875176429748535,
      "rewards/margins": 9.640132904052734,
      "rewards/rejected": -6.952615737915039,
      "step": 2332
    },
    {
      "epoch": 0.9332,
      "grad_norm": 0.03740813583135605,
      "learning_rate": 6.890666666666667e-07,
      "logits/chosen": -2.5883264541625977,
      "logits/rejected": -2.753114700317383,
      "logps/chosen": -100.72296142578125,
      "logps/rejected": -130.78302001953125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4381661415100098,
      "rewards/margins": 8.317380905151367,
      "rewards/rejected": -4.879215240478516,
      "step": 2333
    },
    {
      "epoch": 0.9336,
      "grad_norm": 0.2560746967792511,
      "learning_rate": 6.889333333333333e-07,
      "logits/chosen": -2.5867767333984375,
      "logits/rejected": -3.12045955657959,
      "logps/chosen": -95.59757232666016,
      "logps/rejected": -149.844970703125,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3800830841064453,
      "rewards/margins": 7.48206901550293,
      "rewards/rejected": -4.101985931396484,
      "step": 2334
    },
    {
      "epoch": 0.934,
      "grad_norm": 0.9645795822143555,
      "learning_rate": 6.888e-07,
      "logits/chosen": -2.6125876903533936,
      "logits/rejected": -3.586171865463257,
      "logps/chosen": -171.4463653564453,
      "logps/rejected": -243.45025634765625,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4731700420379639,
      "rewards/margins": 6.947223663330078,
      "rewards/rejected": -5.474053382873535,
      "step": 2335
    },
    {
      "epoch": 0.9344,
      "grad_norm": 0.20238812267780304,
      "learning_rate": 6.886666666666667e-07,
      "logits/chosen": -2.342562675476074,
      "logits/rejected": -3.5338268280029297,
      "logps/chosen": -145.220947265625,
      "logps/rejected": -202.37905883789062,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7872719764709473,
      "rewards/margins": 8.900422096252441,
      "rewards/rejected": -6.113150119781494,
      "step": 2336
    },
    {
      "epoch": 0.9348,
      "grad_norm": 0.0013791908277198672,
      "learning_rate": 6.885333333333333e-07,
      "logits/chosen": -2.7063546180725098,
      "logits/rejected": -3.758030652999878,
      "logps/chosen": -141.52000427246094,
      "logps/rejected": -192.92706298828125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.580500602722168,
      "rewards/margins": 11.424243927001953,
      "rewards/rejected": -6.843743324279785,
      "step": 2337
    },
    {
      "epoch": 0.9352,
      "grad_norm": 0.06289148330688477,
      "learning_rate": 6.883999999999999e-07,
      "logits/chosen": -2.084789276123047,
      "logits/rejected": -2.637204170227051,
      "logps/chosen": -114.32169342041016,
      "logps/rejected": -159.88796997070312,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8933801651000977,
      "rewards/margins": 7.701873779296875,
      "rewards/rejected": -4.808493614196777,
      "step": 2338
    },
    {
      "epoch": 0.9356,
      "grad_norm": 0.043977804481983185,
      "learning_rate": 6.882666666666666e-07,
      "logits/chosen": -2.02846622467041,
      "logits/rejected": -3.2720346450805664,
      "logps/chosen": -89.7076416015625,
      "logps/rejected": -139.0648956298828,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.416797161102295,
      "rewards/margins": 7.826755523681641,
      "rewards/rejected": -4.409958362579346,
      "step": 2339
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.33206507563591003,
      "learning_rate": 6.881333333333333e-07,
      "logits/chosen": -1.8473154306411743,
      "logits/rejected": -3.4173364639282227,
      "logps/chosen": -80.79753875732422,
      "logps/rejected": -131.95697021484375,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7226921319961548,
      "rewards/margins": 6.229052543640137,
      "rewards/rejected": -5.50636100769043,
      "step": 2340
    },
    {
      "epoch": 0.9364,
      "grad_norm": 0.017003614455461502,
      "learning_rate": 6.879999999999999e-07,
      "logits/chosen": -2.279386043548584,
      "logits/rejected": -3.602266311645508,
      "logps/chosen": -90.35721588134766,
      "logps/rejected": -171.20315551757812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0086960792541504,
      "rewards/margins": 9.024375915527344,
      "rewards/rejected": -7.015680313110352,
      "step": 2341
    },
    {
      "epoch": 0.9368,
      "grad_norm": 0.08119688183069229,
      "learning_rate": 6.878666666666666e-07,
      "logits/chosen": -2.1722419261932373,
      "logits/rejected": -3.4479880332946777,
      "logps/chosen": -97.3031234741211,
      "logps/rejected": -154.88433837890625,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2384865283966064,
      "rewards/margins": 8.243900299072266,
      "rewards/rejected": -6.00541353225708,
      "step": 2342
    },
    {
      "epoch": 0.9372,
      "grad_norm": 0.9101852774620056,
      "learning_rate": 6.877333333333333e-07,
      "logits/chosen": -2.587246894836426,
      "logits/rejected": -3.0704867839813232,
      "logps/chosen": -111.53965759277344,
      "logps/rejected": -148.05023193359375,
      "loss": 0.0083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1431735754013062,
      "rewards/margins": 6.070799350738525,
      "rewards/rejected": -4.92762565612793,
      "step": 2343
    },
    {
      "epoch": 0.9376,
      "grad_norm": 1.0143425464630127,
      "learning_rate": 6.876e-07,
      "logits/chosen": -2.036600351333618,
      "logits/rejected": -2.903677463531494,
      "logps/chosen": -137.18804931640625,
      "logps/rejected": -124.58042907714844,
      "loss": 0.0073,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.300568699836731,
      "rewards/margins": 5.412353515625,
      "rewards/rejected": -4.111784934997559,
      "step": 2344
    },
    {
      "epoch": 0.938,
      "grad_norm": 3.171389579772949,
      "learning_rate": 6.874666666666667e-07,
      "logits/chosen": -2.4799556732177734,
      "logits/rejected": -3.230797290802002,
      "logps/chosen": -113.49293518066406,
      "logps/rejected": -146.6014404296875,
      "loss": 0.0291,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6882331967353821,
      "rewards/margins": 4.494842529296875,
      "rewards/rejected": -5.183075428009033,
      "step": 2345
    },
    {
      "epoch": 0.9384,
      "grad_norm": 0.033152271062135696,
      "learning_rate": 6.873333333333334e-07,
      "logits/chosen": -2.079733371734619,
      "logits/rejected": -3.146315574645996,
      "logps/chosen": -126.7078628540039,
      "logps/rejected": -142.9080047607422,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.869401454925537,
      "rewards/margins": 9.265551567077637,
      "rewards/rejected": -5.396149635314941,
      "step": 2346
    },
    {
      "epoch": 0.9388,
      "grad_norm": 0.046470124274492264,
      "learning_rate": 6.872e-07,
      "logits/chosen": -2.180612564086914,
      "logits/rejected": -3.079639434814453,
      "logps/chosen": -131.7039031982422,
      "logps/rejected": -154.83407592773438,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0504631996154785,
      "rewards/margins": 8.914320945739746,
      "rewards/rejected": -5.863858222961426,
      "step": 2347
    },
    {
      "epoch": 0.9392,
      "grad_norm": 8.957571983337402,
      "learning_rate": 6.870666666666667e-07,
      "logits/chosen": -2.548027992248535,
      "logits/rejected": -3.491511821746826,
      "logps/chosen": -143.29721069335938,
      "logps/rejected": -150.33517456054688,
      "loss": 0.0888,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45873117446899414,
      "rewards/margins": 5.106339931488037,
      "rewards/rejected": -4.647608757019043,
      "step": 2348
    },
    {
      "epoch": 0.9396,
      "grad_norm": 7.808318138122559,
      "learning_rate": 6.869333333333332e-07,
      "logits/chosen": -2.195375680923462,
      "logits/rejected": -3.563765287399292,
      "logps/chosen": -78.94401550292969,
      "logps/rejected": -150.17835998535156,
      "loss": 0.0536,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.415515184402466,
      "rewards/margins": 5.520030498504639,
      "rewards/rejected": -3.1045150756835938,
      "step": 2349
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.19233183562755585,
      "learning_rate": 6.867999999999999e-07,
      "logits/chosen": -2.235171318054199,
      "logits/rejected": -2.6170294284820557,
      "logps/chosen": -110.6065673828125,
      "logps/rejected": -118.90567016601562,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.312540054321289,
      "rewards/margins": 6.571955680847168,
      "rewards/rejected": -4.259415626525879,
      "step": 2350
    },
    {
      "epoch": 0.9404,
      "grad_norm": 0.04069026559591293,
      "learning_rate": 6.866666666666666e-07,
      "logits/chosen": -2.5842628479003906,
      "logits/rejected": -2.770010471343994,
      "logps/chosen": -169.1854705810547,
      "logps/rejected": -170.7059326171875,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2248053550720215,
      "rewards/margins": 9.559368133544922,
      "rewards/rejected": -6.334562301635742,
      "step": 2351
    },
    {
      "epoch": 0.9408,
      "grad_norm": 0.19483527541160583,
      "learning_rate": 6.865333333333333e-07,
      "logits/chosen": -2.097109794616699,
      "logits/rejected": -2.816396713256836,
      "logps/chosen": -162.65870666503906,
      "logps/rejected": -159.79891967773438,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8350800275802612,
      "rewards/margins": 6.811674118041992,
      "rewards/rejected": -4.9765944480896,
      "step": 2352
    },
    {
      "epoch": 0.9412,
      "grad_norm": 0.1771705001592636,
      "learning_rate": 6.864e-07,
      "logits/chosen": -1.939808964729309,
      "logits/rejected": -3.152313709259033,
      "logps/chosen": -109.30769348144531,
      "logps/rejected": -133.29388427734375,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0069730281829834,
      "rewards/margins": 6.405821800231934,
      "rewards/rejected": -4.398848533630371,
      "step": 2353
    },
    {
      "epoch": 0.9416,
      "grad_norm": 0.15299762785434723,
      "learning_rate": 6.862666666666667e-07,
      "logits/chosen": -2.074032783508301,
      "logits/rejected": -3.1597065925598145,
      "logps/chosen": -124.06034088134766,
      "logps/rejected": -138.90057373046875,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6245132684707642,
      "rewards/margins": 6.4480438232421875,
      "rewards/rejected": -4.823530673980713,
      "step": 2354
    },
    {
      "epoch": 0.942,
      "grad_norm": 0.035577163100242615,
      "learning_rate": 6.861333333333334e-07,
      "logits/chosen": -2.5554046630859375,
      "logits/rejected": -3.1793670654296875,
      "logps/chosen": -134.0134735107422,
      "logps/rejected": -174.47320556640625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.177994728088379,
      "rewards/margins": 9.043497085571289,
      "rewards/rejected": -5.865503311157227,
      "step": 2355
    },
    {
      "epoch": 0.9424,
      "grad_norm": 0.15951311588287354,
      "learning_rate": 6.86e-07,
      "logits/chosen": -2.361672878265381,
      "logits/rejected": -3.65484356880188,
      "logps/chosen": -144.225341796875,
      "logps/rejected": -192.20790100097656,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.260531187057495,
      "rewards/margins": 9.657371520996094,
      "rewards/rejected": -7.3968400955200195,
      "step": 2356
    },
    {
      "epoch": 0.9428,
      "grad_norm": 0.007511944510042667,
      "learning_rate": 6.858666666666666e-07,
      "logits/chosen": -2.210582733154297,
      "logits/rejected": -3.613276958465576,
      "logps/chosen": -82.11541748046875,
      "logps/rejected": -210.12850952148438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4680538177490234,
      "rewards/margins": 10.319768905639648,
      "rewards/rejected": -8.851715087890625,
      "step": 2357
    },
    {
      "epoch": 0.9432,
      "grad_norm": 0.010575730353593826,
      "learning_rate": 6.857333333333333e-07,
      "logits/chosen": -2.5335617065429688,
      "logits/rejected": -3.353107452392578,
      "logps/chosen": -126.00227355957031,
      "logps/rejected": -161.96566772460938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6431896686553955,
      "rewards/margins": 9.469820022583008,
      "rewards/rejected": -6.826631546020508,
      "step": 2358
    },
    {
      "epoch": 0.9436,
      "grad_norm": 19.98630714416504,
      "learning_rate": 6.855999999999999e-07,
      "logits/chosen": -2.8150534629821777,
      "logits/rejected": -2.930004596710205,
      "logps/chosen": -108.69915771484375,
      "logps/rejected": -137.96786499023438,
      "loss": 0.2202,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.475785732269287,
      "rewards/margins": 2.4333393573760986,
      "rewards/rejected": -4.909125328063965,
      "step": 2359
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.0029627182520926,
      "learning_rate": 6.854666666666666e-07,
      "logits/chosen": -2.202335834503174,
      "logits/rejected": -3.6812520027160645,
      "logps/chosen": -152.2083740234375,
      "logps/rejected": -196.71885681152344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4629411697387695,
      "rewards/margins": 11.210506439208984,
      "rewards/rejected": -8.747565269470215,
      "step": 2360
    },
    {
      "epoch": 0.9444,
      "grad_norm": 0.02519574761390686,
      "learning_rate": 6.853333333333333e-07,
      "logits/chosen": -2.1995930671691895,
      "logits/rejected": -3.6310644149780273,
      "logps/chosen": -115.65585327148438,
      "logps/rejected": -210.57720947265625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0433878898620605,
      "rewards/margins": 8.489176750183105,
      "rewards/rejected": -6.445789337158203,
      "step": 2361
    },
    {
      "epoch": 0.9448,
      "grad_norm": 1.098015546798706,
      "learning_rate": 6.852e-07,
      "logits/chosen": -1.875558614730835,
      "logits/rejected": -2.23348331451416,
      "logps/chosen": -144.40480041503906,
      "logps/rejected": -128.5417022705078,
      "loss": 0.0131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0435622930526733,
      "rewards/margins": 4.358609199523926,
      "rewards/rejected": -3.315046787261963,
      "step": 2362
    },
    {
      "epoch": 0.9452,
      "grad_norm": 0.23357899487018585,
      "learning_rate": 6.850666666666667e-07,
      "logits/chosen": -2.267510175704956,
      "logits/rejected": -3.0514919757843018,
      "logps/chosen": -96.88504028320312,
      "logps/rejected": -163.59828186035156,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.854513168334961,
      "rewards/margins": 8.018004417419434,
      "rewards/rejected": -6.1634907722473145,
      "step": 2363
    },
    {
      "epoch": 0.9456,
      "grad_norm": 0.1735767275094986,
      "learning_rate": 6.849333333333333e-07,
      "logits/chosen": -2.3136796951293945,
      "logits/rejected": -3.1024599075317383,
      "logps/chosen": -131.0944061279297,
      "logps/rejected": -162.66038513183594,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7848800420761108,
      "rewards/margins": 6.445798873901367,
      "rewards/rejected": -5.660918712615967,
      "step": 2364
    },
    {
      "epoch": 0.946,
      "grad_norm": 1.0139353275299072,
      "learning_rate": 6.847999999999999e-07,
      "logits/chosen": -2.513301372528076,
      "logits/rejected": -2.715419292449951,
      "logps/chosen": -123.12724304199219,
      "logps/rejected": -153.61373901367188,
      "loss": 0.0057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.869200587272644,
      "rewards/margins": 6.33753776550293,
      "rewards/rejected": -5.468337059020996,
      "step": 2365
    },
    {
      "epoch": 0.9464,
      "grad_norm": 0.019837776198983192,
      "learning_rate": 6.846666666666666e-07,
      "logits/chosen": -2.5408785343170166,
      "logits/rejected": -3.201681613922119,
      "logps/chosen": -99.5565185546875,
      "logps/rejected": -156.32713317871094,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.161076068878174,
      "rewards/margins": 8.911578178405762,
      "rewards/rejected": -6.750502109527588,
      "step": 2366
    },
    {
      "epoch": 0.9468,
      "grad_norm": 0.02465761825442314,
      "learning_rate": 6.845333333333333e-07,
      "logits/chosen": -1.998279333114624,
      "logits/rejected": -2.922306537628174,
      "logps/chosen": -120.35610961914062,
      "logps/rejected": -154.03428649902344,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.021275758743286,
      "rewards/margins": 8.160140037536621,
      "rewards/rejected": -6.138864517211914,
      "step": 2367
    },
    {
      "epoch": 0.9472,
      "grad_norm": 0.06924372911453247,
      "learning_rate": 6.844e-07,
      "logits/chosen": -2.438579797744751,
      "logits/rejected": -2.6654653549194336,
      "logps/chosen": -196.30050659179688,
      "logps/rejected": -145.34927368164062,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8549256324768066,
      "rewards/margins": 8.211076736450195,
      "rewards/rejected": -5.3561506271362305,
      "step": 2368
    },
    {
      "epoch": 0.9476,
      "grad_norm": 0.11914224922657013,
      "learning_rate": 6.842666666666667e-07,
      "logits/chosen": -2.4805498123168945,
      "logits/rejected": -3.1034388542175293,
      "logps/chosen": -128.39932250976562,
      "logps/rejected": -144.75177001953125,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.85933780670166,
      "rewards/margins": 8.339343070983887,
      "rewards/rejected": -4.480005264282227,
      "step": 2369
    },
    {
      "epoch": 0.948,
      "grad_norm": 0.02021213434636593,
      "learning_rate": 6.841333333333333e-07,
      "logits/chosen": -2.260666608810425,
      "logits/rejected": -3.0243825912475586,
      "logps/chosen": -125.90555572509766,
      "logps/rejected": -160.89154052734375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7209529876708984,
      "rewards/margins": 8.891847610473633,
      "rewards/rejected": -6.170893669128418,
      "step": 2370
    },
    {
      "epoch": 0.9484,
      "grad_norm": 0.18553976714611053,
      "learning_rate": 6.84e-07,
      "logits/chosen": -2.880430221557617,
      "logits/rejected": -2.612074851989746,
      "logps/chosen": -245.78750610351562,
      "logps/rejected": -221.42063903808594,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0511226654052734,
      "rewards/margins": 7.863497734069824,
      "rewards/rejected": -5.812374591827393,
      "step": 2371
    },
    {
      "epoch": 0.9488,
      "grad_norm": 0.15355518460273743,
      "learning_rate": 6.838666666666666e-07,
      "logits/chosen": -2.1071937084198,
      "logits/rejected": -3.0641379356384277,
      "logps/chosen": -107.34307861328125,
      "logps/rejected": -156.017333984375,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40277212858200073,
      "rewards/margins": 6.871951103210449,
      "rewards/rejected": -6.469178676605225,
      "step": 2372
    },
    {
      "epoch": 0.9492,
      "grad_norm": 0.10509104281663895,
      "learning_rate": 6.837333333333333e-07,
      "logits/chosen": -2.8577322959899902,
      "logits/rejected": -3.5438637733459473,
      "logps/chosen": -145.63291931152344,
      "logps/rejected": -155.3596649169922,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8230533599853516,
      "rewards/margins": 8.18593978881836,
      "rewards/rejected": -6.362886905670166,
      "step": 2373
    },
    {
      "epoch": 0.9496,
      "grad_norm": 0.19872362911701202,
      "learning_rate": 6.836e-07,
      "logits/chosen": -2.1171274185180664,
      "logits/rejected": -3.3746156692504883,
      "logps/chosen": -125.44230651855469,
      "logps/rejected": -157.0665740966797,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6251914501190186,
      "rewards/margins": 7.886957168579102,
      "rewards/rejected": -6.261765480041504,
      "step": 2374
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.09563640505075455,
      "learning_rate": 6.834666666666666e-07,
      "logits/chosen": -2.072849988937378,
      "logits/rejected": -3.2585129737854004,
      "logps/chosen": -179.71127319335938,
      "logps/rejected": -169.39523315429688,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4764785766601562,
      "rewards/margins": 8.217270851135254,
      "rewards/rejected": -6.740792274475098,
      "step": 2375
    },
    {
      "epoch": 0.9504,
      "grad_norm": 0.0015409720363095403,
      "learning_rate": 6.833333333333333e-07,
      "logits/chosen": -2.3592498302459717,
      "logits/rejected": -3.518491268157959,
      "logps/chosen": -138.4422607421875,
      "logps/rejected": -186.11257934570312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7665581703186035,
      "rewards/margins": 11.217266082763672,
      "rewards/rejected": -7.450708389282227,
      "step": 2376
    },
    {
      "epoch": 0.9508,
      "grad_norm": 0.04930652305483818,
      "learning_rate": 6.832e-07,
      "logits/chosen": -2.0991411209106445,
      "logits/rejected": -3.533987522125244,
      "logps/chosen": -211.07907104492188,
      "logps/rejected": -177.25833129882812,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.219137191772461,
      "rewards/margins": 8.658562660217285,
      "rewards/rejected": -6.439425468444824,
      "step": 2377
    },
    {
      "epoch": 0.9512,
      "grad_norm": 0.5654629468917847,
      "learning_rate": 6.830666666666667e-07,
      "logits/chosen": -2.746030807495117,
      "logits/rejected": -2.6092898845672607,
      "logps/chosen": -193.22279357910156,
      "logps/rejected": -130.5411376953125,
      "loss": 0.0049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3356895446777344,
      "rewards/margins": 5.50202751159668,
      "rewards/rejected": -5.166337966918945,
      "step": 2378
    },
    {
      "epoch": 0.9516,
      "grad_norm": 0.008607601746916771,
      "learning_rate": 6.829333333333333e-07,
      "logits/chosen": -1.9973487854003906,
      "logits/rejected": -3.245723247528076,
      "logps/chosen": -73.71379089355469,
      "logps/rejected": -150.33963012695312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2959647178649902,
      "rewards/margins": 9.625495910644531,
      "rewards/rejected": -6.329531669616699,
      "step": 2379
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.05220884084701538,
      "learning_rate": 6.827999999999999e-07,
      "logits/chosen": -2.4037020206451416,
      "logits/rejected": -3.7475709915161133,
      "logps/chosen": -246.03639221191406,
      "logps/rejected": -179.23580932617188,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8869843482971191,
      "rewards/margins": 8.80750846862793,
      "rewards/rejected": -6.920523643493652,
      "step": 2380
    },
    {
      "epoch": 0.9524,
      "grad_norm": 9.048072814941406,
      "learning_rate": 6.826666666666666e-07,
      "logits/chosen": -2.416616439819336,
      "logits/rejected": -2.7551045417785645,
      "logps/chosen": -139.16860961914062,
      "logps/rejected": -120.35067749023438,
      "loss": 0.0674,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5280147790908813,
      "rewards/margins": 4.029959678649902,
      "rewards/rejected": -4.557974338531494,
      "step": 2381
    },
    {
      "epoch": 0.9528,
      "grad_norm": 0.03207378834486008,
      "learning_rate": 6.825333333333333e-07,
      "logits/chosen": -2.1108603477478027,
      "logits/rejected": -3.867550849914551,
      "logps/chosen": -59.48456954956055,
      "logps/rejected": -136.9472198486328,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.628925323486328,
      "rewards/margins": 8.878801345825195,
      "rewards/rejected": -5.249876499176025,
      "step": 2382
    },
    {
      "epoch": 0.9532,
      "grad_norm": 0.002412574365735054,
      "learning_rate": 6.824e-07,
      "logits/chosen": -2.2882559299468994,
      "logits/rejected": -3.6584224700927734,
      "logps/chosen": -93.93669128417969,
      "logps/rejected": -177.34542846679688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.140403747558594,
      "rewards/margins": 10.800971984863281,
      "rewards/rejected": -6.6605682373046875,
      "step": 2383
    },
    {
      "epoch": 0.9536,
      "grad_norm": 0.5248910188674927,
      "learning_rate": 6.822666666666666e-07,
      "logits/chosen": -2.4740147590637207,
      "logits/rejected": -2.6955208778381348,
      "logps/chosen": -95.36566925048828,
      "logps/rejected": -114.77182006835938,
      "loss": 0.0087,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5568401217460632,
      "rewards/margins": 4.755710601806641,
      "rewards/rejected": -4.198870658874512,
      "step": 2384
    },
    {
      "epoch": 0.954,
      "grad_norm": 0.16829052567481995,
      "learning_rate": 6.821333333333333e-07,
      "logits/chosen": -2.367523670196533,
      "logits/rejected": -3.1093859672546387,
      "logps/chosen": -236.87734985351562,
      "logps/rejected": -230.90740966796875,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7523231506347656,
      "rewards/margins": 7.417737007141113,
      "rewards/rejected": -5.665413856506348,
      "step": 2385
    },
    {
      "epoch": 0.9544,
      "grad_norm": 0.04821609705686569,
      "learning_rate": 6.82e-07,
      "logits/chosen": -2.448925256729126,
      "logits/rejected": -2.7143850326538086,
      "logps/chosen": -132.51422119140625,
      "logps/rejected": -178.41348266601562,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0814177989959717,
      "rewards/margins": 8.454549789428711,
      "rewards/rejected": -5.37313175201416,
      "step": 2386
    },
    {
      "epoch": 0.9548,
      "grad_norm": 0.004181843716651201,
      "learning_rate": 6.818666666666666e-07,
      "logits/chosen": -2.037330389022827,
      "logits/rejected": -3.373396873474121,
      "logps/chosen": -123.69422912597656,
      "logps/rejected": -221.9896240234375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.161953449249268,
      "rewards/margins": 10.742738723754883,
      "rewards/rejected": -6.580784797668457,
      "step": 2387
    },
    {
      "epoch": 0.9552,
      "grad_norm": 0.1374317705631256,
      "learning_rate": 6.817333333333333e-07,
      "logits/chosen": -2.2086031436920166,
      "logits/rejected": -3.1917061805725098,
      "logps/chosen": -145.75926208496094,
      "logps/rejected": -153.2559814453125,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.428678274154663,
      "rewards/margins": 9.98824691772461,
      "rewards/rejected": -6.559568405151367,
      "step": 2388
    },
    {
      "epoch": 0.9556,
      "grad_norm": 0.06727414578199387,
      "learning_rate": 6.816e-07,
      "logits/chosen": -2.199796199798584,
      "logits/rejected": -3.161555528640747,
      "logps/chosen": -236.59109497070312,
      "logps/rejected": -207.1151885986328,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34424513578414917,
      "rewards/margins": 8.186874389648438,
      "rewards/rejected": -7.8426289558410645,
      "step": 2389
    },
    {
      "epoch": 0.956,
      "grad_norm": 0.06910187751054764,
      "learning_rate": 6.814666666666667e-07,
      "logits/chosen": -2.534770965576172,
      "logits/rejected": -2.9603753089904785,
      "logps/chosen": -156.124755859375,
      "logps/rejected": -214.86798095703125,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.260355830192566,
      "rewards/margins": 7.513261795043945,
      "rewards/rejected": -6.25290584564209,
      "step": 2390
    },
    {
      "epoch": 0.9564,
      "grad_norm": 0.15776102244853973,
      "learning_rate": 6.813333333333333e-07,
      "logits/chosen": -1.944101095199585,
      "logits/rejected": -3.5758209228515625,
      "logps/chosen": -94.8717269897461,
      "logps/rejected": -188.60227966308594,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.657349705696106,
      "rewards/margins": 8.672926902770996,
      "rewards/rejected": -7.01557731628418,
      "step": 2391
    },
    {
      "epoch": 0.9568,
      "grad_norm": 0.24350453913211823,
      "learning_rate": 6.812e-07,
      "logits/chosen": -3.1601157188415527,
      "logits/rejected": -4.0454912185668945,
      "logps/chosen": -136.99061584472656,
      "logps/rejected": -152.0390625,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0977805852890015,
      "rewards/margins": 6.359950542449951,
      "rewards/rejected": -5.26216983795166,
      "step": 2392
    },
    {
      "epoch": 0.9572,
      "grad_norm": 0.13101013004779816,
      "learning_rate": 6.810666666666667e-07,
      "logits/chosen": -2.0070972442626953,
      "logits/rejected": -3.258540391921997,
      "logps/chosen": -172.28497314453125,
      "logps/rejected": -153.56942749023438,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0287857055664062,
      "rewards/margins": 7.6190690994262695,
      "rewards/rejected": -5.590283393859863,
      "step": 2393
    },
    {
      "epoch": 0.9576,
      "grad_norm": 0.3933188021183014,
      "learning_rate": 6.809333333333332e-07,
      "logits/chosen": -2.3300325870513916,
      "logits/rejected": -3.652757406234741,
      "logps/chosen": -133.7714385986328,
      "logps/rejected": -160.1371307373047,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0826294422149658,
      "rewards/margins": 7.520334243774414,
      "rewards/rejected": -6.437704563140869,
      "step": 2394
    },
    {
      "epoch": 0.958,
      "grad_norm": 0.053270597010850906,
      "learning_rate": 6.807999999999999e-07,
      "logits/chosen": -1.9626930952072144,
      "logits/rejected": -3.283143997192383,
      "logps/chosen": -131.6033172607422,
      "logps/rejected": -157.14804077148438,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4857888221740723,
      "rewards/margins": 8.084158897399902,
      "rewards/rejected": -4.598370552062988,
      "step": 2395
    },
    {
      "epoch": 0.9584,
      "grad_norm": 0.20396363735198975,
      "learning_rate": 6.806666666666666e-07,
      "logits/chosen": -2.0052266120910645,
      "logits/rejected": -3.2556896209716797,
      "logps/chosen": -80.2047119140625,
      "logps/rejected": -155.59219360351562,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8816421627998352,
      "rewards/margins": 6.4042158126831055,
      "rewards/rejected": -5.522573471069336,
      "step": 2396
    },
    {
      "epoch": 0.9588,
      "grad_norm": 4.668291091918945,
      "learning_rate": 6.805333333333333e-07,
      "logits/chosen": -2.699746608734131,
      "logits/rejected": -3.0657665729522705,
      "logps/chosen": -305.47308349609375,
      "logps/rejected": -179.11688232421875,
      "loss": 0.0268,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.669189453125,
      "rewards/margins": 8.684983253479004,
      "rewards/rejected": -5.015793800354004,
      "step": 2397
    },
    {
      "epoch": 0.9592,
      "grad_norm": 0.6198081970214844,
      "learning_rate": 6.804e-07,
      "logits/chosen": -1.8589850664138794,
      "logits/rejected": -3.4680871963500977,
      "logps/chosen": -117.3913345336914,
      "logps/rejected": -146.72799682617188,
      "loss": 0.0048,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6178321838378906,
      "rewards/margins": 7.374202728271484,
      "rewards/rejected": -5.756370544433594,
      "step": 2398
    },
    {
      "epoch": 0.9596,
      "grad_norm": 3.4394707679748535,
      "learning_rate": 6.802666666666667e-07,
      "logits/chosen": -2.2565255165100098,
      "logits/rejected": -3.2971701622009277,
      "logps/chosen": -191.9730224609375,
      "logps/rejected": -150.94473266601562,
      "loss": 0.0298,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6418877840042114,
      "rewards/margins": 3.696476459503174,
      "rewards/rejected": -5.338364124298096,
      "step": 2399
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.018567072227597237,
      "learning_rate": 6.801333333333334e-07,
      "logits/chosen": -1.85965895652771,
      "logits/rejected": -2.8418922424316406,
      "logps/chosen": -130.97157287597656,
      "logps/rejected": -170.9580841064453,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4422354698181152,
      "rewards/margins": 9.214805603027344,
      "rewards/rejected": -5.772570610046387,
      "step": 2400
    },
    {
      "epoch": 0.9604,
      "grad_norm": 0.1236962303519249,
      "learning_rate": 6.800000000000001e-07,
      "logits/chosen": -2.079214572906494,
      "logits/rejected": -2.204190254211426,
      "logps/chosen": -140.9990234375,
      "logps/rejected": -142.40081787109375,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.097212314605713,
      "rewards/margins": 6.989615440368652,
      "rewards/rejected": -4.8924031257629395,
      "step": 2401
    },
    {
      "epoch": 0.9608,
      "grad_norm": 0.519507884979248,
      "learning_rate": 6.798666666666666e-07,
      "logits/chosen": -2.58539080619812,
      "logits/rejected": -3.3046469688415527,
      "logps/chosen": -187.00868225097656,
      "logps/rejected": -162.73121643066406,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.231949806213379,
      "rewards/margins": 7.544915199279785,
      "rewards/rejected": -6.312965393066406,
      "step": 2402
    },
    {
      "epoch": 0.9612,
      "grad_norm": 0.3179403841495514,
      "learning_rate": 6.797333333333332e-07,
      "logits/chosen": -2.4973082542419434,
      "logits/rejected": -2.706052303314209,
      "logps/chosen": -150.4781951904297,
      "logps/rejected": -143.327880859375,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6289844512939453,
      "rewards/margins": 7.343062877655029,
      "rewards/rejected": -4.714077949523926,
      "step": 2403
    },
    {
      "epoch": 0.9616,
      "grad_norm": 0.6768586039543152,
      "learning_rate": 6.795999999999999e-07,
      "logits/chosen": -2.489100456237793,
      "logits/rejected": -2.6440601348876953,
      "logps/chosen": -124.30152130126953,
      "logps/rejected": -118.38328552246094,
      "loss": 0.0088,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7459724545478821,
      "rewards/margins": 4.962285041809082,
      "rewards/rejected": -4.216312885284424,
      "step": 2404
    },
    {
      "epoch": 0.962,
      "grad_norm": 0.021447833627462387,
      "learning_rate": 6.794666666666666e-07,
      "logits/chosen": -2.25022554397583,
      "logits/rejected": -3.4182140827178955,
      "logps/chosen": -90.1826171875,
      "logps/rejected": -154.05381774902344,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.067562103271484,
      "rewards/margins": 8.528053283691406,
      "rewards/rejected": -4.460490703582764,
      "step": 2405
    },
    {
      "epoch": 0.9624,
      "grad_norm": 0.04817047342658043,
      "learning_rate": 6.793333333333333e-07,
      "logits/chosen": -1.8647089004516602,
      "logits/rejected": -3.298128128051758,
      "logps/chosen": -141.1111602783203,
      "logps/rejected": -143.33062744140625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2628822326660156,
      "rewards/margins": 7.756003379821777,
      "rewards/rejected": -5.493121147155762,
      "step": 2406
    },
    {
      "epoch": 0.9628,
      "grad_norm": 0.25231462717056274,
      "learning_rate": 6.792e-07,
      "logits/chosen": -2.11626935005188,
      "logits/rejected": -3.391801357269287,
      "logps/chosen": -189.72686767578125,
      "logps/rejected": -213.43228149414062,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7712703943252563,
      "rewards/margins": 6.508354663848877,
      "rewards/rejected": -5.73708438873291,
      "step": 2407
    },
    {
      "epoch": 0.9632,
      "grad_norm": 0.013452468439936638,
      "learning_rate": 6.790666666666667e-07,
      "logits/chosen": -2.0110583305358887,
      "logits/rejected": -3.4184985160827637,
      "logps/chosen": -88.52326965332031,
      "logps/rejected": -151.27960205078125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0937938690185547,
      "rewards/margins": 9.196435928344727,
      "rewards/rejected": -6.10264253616333,
      "step": 2408
    },
    {
      "epoch": 0.9636,
      "grad_norm": 0.2639830410480499,
      "learning_rate": 6.789333333333334e-07,
      "logits/chosen": -1.9127440452575684,
      "logits/rejected": -2.917278289794922,
      "logps/chosen": -76.87259674072266,
      "logps/rejected": -164.61819458007812,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.319171905517578,
      "rewards/margins": 7.703283786773682,
      "rewards/rejected": -4.384111404418945,
      "step": 2409
    },
    {
      "epoch": 0.964,
      "grad_norm": 0.06943060457706451,
      "learning_rate": 6.788e-07,
      "logits/chosen": -2.2469799518585205,
      "logits/rejected": -2.8347275257110596,
      "logps/chosen": -164.70245361328125,
      "logps/rejected": -178.1013946533203,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6455674171447754,
      "rewards/margins": 8.952217102050781,
      "rewards/rejected": -6.306650161743164,
      "step": 2410
    },
    {
      "epoch": 0.9644,
      "grad_norm": 0.0034890947863459587,
      "learning_rate": 6.786666666666667e-07,
      "logits/chosen": -2.0865907669067383,
      "logits/rejected": -3.2635140419006348,
      "logps/chosen": -92.63154602050781,
      "logps/rejected": -176.8563995361328,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.621610641479492,
      "rewards/margins": 10.695320129394531,
      "rewards/rejected": -7.073709011077881,
      "step": 2411
    },
    {
      "epoch": 0.9648,
      "grad_norm": 0.45742520689964294,
      "learning_rate": 6.785333333333332e-07,
      "logits/chosen": -2.062798500061035,
      "logits/rejected": -2.343869209289551,
      "logps/chosen": -120.38569641113281,
      "logps/rejected": -133.7017822265625,
      "loss": 0.0056,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7814658880233765,
      "rewards/margins": 5.19826602935791,
      "rewards/rejected": -4.416800022125244,
      "step": 2412
    },
    {
      "epoch": 0.9652,
      "grad_norm": 0.11543433368206024,
      "learning_rate": 6.783999999999999e-07,
      "logits/chosen": -1.966432809829712,
      "logits/rejected": -3.219944953918457,
      "logps/chosen": -113.26493835449219,
      "logps/rejected": -158.6651611328125,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4239907264709473,
      "rewards/margins": 7.612496852874756,
      "rewards/rejected": -6.188506126403809,
      "step": 2413
    },
    {
      "epoch": 0.9656,
      "grad_norm": 0.18241707980632782,
      "learning_rate": 6.782666666666666e-07,
      "logits/chosen": -1.8379865884780884,
      "logits/rejected": -3.1945197582244873,
      "logps/chosen": -91.73988342285156,
      "logps/rejected": -147.00791931152344,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4036662578582764,
      "rewards/margins": 7.899055480957031,
      "rewards/rejected": -5.495388984680176,
      "step": 2414
    },
    {
      "epoch": 0.966,
      "grad_norm": 0.08798646181821823,
      "learning_rate": 6.781333333333333e-07,
      "logits/chosen": -2.1209425926208496,
      "logits/rejected": -3.2408385276794434,
      "logps/chosen": -159.22018432617188,
      "logps/rejected": -181.93258666992188,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9253876209259033,
      "rewards/margins": 7.465092658996582,
      "rewards/rejected": -5.539705276489258,
      "step": 2415
    },
    {
      "epoch": 0.9664,
      "grad_norm": 0.274242639541626,
      "learning_rate": 6.78e-07,
      "logits/chosen": -2.543870449066162,
      "logits/rejected": -3.231661796569824,
      "logps/chosen": -137.25259399414062,
      "logps/rejected": -147.4133758544922,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4128425121307373,
      "rewards/margins": 5.894830703735352,
      "rewards/rejected": -4.481987953186035,
      "step": 2416
    },
    {
      "epoch": 0.9668,
      "grad_norm": 0.2326928675174713,
      "learning_rate": 6.778666666666666e-07,
      "logits/chosen": -2.0834388732910156,
      "logits/rejected": -3.2038965225219727,
      "logps/chosen": -135.434814453125,
      "logps/rejected": -176.66773986816406,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.556025981903076,
      "rewards/margins": 7.771712303161621,
      "rewards/rejected": -5.215686321258545,
      "step": 2417
    },
    {
      "epoch": 0.9672,
      "grad_norm": 0.19469965994358063,
      "learning_rate": 6.777333333333333e-07,
      "logits/chosen": -2.456083297729492,
      "logits/rejected": -3.1106929779052734,
      "logps/chosen": -145.12835693359375,
      "logps/rejected": -224.70294189453125,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0865436792373657,
      "rewards/margins": 6.423187255859375,
      "rewards/rejected": -5.336644172668457,
      "step": 2418
    },
    {
      "epoch": 0.9676,
      "grad_norm": 0.013168583624064922,
      "learning_rate": 6.776e-07,
      "logits/chosen": -2.2226388454437256,
      "logits/rejected": -3.451603889465332,
      "logps/chosen": -227.88641357421875,
      "logps/rejected": -177.5902099609375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3331375122070312,
      "rewards/margins": 8.835451126098633,
      "rewards/rejected": -6.50231409072876,
      "step": 2419
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.09114859998226166,
      "learning_rate": 6.774666666666667e-07,
      "logits/chosen": -2.41616153717041,
      "logits/rejected": -2.3726205825805664,
      "logps/chosen": -127.13070678710938,
      "logps/rejected": -275.1292724609375,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4859390258789062,
      "rewards/margins": 8.09167766571045,
      "rewards/rejected": -6.605738639831543,
      "step": 2420
    },
    {
      "epoch": 0.9684,
      "grad_norm": 0.24863220751285553,
      "learning_rate": 6.773333333333334e-07,
      "logits/chosen": -1.9609966278076172,
      "logits/rejected": -2.771026611328125,
      "logps/chosen": -77.88778686523438,
      "logps/rejected": -137.006591796875,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2493646144866943,
      "rewards/margins": 6.890672206878662,
      "rewards/rejected": -4.641307353973389,
      "step": 2421
    },
    {
      "epoch": 0.9688,
      "grad_norm": 6.022500038146973,
      "learning_rate": 6.772e-07,
      "logits/chosen": -2.767442226409912,
      "logits/rejected": -3.1213202476501465,
      "logps/chosen": -172.93341064453125,
      "logps/rejected": -218.7270050048828,
      "loss": 0.0365,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.823469638824463,
      "rewards/margins": 6.972712516784668,
      "rewards/rejected": -5.149243354797363,
      "step": 2422
    },
    {
      "epoch": 0.9692,
      "grad_norm": 0.08951817452907562,
      "learning_rate": 6.770666666666666e-07,
      "logits/chosen": -1.9170472621917725,
      "logits/rejected": -3.054141044616699,
      "logps/chosen": -73.3996353149414,
      "logps/rejected": -129.89404296875,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4557228088378906,
      "rewards/margins": 7.199824810028076,
      "rewards/rejected": -4.744102478027344,
      "step": 2423
    },
    {
      "epoch": 0.9696,
      "grad_norm": 0.015252277255058289,
      "learning_rate": 6.769333333333333e-07,
      "logits/chosen": -1.9473979473114014,
      "logits/rejected": -3.581678867340088,
      "logps/chosen": -123.02604675292969,
      "logps/rejected": -195.1375274658203,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3590130805969238,
      "rewards/margins": 8.748568534851074,
      "rewards/rejected": -7.389555931091309,
      "step": 2424
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.2251000851392746,
      "learning_rate": 6.767999999999999e-07,
      "logits/chosen": -2.512667179107666,
      "logits/rejected": -3.4901561737060547,
      "logps/chosen": -114.8808364868164,
      "logps/rejected": -156.7425994873047,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3743915557861328,
      "rewards/margins": 7.720644950866699,
      "rewards/rejected": -6.346253395080566,
      "step": 2425
    },
    {
      "epoch": 0.9704,
      "grad_norm": 0.03419334813952446,
      "learning_rate": 6.766666666666666e-07,
      "logits/chosen": -2.193610668182373,
      "logits/rejected": -2.4762368202209473,
      "logps/chosen": -80.76349639892578,
      "logps/rejected": -135.96194458007812,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.201575517654419,
      "rewards/margins": 7.936321258544922,
      "rewards/rejected": -4.734745502471924,
      "step": 2426
    },
    {
      "epoch": 0.9708,
      "grad_norm": 0.02769390679895878,
      "learning_rate": 6.765333333333333e-07,
      "logits/chosen": -1.0781100988388062,
      "logits/rejected": -3.022246837615967,
      "logps/chosen": -67.59384155273438,
      "logps/rejected": -146.55343627929688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1012678146362305,
      "rewards/margins": 9.484664916992188,
      "rewards/rejected": -6.383396625518799,
      "step": 2427
    },
    {
      "epoch": 0.9712,
      "grad_norm": 1.9844050407409668,
      "learning_rate": 6.764e-07,
      "logits/chosen": -2.023028612136841,
      "logits/rejected": -3.1443405151367188,
      "logps/chosen": -92.39889526367188,
      "logps/rejected": -146.80630493164062,
      "loss": 0.0138,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.699832558631897,
      "rewards/margins": 7.292695045471191,
      "rewards/rejected": -5.592862129211426,
      "step": 2428
    },
    {
      "epoch": 0.9716,
      "grad_norm": 0.31076306104660034,
      "learning_rate": 6.762666666666667e-07,
      "logits/chosen": -2.139536142349243,
      "logits/rejected": -3.9035863876342773,
      "logps/chosen": -128.303466796875,
      "logps/rejected": -230.216064453125,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6033870577812195,
      "rewards/margins": 6.133597373962402,
      "rewards/rejected": -5.530210494995117,
      "step": 2429
    },
    {
      "epoch": 0.972,
      "grad_norm": 0.012371832504868507,
      "learning_rate": 6.761333333333334e-07,
      "logits/chosen": -2.52239990234375,
      "logits/rejected": -3.4506468772888184,
      "logps/chosen": -132.41104125976562,
      "logps/rejected": -230.05435180664062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2497544288635254,
      "rewards/margins": 10.746492385864258,
      "rewards/rejected": -7.496737480163574,
      "step": 2430
    },
    {
      "epoch": 0.9724,
      "grad_norm": 0.1212456226348877,
      "learning_rate": 6.76e-07,
      "logits/chosen": -2.5124924182891846,
      "logits/rejected": -3.0923924446105957,
      "logps/chosen": -129.60467529296875,
      "logps/rejected": -166.6056365966797,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0329155921936035,
      "rewards/margins": 8.543381690979004,
      "rewards/rejected": -6.5104660987854,
      "step": 2431
    },
    {
      "epoch": 0.9728,
      "grad_norm": 0.06410349160432816,
      "learning_rate": 6.758666666666666e-07,
      "logits/chosen": -2.62668514251709,
      "logits/rejected": -3.460207939147949,
      "logps/chosen": -115.0102767944336,
      "logps/rejected": -179.80682373046875,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41908493638038635,
      "rewards/margins": 7.4276533126831055,
      "rewards/rejected": -7.00856876373291,
      "step": 2432
    },
    {
      "epoch": 0.9732,
      "grad_norm": 0.18892261385917664,
      "learning_rate": 6.757333333333332e-07,
      "logits/chosen": -2.0351247787475586,
      "logits/rejected": -2.188474178314209,
      "logps/chosen": -151.34066772460938,
      "logps/rejected": -145.15577697753906,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.14254093170166,
      "rewards/margins": 8.695011138916016,
      "rewards/rejected": -4.5524702072143555,
      "step": 2433
    },
    {
      "epoch": 0.9736,
      "grad_norm": 0.043170057237148285,
      "learning_rate": 6.755999999999999e-07,
      "logits/chosen": -2.142224073410034,
      "logits/rejected": -3.375843048095703,
      "logps/chosen": -138.69261169433594,
      "logps/rejected": -169.63858032226562,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.648470640182495,
      "rewards/margins": 8.794515609741211,
      "rewards/rejected": -6.146044731140137,
      "step": 2434
    },
    {
      "epoch": 0.974,
      "grad_norm": 0.5831682682037354,
      "learning_rate": 6.754666666666666e-07,
      "logits/chosen": -2.096130132675171,
      "logits/rejected": -3.1655044555664062,
      "logps/chosen": -98.06452941894531,
      "logps/rejected": -165.64404296875,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3198944330215454,
      "rewards/margins": 6.439128875732422,
      "rewards/rejected": -5.119234561920166,
      "step": 2435
    },
    {
      "epoch": 0.9744,
      "grad_norm": 0.05729619413614273,
      "learning_rate": 6.753333333333333e-07,
      "logits/chosen": -2.282454013824463,
      "logits/rejected": -3.4028258323669434,
      "logps/chosen": -116.29043579101562,
      "logps/rejected": -183.70355224609375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5974221229553223,
      "rewards/margins": 10.192185401916504,
      "rewards/rejected": -6.594763278961182,
      "step": 2436
    },
    {
      "epoch": 0.9748,
      "grad_norm": 0.009055168367922306,
      "learning_rate": 6.752e-07,
      "logits/chosen": -1.8737980127334595,
      "logits/rejected": -3.1832780838012695,
      "logps/chosen": -126.48796844482422,
      "logps/rejected": -161.63031005859375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5963950157165527,
      "rewards/margins": 9.295040130615234,
      "rewards/rejected": -5.698644638061523,
      "step": 2437
    },
    {
      "epoch": 0.9752,
      "grad_norm": 0.07609070837497711,
      "learning_rate": 6.750666666666667e-07,
      "logits/chosen": -2.4321980476379395,
      "logits/rejected": -2.263784646987915,
      "logps/chosen": -121.73837280273438,
      "logps/rejected": -97.79275512695312,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2467668056488037,
      "rewards/margins": 7.287494659423828,
      "rewards/rejected": -4.040727615356445,
      "step": 2438
    },
    {
      "epoch": 0.9756,
      "grad_norm": 0.013086033053696156,
      "learning_rate": 6.749333333333334e-07,
      "logits/chosen": -2.0482611656188965,
      "logits/rejected": -3.086691379547119,
      "logps/chosen": -72.83871459960938,
      "logps/rejected": -145.607177734375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1082844734191895,
      "rewards/margins": 9.072748184204102,
      "rewards/rejected": -5.96446418762207,
      "step": 2439
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.03284719958901405,
      "learning_rate": 6.747999999999999e-07,
      "logits/chosen": -2.3504838943481445,
      "logits/rejected": -3.0114951133728027,
      "logps/chosen": -255.9422149658203,
      "logps/rejected": -171.9778594970703,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.708706855773926,
      "rewards/margins": 9.530577659606934,
      "rewards/rejected": -5.821871280670166,
      "step": 2440
    },
    {
      "epoch": 0.9764,
      "grad_norm": 0.12323586642742157,
      "learning_rate": 6.746666666666666e-07,
      "logits/chosen": -2.3168118000030518,
      "logits/rejected": -3.5452611446380615,
      "logps/chosen": -103.78736877441406,
      "logps/rejected": -182.47747802734375,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6314972639083862,
      "rewards/margins": 8.982792854309082,
      "rewards/rejected": -7.351295471191406,
      "step": 2441
    },
    {
      "epoch": 0.9768,
      "grad_norm": 0.6893246173858643,
      "learning_rate": 6.745333333333333e-07,
      "logits/chosen": -2.2159459590911865,
      "logits/rejected": -3.1890742778778076,
      "logps/chosen": -118.4804458618164,
      "logps/rejected": -158.45037841796875,
      "loss": 0.0069,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.263789415359497,
      "rewards/margins": 7.977354049682617,
      "rewards/rejected": -5.713564395904541,
      "step": 2442
    },
    {
      "epoch": 0.9772,
      "grad_norm": 0.006151850800961256,
      "learning_rate": 6.744e-07,
      "logits/chosen": -2.1447484493255615,
      "logits/rejected": -3.398897409439087,
      "logps/chosen": -114.53450012207031,
      "logps/rejected": -189.947021484375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.71630597114563,
      "rewards/margins": 11.248541831970215,
      "rewards/rejected": -7.532235622406006,
      "step": 2443
    },
    {
      "epoch": 0.9776,
      "grad_norm": 0.029385564848780632,
      "learning_rate": 6.742666666666666e-07,
      "logits/chosen": -1.8183534145355225,
      "logits/rejected": -2.954193115234375,
      "logps/chosen": -95.25540161132812,
      "logps/rejected": -134.40994262695312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0731639862060547,
      "rewards/margins": 9.06734848022461,
      "rewards/rejected": -5.994183540344238,
      "step": 2444
    },
    {
      "epoch": 0.978,
      "grad_norm": 3.5697808265686035,
      "learning_rate": 6.741333333333333e-07,
      "logits/chosen": -2.2573652267456055,
      "logits/rejected": -1.701620101928711,
      "logps/chosen": -75.78791046142578,
      "logps/rejected": -92.14817810058594,
      "loss": 0.0252,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7571738958358765,
      "rewards/margins": 3.781644105911255,
      "rewards/rejected": -3.024470329284668,
      "step": 2445
    },
    {
      "epoch": 0.9784,
      "grad_norm": 0.03050611913204193,
      "learning_rate": 6.74e-07,
      "logits/chosen": -2.2808332443237305,
      "logits/rejected": -3.2666168212890625,
      "logps/chosen": -103.1859359741211,
      "logps/rejected": -194.6287384033203,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4292995929718018,
      "rewards/margins": 10.073003768920898,
      "rewards/rejected": -7.643703460693359,
      "step": 2446
    },
    {
      "epoch": 0.9788,
      "grad_norm": 1.6971720457077026,
      "learning_rate": 6.738666666666666e-07,
      "logits/chosen": -2.1365866661071777,
      "logits/rejected": -3.2469887733459473,
      "logps/chosen": -204.05609130859375,
      "logps/rejected": -152.1359405517578,
      "loss": 0.0123,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8726978302001953,
      "rewards/margins": 4.611795902252197,
      "rewards/rejected": -5.484493732452393,
      "step": 2447
    },
    {
      "epoch": 0.9792,
      "grad_norm": 0.002539793262258172,
      "learning_rate": 6.737333333333333e-07,
      "logits/chosen": -1.6841034889221191,
      "logits/rejected": -2.9511916637420654,
      "logps/chosen": -112.71601867675781,
      "logps/rejected": -193.04437255859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.858489990234375,
      "rewards/margins": 10.509930610656738,
      "rewards/rejected": -6.651440620422363,
      "step": 2448
    },
    {
      "epoch": 0.9796,
      "grad_norm": 0.2701537311077118,
      "learning_rate": 6.736e-07,
      "logits/chosen": -2.714938163757324,
      "logits/rejected": -3.799914598464966,
      "logps/chosen": -187.93775939941406,
      "logps/rejected": -148.96591186523438,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.126990556716919,
      "rewards/margins": 6.616497993469238,
      "rewards/rejected": -4.48950719833374,
      "step": 2449
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.10035336017608643,
      "learning_rate": 6.734666666666666e-07,
      "logits/chosen": -2.4262075424194336,
      "logits/rejected": -3.585933208465576,
      "logps/chosen": -89.4835433959961,
      "logps/rejected": -176.91697692871094,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8138431310653687,
      "rewards/margins": 7.84294319152832,
      "rewards/rejected": -7.029099941253662,
      "step": 2450
    },
    {
      "epoch": 0.9804,
      "grad_norm": 0.07237432152032852,
      "learning_rate": 6.733333333333333e-07,
      "logits/chosen": -2.2077956199645996,
      "logits/rejected": -2.482342004776001,
      "logps/chosen": -87.63755798339844,
      "logps/rejected": -161.1732940673828,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.400038957595825,
      "rewards/margins": 7.369512557983398,
      "rewards/rejected": -4.969473361968994,
      "step": 2451
    },
    {
      "epoch": 0.9808,
      "grad_norm": 0.02800922468304634,
      "learning_rate": 6.732e-07,
      "logits/chosen": -2.4422693252563477,
      "logits/rejected": -3.375227928161621,
      "logps/chosen": -104.15269470214844,
      "logps/rejected": -162.38095092773438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.098569393157959,
      "rewards/margins": 9.166324615478516,
      "rewards/rejected": -6.067754745483398,
      "step": 2452
    },
    {
      "epoch": 0.9812,
      "grad_norm": 0.024901872500777245,
      "learning_rate": 6.730666666666667e-07,
      "logits/chosen": -2.297358989715576,
      "logits/rejected": -2.9814391136169434,
      "logps/chosen": -131.3067626953125,
      "logps/rejected": -169.55845642089844,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4945478439331055,
      "rewards/margins": 9.322697639465332,
      "rewards/rejected": -5.828149795532227,
      "step": 2453
    },
    {
      "epoch": 0.9816,
      "grad_norm": 0.03239677846431732,
      "learning_rate": 6.729333333333334e-07,
      "logits/chosen": -2.599982738494873,
      "logits/rejected": -3.1375460624694824,
      "logps/chosen": -148.2010955810547,
      "logps/rejected": -161.04922485351562,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8368301391601562,
      "rewards/margins": 8.030135154724121,
      "rewards/rejected": -6.193305015563965,
      "step": 2454
    },
    {
      "epoch": 0.982,
      "grad_norm": 0.5808476209640503,
      "learning_rate": 6.727999999999999e-07,
      "logits/chosen": -2.0775139331817627,
      "logits/rejected": -2.9377408027648926,
      "logps/chosen": -99.67997741699219,
      "logps/rejected": -118.80075073242188,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10413970798254013,
      "rewards/margins": 5.322667121887207,
      "rewards/rejected": -5.426806926727295,
      "step": 2455
    },
    {
      "epoch": 0.9824,
      "grad_norm": 0.028073599562048912,
      "learning_rate": 6.726666666666666e-07,
      "logits/chosen": -1.9779900312423706,
      "logits/rejected": -2.649420738220215,
      "logps/chosen": -56.740196228027344,
      "logps/rejected": -122.7352523803711,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4308063983917236,
      "rewards/margins": 8.219430923461914,
      "rewards/rejected": -4.7886247634887695,
      "step": 2456
    },
    {
      "epoch": 0.9828,
      "grad_norm": 0.012621201574802399,
      "learning_rate": 6.725333333333333e-07,
      "logits/chosen": -2.1714706420898438,
      "logits/rejected": -3.0340285301208496,
      "logps/chosen": -124.02631378173828,
      "logps/rejected": -164.297119140625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3578362464904785,
      "rewards/margins": 9.234312057495117,
      "rewards/rejected": -5.8764753341674805,
      "step": 2457
    },
    {
      "epoch": 0.9832,
      "grad_norm": 0.0905657559633255,
      "learning_rate": 6.724e-07,
      "logits/chosen": -2.3220484256744385,
      "logits/rejected": -3.2714245319366455,
      "logps/chosen": -119.07488250732422,
      "logps/rejected": -162.47958374023438,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5802810192108154,
      "rewards/margins": 7.173504829406738,
      "rewards/rejected": -5.593223571777344,
      "step": 2458
    },
    {
      "epoch": 0.9836,
      "grad_norm": 0.023557420819997787,
      "learning_rate": 6.722666666666666e-07,
      "logits/chosen": -2.2090773582458496,
      "logits/rejected": -3.6974563598632812,
      "logps/chosen": -116.41645812988281,
      "logps/rejected": -202.97149658203125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5536510944366455,
      "rewards/margins": 10.711511611938477,
      "rewards/rejected": -8.157859802246094,
      "step": 2459
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.011766921728849411,
      "learning_rate": 6.721333333333333e-07,
      "logits/chosen": -2.174020767211914,
      "logits/rejected": -2.956752061843872,
      "logps/chosen": -152.3623046875,
      "logps/rejected": -175.13888549804688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.431854248046875,
      "rewards/margins": 10.225088119506836,
      "rewards/rejected": -6.793233871459961,
      "step": 2460
    },
    {
      "epoch": 0.9844,
      "grad_norm": 0.006245819851756096,
      "learning_rate": 6.72e-07,
      "logits/chosen": -2.51430082321167,
      "logits/rejected": -3.202305793762207,
      "logps/chosen": -101.75971221923828,
      "logps/rejected": -159.67059326171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.9489216804504395,
      "rewards/margins": 11.547765731811523,
      "rewards/rejected": -6.598843574523926,
      "step": 2461
    },
    {
      "epoch": 0.9848,
      "grad_norm": 3.512901782989502,
      "learning_rate": 6.718666666666666e-07,
      "logits/chosen": -2.8689379692077637,
      "logits/rejected": -2.8597664833068848,
      "logps/chosen": -143.76913452148438,
      "logps/rejected": -120.24799346923828,
      "loss": 0.0288,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2598133087158203,
      "rewards/margins": 4.725205421447754,
      "rewards/rejected": -4.465392112731934,
      "step": 2462
    },
    {
      "epoch": 0.9852,
      "grad_norm": 0.013064293190836906,
      "learning_rate": 6.717333333333333e-07,
      "logits/chosen": -2.1835174560546875,
      "logits/rejected": -3.5520334243774414,
      "logps/chosen": -91.89543914794922,
      "logps/rejected": -150.47488403320312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7366554737091064,
      "rewards/margins": 9.52149772644043,
      "rewards/rejected": -6.784842491149902,
      "step": 2463
    },
    {
      "epoch": 0.9856,
      "grad_norm": 0.038706012070178986,
      "learning_rate": 6.716e-07,
      "logits/chosen": -2.3774185180664062,
      "logits/rejected": -2.3325343132019043,
      "logps/chosen": -184.0659942626953,
      "logps/rejected": -188.4684600830078,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9805443286895752,
      "rewards/margins": 8.987443923950195,
      "rewards/rejected": -7.006899833679199,
      "step": 2464
    },
    {
      "epoch": 0.986,
      "grad_norm": 5.2928924560546875,
      "learning_rate": 6.714666666666666e-07,
      "logits/chosen": -2.8231399059295654,
      "logits/rejected": -3.552203893661499,
      "logps/chosen": -187.52841186523438,
      "logps/rejected": -183.1795196533203,
      "loss": 0.0538,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9483470320701599,
      "rewards/margins": 7.634283542633057,
      "rewards/rejected": -6.685936450958252,
      "step": 2465
    },
    {
      "epoch": 0.9864,
      "grad_norm": 0.10201310366392136,
      "learning_rate": 6.713333333333333e-07,
      "logits/chosen": -1.8374890089035034,
      "logits/rejected": -2.2376577854156494,
      "logps/chosen": -83.17758178710938,
      "logps/rejected": -145.98580932617188,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8229660987854004,
      "rewards/margins": 7.8887176513671875,
      "rewards/rejected": -6.065752029418945,
      "step": 2466
    },
    {
      "epoch": 0.9868,
      "grad_norm": 0.49804985523223877,
      "learning_rate": 6.712e-07,
      "logits/chosen": -1.970914602279663,
      "logits/rejected": -3.0552477836608887,
      "logps/chosen": -123.90544891357422,
      "logps/rejected": -151.51901245117188,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2662948668003082,
      "rewards/margins": 5.8995819091796875,
      "rewards/rejected": -5.633286476135254,
      "step": 2467
    },
    {
      "epoch": 0.9872,
      "grad_norm": 0.047442130744457245,
      "learning_rate": 6.710666666666667e-07,
      "logits/chosen": -1.833053708076477,
      "logits/rejected": -3.803363800048828,
      "logps/chosen": -90.03251647949219,
      "logps/rejected": -154.33595275878906,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.990630626678467,
      "rewards/margins": 8.121515274047852,
      "rewards/rejected": -5.130884170532227,
      "step": 2468
    },
    {
      "epoch": 0.9876,
      "grad_norm": 0.03907668590545654,
      "learning_rate": 6.709333333333333e-07,
      "logits/chosen": -1.9989287853240967,
      "logits/rejected": -3.194218635559082,
      "logps/chosen": -103.9942855834961,
      "logps/rejected": -134.38201904296875,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.86750864982605,
      "rewards/margins": 7.722904205322266,
      "rewards/rejected": -4.855395317077637,
      "step": 2469
    },
    {
      "epoch": 0.988,
      "grad_norm": 0.09171795099973679,
      "learning_rate": 6.707999999999999e-07,
      "logits/chosen": -2.40071177482605,
      "logits/rejected": -3.1451852321624756,
      "logps/chosen": -172.0655059814453,
      "logps/rejected": -151.9994354248047,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0352578163146973,
      "rewards/margins": 6.971808433532715,
      "rewards/rejected": -4.936550617218018,
      "step": 2470
    },
    {
      "epoch": 0.9884,
      "grad_norm": 0.9570237398147583,
      "learning_rate": 6.706666666666666e-07,
      "logits/chosen": -2.5484366416931152,
      "logits/rejected": -2.951221227645874,
      "logps/chosen": -159.88589477539062,
      "logps/rejected": -133.04837036132812,
      "loss": 0.0068,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2617745399475098,
      "rewards/margins": 6.107575416564941,
      "rewards/rejected": -4.845800876617432,
      "step": 2471
    },
    {
      "epoch": 0.9888,
      "grad_norm": 0.024143503978848457,
      "learning_rate": 6.705333333333333e-07,
      "logits/chosen": -2.5499634742736816,
      "logits/rejected": -2.8609182834625244,
      "logps/chosen": -129.40289306640625,
      "logps/rejected": -135.95755004882812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.976752758026123,
      "rewards/margins": 8.4959716796875,
      "rewards/rejected": -5.519219398498535,
      "step": 2472
    },
    {
      "epoch": 0.9892,
      "grad_norm": 0.027069197967648506,
      "learning_rate": 6.704e-07,
      "logits/chosen": -2.411520481109619,
      "logits/rejected": -3.4319748878479004,
      "logps/chosen": -203.41583251953125,
      "logps/rejected": -170.0001220703125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7504875659942627,
      "rewards/margins": 8.33277702331543,
      "rewards/rejected": -6.582289695739746,
      "step": 2473
    },
    {
      "epoch": 0.9896,
      "grad_norm": 0.2765357792377472,
      "learning_rate": 6.702666666666667e-07,
      "logits/chosen": -2.2582054138183594,
      "logits/rejected": -2.6956746578216553,
      "logps/chosen": -112.72303771972656,
      "logps/rejected": -169.3943634033203,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7173935174942017,
      "rewards/margins": 6.1100921630859375,
      "rewards/rejected": -4.392698287963867,
      "step": 2474
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.07640150189399719,
      "learning_rate": 6.701333333333334e-07,
      "logits/chosen": -1.5364471673965454,
      "logits/rejected": -3.4714550971984863,
      "logps/chosen": -96.09439086914062,
      "logps/rejected": -178.2381591796875,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6258902549743652,
      "rewards/margins": 8.153518676757812,
      "rewards/rejected": -5.527627944946289,
      "step": 2475
    },
    {
      "epoch": 0.9904,
      "grad_norm": 0.008666574023663998,
      "learning_rate": 6.7e-07,
      "logits/chosen": -2.081155776977539,
      "logits/rejected": -3.737943649291992,
      "logps/chosen": -91.977294921875,
      "logps/rejected": -199.77005004882812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8401333093643188,
      "rewards/margins": 9.87696647644043,
      "rewards/rejected": -8.036833763122559,
      "step": 2476
    },
    {
      "epoch": 0.9908,
      "grad_norm": 0.07155263423919678,
      "learning_rate": 6.698666666666667e-07,
      "logits/chosen": -2.599194049835205,
      "logits/rejected": -3.581313133239746,
      "logps/chosen": -257.4053955078125,
      "logps/rejected": -186.53346252441406,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0452585220336914,
      "rewards/margins": 8.964426040649414,
      "rewards/rejected": -5.919167995452881,
      "step": 2477
    },
    {
      "epoch": 0.9912,
      "grad_norm": 0.10666058212518692,
      "learning_rate": 6.697333333333332e-07,
      "logits/chosen": -2.1723883152008057,
      "logits/rejected": -2.995838165283203,
      "logps/chosen": -74.339111328125,
      "logps/rejected": -156.4680938720703,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9868459701538086,
      "rewards/margins": 9.596927642822266,
      "rewards/rejected": -6.610081672668457,
      "step": 2478
    },
    {
      "epoch": 0.9916,
      "grad_norm": 4.465003490447998,
      "learning_rate": 6.695999999999999e-07,
      "logits/chosen": -2.086552858352661,
      "logits/rejected": -3.2069194316864014,
      "logps/chosen": -162.1966552734375,
      "logps/rejected": -136.33428955078125,
      "loss": 0.029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.540249228477478,
      "rewards/margins": 5.3969316482543945,
      "rewards/rejected": -4.856682300567627,
      "step": 2479
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.5999085307121277,
      "learning_rate": 6.694666666666666e-07,
      "logits/chosen": -1.9590885639190674,
      "logits/rejected": -2.9936065673828125,
      "logps/chosen": -137.19430541992188,
      "logps/rejected": -148.75198364257812,
      "loss": 0.0063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13107873499393463,
      "rewards/margins": 5.0568318367004395,
      "rewards/rejected": -4.925753116607666,
      "step": 2480
    },
    {
      "epoch": 0.9924,
      "grad_norm": 0.052766431123018265,
      "learning_rate": 6.693333333333333e-07,
      "logits/chosen": -2.2190113067626953,
      "logits/rejected": -3.440110445022583,
      "logps/chosen": -85.68428802490234,
      "logps/rejected": -158.508056640625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0900352001190186,
      "rewards/margins": 7.781811237335205,
      "rewards/rejected": -6.691776275634766,
      "step": 2481
    },
    {
      "epoch": 0.9928,
      "grad_norm": 0.0270058736205101,
      "learning_rate": 6.692e-07,
      "logits/chosen": -2.1238465309143066,
      "logits/rejected": -2.9680802822113037,
      "logps/chosen": -117.53772735595703,
      "logps/rejected": -144.11195373535156,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0631821155548096,
      "rewards/margins": 8.550854682922363,
      "rewards/rejected": -5.487672805786133,
      "step": 2482
    },
    {
      "epoch": 0.9932,
      "grad_norm": 0.016955552622675896,
      "learning_rate": 6.690666666666667e-07,
      "logits/chosen": -2.2148666381835938,
      "logits/rejected": -3.693223476409912,
      "logps/chosen": -166.69451904296875,
      "logps/rejected": -163.84603881835938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2115187644958496,
      "rewards/margins": 9.387115478515625,
      "rewards/rejected": -6.175596237182617,
      "step": 2483
    },
    {
      "epoch": 0.9936,
      "grad_norm": 0.31934043765068054,
      "learning_rate": 6.689333333333334e-07,
      "logits/chosen": -2.7220568656921387,
      "logits/rejected": -3.163228988647461,
      "logps/chosen": -214.286865234375,
      "logps/rejected": -189.57034301757812,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.28421247005462646,
      "rewards/margins": 6.283362865447998,
      "rewards/rejected": -5.999150276184082,
      "step": 2484
    },
    {
      "epoch": 0.994,
      "grad_norm": 0.5120264887809753,
      "learning_rate": 6.688e-07,
      "logits/chosen": -1.7213916778564453,
      "logits/rejected": -2.8843846321105957,
      "logps/chosen": -92.7246322631836,
      "logps/rejected": -124.67950439453125,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4968101680278778,
      "rewards/margins": 5.443709373474121,
      "rewards/rejected": -4.946898937225342,
      "step": 2485
    },
    {
      "epoch": 0.9944,
      "grad_norm": 0.08521057665348053,
      "learning_rate": 6.686666666666666e-07,
      "logits/chosen": -2.1211276054382324,
      "logits/rejected": -3.5484025478363037,
      "logps/chosen": -171.20875549316406,
      "logps/rejected": -232.18408203125,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4804775714874268,
      "rewards/margins": 7.489754676818848,
      "rewards/rejected": -6.00927734375,
      "step": 2486
    },
    {
      "epoch": 0.9948,
      "grad_norm": 0.006912141107022762,
      "learning_rate": 6.685333333333332e-07,
      "logits/chosen": -2.336595296859741,
      "logits/rejected": -3.7494945526123047,
      "logps/chosen": -102.6041259765625,
      "logps/rejected": -161.07330322265625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.536099433898926,
      "rewards/margins": 9.84878921508789,
      "rewards/rejected": -6.312690258026123,
      "step": 2487
    },
    {
      "epoch": 0.9952,
      "grad_norm": 3.1024630069732666,
      "learning_rate": 6.683999999999999e-07,
      "logits/chosen": -2.3239963054656982,
      "logits/rejected": -3.2169322967529297,
      "logps/chosen": -103.82768249511719,
      "logps/rejected": -130.49057006835938,
      "loss": 0.0207,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7294437885284424,
      "rewards/margins": 5.470015048980713,
      "rewards/rejected": -4.740571022033691,
      "step": 2488
    },
    {
      "epoch": 0.9956,
      "grad_norm": 0.03228077292442322,
      "learning_rate": 6.682666666666666e-07,
      "logits/chosen": -2.4571733474731445,
      "logits/rejected": -3.4055397510528564,
      "logps/chosen": -136.10252380371094,
      "logps/rejected": -151.72329711914062,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9417343139648438,
      "rewards/margins": 8.655094146728516,
      "rewards/rejected": -5.713359832763672,
      "step": 2489
    },
    {
      "epoch": 0.996,
      "grad_norm": 0.4400515854358673,
      "learning_rate": 6.681333333333333e-07,
      "logits/chosen": -2.1892788410186768,
      "logits/rejected": -3.083662986755371,
      "logps/chosen": -129.42002868652344,
      "logps/rejected": -148.00238037109375,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.212958335876465,
      "rewards/margins": 7.828629493713379,
      "rewards/rejected": -5.615671157836914,
      "step": 2490
    },
    {
      "epoch": 0.9964,
      "grad_norm": 0.14044170081615448,
      "learning_rate": 6.68e-07,
      "logits/chosen": -1.9654240608215332,
      "logits/rejected": -3.0183990001678467,
      "logps/chosen": -197.0392303466797,
      "logps/rejected": -188.41102600097656,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2558128833770752,
      "rewards/margins": 8.105728149414062,
      "rewards/rejected": -6.849915504455566,
      "step": 2491
    },
    {
      "epoch": 0.9968,
      "grad_norm": 0.09359949082136154,
      "learning_rate": 6.678666666666667e-07,
      "logits/chosen": -1.9791219234466553,
      "logits/rejected": -3.563105821609497,
      "logps/chosen": -181.2046356201172,
      "logps/rejected": -215.45628356933594,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7609764337539673,
      "rewards/margins": 8.773494720458984,
      "rewards/rejected": -7.012517929077148,
      "step": 2492
    },
    {
      "epoch": 0.9972,
      "grad_norm": 0.1322631537914276,
      "learning_rate": 6.677333333333333e-07,
      "logits/chosen": -2.799485921859741,
      "logits/rejected": -3.7329983711242676,
      "logps/chosen": -170.7764434814453,
      "logps/rejected": -172.05001831054688,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7674610614776611,
      "rewards/margins": 8.056758880615234,
      "rewards/rejected": -6.289297580718994,
      "step": 2493
    },
    {
      "epoch": 0.9976,
      "grad_norm": 0.01508705411106348,
      "learning_rate": 6.676e-07,
      "logits/chosen": -2.621196746826172,
      "logits/rejected": -3.0014548301696777,
      "logps/chosen": -216.976806640625,
      "logps/rejected": -174.50289916992188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9055267572402954,
      "rewards/margins": 8.859487533569336,
      "rewards/rejected": -6.953960418701172,
      "step": 2494
    },
    {
      "epoch": 0.998,
      "grad_norm": 1.2673242092132568,
      "learning_rate": 6.674666666666667e-07,
      "logits/chosen": -2.1130213737487793,
      "logits/rejected": -3.327197790145874,
      "logps/chosen": -170.823486328125,
      "logps/rejected": -164.14389038085938,
      "loss": 0.0092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0187180042266846,
      "rewards/margins": 5.470829963684082,
      "rewards/rejected": -6.4895477294921875,
      "step": 2495
    },
    {
      "epoch": 0.9984,
      "grad_norm": 0.013889714144170284,
      "learning_rate": 6.673333333333334e-07,
      "logits/chosen": -2.5233986377716064,
      "logits/rejected": -3.159823417663574,
      "logps/chosen": -171.2169189453125,
      "logps/rejected": -222.2137908935547,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.806537628173828,
      "rewards/margins": 8.971294403076172,
      "rewards/rejected": -6.1647562980651855,
      "step": 2496
    },
    {
      "epoch": 0.9988,
      "grad_norm": 0.01993376947939396,
      "learning_rate": 6.671999999999999e-07,
      "logits/chosen": -2.5449533462524414,
      "logits/rejected": -3.512787103652954,
      "logps/chosen": -105.66290283203125,
      "logps/rejected": -177.05685424804688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4066848754882812,
      "rewards/margins": 9.472274780273438,
      "rewards/rejected": -8.065589904785156,
      "step": 2497
    },
    {
      "epoch": 0.9992,
      "grad_norm": 0.015499427914619446,
      "learning_rate": 6.670666666666666e-07,
      "logits/chosen": -1.9723724126815796,
      "logits/rejected": -2.892199993133545,
      "logps/chosen": -94.98654174804688,
      "logps/rejected": -139.15249633789062,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.600850820541382,
      "rewards/margins": 8.73945426940918,
      "rewards/rejected": -6.138603687286377,
      "step": 2498
    },
    {
      "epoch": 0.9996,
      "grad_norm": 0.04427120462059975,
      "learning_rate": 6.669333333333333e-07,
      "logits/chosen": -2.613521099090576,
      "logits/rejected": -2.776344060897827,
      "logps/chosen": -114.50736999511719,
      "logps/rejected": -180.61416625976562,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5030791759490967,
      "rewards/margins": 8.6430082321167,
      "rewards/rejected": -6.139928817749023,
      "step": 2499
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.01242956891655922,
      "learning_rate": 6.667999999999999e-07,
      "logits/chosen": -2.467849016189575,
      "logits/rejected": -3.389840602874756,
      "logps/chosen": -116.36892700195312,
      "logps/rejected": -181.22845458984375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0802013874053955,
      "rewards/margins": 10.442777633666992,
      "rewards/rejected": -7.362576484680176,
      "step": 2500
    },
    {
      "epoch": 1.0004,
      "grad_norm": 0.014907946810126305,
      "learning_rate": 6.666666666666666e-07,
      "logits/chosen": -2.1722617149353027,
      "logits/rejected": -3.138725519180298,
      "logps/chosen": -162.38442993164062,
      "logps/rejected": -215.24627685546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.895263671875,
      "rewards/margins": 9.608949661254883,
      "rewards/rejected": -6.713686466217041,
      "step": 2501
    },
    {
      "epoch": 1.0008,
      "grad_norm": 0.02048415131866932,
      "learning_rate": 6.665333333333333e-07,
      "logits/chosen": -2.7794137001037598,
      "logits/rejected": -2.6720120906829834,
      "logps/chosen": -133.74783325195312,
      "logps/rejected": -136.9343719482422,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.199220657348633,
      "rewards/margins": 9.38003158569336,
      "rewards/rejected": -5.180810451507568,
      "step": 2502
    },
    {
      "epoch": 1.0012,
      "grad_norm": 0.13841386139392853,
      "learning_rate": 6.664e-07,
      "logits/chosen": -2.5485620498657227,
      "logits/rejected": -3.398097038269043,
      "logps/chosen": -123.36978149414062,
      "logps/rejected": -152.2628173828125,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4490790367126465,
      "rewards/margins": 8.798019409179688,
      "rewards/rejected": -5.348939895629883,
      "step": 2503
    },
    {
      "epoch": 1.0016,
      "grad_norm": 0.0006265818956308067,
      "learning_rate": 6.662666666666667e-07,
      "logits/chosen": -2.318538188934326,
      "logits/rejected": -3.678800582885742,
      "logps/chosen": -97.98770141601562,
      "logps/rejected": -213.86001586914062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7602458000183105,
      "rewards/margins": 12.306234359741211,
      "rewards/rejected": -8.545988082885742,
      "step": 2504
    },
    {
      "epoch": 1.002,
      "grad_norm": 0.018652494996786118,
      "learning_rate": 6.661333333333334e-07,
      "logits/chosen": -1.8627815246582031,
      "logits/rejected": -2.9282760620117188,
      "logps/chosen": -153.5413055419922,
      "logps/rejected": -177.18075561523438,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4577183723449707,
      "rewards/margins": 9.293869018554688,
      "rewards/rejected": -5.836150169372559,
      "step": 2505
    },
    {
      "epoch": 1.0024,
      "grad_norm": 0.004092731978744268,
      "learning_rate": 6.66e-07,
      "logits/chosen": -2.3839540481567383,
      "logits/rejected": -3.195856809616089,
      "logps/chosen": -120.4983901977539,
      "logps/rejected": -207.2930908203125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9472670555114746,
      "rewards/margins": 10.856500625610352,
      "rewards/rejected": -7.9092326164245605,
      "step": 2506
    },
    {
      "epoch": 1.0028,
      "grad_norm": 0.010263851843774319,
      "learning_rate": 6.658666666666666e-07,
      "logits/chosen": -2.143580913543701,
      "logits/rejected": -2.8195950984954834,
      "logps/chosen": -150.29815673828125,
      "logps/rejected": -159.51095581054688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7326149940490723,
      "rewards/margins": 9.228878021240234,
      "rewards/rejected": -5.496263027191162,
      "step": 2507
    },
    {
      "epoch": 1.0032,
      "grad_norm": 0.13080918788909912,
      "learning_rate": 6.657333333333332e-07,
      "logits/chosen": -3.058652877807617,
      "logits/rejected": -3.3741002082824707,
      "logps/chosen": -211.6591796875,
      "logps/rejected": -187.62538146972656,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6136382818222046,
      "rewards/margins": 6.877656936645508,
      "rewards/rejected": -6.2640180587768555,
      "step": 2508
    },
    {
      "epoch": 1.0036,
      "grad_norm": 2.70590877532959,
      "learning_rate": 6.655999999999999e-07,
      "logits/chosen": -2.7412590980529785,
      "logits/rejected": -3.0607333183288574,
      "logps/chosen": -178.56259155273438,
      "logps/rejected": -140.68060302734375,
      "loss": 0.0276,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.855023980140686,
      "rewards/margins": 5.7594757080078125,
      "rewards/rejected": -4.904451847076416,
      "step": 2509
    },
    {
      "epoch": 1.004,
      "grad_norm": 2.6679275035858154,
      "learning_rate": 6.654666666666666e-07,
      "logits/chosen": -2.4073147773742676,
      "logits/rejected": -2.8180551528930664,
      "logps/chosen": -119.14987182617188,
      "logps/rejected": -144.58682250976562,
      "loss": 0.024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.48504868149757385,
      "rewards/margins": 5.425148010253906,
      "rewards/rejected": -4.940099239349365,
      "step": 2510
    },
    {
      "epoch": 1.0044,
      "grad_norm": 3.3576974868774414,
      "learning_rate": 6.653333333333333e-07,
      "logits/chosen": -1.8410451412200928,
      "logits/rejected": -2.933675765991211,
      "logps/chosen": -94.31827545166016,
      "logps/rejected": -154.7927703857422,
      "loss": 0.0211,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05976104736328125,
      "rewards/margins": 5.896449089050293,
      "rewards/rejected": -5.836688041687012,
      "step": 2511
    },
    {
      "epoch": 1.0048,
      "grad_norm": 0.023930614814162254,
      "learning_rate": 6.652e-07,
      "logits/chosen": -2.0053038597106934,
      "logits/rejected": -3.174692153930664,
      "logps/chosen": -95.38668823242188,
      "logps/rejected": -150.4163360595703,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9872660636901855,
      "rewards/margins": 8.991186141967773,
      "rewards/rejected": -6.003920078277588,
      "step": 2512
    },
    {
      "epoch": 1.0052,
      "grad_norm": 0.036954548209905624,
      "learning_rate": 6.650666666666667e-07,
      "logits/chosen": -2.152785062789917,
      "logits/rejected": -2.984673023223877,
      "logps/chosen": -165.9699249267578,
      "logps/rejected": -219.14671325683594,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3503971099853516,
      "rewards/margins": 9.139570236206055,
      "rewards/rejected": -5.789172649383545,
      "step": 2513
    },
    {
      "epoch": 1.0056,
      "grad_norm": 0.1437421590089798,
      "learning_rate": 6.649333333333334e-07,
      "logits/chosen": -3.0829129219055176,
      "logits/rejected": -3.427196741104126,
      "logps/chosen": -170.54281616210938,
      "logps/rejected": -209.75338745117188,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5461647510528564,
      "rewards/margins": 9.114240646362305,
      "rewards/rejected": -6.568076133728027,
      "step": 2514
    },
    {
      "epoch": 1.006,
      "grad_norm": 0.19776904582977295,
      "learning_rate": 6.647999999999999e-07,
      "logits/chosen": -1.940171480178833,
      "logits/rejected": -3.025747060775757,
      "logps/chosen": -143.05941772460938,
      "logps/rejected": -205.2970428466797,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6601617336273193,
      "rewards/margins": 7.8693437576293945,
      "rewards/rejected": -5.209182262420654,
      "step": 2515
    },
    {
      "epoch": 1.0064,
      "grad_norm": 2.185760974884033,
      "learning_rate": 6.646666666666666e-07,
      "logits/chosen": -2.032431125640869,
      "logits/rejected": -3.386441230773926,
      "logps/chosen": -77.07803344726562,
      "logps/rejected": -161.5469970703125,
      "loss": 0.0126,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5312950611114502,
      "rewards/margins": 6.490431785583496,
      "rewards/rejected": -5.959136962890625,
      "step": 2516
    },
    {
      "epoch": 1.0068,
      "grad_norm": 0.862869143486023,
      "learning_rate": 6.645333333333332e-07,
      "logits/chosen": -1.8816590309143066,
      "logits/rejected": -2.122401475906372,
      "logps/chosen": -110.09882354736328,
      "logps/rejected": -122.205078125,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0955730676651,
      "rewards/margins": 5.194894790649414,
      "rewards/rejected": -4.099321365356445,
      "step": 2517
    },
    {
      "epoch": 1.0072,
      "grad_norm": 0.0024876841343939304,
      "learning_rate": 6.643999999999999e-07,
      "logits/chosen": -2.2310256958007812,
      "logits/rejected": -2.833674430847168,
      "logps/chosen": -107.52323913574219,
      "logps/rejected": -154.45513916015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.253322601318359,
      "rewards/margins": 11.106011390686035,
      "rewards/rejected": -6.852688789367676,
      "step": 2518
    },
    {
      "epoch": 1.0076,
      "grad_norm": 0.1912480741739273,
      "learning_rate": 6.642666666666666e-07,
      "logits/chosen": -1.6798421144485474,
      "logits/rejected": -2.9521470069885254,
      "logps/chosen": -119.28804016113281,
      "logps/rejected": -122.37235260009766,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4276795387268066,
      "rewards/margins": 6.522930145263672,
      "rewards/rejected": -4.095251083374023,
      "step": 2519
    },
    {
      "epoch": 1.008,
      "grad_norm": 0.9376463294029236,
      "learning_rate": 6.641333333333333e-07,
      "logits/chosen": -2.092916965484619,
      "logits/rejected": -2.9297966957092285,
      "logps/chosen": -113.65132141113281,
      "logps/rejected": -143.96112060546875,
      "loss": 0.01,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4583899974822998,
      "rewards/margins": 5.706443786621094,
      "rewards/rejected": -4.248053550720215,
      "step": 2520
    },
    {
      "epoch": 1.0084,
      "grad_norm": 1.8348196744918823,
      "learning_rate": 6.64e-07,
      "logits/chosen": -2.4585139751434326,
      "logits/rejected": -2.8376381397247314,
      "logps/chosen": -164.75885009765625,
      "logps/rejected": -180.34854125976562,
      "loss": 0.0132,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1464715003967285,
      "rewards/margins": 5.200157165527344,
      "rewards/rejected": -6.346628665924072,
      "step": 2521
    },
    {
      "epoch": 1.0088,
      "grad_norm": 0.025476107373833656,
      "learning_rate": 6.638666666666667e-07,
      "logits/chosen": -2.6850414276123047,
      "logits/rejected": -3.493755340576172,
      "logps/chosen": -151.43417358398438,
      "logps/rejected": -184.69009399414062,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9251773357391357,
      "rewards/margins": 8.422073364257812,
      "rewards/rejected": -6.496895790100098,
      "step": 2522
    },
    {
      "epoch": 1.0092,
      "grad_norm": 0.026028191670775414,
      "learning_rate": 6.637333333333333e-07,
      "logits/chosen": -2.1630091667175293,
      "logits/rejected": -3.477597713470459,
      "logps/chosen": -120.60443878173828,
      "logps/rejected": -158.01763916015625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6719906330108643,
      "rewards/margins": 8.419391632080078,
      "rewards/rejected": -5.747400760650635,
      "step": 2523
    },
    {
      "epoch": 1.0096,
      "grad_norm": 1.1929839849472046,
      "learning_rate": 6.636e-07,
      "logits/chosen": -2.2178099155426025,
      "logits/rejected": -3.370427131652832,
      "logps/chosen": -181.50927734375,
      "logps/rejected": -149.14193725585938,
      "loss": 0.0087,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5131425857543945,
      "rewards/margins": 6.524527549743652,
      "rewards/rejected": -5.011384963989258,
      "step": 2524
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.010779410600662231,
      "learning_rate": 6.634666666666666e-07,
      "logits/chosen": -2.2365050315856934,
      "logits/rejected": -3.2867231369018555,
      "logps/chosen": -123.43824768066406,
      "logps/rejected": -175.88742065429688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7303671836853027,
      "rewards/margins": 10.509541511535645,
      "rewards/rejected": -6.779174327850342,
      "step": 2525
    },
    {
      "epoch": 1.0104,
      "grad_norm": 0.043907370418310165,
      "learning_rate": 6.633333333333333e-07,
      "logits/chosen": -2.0676445960998535,
      "logits/rejected": -3.41517972946167,
      "logps/chosen": -89.78709411621094,
      "logps/rejected": -142.126953125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.31960129737854,
      "rewards/margins": 8.2409086227417,
      "rewards/rejected": -4.921307563781738,
      "step": 2526
    },
    {
      "epoch": 1.0108,
      "grad_norm": 0.8505204916000366,
      "learning_rate": 6.632e-07,
      "logits/chosen": -2.240490436553955,
      "logits/rejected": -2.8877172470092773,
      "logps/chosen": -171.45181274414062,
      "logps/rejected": -151.95059204101562,
      "loss": 0.0063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9182541370391846,
      "rewards/margins": 5.70863151550293,
      "rewards/rejected": -4.790377616882324,
      "step": 2527
    },
    {
      "epoch": 1.0112,
      "grad_norm": 0.10080792754888535,
      "learning_rate": 6.630666666666666e-07,
      "logits/chosen": -2.223422050476074,
      "logits/rejected": -3.096066951751709,
      "logps/chosen": -151.05364990234375,
      "logps/rejected": -183.20062255859375,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5080878734588623,
      "rewards/margins": 7.620929718017578,
      "rewards/rejected": -6.112841606140137,
      "step": 2528
    },
    {
      "epoch": 1.0116,
      "grad_norm": 1.0698009729385376,
      "learning_rate": 6.629333333333333e-07,
      "logits/chosen": -2.113696575164795,
      "logits/rejected": -2.5109004974365234,
      "logps/chosen": -116.18567657470703,
      "logps/rejected": -150.279052734375,
      "loss": 0.0056,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6257686614990234,
      "rewards/margins": 7.500711441040039,
      "rewards/rejected": -5.874942779541016,
      "step": 2529
    },
    {
      "epoch": 1.012,
      "grad_norm": 0.23876382410526276,
      "learning_rate": 6.627999999999999e-07,
      "logits/chosen": -2.2740814685821533,
      "logits/rejected": -3.1664414405822754,
      "logps/chosen": -118.9884262084961,
      "logps/rejected": -201.27261352539062,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2395637035369873,
      "rewards/margins": 6.892355918884277,
      "rewards/rejected": -5.652791976928711,
      "step": 2530
    },
    {
      "epoch": 1.0124,
      "grad_norm": 0.026810545474290848,
      "learning_rate": 6.626666666666666e-07,
      "logits/chosen": -2.099790096282959,
      "logits/rejected": -3.6603922843933105,
      "logps/chosen": -87.02291870117188,
      "logps/rejected": -167.21554565429688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.438030958175659,
      "rewards/margins": 9.564825057983398,
      "rewards/rejected": -6.126794815063477,
      "step": 2531
    },
    {
      "epoch": 1.0128,
      "grad_norm": 0.0025109380949288607,
      "learning_rate": 6.625333333333333e-07,
      "logits/chosen": -2.6606862545013428,
      "logits/rejected": -3.268723487854004,
      "logps/chosen": -130.11160278320312,
      "logps/rejected": -179.7005615234375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6503071784973145,
      "rewards/margins": 10.7403564453125,
      "rewards/rejected": -7.090049743652344,
      "step": 2532
    },
    {
      "epoch": 1.0132,
      "grad_norm": 0.005215831100940704,
      "learning_rate": 6.624e-07,
      "logits/chosen": -2.6436080932617188,
      "logits/rejected": -3.665013313293457,
      "logps/chosen": -105.64897155761719,
      "logps/rejected": -208.07223510742188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7724289894104004,
      "rewards/margins": 10.98056411743164,
      "rewards/rejected": -8.208135604858398,
      "step": 2533
    },
    {
      "epoch": 1.0136,
      "grad_norm": 0.01871589757502079,
      "learning_rate": 6.622666666666666e-07,
      "logits/chosen": -2.193160057067871,
      "logits/rejected": -2.9894001483917236,
      "logps/chosen": -93.22239685058594,
      "logps/rejected": -163.1666259765625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8774542808532715,
      "rewards/margins": 8.674206733703613,
      "rewards/rejected": -5.796751976013184,
      "step": 2534
    },
    {
      "epoch": 1.014,
      "grad_norm": 0.00450127711519599,
      "learning_rate": 6.621333333333333e-07,
      "logits/chosen": -2.2772722244262695,
      "logits/rejected": -2.9827046394348145,
      "logps/chosen": -105.1622314453125,
      "logps/rejected": -141.18377685546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.997379779815674,
      "rewards/margins": 9.875904083251953,
      "rewards/rejected": -5.878523826599121,
      "step": 2535
    },
    {
      "epoch": 1.0144,
      "grad_norm": 1.1596949100494385,
      "learning_rate": 6.62e-07,
      "logits/chosen": -1.5119657516479492,
      "logits/rejected": -2.1557939052581787,
      "logps/chosen": -109.44746398925781,
      "logps/rejected": -112.56060791015625,
      "loss": 0.0083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6597889065742493,
      "rewards/margins": 5.053677082061768,
      "rewards/rejected": -4.393887996673584,
      "step": 2536
    },
    {
      "epoch": 1.0148,
      "grad_norm": 0.0012241427320986986,
      "learning_rate": 6.618666666666667e-07,
      "logits/chosen": -1.93821120262146,
      "logits/rejected": -3.2934422492980957,
      "logps/chosen": -122.59904479980469,
      "logps/rejected": -192.60443115234375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.517955303192139,
      "rewards/margins": 11.70618724822998,
      "rewards/rejected": -7.188232421875,
      "step": 2537
    },
    {
      "epoch": 1.0152,
      "grad_norm": 0.19260349869728088,
      "learning_rate": 6.617333333333333e-07,
      "logits/chosen": -2.353379249572754,
      "logits/rejected": -2.583815813064575,
      "logps/chosen": -91.08163452148438,
      "logps/rejected": -113.54536437988281,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.547865390777588,
      "rewards/margins": 7.2844672203063965,
      "rewards/rejected": -3.7366018295288086,
      "step": 2538
    },
    {
      "epoch": 1.0156,
      "grad_norm": 2.816378116607666,
      "learning_rate": 6.615999999999999e-07,
      "logits/chosen": -1.935316562652588,
      "logits/rejected": -3.151379108428955,
      "logps/chosen": -122.19464111328125,
      "logps/rejected": -133.4371795654297,
      "loss": 0.0196,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1449172496795654,
      "rewards/margins": 5.07401704788208,
      "rewards/rejected": -3.9290995597839355,
      "step": 2539
    },
    {
      "epoch": 1.016,
      "grad_norm": 0.17957086861133575,
      "learning_rate": 6.614666666666666e-07,
      "logits/chosen": -2.2333788871765137,
      "logits/rejected": -3.0654611587524414,
      "logps/chosen": -132.481201171875,
      "logps/rejected": -144.29098510742188,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.517876148223877,
      "rewards/margins": 6.3784379959106445,
      "rewards/rejected": -4.860561370849609,
      "step": 2540
    },
    {
      "epoch": 1.0164,
      "grad_norm": 0.004624051507562399,
      "learning_rate": 6.613333333333333e-07,
      "logits/chosen": -2.0031285285949707,
      "logits/rejected": -3.083855152130127,
      "logps/chosen": -97.03662872314453,
      "logps/rejected": -253.65811157226562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3297085762023926,
      "rewards/margins": 11.293779373168945,
      "rewards/rejected": -7.964069843292236,
      "step": 2541
    },
    {
      "epoch": 1.0168,
      "grad_norm": 0.1552908718585968,
      "learning_rate": 6.612e-07,
      "logits/chosen": -2.859666585922241,
      "logits/rejected": -3.69120454788208,
      "logps/chosen": -142.64459228515625,
      "logps/rejected": -179.63302612304688,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9618217945098877,
      "rewards/margins": 8.785314559936523,
      "rewards/rejected": -7.823493003845215,
      "step": 2542
    },
    {
      "epoch": 1.0172,
      "grad_norm": 0.015291617251932621,
      "learning_rate": 6.610666666666667e-07,
      "logits/chosen": -2.539719581604004,
      "logits/rejected": -3.050779342651367,
      "logps/chosen": -140.22943115234375,
      "logps/rejected": -134.30503845214844,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 5.180319786071777,
      "rewards/margins": 10.631216049194336,
      "rewards/rejected": -5.450896263122559,
      "step": 2543
    },
    {
      "epoch": 1.0176,
      "grad_norm": 0.5543475151062012,
      "learning_rate": 6.609333333333333e-07,
      "logits/chosen": -2.8240299224853516,
      "logits/rejected": -3.8281538486480713,
      "logps/chosen": -253.68226623535156,
      "logps/rejected": -188.74342346191406,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8447262048721313,
      "rewards/margins": 8.997350692749023,
      "rewards/rejected": -8.152624130249023,
      "step": 2544
    },
    {
      "epoch": 1.018,
      "grad_norm": 0.0123451454564929,
      "learning_rate": 6.608e-07,
      "logits/chosen": -2.274143695831299,
      "logits/rejected": -3.370805501937866,
      "logps/chosen": -95.73460388183594,
      "logps/rejected": -184.6880645751953,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9281907081604004,
      "rewards/margins": 10.455084800720215,
      "rewards/rejected": -7.526894569396973,
      "step": 2545
    },
    {
      "epoch": 1.0184,
      "grad_norm": 13.361494064331055,
      "learning_rate": 6.606666666666666e-07,
      "logits/chosen": -2.459557056427002,
      "logits/rejected": -2.443032741546631,
      "logps/chosen": -157.51931762695312,
      "logps/rejected": -117.57384490966797,
      "loss": 0.1083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7191082239151001,
      "rewards/margins": 2.751361131668091,
      "rewards/rejected": -3.4704694747924805,
      "step": 2546
    },
    {
      "epoch": 1.0188,
      "grad_norm": 0.03400231525301933,
      "learning_rate": 6.605333333333333e-07,
      "logits/chosen": -2.5576939582824707,
      "logits/rejected": -2.948655128479004,
      "logps/chosen": -98.23062133789062,
      "logps/rejected": -137.94033813476562,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.121798038482666,
      "rewards/margins": 8.25631046295166,
      "rewards/rejected": -5.134512424468994,
      "step": 2547
    },
    {
      "epoch": 1.0192,
      "grad_norm": 0.019201504066586494,
      "learning_rate": 6.604e-07,
      "logits/chosen": -2.320725440979004,
      "logits/rejected": -3.6869139671325684,
      "logps/chosen": -104.04444885253906,
      "logps/rejected": -167.2577667236328,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2590174674987793,
      "rewards/margins": 8.940293312072754,
      "rewards/rejected": -5.681275367736816,
      "step": 2548
    },
    {
      "epoch": 1.0196,
      "grad_norm": 0.15398511290550232,
      "learning_rate": 6.602666666666666e-07,
      "logits/chosen": -2.403977394104004,
      "logits/rejected": -3.3493857383728027,
      "logps/chosen": -82.77957153320312,
      "logps/rejected": -126.513671875,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3685665130615234,
      "rewards/margins": 6.411660671234131,
      "rewards/rejected": -3.0430941581726074,
      "step": 2549
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.08937782049179077,
      "learning_rate": 6.601333333333333e-07,
      "logits/chosen": -1.8406038284301758,
      "logits/rejected": -2.9797816276550293,
      "logps/chosen": -74.09703063964844,
      "logps/rejected": -142.1141357421875,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.851424217224121,
      "rewards/margins": 7.6455769538879395,
      "rewards/rejected": -4.794152736663818,
      "step": 2550
    },
    {
      "epoch": 1.0204,
      "grad_norm": 0.014233330264687538,
      "learning_rate": 6.6e-07,
      "logits/chosen": -2.1327905654907227,
      "logits/rejected": -3.097019910812378,
      "logps/chosen": -74.87864685058594,
      "logps/rejected": -148.628173828125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1104283332824707,
      "rewards/margins": 8.834341049194336,
      "rewards/rejected": -5.723913192749023,
      "step": 2551
    },
    {
      "epoch": 1.0208,
      "grad_norm": 0.0008362116641364992,
      "learning_rate": 6.598666666666667e-07,
      "logits/chosen": -2.254687547683716,
      "logits/rejected": -4.072915077209473,
      "logps/chosen": -118.8138656616211,
      "logps/rejected": -203.013916015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2518022060394287,
      "rewards/margins": 12.070491790771484,
      "rewards/rejected": -8.818689346313477,
      "step": 2552
    },
    {
      "epoch": 1.0212,
      "grad_norm": 0.04721081256866455,
      "learning_rate": 6.597333333333332e-07,
      "logits/chosen": -1.9521175622940063,
      "logits/rejected": -3.080623149871826,
      "logps/chosen": -123.54116821289062,
      "logps/rejected": -198.81512451171875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.385056257247925,
      "rewards/margins": 8.489151000976562,
      "rewards/rejected": -6.104094505310059,
      "step": 2553
    },
    {
      "epoch": 1.0216,
      "grad_norm": 0.7633839845657349,
      "learning_rate": 6.595999999999999e-07,
      "logits/chosen": -2.8372933864593506,
      "logits/rejected": -3.3780465126037598,
      "logps/chosen": -140.5863800048828,
      "logps/rejected": -137.20101928710938,
      "loss": 0.0071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7504463791847229,
      "rewards/margins": 5.038623809814453,
      "rewards/rejected": -4.288177490234375,
      "step": 2554
    },
    {
      "epoch": 1.022,
      "grad_norm": 0.09137539565563202,
      "learning_rate": 6.594666666666666e-07,
      "logits/chosen": -2.436357021331787,
      "logits/rejected": -2.891676425933838,
      "logps/chosen": -165.6703338623047,
      "logps/rejected": -174.20790100097656,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.73508620262146,
      "rewards/margins": 8.668362617492676,
      "rewards/rejected": -5.933276176452637,
      "step": 2555
    },
    {
      "epoch": 1.0224,
      "grad_norm": 2.4663517475128174,
      "learning_rate": 6.593333333333333e-07,
      "logits/chosen": -2.062255382537842,
      "logits/rejected": -2.9611825942993164,
      "logps/chosen": -102.90896606445312,
      "logps/rejected": -117.09244537353516,
      "loss": 0.0231,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8708338737487793,
      "rewards/margins": 5.975765228271484,
      "rewards/rejected": -4.104930877685547,
      "step": 2556
    },
    {
      "epoch": 1.0228,
      "grad_norm": 2.1754963397979736,
      "learning_rate": 6.592e-07,
      "logits/chosen": -2.1093358993530273,
      "logits/rejected": -3.2309975624084473,
      "logps/chosen": -166.55850219726562,
      "logps/rejected": -165.07745361328125,
      "loss": 0.0137,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7121955752372742,
      "rewards/margins": 6.745903015136719,
      "rewards/rejected": -6.033707618713379,
      "step": 2557
    },
    {
      "epoch": 1.0232,
      "grad_norm": 0.06013605371117592,
      "learning_rate": 6.590666666666667e-07,
      "logits/chosen": -2.0975427627563477,
      "logits/rejected": -3.241359233856201,
      "logps/chosen": -136.3177490234375,
      "logps/rejected": -153.59068298339844,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.573809802532196,
      "rewards/margins": 7.620269775390625,
      "rewards/rejected": -7.046460151672363,
      "step": 2558
    },
    {
      "epoch": 1.0236,
      "grad_norm": 0.6614178419113159,
      "learning_rate": 6.589333333333334e-07,
      "logits/chosen": -2.627211570739746,
      "logits/rejected": -2.714275598526001,
      "logps/chosen": -144.30743408203125,
      "logps/rejected": -132.79736328125,
      "loss": 0.0064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2579705715179443,
      "rewards/margins": 7.592106819152832,
      "rewards/rejected": -5.334136009216309,
      "step": 2559
    },
    {
      "epoch": 1.024,
      "grad_norm": 0.3825095295906067,
      "learning_rate": 6.588e-07,
      "logits/chosen": -2.3423943519592285,
      "logits/rejected": -2.9614500999450684,
      "logps/chosen": -73.64085388183594,
      "logps/rejected": -121.38241577148438,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.728950023651123,
      "rewards/margins": 7.10292387008667,
      "rewards/rejected": -4.373973846435547,
      "step": 2560
    },
    {
      "epoch": 1.0244,
      "grad_norm": 0.44569942355155945,
      "learning_rate": 6.586666666666666e-07,
      "logits/chosen": -1.5386059284210205,
      "logits/rejected": -3.0516180992126465,
      "logps/chosen": -102.3912582397461,
      "logps/rejected": -151.3084259033203,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.144960641860962,
      "rewards/margins": 7.0511932373046875,
      "rewards/rejected": -5.906232833862305,
      "step": 2561
    },
    {
      "epoch": 1.0248,
      "grad_norm": 3.75839900970459,
      "learning_rate": 6.585333333333332e-07,
      "logits/chosen": -2.3371567726135254,
      "logits/rejected": -3.4659624099731445,
      "logps/chosen": -89.15232849121094,
      "logps/rejected": -146.1553955078125,
      "loss": 0.0204,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1999772787094116,
      "rewards/margins": 7.505836486816406,
      "rewards/rejected": -6.305859088897705,
      "step": 2562
    },
    {
      "epoch": 1.0252,
      "grad_norm": 0.015877176076173782,
      "learning_rate": 6.583999999999999e-07,
      "logits/chosen": -2.345128059387207,
      "logits/rejected": -3.4299588203430176,
      "logps/chosen": -135.22406005859375,
      "logps/rejected": -174.31491088867188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.703765869140625,
      "rewards/margins": 9.352960586547852,
      "rewards/rejected": -7.649194717407227,
      "step": 2563
    },
    {
      "epoch": 1.0256,
      "grad_norm": 0.05481657758355141,
      "learning_rate": 6.582666666666666e-07,
      "logits/chosen": -2.2504048347473145,
      "logits/rejected": -3.434739828109741,
      "logps/chosen": -170.1231231689453,
      "logps/rejected": -205.74087524414062,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0791221857070923,
      "rewards/margins": 7.854710578918457,
      "rewards/rejected": -6.775588512420654,
      "step": 2564
    },
    {
      "epoch": 1.026,
      "grad_norm": 0.02705271542072296,
      "learning_rate": 6.581333333333333e-07,
      "logits/chosen": -2.1400701999664307,
      "logits/rejected": -3.1595587730407715,
      "logps/chosen": -97.30072784423828,
      "logps/rejected": -169.743408203125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8209731578826904,
      "rewards/margins": 9.377473831176758,
      "rewards/rejected": -6.556500434875488,
      "step": 2565
    },
    {
      "epoch": 1.0264,
      "grad_norm": 0.013274485245347023,
      "learning_rate": 6.58e-07,
      "logits/chosen": -2.3566882610321045,
      "logits/rejected": -3.493563413619995,
      "logps/chosen": -109.2911148071289,
      "logps/rejected": -199.9215850830078,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7231292724609375,
      "rewards/margins": 9.956022262573242,
      "rewards/rejected": -7.2328925132751465,
      "step": 2566
    },
    {
      "epoch": 1.0268,
      "grad_norm": 0.3075287938117981,
      "learning_rate": 6.578666666666667e-07,
      "logits/chosen": -2.389129161834717,
      "logits/rejected": -2.8812427520751953,
      "logps/chosen": -81.10122680664062,
      "logps/rejected": -146.81317138671875,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0526608228683472,
      "rewards/margins": 7.303566932678223,
      "rewards/rejected": -6.250906944274902,
      "step": 2567
    },
    {
      "epoch": 1.0272,
      "grad_norm": 0.0007692768122069538,
      "learning_rate": 6.577333333333333e-07,
      "logits/chosen": -2.0933330059051514,
      "logits/rejected": -3.551774501800537,
      "logps/chosen": -71.42211151123047,
      "logps/rejected": -219.8258514404297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.5134735107421875,
      "rewards/margins": 11.995597839355469,
      "rewards/rejected": -7.482124328613281,
      "step": 2568
    },
    {
      "epoch": 1.0276,
      "grad_norm": 0.4420352280139923,
      "learning_rate": 6.576e-07,
      "logits/chosen": -2.526669502258301,
      "logits/rejected": -3.0800769329071045,
      "logps/chosen": -102.92543029785156,
      "logps/rejected": -141.79798889160156,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9834666848182678,
      "rewards/margins": 7.142996311187744,
      "rewards/rejected": -6.159529685974121,
      "step": 2569
    },
    {
      "epoch": 1.028,
      "grad_norm": 0.11089856177568436,
      "learning_rate": 6.574666666666667e-07,
      "logits/chosen": -1.917898416519165,
      "logits/rejected": -3.755974292755127,
      "logps/chosen": -207.2991943359375,
      "logps/rejected": -150.06991577148438,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.083131790161133,
      "rewards/margins": 8.852849960327148,
      "rewards/rejected": -4.769718647003174,
      "step": 2570
    },
    {
      "epoch": 1.0284,
      "grad_norm": 0.014282668940722942,
      "learning_rate": 6.573333333333333e-07,
      "logits/chosen": -2.3685147762298584,
      "logits/rejected": -3.430959463119507,
      "logps/chosen": -118.49613952636719,
      "logps/rejected": -158.1651611328125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5813374519348145,
      "rewards/margins": 8.861326217651367,
      "rewards/rejected": -6.2799882888793945,
      "step": 2571
    },
    {
      "epoch": 1.0288,
      "grad_norm": 0.013605658896267414,
      "learning_rate": 6.571999999999999e-07,
      "logits/chosen": -2.33876895904541,
      "logits/rejected": -3.6641018390655518,
      "logps/chosen": -186.759033203125,
      "logps/rejected": -150.76473999023438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.697317600250244,
      "rewards/margins": 9.484772682189941,
      "rewards/rejected": -6.787454605102539,
      "step": 2572
    },
    {
      "epoch": 1.0292,
      "grad_norm": 0.02413051202893257,
      "learning_rate": 6.570666666666666e-07,
      "logits/chosen": -2.1582369804382324,
      "logits/rejected": -3.1143441200256348,
      "logps/chosen": -138.29910278320312,
      "logps/rejected": -205.1419219970703,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.079714298248291,
      "rewards/margins": 9.262947082519531,
      "rewards/rejected": -8.183233261108398,
      "step": 2573
    },
    {
      "epoch": 1.0296,
      "grad_norm": 0.002012822311371565,
      "learning_rate": 6.569333333333333e-07,
      "logits/chosen": -2.066213369369507,
      "logits/rejected": -3.400892972946167,
      "logps/chosen": -80.56456756591797,
      "logps/rejected": -195.63421630859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.72880220413208,
      "rewards/margins": 12.020528793334961,
      "rewards/rejected": -8.291726112365723,
      "step": 2574
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.20052163302898407,
      "learning_rate": 6.568e-07,
      "logits/chosen": -2.320166826248169,
      "logits/rejected": -3.124053478240967,
      "logps/chosen": -116.59136962890625,
      "logps/rejected": -161.25509643554688,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.807699203491211,
      "rewards/margins": 8.129983901977539,
      "rewards/rejected": -6.322284698486328,
      "step": 2575
    },
    {
      "epoch": 1.0304,
      "grad_norm": 0.0525798462331295,
      "learning_rate": 6.566666666666666e-07,
      "logits/chosen": -2.7500834465026855,
      "logits/rejected": -3.1576972007751465,
      "logps/chosen": -160.26339721679688,
      "logps/rejected": -169.68045043945312,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2780041694641113,
      "rewards/margins": 8.544425010681152,
      "rewards/rejected": -5.266421318054199,
      "step": 2576
    },
    {
      "epoch": 1.0308,
      "grad_norm": 0.006371655967086554,
      "learning_rate": 6.565333333333333e-07,
      "logits/chosen": -2.33188533782959,
      "logits/rejected": -2.959080219268799,
      "logps/chosen": -194.03712463378906,
      "logps/rejected": -256.5623779296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.684342861175537,
      "rewards/margins": 10.454168319702148,
      "rewards/rejected": -6.7698259353637695,
      "step": 2577
    },
    {
      "epoch": 1.0312,
      "grad_norm": 0.03923521935939789,
      "learning_rate": 6.564e-07,
      "logits/chosen": -2.1001038551330566,
      "logits/rejected": -2.9716014862060547,
      "logps/chosen": -170.4802703857422,
      "logps/rejected": -208.25294494628906,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14597469568252563,
      "rewards/margins": 8.272045135498047,
      "rewards/rejected": -8.126070022583008,
      "step": 2578
    },
    {
      "epoch": 1.0316,
      "grad_norm": 0.939452588558197,
      "learning_rate": 6.562666666666667e-07,
      "logits/chosen": -2.6808319091796875,
      "logits/rejected": -3.115489959716797,
      "logps/chosen": -230.67709350585938,
      "logps/rejected": -159.18869018554688,
      "loss": 0.0068,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.017630100250244,
      "rewards/margins": 7.463477611541748,
      "rewards/rejected": -5.445847511291504,
      "step": 2579
    },
    {
      "epoch": 1.032,
      "grad_norm": 0.008969801478087902,
      "learning_rate": 6.561333333333334e-07,
      "logits/chosen": -2.634754180908203,
      "logits/rejected": -3.0955381393432617,
      "logps/chosen": -75.71676635742188,
      "logps/rejected": -152.63638305664062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.6067681312561035,
      "rewards/margins": 9.980319023132324,
      "rewards/rejected": -5.373550891876221,
      "step": 2580
    },
    {
      "epoch": 1.0324,
      "grad_norm": 0.2027250975370407,
      "learning_rate": 6.56e-07,
      "logits/chosen": -2.2142410278320312,
      "logits/rejected": -3.2207350730895996,
      "logps/chosen": -160.22703552246094,
      "logps/rejected": -147.7168426513672,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4339148998260498,
      "rewards/margins": 8.363186836242676,
      "rewards/rejected": -6.929272174835205,
      "step": 2581
    },
    {
      "epoch": 1.0328,
      "grad_norm": 0.06948352605104446,
      "learning_rate": 6.558666666666666e-07,
      "logits/chosen": -2.164095878601074,
      "logits/rejected": -3.1246986389160156,
      "logps/chosen": -128.6542205810547,
      "logps/rejected": -169.2584228515625,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5964157581329346,
      "rewards/margins": 9.648658752441406,
      "rewards/rejected": -7.052243232727051,
      "step": 2582
    },
    {
      "epoch": 1.0332,
      "grad_norm": 0.004653835203498602,
      "learning_rate": 6.557333333333332e-07,
      "logits/chosen": -2.522237777709961,
      "logits/rejected": -3.160292625427246,
      "logps/chosen": -124.38058471679688,
      "logps/rejected": -169.08822631835938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.965474843978882,
      "rewards/margins": 10.443467140197754,
      "rewards/rejected": -6.477992057800293,
      "step": 2583
    },
    {
      "epoch": 1.0336,
      "grad_norm": 0.6427936553955078,
      "learning_rate": 6.555999999999999e-07,
      "logits/chosen": -1.8367364406585693,
      "logits/rejected": -2.7920563220977783,
      "logps/chosen": -141.9519805908203,
      "logps/rejected": -138.3887939453125,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0534504652023315,
      "rewards/margins": 6.352965354919434,
      "rewards/rejected": -5.299515724182129,
      "step": 2584
    },
    {
      "epoch": 1.034,
      "grad_norm": 0.04782705008983612,
      "learning_rate": 6.554666666666666e-07,
      "logits/chosen": -2.3868513107299805,
      "logits/rejected": -3.009992837905884,
      "logps/chosen": -152.3113555908203,
      "logps/rejected": -168.9256134033203,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9477956295013428,
      "rewards/margins": 9.212607383728027,
      "rewards/rejected": -6.264812469482422,
      "step": 2585
    },
    {
      "epoch": 1.0344,
      "grad_norm": 0.17497380077838898,
      "learning_rate": 6.553333333333333e-07,
      "logits/chosen": -2.4434733390808105,
      "logits/rejected": -3.264582633972168,
      "logps/chosen": -184.74777221679688,
      "logps/rejected": -195.08287048339844,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23221969604492188,
      "rewards/margins": 6.278563499450684,
      "rewards/rejected": -6.046343803405762,
      "step": 2586
    },
    {
      "epoch": 1.0348,
      "grad_norm": 0.1555275171995163,
      "learning_rate": 6.552e-07,
      "logits/chosen": -2.2172365188598633,
      "logits/rejected": -3.217400312423706,
      "logps/chosen": -91.93780517578125,
      "logps/rejected": -194.30224609375,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.651265025138855,
      "rewards/margins": 9.122422218322754,
      "rewards/rejected": -7.471157073974609,
      "step": 2587
    },
    {
      "epoch": 1.0352,
      "grad_norm": 0.03886430710554123,
      "learning_rate": 6.550666666666667e-07,
      "logits/chosen": -2.02436900138855,
      "logits/rejected": -3.1800453662872314,
      "logps/chosen": -178.86024475097656,
      "logps/rejected": -196.9428253173828,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6565582752227783,
      "rewards/margins": 9.126893997192383,
      "rewards/rejected": -7.470335960388184,
      "step": 2588
    },
    {
      "epoch": 1.0356,
      "grad_norm": 9.893245697021484,
      "learning_rate": 6.549333333333334e-07,
      "logits/chosen": -2.3608603477478027,
      "logits/rejected": -2.9276256561279297,
      "logps/chosen": -160.4036865234375,
      "logps/rejected": -157.3076629638672,
      "loss": 0.0755,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13860440254211426,
      "rewards/margins": 6.643935680389404,
      "rewards/rejected": -6.505331039428711,
      "step": 2589
    },
    {
      "epoch": 1.036,
      "grad_norm": 0.02816120535135269,
      "learning_rate": 6.548000000000001e-07,
      "logits/chosen": -1.7027502059936523,
      "logits/rejected": -2.8681318759918213,
      "logps/chosen": -132.24227905273438,
      "logps/rejected": -139.0552978515625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.046720266342163,
      "rewards/margins": 8.43541431427002,
      "rewards/rejected": -6.3886942863464355,
      "step": 2590
    },
    {
      "epoch": 1.0364,
      "grad_norm": 0.14166472852230072,
      "learning_rate": 6.546666666666665e-07,
      "logits/chosen": -1.889697790145874,
      "logits/rejected": -3.311479330062866,
      "logps/chosen": -110.86318969726562,
      "logps/rejected": -158.93605041503906,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6011555194854736,
      "rewards/margins": 8.52477741241455,
      "rewards/rejected": -5.923622131347656,
      "step": 2591
    },
    {
      "epoch": 1.0368,
      "grad_norm": 0.10727772116661072,
      "learning_rate": 6.545333333333332e-07,
      "logits/chosen": -2.646082639694214,
      "logits/rejected": -3.1796011924743652,
      "logps/chosen": -148.01254272460938,
      "logps/rejected": -169.87863159179688,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2035255432128906,
      "rewards/margins": 6.9497294425964355,
      "rewards/rejected": -5.746203422546387,
      "step": 2592
    },
    {
      "epoch": 1.0372,
      "grad_norm": 2.2479500770568848,
      "learning_rate": 6.543999999999999e-07,
      "logits/chosen": -2.232658624649048,
      "logits/rejected": -2.9508872032165527,
      "logps/chosen": -153.00946044921875,
      "logps/rejected": -137.4505615234375,
      "loss": 0.0159,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8849518299102783,
      "rewards/margins": 6.305395126342773,
      "rewards/rejected": -4.420443534851074,
      "step": 2593
    },
    {
      "epoch": 1.0376,
      "grad_norm": 0.0229971781373024,
      "learning_rate": 6.542666666666666e-07,
      "logits/chosen": -2.093611717224121,
      "logits/rejected": -2.9308090209960938,
      "logps/chosen": -124.38150787353516,
      "logps/rejected": -183.95663452148438,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3476860523223877,
      "rewards/margins": 8.469212532043457,
      "rewards/rejected": -5.121526718139648,
      "step": 2594
    },
    {
      "epoch": 1.038,
      "grad_norm": 0.0023587297182530165,
      "learning_rate": 6.541333333333333e-07,
      "logits/chosen": -2.456015110015869,
      "logits/rejected": -2.61285400390625,
      "logps/chosen": -126.91795349121094,
      "logps/rejected": -193.57296752929688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.998726844787598,
      "rewards/margins": 11.982479095458984,
      "rewards/rejected": -6.983752250671387,
      "step": 2595
    },
    {
      "epoch": 1.0384,
      "grad_norm": 0.0018673083977773786,
      "learning_rate": 6.54e-07,
      "logits/chosen": -2.0597524642944336,
      "logits/rejected": -3.036050319671631,
      "logps/chosen": -144.2418670654297,
      "logps/rejected": -159.1171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.434477806091309,
      "rewards/margins": 11.00533676147461,
      "rewards/rejected": -6.570858478546143,
      "step": 2596
    },
    {
      "epoch": 1.0388,
      "grad_norm": 0.004402360878884792,
      "learning_rate": 6.538666666666667e-07,
      "logits/chosen": -2.1278512477874756,
      "logits/rejected": -3.2312698364257812,
      "logps/chosen": -155.77078247070312,
      "logps/rejected": -221.95208740234375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2212433815002441,
      "rewards/margins": 10.92447280883789,
      "rewards/rejected": -9.703229904174805,
      "step": 2597
    },
    {
      "epoch": 1.0392,
      "grad_norm": 0.0353936031460762,
      "learning_rate": 6.537333333333334e-07,
      "logits/chosen": -2.3432350158691406,
      "logits/rejected": -3.0321297645568848,
      "logps/chosen": -233.57174682617188,
      "logps/rejected": -225.7249755859375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8892433643341064,
      "rewards/margins": 8.846908569335938,
      "rewards/rejected": -6.957664489746094,
      "step": 2598
    },
    {
      "epoch": 1.0396,
      "grad_norm": 0.7021445035934448,
      "learning_rate": 6.536e-07,
      "logits/chosen": -2.0557355880737305,
      "logits/rejected": -2.4697837829589844,
      "logps/chosen": -79.07905578613281,
      "logps/rejected": -130.72601318359375,
      "loss": 0.0061,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5990104675292969,
      "rewards/margins": 7.22292423248291,
      "rewards/rejected": -5.623913288116455,
      "step": 2599
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.07027889788150787,
      "learning_rate": 6.534666666666666e-07,
      "logits/chosen": -2.3146886825561523,
      "logits/rejected": -3.2812538146972656,
      "logps/chosen": -158.9566650390625,
      "logps/rejected": -204.0404815673828,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.154317617416382,
      "rewards/margins": 9.66706657409668,
      "rewards/rejected": -6.512748718261719,
      "step": 2600
    },
    {
      "epoch": 1.0404,
      "grad_norm": 0.08431239426136017,
      "learning_rate": 6.533333333333333e-07,
      "logits/chosen": -1.8148088455200195,
      "logits/rejected": -3.18959903717041,
      "logps/chosen": -73.27713012695312,
      "logps/rejected": -134.7212371826172,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.452002763748169,
      "rewards/margins": 7.992652416229248,
      "rewards/rejected": -5.5406494140625,
      "step": 2601
    },
    {
      "epoch": 1.0408,
      "grad_norm": 0.015042969956994057,
      "learning_rate": 6.531999999999999e-07,
      "logits/chosen": -2.326918601989746,
      "logits/rejected": -2.989854097366333,
      "logps/chosen": -165.46951293945312,
      "logps/rejected": -190.83078002929688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.525489091873169,
      "rewards/margins": 8.885412216186523,
      "rewards/rejected": -6.359923362731934,
      "step": 2602
    },
    {
      "epoch": 1.0412,
      "grad_norm": 0.04578924924135208,
      "learning_rate": 6.530666666666666e-07,
      "logits/chosen": -2.1005935668945312,
      "logits/rejected": -2.9075770378112793,
      "logps/chosen": -95.03278350830078,
      "logps/rejected": -134.12628173828125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.820138931274414,
      "rewards/margins": 8.863324165344238,
      "rewards/rejected": -6.043184757232666,
      "step": 2603
    },
    {
      "epoch": 1.0416,
      "grad_norm": 40.94157028198242,
      "learning_rate": 6.529333333333333e-07,
      "logits/chosen": -2.4182329177856445,
      "logits/rejected": -3.453629732131958,
      "logps/chosen": -191.04727172851562,
      "logps/rejected": -137.31478881835938,
      "loss": 0.3323,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3519914150238037,
      "rewards/margins": 4.65657901763916,
      "rewards/rejected": -5.008570194244385,
      "step": 2604
    },
    {
      "epoch": 1.042,
      "grad_norm": 0.42728567123413086,
      "learning_rate": 6.528e-07,
      "logits/chosen": -2.522953748703003,
      "logits/rejected": -2.853262424468994,
      "logps/chosen": -179.127197265625,
      "logps/rejected": -179.60757446289062,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.425485372543335,
      "rewards/margins": 5.70128059387207,
      "rewards/rejected": -4.2757954597473145,
      "step": 2605
    },
    {
      "epoch": 1.0424,
      "grad_norm": 0.005012812092900276,
      "learning_rate": 6.526666666666666e-07,
      "logits/chosen": -2.4280316829681396,
      "logits/rejected": -3.465406656265259,
      "logps/chosen": -190.04437255859375,
      "logps/rejected": -189.6729736328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0956039428710938,
      "rewards/margins": 10.106698989868164,
      "rewards/rejected": -8.01109504699707,
      "step": 2606
    },
    {
      "epoch": 1.0428,
      "grad_norm": 0.01389149110764265,
      "learning_rate": 6.525333333333333e-07,
      "logits/chosen": -2.244417190551758,
      "logits/rejected": -3.7460992336273193,
      "logps/chosen": -155.0369873046875,
      "logps/rejected": -167.79037475585938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3850016593933105,
      "rewards/margins": 9.66843032836914,
      "rewards/rejected": -6.28342866897583,
      "step": 2607
    },
    {
      "epoch": 1.0432,
      "grad_norm": 0.11276187002658844,
      "learning_rate": 6.524e-07,
      "logits/chosen": -2.9294989109039307,
      "logits/rejected": -3.455624580383301,
      "logps/chosen": -119.63066101074219,
      "logps/rejected": -159.71603393554688,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.656341791152954,
      "rewards/margins": 8.738630294799805,
      "rewards/rejected": -6.08228874206543,
      "step": 2608
    },
    {
      "epoch": 1.0436,
      "grad_norm": 0.006087373476475477,
      "learning_rate": 6.522666666666667e-07,
      "logits/chosen": -2.10563063621521,
      "logits/rejected": -2.8966565132141113,
      "logps/chosen": -98.2001953125,
      "logps/rejected": -171.40895080566406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.232449531555176,
      "rewards/margins": 10.931676864624023,
      "rewards/rejected": -6.699227809906006,
      "step": 2609
    },
    {
      "epoch": 1.044,
      "grad_norm": 0.05177432671189308,
      "learning_rate": 6.521333333333333e-07,
      "logits/chosen": -1.9558377265930176,
      "logits/rejected": -3.489513874053955,
      "logps/chosen": -91.71920776367188,
      "logps/rejected": -186.25009155273438,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1038265228271484,
      "rewards/margins": 7.624998569488525,
      "rewards/rejected": -6.521172523498535,
      "step": 2610
    },
    {
      "epoch": 1.0444,
      "grad_norm": 0.00552833266556263,
      "learning_rate": 6.52e-07,
      "logits/chosen": -2.3146002292633057,
      "logits/rejected": -3.4385275840759277,
      "logps/chosen": -114.89637756347656,
      "logps/rejected": -185.93670654296875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5987064838409424,
      "rewards/margins": 9.747515678405762,
      "rewards/rejected": -6.148809432983398,
      "step": 2611
    },
    {
      "epoch": 1.0448,
      "grad_norm": 0.2286565899848938,
      "learning_rate": 6.518666666666667e-07,
      "logits/chosen": -1.92710280418396,
      "logits/rejected": -2.301718235015869,
      "logps/chosen": -146.66664123535156,
      "logps/rejected": -126.45813751220703,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.6329426765441895,
      "rewards/margins": 8.751017570495605,
      "rewards/rejected": -4.118074893951416,
      "step": 2612
    },
    {
      "epoch": 1.0452,
      "grad_norm": 0.021534651517868042,
      "learning_rate": 6.517333333333333e-07,
      "logits/chosen": -2.246065616607666,
      "logits/rejected": -2.498743772506714,
      "logps/chosen": -135.58168029785156,
      "logps/rejected": -142.681396484375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.32801628112793,
      "rewards/margins": 9.251959800720215,
      "rewards/rejected": -4.923943519592285,
      "step": 2613
    },
    {
      "epoch": 1.0456,
      "grad_norm": 0.19302520155906677,
      "learning_rate": 6.515999999999999e-07,
      "logits/chosen": -2.2269768714904785,
      "logits/rejected": -3.175719738006592,
      "logps/chosen": -122.9290542602539,
      "logps/rejected": -169.20884704589844,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2912232875823975,
      "rewards/margins": 9.282398223876953,
      "rewards/rejected": -5.991175651550293,
      "step": 2614
    },
    {
      "epoch": 1.046,
      "grad_norm": 0.012698015198111534,
      "learning_rate": 6.514666666666666e-07,
      "logits/chosen": -1.9446195363998413,
      "logits/rejected": -3.3158068656921387,
      "logps/chosen": -92.72147369384766,
      "logps/rejected": -155.44830322265625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6784846782684326,
      "rewards/margins": 9.08800220489502,
      "rewards/rejected": -7.409517288208008,
      "step": 2615
    },
    {
      "epoch": 1.0464,
      "grad_norm": 0.007336730137467384,
      "learning_rate": 6.513333333333333e-07,
      "logits/chosen": -1.9157521724700928,
      "logits/rejected": -3.3512659072875977,
      "logps/chosen": -80.83145141601562,
      "logps/rejected": -160.40240478515625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4936509132385254,
      "rewards/margins": 9.341506958007812,
      "rewards/rejected": -6.847856521606445,
      "step": 2616
    },
    {
      "epoch": 1.0468,
      "grad_norm": 0.0050982097163796425,
      "learning_rate": 6.512e-07,
      "logits/chosen": -2.2242727279663086,
      "logits/rejected": -3.454432487487793,
      "logps/chosen": -92.70965576171875,
      "logps/rejected": -193.54257202148438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.366481781005859,
      "rewards/margins": 10.868595123291016,
      "rewards/rejected": -6.502114295959473,
      "step": 2617
    },
    {
      "epoch": 1.0472,
      "grad_norm": 0.03275403007864952,
      "learning_rate": 6.510666666666667e-07,
      "logits/chosen": -2.1476709842681885,
      "logits/rejected": -2.939539670944214,
      "logps/chosen": -151.15060424804688,
      "logps/rejected": -175.54306030273438,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7294015884399414,
      "rewards/margins": 7.940029144287109,
      "rewards/rejected": -5.210627555847168,
      "step": 2618
    },
    {
      "epoch": 1.0476,
      "grad_norm": 0.059638675302267075,
      "learning_rate": 6.509333333333333e-07,
      "logits/chosen": -2.3157098293304443,
      "logits/rejected": -3.5412845611572266,
      "logps/chosen": -69.67345428466797,
      "logps/rejected": -141.48382568359375,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9938526153564453,
      "rewards/margins": 8.589754104614258,
      "rewards/rejected": -5.5959014892578125,
      "step": 2619
    },
    {
      "epoch": 1.048,
      "grad_norm": 0.5914106965065002,
      "learning_rate": 6.508e-07,
      "logits/chosen": -2.5031399726867676,
      "logits/rejected": -3.321272373199463,
      "logps/chosen": -173.47621154785156,
      "logps/rejected": -190.03970336914062,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1031899452209473,
      "rewards/margins": 8.270132064819336,
      "rewards/rejected": -6.1669416427612305,
      "step": 2620
    },
    {
      "epoch": 1.0484,
      "grad_norm": 0.3597434461116791,
      "learning_rate": 6.506666666666666e-07,
      "logits/chosen": -2.9049293994903564,
      "logits/rejected": -3.417557954788208,
      "logps/chosen": -183.0703125,
      "logps/rejected": -161.44015502929688,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9617271423339844,
      "rewards/margins": 7.909462928771973,
      "rewards/rejected": -5.9477362632751465,
      "step": 2621
    },
    {
      "epoch": 1.0488,
      "grad_norm": 0.196946918964386,
      "learning_rate": 6.505333333333333e-07,
      "logits/chosen": -2.4904990196228027,
      "logits/rejected": -3.34257173538208,
      "logps/chosen": -109.50482177734375,
      "logps/rejected": -159.17550659179688,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0069265365600586,
      "rewards/margins": 8.217613220214844,
      "rewards/rejected": -6.210686683654785,
      "step": 2622
    },
    {
      "epoch": 1.0492,
      "grad_norm": 0.3734596371650696,
      "learning_rate": 6.504e-07,
      "logits/chosen": -1.6311787366867065,
      "logits/rejected": -3.484234094619751,
      "logps/chosen": -109.21865844726562,
      "logps/rejected": -221.4643096923828,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2684948146343231,
      "rewards/margins": 8.381060600280762,
      "rewards/rejected": -8.649556159973145,
      "step": 2623
    },
    {
      "epoch": 1.0496,
      "grad_norm": 0.009077600203454494,
      "learning_rate": 6.502666666666666e-07,
      "logits/chosen": -2.098285675048828,
      "logits/rejected": -2.807610034942627,
      "logps/chosen": -74.54902648925781,
      "logps/rejected": -137.49664306640625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.12794828414917,
      "rewards/margins": 9.223465919494629,
      "rewards/rejected": -6.095517158508301,
      "step": 2624
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.08868397772312164,
      "learning_rate": 6.501333333333333e-07,
      "logits/chosen": -2.680124282836914,
      "logits/rejected": -4.011038780212402,
      "logps/chosen": -176.14886474609375,
      "logps/rejected": -184.83047485351562,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.657379150390625,
      "rewards/margins": 7.7045512199401855,
      "rewards/rejected": -5.0471720695495605,
      "step": 2625
    },
    {
      "epoch": 1.0504,
      "grad_norm": 0.6635952591896057,
      "learning_rate": 6.5e-07,
      "logits/chosen": -2.7424168586730957,
      "logits/rejected": -3.5838632583618164,
      "logps/chosen": -151.0400390625,
      "logps/rejected": -243.28126525878906,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6964553594589233,
      "rewards/margins": 7.491443157196045,
      "rewards/rejected": -5.794987678527832,
      "step": 2626
    },
    {
      "epoch": 1.0508,
      "grad_norm": 0.05249002203345299,
      "learning_rate": 6.498666666666667e-07,
      "logits/chosen": -2.022799015045166,
      "logits/rejected": -3.3400869369506836,
      "logps/chosen": -93.570068359375,
      "logps/rejected": -160.88873291015625,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.635438919067383,
      "rewards/margins": 8.033002853393555,
      "rewards/rejected": -5.397563934326172,
      "step": 2627
    },
    {
      "epoch": 1.0512,
      "grad_norm": 0.02947615645825863,
      "learning_rate": 6.497333333333334e-07,
      "logits/chosen": -2.723970890045166,
      "logits/rejected": -3.520711898803711,
      "logps/chosen": -228.73641967773438,
      "logps/rejected": -191.4386749267578,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0758888721466064,
      "rewards/margins": 10.30238151550293,
      "rewards/rejected": -7.226492881774902,
      "step": 2628
    },
    {
      "epoch": 1.0516,
      "grad_norm": 1.6527891159057617,
      "learning_rate": 6.495999999999999e-07,
      "logits/chosen": -2.2545270919799805,
      "logits/rejected": -3.0433807373046875,
      "logps/chosen": -81.23046875,
      "logps/rejected": -123.31217956542969,
      "loss": 0.013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7089987993240356,
      "rewards/margins": 6.6276092529296875,
      "rewards/rejected": -4.918610572814941,
      "step": 2629
    },
    {
      "epoch": 1.052,
      "grad_norm": 0.005276028532534838,
      "learning_rate": 6.494666666666666e-07,
      "logits/chosen": -1.9662882089614868,
      "logits/rejected": -3.2213234901428223,
      "logps/chosen": -113.06610870361328,
      "logps/rejected": -180.001220703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.988528251647949,
      "rewards/margins": 10.37470531463623,
      "rewards/rejected": -6.386177062988281,
      "step": 2630
    },
    {
      "epoch": 1.0524,
      "grad_norm": 0.5149880051612854,
      "learning_rate": 6.493333333333333e-07,
      "logits/chosen": -2.414560317993164,
      "logits/rejected": -3.313532829284668,
      "logps/chosen": -128.7408905029297,
      "logps/rejected": -149.86105346679688,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0986099243164062,
      "rewards/margins": 7.805624961853027,
      "rewards/rejected": -6.707015037536621,
      "step": 2631
    },
    {
      "epoch": 1.0528,
      "grad_norm": 0.09405627846717834,
      "learning_rate": 6.492e-07,
      "logits/chosen": -1.9302799701690674,
      "logits/rejected": -3.4944028854370117,
      "logps/chosen": -143.43209838867188,
      "logps/rejected": -137.15989685058594,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8853187561035156,
      "rewards/margins": 6.905081748962402,
      "rewards/rejected": -5.019762992858887,
      "step": 2632
    },
    {
      "epoch": 1.0532,
      "grad_norm": 0.025573639199137688,
      "learning_rate": 6.490666666666667e-07,
      "logits/chosen": -2.1020126342773438,
      "logits/rejected": -2.939911127090454,
      "logps/chosen": -48.154998779296875,
      "logps/rejected": -126.84606170654297,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5928359031677246,
      "rewards/margins": 8.376984596252441,
      "rewards/rejected": -4.784148693084717,
      "step": 2633
    },
    {
      "epoch": 1.0536,
      "grad_norm": 0.07142160087823868,
      "learning_rate": 6.489333333333333e-07,
      "logits/chosen": -1.8714919090270996,
      "logits/rejected": -2.9995341300964355,
      "logps/chosen": -149.75613403320312,
      "logps/rejected": -154.22735595703125,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5472831726074219,
      "rewards/margins": 6.9839982986450195,
      "rewards/rejected": -6.436715126037598,
      "step": 2634
    },
    {
      "epoch": 1.054,
      "grad_norm": 0.0012942564208060503,
      "learning_rate": 6.488e-07,
      "logits/chosen": -2.073373317718506,
      "logits/rejected": -3.3919143676757812,
      "logps/chosen": -115.79438781738281,
      "logps/rejected": -181.30169677734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8756918907165527,
      "rewards/margins": 11.210363388061523,
      "rewards/rejected": -7.334671974182129,
      "step": 2635
    },
    {
      "epoch": 1.0544,
      "grad_norm": 0.011517681181430817,
      "learning_rate": 6.486666666666666e-07,
      "logits/chosen": -2.0563602447509766,
      "logits/rejected": -2.9137332439422607,
      "logps/chosen": -67.8915786743164,
      "logps/rejected": -141.43760681152344,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.203164577484131,
      "rewards/margins": 9.162073135375977,
      "rewards/rejected": -5.958909034729004,
      "step": 2636
    },
    {
      "epoch": 1.0548,
      "grad_norm": 0.0015978546580299735,
      "learning_rate": 6.485333333333333e-07,
      "logits/chosen": -2.2277889251708984,
      "logits/rejected": -3.425358295440674,
      "logps/chosen": -156.96414184570312,
      "logps/rejected": -182.69415283203125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.783944606781006,
      "rewards/margins": 11.529905319213867,
      "rewards/rejected": -8.74596118927002,
      "step": 2637
    },
    {
      "epoch": 1.0552,
      "grad_norm": 0.030748696997761726,
      "learning_rate": 6.483999999999999e-07,
      "logits/chosen": -1.9571279287338257,
      "logits/rejected": -3.611715078353882,
      "logps/chosen": -78.84776306152344,
      "logps/rejected": -163.2278594970703,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6703481674194336,
      "rewards/margins": 8.24606704711914,
      "rewards/rejected": -5.575719833374023,
      "step": 2638
    },
    {
      "epoch": 1.0556,
      "grad_norm": 0.2833224833011627,
      "learning_rate": 6.482666666666666e-07,
      "logits/chosen": -2.4887866973876953,
      "logits/rejected": -3.0683019161224365,
      "logps/chosen": -127.02815246582031,
      "logps/rejected": -143.68270874023438,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.19849930703639984,
      "rewards/margins": 5.950752258300781,
      "rewards/rejected": -6.149251461029053,
      "step": 2639
    },
    {
      "epoch": 1.056,
      "grad_norm": 0.744920015335083,
      "learning_rate": 6.481333333333333e-07,
      "logits/chosen": -2.18046236038208,
      "logits/rejected": -3.0906901359558105,
      "logps/chosen": -163.7802734375,
      "logps/rejected": -130.01190185546875,
      "loss": 0.0081,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2580841779708862,
      "rewards/margins": 6.089229583740234,
      "rewards/rejected": -4.831145286560059,
      "step": 2640
    },
    {
      "epoch": 1.0564,
      "grad_norm": 0.0034264069981873035,
      "learning_rate": 6.48e-07,
      "logits/chosen": -2.3510589599609375,
      "logits/rejected": -3.7101564407348633,
      "logps/chosen": -158.28562927246094,
      "logps/rejected": -198.50973510742188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.38051700592041,
      "rewards/margins": 10.56100082397461,
      "rewards/rejected": -6.180483341217041,
      "step": 2641
    },
    {
      "epoch": 1.0568,
      "grad_norm": 0.034752871841192245,
      "learning_rate": 6.478666666666667e-07,
      "logits/chosen": -1.72958505153656,
      "logits/rejected": -3.1083149909973145,
      "logps/chosen": -79.99173736572266,
      "logps/rejected": -154.52511596679688,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9977516531944275,
      "rewards/margins": 7.873529434204102,
      "rewards/rejected": -6.8757781982421875,
      "step": 2642
    },
    {
      "epoch": 1.0572,
      "grad_norm": 0.03037697821855545,
      "learning_rate": 6.477333333333334e-07,
      "logits/chosen": -2.4329142570495605,
      "logits/rejected": -2.890458106994629,
      "logps/chosen": -143.2111053466797,
      "logps/rejected": -170.3748016357422,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3543379306793213,
      "rewards/margins": 9.675529479980469,
      "rewards/rejected": -6.32119083404541,
      "step": 2643
    },
    {
      "epoch": 1.0576,
      "grad_norm": 0.029107259586453438,
      "learning_rate": 6.476e-07,
      "logits/chosen": -1.876055359840393,
      "logits/rejected": -3.224025249481201,
      "logps/chosen": -63.50868606567383,
      "logps/rejected": -152.61624145507812,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.004526138305664,
      "rewards/margins": 8.120569229125977,
      "rewards/rejected": -5.1160430908203125,
      "step": 2644
    },
    {
      "epoch": 1.058,
      "grad_norm": 0.018012387678027153,
      "learning_rate": 6.474666666666666e-07,
      "logits/chosen": -2.6040170192718506,
      "logits/rejected": -3.533432960510254,
      "logps/chosen": -155.86985778808594,
      "logps/rejected": -176.98269653320312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4204907417297363,
      "rewards/margins": 9.186644554138184,
      "rewards/rejected": -5.766153812408447,
      "step": 2645
    },
    {
      "epoch": 1.0584,
      "grad_norm": 0.1977434903383255,
      "learning_rate": 6.473333333333333e-07,
      "logits/chosen": -2.062502384185791,
      "logits/rejected": -2.8221933841705322,
      "logps/chosen": -118.49368286132812,
      "logps/rejected": -227.3194580078125,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0408942699432373,
      "rewards/margins": 8.493596076965332,
      "rewards/rejected": -6.452701568603516,
      "step": 2646
    },
    {
      "epoch": 1.0588,
      "grad_norm": 0.08956989645957947,
      "learning_rate": 6.471999999999999e-07,
      "logits/chosen": -2.2667434215545654,
      "logits/rejected": -2.2047648429870605,
      "logps/chosen": -112.40646362304688,
      "logps/rejected": -131.13644409179688,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2159507274627686,
      "rewards/margins": 7.316625595092773,
      "rewards/rejected": -5.100675106048584,
      "step": 2647
    },
    {
      "epoch": 1.0592,
      "grad_norm": 0.9567580223083496,
      "learning_rate": 6.470666666666666e-07,
      "logits/chosen": -1.9098753929138184,
      "logits/rejected": -3.1443817615509033,
      "logps/chosen": -116.86128234863281,
      "logps/rejected": -153.0358123779297,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6672782301902771,
      "rewards/margins": 6.847386360168457,
      "rewards/rejected": -6.180108070373535,
      "step": 2648
    },
    {
      "epoch": 1.0596,
      "grad_norm": 0.06403347849845886,
      "learning_rate": 6.469333333333333e-07,
      "logits/chosen": -2.5423498153686523,
      "logits/rejected": -2.4128713607788086,
      "logps/chosen": -194.49090576171875,
      "logps/rejected": -159.80555725097656,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.519998073577881,
      "rewards/margins": 7.699269771575928,
      "rewards/rejected": -5.179271697998047,
      "step": 2649
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.41696175932884216,
      "learning_rate": 6.468e-07,
      "logits/chosen": -1.7281162738800049,
      "logits/rejected": -2.104266881942749,
      "logps/chosen": -96.56122589111328,
      "logps/rejected": -108.84707641601562,
      "loss": 0.0064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3968193531036377,
      "rewards/margins": 6.884442329406738,
      "rewards/rejected": -3.4876232147216797,
      "step": 2650
    },
    {
      "epoch": 1.0604,
      "grad_norm": 0.12468956410884857,
      "learning_rate": 6.466666666666666e-07,
      "logits/chosen": -2.502786636352539,
      "logits/rejected": -2.7944393157958984,
      "logps/chosen": -224.10179138183594,
      "logps/rejected": -201.1591796875,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6342365145683289,
      "rewards/margins": 9.011087417602539,
      "rewards/rejected": -8.376850128173828,
      "step": 2651
    },
    {
      "epoch": 1.0608,
      "grad_norm": 0.07178090512752533,
      "learning_rate": 6.465333333333333e-07,
      "logits/chosen": -1.9974849224090576,
      "logits/rejected": -3.463627576828003,
      "logps/chosen": -151.92138671875,
      "logps/rejected": -174.32861328125,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.336551308631897,
      "rewards/margins": 7.3661699295043945,
      "rewards/rejected": -6.029618263244629,
      "step": 2652
    },
    {
      "epoch": 1.0612,
      "grad_norm": 0.0009710115846246481,
      "learning_rate": 6.464e-07,
      "logits/chosen": -2.3336374759674072,
      "logits/rejected": -3.9845781326293945,
      "logps/chosen": -95.18241882324219,
      "logps/rejected": -238.68588256835938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.833468437194824,
      "rewards/margins": 12.164226531982422,
      "rewards/rejected": -9.330759048461914,
      "step": 2653
    },
    {
      "epoch": 1.0616,
      "grad_norm": 0.014124205335974693,
      "learning_rate": 6.462666666666667e-07,
      "logits/chosen": -2.4534027576446533,
      "logits/rejected": -2.722503662109375,
      "logps/chosen": -175.1049346923828,
      "logps/rejected": -176.31524658203125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.683319091796875,
      "rewards/margins": 9.479998588562012,
      "rewards/rejected": -7.796679496765137,
      "step": 2654
    },
    {
      "epoch": 1.062,
      "grad_norm": 0.2502341866493225,
      "learning_rate": 6.461333333333333e-07,
      "logits/chosen": -1.7657966613769531,
      "logits/rejected": -3.5768418312072754,
      "logps/chosen": -113.45038604736328,
      "logps/rejected": -170.7038116455078,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2652145326137543,
      "rewards/margins": 6.522548675537109,
      "rewards/rejected": -6.7877631187438965,
      "step": 2655
    },
    {
      "epoch": 1.0624,
      "grad_norm": 1.8053834438323975,
      "learning_rate": 6.46e-07,
      "logits/chosen": -2.1634438037872314,
      "logits/rejected": -3.1327433586120605,
      "logps/chosen": -106.72042083740234,
      "logps/rejected": -140.47930908203125,
      "loss": 0.0159,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5428546667098999,
      "rewards/margins": 5.738384246826172,
      "rewards/rejected": -5.195529937744141,
      "step": 2656
    },
    {
      "epoch": 1.0628,
      "grad_norm": 0.04952074587345123,
      "learning_rate": 6.458666666666666e-07,
      "logits/chosen": -2.094496250152588,
      "logits/rejected": -2.971766471862793,
      "logps/chosen": -76.05046081542969,
      "logps/rejected": -149.3309326171875,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9201760292053223,
      "rewards/margins": 8.495047569274902,
      "rewards/rejected": -6.57487154006958,
      "step": 2657
    },
    {
      "epoch": 1.0632,
      "grad_norm": 0.020329710096120834,
      "learning_rate": 6.457333333333333e-07,
      "logits/chosen": -1.856365442276001,
      "logits/rejected": -3.531686305999756,
      "logps/chosen": -102.43551635742188,
      "logps/rejected": -143.76931762695312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.926532745361328,
      "rewards/margins": 8.75061321258545,
      "rewards/rejected": -5.824080467224121,
      "step": 2658
    },
    {
      "epoch": 1.0636,
      "grad_norm": 0.04745175316929817,
      "learning_rate": 6.455999999999999e-07,
      "logits/chosen": -1.902457356452942,
      "logits/rejected": -2.7607035636901855,
      "logps/chosen": -86.8377685546875,
      "logps/rejected": -131.65191650390625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2776951789855957,
      "rewards/margins": 7.875473976135254,
      "rewards/rejected": -5.597779273986816,
      "step": 2659
    },
    {
      "epoch": 1.064,
      "grad_norm": 2.6103482246398926,
      "learning_rate": 6.454666666666666e-07,
      "logits/chosen": -2.384129047393799,
      "logits/rejected": -2.62593936920166,
      "logps/chosen": -107.57803344726562,
      "logps/rejected": -202.20559692382812,
      "loss": 0.0157,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7482402920722961,
      "rewards/margins": 5.400345325469971,
      "rewards/rejected": -4.65210485458374,
      "step": 2660
    },
    {
      "epoch": 1.0644,
      "grad_norm": 0.09114678204059601,
      "learning_rate": 6.453333333333333e-07,
      "logits/chosen": -2.306579351425171,
      "logits/rejected": -3.142062187194824,
      "logps/chosen": -133.45013427734375,
      "logps/rejected": -157.09393310546875,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.401193380355835,
      "rewards/margins": 8.701098442077637,
      "rewards/rejected": -5.299904823303223,
      "step": 2661
    },
    {
      "epoch": 1.0648,
      "grad_norm": 0.01998990587890148,
      "learning_rate": 6.452e-07,
      "logits/chosen": -2.108051300048828,
      "logits/rejected": -3.8209619522094727,
      "logps/chosen": -168.91336059570312,
      "logps/rejected": -189.97982788085938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0552055835723877,
      "rewards/margins": 9.861827850341797,
      "rewards/rejected": -6.80662202835083,
      "step": 2662
    },
    {
      "epoch": 1.0652,
      "grad_norm": 0.007447931915521622,
      "learning_rate": 6.450666666666667e-07,
      "logits/chosen": -1.8929129838943481,
      "logits/rejected": -3.072026014328003,
      "logps/chosen": -117.04664611816406,
      "logps/rejected": -253.881103515625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6383492946624756,
      "rewards/margins": 10.293065071105957,
      "rewards/rejected": -6.654715538024902,
      "step": 2663
    },
    {
      "epoch": 1.0656,
      "grad_norm": 0.06295540183782578,
      "learning_rate": 6.449333333333334e-07,
      "logits/chosen": -2.250854015350342,
      "logits/rejected": -2.57806658744812,
      "logps/chosen": -120.642578125,
      "logps/rejected": -149.53713989257812,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.885596752166748,
      "rewards/margins": 7.560603141784668,
      "rewards/rejected": -4.675005912780762,
      "step": 2664
    },
    {
      "epoch": 1.066,
      "grad_norm": 0.01113238837569952,
      "learning_rate": 6.448000000000001e-07,
      "logits/chosen": -2.132534980773926,
      "logits/rejected": -3.0075812339782715,
      "logps/chosen": -108.53727722167969,
      "logps/rejected": -167.5701904296875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1892178058624268,
      "rewards/margins": 9.684022903442383,
      "rewards/rejected": -6.494805335998535,
      "step": 2665
    },
    {
      "epoch": 1.0664,
      "grad_norm": 0.0021113792899996042,
      "learning_rate": 6.446666666666666e-07,
      "logits/chosen": -2.6414999961853027,
      "logits/rejected": -3.0162830352783203,
      "logps/chosen": -154.8292236328125,
      "logps/rejected": -223.22377014160156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.395002841949463,
      "rewards/margins": 10.977747917175293,
      "rewards/rejected": -6.582744598388672,
      "step": 2666
    },
    {
      "epoch": 1.0668,
      "grad_norm": 0.1290624886751175,
      "learning_rate": 6.445333333333332e-07,
      "logits/chosen": -1.8430397510528564,
      "logits/rejected": -2.913649559020996,
      "logps/chosen": -137.87661743164062,
      "logps/rejected": -154.05313110351562,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.27699613571167,
      "rewards/margins": 6.937933921813965,
      "rewards/rejected": -3.660937547683716,
      "step": 2667
    },
    {
      "epoch": 1.0672,
      "grad_norm": 0.006986526306718588,
      "learning_rate": 6.443999999999999e-07,
      "logits/chosen": -2.2799859046936035,
      "logits/rejected": -3.6794919967651367,
      "logps/chosen": -129.8345184326172,
      "logps/rejected": -164.88973999023438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3458619117736816,
      "rewards/margins": 9.862472534179688,
      "rewards/rejected": -6.516610145568848,
      "step": 2668
    },
    {
      "epoch": 1.0676,
      "grad_norm": 0.029185911640524864,
      "learning_rate": 6.442666666666666e-07,
      "logits/chosen": -2.308288097381592,
      "logits/rejected": -3.4705700874328613,
      "logps/chosen": -88.80583190917969,
      "logps/rejected": -156.51022338867188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3951256275177,
      "rewards/margins": 8.688321113586426,
      "rewards/rejected": -5.293195724487305,
      "step": 2669
    },
    {
      "epoch": 1.068,
      "grad_norm": 0.05102694779634476,
      "learning_rate": 6.441333333333333e-07,
      "logits/chosen": -2.101015090942383,
      "logits/rejected": -3.232776165008545,
      "logps/chosen": -98.81266784667969,
      "logps/rejected": -164.7450714111328,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.873730182647705,
      "rewards/margins": 8.649492263793945,
      "rewards/rejected": -6.775762557983398,
      "step": 2670
    },
    {
      "epoch": 1.0684,
      "grad_norm": 0.03091954067349434,
      "learning_rate": 6.44e-07,
      "logits/chosen": -2.37600040435791,
      "logits/rejected": -3.2479629516601562,
      "logps/chosen": -115.80488586425781,
      "logps/rejected": -137.11256408691406,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.467453956604004,
      "rewards/margins": 7.982367992401123,
      "rewards/rejected": -5.514914035797119,
      "step": 2671
    },
    {
      "epoch": 1.0688,
      "grad_norm": 0.032287221401929855,
      "learning_rate": 6.438666666666667e-07,
      "logits/chosen": -2.244518280029297,
      "logits/rejected": -4.0152740478515625,
      "logps/chosen": -126.3108901977539,
      "logps/rejected": -157.7253875732422,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7550854086875916,
      "rewards/margins": 8.31295108795166,
      "rewards/rejected": -7.557865142822266,
      "step": 2672
    },
    {
      "epoch": 1.0692,
      "grad_norm": 0.26053866744041443,
      "learning_rate": 6.437333333333334e-07,
      "logits/chosen": -2.31667160987854,
      "logits/rejected": -3.8027377128601074,
      "logps/chosen": -183.14813232421875,
      "logps/rejected": -176.93421936035156,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5370712280273438,
      "rewards/margins": 6.108639240264893,
      "rewards/rejected": -6.645710468292236,
      "step": 2673
    },
    {
      "epoch": 1.0695999999999999,
      "grad_norm": 0.012379859574139118,
      "learning_rate": 6.436e-07,
      "logits/chosen": -1.999112844467163,
      "logits/rejected": -3.040454626083374,
      "logps/chosen": -115.48184204101562,
      "logps/rejected": -147.27874755859375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.957113027572632,
      "rewards/margins": 11.497053146362305,
      "rewards/rejected": -7.5399394035339355,
      "step": 2674
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.02189825102686882,
      "learning_rate": 6.434666666666666e-07,
      "logits/chosen": -2.3128621578216553,
      "logits/rejected": -3.260389804840088,
      "logps/chosen": -98.39093017578125,
      "logps/rejected": -173.84860229492188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0558598041534424,
      "rewards/margins": 8.661823272705078,
      "rewards/rejected": -6.605962753295898,
      "step": 2675
    },
    {
      "epoch": 1.0704,
      "grad_norm": 0.004095087293535471,
      "learning_rate": 6.433333333333332e-07,
      "logits/chosen": -2.457550287246704,
      "logits/rejected": -3.2529025077819824,
      "logps/chosen": -100.51962280273438,
      "logps/rejected": -176.29544067382812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7220187187194824,
      "rewards/margins": 10.45290756225586,
      "rewards/rejected": -6.730888366699219,
      "step": 2676
    },
    {
      "epoch": 1.0708,
      "grad_norm": 0.36542433500289917,
      "learning_rate": 6.431999999999999e-07,
      "logits/chosen": -2.1053967475891113,
      "logits/rejected": -3.0197386741638184,
      "logps/chosen": -140.91250610351562,
      "logps/rejected": -142.68797302246094,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5803534984588623,
      "rewards/margins": 7.800868511199951,
      "rewards/rejected": -6.22051477432251,
      "step": 2677
    },
    {
      "epoch": 1.0712,
      "grad_norm": 0.055825479328632355,
      "learning_rate": 6.430666666666666e-07,
      "logits/chosen": -1.948285698890686,
      "logits/rejected": -3.413543224334717,
      "logps/chosen": -126.5978012084961,
      "logps/rejected": -177.06101989746094,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0409328937530518,
      "rewards/margins": 9.036486625671387,
      "rewards/rejected": -6.995553493499756,
      "step": 2678
    },
    {
      "epoch": 1.0716,
      "grad_norm": 0.1980498731136322,
      "learning_rate": 6.429333333333333e-07,
      "logits/chosen": -2.472047805786133,
      "logits/rejected": -2.990060329437256,
      "logps/chosen": -128.24969482421875,
      "logps/rejected": -139.64437866210938,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7248170375823975,
      "rewards/margins": 7.459524154663086,
      "rewards/rejected": -5.734706878662109,
      "step": 2679
    },
    {
      "epoch": 1.072,
      "grad_norm": 0.009649651125073433,
      "learning_rate": 6.428e-07,
      "logits/chosen": -2.397663116455078,
      "logits/rejected": -3.00986385345459,
      "logps/chosen": -189.26910400390625,
      "logps/rejected": -188.59353637695312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8625473976135254,
      "rewards/margins": 10.662821769714355,
      "rewards/rejected": -6.800274848937988,
      "step": 2680
    },
    {
      "epoch": 1.0724,
      "grad_norm": 0.149980828166008,
      "learning_rate": 6.426666666666667e-07,
      "logits/chosen": -2.2313525676727295,
      "logits/rejected": -3.111513614654541,
      "logps/chosen": -92.14314270019531,
      "logps/rejected": -215.9168243408203,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9279887676239014,
      "rewards/margins": 8.030866622924805,
      "rewards/rejected": -6.102878093719482,
      "step": 2681
    },
    {
      "epoch": 1.0728,
      "grad_norm": 0.057821180671453476,
      "learning_rate": 6.425333333333333e-07,
      "logits/chosen": -2.2157647609710693,
      "logits/rejected": -2.4713516235351562,
      "logps/chosen": -87.12448120117188,
      "logps/rejected": -159.47836303710938,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.306140899658203,
      "rewards/margins": 7.9499406814575195,
      "rewards/rejected": -5.643799781799316,
      "step": 2682
    },
    {
      "epoch": 1.0732,
      "grad_norm": 0.03560701757669449,
      "learning_rate": 6.424e-07,
      "logits/chosen": -2.59773325920105,
      "logits/rejected": -2.7886857986450195,
      "logps/chosen": -96.05613708496094,
      "logps/rejected": -160.1386260986328,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.014526844024658,
      "rewards/margins": 8.308818817138672,
      "rewards/rejected": -6.294291973114014,
      "step": 2683
    },
    {
      "epoch": 1.0735999999999999,
      "grad_norm": 0.0423005148768425,
      "learning_rate": 6.422666666666667e-07,
      "logits/chosen": -2.740067481994629,
      "logits/rejected": -3.6049563884735107,
      "logps/chosen": -169.79051208496094,
      "logps/rejected": -173.53280639648438,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.108245849609375,
      "rewards/margins": 9.152837753295898,
      "rewards/rejected": -7.044591426849365,
      "step": 2684
    },
    {
      "epoch": 1.074,
      "grad_norm": 0.06310749799013138,
      "learning_rate": 6.421333333333333e-07,
      "logits/chosen": -2.2164840698242188,
      "logits/rejected": -3.402587413787842,
      "logps/chosen": -147.6459503173828,
      "logps/rejected": -174.1744384765625,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7303895950317383,
      "rewards/margins": 8.154587745666504,
      "rewards/rejected": -5.424198150634766,
      "step": 2685
    },
    {
      "epoch": 1.0744,
      "grad_norm": 3.779676914215088,
      "learning_rate": 6.42e-07,
      "logits/chosen": -2.66286301612854,
      "logits/rejected": -3.2493104934692383,
      "logps/chosen": -136.59872436523438,
      "logps/rejected": -147.656494140625,
      "loss": 0.0298,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8455696105957031,
      "rewards/margins": 7.358457565307617,
      "rewards/rejected": -5.512887954711914,
      "step": 2686
    },
    {
      "epoch": 1.0748,
      "grad_norm": 0.023044664412736893,
      "learning_rate": 6.418666666666666e-07,
      "logits/chosen": -1.9319907426834106,
      "logits/rejected": -3.439131736755371,
      "logps/chosen": -127.49763488769531,
      "logps/rejected": -166.96487426757812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.606626272201538,
      "rewards/margins": 9.64098072052002,
      "rewards/rejected": -7.034354209899902,
      "step": 2687
    },
    {
      "epoch": 1.0752,
      "grad_norm": 0.017911117523908615,
      "learning_rate": 6.417333333333333e-07,
      "logits/chosen": -1.935713291168213,
      "logits/rejected": -2.572972059249878,
      "logps/chosen": -98.41421508789062,
      "logps/rejected": -146.69789123535156,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4440150260925293,
      "rewards/margins": 9.244214057922363,
      "rewards/rejected": -6.800199031829834,
      "step": 2688
    },
    {
      "epoch": 1.0756000000000001,
      "grad_norm": 0.09161496162414551,
      "learning_rate": 6.415999999999999e-07,
      "logits/chosen": -2.5166585445404053,
      "logits/rejected": -3.3774824142456055,
      "logps/chosen": -178.07754516601562,
      "logps/rejected": -174.79444885253906,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.511010766029358,
      "rewards/margins": 8.240507125854492,
      "rewards/rejected": -6.729496479034424,
      "step": 2689
    },
    {
      "epoch": 1.076,
      "grad_norm": 0.16811342537403107,
      "learning_rate": 6.414666666666666e-07,
      "logits/chosen": -1.6928377151489258,
      "logits/rejected": -3.6268787384033203,
      "logps/chosen": -108.21641540527344,
      "logps/rejected": -133.94058227539062,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.047696352005005,
      "rewards/margins": 6.949734687805176,
      "rewards/rejected": -4.90203857421875,
      "step": 2690
    },
    {
      "epoch": 1.0764,
      "grad_norm": 0.004219327121973038,
      "learning_rate": 6.413333333333333e-07,
      "logits/chosen": -2.2241525650024414,
      "logits/rejected": -3.6494674682617188,
      "logps/chosen": -119.84587097167969,
      "logps/rejected": -170.76626586914062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.446073532104492,
      "rewards/margins": 9.95550537109375,
      "rewards/rejected": -6.509431838989258,
      "step": 2691
    },
    {
      "epoch": 1.0768,
      "grad_norm": 0.08362880349159241,
      "learning_rate": 6.412e-07,
      "logits/chosen": -2.3710427284240723,
      "logits/rejected": -3.0114166736602783,
      "logps/chosen": -73.74567413330078,
      "logps/rejected": -187.44964599609375,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.011221408843994,
      "rewards/margins": 10.06329345703125,
      "rewards/rejected": -6.052072525024414,
      "step": 2692
    },
    {
      "epoch": 1.0772,
      "grad_norm": 0.39165061712265015,
      "learning_rate": 6.410666666666667e-07,
      "logits/chosen": -2.4181814193725586,
      "logits/rejected": -3.8702425956726074,
      "logps/chosen": -135.55795288085938,
      "logps/rejected": -166.50930786132812,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.299499750137329,
      "rewards/margins": 8.009791374206543,
      "rewards/rejected": -5.710291385650635,
      "step": 2693
    },
    {
      "epoch": 1.0776,
      "grad_norm": 0.1912027895450592,
      "learning_rate": 6.409333333333333e-07,
      "logits/chosen": -2.012911796569824,
      "logits/rejected": -3.4220728874206543,
      "logps/chosen": -165.22439575195312,
      "logps/rejected": -158.53013610839844,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.98772132396698,
      "rewards/margins": 9.327669143676758,
      "rewards/rejected": -7.339947700500488,
      "step": 2694
    },
    {
      "epoch": 1.078,
      "grad_norm": 0.4312976896762848,
      "learning_rate": 6.408e-07,
      "logits/chosen": -3.2926602363586426,
      "logits/rejected": -3.616572856903076,
      "logps/chosen": -164.91384887695312,
      "logps/rejected": -173.91665649414062,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5691124200820923,
      "rewards/margins": 5.905590057373047,
      "rewards/rejected": -7.474702835083008,
      "step": 2695
    },
    {
      "epoch": 1.0784,
      "grad_norm": 0.0075149210169911385,
      "learning_rate": 6.406666666666667e-07,
      "logits/chosen": -1.8087327480316162,
      "logits/rejected": -2.856661319732666,
      "logps/chosen": -109.78306579589844,
      "logps/rejected": -275.76373291015625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.54514217376709,
      "rewards/margins": 9.815581321716309,
      "rewards/rejected": -7.270439147949219,
      "step": 2696
    },
    {
      "epoch": 1.0788,
      "grad_norm": 0.6221234202384949,
      "learning_rate": 6.405333333333332e-07,
      "logits/chosen": -2.1442360877990723,
      "logits/rejected": -3.5055532455444336,
      "logps/chosen": -109.86638641357422,
      "logps/rejected": -183.2199249267578,
      "loss": 0.0052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5100440979003906,
      "rewards/margins": 6.579015731811523,
      "rewards/rejected": -6.068971633911133,
      "step": 2697
    },
    {
      "epoch": 1.0792,
      "grad_norm": 0.09070009738206863,
      "learning_rate": 6.403999999999999e-07,
      "logits/chosen": -2.4851832389831543,
      "logits/rejected": -3.192049026489258,
      "logps/chosen": -173.90293884277344,
      "logps/rejected": -152.9800567626953,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0432076454162598,
      "rewards/margins": 7.356055736541748,
      "rewards/rejected": -6.312848091125488,
      "step": 2698
    },
    {
      "epoch": 1.0796000000000001,
      "grad_norm": 5.207770347595215,
      "learning_rate": 6.402666666666666e-07,
      "logits/chosen": -3.198681354522705,
      "logits/rejected": -3.307086229324341,
      "logps/chosen": -216.4462432861328,
      "logps/rejected": -235.25558471679688,
      "loss": 0.0197,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1368942260742188,
      "rewards/margins": 6.634903430938721,
      "rewards/rejected": -5.498008728027344,
      "step": 2699
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.020748721435666084,
      "learning_rate": 6.401333333333333e-07,
      "logits/chosen": -2.397559642791748,
      "logits/rejected": -2.653750419616699,
      "logps/chosen": -116.6026840209961,
      "logps/rejected": -167.91677856445312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4229824542999268,
      "rewards/margins": 8.95701789855957,
      "rewards/rejected": -6.5340352058410645,
      "step": 2700
    },
    {
      "epoch": 1.0804,
      "grad_norm": 0.1530815213918686,
      "learning_rate": 6.4e-07,
      "logits/chosen": -2.5300955772399902,
      "logits/rejected": -2.854379653930664,
      "logps/chosen": -252.93603515625,
      "logps/rejected": -141.82171630859375,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6362144947052002,
      "rewards/margins": 7.493668556213379,
      "rewards/rejected": -5.857454299926758,
      "step": 2701
    },
    {
      "epoch": 1.0808,
      "grad_norm": 0.03440951928496361,
      "learning_rate": 6.398666666666667e-07,
      "logits/chosen": -2.249385118484497,
      "logits/rejected": -2.693910598754883,
      "logps/chosen": -85.81281280517578,
      "logps/rejected": -131.43869018554688,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6568799018859863,
      "rewards/margins": 8.218123435974121,
      "rewards/rejected": -4.561243057250977,
      "step": 2702
    },
    {
      "epoch": 1.0812,
      "grad_norm": 0.05360809713602066,
      "learning_rate": 6.397333333333334e-07,
      "logits/chosen": -2.5091001987457275,
      "logits/rejected": -2.630281925201416,
      "logps/chosen": -203.41207885742188,
      "logps/rejected": -165.63148498535156,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.585542678833008,
      "rewards/margins": 8.098605155944824,
      "rewards/rejected": -5.513062477111816,
      "step": 2703
    },
    {
      "epoch": 1.0816,
      "grad_norm": 0.11856017261743546,
      "learning_rate": 6.395999999999999e-07,
      "logits/chosen": -1.4589234590530396,
      "logits/rejected": -3.1707088947296143,
      "logps/chosen": -86.90716552734375,
      "logps/rejected": -127.82581329345703,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.108691930770874,
      "rewards/margins": 6.768426418304443,
      "rewards/rejected": -4.659734725952148,
      "step": 2704
    },
    {
      "epoch": 1.082,
      "grad_norm": 0.007193656172603369,
      "learning_rate": 6.394666666666666e-07,
      "logits/chosen": -2.1960649490356445,
      "logits/rejected": -2.9748103618621826,
      "logps/chosen": -130.82833862304688,
      "logps/rejected": -142.67701721191406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.923150062561035,
      "rewards/margins": 9.721761703491211,
      "rewards/rejected": -4.798611640930176,
      "step": 2705
    },
    {
      "epoch": 1.0824,
      "grad_norm": 0.011771976947784424,
      "learning_rate": 6.393333333333333e-07,
      "logits/chosen": -2.5842838287353516,
      "logits/rejected": -3.477810859680176,
      "logps/chosen": -117.10291290283203,
      "logps/rejected": -167.49856567382812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0137276649475098,
      "rewards/margins": 9.315935134887695,
      "rewards/rejected": -6.302207946777344,
      "step": 2706
    },
    {
      "epoch": 1.0828,
      "grad_norm": 0.05041410028934479,
      "learning_rate": 6.392e-07,
      "logits/chosen": -1.8636558055877686,
      "logits/rejected": -2.805109977722168,
      "logps/chosen": -105.34680938720703,
      "logps/rejected": -129.78819274902344,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8253135681152344,
      "rewards/margins": 7.934354782104492,
      "rewards/rejected": -5.109041213989258,
      "step": 2707
    },
    {
      "epoch": 1.0832,
      "grad_norm": 0.16903407871723175,
      "learning_rate": 6.390666666666666e-07,
      "logits/chosen": -2.1351242065429688,
      "logits/rejected": -2.88153076171875,
      "logps/chosen": -119.97540283203125,
      "logps/rejected": -142.48081970214844,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9103920459747314,
      "rewards/margins": 7.84424352645874,
      "rewards/rejected": -4.93385124206543,
      "step": 2708
    },
    {
      "epoch": 1.0836,
      "grad_norm": 0.864510715007782,
      "learning_rate": 6.389333333333333e-07,
      "logits/chosen": -1.9326841831207275,
      "logits/rejected": -2.4946441650390625,
      "logps/chosen": -91.40264892578125,
      "logps/rejected": -124.64949035644531,
      "loss": 0.0089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.546621322631836,
      "rewards/margins": 6.344905853271484,
      "rewards/rejected": -4.798284530639648,
      "step": 2709
    },
    {
      "epoch": 1.084,
      "grad_norm": 0.07769516855478287,
      "learning_rate": 6.388e-07,
      "logits/chosen": -1.8407559394836426,
      "logits/rejected": -3.356947422027588,
      "logps/chosen": -124.50166320800781,
      "logps/rejected": -172.85777282714844,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6690658926963806,
      "rewards/margins": 7.34323787689209,
      "rewards/rejected": -6.6741719245910645,
      "step": 2710
    },
    {
      "epoch": 1.0844,
      "grad_norm": 0.19839370250701904,
      "learning_rate": 6.386666666666667e-07,
      "logits/chosen": -2.267993450164795,
      "logits/rejected": -3.459639549255371,
      "logps/chosen": -181.14486694335938,
      "logps/rejected": -179.42724609375,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45116347074508667,
      "rewards/margins": 6.26628303527832,
      "rewards/rejected": -5.815119743347168,
      "step": 2711
    },
    {
      "epoch": 1.0848,
      "grad_norm": 0.0011898118536919355,
      "learning_rate": 6.385333333333333e-07,
      "logits/chosen": -2.2029600143432617,
      "logits/rejected": -3.8023252487182617,
      "logps/chosen": -125.88682556152344,
      "logps/rejected": -257.2483215332031,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5333409309387207,
      "rewards/margins": 12.135307312011719,
      "rewards/rejected": -9.60196590423584,
      "step": 2712
    },
    {
      "epoch": 1.0852,
      "grad_norm": 0.06719960272312164,
      "learning_rate": 6.383999999999999e-07,
      "logits/chosen": -2.247356414794922,
      "logits/rejected": -3.4796934127807617,
      "logps/chosen": -129.5424041748047,
      "logps/rejected": -212.65806579589844,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0522679090499878,
      "rewards/margins": 8.108467102050781,
      "rewards/rejected": -7.056199073791504,
      "step": 2713
    },
    {
      "epoch": 1.0856,
      "grad_norm": 0.014898966066539288,
      "learning_rate": 6.382666666666666e-07,
      "logits/chosen": -2.3848819732666016,
      "logits/rejected": -3.9233789443969727,
      "logps/chosen": -167.82586669921875,
      "logps/rejected": -171.9541778564453,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.174742221832275,
      "rewards/margins": 9.096450805664062,
      "rewards/rejected": -4.921709060668945,
      "step": 2714
    },
    {
      "epoch": 1.086,
      "grad_norm": 0.009252910502254963,
      "learning_rate": 6.381333333333333e-07,
      "logits/chosen": -2.279900074005127,
      "logits/rejected": -2.8449816703796387,
      "logps/chosen": -222.80418395996094,
      "logps/rejected": -174.3933563232422,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4854938983917236,
      "rewards/margins": 9.414928436279297,
      "rewards/rejected": -5.929434299468994,
      "step": 2715
    },
    {
      "epoch": 1.0864,
      "grad_norm": 0.029854875057935715,
      "learning_rate": 6.38e-07,
      "logits/chosen": -1.9597258567810059,
      "logits/rejected": -3.192430019378662,
      "logps/chosen": -105.82534790039062,
      "logps/rejected": -289.8694763183594,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1781582832336426,
      "rewards/margins": 9.042158126831055,
      "rewards/rejected": -5.863999843597412,
      "step": 2716
    },
    {
      "epoch": 1.0868,
      "grad_norm": 0.029039300978183746,
      "learning_rate": 6.378666666666667e-07,
      "logits/chosen": -2.114211082458496,
      "logits/rejected": -3.1075878143310547,
      "logps/chosen": -117.09113311767578,
      "logps/rejected": -175.33551025390625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.566737651824951,
      "rewards/margins": 7.947055816650391,
      "rewards/rejected": -5.380317687988281,
      "step": 2717
    },
    {
      "epoch": 1.0872,
      "grad_norm": 0.4521695077419281,
      "learning_rate": 6.377333333333334e-07,
      "logits/chosen": -2.2539477348327637,
      "logits/rejected": -3.01511287689209,
      "logps/chosen": -106.04925537109375,
      "logps/rejected": -146.66107177734375,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.15277671813964844,
      "rewards/margins": 5.552797317504883,
      "rewards/rejected": -5.705574035644531,
      "step": 2718
    },
    {
      "epoch": 1.0876,
      "grad_norm": 0.043266184628009796,
      "learning_rate": 6.375999999999999e-07,
      "logits/chosen": -2.0143496990203857,
      "logits/rejected": -3.2960095405578613,
      "logps/chosen": -95.58690643310547,
      "logps/rejected": -147.90814208984375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.132822036743164,
      "rewards/margins": 8.933218002319336,
      "rewards/rejected": -6.800395488739014,
      "step": 2719
    },
    {
      "epoch": 1.088,
      "grad_norm": 0.021051250398159027,
      "learning_rate": 6.374666666666666e-07,
      "logits/chosen": -1.6176882982254028,
      "logits/rejected": -3.3194756507873535,
      "logps/chosen": -127.11964416503906,
      "logps/rejected": -164.167236328125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8104019165039062,
      "rewards/margins": 9.656883239746094,
      "rewards/rejected": -6.846480846405029,
      "step": 2720
    },
    {
      "epoch": 1.0884,
      "grad_norm": 0.04259384796023369,
      "learning_rate": 6.373333333333333e-07,
      "logits/chosen": -2.2788901329040527,
      "logits/rejected": -3.252436637878418,
      "logps/chosen": -93.94867706298828,
      "logps/rejected": -173.3567352294922,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0954270362854004,
      "rewards/margins": 7.978628158569336,
      "rewards/rejected": -5.8832011222839355,
      "step": 2721
    },
    {
      "epoch": 1.0888,
      "grad_norm": 0.32704320549964905,
      "learning_rate": 6.371999999999999e-07,
      "logits/chosen": -2.3302559852600098,
      "logits/rejected": -2.7069578170776367,
      "logps/chosen": -145.91531372070312,
      "logps/rejected": -160.53846740722656,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.577751636505127,
      "rewards/margins": 8.289766311645508,
      "rewards/rejected": -5.712015151977539,
      "step": 2722
    },
    {
      "epoch": 1.0892,
      "grad_norm": 0.025272957980632782,
      "learning_rate": 6.370666666666666e-07,
      "logits/chosen": -2.275066614151001,
      "logits/rejected": -3.1841917037963867,
      "logps/chosen": -131.20297241210938,
      "logps/rejected": -169.53822326660156,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2182955741882324,
      "rewards/margins": 8.661218643188477,
      "rewards/rejected": -5.442923545837402,
      "step": 2723
    },
    {
      "epoch": 1.0896,
      "grad_norm": 1.321032166481018,
      "learning_rate": 6.369333333333333e-07,
      "logits/chosen": -2.6860995292663574,
      "logits/rejected": -2.9560816287994385,
      "logps/chosen": -213.76925659179688,
      "logps/rejected": -223.93869018554688,
      "loss": 0.0074,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.284426212310791,
      "rewards/margins": 8.017078399658203,
      "rewards/rejected": -6.732651710510254,
      "step": 2724
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.02125934697687626,
      "learning_rate": 6.368e-07,
      "logits/chosen": -2.2322051525115967,
      "logits/rejected": -3.358332633972168,
      "logps/chosen": -89.65264892578125,
      "logps/rejected": -173.80238342285156,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.788405656814575,
      "rewards/margins": 9.342109680175781,
      "rewards/rejected": -6.553704261779785,
      "step": 2725
    },
    {
      "epoch": 1.0904,
      "grad_norm": 0.060328591614961624,
      "learning_rate": 6.366666666666667e-07,
      "logits/chosen": -2.0995781421661377,
      "logits/rejected": -3.0531973838806152,
      "logps/chosen": -91.02464294433594,
      "logps/rejected": -139.4560089111328,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.478605270385742,
      "rewards/margins": 9.926843643188477,
      "rewards/rejected": -6.448238372802734,
      "step": 2726
    },
    {
      "epoch": 1.0908,
      "grad_norm": 6.557313442230225,
      "learning_rate": 6.365333333333333e-07,
      "logits/chosen": -2.6354918479919434,
      "logits/rejected": -3.097796678543091,
      "logps/chosen": -228.13653564453125,
      "logps/rejected": -201.93240356445312,
      "loss": 0.0445,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.570263385772705,
      "rewards/margins": 4.272545337677002,
      "rewards/rejected": -5.842808723449707,
      "step": 2727
    },
    {
      "epoch": 1.0912,
      "grad_norm": 1.2029287815093994,
      "learning_rate": 6.364e-07,
      "logits/chosen": -2.403007984161377,
      "logits/rejected": -3.204348087310791,
      "logps/chosen": -191.75714111328125,
      "logps/rejected": -144.4737548828125,
      "loss": 0.0074,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6147063970565796,
      "rewards/margins": 5.965019226074219,
      "rewards/rejected": -5.350312232971191,
      "step": 2728
    },
    {
      "epoch": 1.0916,
      "grad_norm": 0.3683824837207794,
      "learning_rate": 6.362666666666666e-07,
      "logits/chosen": -2.0952494144439697,
      "logits/rejected": -2.9454498291015625,
      "logps/chosen": -125.71311950683594,
      "logps/rejected": -110.55224609375,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8574512004852295,
      "rewards/margins": 5.43940544128418,
      "rewards/rejected": -3.581954002380371,
      "step": 2729
    },
    {
      "epoch": 1.092,
      "grad_norm": 0.12715090811252594,
      "learning_rate": 6.361333333333333e-07,
      "logits/chosen": -2.529448986053467,
      "logits/rejected": -3.036245107650757,
      "logps/chosen": -144.0711212158203,
      "logps/rejected": -157.9254150390625,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0589451789855957,
      "rewards/margins": 7.114429473876953,
      "rewards/rejected": -5.055484771728516,
      "step": 2730
    },
    {
      "epoch": 1.0924,
      "grad_norm": 0.05175701528787613,
      "learning_rate": 6.36e-07,
      "logits/chosen": -1.7972347736358643,
      "logits/rejected": -3.0922412872314453,
      "logps/chosen": -102.39301300048828,
      "logps/rejected": -158.13296508789062,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1613231748342514,
      "rewards/margins": 7.6282548904418945,
      "rewards/rejected": -7.4669318199157715,
      "step": 2731
    },
    {
      "epoch": 1.0928,
      "grad_norm": 0.014681034721434116,
      "learning_rate": 6.358666666666666e-07,
      "logits/chosen": -1.8641867637634277,
      "logits/rejected": -3.2084767818450928,
      "logps/chosen": -183.2911376953125,
      "logps/rejected": -184.8353729248047,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.752742290496826,
      "rewards/margins": 9.569304466247559,
      "rewards/rejected": -6.816562652587891,
      "step": 2732
    },
    {
      "epoch": 1.0932,
      "grad_norm": 0.005025308579206467,
      "learning_rate": 6.357333333333333e-07,
      "logits/chosen": -2.066164016723633,
      "logits/rejected": -3.198472023010254,
      "logps/chosen": -171.95449829101562,
      "logps/rejected": -171.52439880371094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.414710521697998,
      "rewards/margins": 10.414511680603027,
      "rewards/rejected": -5.999800682067871,
      "step": 2733
    },
    {
      "epoch": 1.0936,
      "grad_norm": 0.003037809394299984,
      "learning_rate": 6.356e-07,
      "logits/chosen": -2.2239835262298584,
      "logits/rejected": -3.659003257751465,
      "logps/chosen": -126.90681457519531,
      "logps/rejected": -194.03184509277344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2706117630004883,
      "rewards/margins": 10.515586853027344,
      "rewards/rejected": -8.244975090026855,
      "step": 2734
    },
    {
      "epoch": 1.094,
      "grad_norm": 0.5243169069290161,
      "learning_rate": 6.354666666666666e-07,
      "logits/chosen": -2.5017342567443848,
      "logits/rejected": -2.899881362915039,
      "logps/chosen": -203.494140625,
      "logps/rejected": -161.08555603027344,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6400226950645447,
      "rewards/margins": 6.326963424682617,
      "rewards/rejected": -5.6869401931762695,
      "step": 2735
    },
    {
      "epoch": 1.0944,
      "grad_norm": 13.588157653808594,
      "learning_rate": 6.353333333333333e-07,
      "logits/chosen": -1.9101613759994507,
      "logits/rejected": -2.5810117721557617,
      "logps/chosen": -114.12053680419922,
      "logps/rejected": -141.05126953125,
      "loss": 0.0548,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.349376678466797,
      "rewards/margins": 6.6775102615356445,
      "rewards/rejected": -4.328133583068848,
      "step": 2736
    },
    {
      "epoch": 1.0948,
      "grad_norm": 0.13186810910701752,
      "learning_rate": 6.352e-07,
      "logits/chosen": -2.7724342346191406,
      "logits/rejected": -3.0611519813537598,
      "logps/chosen": -235.92279052734375,
      "logps/rejected": -201.20199584960938,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.259647399187088,
      "rewards/margins": 6.941714286804199,
      "rewards/rejected": -6.682066917419434,
      "step": 2737
    },
    {
      "epoch": 1.0952,
      "grad_norm": 1.4650598764419556,
      "learning_rate": 6.350666666666667e-07,
      "logits/chosen": -1.6381747722625732,
      "logits/rejected": -3.279273271560669,
      "logps/chosen": -106.95130157470703,
      "logps/rejected": -156.47341918945312,
      "loss": 0.0146,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5486751794815063,
      "rewards/margins": 6.856813907623291,
      "rewards/rejected": -5.308138847351074,
      "step": 2738
    },
    {
      "epoch": 1.0956,
      "grad_norm": 6.750699520111084,
      "learning_rate": 6.349333333333334e-07,
      "logits/chosen": -1.7767448425292969,
      "logits/rejected": -2.9264683723449707,
      "logps/chosen": -160.75982666015625,
      "logps/rejected": -158.90850830078125,
      "loss": 0.0483,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.05734330415725708,
      "rewards/margins": 4.384500503540039,
      "rewards/rejected": -4.441843509674072,
      "step": 2739
    },
    {
      "epoch": 1.096,
      "grad_norm": 0.16845914721488953,
      "learning_rate": 6.348e-07,
      "logits/chosen": -1.8625491857528687,
      "logits/rejected": -3.2910423278808594,
      "logps/chosen": -99.73597717285156,
      "logps/rejected": -193.37689208984375,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.95758056640625,
      "rewards/margins": 9.338172912597656,
      "rewards/rejected": -7.3805928230285645,
      "step": 2740
    },
    {
      "epoch": 1.0964,
      "grad_norm": 0.0510588102042675,
      "learning_rate": 6.346666666666666e-07,
      "logits/chosen": -2.2818961143493652,
      "logits/rejected": -2.5685038566589355,
      "logps/chosen": -151.21810913085938,
      "logps/rejected": -151.44049072265625,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.241780996322632,
      "rewards/margins": 7.653515815734863,
      "rewards/rejected": -5.4117350578308105,
      "step": 2741
    },
    {
      "epoch": 1.0968,
      "grad_norm": 0.11693919450044632,
      "learning_rate": 6.345333333333332e-07,
      "logits/chosen": -2.1320724487304688,
      "logits/rejected": -3.2031099796295166,
      "logps/chosen": -155.64016723632812,
      "logps/rejected": -201.98477172851562,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2391884326934814,
      "rewards/margins": 9.614952087402344,
      "rewards/rejected": -7.375763893127441,
      "step": 2742
    },
    {
      "epoch": 1.0972,
      "grad_norm": 0.023112520575523376,
      "learning_rate": 6.343999999999999e-07,
      "logits/chosen": -1.7278612852096558,
      "logits/rejected": -2.448723316192627,
      "logps/chosen": -89.0423583984375,
      "logps/rejected": -130.66473388671875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5558152198791504,
      "rewards/margins": 8.465729713439941,
      "rewards/rejected": -5.909914493560791,
      "step": 2743
    },
    {
      "epoch": 1.0976,
      "grad_norm": 0.0822421982884407,
      "learning_rate": 6.342666666666666e-07,
      "logits/chosen": -1.9637486934661865,
      "logits/rejected": -2.7366995811462402,
      "logps/chosen": -81.81658935546875,
      "logps/rejected": -119.20238494873047,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0509305000305176,
      "rewards/margins": 6.933426856994629,
      "rewards/rejected": -4.882496356964111,
      "step": 2744
    },
    {
      "epoch": 1.098,
      "grad_norm": 0.028357386589050293,
      "learning_rate": 6.341333333333333e-07,
      "logits/chosen": -2.1286134719848633,
      "logits/rejected": -3.552492618560791,
      "logps/chosen": -131.45045471191406,
      "logps/rejected": -171.40618896484375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.378014087677002,
      "rewards/margins": 8.086352348327637,
      "rewards/rejected": -6.708338260650635,
      "step": 2745
    },
    {
      "epoch": 1.0984,
      "grad_norm": 0.2390771210193634,
      "learning_rate": 6.34e-07,
      "logits/chosen": -1.9984149932861328,
      "logits/rejected": -3.005075454711914,
      "logps/chosen": -117.35981750488281,
      "logps/rejected": -218.3675994873047,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2888526916503906,
      "rewards/margins": 6.114737510681152,
      "rewards/rejected": -6.403590202331543,
      "step": 2746
    },
    {
      "epoch": 1.0988,
      "grad_norm": 0.01061679795384407,
      "learning_rate": 6.338666666666667e-07,
      "logits/chosen": -2.8979434967041016,
      "logits/rejected": -3.1323866844177246,
      "logps/chosen": -185.818603515625,
      "logps/rejected": -196.89491271972656,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.914214611053467,
      "rewards/margins": 10.45160961151123,
      "rewards/rejected": -7.537395000457764,
      "step": 2747
    },
    {
      "epoch": 1.0992,
      "grad_norm": 0.019445674493908882,
      "learning_rate": 6.337333333333334e-07,
      "logits/chosen": -2.320598840713501,
      "logits/rejected": -3.0858120918273926,
      "logps/chosen": -111.47811889648438,
      "logps/rejected": -178.59991455078125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.328040361404419,
      "rewards/margins": 9.46877670288086,
      "rewards/rejected": -6.140736103057861,
      "step": 2748
    },
    {
      "epoch": 1.0996,
      "grad_norm": 0.06132464483380318,
      "learning_rate": 6.336000000000001e-07,
      "logits/chosen": -1.9171266555786133,
      "logits/rejected": -3.8104913234710693,
      "logps/chosen": -134.16799926757812,
      "logps/rejected": -152.505126953125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5810160636901855,
      "rewards/margins": 7.753671646118164,
      "rewards/rejected": -6.17265510559082,
      "step": 2749
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.014303624629974365,
      "learning_rate": 6.334666666666665e-07,
      "logits/chosen": -2.154104709625244,
      "logits/rejected": -2.639815330505371,
      "logps/chosen": -127.69338989257812,
      "logps/rejected": -218.6562957763672,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0884883403778076,
      "rewards/margins": 10.03812026977539,
      "rewards/rejected": -6.94963264465332,
      "step": 2750
    },
    {
      "epoch": 1.1004,
      "grad_norm": 0.14181697368621826,
      "learning_rate": 6.333333333333332e-07,
      "logits/chosen": -2.254647731781006,
      "logits/rejected": -2.441189765930176,
      "logps/chosen": -122.44755554199219,
      "logps/rejected": -135.0537109375,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.63520085811615,
      "rewards/margins": 6.70255708694458,
      "rewards/rejected": -5.067356109619141,
      "step": 2751
    },
    {
      "epoch": 1.1008,
      "grad_norm": 0.04442429915070534,
      "learning_rate": 6.331999999999999e-07,
      "logits/chosen": -2.1536436080932617,
      "logits/rejected": -2.536208391189575,
      "logps/chosen": -108.935791015625,
      "logps/rejected": -141.59730529785156,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.47220611572265625,
      "rewards/margins": 7.412054538726807,
      "rewards/rejected": -6.93984842300415,
      "step": 2752
    },
    {
      "epoch": 1.1012,
      "grad_norm": 0.01715720444917679,
      "learning_rate": 6.330666666666666e-07,
      "logits/chosen": -2.184262752532959,
      "logits/rejected": -3.45505428314209,
      "logps/chosen": -83.03767395019531,
      "logps/rejected": -143.02528381347656,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7512612342834473,
      "rewards/margins": 8.602429389953613,
      "rewards/rejected": -5.851167678833008,
      "step": 2753
    },
    {
      "epoch": 1.1016,
      "grad_norm": 0.10548724979162216,
      "learning_rate": 6.329333333333333e-07,
      "logits/chosen": -2.636742353439331,
      "logits/rejected": -3.3953933715820312,
      "logps/chosen": -244.24102783203125,
      "logps/rejected": -216.60906982421875,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3429626524448395,
      "rewards/margins": 7.175422668457031,
      "rewards/rejected": -7.518385410308838,
      "step": 2754
    },
    {
      "epoch": 1.102,
      "grad_norm": 0.08214813470840454,
      "learning_rate": 6.328e-07,
      "logits/chosen": -2.7669506072998047,
      "logits/rejected": -3.235508918762207,
      "logps/chosen": -155.98861694335938,
      "logps/rejected": -197.1977996826172,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9773247241973877,
      "rewards/margins": 8.860357284545898,
      "rewards/rejected": -6.883032321929932,
      "step": 2755
    },
    {
      "epoch": 1.1024,
      "grad_norm": 0.0014760461635887623,
      "learning_rate": 6.326666666666667e-07,
      "logits/chosen": -2.32776141166687,
      "logits/rejected": -3.346540927886963,
      "logps/chosen": -117.57622528076172,
      "logps/rejected": -198.68179321289062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1430695056915283,
      "rewards/margins": 11.34151840209961,
      "rewards/rejected": -9.19844913482666,
      "step": 2756
    },
    {
      "epoch": 1.1028,
      "grad_norm": 0.0017302448395639658,
      "learning_rate": 6.325333333333333e-07,
      "logits/chosen": -1.8531861305236816,
      "logits/rejected": -3.2434215545654297,
      "logps/chosen": -143.64260864257812,
      "logps/rejected": -177.11990356445312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.42331600189209,
      "rewards/margins": 11.171136856079102,
      "rewards/rejected": -6.7478203773498535,
      "step": 2757
    },
    {
      "epoch": 1.1032,
      "grad_norm": 0.0031563937664031982,
      "learning_rate": 6.324e-07,
      "logits/chosen": -2.268251419067383,
      "logits/rejected": -3.7566304206848145,
      "logps/chosen": -93.7330322265625,
      "logps/rejected": -183.09646606445312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0820302963256836,
      "rewards/margins": 10.626684188842773,
      "rewards/rejected": -7.54465389251709,
      "step": 2758
    },
    {
      "epoch": 1.1036,
      "grad_norm": 0.005868509877473116,
      "learning_rate": 6.322666666666667e-07,
      "logits/chosen": -2.1667447090148926,
      "logits/rejected": -3.4216604232788086,
      "logps/chosen": -152.27618408203125,
      "logps/rejected": -187.06021118164062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.684548854827881,
      "rewards/margins": 10.121125221252441,
      "rewards/rejected": -6.436575889587402,
      "step": 2759
    },
    {
      "epoch": 1.104,
      "grad_norm": 0.5876149535179138,
      "learning_rate": 6.321333333333332e-07,
      "logits/chosen": -2.097095012664795,
      "logits/rejected": -3.356189727783203,
      "logps/chosen": -85.8202896118164,
      "logps/rejected": -157.9595489501953,
      "loss": 0.0048,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8535244464874268,
      "rewards/margins": 7.553497314453125,
      "rewards/rejected": -6.699972629547119,
      "step": 2760
    },
    {
      "epoch": 1.1044,
      "grad_norm": 0.31685659289360046,
      "learning_rate": 6.319999999999999e-07,
      "logits/chosen": -2.388965606689453,
      "logits/rejected": -3.5709898471832275,
      "logps/chosen": -173.00978088378906,
      "logps/rejected": -137.86807250976562,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2587093114852905,
      "rewards/margins": 5.39836311340332,
      "rewards/rejected": -4.13965368270874,
      "step": 2761
    },
    {
      "epoch": 1.1048,
      "grad_norm": 0.39665260910987854,
      "learning_rate": 6.318666666666666e-07,
      "logits/chosen": -2.3816800117492676,
      "logits/rejected": -3.307844638824463,
      "logps/chosen": -120.31027221679688,
      "logps/rejected": -138.04092407226562,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4819526672363281,
      "rewards/margins": 7.0123138427734375,
      "rewards/rejected": -5.530360698699951,
      "step": 2762
    },
    {
      "epoch": 1.1052,
      "grad_norm": 0.005189886782318354,
      "learning_rate": 6.317333333333333e-07,
      "logits/chosen": -2.1376328468322754,
      "logits/rejected": -3.33577299118042,
      "logps/chosen": -155.31182861328125,
      "logps/rejected": -251.541015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.804168701171875,
      "rewards/margins": 10.596841812133789,
      "rewards/rejected": -7.792673110961914,
      "step": 2763
    },
    {
      "epoch": 1.1056,
      "grad_norm": 0.009460204280912876,
      "learning_rate": 6.316e-07,
      "logits/chosen": -2.0686872005462646,
      "logits/rejected": -2.9817895889282227,
      "logps/chosen": -94.17227935791016,
      "logps/rejected": -215.6439971923828,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6838502883911133,
      "rewards/margins": 10.478317260742188,
      "rewards/rejected": -6.794466972351074,
      "step": 2764
    },
    {
      "epoch": 1.106,
      "grad_norm": 0.8146812915802002,
      "learning_rate": 6.314666666666666e-07,
      "logits/chosen": -2.6001954078674316,
      "logits/rejected": -2.8882312774658203,
      "logps/chosen": -204.51239013671875,
      "logps/rejected": -165.06581115722656,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7171798944473267,
      "rewards/margins": 7.381318092346191,
      "rewards/rejected": -6.6641387939453125,
      "step": 2765
    },
    {
      "epoch": 1.1064,
      "grad_norm": 0.2194368988275528,
      "learning_rate": 6.313333333333333e-07,
      "logits/chosen": -2.3679940700531006,
      "logits/rejected": -3.062936782836914,
      "logps/chosen": -158.4852294921875,
      "logps/rejected": -286.58734130859375,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8387985229492188,
      "rewards/margins": 9.151338577270508,
      "rewards/rejected": -8.312540054321289,
      "step": 2766
    },
    {
      "epoch": 1.1068,
      "grad_norm": 6.097158908843994,
      "learning_rate": 6.312e-07,
      "logits/chosen": -2.763944149017334,
      "logits/rejected": -3.4149794578552246,
      "logps/chosen": -177.33261108398438,
      "logps/rejected": -173.80484008789062,
      "loss": 0.0576,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7372223138809204,
      "rewards/margins": 5.945671081542969,
      "rewards/rejected": -5.20844841003418,
      "step": 2767
    },
    {
      "epoch": 1.1072,
      "grad_norm": 0.01790795847773552,
      "learning_rate": 6.310666666666667e-07,
      "logits/chosen": -2.415482521057129,
      "logits/rejected": -3.277096748352051,
      "logps/chosen": -117.35582733154297,
      "logps/rejected": -182.58651733398438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.220247745513916,
      "rewards/margins": 10.63921070098877,
      "rewards/rejected": -7.418962478637695,
      "step": 2768
    },
    {
      "epoch": 1.1076,
      "grad_norm": 0.006475280970335007,
      "learning_rate": 6.309333333333333e-07,
      "logits/chosen": -2.576665163040161,
      "logits/rejected": -3.5363352298736572,
      "logps/chosen": -80.70823669433594,
      "logps/rejected": -140.01992797851562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.223337173461914,
      "rewards/margins": 9.841886520385742,
      "rewards/rejected": -5.618549346923828,
      "step": 2769
    },
    {
      "epoch": 1.108,
      "grad_norm": 0.20245590806007385,
      "learning_rate": 6.308e-07,
      "logits/chosen": -2.1949262619018555,
      "logits/rejected": -3.156893014907837,
      "logps/chosen": -150.52664184570312,
      "logps/rejected": -169.953125,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9914425015449524,
      "rewards/margins": 6.6834330558776855,
      "rewards/rejected": -7.674875259399414,
      "step": 2770
    },
    {
      "epoch": 1.1084,
      "grad_norm": 0.1758873015642166,
      "learning_rate": 6.306666666666666e-07,
      "logits/chosen": -1.8444784879684448,
      "logits/rejected": -3.1760354042053223,
      "logps/chosen": -141.24610900878906,
      "logps/rejected": -150.076416015625,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8866947293281555,
      "rewards/margins": 6.09641170501709,
      "rewards/rejected": -5.209717273712158,
      "step": 2771
    },
    {
      "epoch": 1.1088,
      "grad_norm": 0.5216216444969177,
      "learning_rate": 6.305333333333332e-07,
      "logits/chosen": -2.305009126663208,
      "logits/rejected": -3.7470831871032715,
      "logps/chosen": -141.72317504882812,
      "logps/rejected": -175.70169067382812,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6368881464004517,
      "rewards/margins": 7.629301071166992,
      "rewards/rejected": -6.992413520812988,
      "step": 2772
    },
    {
      "epoch": 1.1092,
      "grad_norm": 0.026104073971509933,
      "learning_rate": 6.303999999999999e-07,
      "logits/chosen": -2.021312952041626,
      "logits/rejected": -2.656038284301758,
      "logps/chosen": -96.59053039550781,
      "logps/rejected": -176.17282104492188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3269309997558594,
      "rewards/margins": 9.944206237792969,
      "rewards/rejected": -7.617275238037109,
      "step": 2773
    },
    {
      "epoch": 1.1096,
      "grad_norm": 0.006032167933881283,
      "learning_rate": 6.302666666666666e-07,
      "logits/chosen": -2.420102596282959,
      "logits/rejected": -3.54496431350708,
      "logps/chosen": -128.44178771972656,
      "logps/rejected": -183.6645965576172,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9860146045684814,
      "rewards/margins": 10.178079605102539,
      "rewards/rejected": -7.1920647621154785,
      "step": 2774
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.05043695122003555,
      "learning_rate": 6.301333333333333e-07,
      "logits/chosen": -1.9436557292938232,
      "logits/rejected": -3.294773817062378,
      "logps/chosen": -63.34787368774414,
      "logps/rejected": -171.42050170898438,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1121437549591064,
      "rewards/margins": 9.078636169433594,
      "rewards/rejected": -6.966492652893066,
      "step": 2775
    },
    {
      "epoch": 1.1104,
      "grad_norm": 0.09671016037464142,
      "learning_rate": 6.3e-07,
      "logits/chosen": -2.0198562145233154,
      "logits/rejected": -3.0685555934906006,
      "logps/chosen": -127.85231018066406,
      "logps/rejected": -172.41574096679688,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.367588758468628,
      "rewards/margins": 8.411425590515137,
      "rewards/rejected": -6.043837070465088,
      "step": 2776
    },
    {
      "epoch": 1.1108,
      "grad_norm": 0.011806336231529713,
      "learning_rate": 6.298666666666667e-07,
      "logits/chosen": -2.2674341201782227,
      "logits/rejected": -2.9629063606262207,
      "logps/chosen": -168.12051391601562,
      "logps/rejected": -197.58457946777344,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3107750415802,
      "rewards/margins": 10.474058151245117,
      "rewards/rejected": -7.163283348083496,
      "step": 2777
    },
    {
      "epoch": 1.1112,
      "grad_norm": 0.2046167105436325,
      "learning_rate": 6.297333333333334e-07,
      "logits/chosen": -2.5200557708740234,
      "logits/rejected": -3.416207790374756,
      "logps/chosen": -119.59568786621094,
      "logps/rejected": -167.09552001953125,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5520912408828735,
      "rewards/margins": 7.31356143951416,
      "rewards/rejected": -5.761469841003418,
      "step": 2778
    },
    {
      "epoch": 1.1116,
      "grad_norm": 0.0019496618770062923,
      "learning_rate": 6.296e-07,
      "logits/chosen": -2.1596803665161133,
      "logits/rejected": -3.5781192779541016,
      "logps/chosen": -122.26812744140625,
      "logps/rejected": -171.6190185546875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 5.572904586791992,
      "rewards/margins": 11.300920486450195,
      "rewards/rejected": -5.728015422821045,
      "step": 2779
    },
    {
      "epoch": 1.112,
      "grad_norm": 0.04981841519474983,
      "learning_rate": 6.294666666666666e-07,
      "logits/chosen": -2.0724129676818848,
      "logits/rejected": -3.1731667518615723,
      "logps/chosen": -89.92395782470703,
      "logps/rejected": -159.0997772216797,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.484362840652466,
      "rewards/margins": 9.37134075164795,
      "rewards/rejected": -6.8869781494140625,
      "step": 2780
    },
    {
      "epoch": 1.1124,
      "grad_norm": 0.007560204714536667,
      "learning_rate": 6.293333333333333e-07,
      "logits/chosen": -2.153165340423584,
      "logits/rejected": -3.555961847305298,
      "logps/chosen": -159.932373046875,
      "logps/rejected": -164.08055114746094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.890136241912842,
      "rewards/margins": 9.958724975585938,
      "rewards/rejected": -5.068589210510254,
      "step": 2781
    },
    {
      "epoch": 1.1128,
      "grad_norm": 0.0006830376805737615,
      "learning_rate": 6.291999999999999e-07,
      "logits/chosen": -2.5094990730285645,
      "logits/rejected": -3.5403902530670166,
      "logps/chosen": -166.4083251953125,
      "logps/rejected": -182.2874755859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 5.094209671020508,
      "rewards/margins": 12.159682273864746,
      "rewards/rejected": -7.065472602844238,
      "step": 2782
    },
    {
      "epoch": 1.1132,
      "grad_norm": 0.06249493360519409,
      "learning_rate": 6.290666666666666e-07,
      "logits/chosen": -2.3546218872070312,
      "logits/rejected": -3.0894103050231934,
      "logps/chosen": -92.01480102539062,
      "logps/rejected": -157.05685424804688,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9750800132751465,
      "rewards/margins": 8.188230514526367,
      "rewards/rejected": -5.213150978088379,
      "step": 2783
    },
    {
      "epoch": 1.1136,
      "grad_norm": 0.14417430758476257,
      "learning_rate": 6.289333333333333e-07,
      "logits/chosen": -1.7765681743621826,
      "logits/rejected": -2.6467020511627197,
      "logps/chosen": -83.69229888916016,
      "logps/rejected": -128.21839904785156,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5834879875183105,
      "rewards/margins": 6.481603145599365,
      "rewards/rejected": -3.8981146812438965,
      "step": 2784
    },
    {
      "epoch": 1.114,
      "grad_norm": 0.006693015806376934,
      "learning_rate": 6.288e-07,
      "logits/chosen": -2.211277961730957,
      "logits/rejected": -3.724407911300659,
      "logps/chosen": -106.24037170410156,
      "logps/rejected": -199.35009765625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4029407501220703,
      "rewards/margins": 10.029498100280762,
      "rewards/rejected": -7.626557350158691,
      "step": 2785
    },
    {
      "epoch": 1.1144,
      "grad_norm": 0.01658799685537815,
      "learning_rate": 6.286666666666667e-07,
      "logits/chosen": -2.068801164627075,
      "logits/rejected": -3.796210289001465,
      "logps/chosen": -124.0145492553711,
      "logps/rejected": -185.3791046142578,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.294579029083252,
      "rewards/margins": 9.750171661376953,
      "rewards/rejected": -6.455592155456543,
      "step": 2786
    },
    {
      "epoch": 1.1148,
      "grad_norm": 0.0099787013605237,
      "learning_rate": 6.285333333333334e-07,
      "logits/chosen": -1.4896177053451538,
      "logits/rejected": -4.037672996520996,
      "logps/chosen": -57.1617431640625,
      "logps/rejected": -169.94833374023438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0465707778930664,
      "rewards/margins": 10.541749954223633,
      "rewards/rejected": -7.495180130004883,
      "step": 2787
    },
    {
      "epoch": 1.1152,
      "grad_norm": 0.0690964013338089,
      "learning_rate": 6.283999999999999e-07,
      "logits/chosen": -1.8155369758605957,
      "logits/rejected": -3.3349051475524902,
      "logps/chosen": -77.91990661621094,
      "logps/rejected": -134.13343811035156,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5834226608276367,
      "rewards/margins": 7.803810119628906,
      "rewards/rejected": -5.2203874588012695,
      "step": 2788
    },
    {
      "epoch": 1.1156,
      "grad_norm": 0.5475291609764099,
      "learning_rate": 6.282666666666666e-07,
      "logits/chosen": -2.204042434692383,
      "logits/rejected": -2.511664390563965,
      "logps/chosen": -106.86274719238281,
      "logps/rejected": -138.6335906982422,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8019917011260986,
      "rewards/margins": 7.299495697021484,
      "rewards/rejected": -6.497503757476807,
      "step": 2789
    },
    {
      "epoch": 1.116,
      "grad_norm": 0.20496343076229095,
      "learning_rate": 6.281333333333333e-07,
      "logits/chosen": -2.259030342102051,
      "logits/rejected": -2.744314432144165,
      "logps/chosen": -133.67259216308594,
      "logps/rejected": -224.17970275878906,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.814397394657135,
      "rewards/margins": 6.622683525085449,
      "rewards/rejected": -5.808286190032959,
      "step": 2790
    },
    {
      "epoch": 1.1164,
      "grad_norm": 0.04827992245554924,
      "learning_rate": 6.28e-07,
      "logits/chosen": -1.8821749687194824,
      "logits/rejected": -2.0997838973999023,
      "logps/chosen": -169.86160278320312,
      "logps/rejected": -135.62110900878906,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1677987575531006,
      "rewards/margins": 8.316710472106934,
      "rewards/rejected": -6.148911476135254,
      "step": 2791
    },
    {
      "epoch": 1.1168,
      "grad_norm": 0.019212132319808006,
      "learning_rate": 6.278666666666667e-07,
      "logits/chosen": -2.2468159198760986,
      "logits/rejected": -3.4588727951049805,
      "logps/chosen": -109.5484619140625,
      "logps/rejected": -168.22238159179688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6157660484313965,
      "rewards/margins": 8.911256790161133,
      "rewards/rejected": -6.29548978805542,
      "step": 2792
    },
    {
      "epoch": 1.1172,
      "grad_norm": 1.7949551343917847,
      "learning_rate": 6.277333333333333e-07,
      "logits/chosen": -2.389525890350342,
      "logits/rejected": -2.6372125148773193,
      "logps/chosen": -115.55990600585938,
      "logps/rejected": -122.28054809570312,
      "loss": 0.0246,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.529613971710205,
      "rewards/margins": 3.721700668334961,
      "rewards/rejected": -5.251314640045166,
      "step": 2793
    },
    {
      "epoch": 1.1176,
      "grad_norm": 0.11561394482851028,
      "learning_rate": 6.276e-07,
      "logits/chosen": -2.913020133972168,
      "logits/rejected": -3.0572357177734375,
      "logps/chosen": -153.65194702148438,
      "logps/rejected": -226.86672973632812,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04522436857223511,
      "rewards/margins": 8.131036758422852,
      "rewards/rejected": -8.08581256866455,
      "step": 2794
    },
    {
      "epoch": 1.1179999999999999,
      "grad_norm": 0.009024389088153839,
      "learning_rate": 6.274666666666666e-07,
      "logits/chosen": -2.0860755443573,
      "logits/rejected": -3.971116542816162,
      "logps/chosen": -99.72509765625,
      "logps/rejected": -207.8592529296875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3197205066680908,
      "rewards/margins": 10.720888137817383,
      "rewards/rejected": -9.401166915893555,
      "step": 2795
    },
    {
      "epoch": 1.1184,
      "grad_norm": 0.049513593316078186,
      "learning_rate": 6.273333333333333e-07,
      "logits/chosen": -2.0682356357574463,
      "logits/rejected": -3.3313369750976562,
      "logps/chosen": -100.94631958007812,
      "logps/rejected": -172.02978515625,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1269078254699707,
      "rewards/margins": 8.252504348754883,
      "rewards/rejected": -5.125596046447754,
      "step": 2796
    },
    {
      "epoch": 1.1188,
      "grad_norm": 0.020328447222709656,
      "learning_rate": 6.271999999999999e-07,
      "logits/chosen": -1.7146854400634766,
      "logits/rejected": -3.3388078212738037,
      "logps/chosen": -80.79945373535156,
      "logps/rejected": -191.00413513183594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4262006282806396,
      "rewards/margins": 10.846088409423828,
      "rewards/rejected": -8.41988754272461,
      "step": 2797
    },
    {
      "epoch": 1.1192,
      "grad_norm": 0.041152723133563995,
      "learning_rate": 6.270666666666666e-07,
      "logits/chosen": -2.676907539367676,
      "logits/rejected": -3.4617509841918945,
      "logps/chosen": -114.63603973388672,
      "logps/rejected": -173.41494750976562,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9164228439331055,
      "rewards/margins": 9.408324241638184,
      "rewards/rejected": -6.491901397705078,
      "step": 2798
    },
    {
      "epoch": 1.1196,
      "grad_norm": 0.45606154203414917,
      "learning_rate": 6.269333333333333e-07,
      "logits/chosen": -2.231302261352539,
      "logits/rejected": -2.9773635864257812,
      "logps/chosen": -193.39215087890625,
      "logps/rejected": -162.74661254882812,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05280914902687073,
      "rewards/margins": 6.720273971557617,
      "rewards/rejected": -6.667464256286621,
      "step": 2799
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.0018298254581168294,
      "learning_rate": 6.268e-07,
      "logits/chosen": -2.227381467819214,
      "logits/rejected": -3.3984367847442627,
      "logps/chosen": -128.67486572265625,
      "logps/rejected": -202.26422119140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.8522233963012695,
      "rewards/margins": 11.571842193603516,
      "rewards/rejected": -6.719618797302246,
      "step": 2800
    },
    {
      "epoch": 1.1204,
      "grad_norm": 0.08444339036941528,
      "learning_rate": 6.266666666666667e-07,
      "logits/chosen": -2.278799533843994,
      "logits/rejected": -2.857245922088623,
      "logps/chosen": -211.45046997070312,
      "logps/rejected": -164.5789794921875,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.704572319984436,
      "rewards/margins": 7.051377296447754,
      "rewards/rejected": -6.346805572509766,
      "step": 2801
    },
    {
      "epoch": 1.1208,
      "grad_norm": 0.0498855859041214,
      "learning_rate": 6.265333333333334e-07,
      "logits/chosen": -2.4253387451171875,
      "logits/rejected": -3.644451141357422,
      "logps/chosen": -65.63673400878906,
      "logps/rejected": -158.96356201171875,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.962559461593628,
      "rewards/margins": 8.43612289428711,
      "rewards/rejected": -5.473562717437744,
      "step": 2802
    },
    {
      "epoch": 1.1212,
      "grad_norm": 0.001485775108449161,
      "learning_rate": 6.263999999999999e-07,
      "logits/chosen": -2.0600781440734863,
      "logits/rejected": -3.2268829345703125,
      "logps/chosen": -112.379638671875,
      "logps/rejected": -187.46844482421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.44352388381958,
      "rewards/margins": 11.692626953125,
      "rewards/rejected": -7.249103546142578,
      "step": 2803
    },
    {
      "epoch": 1.1216,
      "grad_norm": 0.5627207159996033,
      "learning_rate": 6.262666666666666e-07,
      "logits/chosen": -3.0416226387023926,
      "logits/rejected": -3.0532612800598145,
      "logps/chosen": -146.02418518066406,
      "logps/rejected": -183.7241668701172,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8502269983291626,
      "rewards/margins": 5.198752403259277,
      "rewards/rejected": -3.3485255241394043,
      "step": 2804
    },
    {
      "epoch": 1.1219999999999999,
      "grad_norm": 0.004621804226189852,
      "learning_rate": 6.261333333333333e-07,
      "logits/chosen": -1.9973971843719482,
      "logits/rejected": -3.6015686988830566,
      "logps/chosen": -106.87503051757812,
      "logps/rejected": -182.67445373535156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3069896697998047,
      "rewards/margins": 10.240525245666504,
      "rewards/rejected": -7.933535575866699,
      "step": 2805
    },
    {
      "epoch": 1.1224,
      "grad_norm": 0.004441806115210056,
      "learning_rate": 6.26e-07,
      "logits/chosen": -2.0657858848571777,
      "logits/rejected": -3.32560396194458,
      "logps/chosen": -112.13786315917969,
      "logps/rejected": -271.4377746582031,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.555370807647705,
      "rewards/margins": 12.139626502990723,
      "rewards/rejected": -8.584256172180176,
      "step": 2806
    },
    {
      "epoch": 1.1228,
      "grad_norm": 0.037473421543836594,
      "learning_rate": 6.258666666666666e-07,
      "logits/chosen": -1.6123855113983154,
      "logits/rejected": -2.6988272666931152,
      "logps/chosen": -107.65877532958984,
      "logps/rejected": -166.0875701904297,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3159401416778564,
      "rewards/margins": 9.028322219848633,
      "rewards/rejected": -6.712381839752197,
      "step": 2807
    },
    {
      "epoch": 1.1232,
      "grad_norm": 0.08270127326250076,
      "learning_rate": 6.257333333333333e-07,
      "logits/chosen": -2.4656143188476562,
      "logits/rejected": -3.3443965911865234,
      "logps/chosen": -142.82070922851562,
      "logps/rejected": -158.60791015625,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.747650146484375,
      "rewards/margins": 9.098213195800781,
      "rewards/rejected": -6.350563049316406,
      "step": 2808
    },
    {
      "epoch": 1.1236,
      "grad_norm": 0.026599640026688576,
      "learning_rate": 6.256e-07,
      "logits/chosen": -1.911698818206787,
      "logits/rejected": -2.779529094696045,
      "logps/chosen": -92.0213623046875,
      "logps/rejected": -144.2445526123047,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.824225664138794,
      "rewards/margins": 8.42529010772705,
      "rewards/rejected": -5.601064682006836,
      "step": 2809
    },
    {
      "epoch": 1.124,
      "grad_norm": 0.027123166248202324,
      "learning_rate": 6.254666666666666e-07,
      "logits/chosen": -2.3063578605651855,
      "logits/rejected": -2.58730411529541,
      "logps/chosen": -116.78030395507812,
      "logps/rejected": -209.54782104492188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.393564224243164,
      "rewards/margins": 9.624940872192383,
      "rewards/rejected": -5.2313761711120605,
      "step": 2810
    },
    {
      "epoch": 1.1244,
      "grad_norm": 0.1386139839887619,
      "learning_rate": 6.253333333333333e-07,
      "logits/chosen": -2.657162666320801,
      "logits/rejected": -2.6584744453430176,
      "logps/chosen": -87.467529296875,
      "logps/rejected": -123.49263000488281,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.340250015258789,
      "rewards/margins": 6.924903869628906,
      "rewards/rejected": -5.584653854370117,
      "step": 2811
    },
    {
      "epoch": 1.1248,
      "grad_norm": 0.014926758594810963,
      "learning_rate": 6.252e-07,
      "logits/chosen": -2.1201388835906982,
      "logits/rejected": -3.0524632930755615,
      "logps/chosen": -166.00177001953125,
      "logps/rejected": -179.28890991210938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.518716335296631,
      "rewards/margins": 9.781885147094727,
      "rewards/rejected": -5.263169288635254,
      "step": 2812
    },
    {
      "epoch": 1.1252,
      "grad_norm": 0.17783460021018982,
      "learning_rate": 6.250666666666667e-07,
      "logits/chosen": -2.1188576221466064,
      "logits/rejected": -3.258662223815918,
      "logps/chosen": -105.99049377441406,
      "logps/rejected": -175.611328125,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2843337953090668,
      "rewards/margins": 6.655559539794922,
      "rewards/rejected": -6.93989372253418,
      "step": 2813
    },
    {
      "epoch": 1.1256,
      "grad_norm": 1.751926064491272,
      "learning_rate": 6.249333333333333e-07,
      "logits/chosen": -2.00494384765625,
      "logits/rejected": -3.4199440479278564,
      "logps/chosen": -133.93185424804688,
      "logps/rejected": -156.14678955078125,
      "loss": 0.0172,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1587181091308594,
      "rewards/margins": 8.860910415649414,
      "rewards/rejected": -5.702192306518555,
      "step": 2814
    },
    {
      "epoch": 1.126,
      "grad_norm": 0.00914810411632061,
      "learning_rate": 6.248e-07,
      "logits/chosen": -2.420527458190918,
      "logits/rejected": -2.468148708343506,
      "logps/chosen": -163.86312866210938,
      "logps/rejected": -146.46063232421875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.429896354675293,
      "rewards/margins": 9.414012908935547,
      "rewards/rejected": -5.984116554260254,
      "step": 2815
    },
    {
      "epoch": 1.1264,
      "grad_norm": 0.0026342093478888273,
      "learning_rate": 6.246666666666667e-07,
      "logits/chosen": -1.833737850189209,
      "logits/rejected": -3.5319459438323975,
      "logps/chosen": -61.65303421020508,
      "logps/rejected": -198.3819580078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.004939317703247,
      "rewards/margins": 11.362838745117188,
      "rewards/rejected": -8.35789966583252,
      "step": 2816
    },
    {
      "epoch": 1.1268,
      "grad_norm": 0.02188781462609768,
      "learning_rate": 6.245333333333333e-07,
      "logits/chosen": -1.971807837486267,
      "logits/rejected": -3.1746273040771484,
      "logps/chosen": -155.57363891601562,
      "logps/rejected": -179.55938720703125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.029876708984375,
      "rewards/margins": 8.524024963378906,
      "rewards/rejected": -6.494148254394531,
      "step": 2817
    },
    {
      "epoch": 1.1272,
      "grad_norm": 0.09906204789876938,
      "learning_rate": 6.243999999999999e-07,
      "logits/chosen": -1.7154608964920044,
      "logits/rejected": -3.1221954822540283,
      "logps/chosen": -99.88876342773438,
      "logps/rejected": -153.9718780517578,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1793698072433472,
      "rewards/margins": 7.567627906799316,
      "rewards/rejected": -6.388258457183838,
      "step": 2818
    },
    {
      "epoch": 1.1276,
      "grad_norm": 0.19628505408763885,
      "learning_rate": 6.242666666666666e-07,
      "logits/chosen": -2.373793125152588,
      "logits/rejected": -2.650604248046875,
      "logps/chosen": -118.97332763671875,
      "logps/rejected": -157.0148162841797,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.568882703781128,
      "rewards/margins": 7.988720893859863,
      "rewards/rejected": -5.419837951660156,
      "step": 2819
    },
    {
      "epoch": 1.1280000000000001,
      "grad_norm": 0.017854537814855576,
      "learning_rate": 6.241333333333333e-07,
      "logits/chosen": -2.0913033485412598,
      "logits/rejected": -3.45857572555542,
      "logps/chosen": -60.831443786621094,
      "logps/rejected": -146.2198486328125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.149456024169922,
      "rewards/margins": 9.722251892089844,
      "rewards/rejected": -5.57279634475708,
      "step": 2820
    },
    {
      "epoch": 1.1284,
      "grad_norm": 0.3148065507411957,
      "learning_rate": 6.24e-07,
      "logits/chosen": -1.841724157333374,
      "logits/rejected": -2.8199660778045654,
      "logps/chosen": -100.46499633789062,
      "logps/rejected": -170.74002075195312,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7257522940635681,
      "rewards/margins": 7.442007064819336,
      "rewards/rejected": -6.716255187988281,
      "step": 2821
    },
    {
      "epoch": 1.1288,
      "grad_norm": 0.015781933441758156,
      "learning_rate": 6.238666666666667e-07,
      "logits/chosen": -2.528042793273926,
      "logits/rejected": -2.8717575073242188,
      "logps/chosen": -189.38815307617188,
      "logps/rejected": -157.073974609375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8177943229675293,
      "rewards/margins": 8.948201179504395,
      "rewards/rejected": -6.130406856536865,
      "step": 2822
    },
    {
      "epoch": 1.1292,
      "grad_norm": 0.0926174744963646,
      "learning_rate": 6.237333333333334e-07,
      "logits/chosen": -2.4984967708587646,
      "logits/rejected": -2.6610093116760254,
      "logps/chosen": -117.08517456054688,
      "logps/rejected": -167.44447326660156,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.220647096633911,
      "rewards/margins": 8.239130973815918,
      "rewards/rejected": -6.018484115600586,
      "step": 2823
    },
    {
      "epoch": 1.1296,
      "grad_norm": 0.027572236955165863,
      "learning_rate": 6.236e-07,
      "logits/chosen": -1.8793649673461914,
      "logits/rejected": -2.9853975772857666,
      "logps/chosen": -223.27296447753906,
      "logps/rejected": -192.85340881347656,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4757583737373352,
      "rewards/margins": 9.073180198669434,
      "rewards/rejected": -8.597421646118164,
      "step": 2824
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.2252792865037918,
      "learning_rate": 6.234666666666666e-07,
      "logits/chosen": -2.0261290073394775,
      "logits/rejected": -3.3607518672943115,
      "logps/chosen": -103.53182983398438,
      "logps/rejected": -149.68092346191406,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4612782001495361,
      "rewards/margins": 7.847269058227539,
      "rewards/rejected": -6.385991096496582,
      "step": 2825
    },
    {
      "epoch": 1.1304,
      "grad_norm": 0.009234912693500519,
      "learning_rate": 6.233333333333332e-07,
      "logits/chosen": -2.002943754196167,
      "logits/rejected": -3.8238182067871094,
      "logps/chosen": -97.81926727294922,
      "logps/rejected": -174.67611694335938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.362565279006958,
      "rewards/margins": 10.120229721069336,
      "rewards/rejected": -7.757664680480957,
      "step": 2826
    },
    {
      "epoch": 1.1308,
      "grad_norm": 0.005817660130560398,
      "learning_rate": 6.231999999999999e-07,
      "logits/chosen": -2.208773136138916,
      "logits/rejected": -3.1561036109924316,
      "logps/chosen": -138.8282928466797,
      "logps/rejected": -185.111083984375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2418053150177,
      "rewards/margins": 9.966915130615234,
      "rewards/rejected": -7.725110054016113,
      "step": 2827
    },
    {
      "epoch": 1.1312,
      "grad_norm": 0.039314158260822296,
      "learning_rate": 6.230666666666666e-07,
      "logits/chosen": -2.0221588611602783,
      "logits/rejected": -3.0264437198638916,
      "logps/chosen": -98.98350524902344,
      "logps/rejected": -146.9332275390625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1589818000793457,
      "rewards/margins": 8.032939910888672,
      "rewards/rejected": -4.873958110809326,
      "step": 2828
    },
    {
      "epoch": 1.1316,
      "grad_norm": 0.012945882976055145,
      "learning_rate": 6.229333333333333e-07,
      "logits/chosen": -2.259524345397949,
      "logits/rejected": -3.1484360694885254,
      "logps/chosen": -98.89024353027344,
      "logps/rejected": -184.59564208984375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2761287689208984,
      "rewards/margins": 10.071552276611328,
      "rewards/rejected": -6.7954230308532715,
      "step": 2829
    },
    {
      "epoch": 1.1320000000000001,
      "grad_norm": 0.010877614840865135,
      "learning_rate": 6.228e-07,
      "logits/chosen": -2.596029758453369,
      "logits/rejected": -3.186544895172119,
      "logps/chosen": -131.79452514648438,
      "logps/rejected": -187.61676025390625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.037464141845703,
      "rewards/margins": 9.541677474975586,
      "rewards/rejected": -6.504213333129883,
      "step": 2830
    },
    {
      "epoch": 1.1324,
      "grad_norm": 0.013711168430745602,
      "learning_rate": 6.226666666666667e-07,
      "logits/chosen": -2.1517794132232666,
      "logits/rejected": -3.1868653297424316,
      "logps/chosen": -144.35406494140625,
      "logps/rejected": -159.91224670410156,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.755535125732422,
      "rewards/margins": 9.605746269226074,
      "rewards/rejected": -6.850211143493652,
      "step": 2831
    },
    {
      "epoch": 1.1328,
      "grad_norm": 1.0075569152832031,
      "learning_rate": 6.225333333333334e-07,
      "logits/chosen": -2.395632743835449,
      "logits/rejected": -2.8690571784973145,
      "logps/chosen": -164.60301208496094,
      "logps/rejected": -138.73291015625,
      "loss": 0.0071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7901702523231506,
      "rewards/margins": 6.1225481033325195,
      "rewards/rejected": -5.332377910614014,
      "step": 2832
    },
    {
      "epoch": 1.1332,
      "grad_norm": 2.7816145420074463,
      "learning_rate": 6.224e-07,
      "logits/chosen": -2.447406530380249,
      "logits/rejected": -3.4340524673461914,
      "logps/chosen": -106.83769226074219,
      "logps/rejected": -169.36268615722656,
      "loss": 0.0184,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6783156991004944,
      "rewards/margins": 7.439737319946289,
      "rewards/rejected": -8.118053436279297,
      "step": 2833
    },
    {
      "epoch": 1.1336,
      "grad_norm": 0.016239900141954422,
      "learning_rate": 6.222666666666667e-07,
      "logits/chosen": -1.7614221572875977,
      "logits/rejected": -3.2274749279022217,
      "logps/chosen": -125.26486206054688,
      "logps/rejected": -223.00149536132812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.521665632724762,
      "rewards/margins": 9.174277305603027,
      "rewards/rejected": -8.65261173248291,
      "step": 2834
    },
    {
      "epoch": 1.134,
      "grad_norm": 0.9243021011352539,
      "learning_rate": 6.221333333333332e-07,
      "logits/chosen": -2.101986885070801,
      "logits/rejected": -2.757136821746826,
      "logps/chosen": -123.29277038574219,
      "logps/rejected": -127.4449234008789,
      "loss": 0.0077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8002418279647827,
      "rewards/margins": 6.677828788757324,
      "rewards/rejected": -4.87758731842041,
      "step": 2835
    },
    {
      "epoch": 1.1344,
      "grad_norm": 0.06426983326673508,
      "learning_rate": 6.219999999999999e-07,
      "logits/chosen": -2.2926573753356934,
      "logits/rejected": -2.7355234622955322,
      "logps/chosen": -91.99847412109375,
      "logps/rejected": -167.01536560058594,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.568592071533203,
      "rewards/margins": 9.01264762878418,
      "rewards/rejected": -6.444055080413818,
      "step": 2836
    },
    {
      "epoch": 1.1348,
      "grad_norm": 0.03439277037978172,
      "learning_rate": 6.218666666666666e-07,
      "logits/chosen": -1.9811363220214844,
      "logits/rejected": -3.843308448791504,
      "logps/chosen": -138.2357940673828,
      "logps/rejected": -252.7810516357422,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4653926491737366,
      "rewards/margins": 8.780977249145508,
      "rewards/rejected": -8.315584182739258,
      "step": 2837
    },
    {
      "epoch": 1.1352,
      "grad_norm": 0.057179778814315796,
      "learning_rate": 6.217333333333333e-07,
      "logits/chosen": -1.9119164943695068,
      "logits/rejected": -2.8857812881469727,
      "logps/chosen": -123.9247055053711,
      "logps/rejected": -152.92359924316406,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9711029529571533,
      "rewards/margins": 9.257871627807617,
      "rewards/rejected": -6.286768436431885,
      "step": 2838
    },
    {
      "epoch": 1.1356,
      "grad_norm": 0.0040353951044380665,
      "learning_rate": 6.216e-07,
      "logits/chosen": -2.1504054069519043,
      "logits/rejected": -3.6471893787384033,
      "logps/chosen": -129.0188446044922,
      "logps/rejected": -183.09506225585938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.57908296585083,
      "rewards/margins": 10.491758346557617,
      "rewards/rejected": -8.912675857543945,
      "step": 2839
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 0.011430757120251656,
      "learning_rate": 6.214666666666666e-07,
      "logits/chosen": -2.2175445556640625,
      "logits/rejected": -3.5346696376800537,
      "logps/chosen": -136.11495971679688,
      "logps/rejected": -176.88845825195312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9431359767913818,
      "rewards/margins": 9.678661346435547,
      "rewards/rejected": -7.735526084899902,
      "step": 2840
    },
    {
      "epoch": 1.1364,
      "grad_norm": 0.030387485399842262,
      "learning_rate": 6.213333333333333e-07,
      "logits/chosen": -2.0569474697113037,
      "logits/rejected": -3.464763641357422,
      "logps/chosen": -118.51112365722656,
      "logps/rejected": -197.4420166015625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2647621631622314,
      "rewards/margins": 8.8443021774292,
      "rewards/rejected": -6.579540252685547,
      "step": 2841
    },
    {
      "epoch": 1.1368,
      "grad_norm": 2.5677366256713867,
      "learning_rate": 6.212e-07,
      "logits/chosen": -2.3759307861328125,
      "logits/rejected": -3.392732620239258,
      "logps/chosen": -109.294189453125,
      "logps/rejected": -174.9896240234375,
      "loss": 0.0235,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4388427734375,
      "rewards/margins": 8.095858573913574,
      "rewards/rejected": -6.657015800476074,
      "step": 2842
    },
    {
      "epoch": 1.1372,
      "grad_norm": 0.006905761547386646,
      "learning_rate": 6.210666666666667e-07,
      "logits/chosen": -2.635408401489258,
      "logits/rejected": -3.6040844917297363,
      "logps/chosen": -143.5236053466797,
      "logps/rejected": -167.02902221679688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.09857177734375,
      "rewards/margins": 10.52126693725586,
      "rewards/rejected": -6.422695159912109,
      "step": 2843
    },
    {
      "epoch": 1.1376,
      "grad_norm": 0.05340171605348587,
      "learning_rate": 6.209333333333334e-07,
      "logits/chosen": -1.8337867259979248,
      "logits/rejected": -3.6470742225646973,
      "logps/chosen": -136.96722412109375,
      "logps/rejected": -169.7265167236328,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5631630420684814,
      "rewards/margins": 8.622215270996094,
      "rewards/rejected": -7.059051990509033,
      "step": 2844
    },
    {
      "epoch": 1.138,
      "grad_norm": 0.11679238080978394,
      "learning_rate": 6.208e-07,
      "logits/chosen": -1.880165696144104,
      "logits/rejected": -3.0677711963653564,
      "logps/chosen": -142.6904296875,
      "logps/rejected": -155.8719482421875,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7133125066757202,
      "rewards/margins": 7.147932052612305,
      "rewards/rejected": -6.434619903564453,
      "step": 2845
    },
    {
      "epoch": 1.1384,
      "grad_norm": 0.03160783648490906,
      "learning_rate": 6.206666666666666e-07,
      "logits/chosen": -1.9004539251327515,
      "logits/rejected": -3.28371524810791,
      "logps/chosen": -75.37737274169922,
      "logps/rejected": -157.94203186035156,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6777546405792236,
      "rewards/margins": 8.732007026672363,
      "rewards/rejected": -6.054252624511719,
      "step": 2846
    },
    {
      "epoch": 1.1388,
      "grad_norm": 0.051568616181612015,
      "learning_rate": 6.205333333333333e-07,
      "logits/chosen": -2.2830862998962402,
      "logits/rejected": -3.26583194732666,
      "logps/chosen": -146.1939239501953,
      "logps/rejected": -160.88037109375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.558222532272339,
      "rewards/margins": 8.252742767333984,
      "rewards/rejected": -5.694519996643066,
      "step": 2847
    },
    {
      "epoch": 1.1392,
      "grad_norm": 0.001335959997959435,
      "learning_rate": 6.203999999999999e-07,
      "logits/chosen": -2.292445182800293,
      "logits/rejected": -3.4799623489379883,
      "logps/chosen": -81.78533935546875,
      "logps/rejected": -203.9288330078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8180158138275146,
      "rewards/margins": 11.75964069366455,
      "rewards/rejected": -7.941624641418457,
      "step": 2848
    },
    {
      "epoch": 1.1396,
      "grad_norm": 0.04939350485801697,
      "learning_rate": 6.202666666666666e-07,
      "logits/chosen": -1.7611401081085205,
      "logits/rejected": -3.323587417602539,
      "logps/chosen": -70.0777587890625,
      "logps/rejected": -137.7156982421875,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.11011004447937,
      "rewards/margins": 8.119963645935059,
      "rewards/rejected": -6.009853363037109,
      "step": 2849
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 18.780376434326172,
      "learning_rate": 6.201333333333333e-07,
      "logits/chosen": -3.153620481491089,
      "logits/rejected": -3.4845762252807617,
      "logps/chosen": -113.02851867675781,
      "logps/rejected": -152.36264038085938,
      "loss": 0.1925,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.295701503753662,
      "rewards/margins": 5.159595966339111,
      "rewards/rejected": -6.455297470092773,
      "step": 2850
    },
    {
      "epoch": 1.1404,
      "grad_norm": 0.10011966526508331,
      "learning_rate": 6.2e-07,
      "logits/chosen": -1.9925537109375,
      "logits/rejected": -2.9109389781951904,
      "logps/chosen": -150.98968505859375,
      "logps/rejected": -152.9516143798828,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2412383556365967,
      "rewards/margins": 6.813255310058594,
      "rewards/rejected": -5.572016716003418,
      "step": 2851
    },
    {
      "epoch": 1.1408,
      "grad_norm": 0.009752034209668636,
      "learning_rate": 6.198666666666667e-07,
      "logits/chosen": -2.116091251373291,
      "logits/rejected": -3.7325897216796875,
      "logps/chosen": -149.328369140625,
      "logps/rejected": -187.2447509765625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.437129497528076,
      "rewards/margins": 9.916009902954102,
      "rewards/rejected": -7.478880882263184,
      "step": 2852
    },
    {
      "epoch": 1.1412,
      "grad_norm": 0.26088428497314453,
      "learning_rate": 6.197333333333334e-07,
      "logits/chosen": -2.463327407836914,
      "logits/rejected": -3.657536029815674,
      "logps/chosen": -118.56828308105469,
      "logps/rejected": -126.72137451171875,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5513386726379395,
      "rewards/margins": 5.9940009117126465,
      "rewards/rejected": -3.442662239074707,
      "step": 2853
    },
    {
      "epoch": 1.1416,
      "grad_norm": 0.003468372393399477,
      "learning_rate": 6.196e-07,
      "logits/chosen": -2.356142044067383,
      "logits/rejected": -3.5759377479553223,
      "logps/chosen": -120.19358825683594,
      "logps/rejected": -162.7255096435547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2686877250671387,
      "rewards/margins": 10.455039978027344,
      "rewards/rejected": -7.186351299285889,
      "step": 2854
    },
    {
      "epoch": 1.142,
      "grad_norm": 0.05218867212533951,
      "learning_rate": 6.194666666666667e-07,
      "logits/chosen": -1.9044930934906006,
      "logits/rejected": -3.2050209045410156,
      "logps/chosen": -148.3740234375,
      "logps/rejected": -174.98245239257812,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.439878463745117,
      "rewards/margins": 9.339038848876953,
      "rewards/rejected": -6.899160385131836,
      "step": 2855
    },
    {
      "epoch": 1.1424,
      "grad_norm": 2.989572525024414,
      "learning_rate": 6.193333333333332e-07,
      "logits/chosen": -2.3373961448669434,
      "logits/rejected": -3.3519773483276367,
      "logps/chosen": -115.90166473388672,
      "logps/rejected": -166.48696899414062,
      "loss": 0.0156,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5871254205703735,
      "rewards/margins": 4.400521278381348,
      "rewards/rejected": -5.987646579742432,
      "step": 2856
    },
    {
      "epoch": 1.1428,
      "grad_norm": 0.0719837173819542,
      "learning_rate": 6.191999999999999e-07,
      "logits/chosen": -2.05674147605896,
      "logits/rejected": -2.948507785797119,
      "logps/chosen": -148.89596557617188,
      "logps/rejected": -166.032958984375,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2222018241882324,
      "rewards/margins": 7.788073539733887,
      "rewards/rejected": -5.5658721923828125,
      "step": 2857
    },
    {
      "epoch": 1.1432,
      "grad_norm": 0.7701191306114197,
      "learning_rate": 6.190666666666666e-07,
      "logits/chosen": -2.2086973190307617,
      "logits/rejected": -2.816047430038452,
      "logps/chosen": -98.11104583740234,
      "logps/rejected": -162.20217895507812,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.133732557296753,
      "rewards/margins": 8.125822067260742,
      "rewards/rejected": -5.99208927154541,
      "step": 2858
    },
    {
      "epoch": 1.1436,
      "grad_norm": 0.0003686733543872833,
      "learning_rate": 6.189333333333333e-07,
      "logits/chosen": -2.1236209869384766,
      "logits/rejected": -3.4944145679473877,
      "logps/chosen": -139.59747314453125,
      "logps/rejected": -204.10508728027344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.360988140106201,
      "rewards/margins": 12.690656661987305,
      "rewards/rejected": -8.329668998718262,
      "step": 2859
    },
    {
      "epoch": 1.144,
      "grad_norm": 0.0035023847594857216,
      "learning_rate": 6.188e-07,
      "logits/chosen": -2.0834999084472656,
      "logits/rejected": -3.2810096740722656,
      "logps/chosen": -102.51129150390625,
      "logps/rejected": -187.49447631835938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.668731689453125,
      "rewards/margins": 10.89447021484375,
      "rewards/rejected": -6.225739002227783,
      "step": 2860
    },
    {
      "epoch": 1.1444,
      "grad_norm": 0.28209954500198364,
      "learning_rate": 6.186666666666667e-07,
      "logits/chosen": -1.5955345630645752,
      "logits/rejected": -2.0419909954071045,
      "logps/chosen": -99.48544311523438,
      "logps/rejected": -103.801025390625,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9168879985809326,
      "rewards/margins": 6.48090934753418,
      "rewards/rejected": -3.564021587371826,
      "step": 2861
    },
    {
      "epoch": 1.1448,
      "grad_norm": 0.008403686806559563,
      "learning_rate": 6.185333333333334e-07,
      "logits/chosen": -2.1917357444763184,
      "logits/rejected": -3.3053269386291504,
      "logps/chosen": -111.17213439941406,
      "logps/rejected": -193.10842895507812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.484339714050293,
      "rewards/margins": 9.173999786376953,
      "rewards/rejected": -6.68966007232666,
      "step": 2862
    },
    {
      "epoch": 1.1452,
      "grad_norm": 0.008283930830657482,
      "learning_rate": 6.183999999999999e-07,
      "logits/chosen": -2.0653743743896484,
      "logits/rejected": -3.0445456504821777,
      "logps/chosen": -120.45118713378906,
      "logps/rejected": -205.68626403808594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.69718599319458,
      "rewards/margins": 9.963691711425781,
      "rewards/rejected": -7.266505718231201,
      "step": 2863
    },
    {
      "epoch": 1.1456,
      "grad_norm": 0.008884591050446033,
      "learning_rate": 6.182666666666666e-07,
      "logits/chosen": -2.07114577293396,
      "logits/rejected": -3.414071559906006,
      "logps/chosen": -186.28021240234375,
      "logps/rejected": -190.36923217773438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.107226610183716,
      "rewards/margins": 9.718986511230469,
      "rewards/rejected": -6.611760139465332,
      "step": 2864
    },
    {
      "epoch": 1.146,
      "grad_norm": 0.007574346847832203,
      "learning_rate": 6.181333333333333e-07,
      "logits/chosen": -2.0346298217773438,
      "logits/rejected": -3.5407533645629883,
      "logps/chosen": -138.732177734375,
      "logps/rejected": -173.70504760742188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.478311061859131,
      "rewards/margins": 9.857425689697266,
      "rewards/rejected": -6.379115104675293,
      "step": 2865
    },
    {
      "epoch": 1.1464,
      "grad_norm": 0.002148375613614917,
      "learning_rate": 6.18e-07,
      "logits/chosen": -1.7803077697753906,
      "logits/rejected": -3.7717843055725098,
      "logps/chosen": -71.19746398925781,
      "logps/rejected": -170.18032836914062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5894412994384766,
      "rewards/margins": 10.909005165100098,
      "rewards/rejected": -8.319562911987305,
      "step": 2866
    },
    {
      "epoch": 1.1468,
      "grad_norm": 0.018649259582161903,
      "learning_rate": 6.178666666666666e-07,
      "logits/chosen": -2.480107069015503,
      "logits/rejected": -3.3122503757476807,
      "logps/chosen": -127.0744400024414,
      "logps/rejected": -165.43722534179688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.53141713142395,
      "rewards/margins": 8.882914543151855,
      "rewards/rejected": -5.351497650146484,
      "step": 2867
    },
    {
      "epoch": 1.1472,
      "grad_norm": 0.00642590643838048,
      "learning_rate": 6.177333333333333e-07,
      "logits/chosen": -2.1355509757995605,
      "logits/rejected": -2.847940444946289,
      "logps/chosen": -120.36793518066406,
      "logps/rejected": -153.50857543945312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7713255882263184,
      "rewards/margins": 10.017051696777344,
      "rewards/rejected": -6.245726585388184,
      "step": 2868
    },
    {
      "epoch": 1.1476,
      "grad_norm": 0.1069057360291481,
      "learning_rate": 6.176e-07,
      "logits/chosen": -2.463131904602051,
      "logits/rejected": -3.371931791305542,
      "logps/chosen": -92.77101135253906,
      "logps/rejected": -209.7374267578125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9910359382629395,
      "rewards/margins": 10.295549392700195,
      "rewards/rejected": -8.304513931274414,
      "step": 2869
    },
    {
      "epoch": 1.148,
      "grad_norm": 0.28682056069374084,
      "learning_rate": 6.174666666666667e-07,
      "logits/chosen": -1.8194189071655273,
      "logits/rejected": -3.4787964820861816,
      "logps/chosen": -123.1348876953125,
      "logps/rejected": -163.69810485839844,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3856831789016724,
      "rewards/margins": 9.141263961791992,
      "rewards/rejected": -7.755580902099609,
      "step": 2870
    },
    {
      "epoch": 1.1484,
      "grad_norm": 0.00929346401244402,
      "learning_rate": 6.173333333333333e-07,
      "logits/chosen": -2.578979015350342,
      "logits/rejected": -3.9272353649139404,
      "logps/chosen": -83.10726928710938,
      "logps/rejected": -185.13336181640625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.487075090408325,
      "rewards/margins": 10.443841934204102,
      "rewards/rejected": -6.956766605377197,
      "step": 2871
    },
    {
      "epoch": 1.1488,
      "grad_norm": 0.08793719857931137,
      "learning_rate": 6.172e-07,
      "logits/chosen": -2.2531063556671143,
      "logits/rejected": -2.9072351455688477,
      "logps/chosen": -128.73834228515625,
      "logps/rejected": -175.50173950195312,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.581388473510742,
      "rewards/margins": 9.061622619628906,
      "rewards/rejected": -6.480234146118164,
      "step": 2872
    },
    {
      "epoch": 1.1492,
      "grad_norm": 0.03881549835205078,
      "learning_rate": 6.170666666666666e-07,
      "logits/chosen": -2.5231103897094727,
      "logits/rejected": -3.941438674926758,
      "logps/chosen": -100.25988006591797,
      "logps/rejected": -224.62750244140625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.21708832681179047,
      "rewards/margins": 7.9605865478515625,
      "rewards/rejected": -8.177675247192383,
      "step": 2873
    },
    {
      "epoch": 1.1496,
      "grad_norm": 0.025221766903996468,
      "learning_rate": 6.169333333333333e-07,
      "logits/chosen": -2.241162061691284,
      "logits/rejected": -3.216066360473633,
      "logps/chosen": -96.4793701171875,
      "logps/rejected": -215.20323181152344,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.095275640487671,
      "rewards/margins": 9.337814331054688,
      "rewards/rejected": -7.2425384521484375,
      "step": 2874
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.009375246241688728,
      "learning_rate": 6.168e-07,
      "logits/chosen": -1.9508795738220215,
      "logits/rejected": -3.221674919128418,
      "logps/chosen": -132.33929443359375,
      "logps/rejected": -171.99087524414062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.915485382080078,
      "rewards/margins": 10.164163589477539,
      "rewards/rejected": -7.2486772537231445,
      "step": 2875
    },
    {
      "epoch": 1.1504,
      "grad_norm": 0.0073225912638008595,
      "learning_rate": 6.166666666666667e-07,
      "logits/chosen": -1.7695693969726562,
      "logits/rejected": -3.467344284057617,
      "logps/chosen": -92.87722778320312,
      "logps/rejected": -217.28585815429688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6075302362442017,
      "rewards/margins": 11.048383712768555,
      "rewards/rejected": -9.440853118896484,
      "step": 2876
    },
    {
      "epoch": 1.1508,
      "grad_norm": 0.15619024634361267,
      "learning_rate": 6.165333333333333e-07,
      "logits/chosen": -1.7143383026123047,
      "logits/rejected": -3.3517203330993652,
      "logps/chosen": -113.62616729736328,
      "logps/rejected": -159.35702514648438,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2985862493515015,
      "rewards/margins": 7.858233451843262,
      "rewards/rejected": -6.559647560119629,
      "step": 2877
    },
    {
      "epoch": 1.1512,
      "grad_norm": 0.07220827788114548,
      "learning_rate": 6.163999999999999e-07,
      "logits/chosen": -2.0732197761535645,
      "logits/rejected": -3.5130791664123535,
      "logps/chosen": -200.39044189453125,
      "logps/rejected": -215.1451416015625,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6529785394668579,
      "rewards/margins": 7.894182205200195,
      "rewards/rejected": -7.241203308105469,
      "step": 2878
    },
    {
      "epoch": 1.1516,
      "grad_norm": 0.08151626586914062,
      "learning_rate": 6.162666666666666e-07,
      "logits/chosen": -2.193286418914795,
      "logits/rejected": -3.399397134780884,
      "logps/chosen": -68.8507080078125,
      "logps/rejected": -163.0499725341797,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.23580265045166,
      "rewards/margins": 9.040069580078125,
      "rewards/rejected": -5.804266929626465,
      "step": 2879
    },
    {
      "epoch": 1.152,
      "grad_norm": 0.015501449815928936,
      "learning_rate": 6.161333333333333e-07,
      "logits/chosen": -2.5448498725891113,
      "logits/rejected": -3.286714553833008,
      "logps/chosen": -139.27931213378906,
      "logps/rejected": -212.2603759765625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.349177360534668,
      "rewards/margins": 10.570534706115723,
      "rewards/rejected": -8.221357345581055,
      "step": 2880
    },
    {
      "epoch": 1.1524,
      "grad_norm": 0.16247639060020447,
      "learning_rate": 6.16e-07,
      "logits/chosen": -2.185772180557251,
      "logits/rejected": -2.2964556217193604,
      "logps/chosen": -120.14569091796875,
      "logps/rejected": -165.97494506835938,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3297383785247803,
      "rewards/margins": 9.65634536743164,
      "rewards/rejected": -6.3266072273254395,
      "step": 2881
    },
    {
      "epoch": 1.1528,
      "grad_norm": 0.0048258258029818535,
      "learning_rate": 6.158666666666666e-07,
      "logits/chosen": -1.9277663230895996,
      "logits/rejected": -3.017396926879883,
      "logps/chosen": -124.5396728515625,
      "logps/rejected": -238.58872985839844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1507821083068848,
      "rewards/margins": 12.964078903198242,
      "rewards/rejected": -10.813297271728516,
      "step": 2882
    },
    {
      "epoch": 1.1532,
      "grad_norm": 0.028602106496691704,
      "learning_rate": 6.157333333333333e-07,
      "logits/chosen": -2.2995994091033936,
      "logits/rejected": -3.264963150024414,
      "logps/chosen": -156.85113525390625,
      "logps/rejected": -194.337646484375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5770232677459717,
      "rewards/margins": 9.084036827087402,
      "rewards/rejected": -6.50701379776001,
      "step": 2883
    },
    {
      "epoch": 1.1536,
      "grad_norm": 0.6776407957077026,
      "learning_rate": 6.156e-07,
      "logits/chosen": -1.5954062938690186,
      "logits/rejected": -3.3917460441589355,
      "logps/chosen": -125.65855407714844,
      "logps/rejected": -148.75567626953125,
      "loss": 0.0064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6021179556846619,
      "rewards/margins": 5.3223676681518555,
      "rewards/rejected": -5.92448616027832,
      "step": 2884
    },
    {
      "epoch": 1.154,
      "grad_norm": 0.02512546069920063,
      "learning_rate": 6.154666666666667e-07,
      "logits/chosen": -2.0034122467041016,
      "logits/rejected": -3.13045597076416,
      "logps/chosen": -120.18040466308594,
      "logps/rejected": -133.07272338867188,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2319412231445312,
      "rewards/margins": 8.081133842468262,
      "rewards/rejected": -5.8491926193237305,
      "step": 2885
    },
    {
      "epoch": 1.1544,
      "grad_norm": 0.07070517539978027,
      "learning_rate": 6.153333333333333e-07,
      "logits/chosen": -2.588743209838867,
      "logits/rejected": -3.4385299682617188,
      "logps/chosen": -78.36421966552734,
      "logps/rejected": -166.37152099609375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7379270792007446,
      "rewards/margins": 8.528984069824219,
      "rewards/rejected": -7.791057586669922,
      "step": 2886
    },
    {
      "epoch": 1.1548,
      "grad_norm": 0.013288038782775402,
      "learning_rate": 6.152e-07,
      "logits/chosen": -2.475696325302124,
      "logits/rejected": -3.929123878479004,
      "logps/chosen": -101.20176696777344,
      "logps/rejected": -206.24436950683594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.857363224029541,
      "rewards/margins": 9.962955474853516,
      "rewards/rejected": -7.105592727661133,
      "step": 2887
    },
    {
      "epoch": 1.1552,
      "grad_norm": 0.0017311132978647947,
      "learning_rate": 6.150666666666666e-07,
      "logits/chosen": -2.5754647254943848,
      "logits/rejected": -3.8216118812561035,
      "logps/chosen": -150.96559143066406,
      "logps/rejected": -223.39199829101562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7435178756713867,
      "rewards/margins": 11.54804801940918,
      "rewards/rejected": -7.804530143737793,
      "step": 2888
    },
    {
      "epoch": 1.1556,
      "grad_norm": 0.007778258062899113,
      "learning_rate": 6.149333333333333e-07,
      "logits/chosen": -1.9994795322418213,
      "logits/rejected": -3.418696165084839,
      "logps/chosen": -157.83387756347656,
      "logps/rejected": -207.5703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8940906524658203,
      "rewards/margins": 11.342424392700195,
      "rewards/rejected": -8.448333740234375,
      "step": 2889
    },
    {
      "epoch": 1.156,
      "grad_norm": 0.005593552254140377,
      "learning_rate": 6.148e-07,
      "logits/chosen": -1.6631584167480469,
      "logits/rejected": -3.47344970703125,
      "logps/chosen": -88.30755615234375,
      "logps/rejected": -199.5049591064453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.882737398147583,
      "rewards/margins": 11.056718826293945,
      "rewards/rejected": -8.173981666564941,
      "step": 2890
    },
    {
      "epoch": 1.1564,
      "grad_norm": 0.008044393733143806,
      "learning_rate": 6.146666666666667e-07,
      "logits/chosen": -2.062075138092041,
      "logits/rejected": -3.324799060821533,
      "logps/chosen": -104.77816772460938,
      "logps/rejected": -166.69818115234375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.860145092010498,
      "rewards/margins": 9.917564392089844,
      "rewards/rejected": -7.0574188232421875,
      "step": 2891
    },
    {
      "epoch": 1.1568,
      "grad_norm": 0.15297046303749084,
      "learning_rate": 6.145333333333333e-07,
      "logits/chosen": -2.2839298248291016,
      "logits/rejected": -3.1747865676879883,
      "logps/chosen": -121.4920883178711,
      "logps/rejected": -144.59222412109375,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1641188859939575,
      "rewards/margins": 6.4327287673950195,
      "rewards/rejected": -5.268610000610352,
      "step": 2892
    },
    {
      "epoch": 1.1572,
      "grad_norm": 0.033004727214574814,
      "learning_rate": 6.143999999999999e-07,
      "logits/chosen": -2.210296154022217,
      "logits/rejected": -3.2491393089294434,
      "logps/chosen": -146.83106994628906,
      "logps/rejected": -215.65496826171875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3049089908599854,
      "rewards/margins": 11.067758560180664,
      "rewards/rejected": -8.762849807739258,
      "step": 2893
    },
    {
      "epoch": 1.1576,
      "grad_norm": 0.06318455934524536,
      "learning_rate": 6.142666666666666e-07,
      "logits/chosen": -1.9114458560943604,
      "logits/rejected": -2.7467236518859863,
      "logps/chosen": -138.70330810546875,
      "logps/rejected": -138.83856201171875,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.009751796722412,
      "rewards/margins": 7.571666240692139,
      "rewards/rejected": -5.561914443969727,
      "step": 2894
    },
    {
      "epoch": 1.158,
      "grad_norm": 0.013343634083867073,
      "learning_rate": 6.141333333333333e-07,
      "logits/chosen": -1.9672328233718872,
      "logits/rejected": -3.4221858978271484,
      "logps/chosen": -178.29220581054688,
      "logps/rejected": -171.97964477539062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.5398783683776855,
      "rewards/margins": 10.082441329956055,
      "rewards/rejected": -5.542563438415527,
      "step": 2895
    },
    {
      "epoch": 1.1584,
      "grad_norm": 0.057589638978242874,
      "learning_rate": 6.14e-07,
      "logits/chosen": -2.3237464427948,
      "logits/rejected": -3.3871827125549316,
      "logps/chosen": -133.81138610839844,
      "logps/rejected": -178.8948974609375,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.555490493774414,
      "rewards/margins": 7.507344722747803,
      "rewards/rejected": -5.951854228973389,
      "step": 2896
    },
    {
      "epoch": 1.1588,
      "grad_norm": 0.03678265959024429,
      "learning_rate": 6.138666666666667e-07,
      "logits/chosen": -1.9542005062103271,
      "logits/rejected": -3.204657554626465,
      "logps/chosen": -80.25953674316406,
      "logps/rejected": -145.2950439453125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.420149803161621,
      "rewards/margins": 8.378013610839844,
      "rewards/rejected": -5.957864761352539,
      "step": 2897
    },
    {
      "epoch": 1.1592,
      "grad_norm": 1.2026386260986328,
      "learning_rate": 6.137333333333333e-07,
      "logits/chosen": -2.1609103679656982,
      "logits/rejected": -2.7866644859313965,
      "logps/chosen": -120.54331970214844,
      "logps/rejected": -129.90464782714844,
      "loss": 0.0139,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6600937843322754,
      "rewards/margins": 6.47783088684082,
      "rewards/rejected": -3.817737102508545,
      "step": 2898
    },
    {
      "epoch": 1.1596,
      "grad_norm": 0.028056669980287552,
      "learning_rate": 6.136e-07,
      "logits/chosen": -2.3447928428649902,
      "logits/rejected": -3.214937686920166,
      "logps/chosen": -164.8123321533203,
      "logps/rejected": -163.2607879638672,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9956916570663452,
      "rewards/margins": 8.299455642700195,
      "rewards/rejected": -7.303763389587402,
      "step": 2899
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.3234281539916992,
      "learning_rate": 6.134666666666667e-07,
      "logits/chosen": -2.5652334690093994,
      "logits/rejected": -3.5490283966064453,
      "logps/chosen": -102.69740295410156,
      "logps/rejected": -207.2781982421875,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5739345550537109,
      "rewards/margins": 7.951740264892578,
      "rewards/rejected": -7.377805709838867,
      "step": 2900
    },
    {
      "epoch": 1.1604,
      "grad_norm": 0.0012254103785380721,
      "learning_rate": 6.133333333333332e-07,
      "logits/chosen": -2.165947914123535,
      "logits/rejected": -3.0029983520507812,
      "logps/chosen": -107.74163818359375,
      "logps/rejected": -192.16458129882812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.886878490447998,
      "rewards/margins": 11.914429664611816,
      "rewards/rejected": -8.027551651000977,
      "step": 2901
    },
    {
      "epoch": 1.1608,
      "grad_norm": 0.016820434480905533,
      "learning_rate": 6.131999999999999e-07,
      "logits/chosen": -2.0761919021606445,
      "logits/rejected": -2.9083895683288574,
      "logps/chosen": -94.21247100830078,
      "logps/rejected": -172.78392028808594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.085012912750244,
      "rewards/margins": 10.908111572265625,
      "rewards/rejected": -6.823098182678223,
      "step": 2902
    },
    {
      "epoch": 1.1612,
      "grad_norm": 0.7225061655044556,
      "learning_rate": 6.130666666666666e-07,
      "logits/chosen": -2.4341206550598145,
      "logits/rejected": -2.3594887256622314,
      "logps/chosen": -187.09140014648438,
      "logps/rejected": -150.1459197998047,
      "loss": 0.0055,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4510756731033325,
      "rewards/margins": 6.71329402923584,
      "rewards/rejected": -5.262218475341797,
      "step": 2903
    },
    {
      "epoch": 1.1616,
      "grad_norm": 0.009000339545309544,
      "learning_rate": 6.129333333333333e-07,
      "logits/chosen": -2.6091771125793457,
      "logits/rejected": -3.2767062187194824,
      "logps/chosen": -85.16143798828125,
      "logps/rejected": -155.2266082763672,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7428481578826904,
      "rewards/margins": 10.12919807434082,
      "rewards/rejected": -6.386349678039551,
      "step": 2904
    },
    {
      "epoch": 1.162,
      "grad_norm": 0.6059709191322327,
      "learning_rate": 6.128e-07,
      "logits/chosen": -2.2770304679870605,
      "logits/rejected": -3.205678939819336,
      "logps/chosen": -91.5676498413086,
      "logps/rejected": -166.88790893554688,
      "loss": 0.0059,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2017536163330078,
      "rewards/margins": 7.593939781188965,
      "rewards/rejected": -7.795693397521973,
      "step": 2905
    },
    {
      "epoch": 1.1623999999999999,
      "grad_norm": 0.0043413336388766766,
      "learning_rate": 6.126666666666667e-07,
      "logits/chosen": -2.063633441925049,
      "logits/rejected": -2.7653768062591553,
      "logps/chosen": -188.40338134765625,
      "logps/rejected": -203.25489807128906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4999191761016846,
      "rewards/margins": 10.182854652404785,
      "rewards/rejected": -7.6829352378845215,
      "step": 2906
    },
    {
      "epoch": 1.1628,
      "grad_norm": 0.007578603457659483,
      "learning_rate": 6.125333333333334e-07,
      "logits/chosen": -2.020207405090332,
      "logits/rejected": -3.3537368774414062,
      "logps/chosen": -121.51310729980469,
      "logps/rejected": -170.52734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.530982494354248,
      "rewards/margins": 11.329839706420898,
      "rewards/rejected": -7.798856735229492,
      "step": 2907
    },
    {
      "epoch": 1.1632,
      "grad_norm": 0.005482071079313755,
      "learning_rate": 6.124000000000001e-07,
      "logits/chosen": -2.0662317276000977,
      "logits/rejected": -3.617340564727783,
      "logps/chosen": -109.37411499023438,
      "logps/rejected": -183.2929229736328,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9531373977661133,
      "rewards/margins": 10.704765319824219,
      "rewards/rejected": -7.7516279220581055,
      "step": 2908
    },
    {
      "epoch": 1.1636,
      "grad_norm": 0.06229551509022713,
      "learning_rate": 6.122666666666666e-07,
      "logits/chosen": -1.6824662685394287,
      "logits/rejected": -2.3534374237060547,
      "logps/chosen": -126.55330657958984,
      "logps/rejected": -116.71641540527344,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.987037181854248,
      "rewards/margins": 8.058406829833984,
      "rewards/rejected": -5.071369171142578,
      "step": 2909
    },
    {
      "epoch": 1.164,
      "grad_norm": 0.017272938042879105,
      "learning_rate": 6.121333333333332e-07,
      "logits/chosen": -2.1939311027526855,
      "logits/rejected": -3.2285714149475098,
      "logps/chosen": -92.72966003417969,
      "logps/rejected": -171.90187072753906,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.977617025375366,
      "rewards/margins": 9.747386932373047,
      "rewards/rejected": -6.76977014541626,
      "step": 2910
    },
    {
      "epoch": 1.1644,
      "grad_norm": 0.011299367994070053,
      "learning_rate": 6.119999999999999e-07,
      "logits/chosen": -2.611450433731079,
      "logits/rejected": -3.1980137825012207,
      "logps/chosen": -140.0802459716797,
      "logps/rejected": -170.05828857421875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9955506324768066,
      "rewards/margins": 10.792505264282227,
      "rewards/rejected": -6.796954154968262,
      "step": 2911
    },
    {
      "epoch": 1.1648,
      "grad_norm": 0.22708307206630707,
      "learning_rate": 6.118666666666666e-07,
      "logits/chosen": -2.2481603622436523,
      "logits/rejected": -2.8045527935028076,
      "logps/chosen": -127.98812866210938,
      "logps/rejected": -150.10812377929688,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5041557550430298,
      "rewards/margins": 6.567734718322754,
      "rewards/rejected": -6.063579559326172,
      "step": 2912
    },
    {
      "epoch": 1.1652,
      "grad_norm": 0.0009751825127750635,
      "learning_rate": 6.117333333333333e-07,
      "logits/chosen": -2.6248693466186523,
      "logits/rejected": -3.3948774337768555,
      "logps/chosen": -154.78086853027344,
      "logps/rejected": -212.5840606689453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.011446952819824,
      "rewards/margins": 13.575898170471191,
      "rewards/rejected": -9.564451217651367,
      "step": 2913
    },
    {
      "epoch": 1.1656,
      "grad_norm": 8.208962440490723,
      "learning_rate": 6.116e-07,
      "logits/chosen": -2.181004524230957,
      "logits/rejected": -3.147979736328125,
      "logps/chosen": -212.81698608398438,
      "logps/rejected": -136.83937072753906,
      "loss": 0.0786,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5965843200683594,
      "rewards/margins": 6.35994815826416,
      "rewards/rejected": -5.763363838195801,
      "step": 2914
    },
    {
      "epoch": 1.166,
      "grad_norm": 0.07351601868867874,
      "learning_rate": 6.114666666666667e-07,
      "logits/chosen": -2.0649967193603516,
      "logits/rejected": -2.5015783309936523,
      "logps/chosen": -113.27404022216797,
      "logps/rejected": -130.30026245117188,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5372223258018494,
      "rewards/margins": 7.21147346496582,
      "rewards/rejected": -6.674251079559326,
      "step": 2915
    },
    {
      "epoch": 1.1663999999999999,
      "grad_norm": 0.0030748071148991585,
      "learning_rate": 6.113333333333333e-07,
      "logits/chosen": -2.5166492462158203,
      "logits/rejected": -3.608529567718506,
      "logps/chosen": -155.11224365234375,
      "logps/rejected": -180.63294982910156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.720925331115723,
      "rewards/margins": 11.76595687866211,
      "rewards/rejected": -7.045032501220703,
      "step": 2916
    },
    {
      "epoch": 1.1668,
      "grad_norm": 0.0774555653333664,
      "learning_rate": 6.112e-07,
      "logits/chosen": -2.062835931777954,
      "logits/rejected": -3.33012318611145,
      "logps/chosen": -98.9752426147461,
      "logps/rejected": -165.18809509277344,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4384665489196777,
      "rewards/margins": 8.17776107788086,
      "rewards/rejected": -5.739294528961182,
      "step": 2917
    },
    {
      "epoch": 1.1672,
      "grad_norm": 0.2796062231063843,
      "learning_rate": 6.110666666666667e-07,
      "logits/chosen": -2.7171459197998047,
      "logits/rejected": -3.6578545570373535,
      "logps/chosen": -123.8581771850586,
      "logps/rejected": -165.9907989501953,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0946277379989624,
      "rewards/margins": 6.769827842712402,
      "rewards/rejected": -7.8644561767578125,
      "step": 2918
    },
    {
      "epoch": 1.1676,
      "grad_norm": 0.01530269905924797,
      "learning_rate": 6.109333333333334e-07,
      "logits/chosen": -1.9975042343139648,
      "logits/rejected": -2.9730982780456543,
      "logps/chosen": -125.05791473388672,
      "logps/rejected": -136.00958251953125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.604506254196167,
      "rewards/margins": 8.818721771240234,
      "rewards/rejected": -6.214215278625488,
      "step": 2919
    },
    {
      "epoch": 1.168,
      "grad_norm": 0.09792489558458328,
      "learning_rate": 6.107999999999999e-07,
      "logits/chosen": -2.7419872283935547,
      "logits/rejected": -3.6244330406188965,
      "logps/chosen": -175.61495971679688,
      "logps/rejected": -176.0227813720703,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7993590831756592,
      "rewards/margins": 8.426801681518555,
      "rewards/rejected": -7.627443313598633,
      "step": 2920
    },
    {
      "epoch": 1.1684,
      "grad_norm": 0.11147426068782806,
      "learning_rate": 6.106666666666666e-07,
      "logits/chosen": -2.19299054145813,
      "logits/rejected": -3.804720163345337,
      "logps/chosen": -148.06399536132812,
      "logps/rejected": -140.17959594726562,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1929337978363037,
      "rewards/margins": 7.94661283493042,
      "rewards/rejected": -5.753679275512695,
      "step": 2921
    },
    {
      "epoch": 1.1688,
      "grad_norm": 0.017590966075658798,
      "learning_rate": 6.105333333333333e-07,
      "logits/chosen": -2.354793071746826,
      "logits/rejected": -2.90512752532959,
      "logps/chosen": -161.45599365234375,
      "logps/rejected": -204.4562225341797,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9012038707733154,
      "rewards/margins": 10.45207405090332,
      "rewards/rejected": -7.550869941711426,
      "step": 2922
    },
    {
      "epoch": 1.1692,
      "grad_norm": 0.22572970390319824,
      "learning_rate": 6.104e-07,
      "logits/chosen": -1.660869836807251,
      "logits/rejected": -3.1338086128234863,
      "logps/chosen": -73.02322387695312,
      "logps/rejected": -151.07534790039062,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6732697486877441,
      "rewards/margins": 6.306631088256836,
      "rewards/rejected": -4.633361339569092,
      "step": 2923
    },
    {
      "epoch": 1.1696,
      "grad_norm": 0.30086883902549744,
      "learning_rate": 6.102666666666666e-07,
      "logits/chosen": -2.631608486175537,
      "logits/rejected": -3.705400228500366,
      "logps/chosen": -140.7926483154297,
      "logps/rejected": -174.4517822265625,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9381866455078125,
      "rewards/margins": 6.93380069732666,
      "rewards/rejected": -5.9956135749816895,
      "step": 2924
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.0031469028908759356,
      "learning_rate": 6.101333333333333e-07,
      "logits/chosen": -2.1516988277435303,
      "logits/rejected": -3.0968079566955566,
      "logps/chosen": -129.378662109375,
      "logps/rejected": -191.70883178710938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.879014015197754,
      "rewards/margins": 12.65941333770752,
      "rewards/rejected": -7.780399322509766,
      "step": 2925
    },
    {
      "epoch": 1.1703999999999999,
      "grad_norm": 0.42884179949760437,
      "learning_rate": 6.1e-07,
      "logits/chosen": -1.9753611087799072,
      "logits/rejected": -3.3295016288757324,
      "logps/chosen": -129.39794921875,
      "logps/rejected": -184.45120239257812,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.04308471083641052,
      "rewards/margins": 7.281163215637207,
      "rewards/rejected": -7.324247360229492,
      "step": 2926
    },
    {
      "epoch": 1.1708,
      "grad_norm": 0.059500131756067276,
      "learning_rate": 6.098666666666667e-07,
      "logits/chosen": -3.039883852005005,
      "logits/rejected": -3.2699615955352783,
      "logps/chosen": -266.2032165527344,
      "logps/rejected": -205.6183319091797,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.888388156890869,
      "rewards/margins": 8.268901824951172,
      "rewards/rejected": -5.380513668060303,
      "step": 2927
    },
    {
      "epoch": 1.1712,
      "grad_norm": 0.022922297939658165,
      "learning_rate": 6.097333333333334e-07,
      "logits/chosen": -2.6050832271575928,
      "logits/rejected": -3.827333450317383,
      "logps/chosen": -171.82867431640625,
      "logps/rejected": -233.94915771484375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.882943868637085,
      "rewards/margins": 10.273378372192383,
      "rewards/rejected": -8.390434265136719,
      "step": 2928
    },
    {
      "epoch": 1.1716,
      "grad_norm": 4.240311145782471,
      "learning_rate": 6.096e-07,
      "logits/chosen": -2.755507469177246,
      "logits/rejected": -3.2515790462493896,
      "logps/chosen": -136.35379028320312,
      "logps/rejected": -129.27102661132812,
      "loss": 0.0344,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6293953061103821,
      "rewards/margins": 4.438146591186523,
      "rewards/rejected": -5.067541599273682,
      "step": 2929
    },
    {
      "epoch": 1.172,
      "grad_norm": 0.030650515109300613,
      "learning_rate": 6.094666666666666e-07,
      "logits/chosen": -2.674337148666382,
      "logits/rejected": -2.9833645820617676,
      "logps/chosen": -188.197509765625,
      "logps/rejected": -241.4534912109375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.288127899169922,
      "rewards/margins": 8.550640106201172,
      "rewards/rejected": -5.262511730194092,
      "step": 2930
    },
    {
      "epoch": 1.1724,
      "grad_norm": 0.007300292141735554,
      "learning_rate": 6.093333333333332e-07,
      "logits/chosen": -2.373063087463379,
      "logits/rejected": -2.7557783126831055,
      "logps/chosen": -127.27247619628906,
      "logps/rejected": -188.0891876220703,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.200552463531494,
      "rewards/margins": 9.664693832397461,
      "rewards/rejected": -6.464140892028809,
      "step": 2931
    },
    {
      "epoch": 1.1728,
      "grad_norm": 0.006010401528328657,
      "learning_rate": 6.091999999999999e-07,
      "logits/chosen": -1.8398044109344482,
      "logits/rejected": -3.3488240242004395,
      "logps/chosen": -89.82564544677734,
      "logps/rejected": -222.4752655029297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3560749292373657,
      "rewards/margins": 10.706873893737793,
      "rewards/rejected": -9.350799560546875,
      "step": 2932
    },
    {
      "epoch": 1.1732,
      "grad_norm": 0.015100887045264244,
      "learning_rate": 6.090666666666666e-07,
      "logits/chosen": -2.1101040840148926,
      "logits/rejected": -3.2302961349487305,
      "logps/chosen": -111.69972229003906,
      "logps/rejected": -162.76206970214844,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.885016918182373,
      "rewards/margins": 9.247820854187012,
      "rewards/rejected": -6.3628034591674805,
      "step": 2933
    },
    {
      "epoch": 1.1736,
      "grad_norm": 0.022642875090241432,
      "learning_rate": 6.089333333333333e-07,
      "logits/chosen": -2.556090831756592,
      "logits/rejected": -2.644850730895996,
      "logps/chosen": -92.56948852539062,
      "logps/rejected": -167.76231384277344,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9285120964050293,
      "rewards/margins": 8.783780097961426,
      "rewards/rejected": -6.855268478393555,
      "step": 2934
    },
    {
      "epoch": 1.174,
      "grad_norm": 0.1970887929201126,
      "learning_rate": 6.088e-07,
      "logits/chosen": -2.032320976257324,
      "logits/rejected": -3.245060682296753,
      "logps/chosen": -152.986083984375,
      "logps/rejected": -217.19920349121094,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3043479919433594,
      "rewards/margins": 7.1555023193359375,
      "rewards/rejected": -6.851154327392578,
      "step": 2935
    },
    {
      "epoch": 1.1743999999999999,
      "grad_norm": 0.036948125809431076,
      "learning_rate": 6.086666666666667e-07,
      "logits/chosen": -2.2532081604003906,
      "logits/rejected": -2.8022079467773438,
      "logps/chosen": -88.04862976074219,
      "logps/rejected": -155.83274841308594,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.487156629562378,
      "rewards/margins": 8.01551628112793,
      "rewards/rejected": -6.528359413146973,
      "step": 2936
    },
    {
      "epoch": 1.1748,
      "grad_norm": 0.20499418675899506,
      "learning_rate": 6.085333333333334e-07,
      "logits/chosen": -1.9696393013000488,
      "logits/rejected": -3.3527636528015137,
      "logps/chosen": -134.42083740234375,
      "logps/rejected": -162.00767517089844,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.037057876586914,
      "rewards/margins": 7.595127582550049,
      "rewards/rejected": -6.558069705963135,
      "step": 2937
    },
    {
      "epoch": 1.1752,
      "grad_norm": 0.011518510989844799,
      "learning_rate": 6.084000000000001e-07,
      "logits/chosen": -2.4587161540985107,
      "logits/rejected": -3.084573745727539,
      "logps/chosen": -130.6427459716797,
      "logps/rejected": -170.52505493164062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.241713047027588,
      "rewards/margins": 10.722257614135742,
      "rewards/rejected": -6.4805450439453125,
      "step": 2938
    },
    {
      "epoch": 1.1756,
      "grad_norm": 4.82632303237915,
      "learning_rate": 6.082666666666666e-07,
      "logits/chosen": -2.1571669578552246,
      "logits/rejected": -3.4968042373657227,
      "logps/chosen": -80.28030395507812,
      "logps/rejected": -143.7224884033203,
      "loss": 0.0243,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3397499322891235,
      "rewards/margins": 5.814924716949463,
      "rewards/rejected": -4.475174903869629,
      "step": 2939
    },
    {
      "epoch": 1.176,
      "grad_norm": 0.08175607770681381,
      "learning_rate": 6.081333333333332e-07,
      "logits/chosen": -2.0709636211395264,
      "logits/rejected": -3.130635976791382,
      "logps/chosen": -155.22799682617188,
      "logps/rejected": -192.12997436523438,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5391170978546143,
      "rewards/margins": 8.98958683013916,
      "rewards/rejected": -6.450469493865967,
      "step": 2940
    },
    {
      "epoch": 1.1764000000000001,
      "grad_norm": 0.005458765663206577,
      "learning_rate": 6.079999999999999e-07,
      "logits/chosen": -2.5275914669036865,
      "logits/rejected": -3.882877826690674,
      "logps/chosen": -120.33454895019531,
      "logps/rejected": -151.1190185546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.743624448776245,
      "rewards/margins": 9.804034233093262,
      "rewards/rejected": -6.060410022735596,
      "step": 2941
    },
    {
      "epoch": 1.1768,
      "grad_norm": 0.0057812584564089775,
      "learning_rate": 6.078666666666666e-07,
      "logits/chosen": -2.1787118911743164,
      "logits/rejected": -3.3660764694213867,
      "logps/chosen": -180.5687255859375,
      "logps/rejected": -248.1680450439453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5731873512268066,
      "rewards/margins": 11.86037540435791,
      "rewards/rejected": -11.287187576293945,
      "step": 2942
    },
    {
      "epoch": 1.1772,
      "grad_norm": 0.009563100524246693,
      "learning_rate": 6.077333333333333e-07,
      "logits/chosen": -1.8090622425079346,
      "logits/rejected": -3.051875114440918,
      "logps/chosen": -72.93247985839844,
      "logps/rejected": -143.17767333984375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5361719131469727,
      "rewards/margins": 9.315296173095703,
      "rewards/rejected": -6.7791242599487305,
      "step": 2943
    },
    {
      "epoch": 1.1776,
      "grad_norm": 0.004262357018887997,
      "learning_rate": 6.076e-07,
      "logits/chosen": -2.3268420696258545,
      "logits/rejected": -3.887803077697754,
      "logps/chosen": -141.082763671875,
      "logps/rejected": -163.41000366210938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5053539276123047,
      "rewards/margins": 10.625648498535156,
      "rewards/rejected": -8.120294570922852,
      "step": 2944
    },
    {
      "epoch": 1.178,
      "grad_norm": 2.7947373390197754,
      "learning_rate": 6.074666666666667e-07,
      "logits/chosen": -2.254343032836914,
      "logits/rejected": -3.5504167079925537,
      "logps/chosen": -178.65524291992188,
      "logps/rejected": -176.70372009277344,
      "loss": 0.0181,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27380597591400146,
      "rewards/margins": 6.67228364944458,
      "rewards/rejected": -6.398477554321289,
      "step": 2945
    },
    {
      "epoch": 1.1784,
      "grad_norm": 0.07925382256507874,
      "learning_rate": 6.073333333333333e-07,
      "logits/chosen": -2.221431255340576,
      "logits/rejected": -3.6302976608276367,
      "logps/chosen": -105.68195343017578,
      "logps/rejected": -157.03379821777344,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5824341773986816,
      "rewards/margins": 9.037367820739746,
      "rewards/rejected": -6.454934120178223,
      "step": 2946
    },
    {
      "epoch": 1.1788,
      "grad_norm": 0.23111887276172638,
      "learning_rate": 6.072e-07,
      "logits/chosen": -2.4406418800354004,
      "logits/rejected": -3.6642234325408936,
      "logps/chosen": -220.17124938964844,
      "logps/rejected": -178.99343872070312,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6089919805526733,
      "rewards/margins": 6.765616416931152,
      "rewards/rejected": -7.374608516693115,
      "step": 2947
    },
    {
      "epoch": 1.1792,
      "grad_norm": 0.33663612604141235,
      "learning_rate": 6.070666666666666e-07,
      "logits/chosen": -1.6102561950683594,
      "logits/rejected": -3.3391923904418945,
      "logps/chosen": -142.20974731445312,
      "logps/rejected": -152.3817138671875,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.109818696975708,
      "rewards/margins": 8.274171829223633,
      "rewards/rejected": -6.164352893829346,
      "step": 2948
    },
    {
      "epoch": 1.1796,
      "grad_norm": 42.12331008911133,
      "learning_rate": 6.069333333333333e-07,
      "logits/chosen": -3.249354124069214,
      "logits/rejected": -3.338285446166992,
      "logps/chosen": -256.13031005859375,
      "logps/rejected": -154.37127685546875,
      "loss": 0.5639,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -2.6520605087280273,
      "rewards/margins": 1.6661245822906494,
      "rewards/rejected": -4.318184852600098,
      "step": 2949
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.008041901513934135,
      "learning_rate": 6.068e-07,
      "logits/chosen": -1.9904544353485107,
      "logits/rejected": -3.1506500244140625,
      "logps/chosen": -75.68144989013672,
      "logps/rejected": -203.0415496826172,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5486252307891846,
      "rewards/margins": 9.79706859588623,
      "rewards/rejected": -6.248443603515625,
      "step": 2950
    },
    {
      "epoch": 1.1804000000000001,
      "grad_norm": 0.231516495347023,
      "learning_rate": 6.066666666666666e-07,
      "logits/chosen": -2.2684760093688965,
      "logits/rejected": -3.1386256217956543,
      "logps/chosen": -154.3052215576172,
      "logps/rejected": -156.74131774902344,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0562653541564941,
      "rewards/margins": 6.084814071655273,
      "rewards/rejected": -5.0285491943359375,
      "step": 2951
    },
    {
      "epoch": 1.1808,
      "grad_norm": 0.01613379642367363,
      "learning_rate": 6.065333333333333e-07,
      "logits/chosen": -2.3834848403930664,
      "logits/rejected": -2.880415439605713,
      "logps/chosen": -147.04644775390625,
      "logps/rejected": -190.7293701171875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2226648330688477,
      "rewards/margins": 9.764400482177734,
      "rewards/rejected": -6.541736602783203,
      "step": 2952
    },
    {
      "epoch": 1.1812,
      "grad_norm": 0.02001911774277687,
      "learning_rate": 6.064e-07,
      "logits/chosen": -2.3763489723205566,
      "logits/rejected": -3.6441893577575684,
      "logps/chosen": -77.92008972167969,
      "logps/rejected": -165.63987731933594,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0366920232772827,
      "rewards/margins": 9.026796340942383,
      "rewards/rejected": -7.990104675292969,
      "step": 2953
    },
    {
      "epoch": 1.1816,
      "grad_norm": 1.4910378456115723,
      "learning_rate": 6.062666666666666e-07,
      "logits/chosen": -2.7309367656707764,
      "logits/rejected": -2.8184309005737305,
      "logps/chosen": -124.70005798339844,
      "logps/rejected": -179.55067443847656,
      "loss": 0.0093,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.48776400089263916,
      "rewards/margins": 7.001660346984863,
      "rewards/rejected": -6.513896465301514,
      "step": 2954
    },
    {
      "epoch": 1.182,
      "grad_norm": 0.1610766053199768,
      "learning_rate": 6.061333333333333e-07,
      "logits/chosen": -1.7910882234573364,
      "logits/rejected": -2.6297945976257324,
      "logps/chosen": -95.05638885498047,
      "logps/rejected": -156.37130737304688,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6022415161132812,
      "rewards/margins": 8.110955238342285,
      "rewards/rejected": -6.508713245391846,
      "step": 2955
    },
    {
      "epoch": 1.1824,
      "grad_norm": 0.021344779059290886,
      "learning_rate": 6.06e-07,
      "logits/chosen": -2.2797775268554688,
      "logits/rejected": -3.0160446166992188,
      "logps/chosen": -123.13423156738281,
      "logps/rejected": -158.36883544921875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3268752098083496,
      "rewards/margins": 8.79533576965332,
      "rewards/rejected": -6.4684600830078125,
      "step": 2956
    },
    {
      "epoch": 1.1828,
      "grad_norm": 0.01965896598994732,
      "learning_rate": 6.058666666666666e-07,
      "logits/chosen": -2.8384575843811035,
      "logits/rejected": -3.550490379333496,
      "logps/chosen": -134.87548828125,
      "logps/rejected": -260.79376220703125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2276718616485596,
      "rewards/margins": 10.647683143615723,
      "rewards/rejected": -8.420011520385742,
      "step": 2957
    },
    {
      "epoch": 1.1832,
      "grad_norm": 0.3310895264148712,
      "learning_rate": 6.057333333333333e-07,
      "logits/chosen": -2.279127359390259,
      "logits/rejected": -2.961183547973633,
      "logps/chosen": -118.82393646240234,
      "logps/rejected": -129.13919067382812,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.107905149459839,
      "rewards/margins": 5.810702323913574,
      "rewards/rejected": -3.7027969360351562,
      "step": 2958
    },
    {
      "epoch": 1.1836,
      "grad_norm": 0.03682398423552513,
      "learning_rate": 6.056e-07,
      "logits/chosen": -2.0579166412353516,
      "logits/rejected": -2.909320831298828,
      "logps/chosen": -87.16532897949219,
      "logps/rejected": -132.12855529785156,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3790950775146484,
      "rewards/margins": 7.972144603729248,
      "rewards/rejected": -5.593050003051758,
      "step": 2959
    },
    {
      "epoch": 1.184,
      "grad_norm": 0.24443760514259338,
      "learning_rate": 6.054666666666667e-07,
      "logits/chosen": -2.8616929054260254,
      "logits/rejected": -3.3948636054992676,
      "logps/chosen": -184.4813232421875,
      "logps/rejected": -155.20513916015625,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9821183681488037,
      "rewards/margins": 7.022396087646484,
      "rewards/rejected": -5.040278434753418,
      "step": 2960
    },
    {
      "epoch": 1.1844000000000001,
      "grad_norm": 0.0027621276676654816,
      "learning_rate": 6.053333333333332e-07,
      "logits/chosen": -2.5893187522888184,
      "logits/rejected": -4.015104293823242,
      "logps/chosen": -151.78366088867188,
      "logps/rejected": -220.64224243164062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9959728717803955,
      "rewards/margins": 12.11728286743164,
      "rewards/rejected": -8.121309280395508,
      "step": 2961
    },
    {
      "epoch": 1.1848,
      "grad_norm": 0.003132275305688381,
      "learning_rate": 6.051999999999999e-07,
      "logits/chosen": -2.2173619270324707,
      "logits/rejected": -3.3928112983703613,
      "logps/chosen": -99.86872863769531,
      "logps/rejected": -176.94546508789062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.780579090118408,
      "rewards/margins": 10.689977645874023,
      "rewards/rejected": -6.909398078918457,
      "step": 2962
    },
    {
      "epoch": 1.1852,
      "grad_norm": 0.002180706011131406,
      "learning_rate": 6.050666666666666e-07,
      "logits/chosen": -2.1871907711029053,
      "logits/rejected": -3.622957468032837,
      "logps/chosen": -118.29562377929688,
      "logps/rejected": -194.42420959472656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.893263339996338,
      "rewards/margins": 11.221837997436523,
      "rewards/rejected": -8.328575134277344,
      "step": 2963
    },
    {
      "epoch": 1.1856,
      "grad_norm": 0.0013513341546058655,
      "learning_rate": 6.049333333333333e-07,
      "logits/chosen": -2.6443097591400146,
      "logits/rejected": -2.8165502548217773,
      "logps/chosen": -154.67044067382812,
      "logps/rejected": -190.81317138671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.382845401763916,
      "rewards/margins": 11.06540298461914,
      "rewards/rejected": -6.682557582855225,
      "step": 2964
    },
    {
      "epoch": 1.186,
      "grad_norm": 0.005346064455807209,
      "learning_rate": 6.048e-07,
      "logits/chosen": -2.032912015914917,
      "logits/rejected": -3.1714413166046143,
      "logps/chosen": -115.20899200439453,
      "logps/rejected": -178.91917419433594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5186753273010254,
      "rewards/margins": 10.593323707580566,
      "rewards/rejected": -7.074648380279541,
      "step": 2965
    },
    {
      "epoch": 1.1864,
      "grad_norm": 1.9225901365280151,
      "learning_rate": 6.046666666666667e-07,
      "logits/chosen": -2.9524877071380615,
      "logits/rejected": -3.818510055541992,
      "logps/chosen": -325.6929931640625,
      "logps/rejected": -163.00973510742188,
      "loss": 0.0176,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.266058325767517,
      "rewards/margins": 5.21627950668335,
      "rewards/rejected": -6.482337951660156,
      "step": 2966
    },
    {
      "epoch": 1.1868,
      "grad_norm": 0.1520475298166275,
      "learning_rate": 6.045333333333333e-07,
      "logits/chosen": -2.446467638015747,
      "logits/rejected": -2.933014392852783,
      "logps/chosen": -130.31997680664062,
      "logps/rejected": -151.85009765625,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9867334365844727,
      "rewards/margins": 7.674014091491699,
      "rewards/rejected": -5.687280654907227,
      "step": 2967
    },
    {
      "epoch": 1.1872,
      "grad_norm": 0.015299225226044655,
      "learning_rate": 6.044e-07,
      "logits/chosen": -2.204474687576294,
      "logits/rejected": -2.8726718425750732,
      "logps/chosen": -133.69430541992188,
      "logps/rejected": -151.431396484375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1247010231018066,
      "rewards/margins": 9.707740783691406,
      "rewards/rejected": -6.583040237426758,
      "step": 2968
    },
    {
      "epoch": 1.1876,
      "grad_norm": 0.0023683211766183376,
      "learning_rate": 6.042666666666666e-07,
      "logits/chosen": -2.4730031490325928,
      "logits/rejected": -3.2916502952575684,
      "logps/chosen": -105.37212371826172,
      "logps/rejected": -241.9530029296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7568509578704834,
      "rewards/margins": 11.787765502929688,
      "rewards/rejected": -9.030915260314941,
      "step": 2969
    },
    {
      "epoch": 1.188,
      "grad_norm": 0.043192826211452484,
      "learning_rate": 6.041333333333333e-07,
      "logits/chosen": -2.367220163345337,
      "logits/rejected": -3.721095085144043,
      "logps/chosen": -118.95869445800781,
      "logps/rejected": -179.4246826171875,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.31288743019104,
      "rewards/margins": 8.890899658203125,
      "rewards/rejected": -6.578012466430664,
      "step": 2970
    },
    {
      "epoch": 1.1884000000000001,
      "grad_norm": 0.017551863566040993,
      "learning_rate": 6.04e-07,
      "logits/chosen": -2.4968526363372803,
      "logits/rejected": -3.310345411300659,
      "logps/chosen": -167.36761474609375,
      "logps/rejected": -166.55262756347656,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1429665088653564,
      "rewards/margins": 9.053786277770996,
      "rewards/rejected": -5.910820007324219,
      "step": 2971
    },
    {
      "epoch": 1.1888,
      "grad_norm": 0.05624588578939438,
      "learning_rate": 6.038666666666666e-07,
      "logits/chosen": -1.957308053970337,
      "logits/rejected": -3.2733163833618164,
      "logps/chosen": -74.96470642089844,
      "logps/rejected": -189.4658203125,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.966161012649536,
      "rewards/margins": 11.12569808959961,
      "rewards/rejected": -8.159536361694336,
      "step": 2972
    },
    {
      "epoch": 1.1892,
      "grad_norm": 0.009036143310368061,
      "learning_rate": 6.037333333333333e-07,
      "logits/chosen": -2.5317728519439697,
      "logits/rejected": -3.6642110347747803,
      "logps/chosen": -192.91197204589844,
      "logps/rejected": -174.99462890625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2653775215148926,
      "rewards/margins": 10.308282852172852,
      "rewards/rejected": -7.042904853820801,
      "step": 2973
    },
    {
      "epoch": 1.1896,
      "grad_norm": 0.08403974771499634,
      "learning_rate": 6.036e-07,
      "logits/chosen": -2.726104974746704,
      "logits/rejected": -3.315171718597412,
      "logps/chosen": -288.6339111328125,
      "logps/rejected": -170.2078857421875,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4515427350997925,
      "rewards/margins": 8.567161560058594,
      "rewards/rejected": -7.1156182289123535,
      "step": 2974
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.018690655007958412,
      "learning_rate": 6.034666666666667e-07,
      "logits/chosen": -2.052255630493164,
      "logits/rejected": -2.8820595741271973,
      "logps/chosen": -83.57847595214844,
      "logps/rejected": -191.45384216308594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.50343656539917,
      "rewards/margins": 9.699461936950684,
      "rewards/rejected": -7.1960248947143555,
      "step": 2975
    },
    {
      "epoch": 1.1904,
      "grad_norm": 0.004508460406213999,
      "learning_rate": 6.033333333333333e-07,
      "logits/chosen": -2.4067540168762207,
      "logits/rejected": -2.755589485168457,
      "logps/chosen": -103.59698486328125,
      "logps/rejected": -156.53372192382812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3657970428466797,
      "rewards/margins": 10.524530410766602,
      "rewards/rejected": -7.1587324142456055,
      "step": 2976
    },
    {
      "epoch": 1.1908,
      "grad_norm": 0.0025478999596089125,
      "learning_rate": 6.031999999999999e-07,
      "logits/chosen": -2.4303817749023438,
      "logits/rejected": -3.09006404876709,
      "logps/chosen": -169.27818298339844,
      "logps/rejected": -202.7578125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9029579162597656,
      "rewards/margins": 11.60348129272461,
      "rewards/rejected": -8.700523376464844,
      "step": 2977
    },
    {
      "epoch": 1.1912,
      "grad_norm": 0.8358733057975769,
      "learning_rate": 6.030666666666666e-07,
      "logits/chosen": -2.319931983947754,
      "logits/rejected": -2.967249870300293,
      "logps/chosen": -124.46083068847656,
      "logps/rejected": -145.58099365234375,
      "loss": 0.0081,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4675121307373047,
      "rewards/margins": 7.034336090087891,
      "rewards/rejected": -4.566823959350586,
      "step": 2978
    },
    {
      "epoch": 1.1916,
      "grad_norm": 0.18788288533687592,
      "learning_rate": 6.029333333333333e-07,
      "logits/chosen": -2.531358003616333,
      "logits/rejected": -3.4915714263916016,
      "logps/chosen": -117.87932586669922,
      "logps/rejected": -158.59298706054688,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5169017314910889,
      "rewards/margins": 8.196467399597168,
      "rewards/rejected": -6.6795654296875,
      "step": 2979
    },
    {
      "epoch": 1.192,
      "grad_norm": 0.0003839869168587029,
      "learning_rate": 6.028e-07,
      "logits/chosen": -2.468158006668091,
      "logits/rejected": -3.821033477783203,
      "logps/chosen": -87.23924255371094,
      "logps/rejected": -237.33299255371094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.444361209869385,
      "rewards/margins": 13.18094253540039,
      "rewards/rejected": -8.736581802368164,
      "step": 2980
    },
    {
      "epoch": 1.1924,
      "grad_norm": 0.028999246656894684,
      "learning_rate": 6.026666666666667e-07,
      "logits/chosen": -2.9512763023376465,
      "logits/rejected": -3.576900005340576,
      "logps/chosen": -193.26170349121094,
      "logps/rejected": -232.30126953125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6193618774414062,
      "rewards/margins": 9.121305465698242,
      "rewards/rejected": -8.501943588256836,
      "step": 2981
    },
    {
      "epoch": 1.1928,
      "grad_norm": 0.006480989512056112,
      "learning_rate": 6.025333333333334e-07,
      "logits/chosen": -2.0068976879119873,
      "logits/rejected": -3.4144811630249023,
      "logps/chosen": -89.42184448242188,
      "logps/rejected": -223.1316375732422,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0015430450439453,
      "rewards/margins": 9.960338592529297,
      "rewards/rejected": -6.958795547485352,
      "step": 2982
    },
    {
      "epoch": 1.1932,
      "grad_norm": 0.006653732620179653,
      "learning_rate": 6.024e-07,
      "logits/chosen": -2.398439884185791,
      "logits/rejected": -3.252657890319824,
      "logps/chosen": -91.60755920410156,
      "logps/rejected": -186.2889404296875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.630934715270996,
      "rewards/margins": 10.130824089050293,
      "rewards/rejected": -6.499889373779297,
      "step": 2983
    },
    {
      "epoch": 1.1936,
      "grad_norm": 0.012084044516086578,
      "learning_rate": 6.022666666666666e-07,
      "logits/chosen": -2.2223119735717773,
      "logits/rejected": -3.2580909729003906,
      "logps/chosen": -137.2307891845703,
      "logps/rejected": -163.7228546142578,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1609413623809814,
      "rewards/margins": 9.379074096679688,
      "rewards/rejected": -6.218132972717285,
      "step": 2984
    },
    {
      "epoch": 1.194,
      "grad_norm": 0.013501896522939205,
      "learning_rate": 6.021333333333332e-07,
      "logits/chosen": -2.829030990600586,
      "logits/rejected": -3.0760433673858643,
      "logps/chosen": -141.67510986328125,
      "logps/rejected": -163.2481689453125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.224626064300537,
      "rewards/margins": 8.899971008300781,
      "rewards/rejected": -6.675344467163086,
      "step": 2985
    },
    {
      "epoch": 1.1944,
      "grad_norm": 0.1087660938501358,
      "learning_rate": 6.019999999999999e-07,
      "logits/chosen": -1.9985764026641846,
      "logits/rejected": -3.1632742881774902,
      "logps/chosen": -161.14695739746094,
      "logps/rejected": -177.59371948242188,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6514892578125,
      "rewards/margins": 7.365093231201172,
      "rewards/rejected": -6.713603973388672,
      "step": 2986
    },
    {
      "epoch": 1.1948,
      "grad_norm": 0.026262864470481873,
      "learning_rate": 6.018666666666666e-07,
      "logits/chosen": -2.291839361190796,
      "logits/rejected": -2.7868847846984863,
      "logps/chosen": -113.73946380615234,
      "logps/rejected": -166.1619873046875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2729859352111816,
      "rewards/margins": 8.932910919189453,
      "rewards/rejected": -5.65992546081543,
      "step": 2987
    },
    {
      "epoch": 1.1952,
      "grad_norm": 0.002201671479269862,
      "learning_rate": 6.017333333333333e-07,
      "logits/chosen": -2.177802085876465,
      "logits/rejected": -3.205695629119873,
      "logps/chosen": -119.78700256347656,
      "logps/rejected": -182.3749237060547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.386139392852783,
      "rewards/margins": 10.729644775390625,
      "rewards/rejected": -6.343505859375,
      "step": 2988
    },
    {
      "epoch": 1.1956,
      "grad_norm": 0.004049794282764196,
      "learning_rate": 6.016e-07,
      "logits/chosen": -2.1240384578704834,
      "logits/rejected": -3.4221839904785156,
      "logps/chosen": -108.09649658203125,
      "logps/rejected": -225.8843994140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.738682508468628,
      "rewards/margins": 11.16159439086914,
      "rewards/rejected": -7.422912120819092,
      "step": 2989
    },
    {
      "epoch": 1.196,
      "grad_norm": 0.029513565823435783,
      "learning_rate": 6.014666666666667e-07,
      "logits/chosen": -2.129484176635742,
      "logits/rejected": -3.757793426513672,
      "logps/chosen": -130.28387451171875,
      "logps/rejected": -201.0375213623047,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18447798490524292,
      "rewards/margins": 8.414565086364746,
      "rewards/rejected": -8.230087280273438,
      "step": 2990
    },
    {
      "epoch": 1.1964,
      "grad_norm": 0.001064465963281691,
      "learning_rate": 6.013333333333334e-07,
      "logits/chosen": -1.9966723918914795,
      "logits/rejected": -3.6927738189697266,
      "logps/chosen": -80.28128051757812,
      "logps/rejected": -179.8369140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.195171356201172,
      "rewards/margins": 11.505653381347656,
      "rewards/rejected": -8.310482025146484,
      "step": 2991
    },
    {
      "epoch": 1.1968,
      "grad_norm": 0.07448919117450714,
      "learning_rate": 6.012e-07,
      "logits/chosen": -1.9474433660507202,
      "logits/rejected": -2.539003849029541,
      "logps/chosen": -132.5611114501953,
      "logps/rejected": -137.74110412597656,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9611423015594482,
      "rewards/margins": 8.87808609008789,
      "rewards/rejected": -5.9169440269470215,
      "step": 2992
    },
    {
      "epoch": 1.1972,
      "grad_norm": 0.21852827072143555,
      "learning_rate": 6.010666666666666e-07,
      "logits/chosen": -2.2035865783691406,
      "logits/rejected": -3.7357125282287598,
      "logps/chosen": -112.11244201660156,
      "logps/rejected": -184.34201049804688,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3643180727958679,
      "rewards/margins": 7.194118499755859,
      "rewards/rejected": -6.829800605773926,
      "step": 2993
    },
    {
      "epoch": 1.1976,
      "grad_norm": 0.0820249393582344,
      "learning_rate": 6.009333333333333e-07,
      "logits/chosen": -2.3783836364746094,
      "logits/rejected": -2.895822048187256,
      "logps/chosen": -138.7926025390625,
      "logps/rejected": -162.545654296875,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0437123775482178,
      "rewards/margins": 8.670126914978027,
      "rewards/rejected": -6.6264142990112305,
      "step": 2994
    },
    {
      "epoch": 1.198,
      "grad_norm": 0.09875192493200302,
      "learning_rate": 6.007999999999999e-07,
      "logits/chosen": -2.3538765907287598,
      "logits/rejected": -3.2520790100097656,
      "logps/chosen": -150.96096801757812,
      "logps/rejected": -135.73805236816406,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8012146949768066,
      "rewards/margins": 7.0896196365356445,
      "rewards/rejected": -5.288404941558838,
      "step": 2995
    },
    {
      "epoch": 1.1984,
      "grad_norm": 0.0024575451388955116,
      "learning_rate": 6.006666666666666e-07,
      "logits/chosen": -1.9825667142868042,
      "logits/rejected": -3.0823116302490234,
      "logps/chosen": -146.9594268798828,
      "logps/rejected": -240.71798706054688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9737141132354736,
      "rewards/margins": 11.353147506713867,
      "rewards/rejected": -8.379433631896973,
      "step": 2996
    },
    {
      "epoch": 1.1988,
      "grad_norm": 0.2053157538175583,
      "learning_rate": 6.005333333333333e-07,
      "logits/chosen": -2.2264723777770996,
      "logits/rejected": -3.1305837631225586,
      "logps/chosen": -174.79473876953125,
      "logps/rejected": -176.42916870117188,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.946478247642517,
      "rewards/margins": 7.912795066833496,
      "rewards/rejected": -5.966317176818848,
      "step": 2997
    },
    {
      "epoch": 1.1992,
      "grad_norm": 0.025719648227095604,
      "learning_rate": 6.004e-07,
      "logits/chosen": -2.2530429363250732,
      "logits/rejected": -2.9287939071655273,
      "logps/chosen": -122.99894714355469,
      "logps/rejected": -219.81602478027344,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9517574310302734,
      "rewards/margins": 9.108610153198242,
      "rewards/rejected": -5.156853199005127,
      "step": 2998
    },
    {
      "epoch": 1.1996,
      "grad_norm": 0.004682561382651329,
      "learning_rate": 6.002666666666666e-07,
      "logits/chosen": -1.9354066848754883,
      "logits/rejected": -3.4019417762756348,
      "logps/chosen": -84.40376281738281,
      "logps/rejected": -182.58401489257812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4564433097839355,
      "rewards/margins": 10.87117862701416,
      "rewards/rejected": -8.414734840393066,
      "step": 2999
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.023524943739175797,
      "learning_rate": 6.001333333333333e-07,
      "logits/chosen": -2.2820141315460205,
      "logits/rejected": -3.1596789360046387,
      "logps/chosen": -113.34974670410156,
      "logps/rejected": -183.081298828125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4432902336120605,
      "rewards/margins": 8.276802062988281,
      "rewards/rejected": -5.833512306213379,
      "step": 3000
    },
    {
      "epoch": 1.2004,
      "grad_norm": 6.720093250274658,
      "learning_rate": 6e-07,
      "logits/chosen": -2.780050277709961,
      "logits/rejected": -3.215782642364502,
      "logps/chosen": -193.23193359375,
      "logps/rejected": -185.1992950439453,
      "loss": 0.0688,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7977875471115112,
      "rewards/margins": 5.83223819732666,
      "rewards/rejected": -6.630025863647461,
      "step": 3001
    },
    {
      "epoch": 1.2008,
      "grad_norm": 0.003924086224287748,
      "learning_rate": 5.998666666666667e-07,
      "logits/chosen": -2.5539517402648926,
      "logits/rejected": -3.4213833808898926,
      "logps/chosen": -222.9680938720703,
      "logps/rejected": -187.17587280273438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.048574924468994,
      "rewards/margins": 10.368350982666016,
      "rewards/rejected": -7.319775581359863,
      "step": 3002
    },
    {
      "epoch": 1.2012,
      "grad_norm": 0.011809871532022953,
      "learning_rate": 5.997333333333334e-07,
      "logits/chosen": -2.130924701690674,
      "logits/rejected": -3.423593044281006,
      "logps/chosen": -154.09503173828125,
      "logps/rejected": -184.58251953125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7118096351623535,
      "rewards/margins": 10.687808990478516,
      "rewards/rejected": -7.97599983215332,
      "step": 3003
    },
    {
      "epoch": 1.2016,
      "grad_norm": 0.14891527593135834,
      "learning_rate": 5.995999999999999e-07,
      "logits/chosen": -2.502811908721924,
      "logits/rejected": -3.573154926300049,
      "logps/chosen": -130.2399139404297,
      "logps/rejected": -168.17901611328125,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1171212196350098,
      "rewards/margins": 7.766436576843262,
      "rewards/rejected": -5.649314880371094,
      "step": 3004
    },
    {
      "epoch": 1.202,
      "grad_norm": 0.018929963931441307,
      "learning_rate": 5.994666666666666e-07,
      "logits/chosen": -2.1610841751098633,
      "logits/rejected": -3.7553930282592773,
      "logps/chosen": -134.63729858398438,
      "logps/rejected": -198.874267578125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4259133338928223,
      "rewards/margins": 10.079172134399414,
      "rewards/rejected": -7.65325927734375,
      "step": 3005
    },
    {
      "epoch": 1.2024,
      "grad_norm": 0.4743309020996094,
      "learning_rate": 5.993333333333333e-07,
      "logits/chosen": -2.2483770847320557,
      "logits/rejected": -3.1725690364837646,
      "logps/chosen": -116.04035186767578,
      "logps/rejected": -144.1240997314453,
      "loss": 0.0051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6775215864181519,
      "rewards/margins": 6.326641082763672,
      "rewards/rejected": -5.6491193771362305,
      "step": 3006
    },
    {
      "epoch": 1.2028,
      "grad_norm": 0.00408139917999506,
      "learning_rate": 5.991999999999999e-07,
      "logits/chosen": -2.7170214653015137,
      "logits/rejected": -3.3149755001068115,
      "logps/chosen": -197.26727294921875,
      "logps/rejected": -278.0271301269531,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.863405704498291,
      "rewards/margins": 10.809823989868164,
      "rewards/rejected": -8.946418762207031,
      "step": 3007
    },
    {
      "epoch": 1.2032,
      "grad_norm": 0.40944647789001465,
      "learning_rate": 5.990666666666666e-07,
      "logits/chosen": -2.6730284690856934,
      "logits/rejected": -3.7008426189422607,
      "logps/chosen": -159.1812744140625,
      "logps/rejected": -173.89434814453125,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3826851844787598,
      "rewards/margins": 7.523378849029541,
      "rewards/rejected": -6.140693664550781,
      "step": 3008
    },
    {
      "epoch": 1.2036,
      "grad_norm": 0.12325417995452881,
      "learning_rate": 5.989333333333333e-07,
      "logits/chosen": -2.062422752380371,
      "logits/rejected": -2.9203171730041504,
      "logps/chosen": -124.10420227050781,
      "logps/rejected": -156.45700073242188,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.813357949256897,
      "rewards/margins": 8.275711059570312,
      "rewards/rejected": -6.462353229522705,
      "step": 3009
    },
    {
      "epoch": 1.204,
      "grad_norm": 0.02476191334426403,
      "learning_rate": 5.988e-07,
      "logits/chosen": -2.732412338256836,
      "logits/rejected": -3.554196834564209,
      "logps/chosen": -96.36241912841797,
      "logps/rejected": -155.18508911132812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.195460081100464,
      "rewards/margins": 9.342681884765625,
      "rewards/rejected": -6.147221565246582,
      "step": 3010
    },
    {
      "epoch": 1.2044,
      "grad_norm": 0.0036401990801095963,
      "learning_rate": 5.986666666666667e-07,
      "logits/chosen": -2.193584442138672,
      "logits/rejected": -3.1677002906799316,
      "logps/chosen": -82.58665466308594,
      "logps/rejected": -169.6482696533203,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.360586166381836,
      "rewards/margins": 12.216320037841797,
      "rewards/rejected": -7.855733871459961,
      "step": 3011
    },
    {
      "epoch": 1.2048,
      "grad_norm": 5.006991863250732,
      "learning_rate": 5.985333333333334e-07,
      "logits/chosen": -2.431368827819824,
      "logits/rejected": -3.4660775661468506,
      "logps/chosen": -222.09844970703125,
      "logps/rejected": -145.30764770507812,
      "loss": 0.0353,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8266037106513977,
      "rewards/margins": 4.171074867248535,
      "rewards/rejected": -4.997678756713867,
      "step": 3012
    },
    {
      "epoch": 1.2052,
      "grad_norm": 0.002222995040938258,
      "learning_rate": 5.984000000000001e-07,
      "logits/chosen": -2.0879738330841064,
      "logits/rejected": -3.722660541534424,
      "logps/chosen": -102.31309509277344,
      "logps/rejected": -191.94322204589844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.152470827102661,
      "rewards/margins": 11.322230339050293,
      "rewards/rejected": -9.169759750366211,
      "step": 3013
    },
    {
      "epoch": 1.2056,
      "grad_norm": 0.015393439680337906,
      "learning_rate": 5.982666666666665e-07,
      "logits/chosen": -1.8171958923339844,
      "logits/rejected": -3.51124906539917,
      "logps/chosen": -140.16549682617188,
      "logps/rejected": -217.19154357910156,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4546215534210205,
      "rewards/margins": 10.38926887512207,
      "rewards/rejected": -7.9346466064453125,
      "step": 3014
    },
    {
      "epoch": 1.206,
      "grad_norm": 0.054461076855659485,
      "learning_rate": 5.981333333333332e-07,
      "logits/chosen": -1.8132013082504272,
      "logits/rejected": -3.586864948272705,
      "logps/chosen": -139.84230041503906,
      "logps/rejected": -188.357666015625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.307553768157959,
      "rewards/margins": 8.024238586425781,
      "rewards/rejected": -5.716684818267822,
      "step": 3015
    },
    {
      "epoch": 1.2064,
      "grad_norm": 0.39701583981513977,
      "learning_rate": 5.979999999999999e-07,
      "logits/chosen": -1.5920023918151855,
      "logits/rejected": -2.310567617416382,
      "logps/chosen": -83.42729187011719,
      "logps/rejected": -136.45384216308594,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9240429401397705,
      "rewards/margins": 6.9832916259765625,
      "rewards/rejected": -4.059248924255371,
      "step": 3016
    },
    {
      "epoch": 1.2068,
      "grad_norm": 0.00964674074202776,
      "learning_rate": 5.978666666666666e-07,
      "logits/chosen": -2.050065517425537,
      "logits/rejected": -3.028306007385254,
      "logps/chosen": -78.24061584472656,
      "logps/rejected": -160.36480712890625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.0595927238464355,
      "rewards/margins": 9.634050369262695,
      "rewards/rejected": -5.574457168579102,
      "step": 3017
    },
    {
      "epoch": 1.2072,
      "grad_norm": 0.0016536506591364741,
      "learning_rate": 5.977333333333333e-07,
      "logits/chosen": -2.060542345046997,
      "logits/rejected": -3.377316951751709,
      "logps/chosen": -124.41412353515625,
      "logps/rejected": -213.08917236328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9851698875427246,
      "rewards/margins": 11.275022506713867,
      "rewards/rejected": -8.289852142333984,
      "step": 3018
    },
    {
      "epoch": 1.2076,
      "grad_norm": 0.018244829028844833,
      "learning_rate": 5.976e-07,
      "logits/chosen": -1.9483299255371094,
      "logits/rejected": -3.511949062347412,
      "logps/chosen": -93.15248107910156,
      "logps/rejected": -183.7957000732422,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.411247968673706,
      "rewards/margins": 8.776482582092285,
      "rewards/rejected": -7.365234851837158,
      "step": 3019
    },
    {
      "epoch": 1.208,
      "grad_norm": 0.3819509744644165,
      "learning_rate": 5.974666666666667e-07,
      "logits/chosen": -1.4936070442199707,
      "logits/rejected": -3.1739649772644043,
      "logps/chosen": -106.06625366210938,
      "logps/rejected": -146.1064910888672,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.267737627029419,
      "rewards/margins": 7.9603729248046875,
      "rewards/rejected": -6.6926350593566895,
      "step": 3020
    },
    {
      "epoch": 1.2084,
      "grad_norm": 0.7153005003929138,
      "learning_rate": 5.973333333333334e-07,
      "logits/chosen": -2.1411781311035156,
      "logits/rejected": -3.15102481842041,
      "logps/chosen": -96.92491149902344,
      "logps/rejected": -155.28195190429688,
      "loss": 0.0071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7438983917236328,
      "rewards/margins": 6.259815692901611,
      "rewards/rejected": -5.5159173011779785,
      "step": 3021
    },
    {
      "epoch": 1.2088,
      "grad_norm": 0.008779507130384445,
      "learning_rate": 5.972e-07,
      "logits/chosen": -2.305631637573242,
      "logits/rejected": -3.333223819732666,
      "logps/chosen": -141.24903869628906,
      "logps/rejected": -170.1925811767578,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1471400260925293,
      "rewards/margins": 9.499561309814453,
      "rewards/rejected": -6.352421283721924,
      "step": 3022
    },
    {
      "epoch": 1.2092,
      "grad_norm": 0.001570589723996818,
      "learning_rate": 5.970666666666666e-07,
      "logits/chosen": -2.059144973754883,
      "logits/rejected": -3.570100784301758,
      "logps/chosen": -99.9640121459961,
      "logps/rejected": -207.5943603515625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.834887981414795,
      "rewards/margins": 12.401975631713867,
      "rewards/rejected": -8.567087173461914,
      "step": 3023
    },
    {
      "epoch": 1.2096,
      "grad_norm": 0.30009108781814575,
      "learning_rate": 5.969333333333333e-07,
      "logits/chosen": -2.6137237548828125,
      "logits/rejected": -3.628814935684204,
      "logps/chosen": -127.97877502441406,
      "logps/rejected": -152.10025024414062,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.18489304184913635,
      "rewards/margins": 6.1043806076049805,
      "rewards/rejected": -6.289273262023926,
      "step": 3024
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.17123353481292725,
      "learning_rate": 5.967999999999999e-07,
      "logits/chosen": -2.771930694580078,
      "logits/rejected": -3.1366734504699707,
      "logps/chosen": -129.1180877685547,
      "logps/rejected": -165.44400024414062,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.38813936710357666,
      "rewards/margins": 7.534261703491211,
      "rewards/rejected": -7.92240047454834,
      "step": 3025
    },
    {
      "epoch": 1.2104,
      "grad_norm": 0.06288314610719681,
      "learning_rate": 5.966666666666666e-07,
      "logits/chosen": -2.4793076515197754,
      "logits/rejected": -2.950294256210327,
      "logps/chosen": -126.49495697021484,
      "logps/rejected": -174.23251342773438,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2311549186706543,
      "rewards/margins": 7.879051685333252,
      "rewards/rejected": -6.647896766662598,
      "step": 3026
    },
    {
      "epoch": 1.2107999999999999,
      "grad_norm": 0.1402200609445572,
      "learning_rate": 5.965333333333333e-07,
      "logits/chosen": -2.0287511348724365,
      "logits/rejected": -3.1489391326904297,
      "logps/chosen": -120.24693298339844,
      "logps/rejected": -190.1489715576172,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.920881986618042,
      "rewards/margins": 8.750062942504883,
      "rewards/rejected": -6.829180717468262,
      "step": 3027
    },
    {
      "epoch": 1.2112,
      "grad_norm": 0.3242248594760895,
      "learning_rate": 5.964e-07,
      "logits/chosen": -2.958840847015381,
      "logits/rejected": -3.515598773956299,
      "logps/chosen": -183.5152130126953,
      "logps/rejected": -187.18783569335938,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.242069959640503,
      "rewards/margins": 6.837719917297363,
      "rewards/rejected": -5.595649719238281,
      "step": 3028
    },
    {
      "epoch": 1.2116,
      "grad_norm": 0.004066715482622385,
      "learning_rate": 5.962666666666666e-07,
      "logits/chosen": -2.530768632888794,
      "logits/rejected": -3.0872128009796143,
      "logps/chosen": -186.4169921875,
      "logps/rejected": -205.72254943847656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7048922777175903,
      "rewards/margins": 10.60577392578125,
      "rewards/rejected": -8.90088176727295,
      "step": 3029
    },
    {
      "epoch": 1.212,
      "grad_norm": 0.2015605866909027,
      "learning_rate": 5.961333333333333e-07,
      "logits/chosen": -2.184281587600708,
      "logits/rejected": -3.5303688049316406,
      "logps/chosen": -140.45156860351562,
      "logps/rejected": -203.8914794921875,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.11099015176296234,
      "rewards/margins": 7.8246002197265625,
      "rewards/rejected": -7.935590744018555,
      "step": 3030
    },
    {
      "epoch": 1.2124,
      "grad_norm": 0.042729754000902176,
      "learning_rate": 5.96e-07,
      "logits/chosen": -2.5477702617645264,
      "logits/rejected": -3.510915756225586,
      "logps/chosen": -148.60980224609375,
      "logps/rejected": -187.53640747070312,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4373939037322998,
      "rewards/margins": 8.392647743225098,
      "rewards/rejected": -7.955253601074219,
      "step": 3031
    },
    {
      "epoch": 1.2128,
      "grad_norm": 0.0748056024312973,
      "learning_rate": 5.958666666666666e-07,
      "logits/chosen": -2.2810046672821045,
      "logits/rejected": -3.195523977279663,
      "logps/chosen": -65.50877380371094,
      "logps/rejected": -146.4276885986328,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.515064239501953,
      "rewards/margins": 8.252941131591797,
      "rewards/rejected": -5.737876892089844,
      "step": 3032
    },
    {
      "epoch": 1.2132,
      "grad_norm": 0.018940217792987823,
      "learning_rate": 5.957333333333333e-07,
      "logits/chosen": -2.5875744819641113,
      "logits/rejected": -2.5643856525421143,
      "logps/chosen": -254.22225952148438,
      "logps/rejected": -201.4153289794922,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.519926071166992,
      "rewards/margins": 9.241130828857422,
      "rewards/rejected": -5.7212042808532715,
      "step": 3033
    },
    {
      "epoch": 1.2136,
      "grad_norm": 0.012107787653803825,
      "learning_rate": 5.956e-07,
      "logits/chosen": -2.1477208137512207,
      "logits/rejected": -3.2053909301757812,
      "logps/chosen": -90.40928649902344,
      "logps/rejected": -147.67239379882812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.782268524169922,
      "rewards/margins": 9.136453628540039,
      "rewards/rejected": -6.354185581207275,
      "step": 3034
    },
    {
      "epoch": 1.214,
      "grad_norm": 0.09188199788331985,
      "learning_rate": 5.954666666666667e-07,
      "logits/chosen": -1.8731935024261475,
      "logits/rejected": -3.4119298458099365,
      "logps/chosen": -78.72479248046875,
      "logps/rejected": -149.31887817382812,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9529892206192017,
      "rewards/margins": 7.828797817230225,
      "rewards/rejected": -6.8758087158203125,
      "step": 3035
    },
    {
      "epoch": 1.2144,
      "grad_norm": 0.036110565066337585,
      "learning_rate": 5.953333333333333e-07,
      "logits/chosen": -1.9259675741195679,
      "logits/rejected": -2.7086215019226074,
      "logps/chosen": -138.63381958007812,
      "logps/rejected": -143.34915161132812,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.570620059967041,
      "rewards/margins": 7.957776069641113,
      "rewards/rejected": -6.387156009674072,
      "step": 3036
    },
    {
      "epoch": 1.2147999999999999,
      "grad_norm": 0.023335857316851616,
      "learning_rate": 5.951999999999999e-07,
      "logits/chosen": -2.292912483215332,
      "logits/rejected": -3.554205894470215,
      "logps/chosen": -100.36376953125,
      "logps/rejected": -166.12887573242188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.009967088699341,
      "rewards/margins": 8.606492042541504,
      "rewards/rejected": -6.596525192260742,
      "step": 3037
    },
    {
      "epoch": 1.2152,
      "grad_norm": 0.013814132660627365,
      "learning_rate": 5.950666666666666e-07,
      "logits/chosen": -1.9446463584899902,
      "logits/rejected": -3.321657180786133,
      "logps/chosen": -116.88468170166016,
      "logps/rejected": -168.22085571289062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9898709058761597,
      "rewards/margins": 9.062664031982422,
      "rewards/rejected": -7.072793483734131,
      "step": 3038
    },
    {
      "epoch": 1.2156,
      "grad_norm": 1.2135682106018066,
      "learning_rate": 5.949333333333333e-07,
      "logits/chosen": -2.2198469638824463,
      "logits/rejected": -2.6699514389038086,
      "logps/chosen": -140.8770751953125,
      "logps/rejected": -143.3751220703125,
      "loss": 0.0098,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1344020962715149,
      "rewards/margins": 5.4808549880981445,
      "rewards/rejected": -5.615257263183594,
      "step": 3039
    },
    {
      "epoch": 1.216,
      "grad_norm": 0.2037455141544342,
      "learning_rate": 5.948e-07,
      "logits/chosen": -2.6491315364837646,
      "logits/rejected": -3.2728075981140137,
      "logps/chosen": -136.9748992919922,
      "logps/rejected": -163.80441284179688,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3377586603164673,
      "rewards/margins": 6.982465744018555,
      "rewards/rejected": -6.644707202911377,
      "step": 3040
    },
    {
      "epoch": 1.2164,
      "grad_norm": 0.011813038028776646,
      "learning_rate": 5.946666666666667e-07,
      "logits/chosen": -1.700314998626709,
      "logits/rejected": -2.873223304748535,
      "logps/chosen": -121.398193359375,
      "logps/rejected": -150.09213256835938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5754177570343018,
      "rewards/margins": 8.955663681030273,
      "rewards/rejected": -6.380246162414551,
      "step": 3041
    },
    {
      "epoch": 1.2168,
      "grad_norm": 0.009952226653695107,
      "learning_rate": 5.945333333333333e-07,
      "logits/chosen": -1.9522080421447754,
      "logits/rejected": -2.5945520401000977,
      "logps/chosen": -101.7295150756836,
      "logps/rejected": -139.3931121826172,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6226344108581543,
      "rewards/margins": 9.181585311889648,
      "rewards/rejected": -5.558950424194336,
      "step": 3042
    },
    {
      "epoch": 1.2172,
      "grad_norm": 0.322035551071167,
      "learning_rate": 5.944e-07,
      "logits/chosen": -2.375716209411621,
      "logits/rejected": -3.1138718128204346,
      "logps/chosen": -105.7526626586914,
      "logps/rejected": -148.2691650390625,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6118125915527344,
      "rewards/margins": 7.2060866355896,
      "rewards/rejected": -5.594274044036865,
      "step": 3043
    },
    {
      "epoch": 1.2176,
      "grad_norm": 0.125159353017807,
      "learning_rate": 5.942666666666667e-07,
      "logits/chosen": -2.13917875289917,
      "logits/rejected": -3.2017529010772705,
      "logps/chosen": -103.18136596679688,
      "logps/rejected": -150.82989501953125,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.448842525482178,
      "rewards/margins": 10.545567512512207,
      "rewards/rejected": -6.0967254638671875,
      "step": 3044
    },
    {
      "epoch": 1.218,
      "grad_norm": 0.008327759802341461,
      "learning_rate": 5.941333333333333e-07,
      "logits/chosen": -2.036606550216675,
      "logits/rejected": -2.8767001628875732,
      "logps/chosen": -80.2027587890625,
      "logps/rejected": -153.1842803955078,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.461315870285034,
      "rewards/margins": 9.667630195617676,
      "rewards/rejected": -7.2063140869140625,
      "step": 3045
    },
    {
      "epoch": 1.2184,
      "grad_norm": 0.003836805932223797,
      "learning_rate": 5.939999999999999e-07,
      "logits/chosen": -2.2633466720581055,
      "logits/rejected": -3.1596522331237793,
      "logps/chosen": -117.53446960449219,
      "logps/rejected": -190.00709533691406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9599390029907227,
      "rewards/margins": 10.54824161529541,
      "rewards/rejected": -6.5883026123046875,
      "step": 3046
    },
    {
      "epoch": 1.2187999999999999,
      "grad_norm": 0.07345099747180939,
      "learning_rate": 5.938666666666666e-07,
      "logits/chosen": -1.9602704048156738,
      "logits/rejected": -2.7793540954589844,
      "logps/chosen": -121.82276153564453,
      "logps/rejected": -164.4788818359375,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5925216674804688,
      "rewards/margins": 7.49043083190918,
      "rewards/rejected": -6.897909164428711,
      "step": 3047
    },
    {
      "epoch": 1.2192,
      "grad_norm": 0.054226215928792953,
      "learning_rate": 5.937333333333333e-07,
      "logits/chosen": -1.9913710355758667,
      "logits/rejected": -3.517167568206787,
      "logps/chosen": -122.94615173339844,
      "logps/rejected": -185.2291259765625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7282077670097351,
      "rewards/margins": 8.551753044128418,
      "rewards/rejected": -7.823545455932617,
      "step": 3048
    },
    {
      "epoch": 1.2196,
      "grad_norm": 0.03930317983031273,
      "learning_rate": 5.936e-07,
      "logits/chosen": -1.924837350845337,
      "logits/rejected": -3.6627349853515625,
      "logps/chosen": -92.87554931640625,
      "logps/rejected": -179.36082458496094,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7470493912696838,
      "rewards/margins": 8.162571907043457,
      "rewards/rejected": -7.415522575378418,
      "step": 3049
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.06063186004757881,
      "learning_rate": 5.934666666666667e-07,
      "logits/chosen": -2.623471260070801,
      "logits/rejected": -3.652256965637207,
      "logps/chosen": -169.644775390625,
      "logps/rejected": -212.9212646484375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1246289014816284,
      "rewards/margins": 8.998848915100098,
      "rewards/rejected": -10.123477935791016,
      "step": 3050
    },
    {
      "epoch": 1.2204,
      "grad_norm": 0.28484824299812317,
      "learning_rate": 5.933333333333334e-07,
      "logits/chosen": -1.868578314781189,
      "logits/rejected": -3.3806772232055664,
      "logps/chosen": -119.57221984863281,
      "logps/rejected": -164.02833557128906,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5698699951171875,
      "rewards/margins": 6.508584976196289,
      "rewards/rejected": -5.938714504241943,
      "step": 3051
    },
    {
      "epoch": 1.2208,
      "grad_norm": 0.0029090961907058954,
      "learning_rate": 5.931999999999999e-07,
      "logits/chosen": -2.1871912479400635,
      "logits/rejected": -3.4129698276519775,
      "logps/chosen": -177.121826171875,
      "logps/rejected": -168.34185791015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.112071514129639,
      "rewards/margins": 10.634613037109375,
      "rewards/rejected": -6.522541046142578,
      "step": 3052
    },
    {
      "epoch": 1.2212,
      "grad_norm": 0.1993713229894638,
      "learning_rate": 5.930666666666666e-07,
      "logits/chosen": -2.041924476623535,
      "logits/rejected": -3.1779706478118896,
      "logps/chosen": -90.52574157714844,
      "logps/rejected": -163.23452758789062,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.879979133605957,
      "rewards/margins": 9.251307487487793,
      "rewards/rejected": -6.371328353881836,
      "step": 3053
    },
    {
      "epoch": 1.2216,
      "grad_norm": 0.23381060361862183,
      "learning_rate": 5.929333333333333e-07,
      "logits/chosen": -2.2223191261291504,
      "logits/rejected": -3.40739107131958,
      "logps/chosen": -162.94789123535156,
      "logps/rejected": -177.3485870361328,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.266181230545044,
      "rewards/margins": 8.123922348022461,
      "rewards/rejected": -6.857741355895996,
      "step": 3054
    },
    {
      "epoch": 1.222,
      "grad_norm": 0.0030579918529838324,
      "learning_rate": 5.928e-07,
      "logits/chosen": -2.248105764389038,
      "logits/rejected": -3.4088339805603027,
      "logps/chosen": -147.1683807373047,
      "logps/rejected": -225.92103576660156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.24030065536499,
      "rewards/margins": 12.636690139770508,
      "rewards/rejected": -8.396389961242676,
      "step": 3055
    },
    {
      "epoch": 1.2224,
      "grad_norm": 0.4454737901687622,
      "learning_rate": 5.926666666666667e-07,
      "logits/chosen": -2.1653871536254883,
      "logits/rejected": -3.7054805755615234,
      "logps/chosen": -160.88790893554688,
      "logps/rejected": -212.90675354003906,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8587031364440918,
      "rewards/margins": 8.610618591308594,
      "rewards/rejected": -7.75191593170166,
      "step": 3056
    },
    {
      "epoch": 1.2227999999999999,
      "grad_norm": 0.10656547546386719,
      "learning_rate": 5.925333333333333e-07,
      "logits/chosen": -1.6101170778274536,
      "logits/rejected": -3.160860776901245,
      "logps/chosen": -106.99359130859375,
      "logps/rejected": -144.6133270263672,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3466224670410156,
      "rewards/margins": 8.889881134033203,
      "rewards/rejected": -5.543259143829346,
      "step": 3057
    },
    {
      "epoch": 1.2232,
      "grad_norm": 0.0026054626796394587,
      "learning_rate": 5.924e-07,
      "logits/chosen": -2.0428216457366943,
      "logits/rejected": -3.164857864379883,
      "logps/chosen": -114.57365417480469,
      "logps/rejected": -223.7337188720703,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2790234088897705,
      "rewards/margins": 11.674273490905762,
      "rewards/rejected": -8.39525032043457,
      "step": 3058
    },
    {
      "epoch": 1.2236,
      "grad_norm": 0.150038942694664,
      "learning_rate": 5.922666666666667e-07,
      "logits/chosen": -2.036384105682373,
      "logits/rejected": -2.9541287422180176,
      "logps/chosen": -130.0576171875,
      "logps/rejected": -211.23251342773438,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4157211780548096,
      "rewards/margins": 7.360192775726318,
      "rewards/rejected": -5.944471836090088,
      "step": 3059
    },
    {
      "epoch": 1.224,
      "grad_norm": 0.45510825514793396,
      "learning_rate": 5.921333333333333e-07,
      "logits/chosen": -1.8961644172668457,
      "logits/rejected": -3.0876059532165527,
      "logps/chosen": -201.47369384765625,
      "logps/rejected": -149.46347045898438,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.06728820502758026,
      "rewards/margins": 5.500020980834961,
      "rewards/rejected": -5.567309379577637,
      "step": 3060
    },
    {
      "epoch": 1.2244,
      "grad_norm": 0.7174652814865112,
      "learning_rate": 5.919999999999999e-07,
      "logits/chosen": -2.0461883544921875,
      "logits/rejected": -3.504457473754883,
      "logps/chosen": -167.0657958984375,
      "logps/rejected": -167.37966918945312,
      "loss": 0.0071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4755420684814453,
      "rewards/margins": 5.167055130004883,
      "rewards/rejected": -6.642597198486328,
      "step": 3061
    },
    {
      "epoch": 1.2248,
      "grad_norm": 1.9337351322174072,
      "learning_rate": 5.918666666666666e-07,
      "logits/chosen": -2.4147696495056152,
      "logits/rejected": -2.7005152702331543,
      "logps/chosen": -126.8648452758789,
      "logps/rejected": -147.02847290039062,
      "loss": 0.0155,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.873897910118103,
      "rewards/margins": 5.0336713790893555,
      "rewards/rejected": -5.907569885253906,
      "step": 3062
    },
    {
      "epoch": 1.2252,
      "grad_norm": 0.06271830946207047,
      "learning_rate": 5.917333333333333e-07,
      "logits/chosen": -3.0086307525634766,
      "logits/rejected": -3.240164279937744,
      "logps/chosen": -94.39217376708984,
      "logps/rejected": -204.65631103515625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.991050362586975,
      "rewards/margins": 7.885095596313477,
      "rewards/rejected": -5.894045352935791,
      "step": 3063
    },
    {
      "epoch": 1.2256,
      "grad_norm": 0.021232323721051216,
      "learning_rate": 5.916e-07,
      "logits/chosen": -1.88199782371521,
      "logits/rejected": -3.689105749130249,
      "logps/chosen": -127.16048431396484,
      "logps/rejected": -196.81288146972656,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9629348516464233,
      "rewards/margins": 8.632667541503906,
      "rewards/rejected": -6.669733047485352,
      "step": 3064
    },
    {
      "epoch": 1.226,
      "grad_norm": 0.010161260142922401,
      "learning_rate": 5.914666666666667e-07,
      "logits/chosen": -1.7634098529815674,
      "logits/rejected": -3.171816349029541,
      "logps/chosen": -62.645904541015625,
      "logps/rejected": -154.55479431152344,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.543059825897217,
      "rewards/margins": 9.888736724853516,
      "rewards/rejected": -6.345677375793457,
      "step": 3065
    },
    {
      "epoch": 1.2264,
      "grad_norm": 0.0076227933168411255,
      "learning_rate": 5.913333333333334e-07,
      "logits/chosen": -1.3863623142242432,
      "logits/rejected": -3.834199905395508,
      "logps/chosen": -125.47039794921875,
      "logps/rejected": -235.31394958496094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1804394721984863,
      "rewards/margins": 10.321878433227539,
      "rewards/rejected": -7.141439437866211,
      "step": 3066
    },
    {
      "epoch": 1.2268,
      "grad_norm": 0.0174856036901474,
      "learning_rate": 5.911999999999999e-07,
      "logits/chosen": -2.045811891555786,
      "logits/rejected": -3.841752529144287,
      "logps/chosen": -100.2807388305664,
      "logps/rejected": -146.24957275390625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4568686485290527,
      "rewards/margins": 8.696439743041992,
      "rewards/rejected": -6.239571571350098,
      "step": 3067
    },
    {
      "epoch": 1.2272,
      "grad_norm": 0.03851357102394104,
      "learning_rate": 5.910666666666666e-07,
      "logits/chosen": -1.8860604763031006,
      "logits/rejected": -3.425384044647217,
      "logps/chosen": -175.4634246826172,
      "logps/rejected": -182.91091918945312,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.756486177444458,
      "rewards/margins": 8.327770233154297,
      "rewards/rejected": -6.571283340454102,
      "step": 3068
    },
    {
      "epoch": 1.2276,
      "grad_norm": 0.0073560550808906555,
      "learning_rate": 5.909333333333333e-07,
      "logits/chosen": -1.805332899093628,
      "logits/rejected": -3.521725654602051,
      "logps/chosen": -67.62081909179688,
      "logps/rejected": -184.4908905029297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8283438682556152,
      "rewards/margins": 10.344568252563477,
      "rewards/rejected": -7.516223907470703,
      "step": 3069
    },
    {
      "epoch": 1.228,
      "grad_norm": 0.009941698051989079,
      "learning_rate": 5.907999999999999e-07,
      "logits/chosen": -2.76638126373291,
      "logits/rejected": -3.3995673656463623,
      "logps/chosen": -175.0571746826172,
      "logps/rejected": -206.65260314941406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.080409526824951,
      "rewards/margins": 10.447689056396484,
      "rewards/rejected": -8.367280006408691,
      "step": 3070
    },
    {
      "epoch": 1.2284,
      "grad_norm": 0.02017091028392315,
      "learning_rate": 5.906666666666666e-07,
      "logits/chosen": -2.9184093475341797,
      "logits/rejected": -2.798063278198242,
      "logps/chosen": -138.2709503173828,
      "logps/rejected": -150.52658081054688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.083713054656982,
      "rewards/margins": 9.540918350219727,
      "rewards/rejected": -5.457205295562744,
      "step": 3071
    },
    {
      "epoch": 1.2288000000000001,
      "grad_norm": 3.061818838119507,
      "learning_rate": 5.905333333333333e-07,
      "logits/chosen": -2.4831509590148926,
      "logits/rejected": -2.859795093536377,
      "logps/chosen": -115.12712097167969,
      "logps/rejected": -138.358154296875,
      "loss": 0.0219,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3580707311630249,
      "rewards/margins": 5.394317626953125,
      "rewards/rejected": -5.036246299743652,
      "step": 3072
    },
    {
      "epoch": 1.2292,
      "grad_norm": 0.013646181672811508,
      "learning_rate": 5.904e-07,
      "logits/chosen": -2.525484085083008,
      "logits/rejected": -2.851337194442749,
      "logps/chosen": -136.43011474609375,
      "logps/rejected": -188.36941528320312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.472726821899414,
      "rewards/margins": 10.574047088623047,
      "rewards/rejected": -7.101320266723633,
      "step": 3073
    },
    {
      "epoch": 1.2296,
      "grad_norm": 0.015942569822072983,
      "learning_rate": 5.902666666666667e-07,
      "logits/chosen": -2.4201722145080566,
      "logits/rejected": -3.6004838943481445,
      "logps/chosen": -128.97068786621094,
      "logps/rejected": -160.63125610351562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6379127502441406,
      "rewards/margins": 10.109939575195312,
      "rewards/rejected": -7.4720258712768555,
      "step": 3074
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.15477649867534637,
      "learning_rate": 5.901333333333333e-07,
      "logits/chosen": -2.3752803802490234,
      "logits/rejected": -3.309129476547241,
      "logps/chosen": -142.27435302734375,
      "logps/rejected": -213.6357421875,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.248293161392212,
      "rewards/margins": 9.335166931152344,
      "rewards/rejected": -7.086874485015869,
      "step": 3075
    },
    {
      "epoch": 1.2304,
      "grad_norm": 0.005186822731047869,
      "learning_rate": 5.9e-07,
      "logits/chosen": -2.1142969131469727,
      "logits/rejected": -3.5367350578308105,
      "logps/chosen": -130.871826171875,
      "logps/rejected": -200.8818359375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.052462100982666,
      "rewards/margins": 10.227094650268555,
      "rewards/rejected": -8.174633026123047,
      "step": 3076
    },
    {
      "epoch": 1.2308,
      "grad_norm": 0.028556745499372482,
      "learning_rate": 5.898666666666667e-07,
      "logits/chosen": -2.3212339878082275,
      "logits/rejected": -2.8181259632110596,
      "logps/chosen": -145.87388610839844,
      "logps/rejected": -231.03125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0561506748199463,
      "rewards/margins": 8.923181533813477,
      "rewards/rejected": -6.867031097412109,
      "step": 3077
    },
    {
      "epoch": 1.2312,
      "grad_norm": 0.1305769830942154,
      "learning_rate": 5.897333333333333e-07,
      "logits/chosen": -2.602696418762207,
      "logits/rejected": -3.514058828353882,
      "logps/chosen": -138.11135864257812,
      "logps/rejected": -186.79678344726562,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6077263355255127,
      "rewards/margins": 9.351517677307129,
      "rewards/rejected": -6.743791103363037,
      "step": 3078
    },
    {
      "epoch": 1.2316,
      "grad_norm": 0.0015683292876929045,
      "learning_rate": 5.896e-07,
      "logits/chosen": -1.770113229751587,
      "logits/rejected": -3.3438515663146973,
      "logps/chosen": -110.2386474609375,
      "logps/rejected": -176.46209716796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3250572681427,
      "rewards/margins": 11.078930854797363,
      "rewards/rejected": -8.753873825073242,
      "step": 3079
    },
    {
      "epoch": 1.232,
      "grad_norm": 0.010053582489490509,
      "learning_rate": 5.894666666666666e-07,
      "logits/chosen": -2.513209819793701,
      "logits/rejected": -3.6846654415130615,
      "logps/chosen": -136.49903869628906,
      "logps/rejected": -217.29689025878906,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4840179681777954,
      "rewards/margins": 9.458002090454102,
      "rewards/rejected": -7.9739837646484375,
      "step": 3080
    },
    {
      "epoch": 1.2324,
      "grad_norm": 0.10735775530338287,
      "learning_rate": 5.893333333333333e-07,
      "logits/chosen": -2.2684707641601562,
      "logits/rejected": -2.5913805961608887,
      "logps/chosen": -78.5450210571289,
      "logps/rejected": -122.54060363769531,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.495668411254883,
      "rewards/margins": 6.892090797424316,
      "rewards/rejected": -4.396422386169434,
      "step": 3081
    },
    {
      "epoch": 1.2328000000000001,
      "grad_norm": 0.017338141798973083,
      "learning_rate": 5.891999999999999e-07,
      "logits/chosen": -2.3784584999084473,
      "logits/rejected": -3.3887553215026855,
      "logps/chosen": -151.51287841796875,
      "logps/rejected": -195.2576904296875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7393250465393066,
      "rewards/margins": 10.518228530883789,
      "rewards/rejected": -8.77890396118164,
      "step": 3082
    },
    {
      "epoch": 1.2332,
      "grad_norm": 0.22856462001800537,
      "learning_rate": 5.890666666666666e-07,
      "logits/chosen": -1.8846187591552734,
      "logits/rejected": -2.4102213382720947,
      "logps/chosen": -90.25337982177734,
      "logps/rejected": -136.29995727539062,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7859474420547485,
      "rewards/margins": 5.666606903076172,
      "rewards/rejected": -3.8806591033935547,
      "step": 3083
    },
    {
      "epoch": 1.2336,
      "grad_norm": 0.01001814380288124,
      "learning_rate": 5.889333333333333e-07,
      "logits/chosen": -2.2199277877807617,
      "logits/rejected": -3.180699586868286,
      "logps/chosen": -152.24331665039062,
      "logps/rejected": -183.58843994140625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.160428524017334,
      "rewards/margins": 9.390207290649414,
      "rewards/rejected": -7.229779243469238,
      "step": 3084
    },
    {
      "epoch": 1.234,
      "grad_norm": 0.007910053245723248,
      "learning_rate": 5.888e-07,
      "logits/chosen": -2.1667346954345703,
      "logits/rejected": -3.17875337600708,
      "logps/chosen": -121.0951919555664,
      "logps/rejected": -197.83119201660156,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.615212619304657,
      "rewards/margins": 9.648033142089844,
      "rewards/rejected": -9.032819747924805,
      "step": 3085
    },
    {
      "epoch": 1.2344,
      "grad_norm": 2.619180917739868,
      "learning_rate": 5.886666666666667e-07,
      "logits/chosen": -2.63999342918396,
      "logits/rejected": -3.0983176231384277,
      "logps/chosen": -187.97203063964844,
      "logps/rejected": -189.8404541015625,
      "loss": 0.0208,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1427960395812988,
      "rewards/margins": 5.785026550292969,
      "rewards/rejected": -6.927823066711426,
      "step": 3086
    },
    {
      "epoch": 1.2348,
      "grad_norm": 0.0012550095561891794,
      "learning_rate": 5.885333333333334e-07,
      "logits/chosen": -2.0801029205322266,
      "logits/rejected": -3.6180477142333984,
      "logps/chosen": -136.5296630859375,
      "logps/rejected": -208.4569091796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.258776664733887,
      "rewards/margins": 12.269018173217773,
      "rewards/rejected": -8.01024055480957,
      "step": 3087
    },
    {
      "epoch": 1.2352,
      "grad_norm": 0.031067680567502975,
      "learning_rate": 5.884000000000001e-07,
      "logits/chosen": -2.14553165435791,
      "logits/rejected": -3.201770305633545,
      "logps/chosen": -144.85366821289062,
      "logps/rejected": -213.2667236328125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7959933280944824,
      "rewards/margins": 11.493791580200195,
      "rewards/rejected": -8.697798728942871,
      "step": 3088
    },
    {
      "epoch": 1.2356,
      "grad_norm": 0.016297472640872,
      "learning_rate": 5.882666666666666e-07,
      "logits/chosen": -1.9663586616516113,
      "logits/rejected": -3.580122947692871,
      "logps/chosen": -91.66878509521484,
      "logps/rejected": -174.85980224609375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6245810985565186,
      "rewards/margins": 9.204268455505371,
      "rewards/rejected": -6.579687595367432,
      "step": 3089
    },
    {
      "epoch": 1.236,
      "grad_norm": 0.03024216927587986,
      "learning_rate": 5.881333333333332e-07,
      "logits/chosen": -2.5199050903320312,
      "logits/rejected": -3.406679153442383,
      "logps/chosen": -112.7331314086914,
      "logps/rejected": -166.76324462890625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3108081817626953,
      "rewards/margins": 8.103239059448242,
      "rewards/rejected": -6.792430877685547,
      "step": 3090
    },
    {
      "epoch": 1.2364,
      "grad_norm": 0.1155920997262001,
      "learning_rate": 5.879999999999999e-07,
      "logits/chosen": -2.053659439086914,
      "logits/rejected": -3.325453519821167,
      "logps/chosen": -178.02545166015625,
      "logps/rejected": -199.67234802246094,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.745516300201416,
      "rewards/margins": 10.228346824645996,
      "rewards/rejected": -8.482830047607422,
      "step": 3091
    },
    {
      "epoch": 1.2368000000000001,
      "grad_norm": 0.10952604562044144,
      "learning_rate": 5.878666666666666e-07,
      "logits/chosen": -2.4251797199249268,
      "logits/rejected": -3.423696756362915,
      "logps/chosen": -146.29214477539062,
      "logps/rejected": -150.93569946289062,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9270052909851074,
      "rewards/margins": 6.94227933883667,
      "rewards/rejected": -5.0152740478515625,
      "step": 3092
    },
    {
      "epoch": 1.2372,
      "grad_norm": 0.1281321793794632,
      "learning_rate": 5.877333333333333e-07,
      "logits/chosen": -2.179441213607788,
      "logits/rejected": -3.190406084060669,
      "logps/chosen": -115.67597961425781,
      "logps/rejected": -159.08570861816406,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1901836395263672,
      "rewards/margins": 7.968720436096191,
      "rewards/rejected": -6.778536319732666,
      "step": 3093
    },
    {
      "epoch": 1.2376,
      "grad_norm": 0.002358068944886327,
      "learning_rate": 5.876e-07,
      "logits/chosen": -2.4498026371002197,
      "logits/rejected": -3.321805238723755,
      "logps/chosen": -111.89340209960938,
      "logps/rejected": -187.34515380859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9621227979660034,
      "rewards/margins": 10.872071266174316,
      "rewards/rejected": -8.909948348999023,
      "step": 3094
    },
    {
      "epoch": 1.238,
      "grad_norm": 0.023265767842531204,
      "learning_rate": 5.874666666666667e-07,
      "logits/chosen": -2.10384464263916,
      "logits/rejected": -3.4925336837768555,
      "logps/chosen": -97.94004821777344,
      "logps/rejected": -175.02609252929688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.81473970413208,
      "rewards/margins": 9.098381042480469,
      "rewards/rejected": -6.283641815185547,
      "step": 3095
    },
    {
      "epoch": 1.2384,
      "grad_norm": 0.038852304220199585,
      "learning_rate": 5.873333333333334e-07,
      "logits/chosen": -2.5010013580322266,
      "logits/rejected": -3.3693690299987793,
      "logps/chosen": -180.1089324951172,
      "logps/rejected": -186.12692260742188,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6420296430587769,
      "rewards/margins": 9.078777313232422,
      "rewards/rejected": -7.436748504638672,
      "step": 3096
    },
    {
      "epoch": 1.2388,
      "grad_norm": 0.026762479916214943,
      "learning_rate": 5.872000000000001e-07,
      "logits/chosen": -2.036550998687744,
      "logits/rejected": -3.2901062965393066,
      "logps/chosen": -100.33129119873047,
      "logps/rejected": -163.8977508544922,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0739340782165527,
      "rewards/margins": 9.756412506103516,
      "rewards/rejected": -7.682478427886963,
      "step": 3097
    },
    {
      "epoch": 1.2392,
      "grad_norm": 0.0027837809175252914,
      "learning_rate": 5.870666666666666e-07,
      "logits/chosen": -2.1911492347717285,
      "logits/rejected": -3.914109706878662,
      "logps/chosen": -91.8660888671875,
      "logps/rejected": -207.39263916015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6939656734466553,
      "rewards/margins": 12.090103149414062,
      "rewards/rejected": -8.396137237548828,
      "step": 3098
    },
    {
      "epoch": 1.2396,
      "grad_norm": 0.06284007430076599,
      "learning_rate": 5.869333333333332e-07,
      "logits/chosen": -2.234342575073242,
      "logits/rejected": -3.3534867763519287,
      "logps/chosen": -115.73845672607422,
      "logps/rejected": -180.0885009765625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.976633071899414,
      "rewards/margins": 8.81582260131836,
      "rewards/rejected": -6.839189529418945,
      "step": 3099
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.22895675897598267,
      "learning_rate": 5.867999999999999e-07,
      "logits/chosen": -2.0032501220703125,
      "logits/rejected": -3.267686605453491,
      "logps/chosen": -81.77931213378906,
      "logps/rejected": -151.2957763671875,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.940584421157837,
      "rewards/margins": 8.321466445922852,
      "rewards/rejected": -6.3808817863464355,
      "step": 3100
    },
    {
      "epoch": 1.2404,
      "grad_norm": 0.31110134720802307,
      "learning_rate": 5.866666666666666e-07,
      "logits/chosen": -2.4108099937438965,
      "logits/rejected": -3.3810532093048096,
      "logps/chosen": -107.0269775390625,
      "logps/rejected": -150.41502380371094,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8134994506835938,
      "rewards/margins": 7.988905906677246,
      "rewards/rejected": -6.175406455993652,
      "step": 3101
    },
    {
      "epoch": 1.2408,
      "grad_norm": 0.26998171210289,
      "learning_rate": 5.865333333333333e-07,
      "logits/chosen": -2.2056896686553955,
      "logits/rejected": -2.7412233352661133,
      "logps/chosen": -88.48623657226562,
      "logps/rejected": -137.61935424804688,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.334794044494629,
      "rewards/margins": 8.35588550567627,
      "rewards/rejected": -6.021091461181641,
      "step": 3102
    },
    {
      "epoch": 1.2412,
      "grad_norm": 2.884422540664673,
      "learning_rate": 5.864e-07,
      "logits/chosen": -2.416718006134033,
      "logits/rejected": -3.019101858139038,
      "logps/chosen": -105.97491455078125,
      "logps/rejected": -114.0287094116211,
      "loss": 0.0326,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6195381879806519,
      "rewards/margins": 5.349276542663574,
      "rewards/rejected": -3.7297379970550537,
      "step": 3103
    },
    {
      "epoch": 1.2416,
      "grad_norm": 0.8556586503982544,
      "learning_rate": 5.862666666666667e-07,
      "logits/chosen": -2.4937877655029297,
      "logits/rejected": -3.107187271118164,
      "logps/chosen": -147.5987091064453,
      "logps/rejected": -151.1216583251953,
      "loss": 0.0079,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2379084825515747,
      "rewards/margins": 6.862486839294434,
      "rewards/rejected": -5.624578475952148,
      "step": 3104
    },
    {
      "epoch": 1.242,
      "grad_norm": 0.2809755504131317,
      "learning_rate": 5.861333333333333e-07,
      "logits/chosen": -2.218149185180664,
      "logits/rejected": -3.057746171951294,
      "logps/chosen": -115.20993041992188,
      "logps/rejected": -137.48153686523438,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.135059118270874,
      "rewards/margins": 7.006606578826904,
      "rewards/rejected": -4.871547698974609,
      "step": 3105
    },
    {
      "epoch": 1.2424,
      "grad_norm": 0.004581814631819725,
      "learning_rate": 5.86e-07,
      "logits/chosen": -2.2885637283325195,
      "logits/rejected": -3.1565463542938232,
      "logps/chosen": -114.7972412109375,
      "logps/rejected": -196.8986358642578,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.345452070236206,
      "rewards/margins": 11.409461975097656,
      "rewards/rejected": -9.064009666442871,
      "step": 3106
    },
    {
      "epoch": 1.2428,
      "grad_norm": 0.005710846744477749,
      "learning_rate": 5.858666666666667e-07,
      "logits/chosen": -1.8955336809158325,
      "logits/rejected": -2.52885103225708,
      "logps/chosen": -74.4835433959961,
      "logps/rejected": -154.099853515625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.492707252502441,
      "rewards/margins": 10.134225845336914,
      "rewards/rejected": -5.641519069671631,
      "step": 3107
    },
    {
      "epoch": 1.2432,
      "grad_norm": 0.5010331273078918,
      "learning_rate": 5.857333333333333e-07,
      "logits/chosen": -2.666598320007324,
      "logits/rejected": -3.1621103286743164,
      "logps/chosen": -109.33930969238281,
      "logps/rejected": -144.2867431640625,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6401481032371521,
      "rewards/margins": 7.001278877258301,
      "rewards/rejected": -6.361131191253662,
      "step": 3108
    },
    {
      "epoch": 1.2436,
      "grad_norm": 0.04105314984917641,
      "learning_rate": 5.856e-07,
      "logits/chosen": -2.45357084274292,
      "logits/rejected": -2.582411289215088,
      "logps/chosen": -136.06271362304688,
      "logps/rejected": -112.92005157470703,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.516364574432373,
      "rewards/margins": 8.059205055236816,
      "rewards/rejected": -4.542840957641602,
      "step": 3109
    },
    {
      "epoch": 1.244,
      "grad_norm": 0.005866833496838808,
      "learning_rate": 5.854666666666666e-07,
      "logits/chosen": -1.8584556579589844,
      "logits/rejected": -3.0452139377593994,
      "logps/chosen": -92.407470703125,
      "logps/rejected": -163.39682006835938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5622572898864746,
      "rewards/margins": 10.023065567016602,
      "rewards/rejected": -6.460809230804443,
      "step": 3110
    },
    {
      "epoch": 1.2444,
      "grad_norm": 0.02777012437582016,
      "learning_rate": 5.853333333333333e-07,
      "logits/chosen": -2.2106411457061768,
      "logits/rejected": -3.849316120147705,
      "logps/chosen": -95.61917877197266,
      "logps/rejected": -187.80068969726562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.02299165725708,
      "rewards/margins": 8.979995727539062,
      "rewards/rejected": -7.957003593444824,
      "step": 3111
    },
    {
      "epoch": 1.2448,
      "grad_norm": 0.01035433728247881,
      "learning_rate": 5.852e-07,
      "logits/chosen": -2.201768159866333,
      "logits/rejected": -2.907935380935669,
      "logps/chosen": -92.51192474365234,
      "logps/rejected": -160.60516357421875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.564276218414307,
      "rewards/margins": 10.327244758605957,
      "rewards/rejected": -5.76296854019165,
      "step": 3112
    },
    {
      "epoch": 1.2452,
      "grad_norm": 2.9484498500823975,
      "learning_rate": 5.850666666666666e-07,
      "logits/chosen": -2.43929123878479,
      "logits/rejected": -3.492504596710205,
      "logps/chosen": -129.42718505859375,
      "logps/rejected": -139.46200561523438,
      "loss": 0.0228,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8602710962295532,
      "rewards/margins": 4.589663505554199,
      "rewards/rejected": -5.449934482574463,
      "step": 3113
    },
    {
      "epoch": 1.2456,
      "grad_norm": 0.02765018306672573,
      "learning_rate": 5.849333333333333e-07,
      "logits/chosen": -2.597158908843994,
      "logits/rejected": -3.9479575157165527,
      "logps/chosen": -222.6101837158203,
      "logps/rejected": -181.53170776367188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0300343036651611,
      "rewards/margins": 9.027973175048828,
      "rewards/rejected": -7.997939586639404,
      "step": 3114
    },
    {
      "epoch": 1.246,
      "grad_norm": 0.019634343683719635,
      "learning_rate": 5.848e-07,
      "logits/chosen": -2.544771671295166,
      "logits/rejected": -3.753325939178467,
      "logps/chosen": -131.6433868408203,
      "logps/rejected": -177.451171875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0818302631378174,
      "rewards/margins": 9.649396896362305,
      "rewards/rejected": -8.56756591796875,
      "step": 3115
    },
    {
      "epoch": 1.2464,
      "grad_norm": 0.034281469881534576,
      "learning_rate": 5.846666666666667e-07,
      "logits/chosen": -2.3810362815856934,
      "logits/rejected": -3.9779961109161377,
      "logps/chosen": -140.98684692382812,
      "logps/rejected": -164.16688537597656,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2613823413848877,
      "rewards/margins": 8.062287330627441,
      "rewards/rejected": -5.800905227661133,
      "step": 3116
    },
    {
      "epoch": 1.2468,
      "grad_norm": 0.11972488462924957,
      "learning_rate": 5.845333333333333e-07,
      "logits/chosen": -2.5794596672058105,
      "logits/rejected": -3.5882568359375,
      "logps/chosen": -99.18061065673828,
      "logps/rejected": -178.68142700195312,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7675342559814453,
      "rewards/margins": 7.583827495574951,
      "rewards/rejected": -6.816292762756348,
      "step": 3117
    },
    {
      "epoch": 1.2472,
      "grad_norm": 0.2846294045448303,
      "learning_rate": 5.844e-07,
      "logits/chosen": -2.5037777423858643,
      "logits/rejected": -3.11751127243042,
      "logps/chosen": -83.45677947998047,
      "logps/rejected": -145.32920837402344,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1556346416473389,
      "rewards/margins": 7.224367141723633,
      "rewards/rejected": -6.068732261657715,
      "step": 3118
    },
    {
      "epoch": 1.2476,
      "grad_norm": 0.010129142552614212,
      "learning_rate": 5.842666666666667e-07,
      "logits/chosen": -2.75736927986145,
      "logits/rejected": -3.499508857727051,
      "logps/chosen": -167.6620330810547,
      "logps/rejected": -162.3590087890625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7227940559387207,
      "rewards/margins": 9.956600189208984,
      "rewards/rejected": -7.2338056564331055,
      "step": 3119
    },
    {
      "epoch": 1.248,
      "grad_norm": 0.043102115392684937,
      "learning_rate": 5.841333333333332e-07,
      "logits/chosen": -2.377147674560547,
      "logits/rejected": -2.3464066982269287,
      "logps/chosen": -114.71086120605469,
      "logps/rejected": -152.94158935546875,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.986673355102539,
      "rewards/margins": 7.779449462890625,
      "rewards/rejected": -5.792776107788086,
      "step": 3120
    },
    {
      "epoch": 1.2484,
      "grad_norm": 0.5390084981918335,
      "learning_rate": 5.839999999999999e-07,
      "logits/chosen": -1.8241088390350342,
      "logits/rejected": -3.5318779945373535,
      "logps/chosen": -153.747314453125,
      "logps/rejected": -143.30430603027344,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7029006481170654,
      "rewards/margins": 7.109743118286133,
      "rewards/rejected": -5.406842231750488,
      "step": 3121
    },
    {
      "epoch": 1.2488,
      "grad_norm": 0.0009865943575277925,
      "learning_rate": 5.838666666666666e-07,
      "logits/chosen": -2.1396193504333496,
      "logits/rejected": -3.4216160774230957,
      "logps/chosen": -89.57215118408203,
      "logps/rejected": -201.9923095703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8718605041503906,
      "rewards/margins": 12.882152557373047,
      "rewards/rejected": -9.010292053222656,
      "step": 3122
    },
    {
      "epoch": 1.2492,
      "grad_norm": 0.15688709914684296,
      "learning_rate": 5.837333333333333e-07,
      "logits/chosen": -2.0443010330200195,
      "logits/rejected": -3.5868539810180664,
      "logps/chosen": -131.36016845703125,
      "logps/rejected": -162.58883666992188,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0697548389434814,
      "rewards/margins": 7.493323802947998,
      "rewards/rejected": -6.423569202423096,
      "step": 3123
    },
    {
      "epoch": 1.2496,
      "grad_norm": 0.0005925714503973722,
      "learning_rate": 5.836e-07,
      "logits/chosen": -2.2654521465301514,
      "logits/rejected": -3.306273937225342,
      "logps/chosen": -116.83525085449219,
      "logps/rejected": -192.93411254882812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 5.232016086578369,
      "rewards/margins": 13.221675872802734,
      "rewards/rejected": -7.989659309387207,
      "step": 3124
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.01773758977651596,
      "learning_rate": 5.834666666666667e-07,
      "logits/chosen": -2.2834391593933105,
      "logits/rejected": -3.05796217918396,
      "logps/chosen": -73.18144226074219,
      "logps/rejected": -159.75633239746094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.16235876083374,
      "rewards/margins": 10.346397399902344,
      "rewards/rejected": -6.184039115905762,
      "step": 3125
    },
    {
      "epoch": 1.2504,
      "grad_norm": 0.034752167761325836,
      "learning_rate": 5.833333333333334e-07,
      "logits/chosen": -2.0732665061950684,
      "logits/rejected": -3.069337844848633,
      "logps/chosen": -130.6997833251953,
      "logps/rejected": -146.0604248046875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2010085582733154,
      "rewards/margins": 8.364063262939453,
      "rewards/rejected": -6.163054466247559,
      "step": 3126
    },
    {
      "epoch": 1.2508,
      "grad_norm": 0.17098881304264069,
      "learning_rate": 5.832e-07,
      "logits/chosen": -2.226128101348877,
      "logits/rejected": -2.7914271354675293,
      "logps/chosen": -101.19043731689453,
      "logps/rejected": -143.8319091796875,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6231685876846313,
      "rewards/margins": 6.480388641357422,
      "rewards/rejected": -5.85722017288208,
      "step": 3127
    },
    {
      "epoch": 1.2511999999999999,
      "grad_norm": 0.006066006142646074,
      "learning_rate": 5.830666666666666e-07,
      "logits/chosen": -2.081515073776245,
      "logits/rejected": -3.392993450164795,
      "logps/chosen": -121.90740966796875,
      "logps/rejected": -164.76065063476562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.822092056274414,
      "rewards/margins": 11.067209243774414,
      "rewards/rejected": -7.245116233825684,
      "step": 3128
    },
    {
      "epoch": 1.2516,
      "grad_norm": 0.013330849818885326,
      "learning_rate": 5.829333333333333e-07,
      "logits/chosen": -2.3967995643615723,
      "logits/rejected": -3.4197275638580322,
      "logps/chosen": -112.21878051757812,
      "logps/rejected": -215.36068725585938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6883630752563477,
      "rewards/margins": 11.56881332397461,
      "rewards/rejected": -8.880451202392578,
      "step": 3129
    },
    {
      "epoch": 1.252,
      "grad_norm": 0.14915376901626587,
      "learning_rate": 5.828e-07,
      "logits/chosen": -2.2474732398986816,
      "logits/rejected": -3.503091335296631,
      "logps/chosen": -118.30511474609375,
      "logps/rejected": -226.0750274658203,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4509358406066895,
      "rewards/margins": 7.460371494293213,
      "rewards/rejected": -8.911307334899902,
      "step": 3130
    },
    {
      "epoch": 1.2524,
      "grad_norm": 0.008044151589274406,
      "learning_rate": 5.826666666666666e-07,
      "logits/chosen": -2.2437584400177,
      "logits/rejected": -3.477781057357788,
      "logps/chosen": -137.186767578125,
      "logps/rejected": -180.56048583984375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.017336845397949,
      "rewards/margins": 10.790841102600098,
      "rewards/rejected": -7.773504257202148,
      "step": 3131
    },
    {
      "epoch": 1.2528000000000001,
      "grad_norm": 0.03806345537304878,
      "learning_rate": 5.825333333333333e-07,
      "logits/chosen": -2.6087779998779297,
      "logits/rejected": -3.346125364303589,
      "logps/chosen": -171.9717254638672,
      "logps/rejected": -206.1536865234375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7504669427871704,
      "rewards/margins": 8.280461311340332,
      "rewards/rejected": -7.529994010925293,
      "step": 3132
    },
    {
      "epoch": 1.2532,
      "grad_norm": 0.0028171255253255367,
      "learning_rate": 5.824e-07,
      "logits/chosen": -1.9782016277313232,
      "logits/rejected": -3.2505640983581543,
      "logps/chosen": -112.31997680664062,
      "logps/rejected": -179.13323974609375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2434298992156982,
      "rewards/margins": 10.733804702758789,
      "rewards/rejected": -8.490373611450195,
      "step": 3133
    },
    {
      "epoch": 1.2536,
      "grad_norm": 0.1624986231327057,
      "learning_rate": 5.822666666666667e-07,
      "logits/chosen": -2.564262866973877,
      "logits/rejected": -2.9793620109558105,
      "logps/chosen": -141.81005859375,
      "logps/rejected": -162.3377227783203,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8086814880371094,
      "rewards/margins": 8.875381469726562,
      "rewards/rejected": -7.066699981689453,
      "step": 3134
    },
    {
      "epoch": 1.254,
      "grad_norm": 0.009163148701190948,
      "learning_rate": 5.821333333333333e-07,
      "logits/chosen": -2.2533016204833984,
      "logits/rejected": -3.0951027870178223,
      "logps/chosen": -198.33761596679688,
      "logps/rejected": -203.91094970703125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6163270473480225,
      "rewards/margins": 9.544647216796875,
      "rewards/rejected": -6.928319931030273,
      "step": 3135
    },
    {
      "epoch": 1.2544,
      "grad_norm": 0.7052271962165833,
      "learning_rate": 5.819999999999999e-07,
      "logits/chosen": -1.804659366607666,
      "logits/rejected": -3.233264446258545,
      "logps/chosen": -81.46842956542969,
      "logps/rejected": -147.57199096679688,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.008364483714103699,
      "rewards/margins": 6.274846076965332,
      "rewards/rejected": -6.283210754394531,
      "step": 3136
    },
    {
      "epoch": 1.2548,
      "grad_norm": 0.19000886380672455,
      "learning_rate": 5.818666666666666e-07,
      "logits/chosen": -1.8850562572479248,
      "logits/rejected": -3.2110562324523926,
      "logps/chosen": -162.8245086669922,
      "logps/rejected": -137.91653442382812,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6813583374023438,
      "rewards/margins": 7.110746383666992,
      "rewards/rejected": -6.429388046264648,
      "step": 3137
    },
    {
      "epoch": 1.2551999999999999,
      "grad_norm": 0.06551241129636765,
      "learning_rate": 5.817333333333333e-07,
      "logits/chosen": -2.1563806533813477,
      "logits/rejected": -3.642807960510254,
      "logps/chosen": -119.5287857055664,
      "logps/rejected": -156.55384826660156,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5428634881973267,
      "rewards/margins": 7.690392017364502,
      "rewards/rejected": -6.147528648376465,
      "step": 3138
    },
    {
      "epoch": 1.2556,
      "grad_norm": 0.0722668245434761,
      "learning_rate": 5.816e-07,
      "logits/chosen": -2.2162132263183594,
      "logits/rejected": -3.14859676361084,
      "logps/chosen": -110.91808319091797,
      "logps/rejected": -148.1868438720703,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.04915714263916,
      "rewards/margins": 7.450123310089111,
      "rewards/rejected": -5.400966644287109,
      "step": 3139
    },
    {
      "epoch": 1.256,
      "grad_norm": 0.9844754338264465,
      "learning_rate": 5.814666666666667e-07,
      "logits/chosen": -2.128568649291992,
      "logits/rejected": -3.0132100582122803,
      "logps/chosen": -112.051025390625,
      "logps/rejected": -130.38987731933594,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3541336059570312,
      "rewards/margins": 6.979602336883545,
      "rewards/rejected": -4.6254682540893555,
      "step": 3140
    },
    {
      "epoch": 1.2564,
      "grad_norm": 0.0047630430199205875,
      "learning_rate": 5.813333333333334e-07,
      "logits/chosen": -1.9748499393463135,
      "logits/rejected": -3.3242318630218506,
      "logps/chosen": -107.43054962158203,
      "logps/rejected": -169.17977905273438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.989403247833252,
      "rewards/margins": 10.109929084777832,
      "rewards/rejected": -7.12052583694458,
      "step": 3141
    },
    {
      "epoch": 1.2568,
      "grad_norm": 0.14408035576343536,
      "learning_rate": 5.812e-07,
      "logits/chosen": -2.041954755783081,
      "logits/rejected": -3.08496356010437,
      "logps/chosen": -138.4808807373047,
      "logps/rejected": -158.65847778320312,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3789879083633423,
      "rewards/margins": 8.630108833312988,
      "rewards/rejected": -7.251120567321777,
      "step": 3142
    },
    {
      "epoch": 1.2572,
      "grad_norm": 0.008806614205241203,
      "learning_rate": 5.810666666666666e-07,
      "logits/chosen": -2.3023314476013184,
      "logits/rejected": -3.3902297019958496,
      "logps/chosen": -183.517578125,
      "logps/rejected": -210.1927490234375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6725754737854004,
      "rewards/margins": 9.54822063446045,
      "rewards/rejected": -7.875644683837891,
      "step": 3143
    },
    {
      "epoch": 1.2576,
      "grad_norm": 0.0033412345219403505,
      "learning_rate": 5.809333333333333e-07,
      "logits/chosen": -2.7524328231811523,
      "logits/rejected": -3.5109355449676514,
      "logps/chosen": -139.44515991210938,
      "logps/rejected": -188.81930541992188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.522154808044434,
      "rewards/margins": 11.760479927062988,
      "rewards/rejected": -7.238325119018555,
      "step": 3144
    },
    {
      "epoch": 1.258,
      "grad_norm": 0.055037714540958405,
      "learning_rate": 5.807999999999999e-07,
      "logits/chosen": -1.8127795457839966,
      "logits/rejected": -3.2552380561828613,
      "logps/chosen": -143.4359130859375,
      "logps/rejected": -182.476318359375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4285125732421875,
      "rewards/margins": 8.387173652648926,
      "rewards/rejected": -6.958661079406738,
      "step": 3145
    },
    {
      "epoch": 1.2584,
      "grad_norm": 0.030097011476755142,
      "learning_rate": 5.806666666666666e-07,
      "logits/chosen": -2.574976921081543,
      "logits/rejected": -3.1701431274414062,
      "logps/chosen": -202.25772094726562,
      "logps/rejected": -175.8133544921875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9809326529502869,
      "rewards/margins": 8.43813419342041,
      "rewards/rejected": -7.457201957702637,
      "step": 3146
    },
    {
      "epoch": 1.2588,
      "grad_norm": 0.00719517283141613,
      "learning_rate": 5.805333333333333e-07,
      "logits/chosen": -2.3637380599975586,
      "logits/rejected": -3.71572208404541,
      "logps/chosen": -104.54804992675781,
      "logps/rejected": -199.73753356933594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9111030101776123,
      "rewards/margins": 11.590365409851074,
      "rewards/rejected": -9.679262161254883,
      "step": 3147
    },
    {
      "epoch": 1.2591999999999999,
      "grad_norm": 0.11152348667383194,
      "learning_rate": 5.804e-07,
      "logits/chosen": -1.7631105184555054,
      "logits/rejected": -2.6929798126220703,
      "logps/chosen": -163.16476440429688,
      "logps/rejected": -148.25807189941406,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0108588933944702,
      "rewards/margins": 6.912184715270996,
      "rewards/rejected": -5.901325702667236,
      "step": 3148
    },
    {
      "epoch": 1.2596,
      "grad_norm": 0.027557509019970894,
      "learning_rate": 5.802666666666667e-07,
      "logits/chosen": -2.459416389465332,
      "logits/rejected": -3.2492833137512207,
      "logps/chosen": -150.14120483398438,
      "logps/rejected": -181.4239044189453,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.72031831741333,
      "rewards/margins": 9.475143432617188,
      "rewards/rejected": -7.754825592041016,
      "step": 3149
    },
    {
      "epoch": 1.26,
      "grad_norm": 2.728640079498291,
      "learning_rate": 5.801333333333333e-07,
      "logits/chosen": -1.9954349994659424,
      "logits/rejected": -3.4947173595428467,
      "logps/chosen": -153.97903442382812,
      "logps/rejected": -148.09751892089844,
      "loss": 0.0163,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21006083488464355,
      "rewards/margins": 6.471347808837891,
      "rewards/rejected": -6.261287212371826,
      "step": 3150
    },
    {
      "epoch": 1.2604,
      "grad_norm": 0.007724484894424677,
      "learning_rate": 5.8e-07,
      "logits/chosen": -2.633601188659668,
      "logits/rejected": -3.523815631866455,
      "logps/chosen": -195.82525634765625,
      "logps/rejected": -172.55738830566406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4001121520996094,
      "rewards/margins": 9.731989860534668,
      "rewards/rejected": -7.331877708435059,
      "step": 3151
    },
    {
      "epoch": 1.2608,
      "grad_norm": 0.14339308440685272,
      "learning_rate": 5.798666666666666e-07,
      "logits/chosen": -2.138599395751953,
      "logits/rejected": -3.0442209243774414,
      "logps/chosen": -147.1792449951172,
      "logps/rejected": -170.68515014648438,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4636543393135071,
      "rewards/margins": 7.2330145835876465,
      "rewards/rejected": -6.769360542297363,
      "step": 3152
    },
    {
      "epoch": 1.2612,
      "grad_norm": 0.002124184975400567,
      "learning_rate": 5.797333333333333e-07,
      "logits/chosen": -2.2285358905792236,
      "logits/rejected": -3.1558115482330322,
      "logps/chosen": -115.54395294189453,
      "logps/rejected": -189.88616943359375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5294642448425293,
      "rewards/margins": 11.138082504272461,
      "rewards/rejected": -7.608617782592773,
      "step": 3153
    },
    {
      "epoch": 1.2616,
      "grad_norm": 15.783527374267578,
      "learning_rate": 5.796e-07,
      "logits/chosen": -2.2229630947113037,
      "logits/rejected": -2.829123020172119,
      "logps/chosen": -105.01459503173828,
      "logps/rejected": -150.72378540039062,
      "loss": 0.1363,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5272150039672852,
      "rewards/margins": 6.349395751953125,
      "rewards/rejected": -4.82218074798584,
      "step": 3154
    },
    {
      "epoch": 1.262,
      "grad_norm": 0.05742137134075165,
      "learning_rate": 5.794666666666666e-07,
      "logits/chosen": -2.0176148414611816,
      "logits/rejected": -3.2251272201538086,
      "logps/chosen": -114.56129455566406,
      "logps/rejected": -197.11985778808594,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0143318176269531,
      "rewards/margins": 7.7863898277282715,
      "rewards/rejected": -6.77205753326416,
      "step": 3155
    },
    {
      "epoch": 1.2624,
      "grad_norm": 0.009676812216639519,
      "learning_rate": 5.793333333333333e-07,
      "logits/chosen": -2.7547101974487305,
      "logits/rejected": -3.603757381439209,
      "logps/chosen": -164.9153289794922,
      "logps/rejected": -192.23602294921875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5856189727783203,
      "rewards/margins": 9.880817413330078,
      "rewards/rejected": -8.295198440551758,
      "step": 3156
    },
    {
      "epoch": 1.2628,
      "grad_norm": 0.0066858744248747826,
      "learning_rate": 5.792e-07,
      "logits/chosen": -2.220703601837158,
      "logits/rejected": -3.3036508560180664,
      "logps/chosen": -114.8333740234375,
      "logps/rejected": -195.95370483398438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2912063598632812,
      "rewards/margins": 10.06612777709961,
      "rewards/rejected": -7.774921417236328,
      "step": 3157
    },
    {
      "epoch": 1.2631999999999999,
      "grad_norm": 0.0028761490248143673,
      "learning_rate": 5.790666666666666e-07,
      "logits/chosen": -1.959073781967163,
      "logits/rejected": -3.6915395259857178,
      "logps/chosen": -100.70948791503906,
      "logps/rejected": -237.58595275878906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7574764490127563,
      "rewards/margins": 12.366971969604492,
      "rewards/rejected": -10.609495162963867,
      "step": 3158
    },
    {
      "epoch": 1.2636,
      "grad_norm": 0.327236533164978,
      "learning_rate": 5.789333333333333e-07,
      "logits/chosen": -2.9029579162597656,
      "logits/rejected": -3.3348228931427,
      "logps/chosen": -205.38583374023438,
      "logps/rejected": -193.6752471923828,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4165611267089844,
      "rewards/margins": 6.012016296386719,
      "rewards/rejected": -6.428577423095703,
      "step": 3159
    },
    {
      "epoch": 1.264,
      "grad_norm": 0.09558172523975372,
      "learning_rate": 5.788e-07,
      "logits/chosen": -2.5588552951812744,
      "logits/rejected": -3.1956255435943604,
      "logps/chosen": -89.57459259033203,
      "logps/rejected": -179.140380859375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2810814380645752,
      "rewards/margins": 9.938322067260742,
      "rewards/rejected": -8.657240867614746,
      "step": 3160
    },
    {
      "epoch": 1.2644,
      "grad_norm": 1.2543625831604004,
      "learning_rate": 5.786666666666667e-07,
      "logits/chosen": -2.9306116104125977,
      "logits/rejected": -3.098785400390625,
      "logps/chosen": -259.3002624511719,
      "logps/rejected": -249.35707092285156,
      "loss": 0.0063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9381417036056519,
      "rewards/margins": 9.122575759887695,
      "rewards/rejected": -8.18443489074707,
      "step": 3161
    },
    {
      "epoch": 1.2648,
      "grad_norm": 4.777478218078613,
      "learning_rate": 5.785333333333334e-07,
      "logits/chosen": -2.873593807220459,
      "logits/rejected": -3.3944802284240723,
      "logps/chosen": -192.5987091064453,
      "logps/rejected": -224.04896545410156,
      "loss": 0.0533,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.877428412437439,
      "rewards/margins": 6.614739894866943,
      "rewards/rejected": -5.737311363220215,
      "step": 3162
    },
    {
      "epoch": 1.2652,
      "grad_norm": 0.038152094930410385,
      "learning_rate": 5.784e-07,
      "logits/chosen": -2.1612706184387207,
      "logits/rejected": -2.6304798126220703,
      "logps/chosen": -79.42759704589844,
      "logps/rejected": -138.01022338867188,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2584986686706543,
      "rewards/margins": 9.264847755432129,
      "rewards/rejected": -6.006349086761475,
      "step": 3163
    },
    {
      "epoch": 1.2656,
      "grad_norm": 0.026752490550279617,
      "learning_rate": 5.782666666666666e-07,
      "logits/chosen": -1.5254547595977783,
      "logits/rejected": -2.8518171310424805,
      "logps/chosen": -84.57606506347656,
      "logps/rejected": -198.45376586914062,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4307069778442383,
      "rewards/margins": 9.625362396240234,
      "rewards/rejected": -6.194655418395996,
      "step": 3164
    },
    {
      "epoch": 1.266,
      "grad_norm": 0.0031374983955174685,
      "learning_rate": 5.781333333333333e-07,
      "logits/chosen": -2.106416940689087,
      "logits/rejected": -3.689897060394287,
      "logps/chosen": -120.16661071777344,
      "logps/rejected": -197.8560791015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.921069383621216,
      "rewards/margins": 10.515320777893066,
      "rewards/rejected": -7.59425163269043,
      "step": 3165
    },
    {
      "epoch": 1.2664,
      "grad_norm": 0.22325286269187927,
      "learning_rate": 5.779999999999999e-07,
      "logits/chosen": -2.257124900817871,
      "logits/rejected": -2.2875406742095947,
      "logps/chosen": -91.65628051757812,
      "logps/rejected": -147.25022888183594,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.709232807159424,
      "rewards/margins": 7.810111045837402,
      "rewards/rejected": -5.1008782386779785,
      "step": 3166
    },
    {
      "epoch": 1.2668,
      "grad_norm": 0.013641858473420143,
      "learning_rate": 5.778666666666666e-07,
      "logits/chosen": -2.183626174926758,
      "logits/rejected": -3.6380014419555664,
      "logps/chosen": -150.21376037597656,
      "logps/rejected": -262.3482666015625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9987807273864746,
      "rewards/margins": 10.621379852294922,
      "rewards/rejected": -7.622598648071289,
      "step": 3167
    },
    {
      "epoch": 1.2671999999999999,
      "grad_norm": 0.02987021394073963,
      "learning_rate": 5.777333333333333e-07,
      "logits/chosen": -2.5418429374694824,
      "logits/rejected": -3.632262706756592,
      "logps/chosen": -155.65252685546875,
      "logps/rejected": -203.9285430908203,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.655377984046936,
      "rewards/margins": 9.891925811767578,
      "rewards/rejected": -9.236547470092773,
      "step": 3168
    },
    {
      "epoch": 1.2676,
      "grad_norm": 0.1129482090473175,
      "learning_rate": 5.776e-07,
      "logits/chosen": -2.012326240539551,
      "logits/rejected": -3.2722368240356445,
      "logps/chosen": -144.479736328125,
      "logps/rejected": -274.6001281738281,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7839500308036804,
      "rewards/margins": 7.553432941436768,
      "rewards/rejected": -8.337383270263672,
      "step": 3169
    },
    {
      "epoch": 1.268,
      "grad_norm": 0.019317906349897385,
      "learning_rate": 5.774666666666667e-07,
      "logits/chosen": -1.9136173725128174,
      "logits/rejected": -3.278524875640869,
      "logps/chosen": -162.9046630859375,
      "logps/rejected": -204.41607666015625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.082202911376953,
      "rewards/margins": 11.040328025817871,
      "rewards/rejected": -7.958125114440918,
      "step": 3170
    },
    {
      "epoch": 1.2684,
      "grad_norm": 0.08918654173612595,
      "learning_rate": 5.773333333333334e-07,
      "logits/chosen": -2.1918864250183105,
      "logits/rejected": -3.5541486740112305,
      "logps/chosen": -159.81222534179688,
      "logps/rejected": -197.01470947265625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.003253161907196045,
      "rewards/margins": 7.8431782722473145,
      "rewards/rejected": -7.8399248123168945,
      "step": 3171
    },
    {
      "epoch": 1.2688,
      "grad_norm": 0.001103584305383265,
      "learning_rate": 5.772000000000001e-07,
      "logits/chosen": -2.3820366859436035,
      "logits/rejected": -3.5813698768615723,
      "logps/chosen": -157.220947265625,
      "logps/rejected": -170.8631591796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.082060813903809,
      "rewards/margins": 11.596359252929688,
      "rewards/rejected": -7.5142974853515625,
      "step": 3172
    },
    {
      "epoch": 1.2692,
      "grad_norm": 0.05639147013425827,
      "learning_rate": 5.770666666666665e-07,
      "logits/chosen": -2.285888671875,
      "logits/rejected": -3.0140836238861084,
      "logps/chosen": -144.25607299804688,
      "logps/rejected": -195.84307861328125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.185159206390381,
      "rewards/margins": 9.61247730255127,
      "rewards/rejected": -7.4273176193237305,
      "step": 3173
    },
    {
      "epoch": 1.2696,
      "grad_norm": 0.07251758873462677,
      "learning_rate": 5.769333333333332e-07,
      "logits/chosen": -1.8191535472869873,
      "logits/rejected": -2.83204984664917,
      "logps/chosen": -67.43523406982422,
      "logps/rejected": -133.2186279296875,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.256296396255493,
      "rewards/margins": 7.991191864013672,
      "rewards/rejected": -4.7348952293396,
      "step": 3174
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.006873068865388632,
      "learning_rate": 5.767999999999999e-07,
      "logits/chosen": -2.4387950897216797,
      "logits/rejected": -2.732661247253418,
      "logps/chosen": -125.47102355957031,
      "logps/rejected": -178.64682006835938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6888437271118164,
      "rewards/margins": 10.748427391052246,
      "rewards/rejected": -8.05958366394043,
      "step": 3175
    },
    {
      "epoch": 1.2704,
      "grad_norm": 0.15378345549106598,
      "learning_rate": 5.766666666666666e-07,
      "logits/chosen": -2.024890899658203,
      "logits/rejected": -2.600982189178467,
      "logps/chosen": -107.41513061523438,
      "logps/rejected": -139.8972930908203,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9164081811904907,
      "rewards/margins": 6.872937202453613,
      "rewards/rejected": -5.95652961730957,
      "step": 3176
    },
    {
      "epoch": 1.2708,
      "grad_norm": 0.0029903107788413763,
      "learning_rate": 5.765333333333333e-07,
      "logits/chosen": -2.626915454864502,
      "logits/rejected": -3.176539897918701,
      "logps/chosen": -200.3753662109375,
      "logps/rejected": -203.91058349609375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4685006141662598,
      "rewards/margins": 11.73398208618164,
      "rewards/rejected": -8.265480995178223,
      "step": 3177
    },
    {
      "epoch": 1.2711999999999999,
      "grad_norm": 0.004283048678189516,
      "learning_rate": 5.764e-07,
      "logits/chosen": -2.1256022453308105,
      "logits/rejected": -3.494436264038086,
      "logps/chosen": -153.96395874023438,
      "logps/rejected": -169.9874725341797,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5088608264923096,
      "rewards/margins": 10.272647857666016,
      "rewards/rejected": -6.763787269592285,
      "step": 3178
    },
    {
      "epoch": 1.2716,
      "grad_norm": 0.00387370097450912,
      "learning_rate": 5.762666666666667e-07,
      "logits/chosen": -2.3552677631378174,
      "logits/rejected": -3.6048707962036133,
      "logps/chosen": -136.75543212890625,
      "logps/rejected": -202.42938232421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.42791748046875,
      "rewards/margins": 10.731189727783203,
      "rewards/rejected": -9.303271293640137,
      "step": 3179
    },
    {
      "epoch": 1.272,
      "grad_norm": 0.019455580040812492,
      "learning_rate": 5.761333333333334e-07,
      "logits/chosen": -2.163057804107666,
      "logits/rejected": -3.0332717895507812,
      "logps/chosen": -168.17640686035156,
      "logps/rejected": -161.2858123779297,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9230473041534424,
      "rewards/margins": 8.589147567749023,
      "rewards/rejected": -6.666100978851318,
      "step": 3180
    },
    {
      "epoch": 1.2724,
      "grad_norm": 0.9916066527366638,
      "learning_rate": 5.76e-07,
      "logits/chosen": -2.2432913780212402,
      "logits/rejected": -3.1539103984832764,
      "logps/chosen": -101.77497100830078,
      "logps/rejected": -139.91477966308594,
      "loss": 0.0091,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5876165628433228,
      "rewards/margins": 5.761680603027344,
      "rewards/rejected": -5.1740641593933105,
      "step": 3181
    },
    {
      "epoch": 1.2728,
      "grad_norm": 0.4202343821525574,
      "learning_rate": 5.758666666666667e-07,
      "logits/chosen": -2.148658275604248,
      "logits/rejected": -3.4065709114074707,
      "logps/chosen": -178.41506958007812,
      "logps/rejected": -187.75735473632812,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7203269600868225,
      "rewards/margins": 6.861126899719238,
      "rewards/rejected": -6.140800476074219,
      "step": 3182
    },
    {
      "epoch": 1.2732,
      "grad_norm": 0.005418990273028612,
      "learning_rate": 5.757333333333332e-07,
      "logits/chosen": -1.9500744342803955,
      "logits/rejected": -3.119978904724121,
      "logps/chosen": -102.06169891357422,
      "logps/rejected": -155.9560546875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5833024978637695,
      "rewards/margins": 10.267386436462402,
      "rewards/rejected": -7.684083938598633,
      "step": 3183
    },
    {
      "epoch": 1.2736,
      "grad_norm": 0.049054116010665894,
      "learning_rate": 5.755999999999999e-07,
      "logits/chosen": -2.2677783966064453,
      "logits/rejected": -3.205655574798584,
      "logps/chosen": -105.285888671875,
      "logps/rejected": -126.28659057617188,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1836788654327393,
      "rewards/margins": 7.520313262939453,
      "rewards/rejected": -5.336634159088135,
      "step": 3184
    },
    {
      "epoch": 1.274,
      "grad_norm": 0.019349105656147003,
      "learning_rate": 5.754666666666666e-07,
      "logits/chosen": -2.5016465187072754,
      "logits/rejected": -3.2927353382110596,
      "logps/chosen": -265.8930969238281,
      "logps/rejected": -161.53018188476562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3026247024536133,
      "rewards/margins": 10.039816856384277,
      "rewards/rejected": -6.737192153930664,
      "step": 3185
    },
    {
      "epoch": 1.2744,
      "grad_norm": 0.002131799468770623,
      "learning_rate": 5.753333333333333e-07,
      "logits/chosen": -2.331695556640625,
      "logits/rejected": -3.199138641357422,
      "logps/chosen": -140.17782592773438,
      "logps/rejected": -179.33221435546875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.904644727706909,
      "rewards/margins": 11.49189567565918,
      "rewards/rejected": -7.587250709533691,
      "step": 3186
    },
    {
      "epoch": 1.2748,
      "grad_norm": 0.022705959156155586,
      "learning_rate": 5.752e-07,
      "logits/chosen": -2.1877355575561523,
      "logits/rejected": -3.2368884086608887,
      "logps/chosen": -174.68865966796875,
      "logps/rejected": -231.54666137695312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9908897876739502,
      "rewards/margins": 8.939348220825195,
      "rewards/rejected": -7.948458671569824,
      "step": 3187
    },
    {
      "epoch": 1.2752,
      "grad_norm": 0.009582838043570518,
      "learning_rate": 5.750666666666666e-07,
      "logits/chosen": -2.308666706085205,
      "logits/rejected": -3.646355628967285,
      "logps/chosen": -183.80926513671875,
      "logps/rejected": -261.84881591796875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.88532555103302,
      "rewards/margins": 9.568336486816406,
      "rewards/rejected": -7.683010101318359,
      "step": 3188
    },
    {
      "epoch": 1.2756,
      "grad_norm": 0.003333775559440255,
      "learning_rate": 5.749333333333333e-07,
      "logits/chosen": -2.2883431911468506,
      "logits/rejected": -3.4106569290161133,
      "logps/chosen": -116.93891906738281,
      "logps/rejected": -166.74832153320312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2270851135253906,
      "rewards/margins": 10.447073936462402,
      "rewards/rejected": -7.2199883460998535,
      "step": 3189
    },
    {
      "epoch": 1.276,
      "grad_norm": 0.004163706209510565,
      "learning_rate": 5.748e-07,
      "logits/chosen": -1.9823081493377686,
      "logits/rejected": -3.238008975982666,
      "logps/chosen": -167.9354248046875,
      "logps/rejected": -161.07354736328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.078627586364746,
      "rewards/margins": 11.157926559448242,
      "rewards/rejected": -7.079298973083496,
      "step": 3190
    },
    {
      "epoch": 1.2764,
      "grad_norm": 0.010191778652369976,
      "learning_rate": 5.746666666666667e-07,
      "logits/chosen": -2.0142600536346436,
      "logits/rejected": -3.059967279434204,
      "logps/chosen": -97.88945770263672,
      "logps/rejected": -161.33279418945312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4324803352355957,
      "rewards/margins": 10.479754447937012,
      "rewards/rejected": -7.047274112701416,
      "step": 3191
    },
    {
      "epoch": 1.2768,
      "grad_norm": 0.6415467858314514,
      "learning_rate": 5.745333333333333e-07,
      "logits/chosen": -2.7517218589782715,
      "logits/rejected": -3.5755844116210938,
      "logps/chosen": -190.30567932128906,
      "logps/rejected": -210.2979736328125,
      "loss": 0.0051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2042644023895264,
      "rewards/margins": 8.199094772338867,
      "rewards/rejected": -6.994830131530762,
      "step": 3192
    },
    {
      "epoch": 1.2772000000000001,
      "grad_norm": 0.0320386104285717,
      "learning_rate": 5.744e-07,
      "logits/chosen": -2.0422747135162354,
      "logits/rejected": -3.2587027549743652,
      "logps/chosen": -130.45022583007812,
      "logps/rejected": -195.8443603515625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3419957160949707,
      "rewards/margins": 8.908231735229492,
      "rewards/rejected": -7.5662360191345215,
      "step": 3193
    },
    {
      "epoch": 1.2776,
      "grad_norm": 2.008751153945923,
      "learning_rate": 5.742666666666666e-07,
      "logits/chosen": -1.9076483249664307,
      "logits/rejected": -2.8872060775756836,
      "logps/chosen": -151.20364379882812,
      "logps/rejected": -141.46072387695312,
      "loss": 0.0134,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9600608944892883,
      "rewards/margins": 6.964085102081299,
      "rewards/rejected": -6.004024028778076,
      "step": 3194
    },
    {
      "epoch": 1.278,
      "grad_norm": 0.7474678158760071,
      "learning_rate": 5.741333333333333e-07,
      "logits/chosen": -2.4735066890716553,
      "logits/rejected": -2.638824462890625,
      "logps/chosen": -117.19216918945312,
      "logps/rejected": -195.37356567382812,
      "loss": 0.0052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1674156188964844,
      "rewards/margins": 10.162642478942871,
      "rewards/rejected": -7.995226860046387,
      "step": 3195
    },
    {
      "epoch": 1.2784,
      "grad_norm": 0.7651922106742859,
      "learning_rate": 5.739999999999999e-07,
      "logits/chosen": -1.6897796392440796,
      "logits/rejected": -2.706798791885376,
      "logps/chosen": -80.25115966796875,
      "logps/rejected": -150.49954223632812,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8277406692504883,
      "rewards/margins": 8.54544448852539,
      "rewards/rejected": -5.717703819274902,
      "step": 3196
    },
    {
      "epoch": 1.2788,
      "grad_norm": 0.0022398580331355333,
      "learning_rate": 5.738666666666666e-07,
      "logits/chosen": -2.289292097091675,
      "logits/rejected": -3.7414188385009766,
      "logps/chosen": -156.1019287109375,
      "logps/rejected": -217.5732421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.453888416290283,
      "rewards/margins": 10.82204818725586,
      "rewards/rejected": -7.368159294128418,
      "step": 3197
    },
    {
      "epoch": 1.2792,
      "grad_norm": 0.0025841593742370605,
      "learning_rate": 5.737333333333333e-07,
      "logits/chosen": -2.0352072715759277,
      "logits/rejected": -3.19653582572937,
      "logps/chosen": -121.99957275390625,
      "logps/rejected": -220.71910095214844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.113542318344116,
      "rewards/margins": 11.428459167480469,
      "rewards/rejected": -8.314916610717773,
      "step": 3198
    },
    {
      "epoch": 1.2796,
      "grad_norm": 0.34884345531463623,
      "learning_rate": 5.736e-07,
      "logits/chosen": -1.6927235126495361,
      "logits/rejected": -3.2316999435424805,
      "logps/chosen": -119.88054656982422,
      "logps/rejected": -141.8130645751953,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1484115719795227,
      "rewards/margins": 6.163239479064941,
      "rewards/rejected": -6.014827728271484,
      "step": 3199
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.5888371467590332,
      "learning_rate": 5.734666666666667e-07,
      "logits/chosen": -2.717000961303711,
      "logits/rejected": -3.3590078353881836,
      "logps/chosen": -105.72342681884766,
      "logps/rejected": -152.0982666015625,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7150924801826477,
      "rewards/margins": 7.713465213775635,
      "rewards/rejected": -6.998372554779053,
      "step": 3200
    },
    {
      "epoch": 1.2804,
      "grad_norm": 1.5441466569900513,
      "learning_rate": 5.733333333333334e-07,
      "logits/chosen": -2.75779128074646,
      "logits/rejected": -2.9367027282714844,
      "logps/chosen": -188.9878692626953,
      "logps/rejected": -151.13015747070312,
      "loss": 0.0157,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8003188371658325,
      "rewards/margins": 6.929452896118164,
      "rewards/rejected": -5.129134178161621,
      "step": 3201
    },
    {
      "epoch": 1.2808,
      "grad_norm": 0.0718936175107956,
      "learning_rate": 5.732e-07,
      "logits/chosen": -2.3743739128112793,
      "logits/rejected": -3.0112035274505615,
      "logps/chosen": -172.61572265625,
      "logps/rejected": -163.92141723632812,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2956581115722656,
      "rewards/margins": 7.843939781188965,
      "rewards/rejected": -8.13959789276123,
      "step": 3202
    },
    {
      "epoch": 1.2812000000000001,
      "grad_norm": 0.06286954879760742,
      "learning_rate": 5.730666666666666e-07,
      "logits/chosen": -2.2460708618164062,
      "logits/rejected": -3.033447265625,
      "logps/chosen": -128.6224365234375,
      "logps/rejected": -128.28274536132812,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.569540500640869,
      "rewards/margins": 7.986575126647949,
      "rewards/rejected": -5.41703462600708,
      "step": 3203
    },
    {
      "epoch": 1.2816,
      "grad_norm": 0.22625471651554108,
      "learning_rate": 5.729333333333332e-07,
      "logits/chosen": -2.564455509185791,
      "logits/rejected": -3.798548460006714,
      "logps/chosen": -139.6654052734375,
      "logps/rejected": -191.3834228515625,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.12054136395454407,
      "rewards/margins": 6.874403953552246,
      "rewards/rejected": -6.994945049285889,
      "step": 3204
    },
    {
      "epoch": 1.282,
      "grad_norm": 0.5018612146377563,
      "learning_rate": 5.727999999999999e-07,
      "logits/chosen": -2.482407331466675,
      "logits/rejected": -3.3131911754608154,
      "logps/chosen": -228.08058166503906,
      "logps/rejected": -167.27310180664062,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3177887201309204,
      "rewards/margins": 7.246997356414795,
      "rewards/rejected": -6.929208755493164,
      "step": 3205
    },
    {
      "epoch": 1.2824,
      "grad_norm": 0.03649932146072388,
      "learning_rate": 5.726666666666666e-07,
      "logits/chosen": -2.4686460494995117,
      "logits/rejected": -3.0814056396484375,
      "logps/chosen": -112.78327941894531,
      "logps/rejected": -145.7364501953125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0859131813049316,
      "rewards/margins": 8.366954803466797,
      "rewards/rejected": -6.281041145324707,
      "step": 3206
    },
    {
      "epoch": 1.2828,
      "grad_norm": 0.042263589799404144,
      "learning_rate": 5.725333333333333e-07,
      "logits/chosen": -2.78568172454834,
      "logits/rejected": -3.248065710067749,
      "logps/chosen": -204.68032836914062,
      "logps/rejected": -170.7861328125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2181007862091064,
      "rewards/margins": 9.87804126739502,
      "rewards/rejected": -6.659940242767334,
      "step": 3207
    },
    {
      "epoch": 1.2832,
      "grad_norm": 0.014806785620748997,
      "learning_rate": 5.724e-07,
      "logits/chosen": -2.4383134841918945,
      "logits/rejected": -3.6063437461853027,
      "logps/chosen": -129.44912719726562,
      "logps/rejected": -206.85552978515625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.33984375,
      "rewards/margins": 10.598848342895508,
      "rewards/rejected": -7.259004592895508,
      "step": 3208
    },
    {
      "epoch": 1.2836,
      "grad_norm": 4.237555980682373,
      "learning_rate": 5.722666666666667e-07,
      "logits/chosen": -2.590592622756958,
      "logits/rejected": -3.3520355224609375,
      "logps/chosen": -224.129638671875,
      "logps/rejected": -217.98379516601562,
      "loss": 0.0262,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4367904663085938,
      "rewards/margins": 8.724374771118164,
      "rewards/rejected": -7.28758430480957,
      "step": 3209
    },
    {
      "epoch": 1.284,
      "grad_norm": 0.09944713115692139,
      "learning_rate": 5.721333333333334e-07,
      "logits/chosen": -2.6617655754089355,
      "logits/rejected": -3.114421844482422,
      "logps/chosen": -113.43302917480469,
      "logps/rejected": -156.60440063476562,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5016262531280518,
      "rewards/margins": 8.326404571533203,
      "rewards/rejected": -5.8247785568237305,
      "step": 3210
    },
    {
      "epoch": 1.2844,
      "grad_norm": 0.01289114635437727,
      "learning_rate": 5.719999999999999e-07,
      "logits/chosen": -1.9172369241714478,
      "logits/rejected": -3.0886478424072266,
      "logps/chosen": -102.63859558105469,
      "logps/rejected": -159.4156494140625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2397708892822266,
      "rewards/margins": 9.379502296447754,
      "rewards/rejected": -7.139731407165527,
      "step": 3211
    },
    {
      "epoch": 1.2848,
      "grad_norm": 0.032617051154375076,
      "learning_rate": 5.718666666666666e-07,
      "logits/chosen": -2.290457248687744,
      "logits/rejected": -2.997844696044922,
      "logps/chosen": -129.06240844726562,
      "logps/rejected": -151.216552734375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.401535749435425,
      "rewards/margins": 8.323503494262695,
      "rewards/rejected": -5.921967029571533,
      "step": 3212
    },
    {
      "epoch": 1.2852000000000001,
      "grad_norm": 0.457929790019989,
      "learning_rate": 5.717333333333333e-07,
      "logits/chosen": -2.793694496154785,
      "logits/rejected": -3.059384346008301,
      "logps/chosen": -129.61221313476562,
      "logps/rejected": -177.431884765625,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.201681137084961,
      "rewards/margins": 8.618414878845215,
      "rewards/rejected": -7.416733741760254,
      "step": 3213
    },
    {
      "epoch": 1.2856,
      "grad_norm": 0.6997088193893433,
      "learning_rate": 5.716e-07,
      "logits/chosen": -1.9427857398986816,
      "logits/rejected": -2.8822615146636963,
      "logps/chosen": -116.283447265625,
      "logps/rejected": -120.77986907958984,
      "loss": 0.006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7664822340011597,
      "rewards/margins": 5.586889743804932,
      "rewards/rejected": -3.8204076290130615,
      "step": 3214
    },
    {
      "epoch": 1.286,
      "grad_norm": 1.703493595123291,
      "learning_rate": 5.714666666666666e-07,
      "logits/chosen": -2.0566017627716064,
      "logits/rejected": -3.218836784362793,
      "logps/chosen": -101.95608520507812,
      "logps/rejected": -158.49681091308594,
      "loss": 0.0135,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6440227627754211,
      "rewards/margins": 6.827658653259277,
      "rewards/rejected": -6.183635711669922,
      "step": 3215
    },
    {
      "epoch": 1.2864,
      "grad_norm": 0.4431508779525757,
      "learning_rate": 5.713333333333333e-07,
      "logits/chosen": -1.8772441148757935,
      "logits/rejected": -3.2865419387817383,
      "logps/chosen": -74.57760620117188,
      "logps/rejected": -165.05682373046875,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8156570196151733,
      "rewards/margins": 8.206194877624512,
      "rewards/rejected": -6.390538215637207,
      "step": 3216
    },
    {
      "epoch": 1.2868,
      "grad_norm": 0.006721284240484238,
      "learning_rate": 5.712e-07,
      "logits/chosen": -2.8716695308685303,
      "logits/rejected": -2.7065486907958984,
      "logps/chosen": -245.57827758789062,
      "logps/rejected": -192.1611328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8046607971191406,
      "rewards/margins": 10.193418502807617,
      "rewards/rejected": -7.388758182525635,
      "step": 3217
    },
    {
      "epoch": 1.2872,
      "grad_norm": 0.026415180414915085,
      "learning_rate": 5.710666666666666e-07,
      "logits/chosen": -2.704787015914917,
      "logits/rejected": -3.096094846725464,
      "logps/chosen": -163.40109252929688,
      "logps/rejected": -132.71902465820312,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1188063621520996,
      "rewards/margins": 8.248300552368164,
      "rewards/rejected": -6.129494667053223,
      "step": 3218
    },
    {
      "epoch": 1.2876,
      "grad_norm": 0.03284721449017525,
      "learning_rate": 5.709333333333333e-07,
      "logits/chosen": -2.653778553009033,
      "logits/rejected": -3.15791654586792,
      "logps/chosen": -116.53611755371094,
      "logps/rejected": -227.8777313232422,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.097179412841797,
      "rewards/margins": 8.75494384765625,
      "rewards/rejected": -6.6577653884887695,
      "step": 3219
    },
    {
      "epoch": 1.288,
      "grad_norm": 0.004678077530115843,
      "learning_rate": 5.707999999999999e-07,
      "logits/chosen": -2.1179747581481934,
      "logits/rejected": -2.9925475120544434,
      "logps/chosen": -70.14440155029297,
      "logps/rejected": -141.00625610351562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6497910022735596,
      "rewards/margins": 10.244236946105957,
      "rewards/rejected": -6.594446182250977,
      "step": 3220
    },
    {
      "epoch": 1.2884,
      "grad_norm": 1.7708853483200073,
      "learning_rate": 5.706666666666666e-07,
      "logits/chosen": -2.524643898010254,
      "logits/rejected": -3.777360200881958,
      "logps/chosen": -245.11016845703125,
      "logps/rejected": -184.01986694335938,
      "loss": 0.0186,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5023986101150513,
      "rewards/margins": 6.408945083618164,
      "rewards/rejected": -5.906546592712402,
      "step": 3221
    },
    {
      "epoch": 1.2888,
      "grad_norm": 0.04297729581594467,
      "learning_rate": 5.705333333333333e-07,
      "logits/chosen": -1.9797956943511963,
      "logits/rejected": -3.4394097328186035,
      "logps/chosen": -126.76671600341797,
      "logps/rejected": -201.8001251220703,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9486912488937378,
      "rewards/margins": 9.78844928741455,
      "rewards/rejected": -7.839757919311523,
      "step": 3222
    },
    {
      "epoch": 1.2892000000000001,
      "grad_norm": 0.028339162468910217,
      "learning_rate": 5.704e-07,
      "logits/chosen": -1.731142282485962,
      "logits/rejected": -3.2046024799346924,
      "logps/chosen": -132.14566040039062,
      "logps/rejected": -158.99203491210938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5032459497451782,
      "rewards/margins": 8.680814743041992,
      "rewards/rejected": -7.177569389343262,
      "step": 3223
    },
    {
      "epoch": 1.2896,
      "grad_norm": 0.0098177595064044,
      "learning_rate": 5.702666666666667e-07,
      "logits/chosen": -2.130953788757324,
      "logits/rejected": -3.260016441345215,
      "logps/chosen": -180.0615692138672,
      "logps/rejected": -157.18984985351562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6753830909729004,
      "rewards/margins": 10.057636260986328,
      "rewards/rejected": -6.3822526931762695,
      "step": 3224
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.03550605848431587,
      "learning_rate": 5.701333333333334e-07,
      "logits/chosen": -2.167307138442993,
      "logits/rejected": -2.8085267543792725,
      "logps/chosen": -113.99980163574219,
      "logps/rejected": -201.77301025390625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14274254441261292,
      "rewards/margins": 8.205669403076172,
      "rewards/rejected": -8.06292724609375,
      "step": 3225
    },
    {
      "epoch": 1.2904,
      "grad_norm": 0.014579910784959793,
      "learning_rate": 5.699999999999999e-07,
      "logits/chosen": -1.9099310636520386,
      "logits/rejected": -3.3774242401123047,
      "logps/chosen": -69.65151977539062,
      "logps/rejected": -150.96502685546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0541329383850098,
      "rewards/margins": 8.930529594421387,
      "rewards/rejected": -5.876396656036377,
      "step": 3226
    },
    {
      "epoch": 1.2908,
      "grad_norm": 0.0177349504083395,
      "learning_rate": 5.698666666666666e-07,
      "logits/chosen": -2.7764530181884766,
      "logits/rejected": -3.6957521438598633,
      "logps/chosen": -214.16842651367188,
      "logps/rejected": -200.792236328125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.782486915588379,
      "rewards/margins": 10.47149658203125,
      "rewards/rejected": -7.689009666442871,
      "step": 3227
    },
    {
      "epoch": 1.2912,
      "grad_norm": 0.07133565843105316,
      "learning_rate": 5.697333333333333e-07,
      "logits/chosen": -2.0765514373779297,
      "logits/rejected": -3.3721561431884766,
      "logps/chosen": -110.78746032714844,
      "logps/rejected": -203.46185302734375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.26470106840133667,
      "rewards/margins": 9.387163162231445,
      "rewards/rejected": -9.122461318969727,
      "step": 3228
    },
    {
      "epoch": 1.2916,
      "grad_norm": 0.000849424977786839,
      "learning_rate": 5.696e-07,
      "logits/chosen": -2.536557197570801,
      "logits/rejected": -3.6831207275390625,
      "logps/chosen": -129.74118041992188,
      "logps/rejected": -240.2826385498047,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.855813503265381,
      "rewards/margins": 13.803098678588867,
      "rewards/rejected": -8.947284698486328,
      "step": 3229
    },
    {
      "epoch": 1.292,
      "grad_norm": 0.021539118140935898,
      "learning_rate": 5.694666666666666e-07,
      "logits/chosen": -2.260450839996338,
      "logits/rejected": -2.7160274982452393,
      "logps/chosen": -95.07075500488281,
      "logps/rejected": -169.45281982421875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4020915031433105,
      "rewards/margins": 8.797441482543945,
      "rewards/rejected": -6.395349502563477,
      "step": 3230
    },
    {
      "epoch": 1.2924,
      "grad_norm": 0.07940766215324402,
      "learning_rate": 5.693333333333333e-07,
      "logits/chosen": -2.0337438583374023,
      "logits/rejected": -3.517183542251587,
      "logps/chosen": -88.47358703613281,
      "logps/rejected": -197.1811065673828,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4491767883300781,
      "rewards/margins": 10.548725128173828,
      "rewards/rejected": -9.09954833984375,
      "step": 3231
    },
    {
      "epoch": 1.2928,
      "grad_norm": 0.020493634045124054,
      "learning_rate": 5.692e-07,
      "logits/chosen": -2.2339444160461426,
      "logits/rejected": -2.908522129058838,
      "logps/chosen": -123.97383117675781,
      "logps/rejected": -164.5667724609375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.136972427368164,
      "rewards/margins": 8.254144668579102,
      "rewards/rejected": -6.117172718048096,
      "step": 3232
    },
    {
      "epoch": 1.2932000000000001,
      "grad_norm": 0.042960215359926224,
      "learning_rate": 5.690666666666667e-07,
      "logits/chosen": -2.6837878227233887,
      "logits/rejected": -3.9971542358398438,
      "logps/chosen": -249.48809814453125,
      "logps/rejected": -196.32240295410156,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8198150396347046,
      "rewards/margins": 8.163385391235352,
      "rewards/rejected": -7.343570709228516,
      "step": 3233
    },
    {
      "epoch": 1.2936,
      "grad_norm": 0.11353340744972229,
      "learning_rate": 5.689333333333333e-07,
      "logits/chosen": -2.0825419425964355,
      "logits/rejected": -3.2924299240112305,
      "logps/chosen": -200.1795654296875,
      "logps/rejected": -209.62538146972656,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.206225872039795,
      "rewards/margins": 8.970300674438477,
      "rewards/rejected": -5.764074802398682,
      "step": 3234
    },
    {
      "epoch": 1.294,
      "grad_norm": 0.3077906370162964,
      "learning_rate": 5.688e-07,
      "logits/chosen": -2.2098960876464844,
      "logits/rejected": -1.5348124504089355,
      "logps/chosen": -186.86077880859375,
      "logps/rejected": -165.24935913085938,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.227741241455078,
      "rewards/margins": 7.20274543762207,
      "rewards/rejected": -4.975004196166992,
      "step": 3235
    },
    {
      "epoch": 1.2944,
      "grad_norm": 0.0007531918818131089,
      "learning_rate": 5.686666666666667e-07,
      "logits/chosen": -2.3642587661743164,
      "logits/rejected": -3.1341280937194824,
      "logps/chosen": -224.38531494140625,
      "logps/rejected": -250.75819396972656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.483245849609375,
      "rewards/margins": 12.041450500488281,
      "rewards/rejected": -8.558204650878906,
      "step": 3236
    },
    {
      "epoch": 1.2948,
      "grad_norm": 0.10754449665546417,
      "learning_rate": 5.685333333333333e-07,
      "logits/chosen": -2.4035134315490723,
      "logits/rejected": -2.938481330871582,
      "logps/chosen": -123.32284545898438,
      "logps/rejected": -187.73602294921875,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.515756368637085,
      "rewards/margins": 8.666729927062988,
      "rewards/rejected": -6.150973320007324,
      "step": 3237
    },
    {
      "epoch": 1.2952,
      "grad_norm": 0.01001805905252695,
      "learning_rate": 5.684e-07,
      "logits/chosen": -2.5308151245117188,
      "logits/rejected": -2.7952675819396973,
      "logps/chosen": -123.94207000732422,
      "logps/rejected": -171.48983764648438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2052621841430664,
      "rewards/margins": 10.372457504272461,
      "rewards/rejected": -7.167195796966553,
      "step": 3238
    },
    {
      "epoch": 1.2955999999999999,
      "grad_norm": 0.037608154118061066,
      "learning_rate": 5.682666666666666e-07,
      "logits/chosen": -3.1490888595581055,
      "logits/rejected": -3.2736854553222656,
      "logps/chosen": -188.8389129638672,
      "logps/rejected": -198.27532958984375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9773354530334473,
      "rewards/margins": 9.434530258178711,
      "rewards/rejected": -7.4571943283081055,
      "step": 3239
    },
    {
      "epoch": 1.296,
      "grad_norm": 0.15816153585910797,
      "learning_rate": 5.681333333333333e-07,
      "logits/chosen": -2.4433298110961914,
      "logits/rejected": -3.55546498298645,
      "logps/chosen": -141.9429931640625,
      "logps/rejected": -153.0301513671875,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10394401848316193,
      "rewards/margins": 6.287916660308838,
      "rewards/rejected": -6.183972358703613,
      "step": 3240
    },
    {
      "epoch": 1.2964,
      "grad_norm": 0.34035035967826843,
      "learning_rate": 5.679999999999999e-07,
      "logits/chosen": -2.274296760559082,
      "logits/rejected": -2.856468677520752,
      "logps/chosen": -112.50215148925781,
      "logps/rejected": -139.4716339111328,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0368003845214844,
      "rewards/margins": 7.534141540527344,
      "rewards/rejected": -5.497341156005859,
      "step": 3241
    },
    {
      "epoch": 1.2968,
      "grad_norm": 0.8485758900642395,
      "learning_rate": 5.678666666666666e-07,
      "logits/chosen": -2.0222725868225098,
      "logits/rejected": -3.1154236793518066,
      "logps/chosen": -112.88147735595703,
      "logps/rejected": -134.14895629882812,
      "loss": 0.0101,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4293525815010071,
      "rewards/margins": 4.594395637512207,
      "rewards/rejected": -5.023748397827148,
      "step": 3242
    },
    {
      "epoch": 1.2972000000000001,
      "grad_norm": 0.003390744561329484,
      "learning_rate": 5.677333333333333e-07,
      "logits/chosen": -2.252476215362549,
      "logits/rejected": -3.469686985015869,
      "logps/chosen": -60.96435546875,
      "logps/rejected": -160.6766815185547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3276069164276123,
      "rewards/margins": 10.619063377380371,
      "rewards/rejected": -7.29145622253418,
      "step": 3243
    },
    {
      "epoch": 1.2976,
      "grad_norm": 0.10727965831756592,
      "learning_rate": 5.676e-07,
      "logits/chosen": -2.458390235900879,
      "logits/rejected": -3.245387554168701,
      "logps/chosen": -123.00465393066406,
      "logps/rejected": -175.07632446289062,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.108938217163086,
      "rewards/margins": 9.423196792602539,
      "rewards/rejected": -6.314258098602295,
      "step": 3244
    },
    {
      "epoch": 1.298,
      "grad_norm": 0.013998576439917088,
      "learning_rate": 5.674666666666667e-07,
      "logits/chosen": -1.9899636507034302,
      "logits/rejected": -3.20391845703125,
      "logps/chosen": -117.05803680419922,
      "logps/rejected": -176.57005310058594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6612677574157715,
      "rewards/margins": 9.690421104431152,
      "rewards/rejected": -6.029152870178223,
      "step": 3245
    },
    {
      "epoch": 1.2984,
      "grad_norm": 0.1214490681886673,
      "learning_rate": 5.673333333333334e-07,
      "logits/chosen": -2.1163270473480225,
      "logits/rejected": -3.340644598007202,
      "logps/chosen": -173.94384765625,
      "logps/rejected": -188.667724609375,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.464505672454834,
      "rewards/margins": 8.211763381958008,
      "rewards/rejected": -5.747257232666016,
      "step": 3246
    },
    {
      "epoch": 1.2988,
      "grad_norm": 0.18889223039150238,
      "learning_rate": 5.672e-07,
      "logits/chosen": -2.3592700958251953,
      "logits/rejected": -3.5908029079437256,
      "logps/chosen": -155.54254150390625,
      "logps/rejected": -168.39981079101562,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08571010828018188,
      "rewards/margins": 7.999249458312988,
      "rewards/rejected": -7.913539886474609,
      "step": 3247
    },
    {
      "epoch": 1.2992,
      "grad_norm": 0.015493679791688919,
      "learning_rate": 5.670666666666667e-07,
      "logits/chosen": -2.4824352264404297,
      "logits/rejected": -3.2695083618164062,
      "logps/chosen": -123.98201751708984,
      "logps/rejected": -154.82086181640625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.308736801147461,
      "rewards/margins": 9.501087188720703,
      "rewards/rejected": -6.192350387573242,
      "step": 3248
    },
    {
      "epoch": 1.2995999999999999,
      "grad_norm": 0.003864592406898737,
      "learning_rate": 5.669333333333332e-07,
      "logits/chosen": -2.2433688640594482,
      "logits/rejected": -2.969444751739502,
      "logps/chosen": -145.228515625,
      "logps/rejected": -281.96490478515625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.017160177230835,
      "rewards/margins": 10.542279243469238,
      "rewards/rejected": -7.525118827819824,
      "step": 3249
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.033868707716464996,
      "learning_rate": 5.667999999999999e-07,
      "logits/chosen": -1.7834627628326416,
      "logits/rejected": -3.3113880157470703,
      "logps/chosen": -103.41038513183594,
      "logps/rejected": -189.283203125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4329861402511597,
      "rewards/margins": 8.410381317138672,
      "rewards/rejected": -6.977395057678223,
      "step": 3250
    },
    {
      "epoch": 1.3004,
      "grad_norm": 0.0004161904798820615,
      "learning_rate": 5.666666666666666e-07,
      "logits/chosen": -2.557732105255127,
      "logits/rejected": -3.807084321975708,
      "logps/chosen": -122.34625244140625,
      "logps/rejected": -168.54556274414062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.904232978820801,
      "rewards/margins": 12.5316801071167,
      "rewards/rejected": -7.627447128295898,
      "step": 3251
    },
    {
      "epoch": 1.3008,
      "grad_norm": 0.0171539057046175,
      "learning_rate": 5.665333333333333e-07,
      "logits/chosen": -2.3617873191833496,
      "logits/rejected": -3.1812806129455566,
      "logps/chosen": -74.31471252441406,
      "logps/rejected": -155.174560546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.558176040649414,
      "rewards/margins": 9.004607200622559,
      "rewards/rejected": -5.4464311599731445,
      "step": 3252
    },
    {
      "epoch": 1.3012000000000001,
      "grad_norm": 1.4361544847488403,
      "learning_rate": 5.664e-07,
      "logits/chosen": -2.3622922897338867,
      "logits/rejected": -2.5943193435668945,
      "logps/chosen": -149.28131103515625,
      "logps/rejected": -174.145751953125,
      "loss": 0.011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.023062825202942,
      "rewards/margins": 6.205674171447754,
      "rewards/rejected": -5.182611465454102,
      "step": 3253
    },
    {
      "epoch": 1.3016,
      "grad_norm": 0.3665285110473633,
      "learning_rate": 5.662666666666667e-07,
      "logits/chosen": -2.868262767791748,
      "logits/rejected": -3.209998369216919,
      "logps/chosen": -215.48947143554688,
      "logps/rejected": -178.1783905029297,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0581002235412598,
      "rewards/margins": 6.651677131652832,
      "rewards/rejected": -7.709777355194092,
      "step": 3254
    },
    {
      "epoch": 1.302,
      "grad_norm": 0.08300799131393433,
      "learning_rate": 5.661333333333334e-07,
      "logits/chosen": -2.350644588470459,
      "logits/rejected": -3.453033924102783,
      "logps/chosen": -103.02696990966797,
      "logps/rejected": -193.65249633789062,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3236755430698395,
      "rewards/margins": 7.9129228591918945,
      "rewards/rejected": -7.58924674987793,
      "step": 3255
    },
    {
      "epoch": 1.3024,
      "grad_norm": 0.015657132491469383,
      "learning_rate": 5.66e-07,
      "logits/chosen": -1.895991563796997,
      "logits/rejected": -3.0638785362243652,
      "logps/chosen": -206.7974853515625,
      "logps/rejected": -166.86695861816406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7036831378936768,
      "rewards/margins": 9.145718574523926,
      "rewards/rejected": -6.442034721374512,
      "step": 3256
    },
    {
      "epoch": 1.3028,
      "grad_norm": 0.09729233384132385,
      "learning_rate": 5.658666666666667e-07,
      "logits/chosen": -2.6015701293945312,
      "logits/rejected": -3.342531204223633,
      "logps/chosen": -158.9151611328125,
      "logps/rejected": -159.091064453125,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5599548816680908,
      "rewards/margins": 7.29096794128418,
      "rewards/rejected": -5.731013298034668,
      "step": 3257
    },
    {
      "epoch": 1.3032,
      "grad_norm": 0.020281869918107986,
      "learning_rate": 5.657333333333332e-07,
      "logits/chosen": -1.9989638328552246,
      "logits/rejected": -3.2655856609344482,
      "logps/chosen": -79.71139526367188,
      "logps/rejected": -194.3529815673828,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6848591566085815,
      "rewards/margins": 10.022403717041016,
      "rewards/rejected": -8.337543487548828,
      "step": 3258
    },
    {
      "epoch": 1.3035999999999999,
      "grad_norm": 0.04005316272377968,
      "learning_rate": 5.655999999999999e-07,
      "logits/chosen": -2.626741409301758,
      "logits/rejected": -3.5833377838134766,
      "logps/chosen": -121.3228759765625,
      "logps/rejected": -225.32373046875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.430094838142395,
      "rewards/margins": 10.3767728805542,
      "rewards/rejected": -8.946678161621094,
      "step": 3259
    },
    {
      "epoch": 1.304,
      "grad_norm": 0.023629620671272278,
      "learning_rate": 5.654666666666666e-07,
      "logits/chosen": -2.38211727142334,
      "logits/rejected": -3.2164435386657715,
      "logps/chosen": -118.48069763183594,
      "logps/rejected": -247.44189453125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.012787342071533,
      "rewards/margins": 8.448186874389648,
      "rewards/rejected": -5.435399055480957,
      "step": 3260
    },
    {
      "epoch": 1.3044,
      "grad_norm": 0.002538269618526101,
      "learning_rate": 5.653333333333333e-07,
      "logits/chosen": -2.396406412124634,
      "logits/rejected": -3.285205364227295,
      "logps/chosen": -208.57217407226562,
      "logps/rejected": -179.04046630859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.806361436843872,
      "rewards/margins": 11.407135963439941,
      "rewards/rejected": -7.600774765014648,
      "step": 3261
    },
    {
      "epoch": 1.3048,
      "grad_norm": 0.36168035864830017,
      "learning_rate": 5.652e-07,
      "logits/chosen": -2.289240837097168,
      "logits/rejected": -3.499295473098755,
      "logps/chosen": -222.5040283203125,
      "logps/rejected": -197.93081665039062,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.07434006035327911,
      "rewards/margins": 5.764500617980957,
      "rewards/rejected": -5.838840961456299,
      "step": 3262
    },
    {
      "epoch": 1.3052000000000001,
      "grad_norm": 0.009438246488571167,
      "learning_rate": 5.650666666666667e-07,
      "logits/chosen": -2.1154613494873047,
      "logits/rejected": -3.2843921184539795,
      "logps/chosen": -84.95953369140625,
      "logps/rejected": -151.6436767578125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.383145332336426,
      "rewards/margins": 9.685811996459961,
      "rewards/rejected": -6.302666664123535,
      "step": 3263
    },
    {
      "epoch": 1.3056,
      "grad_norm": 0.00034178621717728674,
      "learning_rate": 5.649333333333333e-07,
      "logits/chosen": -2.2713170051574707,
      "logits/rejected": -3.8474674224853516,
      "logps/chosen": -152.40428161621094,
      "logps/rejected": -193.36758422851562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.451207637786865,
      "rewards/margins": 13.226329803466797,
      "rewards/rejected": -8.77512264251709,
      "step": 3264
    },
    {
      "epoch": 1.306,
      "grad_norm": 0.028332483023405075,
      "learning_rate": 5.648e-07,
      "logits/chosen": -2.758478879928589,
      "logits/rejected": -3.5289573669433594,
      "logps/chosen": -134.3199462890625,
      "logps/rejected": -250.7054443359375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3969463109970093,
      "rewards/margins": 10.51035213470459,
      "rewards/rejected": -9.11340618133545,
      "step": 3265
    },
    {
      "epoch": 1.3064,
      "grad_norm": 0.0171833336353302,
      "learning_rate": 5.646666666666667e-07,
      "logits/chosen": -2.1554811000823975,
      "logits/rejected": -3.4326562881469727,
      "logps/chosen": -133.05874633789062,
      "logps/rejected": -174.20437622070312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.927717685699463,
      "rewards/margins": 10.88154411315918,
      "rewards/rejected": -7.953825950622559,
      "step": 3266
    },
    {
      "epoch": 1.3068,
      "grad_norm": 0.001207228284329176,
      "learning_rate": 5.645333333333333e-07,
      "logits/chosen": -2.1503753662109375,
      "logits/rejected": -3.4275550842285156,
      "logps/chosen": -102.22650909423828,
      "logps/rejected": -202.44667053222656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3119866847991943,
      "rewards/margins": 11.958463668823242,
      "rewards/rejected": -8.646476745605469,
      "step": 3267
    },
    {
      "epoch": 1.3072,
      "grad_norm": 0.002983215730637312,
      "learning_rate": 5.643999999999999e-07,
      "logits/chosen": -2.186225175857544,
      "logits/rejected": -3.785630226135254,
      "logps/chosen": -122.72447204589844,
      "logps/rejected": -160.49757385253906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.782928943634033,
      "rewards/margins": 10.418391227722168,
      "rewards/rejected": -6.635462284088135,
      "step": 3268
    },
    {
      "epoch": 1.3075999999999999,
      "grad_norm": 0.013508959673345089,
      "learning_rate": 5.642666666666666e-07,
      "logits/chosen": -2.2014176845550537,
      "logits/rejected": -3.633786201477051,
      "logps/chosen": -165.62265014648438,
      "logps/rejected": -230.51388549804688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6991991996765137,
      "rewards/margins": 9.337991714477539,
      "rewards/rejected": -5.638792514801025,
      "step": 3269
    },
    {
      "epoch": 1.308,
      "grad_norm": 0.003319383133202791,
      "learning_rate": 5.641333333333333e-07,
      "logits/chosen": -2.407503128051758,
      "logits/rejected": -3.6930084228515625,
      "logps/chosen": -217.790771484375,
      "logps/rejected": -194.0155029296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.340643882751465,
      "rewards/margins": 10.721487998962402,
      "rewards/rejected": -8.380844116210938,
      "step": 3270
    },
    {
      "epoch": 1.3084,
      "grad_norm": 0.0007598235388286412,
      "learning_rate": 5.639999999999999e-07,
      "logits/chosen": -2.2193987369537354,
      "logits/rejected": -3.2651219367980957,
      "logps/chosen": -139.8258056640625,
      "logps/rejected": -169.22836303710938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 5.05111026763916,
      "rewards/margins": 12.23945426940918,
      "rewards/rejected": -7.188344478607178,
      "step": 3271
    },
    {
      "epoch": 1.3088,
      "grad_norm": 0.007241435348987579,
      "learning_rate": 5.638666666666666e-07,
      "logits/chosen": -2.503361701965332,
      "logits/rejected": -3.519730567932129,
      "logps/chosen": -92.57292175292969,
      "logps/rejected": -188.24948120117188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.518855094909668,
      "rewards/margins": 10.114326477050781,
      "rewards/rejected": -6.595470905303955,
      "step": 3272
    },
    {
      "epoch": 1.3092,
      "grad_norm": 0.25435391068458557,
      "learning_rate": 5.637333333333333e-07,
      "logits/chosen": -2.484768867492676,
      "logits/rejected": -3.3298559188842773,
      "logps/chosen": -229.0201416015625,
      "logps/rejected": -171.50868225097656,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1806488037109375,
      "rewards/margins": 5.920292854309082,
      "rewards/rejected": -6.1009416580200195,
      "step": 3273
    },
    {
      "epoch": 1.3096,
      "grad_norm": 0.3523423969745636,
      "learning_rate": 5.636e-07,
      "logits/chosen": -1.7979519367218018,
      "logits/rejected": -3.2519092559814453,
      "logps/chosen": -89.25599670410156,
      "logps/rejected": -141.4923858642578,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5401836633682251,
      "rewards/margins": 6.323115825653076,
      "rewards/rejected": -5.782932281494141,
      "step": 3274
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.08412392437458038,
      "learning_rate": 5.634666666666667e-07,
      "logits/chosen": -2.1139075756073,
      "logits/rejected": -3.119317054748535,
      "logps/chosen": -99.62845611572266,
      "logps/rejected": -211.93728637695312,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4329853057861328,
      "rewards/margins": 9.356386184692383,
      "rewards/rejected": -7.92340087890625,
      "step": 3275
    },
    {
      "epoch": 1.3104,
      "grad_norm": 0.005585668608546257,
      "learning_rate": 5.633333333333334e-07,
      "logits/chosen": -2.0340983867645264,
      "logits/rejected": -3.1681716442108154,
      "logps/chosen": -93.68853759765625,
      "logps/rejected": -178.7577667236328,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2200710773468018,
      "rewards/margins": 10.083553314208984,
      "rewards/rejected": -7.863482475280762,
      "step": 3276
    },
    {
      "epoch": 1.3108,
      "grad_norm": 0.0055672358721494675,
      "learning_rate": 5.632e-07,
      "logits/chosen": -2.282916307449341,
      "logits/rejected": -3.7260773181915283,
      "logps/chosen": -190.0277099609375,
      "logps/rejected": -206.73951721191406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5016486644744873,
      "rewards/margins": 10.687177658081055,
      "rewards/rejected": -9.185528755187988,
      "step": 3277
    },
    {
      "epoch": 1.3112,
      "grad_norm": 0.002034634817391634,
      "learning_rate": 5.630666666666667e-07,
      "logits/chosen": -2.231578826904297,
      "logits/rejected": -3.434619426727295,
      "logps/chosen": -123.09614562988281,
      "logps/rejected": -197.66677856445312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8541860580444336,
      "rewards/margins": 11.944530487060547,
      "rewards/rejected": -8.090344429016113,
      "step": 3278
    },
    {
      "epoch": 1.3115999999999999,
      "grad_norm": 1.072994351387024,
      "learning_rate": 5.629333333333332e-07,
      "logits/chosen": -2.3346686363220215,
      "logits/rejected": -3.071070671081543,
      "logps/chosen": -140.38131713867188,
      "logps/rejected": -138.57789611816406,
      "loss": 0.0075,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2456710934638977,
      "rewards/margins": 5.6437883377075195,
      "rewards/rejected": -5.398117542266846,
      "step": 3279
    },
    {
      "epoch": 1.312,
      "grad_norm": 0.06460133194923401,
      "learning_rate": 5.627999999999999e-07,
      "logits/chosen": -2.735678195953369,
      "logits/rejected": -3.326263904571533,
      "logps/chosen": -135.9517822265625,
      "logps/rejected": -137.66311645507812,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2692383527755737,
      "rewards/margins": 7.367798805236816,
      "rewards/rejected": -6.098560810089111,
      "step": 3280
    },
    {
      "epoch": 1.3124,
      "grad_norm": 0.02175789140164852,
      "learning_rate": 5.626666666666666e-07,
      "logits/chosen": -2.4859819412231445,
      "logits/rejected": -3.154952049255371,
      "logps/chosen": -184.469970703125,
      "logps/rejected": -240.13961791992188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7040772438049316,
      "rewards/margins": 10.319297790527344,
      "rewards/rejected": -7.615220069885254,
      "step": 3281
    },
    {
      "epoch": 1.3128,
      "grad_norm": 0.1426144391298294,
      "learning_rate": 5.625333333333333e-07,
      "logits/chosen": -1.7857730388641357,
      "logits/rejected": -3.248918056488037,
      "logps/chosen": -108.03734588623047,
      "logps/rejected": -153.41049194335938,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8065121173858643,
      "rewards/margins": 8.25457763671875,
      "rewards/rejected": -6.448065757751465,
      "step": 3282
    },
    {
      "epoch": 1.3132,
      "grad_norm": 0.5128206610679626,
      "learning_rate": 5.624e-07,
      "logits/chosen": -2.404615879058838,
      "logits/rejected": -2.497023344039917,
      "logps/chosen": -158.6175537109375,
      "logps/rejected": -123.27880859375,
      "loss": 0.0049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.048211693763733,
      "rewards/margins": 5.572772026062012,
      "rewards/rejected": -4.524560451507568,
      "step": 3283
    },
    {
      "epoch": 1.3136,
      "grad_norm": 0.07973477244377136,
      "learning_rate": 5.622666666666667e-07,
      "logits/chosen": -2.5741848945617676,
      "logits/rejected": -3.2746567726135254,
      "logps/chosen": -132.48207092285156,
      "logps/rejected": -200.02342224121094,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.586137294769287,
      "rewards/margins": 8.419843673706055,
      "rewards/rejected": -4.833705902099609,
      "step": 3284
    },
    {
      "epoch": 1.314,
      "grad_norm": 0.16634432971477509,
      "learning_rate": 5.621333333333334e-07,
      "logits/chosen": -2.685389757156372,
      "logits/rejected": -2.8166890144348145,
      "logps/chosen": -107.7118911743164,
      "logps/rejected": -165.04234313964844,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4855003356933594,
      "rewards/margins": 7.860927581787109,
      "rewards/rejected": -6.375427722930908,
      "step": 3285
    },
    {
      "epoch": 1.3144,
      "grad_norm": 0.6331791877746582,
      "learning_rate": 5.620000000000001e-07,
      "logits/chosen": -2.5087039470672607,
      "logits/rejected": -2.6837453842163086,
      "logps/chosen": -271.680908203125,
      "logps/rejected": -165.22145080566406,
      "loss": 0.0062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.097248911857605,
      "rewards/margins": 6.091853618621826,
      "rewards/rejected": -4.994604587554932,
      "step": 3286
    },
    {
      "epoch": 1.3148,
      "grad_norm": 0.0035858468618243933,
      "learning_rate": 5.618666666666666e-07,
      "logits/chosen": -2.407604694366455,
      "logits/rejected": -3.5067474842071533,
      "logps/chosen": -62.393089294433594,
      "logps/rejected": -157.12506103515625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9076318740844727,
      "rewards/margins": 10.295326232910156,
      "rewards/rejected": -6.387694358825684,
      "step": 3287
    },
    {
      "epoch": 1.3152,
      "grad_norm": 0.0067553892731666565,
      "learning_rate": 5.617333333333333e-07,
      "logits/chosen": -2.3755931854248047,
      "logits/rejected": -3.406905174255371,
      "logps/chosen": -113.44707489013672,
      "logps/rejected": -171.57473754882812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.944007396697998,
      "rewards/margins": 10.030887603759766,
      "rewards/rejected": -7.086879730224609,
      "step": 3288
    },
    {
      "epoch": 1.3155999999999999,
      "grad_norm": 5.9569878578186035,
      "learning_rate": 5.615999999999999e-07,
      "logits/chosen": -2.567951202392578,
      "logits/rejected": -3.185657262802124,
      "logps/chosen": -140.768310546875,
      "logps/rejected": -165.77928161621094,
      "loss": 0.0317,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.324103593826294,
      "rewards/margins": 7.802547454833984,
      "rewards/rejected": -5.478443145751953,
      "step": 3289
    },
    {
      "epoch": 1.316,
      "grad_norm": 0.10260947048664093,
      "learning_rate": 5.614666666666666e-07,
      "logits/chosen": -2.0487618446350098,
      "logits/rejected": -3.3756766319274902,
      "logps/chosen": -137.40924072265625,
      "logps/rejected": -174.8717041015625,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6394256949424744,
      "rewards/margins": 6.98868465423584,
      "rewards/rejected": -6.349259376525879,
      "step": 3290
    },
    {
      "epoch": 1.3164,
      "grad_norm": 0.02724492736160755,
      "learning_rate": 5.613333333333333e-07,
      "logits/chosen": -1.917306661605835,
      "logits/rejected": -2.914882183074951,
      "logps/chosen": -123.8673095703125,
      "logps/rejected": -145.2386932373047,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4880661964416504,
      "rewards/margins": 10.127962112426758,
      "rewards/rejected": -6.639895915985107,
      "step": 3291
    },
    {
      "epoch": 1.3168,
      "grad_norm": 0.008595076389610767,
      "learning_rate": 5.612e-07,
      "logits/chosen": -1.893601655960083,
      "logits/rejected": -2.8612453937530518,
      "logps/chosen": -121.77495574951172,
      "logps/rejected": -195.6885986328125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.469944953918457,
      "rewards/margins": 9.307548522949219,
      "rewards/rejected": -6.837603569030762,
      "step": 3292
    },
    {
      "epoch": 1.3172,
      "grad_norm": 0.3457602858543396,
      "learning_rate": 5.610666666666667e-07,
      "logits/chosen": -2.1552486419677734,
      "logits/rejected": -3.4691100120544434,
      "logps/chosen": -90.29473876953125,
      "logps/rejected": -151.5907440185547,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6692333221435547,
      "rewards/margins": 7.412490367889404,
      "rewards/rejected": -6.743256568908691,
      "step": 3293
    },
    {
      "epoch": 1.3176,
      "grad_norm": 0.8614508509635925,
      "learning_rate": 5.609333333333333e-07,
      "logits/chosen": -1.390800952911377,
      "logits/rejected": -3.158961772918701,
      "logps/chosen": -102.37521362304688,
      "logps/rejected": -158.17156982421875,
      "loss": 0.0051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.476322889328003,
      "rewards/margins": 8.66201114654541,
      "rewards/rejected": -7.185688018798828,
      "step": 3294
    },
    {
      "epoch": 1.318,
      "grad_norm": 0.05844319611787796,
      "learning_rate": 5.608e-07,
      "logits/chosen": -2.086944580078125,
      "logits/rejected": -3.8107218742370605,
      "logps/chosen": -120.56892395019531,
      "logps/rejected": -173.8875274658203,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9242485761642456,
      "rewards/margins": 9.26794719696045,
      "rewards/rejected": -7.343698501586914,
      "step": 3295
    },
    {
      "epoch": 1.3184,
      "grad_norm": 0.13501407206058502,
      "learning_rate": 5.606666666666666e-07,
      "logits/chosen": -2.593313455581665,
      "logits/rejected": -3.4377522468566895,
      "logps/chosen": -255.78256225585938,
      "logps/rejected": -168.4666290283203,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2288124561309814,
      "rewards/margins": 7.649133205413818,
      "rewards/rejected": -6.420320510864258,
      "step": 3296
    },
    {
      "epoch": 1.3188,
      "grad_norm": 0.005056895315647125,
      "learning_rate": 5.605333333333333e-07,
      "logits/chosen": -2.4453601837158203,
      "logits/rejected": -3.443784713745117,
      "logps/chosen": -209.82171630859375,
      "logps/rejected": -179.98358154296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.015578269958496,
      "rewards/margins": 10.16309928894043,
      "rewards/rejected": -6.147521018981934,
      "step": 3297
    },
    {
      "epoch": 1.3192,
      "grad_norm": 0.04942365735769272,
      "learning_rate": 5.604e-07,
      "logits/chosen": -2.3755292892456055,
      "logits/rejected": -3.559812068939209,
      "logps/chosen": -226.4959716796875,
      "logps/rejected": -164.5074462890625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1017684936523438,
      "rewards/margins": 7.931953430175781,
      "rewards/rejected": -6.830185413360596,
      "step": 3298
    },
    {
      "epoch": 1.3195999999999999,
      "grad_norm": 0.00044339371379464865,
      "learning_rate": 5.602666666666667e-07,
      "logits/chosen": -2.4156432151794434,
      "logits/rejected": -3.5871877670288086,
      "logps/chosen": -145.57522583007812,
      "logps/rejected": -209.610107421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.775693893432617,
      "rewards/margins": 13.066635131835938,
      "rewards/rejected": -8.29094123840332,
      "step": 3299
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.03193029761314392,
      "learning_rate": 5.601333333333333e-07,
      "logits/chosen": -2.5029213428497314,
      "logits/rejected": -3.6766903400421143,
      "logps/chosen": -108.06727600097656,
      "logps/rejected": -173.13986206054688,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2258434295654297,
      "rewards/margins": 9.394423484802246,
      "rewards/rejected": -7.168580055236816,
      "step": 3300
    },
    {
      "epoch": 1.3204,
      "grad_norm": 0.013123778626322746,
      "learning_rate": 5.6e-07,
      "logits/chosen": -2.7409005165100098,
      "logits/rejected": -3.8841848373413086,
      "logps/chosen": -142.94009399414062,
      "logps/rejected": -185.02981567382812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0636780261993408,
      "rewards/margins": 9.510942459106445,
      "rewards/rejected": -8.447263717651367,
      "step": 3301
    },
    {
      "epoch": 1.3208,
      "grad_norm": 0.0022730957716703415,
      "learning_rate": 5.598666666666666e-07,
      "logits/chosen": -2.5027806758880615,
      "logits/rejected": -3.5439844131469727,
      "logps/chosen": -118.63009643554688,
      "logps/rejected": -199.1200408935547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.753048896789551,
      "rewards/margins": 11.655171394348145,
      "rewards/rejected": -8.902122497558594,
      "step": 3302
    },
    {
      "epoch": 1.3212,
      "grad_norm": 0.12397707253694534,
      "learning_rate": 5.597333333333333e-07,
      "logits/chosen": -2.3910179138183594,
      "logits/rejected": -3.551948070526123,
      "logps/chosen": -200.8402099609375,
      "logps/rejected": -218.17926025390625,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1665122509002686,
      "rewards/margins": 9.084772109985352,
      "rewards/rejected": -7.918259620666504,
      "step": 3303
    },
    {
      "epoch": 1.3216,
      "grad_norm": 0.6805009841918945,
      "learning_rate": 5.596e-07,
      "logits/chosen": -2.0120208263397217,
      "logits/rejected": -3.5484237670898438,
      "logps/chosen": -86.5245132446289,
      "logps/rejected": -163.78317260742188,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5428054332733154,
      "rewards/margins": 7.2158050537109375,
      "rewards/rejected": -5.672999382019043,
      "step": 3304
    },
    {
      "epoch": 1.322,
      "grad_norm": 0.045877955853939056,
      "learning_rate": 5.594666666666666e-07,
      "logits/chosen": -1.7821683883666992,
      "logits/rejected": -2.851816415786743,
      "logps/chosen": -114.60821533203125,
      "logps/rejected": -138.71214294433594,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4229373931884766,
      "rewards/margins": 8.218488693237305,
      "rewards/rejected": -5.795551776885986,
      "step": 3305
    },
    {
      "epoch": 1.3224,
      "grad_norm": 0.004212320316582918,
      "learning_rate": 5.593333333333333e-07,
      "logits/chosen": -1.6522800922393799,
      "logits/rejected": -3.2956702709198,
      "logps/chosen": -68.82366943359375,
      "logps/rejected": -176.74624633789062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1208314895629883,
      "rewards/margins": 10.924670219421387,
      "rewards/rejected": -7.803838729858398,
      "step": 3306
    },
    {
      "epoch": 1.3228,
      "grad_norm": 0.03434860333800316,
      "learning_rate": 5.592e-07,
      "logits/chosen": -1.9178602695465088,
      "logits/rejected": -3.457216262817383,
      "logps/chosen": -102.60240936279297,
      "logps/rejected": -171.69488525390625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1961939334869385,
      "rewards/margins": 9.935914993286133,
      "rewards/rejected": -7.739720821380615,
      "step": 3307
    },
    {
      "epoch": 1.3232,
      "grad_norm": 0.003958503250032663,
      "learning_rate": 5.590666666666667e-07,
      "logits/chosen": -2.268667697906494,
      "logits/rejected": -3.463733196258545,
      "logps/chosen": -128.65802001953125,
      "logps/rejected": -165.7054443359375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.486008882522583,
      "rewards/margins": 10.4268798828125,
      "rewards/rejected": -7.940871238708496,
      "step": 3308
    },
    {
      "epoch": 1.3235999999999999,
      "grad_norm": 0.01949886605143547,
      "learning_rate": 5.589333333333333e-07,
      "logits/chosen": -2.6438708305358887,
      "logits/rejected": -3.4113211631774902,
      "logps/chosen": -150.87557983398438,
      "logps/rejected": -216.1789093017578,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0906779766082764,
      "rewards/margins": 8.900468826293945,
      "rewards/rejected": -6.80979061126709,
      "step": 3309
    },
    {
      "epoch": 1.324,
      "grad_norm": 0.04613851010799408,
      "learning_rate": 5.588e-07,
      "logits/chosen": -1.8219187259674072,
      "logits/rejected": -2.5924973487854004,
      "logps/chosen": -57.678466796875,
      "logps/rejected": -129.69961547851562,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9877302646636963,
      "rewards/margins": 9.576364517211914,
      "rewards/rejected": -6.588634014129639,
      "step": 3310
    },
    {
      "epoch": 1.3244,
      "grad_norm": 0.00850802380591631,
      "learning_rate": 5.586666666666666e-07,
      "logits/chosen": -2.5527572631835938,
      "logits/rejected": -3.1263532638549805,
      "logps/chosen": -109.580078125,
      "logps/rejected": -184.9806365966797,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.406370162963867,
      "rewards/margins": 10.042928695678711,
      "rewards/rejected": -6.636557579040527,
      "step": 3311
    },
    {
      "epoch": 1.3248,
      "grad_norm": 0.0328860841691494,
      "learning_rate": 5.585333333333333e-07,
      "logits/chosen": -1.5424156188964844,
      "logits/rejected": -3.670539140701294,
      "logps/chosen": -86.82921600341797,
      "logps/rejected": -162.71340942382812,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6027096509933472,
      "rewards/margins": 9.044126510620117,
      "rewards/rejected": -7.4414167404174805,
      "step": 3312
    },
    {
      "epoch": 1.3252,
      "grad_norm": 0.19924598932266235,
      "learning_rate": 5.584e-07,
      "logits/chosen": -2.145271062850952,
      "logits/rejected": -3.3330109119415283,
      "logps/chosen": -88.23200225830078,
      "logps/rejected": -157.18487548828125,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4044532775878906,
      "rewards/margins": 7.74355411529541,
      "rewards/rejected": -7.3391008377075195,
      "step": 3313
    },
    {
      "epoch": 1.3256000000000001,
      "grad_norm": 0.03885216265916824,
      "learning_rate": 5.582666666666667e-07,
      "logits/chosen": -2.379732847213745,
      "logits/rejected": -3.2266173362731934,
      "logps/chosen": -158.5232391357422,
      "logps/rejected": -192.97821044921875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4036431312561035,
      "rewards/margins": 10.019403457641602,
      "rewards/rejected": -6.615760803222656,
      "step": 3314
    },
    {
      "epoch": 1.326,
      "grad_norm": 0.02725069783627987,
      "learning_rate": 5.581333333333333e-07,
      "logits/chosen": -2.5675840377807617,
      "logits/rejected": -3.1754226684570312,
      "logps/chosen": -139.8955078125,
      "logps/rejected": -173.4216766357422,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7244071960449219,
      "rewards/margins": 8.487340927124023,
      "rewards/rejected": -6.762933731079102,
      "step": 3315
    },
    {
      "epoch": 1.3264,
      "grad_norm": 0.012723305262625217,
      "learning_rate": 5.58e-07,
      "logits/chosen": -2.3248062133789062,
      "logits/rejected": -2.823671579360962,
      "logps/chosen": -129.6715850830078,
      "logps/rejected": -187.224365234375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4511992931365967,
      "rewards/margins": 11.63977336883545,
      "rewards/rejected": -8.188573837280273,
      "step": 3316
    },
    {
      "epoch": 1.3268,
      "grad_norm": 1.4722623825073242,
      "learning_rate": 5.578666666666666e-07,
      "logits/chosen": -2.321807861328125,
      "logits/rejected": -2.7855098247528076,
      "logps/chosen": -112.20404052734375,
      "logps/rejected": -119.0688705444336,
      "loss": 0.0199,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7733050584793091,
      "rewards/margins": 4.143240928649902,
      "rewards/rejected": -3.369935989379883,
      "step": 3317
    },
    {
      "epoch": 1.3272,
      "grad_norm": 0.10465968400239944,
      "learning_rate": 5.577333333333333e-07,
      "logits/chosen": -2.0516886711120605,
      "logits/rejected": -3.816284418106079,
      "logps/chosen": -115.09683990478516,
      "logps/rejected": -171.64309692382812,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8484429121017456,
      "rewards/margins": 8.068181991577148,
      "rewards/rejected": -6.21973991394043,
      "step": 3318
    },
    {
      "epoch": 1.3276,
      "grad_norm": 0.002595125697553158,
      "learning_rate": 5.576e-07,
      "logits/chosen": -2.093539237976074,
      "logits/rejected": -3.0163509845733643,
      "logps/chosen": -197.97830200195312,
      "logps/rejected": -176.06732177734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.488269329071045,
      "rewards/margins": 10.981239318847656,
      "rewards/rejected": -6.492969989776611,
      "step": 3319
    },
    {
      "epoch": 1.328,
      "grad_norm": 0.12361059337854385,
      "learning_rate": 5.574666666666667e-07,
      "logits/chosen": -2.409210681915283,
      "logits/rejected": -3.451143980026245,
      "logps/chosen": -217.2797393798828,
      "logps/rejected": -206.7064208984375,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2265114784240723,
      "rewards/margins": 8.69475269317627,
      "rewards/rejected": -7.468241214752197,
      "step": 3320
    },
    {
      "epoch": 1.3284,
      "grad_norm": 3.438394784927368,
      "learning_rate": 5.573333333333333e-07,
      "logits/chosen": -2.126107692718506,
      "logits/rejected": -2.3953440189361572,
      "logps/chosen": -102.36239624023438,
      "logps/rejected": -131.82583618164062,
      "loss": 0.0316,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4171023964881897,
      "rewards/margins": 5.699440956115723,
      "rewards/rejected": -5.282338619232178,
      "step": 3321
    },
    {
      "epoch": 1.3288,
      "grad_norm": 0.01707552745938301,
      "learning_rate": 5.572e-07,
      "logits/chosen": -2.413475513458252,
      "logits/rejected": -3.3710596561431885,
      "logps/chosen": -161.30337524414062,
      "logps/rejected": -197.58380126953125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8936413526535034,
      "rewards/margins": 10.896160125732422,
      "rewards/rejected": -9.002518653869629,
      "step": 3322
    },
    {
      "epoch": 1.3292,
      "grad_norm": 0.005587932653725147,
      "learning_rate": 5.570666666666667e-07,
      "logits/chosen": -2.3508241176605225,
      "logits/rejected": -3.5458102226257324,
      "logps/chosen": -139.95071411132812,
      "logps/rejected": -186.692138671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.383200168609619,
      "rewards/margins": 10.410038948059082,
      "rewards/rejected": -7.026838779449463,
      "step": 3323
    },
    {
      "epoch": 1.3296000000000001,
      "grad_norm": 0.015884580090641975,
      "learning_rate": 5.569333333333332e-07,
      "logits/chosen": -2.120105266571045,
      "logits/rejected": -3.545182228088379,
      "logps/chosen": -129.92922973632812,
      "logps/rejected": -200.96112060546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3563084602355957,
      "rewards/margins": 10.722885131835938,
      "rewards/rejected": -8.366576194763184,
      "step": 3324
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.02734476514160633,
      "learning_rate": 5.567999999999999e-07,
      "logits/chosen": -2.5821492671966553,
      "logits/rejected": -4.000985145568848,
      "logps/chosen": -110.78813171386719,
      "logps/rejected": -221.2541961669922,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1885185241699219,
      "rewards/margins": 8.686686515808105,
      "rewards/rejected": -9.875205039978027,
      "step": 3325
    },
    {
      "epoch": 1.3304,
      "grad_norm": 0.004839755594730377,
      "learning_rate": 5.566666666666666e-07,
      "logits/chosen": -2.0615127086639404,
      "logits/rejected": -3.308987855911255,
      "logps/chosen": -91.6992416381836,
      "logps/rejected": -163.5699462890625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4431533813476562,
      "rewards/margins": 11.266895294189453,
      "rewards/rejected": -7.823741912841797,
      "step": 3326
    },
    {
      "epoch": 1.3308,
      "grad_norm": 0.021221930161118507,
      "learning_rate": 5.565333333333333e-07,
      "logits/chosen": -2.2689342498779297,
      "logits/rejected": -3.479050636291504,
      "logps/chosen": -134.91592407226562,
      "logps/rejected": -154.53533935546875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.369954824447632,
      "rewards/margins": 9.67647933959961,
      "rewards/rejected": -6.306524276733398,
      "step": 3327
    },
    {
      "epoch": 1.3312,
      "grad_norm": 0.27572891116142273,
      "learning_rate": 5.564e-07,
      "logits/chosen": -2.0909626483917236,
      "logits/rejected": -3.099973678588867,
      "logps/chosen": -149.44287109375,
      "logps/rejected": -148.278076171875,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1328102350234985,
      "rewards/margins": 5.886483192443848,
      "rewards/rejected": -7.019293308258057,
      "step": 3328
    },
    {
      "epoch": 1.3316,
      "grad_norm": 0.013097573071718216,
      "learning_rate": 5.562666666666667e-07,
      "logits/chosen": -2.565394401550293,
      "logits/rejected": -3.175374746322632,
      "logps/chosen": -160.50962829589844,
      "logps/rejected": -206.59454345703125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.294571876525879,
      "rewards/margins": 10.685626983642578,
      "rewards/rejected": -7.391054630279541,
      "step": 3329
    },
    {
      "epoch": 1.332,
      "grad_norm": 0.20252540707588196,
      "learning_rate": 5.561333333333334e-07,
      "logits/chosen": -1.7613744735717773,
      "logits/rejected": -2.830594778060913,
      "logps/chosen": -108.3167953491211,
      "logps/rejected": -163.1279296875,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6607944369316101,
      "rewards/margins": 6.236010551452637,
      "rewards/rejected": -6.896805286407471,
      "step": 3330
    },
    {
      "epoch": 1.3324,
      "grad_norm": 0.001968582859262824,
      "learning_rate": 5.560000000000001e-07,
      "logits/chosen": -1.990114688873291,
      "logits/rejected": -3.1155762672424316,
      "logps/chosen": -183.89456176757812,
      "logps/rejected": -233.63116455078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.181971073150635,
      "rewards/margins": 11.22332763671875,
      "rewards/rejected": -7.041356086730957,
      "step": 3331
    },
    {
      "epoch": 1.3328,
      "grad_norm": 1.8300986289978027,
      "learning_rate": 5.558666666666666e-07,
      "logits/chosen": -2.2131378650665283,
      "logits/rejected": -2.687809705734253,
      "logps/chosen": -71.79547119140625,
      "logps/rejected": -126.64866638183594,
      "loss": 0.0125,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3187520503997803,
      "rewards/margins": 7.904551982879639,
      "rewards/rejected": -5.585799694061279,
      "step": 3332
    },
    {
      "epoch": 1.3332,
      "grad_norm": 0.04643715173006058,
      "learning_rate": 5.557333333333332e-07,
      "logits/chosen": -2.640681266784668,
      "logits/rejected": -3.374764919281006,
      "logps/chosen": -128.08436584472656,
      "logps/rejected": -203.05459594726562,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.30106782913208,
      "rewards/margins": 11.226969718933105,
      "rewards/rejected": -8.925901412963867,
      "step": 3333
    },
    {
      "epoch": 1.3336000000000001,
      "grad_norm": 0.13605035841464996,
      "learning_rate": 5.555999999999999e-07,
      "logits/chosen": -2.2860422134399414,
      "logits/rejected": -2.362971305847168,
      "logps/chosen": -106.18304443359375,
      "logps/rejected": -193.0784149169922,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.415873408317566,
      "rewards/margins": 7.768640995025635,
      "rewards/rejected": -6.3527679443359375,
      "step": 3334
    },
    {
      "epoch": 1.334,
      "grad_norm": 0.41047170758247375,
      "learning_rate": 5.554666666666666e-07,
      "logits/chosen": -1.8304286003112793,
      "logits/rejected": -3.179624319076538,
      "logps/chosen": -100.60028839111328,
      "logps/rejected": -165.7879638671875,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.090415596961975,
      "rewards/margins": 7.0968918800354,
      "rewards/rejected": -8.187307357788086,
      "step": 3335
    },
    {
      "epoch": 1.3344,
      "grad_norm": 0.055089592933654785,
      "learning_rate": 5.553333333333333e-07,
      "logits/chosen": -2.7035746574401855,
      "logits/rejected": -3.645857810974121,
      "logps/chosen": -152.8256072998047,
      "logps/rejected": -216.66543579101562,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4446861147880554,
      "rewards/margins": 7.959420680999756,
      "rewards/rejected": -7.514734745025635,
      "step": 3336
    },
    {
      "epoch": 1.3348,
      "grad_norm": 0.004660223610699177,
      "learning_rate": 5.552e-07,
      "logits/chosen": -2.3922324180603027,
      "logits/rejected": -2.5352602005004883,
      "logps/chosen": -100.82022094726562,
      "logps/rejected": -147.689697265625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.74772310256958,
      "rewards/margins": 11.360191345214844,
      "rewards/rejected": -6.6124677658081055,
      "step": 3337
    },
    {
      "epoch": 1.3352,
      "grad_norm": 0.09756587445735931,
      "learning_rate": 5.550666666666667e-07,
      "logits/chosen": -2.554530382156372,
      "logits/rejected": -3.40676212310791,
      "logps/chosen": -151.4966583251953,
      "logps/rejected": -329.68475341796875,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3189254999160767,
      "rewards/margins": 8.412701606750488,
      "rewards/rejected": -7.093776226043701,
      "step": 3338
    },
    {
      "epoch": 1.3356,
      "grad_norm": 0.05626216158270836,
      "learning_rate": 5.549333333333333e-07,
      "logits/chosen": -2.927898406982422,
      "logits/rejected": -3.053677558898926,
      "logps/chosen": -246.76722717285156,
      "logps/rejected": -200.45669555664062,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9402637481689453,
      "rewards/margins": 8.001893043518066,
      "rewards/rejected": -5.061629295349121,
      "step": 3339
    },
    {
      "epoch": 1.336,
      "grad_norm": 0.027317343279719353,
      "learning_rate": 5.548e-07,
      "logits/chosen": -1.8642282485961914,
      "logits/rejected": -3.5812978744506836,
      "logps/chosen": -203.97903442382812,
      "logps/rejected": -184.96356201171875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.354466199874878,
      "rewards/margins": 9.000529289245605,
      "rewards/rejected": -7.646062850952148,
      "step": 3340
    },
    {
      "epoch": 1.3364,
      "grad_norm": 0.00624862452968955,
      "learning_rate": 5.546666666666667e-07,
      "logits/chosen": -2.4259297847747803,
      "logits/rejected": -3.3121800422668457,
      "logps/chosen": -178.4134063720703,
      "logps/rejected": -224.15521240234375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.829505205154419,
      "rewards/margins": 10.38709831237793,
      "rewards/rejected": -8.557592391967773,
      "step": 3341
    },
    {
      "epoch": 1.3368,
      "grad_norm": 0.0673353374004364,
      "learning_rate": 5.545333333333333e-07,
      "logits/chosen": -2.209512710571289,
      "logits/rejected": -3.5274057388305664,
      "logps/chosen": -157.87083435058594,
      "logps/rejected": -136.92343139648438,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.143741250038147,
      "rewards/margins": 7.469577789306641,
      "rewards/rejected": -6.325836658477783,
      "step": 3342
    },
    {
      "epoch": 1.3372,
      "grad_norm": 0.058022212237119675,
      "learning_rate": 5.543999999999999e-07,
      "logits/chosen": -2.3865742683410645,
      "logits/rejected": -3.481541156768799,
      "logps/chosen": -150.59283447265625,
      "logps/rejected": -165.85494995117188,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8192123770713806,
      "rewards/margins": 7.526463508605957,
      "rewards/rejected": -6.707251071929932,
      "step": 3343
    },
    {
      "epoch": 1.3376000000000001,
      "grad_norm": 0.0027418178506195545,
      "learning_rate": 5.542666666666666e-07,
      "logits/chosen": -2.3369712829589844,
      "logits/rejected": -3.5418312549591064,
      "logps/chosen": -80.09931182861328,
      "logps/rejected": -200.11822509765625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.01861572265625,
      "rewards/margins": 12.01409912109375,
      "rewards/rejected": -7.9954833984375,
      "step": 3344
    },
    {
      "epoch": 1.338,
      "grad_norm": 0.07037851959466934,
      "learning_rate": 5.541333333333333e-07,
      "logits/chosen": -1.7381396293640137,
      "logits/rejected": -2.944199800491333,
      "logps/chosen": -63.56418228149414,
      "logps/rejected": -154.0158233642578,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9018349647521973,
      "rewards/margins": 9.003451347351074,
      "rewards/rejected": -7.101616382598877,
      "step": 3345
    },
    {
      "epoch": 1.3384,
      "grad_norm": 0.45381563901901245,
      "learning_rate": 5.54e-07,
      "logits/chosen": -2.6837997436523438,
      "logits/rejected": -3.735006332397461,
      "logps/chosen": -140.60287475585938,
      "logps/rejected": -196.58639526367188,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3534034490585327,
      "rewards/margins": 7.6253485679626465,
      "rewards/rejected": -7.271944999694824,
      "step": 3346
    },
    {
      "epoch": 1.3388,
      "grad_norm": 0.580228328704834,
      "learning_rate": 5.538666666666666e-07,
      "logits/chosen": -2.581540584564209,
      "logits/rejected": -3.2004637718200684,
      "logps/chosen": -146.10882568359375,
      "logps/rejected": -166.81039428710938,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.14623452723026276,
      "rewards/margins": 5.449617385864258,
      "rewards/rejected": -5.595851898193359,
      "step": 3347
    },
    {
      "epoch": 1.3392,
      "grad_norm": 0.01973916031420231,
      "learning_rate": 5.537333333333333e-07,
      "logits/chosen": -2.3547186851501465,
      "logits/rejected": -3.309290885925293,
      "logps/chosen": -129.4670867919922,
      "logps/rejected": -166.62615966796875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8885185718536377,
      "rewards/margins": 9.708521842956543,
      "rewards/rejected": -7.820002555847168,
      "step": 3348
    },
    {
      "epoch": 1.3396,
      "grad_norm": 0.14521826803684235,
      "learning_rate": 5.536e-07,
      "logits/chosen": -2.5712594985961914,
      "logits/rejected": -2.704655647277832,
      "logps/chosen": -77.74221801757812,
      "logps/rejected": -164.47726440429688,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0095481872558594,
      "rewards/margins": 8.162012100219727,
      "rewards/rejected": -6.152463912963867,
      "step": 3349
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.005273354239761829,
      "learning_rate": 5.534666666666667e-07,
      "logits/chosen": -1.8616626262664795,
      "logits/rejected": -3.11617374420166,
      "logps/chosen": -77.31385803222656,
      "logps/rejected": -170.3544921875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.605212688446045,
      "rewards/margins": 10.518228530883789,
      "rewards/rejected": -6.913015842437744,
      "step": 3350
    },
    {
      "epoch": 1.3404,
      "grad_norm": 0.0164694394916296,
      "learning_rate": 5.533333333333334e-07,
      "logits/chosen": -2.2397122383117676,
      "logits/rejected": -3.3325743675231934,
      "logps/chosen": -163.68389892578125,
      "logps/rejected": -169.663330078125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.690272569656372,
      "rewards/margins": 11.266841888427734,
      "rewards/rejected": -7.576569080352783,
      "step": 3351
    },
    {
      "epoch": 1.3408,
      "grad_norm": 0.0006298281368799508,
      "learning_rate": 5.532e-07,
      "logits/chosen": -1.956566572189331,
      "logits/rejected": -3.8169937133789062,
      "logps/chosen": -83.71659851074219,
      "logps/rejected": -226.03884887695312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.127738952636719,
      "rewards/margins": 13.767728805541992,
      "rewards/rejected": -9.639989852905273,
      "step": 3352
    },
    {
      "epoch": 1.3412,
      "grad_norm": 0.034839093685150146,
      "learning_rate": 5.530666666666666e-07,
      "logits/chosen": -1.9197134971618652,
      "logits/rejected": -3.11085844039917,
      "logps/chosen": -79.6504898071289,
      "logps/rejected": -151.22604370117188,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.627305507659912,
      "rewards/margins": 8.21202278137207,
      "rewards/rejected": -5.584716796875,
      "step": 3353
    },
    {
      "epoch": 1.3416000000000001,
      "grad_norm": 0.17992056906223297,
      "learning_rate": 5.529333333333333e-07,
      "logits/chosen": -2.198606014251709,
      "logits/rejected": -3.457979679107666,
      "logps/chosen": -143.21873474121094,
      "logps/rejected": -194.45582580566406,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.21628224849700928,
      "rewards/margins": 7.974043846130371,
      "rewards/rejected": -8.190326690673828,
      "step": 3354
    },
    {
      "epoch": 1.342,
      "grad_norm": 0.12812770903110504,
      "learning_rate": 5.527999999999999e-07,
      "logits/chosen": -2.4150407314300537,
      "logits/rejected": -3.2734580039978027,
      "logps/chosen": -148.26824951171875,
      "logps/rejected": -141.58419799804688,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5018108487129211,
      "rewards/margins": 6.865481376647949,
      "rewards/rejected": -6.363670349121094,
      "step": 3355
    },
    {
      "epoch": 1.3424,
      "grad_norm": 0.0006030875374563038,
      "learning_rate": 5.526666666666666e-07,
      "logits/chosen": -1.985231876373291,
      "logits/rejected": -3.8748974800109863,
      "logps/chosen": -118.61734008789062,
      "logps/rejected": -202.30953979492188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.238201141357422,
      "rewards/margins": 13.890820503234863,
      "rewards/rejected": -9.652618408203125,
      "step": 3356
    },
    {
      "epoch": 1.3428,
      "grad_norm": 0.0559871569275856,
      "learning_rate": 5.525333333333333e-07,
      "logits/chosen": -1.664412021636963,
      "logits/rejected": -3.522655963897705,
      "logps/chosen": -91.486572265625,
      "logps/rejected": -177.83682250976562,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34990960359573364,
      "rewards/margins": 8.978145599365234,
      "rewards/rejected": -8.628236770629883,
      "step": 3357
    },
    {
      "epoch": 1.3432,
      "grad_norm": 0.02424623817205429,
      "learning_rate": 5.524e-07,
      "logits/chosen": -2.754354476928711,
      "logits/rejected": -2.9178104400634766,
      "logps/chosen": -94.34456634521484,
      "logps/rejected": -155.6004638671875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4783844947814941,
      "rewards/margins": 8.692375183105469,
      "rewards/rejected": -7.213990688323975,
      "step": 3358
    },
    {
      "epoch": 1.3436,
      "grad_norm": 6.656720506725833e-05,
      "learning_rate": 5.522666666666667e-07,
      "logits/chosen": -2.319509744644165,
      "logits/rejected": -3.3519585132598877,
      "logps/chosen": -233.04608154296875,
      "logps/rejected": -270.66265869140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 6.834787368774414,
      "rewards/margins": 15.13412857055664,
      "rewards/rejected": -8.299341201782227,
      "step": 3359
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 0.04508141428232193,
      "learning_rate": 5.521333333333334e-07,
      "logits/chosen": -1.78934645652771,
      "logits/rejected": -3.0976176261901855,
      "logps/chosen": -71.71405792236328,
      "logps/rejected": -145.58575439453125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.83626389503479,
      "rewards/margins": 8.99539852142334,
      "rewards/rejected": -6.159134387969971,
      "step": 3360
    },
    {
      "epoch": 1.3444,
      "grad_norm": 0.16809773445129395,
      "learning_rate": 5.520000000000001e-07,
      "logits/chosen": -1.791809320449829,
      "logits/rejected": -2.768079996109009,
      "logps/chosen": -77.35060119628906,
      "logps/rejected": -128.6717071533203,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6020007133483887,
      "rewards/margins": 7.752662658691406,
      "rewards/rejected": -5.150661945343018,
      "step": 3361
    },
    {
      "epoch": 1.3448,
      "grad_norm": 0.009077759459614754,
      "learning_rate": 5.518666666666666e-07,
      "logits/chosen": -1.7333182096481323,
      "logits/rejected": -3.2456212043762207,
      "logps/chosen": -89.02517700195312,
      "logps/rejected": -170.99301147460938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7842860221862793,
      "rewards/margins": 9.962654113769531,
      "rewards/rejected": -7.178367614746094,
      "step": 3362
    },
    {
      "epoch": 1.3452,
      "grad_norm": 0.14823928475379944,
      "learning_rate": 5.517333333333332e-07,
      "logits/chosen": -2.093106746673584,
      "logits/rejected": -2.9889614582061768,
      "logps/chosen": -95.6575698852539,
      "logps/rejected": -164.06256103515625,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9289878606796265,
      "rewards/margins": 7.269955635070801,
      "rewards/rejected": -6.340967655181885,
      "step": 3363
    },
    {
      "epoch": 1.3456000000000001,
      "grad_norm": 0.0874449610710144,
      "learning_rate": 5.515999999999999e-07,
      "logits/chosen": -2.0287067890167236,
      "logits/rejected": -3.66035795211792,
      "logps/chosen": -108.23212432861328,
      "logps/rejected": -169.01214599609375,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3312716484069824,
      "rewards/margins": 8.095675468444824,
      "rewards/rejected": -5.764403820037842,
      "step": 3364
    },
    {
      "epoch": 1.346,
      "grad_norm": 0.005249823443591595,
      "learning_rate": 5.514666666666666e-07,
      "logits/chosen": -2.038541793823242,
      "logits/rejected": -3.153522491455078,
      "logps/chosen": -122.75486755371094,
      "logps/rejected": -194.14076232910156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.872457981109619,
      "rewards/margins": 10.483327865600586,
      "rewards/rejected": -6.610870361328125,
      "step": 3365
    },
    {
      "epoch": 1.3464,
      "grad_norm": 0.0007314055110327899,
      "learning_rate": 5.513333333333333e-07,
      "logits/chosen": -2.291482925415039,
      "logits/rejected": -3.564159393310547,
      "logps/chosen": -159.240234375,
      "logps/rejected": -207.51925659179688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.309171676635742,
      "rewards/margins": 13.83389663696289,
      "rewards/rejected": -9.524724960327148,
      "step": 3366
    },
    {
      "epoch": 1.3468,
      "grad_norm": 0.22440099716186523,
      "learning_rate": 5.512e-07,
      "logits/chosen": -1.8347389698028564,
      "logits/rejected": -3.42935848236084,
      "logps/chosen": -149.83624267578125,
      "logps/rejected": -190.224365234375,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.908599853515625,
      "rewards/margins": 8.20649528503418,
      "rewards/rejected": -7.2978949546813965,
      "step": 3367
    },
    {
      "epoch": 1.3472,
      "grad_norm": 0.0016117494087666273,
      "learning_rate": 5.510666666666667e-07,
      "logits/chosen": -1.7371610403060913,
      "logits/rejected": -3.4105496406555176,
      "logps/chosen": -94.50008392333984,
      "logps/rejected": -236.7164764404297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7030348777770996,
      "rewards/margins": 12.441843032836914,
      "rewards/rejected": -9.738807678222656,
      "step": 3368
    },
    {
      "epoch": 1.3476,
      "grad_norm": 0.004061830695718527,
      "learning_rate": 5.509333333333334e-07,
      "logits/chosen": -2.27225661277771,
      "logits/rejected": -3.22769832611084,
      "logps/chosen": -140.5670166015625,
      "logps/rejected": -243.49024963378906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.302239418029785,
      "rewards/margins": 10.673667907714844,
      "rewards/rejected": -6.371428489685059,
      "step": 3369
    },
    {
      "epoch": 1.3479999999999999,
      "grad_norm": 0.00752025144174695,
      "learning_rate": 5.508e-07,
      "logits/chosen": -1.8451454639434814,
      "logits/rejected": -3.3484268188476562,
      "logps/chosen": -114.85547637939453,
      "logps/rejected": -184.07138061523438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.485223412513733,
      "rewards/margins": 9.927053451538086,
      "rewards/rejected": -8.4418306350708,
      "step": 3370
    },
    {
      "epoch": 1.3484,
      "grad_norm": 0.011458508670330048,
      "learning_rate": 5.506666666666666e-07,
      "logits/chosen": -1.7426137924194336,
      "logits/rejected": -3.0164880752563477,
      "logps/chosen": -100.97846221923828,
      "logps/rejected": -158.4820556640625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.538938522338867,
      "rewards/margins": 9.212717056274414,
      "rewards/rejected": -6.673778533935547,
      "step": 3371
    },
    {
      "epoch": 1.3488,
      "grad_norm": 0.03039856255054474,
      "learning_rate": 5.505333333333333e-07,
      "logits/chosen": -2.155165195465088,
      "logits/rejected": -3.112147808074951,
      "logps/chosen": -94.28463745117188,
      "logps/rejected": -164.22216796875,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34542617201805115,
      "rewards/margins": 7.852119445800781,
      "rewards/rejected": -7.506693363189697,
      "step": 3372
    },
    {
      "epoch": 1.3492,
      "grad_norm": 0.010732915252447128,
      "learning_rate": 5.504e-07,
      "logits/chosen": -2.0792462825775146,
      "logits/rejected": -2.952695846557617,
      "logps/chosen": -110.27806091308594,
      "logps/rejected": -166.81219482421875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.375916004180908,
      "rewards/margins": 10.547274589538574,
      "rewards/rejected": -7.171358585357666,
      "step": 3373
    },
    {
      "epoch": 1.3496000000000001,
      "grad_norm": 0.06387251615524292,
      "learning_rate": 5.502666666666666e-07,
      "logits/chosen": -2.375194787979126,
      "logits/rejected": -3.0884127616882324,
      "logps/chosen": -154.88568115234375,
      "logps/rejected": -160.0457763671875,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9172377586364746,
      "rewards/margins": 9.61221981048584,
      "rewards/rejected": -5.694981575012207,
      "step": 3374
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.5177715420722961,
      "learning_rate": 5.501333333333333e-07,
      "logits/chosen": -2.46468448638916,
      "logits/rejected": -3.1445136070251465,
      "logps/chosen": -166.9657745361328,
      "logps/rejected": -153.32374572753906,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10729598999023438,
      "rewards/margins": 6.350679397583008,
      "rewards/rejected": -6.457975387573242,
      "step": 3375
    },
    {
      "epoch": 1.3504,
      "grad_norm": 0.3643399178981781,
      "learning_rate": 5.5e-07,
      "logits/chosen": -1.862060308456421,
      "logits/rejected": -2.617002010345459,
      "logps/chosen": -115.27272033691406,
      "logps/rejected": -156.0975341796875,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5970962643623352,
      "rewards/margins": 5.5042290687561035,
      "rewards/rejected": -6.101325035095215,
      "step": 3376
    },
    {
      "epoch": 1.3508,
      "grad_norm": 0.0287875235080719,
      "learning_rate": 5.498666666666666e-07,
      "logits/chosen": -1.8215265274047852,
      "logits/rejected": -3.059997797012329,
      "logps/chosen": -65.04423522949219,
      "logps/rejected": -144.49551391601562,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1484169960021973,
      "rewards/margins": 8.27560806274414,
      "rewards/rejected": -6.127191543579102,
      "step": 3377
    },
    {
      "epoch": 1.3512,
      "grad_norm": 0.13973446190357208,
      "learning_rate": 5.497333333333333e-07,
      "logits/chosen": -2.3190555572509766,
      "logits/rejected": -3.1488637924194336,
      "logps/chosen": -115.1384048461914,
      "logps/rejected": -165.57421875,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1869208812713623,
      "rewards/margins": 9.085482597351074,
      "rewards/rejected": -6.898561477661133,
      "step": 3378
    },
    {
      "epoch": 1.3516,
      "grad_norm": 0.1016937643289566,
      "learning_rate": 5.496e-07,
      "logits/chosen": -2.191790819168091,
      "logits/rejected": -3.5055184364318848,
      "logps/chosen": -118.8572998046875,
      "logps/rejected": -175.37911987304688,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5723110437393188,
      "rewards/margins": 8.14937686920166,
      "rewards/rejected": -6.577065944671631,
      "step": 3379
    },
    {
      "epoch": 1.3519999999999999,
      "grad_norm": 0.13161809742450714,
      "learning_rate": 5.494666666666666e-07,
      "logits/chosen": -2.6635241508483887,
      "logits/rejected": -3.4089035987854004,
      "logps/chosen": -143.41925048828125,
      "logps/rejected": -144.85888671875,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.803575873374939,
      "rewards/margins": 7.077701091766357,
      "rewards/rejected": -5.274125099182129,
      "step": 3380
    },
    {
      "epoch": 1.3524,
      "grad_norm": 0.0008079735562205315,
      "learning_rate": 5.493333333333333e-07,
      "logits/chosen": -2.2847251892089844,
      "logits/rejected": -3.1879115104675293,
      "logps/chosen": -139.3980255126953,
      "logps/rejected": -178.2413330078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.137483596801758,
      "rewards/margins": 11.8480224609375,
      "rewards/rejected": -7.710537910461426,
      "step": 3381
    },
    {
      "epoch": 1.3528,
      "grad_norm": 0.17997480928897858,
      "learning_rate": 5.492e-07,
      "logits/chosen": -2.4141716957092285,
      "logits/rejected": -3.305257797241211,
      "logps/chosen": -142.1548614501953,
      "logps/rejected": -200.01148986816406,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.916815996170044,
      "rewards/margins": 9.221174240112305,
      "rewards/rejected": -7.304357528686523,
      "step": 3382
    },
    {
      "epoch": 1.3532,
      "grad_norm": 0.042789608240127563,
      "learning_rate": 5.490666666666667e-07,
      "logits/chosen": -2.195228099822998,
      "logits/rejected": -3.7978572845458984,
      "logps/chosen": -106.53031158447266,
      "logps/rejected": -167.8712158203125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.924141764640808,
      "rewards/margins": 8.465180397033691,
      "rewards/rejected": -6.541038990020752,
      "step": 3383
    },
    {
      "epoch": 1.3536000000000001,
      "grad_norm": 0.07062304764986038,
      "learning_rate": 5.489333333333334e-07,
      "logits/chosen": -2.5542404651641846,
      "logits/rejected": -3.585740804672241,
      "logps/chosen": -124.8267822265625,
      "logps/rejected": -191.7339324951172,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.038460612297058,
      "rewards/margins": 8.302793502807617,
      "rewards/rejected": -9.341254234313965,
      "step": 3384
    },
    {
      "epoch": 1.354,
      "grad_norm": 0.0013335580006241798,
      "learning_rate": 5.487999999999999e-07,
      "logits/chosen": -1.6178501844406128,
      "logits/rejected": -3.8267316818237305,
      "logps/chosen": -109.71461486816406,
      "logps/rejected": -189.03668212890625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4213955402374268,
      "rewards/margins": 11.368408203125,
      "rewards/rejected": -7.947012901306152,
      "step": 3385
    },
    {
      "epoch": 1.3544,
      "grad_norm": 0.05788673833012581,
      "learning_rate": 5.486666666666666e-07,
      "logits/chosen": -2.325857639312744,
      "logits/rejected": -3.292642831802368,
      "logps/chosen": -149.97384643554688,
      "logps/rejected": -165.501220703125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.904101610183716,
      "rewards/margins": 9.510464668273926,
      "rewards/rejected": -6.606362819671631,
      "step": 3386
    },
    {
      "epoch": 1.3548,
      "grad_norm": 0.04152711480855942,
      "learning_rate": 5.485333333333333e-07,
      "logits/chosen": -2.0201823711395264,
      "logits/rejected": -3.3842520713806152,
      "logps/chosen": -102.65122985839844,
      "logps/rejected": -223.37014770507812,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31717872619628906,
      "rewards/margins": 10.59657096862793,
      "rewards/rejected": -10.27939224243164,
      "step": 3387
    },
    {
      "epoch": 1.3552,
      "grad_norm": 0.0011615146650001407,
      "learning_rate": 5.484e-07,
      "logits/chosen": -2.268134355545044,
      "logits/rejected": -3.4896240234375,
      "logps/chosen": -98.73110961914062,
      "logps/rejected": -186.0728759765625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.580296516418457,
      "rewards/margins": 12.846122741699219,
      "rewards/rejected": -9.265825271606445,
      "step": 3388
    },
    {
      "epoch": 1.3556,
      "grad_norm": 0.013965348713099957,
      "learning_rate": 5.482666666666667e-07,
      "logits/chosen": -2.01778507232666,
      "logits/rejected": -3.2167367935180664,
      "logps/chosen": -99.92620849609375,
      "logps/rejected": -147.28460693359375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.992392063140869,
      "rewards/margins": 8.835497856140137,
      "rewards/rejected": -5.843106269836426,
      "step": 3389
    },
    {
      "epoch": 1.3559999999999999,
      "grad_norm": 0.23807373642921448,
      "learning_rate": 5.481333333333333e-07,
      "logits/chosen": -2.1064486503601074,
      "logits/rejected": -3.353855609893799,
      "logps/chosen": -120.00745391845703,
      "logps/rejected": -169.14035034179688,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1502830982208252,
      "rewards/margins": 8.003519058227539,
      "rewards/rejected": -6.853236198425293,
      "step": 3390
    },
    {
      "epoch": 1.3564,
      "grad_norm": 0.004070315510034561,
      "learning_rate": 5.48e-07,
      "logits/chosen": -1.9741387367248535,
      "logits/rejected": -3.3499326705932617,
      "logps/chosen": -99.07325744628906,
      "logps/rejected": -242.31422424316406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.731189250946045,
      "rewards/margins": 10.452960968017578,
      "rewards/rejected": -7.721771240234375,
      "step": 3391
    },
    {
      "epoch": 1.3568,
      "grad_norm": 2.4690639972686768,
      "learning_rate": 5.478666666666666e-07,
      "logits/chosen": -2.371582508087158,
      "logits/rejected": -2.7370705604553223,
      "logps/chosen": -139.4737548828125,
      "logps/rejected": -114.18875885009766,
      "loss": 0.0272,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21791839599609375,
      "rewards/margins": 4.530102729797363,
      "rewards/rejected": -4.3121843338012695,
      "step": 3392
    },
    {
      "epoch": 1.3572,
      "grad_norm": 0.009956283494830132,
      "learning_rate": 5.477333333333333e-07,
      "logits/chosen": -2.134885549545288,
      "logits/rejected": -2.683547258377075,
      "logps/chosen": -89.1182861328125,
      "logps/rejected": -161.87716674804688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0462124347686768,
      "rewards/margins": 9.331283569335938,
      "rewards/rejected": -6.28507137298584,
      "step": 3393
    },
    {
      "epoch": 1.3576,
      "grad_norm": 0.06828025728464127,
      "learning_rate": 5.476e-07,
      "logits/chosen": -1.7230932712554932,
      "logits/rejected": -3.438424587249756,
      "logps/chosen": -98.08308410644531,
      "logps/rejected": -161.6199188232422,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.237324595451355,
      "rewards/margins": 8.619796752929688,
      "rewards/rejected": -7.382472038269043,
      "step": 3394
    },
    {
      "epoch": 1.358,
      "grad_norm": 0.06873510777950287,
      "learning_rate": 5.474666666666666e-07,
      "logits/chosen": -2.333916664123535,
      "logits/rejected": -3.310563087463379,
      "logps/chosen": -113.87152099609375,
      "logps/rejected": -151.71337890625,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.381098210811615,
      "rewards/margins": 7.592936038970947,
      "rewards/rejected": -7.2118377685546875,
      "step": 3395
    },
    {
      "epoch": 1.3584,
      "grad_norm": 0.007926777936518192,
      "learning_rate": 5.473333333333333e-07,
      "logits/chosen": -2.660036087036133,
      "logits/rejected": -3.1133928298950195,
      "logps/chosen": -175.47048950195312,
      "logps/rejected": -164.15440368652344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5706787109375,
      "rewards/margins": 10.933137893676758,
      "rewards/rejected": -7.362459182739258,
      "step": 3396
    },
    {
      "epoch": 1.3588,
      "grad_norm": 0.016765564680099487,
      "learning_rate": 5.472e-07,
      "logits/chosen": -2.619147300720215,
      "logits/rejected": -3.5293071269989014,
      "logps/chosen": -148.81756591796875,
      "logps/rejected": -202.8214111328125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.049577236175537,
      "rewards/margins": 10.782867431640625,
      "rewards/rejected": -8.73328971862793,
      "step": 3397
    },
    {
      "epoch": 1.3592,
      "grad_norm": 0.24560104310512543,
      "learning_rate": 5.470666666666667e-07,
      "logits/chosen": -2.4711110591888428,
      "logits/rejected": -3.06298565864563,
      "logps/chosen": -153.8604736328125,
      "logps/rejected": -175.1102294921875,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2973487973213196,
      "rewards/margins": 7.3084306716918945,
      "rewards/rejected": -7.605779647827148,
      "step": 3398
    },
    {
      "epoch": 1.3596,
      "grad_norm": 0.02579808421432972,
      "learning_rate": 5.469333333333333e-07,
      "logits/chosen": -2.318981170654297,
      "logits/rejected": -3.935965061187744,
      "logps/chosen": -143.96446228027344,
      "logps/rejected": -169.51779174804688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2982075214385986,
      "rewards/margins": 10.005942344665527,
      "rewards/rejected": -8.707735061645508,
      "step": 3399
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.07481814175844193,
      "learning_rate": 5.467999999999999e-07,
      "logits/chosen": -2.2993338108062744,
      "logits/rejected": -3.26235294342041,
      "logps/chosen": -153.69711303710938,
      "logps/rejected": -170.95635986328125,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.193919375538826,
      "rewards/margins": 7.398642063140869,
      "rewards/rejected": -7.592561721801758,
      "step": 3400
    },
    {
      "epoch": 1.3604,
      "grad_norm": 0.008497816510498524,
      "learning_rate": 5.466666666666666e-07,
      "logits/chosen": -1.6830471754074097,
      "logits/rejected": -2.9777538776397705,
      "logps/chosen": -114.49674987792969,
      "logps/rejected": -197.108154296875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2465245723724365,
      "rewards/margins": 10.203142166137695,
      "rewards/rejected": -6.95661735534668,
      "step": 3401
    },
    {
      "epoch": 1.3608,
      "grad_norm": 0.07009761035442352,
      "learning_rate": 5.465333333333333e-07,
      "logits/chosen": -1.6801416873931885,
      "logits/rejected": -3.6881349086761475,
      "logps/chosen": -133.79556274414062,
      "logps/rejected": -159.3442840576172,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6610027551651,
      "rewards/margins": 9.227241516113281,
      "rewards/rejected": -7.5662384033203125,
      "step": 3402
    },
    {
      "epoch": 1.3612,
      "grad_norm": 0.3910074532032013,
      "learning_rate": 5.464e-07,
      "logits/chosen": -2.376150131225586,
      "logits/rejected": -2.8622307777404785,
      "logps/chosen": -121.93655395507812,
      "logps/rejected": -183.6597900390625,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9398689270019531,
      "rewards/margins": 10.066387176513672,
      "rewards/rejected": -8.126518249511719,
      "step": 3403
    },
    {
      "epoch": 1.3616,
      "grad_norm": 0.0008141713915392756,
      "learning_rate": 5.462666666666667e-07,
      "logits/chosen": -2.2205591201782227,
      "logits/rejected": -3.9711074829101562,
      "logps/chosen": -126.00658416748047,
      "logps/rejected": -189.701416015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.324376583099365,
      "rewards/margins": 11.97967529296875,
      "rewards/rejected": -7.655298709869385,
      "step": 3404
    },
    {
      "epoch": 1.362,
      "grad_norm": 0.1184140145778656,
      "learning_rate": 5.461333333333334e-07,
      "logits/chosen": -2.7298121452331543,
      "logits/rejected": -3.226067304611206,
      "logps/chosen": -149.66053771972656,
      "logps/rejected": -137.82508850097656,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3726234436035156,
      "rewards/margins": 7.497591972351074,
      "rewards/rejected": -5.124968528747559,
      "step": 3405
    },
    {
      "epoch": 1.3624,
      "grad_norm": 3.6029176712036133,
      "learning_rate": 5.46e-07,
      "logits/chosen": -1.7540335655212402,
      "logits/rejected": -3.4062747955322266,
      "logps/chosen": -114.4879379272461,
      "logps/rejected": -179.70567321777344,
      "loss": 0.02,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4186099767684937,
      "rewards/margins": 6.333697319030762,
      "rewards/rejected": -7.752306938171387,
      "step": 3406
    },
    {
      "epoch": 1.3628,
      "grad_norm": 0.06541936844587326,
      "learning_rate": 5.458666666666666e-07,
      "logits/chosen": -2.5221900939941406,
      "logits/rejected": -3.2923617362976074,
      "logps/chosen": -85.59237670898438,
      "logps/rejected": -155.02792358398438,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5848698616027832,
      "rewards/margins": 8.875919342041016,
      "rewards/rejected": -7.291049003601074,
      "step": 3407
    },
    {
      "epoch": 1.3632,
      "grad_norm": 0.008323402144014835,
      "learning_rate": 5.457333333333332e-07,
      "logits/chosen": -2.4221835136413574,
      "logits/rejected": -2.737614870071411,
      "logps/chosen": -149.28668212890625,
      "logps/rejected": -283.7855529785156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.765763998031616,
      "rewards/margins": 11.966314315795898,
      "rewards/rejected": -9.20055103302002,
      "step": 3408
    },
    {
      "epoch": 1.3636,
      "grad_norm": 0.007432195357978344,
      "learning_rate": 5.455999999999999e-07,
      "logits/chosen": -2.8586511611938477,
      "logits/rejected": -3.0384397506713867,
      "logps/chosen": -189.03749084472656,
      "logps/rejected": -190.89158630371094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.403859853744507,
      "rewards/margins": 9.663315773010254,
      "rewards/rejected": -6.259456157684326,
      "step": 3409
    },
    {
      "epoch": 1.3639999999999999,
      "grad_norm": 0.08809802681207657,
      "learning_rate": 5.454666666666666e-07,
      "logits/chosen": -2.349163055419922,
      "logits/rejected": -3.514000415802002,
      "logps/chosen": -102.25886535644531,
      "logps/rejected": -172.04563903808594,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.36183130741119385,
      "rewards/margins": 8.8494873046875,
      "rewards/rejected": -8.487655639648438,
      "step": 3410
    },
    {
      "epoch": 1.3644,
      "grad_norm": 151.07644653320312,
      "learning_rate": 5.453333333333333e-07,
      "logits/chosen": -1.15156888961792,
      "logits/rejected": -2.8609747886657715,
      "logps/chosen": -288.7881164550781,
      "logps/rejected": -142.70541381835938,
      "loss": 0.5206,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -1.9699203968048096,
      "rewards/margins": 3.294041872024536,
      "rewards/rejected": -5.263962268829346,
      "step": 3411
    },
    {
      "epoch": 1.3648,
      "grad_norm": 0.008091667667031288,
      "learning_rate": 5.452e-07,
      "logits/chosen": -2.094576358795166,
      "logits/rejected": -3.1858863830566406,
      "logps/chosen": -74.78561401367188,
      "logps/rejected": -158.3361358642578,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5580551624298096,
      "rewards/margins": 10.482742309570312,
      "rewards/rejected": -6.924687385559082,
      "step": 3412
    },
    {
      "epoch": 1.3652,
      "grad_norm": 0.017532512545585632,
      "learning_rate": 5.450666666666667e-07,
      "logits/chosen": -1.994133472442627,
      "logits/rejected": -3.567659854888916,
      "logps/chosen": -145.9176788330078,
      "logps/rejected": -196.94314575195312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9106113910675049,
      "rewards/margins": 9.860142707824707,
      "rewards/rejected": -7.949531555175781,
      "step": 3413
    },
    {
      "epoch": 1.3656,
      "grad_norm": 0.004644567146897316,
      "learning_rate": 5.449333333333334e-07,
      "logits/chosen": -2.7710230350494385,
      "logits/rejected": -3.2765960693359375,
      "logps/chosen": -162.2278594970703,
      "logps/rejected": -186.8624267578125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.086432456970215,
      "rewards/margins": 10.077438354492188,
      "rewards/rejected": -7.991005897521973,
      "step": 3414
    },
    {
      "epoch": 1.366,
      "grad_norm": 0.2575182616710663,
      "learning_rate": 5.448e-07,
      "logits/chosen": -2.554142475128174,
      "logits/rejected": -2.6955299377441406,
      "logps/chosen": -137.2410125732422,
      "logps/rejected": -137.7977294921875,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0364487171173096,
      "rewards/margins": 6.362786293029785,
      "rewards/rejected": -5.3263373374938965,
      "step": 3415
    },
    {
      "epoch": 1.3664,
      "grad_norm": 0.003933089319616556,
      "learning_rate": 5.446666666666666e-07,
      "logits/chosen": -2.5258193016052246,
      "logits/rejected": -3.3288002014160156,
      "logps/chosen": -153.63385009765625,
      "logps/rejected": -233.88833618164062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.133000373840332,
      "rewards/margins": 10.959532737731934,
      "rewards/rejected": -7.826532363891602,
      "step": 3416
    },
    {
      "epoch": 1.3668,
      "grad_norm": 0.09604837745428085,
      "learning_rate": 5.445333333333333e-07,
      "logits/chosen": -1.512987732887268,
      "logits/rejected": -3.5859322547912598,
      "logps/chosen": -105.4842758178711,
      "logps/rejected": -179.59942626953125,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0990192890167236,
      "rewards/margins": 7.662693977355957,
      "rewards/rejected": -6.563673973083496,
      "step": 3417
    },
    {
      "epoch": 1.3672,
      "grad_norm": 0.040366556495428085,
      "learning_rate": 5.443999999999999e-07,
      "logits/chosen": -2.3177061080932617,
      "logits/rejected": -3.0062947273254395,
      "logps/chosen": -109.09587860107422,
      "logps/rejected": -173.93324279785156,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9939934015274048,
      "rewards/margins": 8.848694801330566,
      "rewards/rejected": -7.854701042175293,
      "step": 3418
    },
    {
      "epoch": 1.3676,
      "grad_norm": 0.00529648968949914,
      "learning_rate": 5.442666666666666e-07,
      "logits/chosen": -2.4193782806396484,
      "logits/rejected": -3.540604591369629,
      "logps/chosen": -108.18638610839844,
      "logps/rejected": -179.9781036376953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.167480945587158,
      "rewards/margins": 10.086762428283691,
      "rewards/rejected": -7.919281959533691,
      "step": 3419
    },
    {
      "epoch": 1.3679999999999999,
      "grad_norm": 0.02662729099392891,
      "learning_rate": 5.441333333333333e-07,
      "logits/chosen": -2.085671901702881,
      "logits/rejected": -2.990004062652588,
      "logps/chosen": -113.09922790527344,
      "logps/rejected": -162.88992309570312,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3015315532684326,
      "rewards/margins": 9.635967254638672,
      "rewards/rejected": -7.334435939788818,
      "step": 3420
    },
    {
      "epoch": 1.3684,
      "grad_norm": 0.002877394435927272,
      "learning_rate": 5.44e-07,
      "logits/chosen": -2.2153677940368652,
      "logits/rejected": -3.4277994632720947,
      "logps/chosen": -180.04483032226562,
      "logps/rejected": -189.84024047851562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6350723505020142,
      "rewards/margins": 10.712381362915039,
      "rewards/rejected": -9.077308654785156,
      "step": 3421
    },
    {
      "epoch": 1.3688,
      "grad_norm": 0.08355762809515,
      "learning_rate": 5.438666666666667e-07,
      "logits/chosen": -2.1258327960968018,
      "logits/rejected": -3.479949474334717,
      "logps/chosen": -111.40666961669922,
      "logps/rejected": -183.37742614746094,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5979591608047485,
      "rewards/margins": 8.38560962677002,
      "rewards/rejected": -6.787651062011719,
      "step": 3422
    },
    {
      "epoch": 1.3692,
      "grad_norm": 0.00047370014362968504,
      "learning_rate": 5.437333333333333e-07,
      "logits/chosen": -2.0836801528930664,
      "logits/rejected": -3.4939911365509033,
      "logps/chosen": -72.09071350097656,
      "logps/rejected": -182.99163818359375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8829877376556396,
      "rewards/margins": 12.379220962524414,
      "rewards/rejected": -8.496232986450195,
      "step": 3423
    },
    {
      "epoch": 1.3696,
      "grad_norm": 5.515502452850342,
      "learning_rate": 5.436e-07,
      "logits/chosen": -2.1371865272521973,
      "logits/rejected": -3.179831027984619,
      "logps/chosen": -126.50559997558594,
      "logps/rejected": -179.62632751464844,
      "loss": 0.0389,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06795042753219604,
      "rewards/margins": 5.9583940505981445,
      "rewards/rejected": -5.890443801879883,
      "step": 3424
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.0010741313453763723,
      "learning_rate": 5.434666666666667e-07,
      "logits/chosen": -2.026064395904541,
      "logits/rejected": -3.873716354370117,
      "logps/chosen": -103.30862426757812,
      "logps/rejected": -236.44192504882812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.285842180252075,
      "rewards/margins": 12.266624450683594,
      "rewards/rejected": -8.980782508850098,
      "step": 3425
    },
    {
      "epoch": 1.3704,
      "grad_norm": 0.15244075655937195,
      "learning_rate": 5.433333333333334e-07,
      "logits/chosen": -1.4508941173553467,
      "logits/rejected": -2.990675449371338,
      "logps/chosen": -89.666015625,
      "logps/rejected": -134.51158142089844,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6738033294677734,
      "rewards/margins": 6.871191024780273,
      "rewards/rejected": -5.1973876953125,
      "step": 3426
    },
    {
      "epoch": 1.3708,
      "grad_norm": 0.00262220436707139,
      "learning_rate": 5.431999999999999e-07,
      "logits/chosen": -1.8826625347137451,
      "logits/rejected": -3.2640223503112793,
      "logps/chosen": -76.80204010009766,
      "logps/rejected": -170.68679809570312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.340338706970215,
      "rewards/margins": 10.866576194763184,
      "rewards/rejected": -7.526237487792969,
      "step": 3427
    },
    {
      "epoch": 1.3712,
      "grad_norm": 0.6575362086296082,
      "learning_rate": 5.430666666666666e-07,
      "logits/chosen": -1.8646304607391357,
      "logits/rejected": -3.0353503227233887,
      "logps/chosen": -116.08843994140625,
      "logps/rejected": -147.505859375,
      "loss": 0.0059,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4164532423019409,
      "rewards/margins": 7.233559608459473,
      "rewards/rejected": -6.817106246948242,
      "step": 3428
    },
    {
      "epoch": 1.3716,
      "grad_norm": 0.0023506300058215857,
      "learning_rate": 5.429333333333333e-07,
      "logits/chosen": -1.8202242851257324,
      "logits/rejected": -2.9077041149139404,
      "logps/chosen": -107.40009307861328,
      "logps/rejected": -183.17971801757812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4836935997009277,
      "rewards/margins": 11.640216827392578,
      "rewards/rejected": -8.156522750854492,
      "step": 3429
    },
    {
      "epoch": 1.3719999999999999,
      "grad_norm": 0.00592481903731823,
      "learning_rate": 5.427999999999999e-07,
      "logits/chosen": -1.9495892524719238,
      "logits/rejected": -3.300386428833008,
      "logps/chosen": -82.26116180419922,
      "logps/rejected": -182.1758270263672,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3586416244506836,
      "rewards/margins": 10.16661548614502,
      "rewards/rejected": -7.807973861694336,
      "step": 3430
    },
    {
      "epoch": 1.3724,
      "grad_norm": 2.0519015789031982,
      "learning_rate": 5.426666666666666e-07,
      "logits/chosen": -1.9242894649505615,
      "logits/rejected": -3.3292236328125,
      "logps/chosen": -139.64503479003906,
      "logps/rejected": -159.28805541992188,
      "loss": 0.016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5124977231025696,
      "rewards/margins": 6.022792816162109,
      "rewards/rejected": -6.535290718078613,
      "step": 3431
    },
    {
      "epoch": 1.3728,
      "grad_norm": 0.015663782134652138,
      "learning_rate": 5.425333333333333e-07,
      "logits/chosen": -2.156209945678711,
      "logits/rejected": -3.3009276390075684,
      "logps/chosen": -119.07624053955078,
      "logps/rejected": -208.27566528320312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.415592670440674,
      "rewards/margins": 9.599973678588867,
      "rewards/rejected": -7.184381484985352,
      "step": 3432
    },
    {
      "epoch": 1.3732,
      "grad_norm": 0.05819099768996239,
      "learning_rate": 5.424e-07,
      "logits/chosen": -1.963496208190918,
      "logits/rejected": -3.154148578643799,
      "logps/chosen": -110.74797821044922,
      "logps/rejected": -153.4588623046875,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.757664680480957,
      "rewards/margins": 9.633227348327637,
      "rewards/rejected": -5.87556266784668,
      "step": 3433
    },
    {
      "epoch": 1.3736,
      "grad_norm": 0.29837632179260254,
      "learning_rate": 5.422666666666667e-07,
      "logits/chosen": -1.7665791511535645,
      "logits/rejected": -3.1081931591033936,
      "logps/chosen": -88.86061096191406,
      "logps/rejected": -144.43385314941406,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6604393124580383,
      "rewards/margins": 6.137648582458496,
      "rewards/rejected": -5.477209091186523,
      "step": 3434
    },
    {
      "epoch": 1.374,
      "grad_norm": 0.004660737235099077,
      "learning_rate": 5.421333333333334e-07,
      "logits/chosen": -2.5461721420288086,
      "logits/rejected": -3.408257484436035,
      "logps/chosen": -118.89640045166016,
      "logps/rejected": -186.86373901367188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.698716640472412,
      "rewards/margins": 10.233155250549316,
      "rewards/rejected": -6.534438133239746,
      "step": 3435
    },
    {
      "epoch": 1.3744,
      "grad_norm": 0.0024593151174485683,
      "learning_rate": 5.420000000000001e-07,
      "logits/chosen": -2.2038028240203857,
      "logits/rejected": -3.4984166622161865,
      "logps/chosen": -219.13880920410156,
      "logps/rejected": -221.1938018798828,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6468703746795654,
      "rewards/margins": 10.841236114501953,
      "rewards/rejected": -8.194364547729492,
      "step": 3436
    },
    {
      "epoch": 1.3748,
      "grad_norm": 0.011324518360197544,
      "learning_rate": 5.418666666666666e-07,
      "logits/chosen": -2.6345856189727783,
      "logits/rejected": -3.0781044960021973,
      "logps/chosen": -176.8226318359375,
      "logps/rejected": -246.84909057617188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4000167846679688,
      "rewards/margins": 10.275137901306152,
      "rewards/rejected": -7.875121116638184,
      "step": 3437
    },
    {
      "epoch": 1.3752,
      "grad_norm": 0.05784136429429054,
      "learning_rate": 5.417333333333332e-07,
      "logits/chosen": -2.2794322967529297,
      "logits/rejected": -3.5482921600341797,
      "logps/chosen": -118.6419677734375,
      "logps/rejected": -174.6085205078125,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8292182683944702,
      "rewards/margins": 9.091476440429688,
      "rewards/rejected": -7.262258529663086,
      "step": 3438
    },
    {
      "epoch": 1.3756,
      "grad_norm": 0.017162593081593513,
      "learning_rate": 5.415999999999999e-07,
      "logits/chosen": -3.113914728164673,
      "logits/rejected": -3.6242637634277344,
      "logps/chosen": -156.81890869140625,
      "logps/rejected": -209.62857055664062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9285606145858765,
      "rewards/margins": 9.097251892089844,
      "rewards/rejected": -10.025812149047852,
      "step": 3439
    },
    {
      "epoch": 1.376,
      "grad_norm": 0.014670166186988354,
      "learning_rate": 5.414666666666666e-07,
      "logits/chosen": -2.0397789478302,
      "logits/rejected": -3.628289222717285,
      "logps/chosen": -63.38676452636719,
      "logps/rejected": -208.40292358398438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3284976482391357,
      "rewards/margins": 12.082730293273926,
      "rewards/rejected": -9.754232406616211,
      "step": 3440
    },
    {
      "epoch": 1.3764,
      "grad_norm": 0.024716494604945183,
      "learning_rate": 5.413333333333333e-07,
      "logits/chosen": -2.0793297290802,
      "logits/rejected": -3.491459369659424,
      "logps/chosen": -161.36151123046875,
      "logps/rejected": -215.49151611328125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5713067054748535,
      "rewards/margins": 10.549238204956055,
      "rewards/rejected": -8.977931022644043,
      "step": 3441
    },
    {
      "epoch": 1.3768,
      "grad_norm": 0.0023099826648831367,
      "learning_rate": 5.412e-07,
      "logits/chosen": -2.1592445373535156,
      "logits/rejected": -3.2944247722625732,
      "logps/chosen": -180.67837524414062,
      "logps/rejected": -218.2738037109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8071129322052,
      "rewards/margins": 11.2916841506958,
      "rewards/rejected": -7.48457145690918,
      "step": 3442
    },
    {
      "epoch": 1.3772,
      "grad_norm": 0.03688879683613777,
      "learning_rate": 5.410666666666667e-07,
      "logits/chosen": -2.2025821208953857,
      "logits/rejected": -2.860609292984009,
      "logps/chosen": -96.96751403808594,
      "logps/rejected": -188.08523559570312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6409492492675781,
      "rewards/margins": 10.294017791748047,
      "rewards/rejected": -8.653068542480469,
      "step": 3443
    },
    {
      "epoch": 1.3776,
      "grad_norm": 0.015208949334919453,
      "learning_rate": 5.409333333333334e-07,
      "logits/chosen": -2.4039387702941895,
      "logits/rejected": -3.584955930709839,
      "logps/chosen": -128.41326904296875,
      "logps/rejected": -195.32958984375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9203765988349915,
      "rewards/margins": 9.178627967834473,
      "rewards/rejected": -8.258251190185547,
      "step": 3444
    },
    {
      "epoch": 1.3780000000000001,
      "grad_norm": 0.0002108612679876387,
      "learning_rate": 5.408e-07,
      "logits/chosen": -2.231881618499756,
      "logits/rejected": -3.8879234790802,
      "logps/chosen": -161.47024536132812,
      "logps/rejected": -246.16741943359375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8845505714416504,
      "rewards/margins": 13.807657241821289,
      "rewards/rejected": -10.923107147216797,
      "step": 3445
    },
    {
      "epoch": 1.3784,
      "grad_norm": 0.04531078785657883,
      "learning_rate": 5.406666666666666e-07,
      "logits/chosen": -3.0655734539031982,
      "logits/rejected": -3.083458423614502,
      "logps/chosen": -276.9087219238281,
      "logps/rejected": -175.99032592773438,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8971694707870483,
      "rewards/margins": 8.038776397705078,
      "rewards/rejected": -7.141607284545898,
      "step": 3446
    },
    {
      "epoch": 1.3788,
      "grad_norm": 0.003089587204158306,
      "learning_rate": 5.405333333333333e-07,
      "logits/chosen": -2.0481274127960205,
      "logits/rejected": -3.458081007003784,
      "logps/chosen": -100.05106353759766,
      "logps/rejected": -185.2686767578125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0783421993255615,
      "rewards/margins": 10.791255950927734,
      "rewards/rejected": -7.712913513183594,
      "step": 3447
    },
    {
      "epoch": 1.3792,
      "grad_norm": 0.05000099912285805,
      "learning_rate": 5.403999999999999e-07,
      "logits/chosen": -1.8220171928405762,
      "logits/rejected": -3.044877529144287,
      "logps/chosen": -63.98451614379883,
      "logps/rejected": -143.14599609375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9360835552215576,
      "rewards/margins": 8.442010879516602,
      "rewards/rejected": -5.505927085876465,
      "step": 3448
    },
    {
      "epoch": 1.3796,
      "grad_norm": 0.33109813928604126,
      "learning_rate": 5.402666666666666e-07,
      "logits/chosen": -2.3167357444763184,
      "logits/rejected": -3.326051950454712,
      "logps/chosen": -187.991455078125,
      "logps/rejected": -146.32289123535156,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7299209237098694,
      "rewards/margins": 5.9299821853637695,
      "rewards/rejected": -5.200060844421387,
      "step": 3449
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.002062731422483921,
      "learning_rate": 5.401333333333333e-07,
      "logits/chosen": -2.562396287918091,
      "logits/rejected": -3.2347967624664307,
      "logps/chosen": -188.5299530029297,
      "logps/rejected": -197.41297912597656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 5.172039985656738,
      "rewards/margins": 11.575142860412598,
      "rewards/rejected": -6.403102874755859,
      "step": 3450
    },
    {
      "epoch": 1.3804,
      "grad_norm": 0.00043140322668477893,
      "learning_rate": 5.4e-07,
      "logits/chosen": -1.9427001476287842,
      "logits/rejected": -3.3620269298553467,
      "logps/chosen": -82.71237182617188,
      "logps/rejected": -206.43283081054688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.154560089111328,
      "rewards/margins": 13.110179901123047,
      "rewards/rejected": -8.955620765686035,
      "step": 3451
    },
    {
      "epoch": 1.3808,
      "grad_norm": 1.5343953371047974,
      "learning_rate": 5.398666666666667e-07,
      "logits/chosen": -2.330404758453369,
      "logits/rejected": -3.019711494445801,
      "logps/chosen": -130.10047912597656,
      "logps/rejected": -139.97244262695312,
      "loss": 0.0129,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14254796504974365,
      "rewards/margins": 5.599654197692871,
      "rewards/rejected": -5.457106590270996,
      "step": 3452
    },
    {
      "epoch": 1.3812,
      "grad_norm": 9.079016308533028e-05,
      "learning_rate": 5.397333333333333e-07,
      "logits/chosen": -2.1128485202789307,
      "logits/rejected": -3.2797186374664307,
      "logps/chosen": -161.8375244140625,
      "logps/rejected": -238.22760009765625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.037444114685059,
      "rewards/margins": 14.477157592773438,
      "rewards/rejected": -10.439713478088379,
      "step": 3453
    },
    {
      "epoch": 1.3816,
      "grad_norm": 0.003092778380960226,
      "learning_rate": 5.396e-07,
      "logits/chosen": -2.3501527309417725,
      "logits/rejected": -3.7537903785705566,
      "logps/chosen": -141.24441528320312,
      "logps/rejected": -171.05752563476562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.0050225257873535,
      "rewards/margins": 11.087505340576172,
      "rewards/rejected": -7.082482814788818,
      "step": 3454
    },
    {
      "epoch": 1.3820000000000001,
      "grad_norm": 0.2971358597278595,
      "learning_rate": 5.394666666666666e-07,
      "logits/chosen": -1.8265388011932373,
      "logits/rejected": -2.4500951766967773,
      "logps/chosen": -128.46951293945312,
      "logps/rejected": -127.65420532226562,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2118263244628906,
      "rewards/margins": 6.76844596862793,
      "rewards/rejected": -5.556619644165039,
      "step": 3455
    },
    {
      "epoch": 1.3824,
      "grad_norm": 0.008108253590762615,
      "learning_rate": 5.393333333333333e-07,
      "logits/chosen": -2.546058416366577,
      "logits/rejected": -3.1263906955718994,
      "logps/chosen": -109.1124267578125,
      "logps/rejected": -187.41688537597656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4621939659118652,
      "rewards/margins": 10.52215576171875,
      "rewards/rejected": -7.059962749481201,
      "step": 3456
    },
    {
      "epoch": 1.3828,
      "grad_norm": 0.0955437645316124,
      "learning_rate": 5.392e-07,
      "logits/chosen": -2.1586694717407227,
      "logits/rejected": -3.178694486618042,
      "logps/chosen": -93.43561553955078,
      "logps/rejected": -152.78529357910156,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0556529760360718,
      "rewards/margins": 8.51258659362793,
      "rewards/rejected": -7.45693302154541,
      "step": 3457
    },
    {
      "epoch": 1.3832,
      "grad_norm": 0.2127586156129837,
      "learning_rate": 5.390666666666666e-07,
      "logits/chosen": -2.882551908493042,
      "logits/rejected": -3.1728949546813965,
      "logps/chosen": -182.1014404296875,
      "logps/rejected": -184.17922973632812,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2214088439941406,
      "rewards/margins": 8.324578285217285,
      "rewards/rejected": -7.1031694412231445,
      "step": 3458
    },
    {
      "epoch": 1.3836,
      "grad_norm": 0.06863488256931305,
      "learning_rate": 5.389333333333333e-07,
      "logits/chosen": -2.0588431358337402,
      "logits/rejected": -3.398890256881714,
      "logps/chosen": -207.8009796142578,
      "logps/rejected": -217.96548461914062,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6897018551826477,
      "rewards/margins": 8.96949577331543,
      "rewards/rejected": -8.279793739318848,
      "step": 3459
    },
    {
      "epoch": 1.384,
      "grad_norm": 0.19096197187900543,
      "learning_rate": 5.387999999999999e-07,
      "logits/chosen": -2.3398663997650146,
      "logits/rejected": -2.578622579574585,
      "logps/chosen": -73.54931640625,
      "logps/rejected": -135.0591278076172,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0820003747940063,
      "rewards/margins": 7.8044657707214355,
      "rewards/rejected": -6.722465515136719,
      "step": 3460
    },
    {
      "epoch": 1.3844,
      "grad_norm": 0.019174247980117798,
      "learning_rate": 5.386666666666666e-07,
      "logits/chosen": -2.1029927730560303,
      "logits/rejected": -3.2589375972747803,
      "logps/chosen": -130.16665649414062,
      "logps/rejected": -152.26947021484375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.671485185623169,
      "rewards/margins": 9.152288436889648,
      "rewards/rejected": -6.480803489685059,
      "step": 3461
    },
    {
      "epoch": 1.3848,
      "grad_norm": 0.0982850044965744,
      "learning_rate": 5.385333333333333e-07,
      "logits/chosen": -2.3778867721557617,
      "logits/rejected": -3.3695855140686035,
      "logps/chosen": -151.2066650390625,
      "logps/rejected": -160.91900634765625,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.512959361076355,
      "rewards/margins": 7.597134590148926,
      "rewards/rejected": -6.084175109863281,
      "step": 3462
    },
    {
      "epoch": 1.3852,
      "grad_norm": 0.11505002528429031,
      "learning_rate": 5.384e-07,
      "logits/chosen": -2.1260011196136475,
      "logits/rejected": -3.175778865814209,
      "logps/chosen": -119.359130859375,
      "logps/rejected": -165.37852478027344,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.75664222240448,
      "rewards/margins": 8.905649185180664,
      "rewards/rejected": -7.1490068435668945,
      "step": 3463
    },
    {
      "epoch": 1.3856,
      "grad_norm": 0.2547183632850647,
      "learning_rate": 5.382666666666667e-07,
      "logits/chosen": -2.283054828643799,
      "logits/rejected": -3.3685436248779297,
      "logps/chosen": -236.61170959472656,
      "logps/rejected": -217.8897705078125,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.48478472232818604,
      "rewards/margins": 8.685222625732422,
      "rewards/rejected": -8.200437545776367,
      "step": 3464
    },
    {
      "epoch": 1.3860000000000001,
      "grad_norm": 0.034841250628232956,
      "learning_rate": 5.381333333333333e-07,
      "logits/chosen": -2.253216028213501,
      "logits/rejected": -3.788217067718506,
      "logps/chosen": -128.60118103027344,
      "logps/rejected": -199.2213897705078,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2975802421569824,
      "rewards/margins": 9.454218864440918,
      "rewards/rejected": -8.156639099121094,
      "step": 3465
    },
    {
      "epoch": 1.3864,
      "grad_norm": 0.0021856925450265408,
      "learning_rate": 5.38e-07,
      "logits/chosen": -2.39211368560791,
      "logits/rejected": -3.399993419647217,
      "logps/chosen": -211.2764892578125,
      "logps/rejected": -192.36460876464844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1546566486358643,
      "rewards/margins": 11.469669342041016,
      "rewards/rejected": -8.315011978149414,
      "step": 3466
    },
    {
      "epoch": 1.3868,
      "grad_norm": 0.022844159975647926,
      "learning_rate": 5.378666666666667e-07,
      "logits/chosen": -2.258826732635498,
      "logits/rejected": -2.425863265991211,
      "logps/chosen": -105.50385284423828,
      "logps/rejected": -162.13522338867188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0614404678344727,
      "rewards/margins": 8.653818130493164,
      "rewards/rejected": -5.592377662658691,
      "step": 3467
    },
    {
      "epoch": 1.3872,
      "grad_norm": 0.0015126601792871952,
      "learning_rate": 5.377333333333333e-07,
      "logits/chosen": -2.176513671875,
      "logits/rejected": -3.2533304691314697,
      "logps/chosen": -124.6181411743164,
      "logps/rejected": -184.06297302246094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.077610015869141,
      "rewards/margins": 11.306144714355469,
      "rewards/rejected": -7.2285356521606445,
      "step": 3468
    },
    {
      "epoch": 1.3876,
      "grad_norm": 0.6285693645477295,
      "learning_rate": 5.375999999999999e-07,
      "logits/chosen": -1.846055030822754,
      "logits/rejected": -3.1885995864868164,
      "logps/chosen": -92.56438446044922,
      "logps/rejected": -130.0831298828125,
      "loss": 0.0075,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6306400895118713,
      "rewards/margins": 6.094494819641113,
      "rewards/rejected": -5.463854789733887,
      "step": 3469
    },
    {
      "epoch": 1.388,
      "grad_norm": 0.000724516692571342,
      "learning_rate": 5.374666666666666e-07,
      "logits/chosen": -2.5890755653381348,
      "logits/rejected": -3.231489658355713,
      "logps/chosen": -143.37646484375,
      "logps/rejected": -174.3960418701172,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 5.0731658935546875,
      "rewards/margins": 12.493000984191895,
      "rewards/rejected": -7.419834613800049,
      "step": 3470
    },
    {
      "epoch": 1.3884,
      "grad_norm": 0.01621708646416664,
      "learning_rate": 5.373333333333333e-07,
      "logits/chosen": -1.9395904541015625,
      "logits/rejected": -3.1241402626037598,
      "logps/chosen": -72.97811889648438,
      "logps/rejected": -157.58935546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8807671070098877,
      "rewards/margins": 9.162457466125488,
      "rewards/rejected": -7.28169059753418,
      "step": 3471
    },
    {
      "epoch": 1.3888,
      "grad_norm": 0.008250068873167038,
      "learning_rate": 5.372e-07,
      "logits/chosen": -1.779746413230896,
      "logits/rejected": -3.2055611610412598,
      "logps/chosen": -107.82627868652344,
      "logps/rejected": -154.5940704345703,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4742026329040527,
      "rewards/margins": 9.266385078430176,
      "rewards/rejected": -5.792182445526123,
      "step": 3472
    },
    {
      "epoch": 1.3892,
      "grad_norm": 0.014430619776248932,
      "learning_rate": 5.370666666666667e-07,
      "logits/chosen": -2.2668063640594482,
      "logits/rejected": -3.328462600708008,
      "logps/chosen": -196.80006408691406,
      "logps/rejected": -341.4910888671875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7586631774902344,
      "rewards/margins": 10.383761405944824,
      "rewards/rejected": -7.62509822845459,
      "step": 3473
    },
    {
      "epoch": 1.3896,
      "grad_norm": 0.0011186482151970267,
      "learning_rate": 5.369333333333333e-07,
      "logits/chosen": -1.982896327972412,
      "logits/rejected": -3.545443058013916,
      "logps/chosen": -92.99392700195312,
      "logps/rejected": -180.67462158203125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9589877128601074,
      "rewards/margins": 11.723896980285645,
      "rewards/rejected": -7.764908790588379,
      "step": 3474
    },
    {
      "epoch": 1.3900000000000001,
      "grad_norm": 0.008757694624364376,
      "learning_rate": 5.368e-07,
      "logits/chosen": -2.061586856842041,
      "logits/rejected": -3.2788877487182617,
      "logps/chosen": -144.7505340576172,
      "logps/rejected": -230.957763671875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0709166526794434,
      "rewards/margins": 9.63526439666748,
      "rewards/rejected": -7.564348220825195,
      "step": 3475
    },
    {
      "epoch": 1.3904,
      "grad_norm": 0.030267737805843353,
      "learning_rate": 5.366666666666666e-07,
      "logits/chosen": -2.3488545417785645,
      "logits/rejected": -3.243222713470459,
      "logps/chosen": -147.49632263183594,
      "logps/rejected": -162.07427978515625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8035286664962769,
      "rewards/margins": 8.283478736877441,
      "rewards/rejected": -6.479949951171875,
      "step": 3476
    },
    {
      "epoch": 1.3908,
      "grad_norm": 0.09654010832309723,
      "learning_rate": 5.365333333333333e-07,
      "logits/chosen": -1.9669979810714722,
      "logits/rejected": -2.9312665462493896,
      "logps/chosen": -131.84153747558594,
      "logps/rejected": -163.1572265625,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8357930183410645,
      "rewards/margins": 8.733388900756836,
      "rewards/rejected": -5.89759635925293,
      "step": 3477
    },
    {
      "epoch": 1.3912,
      "grad_norm": 0.009807892143726349,
      "learning_rate": 5.364e-07,
      "logits/chosen": -2.0024828910827637,
      "logits/rejected": -3.322760581970215,
      "logps/chosen": -144.89524841308594,
      "logps/rejected": -184.5320587158203,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.570685386657715,
      "rewards/margins": 9.768035888671875,
      "rewards/rejected": -7.197350978851318,
      "step": 3478
    },
    {
      "epoch": 1.3916,
      "grad_norm": 0.0778869166970253,
      "learning_rate": 5.362666666666667e-07,
      "logits/chosen": -2.3942818641662598,
      "logits/rejected": -3.7722792625427246,
      "logps/chosen": -119.39302062988281,
      "logps/rejected": -184.94898986816406,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6013035178184509,
      "rewards/margins": 8.796699523925781,
      "rewards/rejected": -8.195395469665527,
      "step": 3479
    },
    {
      "epoch": 1.392,
      "grad_norm": 0.0022253391798585653,
      "learning_rate": 5.361333333333333e-07,
      "logits/chosen": -1.8555065393447876,
      "logits/rejected": -2.9555275440216064,
      "logps/chosen": -75.20215606689453,
      "logps/rejected": -177.028564453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1242499351501465,
      "rewards/margins": 12.32335090637207,
      "rewards/rejected": -9.199101448059082,
      "step": 3480
    },
    {
      "epoch": 1.3924,
      "grad_norm": 0.003274311078712344,
      "learning_rate": 5.36e-07,
      "logits/chosen": -2.1010019779205322,
      "logits/rejected": -3.5694074630737305,
      "logps/chosen": -93.82524871826172,
      "logps/rejected": -188.0611114501953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.680044651031494,
      "rewards/margins": 11.103349685668945,
      "rewards/rejected": -7.423304557800293,
      "step": 3481
    },
    {
      "epoch": 1.3928,
      "grad_norm": 0.04290447384119034,
      "learning_rate": 5.358666666666667e-07,
      "logits/chosen": -2.0729711055755615,
      "logits/rejected": -3.49495792388916,
      "logps/chosen": -93.8240966796875,
      "logps/rejected": -201.926513671875,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8330185413360596,
      "rewards/margins": 9.35880184173584,
      "rewards/rejected": -8.52578353881836,
      "step": 3482
    },
    {
      "epoch": 1.3932,
      "grad_norm": 1.2481311559677124,
      "learning_rate": 5.357333333333332e-07,
      "logits/chosen": -2.751458168029785,
      "logits/rejected": -3.5210824012756348,
      "logps/chosen": -170.4365234375,
      "logps/rejected": -178.04525756835938,
      "loss": 0.0072,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18090319633483887,
      "rewards/margins": 8.073091506958008,
      "rewards/rejected": -7.892189025878906,
      "step": 3483
    },
    {
      "epoch": 1.3936,
      "grad_norm": 0.006323240231722593,
      "learning_rate": 5.355999999999999e-07,
      "logits/chosen": -2.152346611022949,
      "logits/rejected": -3.335087776184082,
      "logps/chosen": -93.72028350830078,
      "logps/rejected": -169.36886596679688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.176426410675049,
      "rewards/margins": 9.830836296081543,
      "rewards/rejected": -6.654409885406494,
      "step": 3484
    },
    {
      "epoch": 1.3940000000000001,
      "grad_norm": 0.13272187113761902,
      "learning_rate": 5.354666666666666e-07,
      "logits/chosen": -1.727675199508667,
      "logits/rejected": -3.3227427005767822,
      "logps/chosen": -100.7759017944336,
      "logps/rejected": -172.98580932617188,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.090301513671875,
      "rewards/margins": 6.703864097595215,
      "rewards/rejected": -6.79416561126709,
      "step": 3485
    },
    {
      "epoch": 1.3944,
      "grad_norm": 0.018369128927588463,
      "learning_rate": 5.353333333333333e-07,
      "logits/chosen": -2.4588332176208496,
      "logits/rejected": -3.323172092437744,
      "logps/chosen": -216.91339111328125,
      "logps/rejected": -192.05638122558594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1587042808532715,
      "rewards/margins": 9.05293083190918,
      "rewards/rejected": -6.89422607421875,
      "step": 3486
    },
    {
      "epoch": 1.3948,
      "grad_norm": 0.1102137416601181,
      "learning_rate": 5.352e-07,
      "logits/chosen": -2.3014912605285645,
      "logits/rejected": -3.139071464538574,
      "logps/chosen": -148.9806671142578,
      "logps/rejected": -166.0691680908203,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.341799020767212,
      "rewards/margins": 9.104132652282715,
      "rewards/rejected": -5.762333869934082,
      "step": 3487
    },
    {
      "epoch": 1.3952,
      "grad_norm": 0.09613453596830368,
      "learning_rate": 5.350666666666667e-07,
      "logits/chosen": -1.883432149887085,
      "logits/rejected": -3.5860049724578857,
      "logps/chosen": -101.85417175292969,
      "logps/rejected": -159.52806091308594,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5806106328964233,
      "rewards/margins": 8.360749244689941,
      "rewards/rejected": -6.78013801574707,
      "step": 3488
    },
    {
      "epoch": 1.3956,
      "grad_norm": 0.5581706762313843,
      "learning_rate": 5.349333333333334e-07,
      "logits/chosen": -1.933373212814331,
      "logits/rejected": -3.02872896194458,
      "logps/chosen": -159.33673095703125,
      "logps/rejected": -173.40182495117188,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.636381983757019,
      "rewards/margins": 9.305288314819336,
      "rewards/rejected": -7.668906211853027,
      "step": 3489
    },
    {
      "epoch": 1.396,
      "grad_norm": 0.05111604928970337,
      "learning_rate": 5.348e-07,
      "logits/chosen": -1.6617376804351807,
      "logits/rejected": -3.2883236408233643,
      "logps/chosen": -109.97703552246094,
      "logps/rejected": -155.37823486328125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9245700836181641,
      "rewards/margins": 7.6407623291015625,
      "rewards/rejected": -6.716192245483398,
      "step": 3490
    },
    {
      "epoch": 1.3963999999999999,
      "grad_norm": 0.0021151965484023094,
      "learning_rate": 5.346666666666666e-07,
      "logits/chosen": -1.9430065155029297,
      "logits/rejected": -3.503030776977539,
      "logps/chosen": -165.89088439941406,
      "logps/rejected": -194.38331604003906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6338372230529785,
      "rewards/margins": 11.018386840820312,
      "rewards/rejected": -8.384550094604492,
      "step": 3491
    },
    {
      "epoch": 1.3968,
      "grad_norm": 0.28893059492111206,
      "learning_rate": 5.345333333333333e-07,
      "logits/chosen": -1.9573380947113037,
      "logits/rejected": -3.210632801055908,
      "logps/chosen": -130.45510864257812,
      "logps/rejected": -115.92745971679688,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3618221282958984,
      "rewards/margins": 5.95286750793457,
      "rewards/rejected": -4.591045379638672,
      "step": 3492
    },
    {
      "epoch": 1.3972,
      "grad_norm": 0.03797093406319618,
      "learning_rate": 5.343999999999999e-07,
      "logits/chosen": -2.09277081489563,
      "logits/rejected": -2.992217540740967,
      "logps/chosen": -145.11227416992188,
      "logps/rejected": -157.9967041015625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.277761936187744,
      "rewards/margins": 7.978091716766357,
      "rewards/rejected": -5.700329780578613,
      "step": 3493
    },
    {
      "epoch": 1.3976,
      "grad_norm": 0.005203068256378174,
      "learning_rate": 5.342666666666666e-07,
      "logits/chosen": -1.9092764854431152,
      "logits/rejected": -2.8871090412139893,
      "logps/chosen": -69.15534973144531,
      "logps/rejected": -160.77090454101562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6554787158966064,
      "rewards/margins": 10.75063419342041,
      "rewards/rejected": -7.095155239105225,
      "step": 3494
    },
    {
      "epoch": 1.3980000000000001,
      "grad_norm": 1.7883546352386475,
      "learning_rate": 5.341333333333333e-07,
      "logits/chosen": -1.9262073040008545,
      "logits/rejected": -2.662802219390869,
      "logps/chosen": -68.80422973632812,
      "logps/rejected": -134.2666473388672,
      "loss": 0.0097,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3454931676387787,
      "rewards/margins": 5.347211837768555,
      "rewards/rejected": -5.001718521118164,
      "step": 3495
    },
    {
      "epoch": 1.3984,
      "grad_norm": 0.024693699553608894,
      "learning_rate": 5.34e-07,
      "logits/chosen": -2.0570878982543945,
      "logits/rejected": -2.3044888973236084,
      "logps/chosen": -159.1743927001953,
      "logps/rejected": -179.04074096679688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3698761463165283,
      "rewards/margins": 10.596364974975586,
      "rewards/rejected": -7.226489543914795,
      "step": 3496
    },
    {
      "epoch": 1.3988,
      "grad_norm": 0.07914233952760696,
      "learning_rate": 5.338666666666667e-07,
      "logits/chosen": -2.751997709274292,
      "logits/rejected": -3.2592058181762695,
      "logps/chosen": -119.19865417480469,
      "logps/rejected": -171.95217895507812,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4041881561279297,
      "rewards/margins": 9.199613571166992,
      "rewards/rejected": -7.7954254150390625,
      "step": 3497
    },
    {
      "epoch": 1.3992,
      "grad_norm": 0.022642454132437706,
      "learning_rate": 5.337333333333333e-07,
      "logits/chosen": -1.857234001159668,
      "logits/rejected": -3.4360647201538086,
      "logps/chosen": -110.70783996582031,
      "logps/rejected": -172.3594207763672,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.983048677444458,
      "rewards/margins": 10.270830154418945,
      "rewards/rejected": -8.28778076171875,
      "step": 3498
    },
    {
      "epoch": 1.3996,
      "grad_norm": 0.013797265477478504,
      "learning_rate": 5.336e-07,
      "logits/chosen": -1.7619857788085938,
      "logits/rejected": -3.4911911487579346,
      "logps/chosen": -129.77255249023438,
      "logps/rejected": -215.84664916992188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2663745880126953,
      "rewards/margins": 10.541528701782227,
      "rewards/rejected": -8.275154113769531,
      "step": 3499
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.4250201880931854,
      "learning_rate": 5.334666666666667e-07,
      "logits/chosen": -2.048354148864746,
      "logits/rejected": -2.2538371086120605,
      "logps/chosen": -107.07967376708984,
      "logps/rejected": -133.42724609375,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10570908337831497,
      "rewards/margins": 6.486437797546387,
      "rewards/rejected": -6.380728721618652,
      "step": 3500
    },
    {
      "epoch": 1.4003999999999999,
      "grad_norm": 0.03486480191349983,
      "learning_rate": 5.333333333333333e-07,
      "logits/chosen": -1.830977439880371,
      "logits/rejected": -3.1324477195739746,
      "logps/chosen": -109.28962707519531,
      "logps/rejected": -137.40594482421875,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4361355304718018,
      "rewards/margins": 7.870007514953613,
      "rewards/rejected": -6.433872222900391,
      "step": 3501
    },
    {
      "epoch": 1.4008,
      "grad_norm": 0.11963450163602829,
      "learning_rate": 5.331999999999999e-07,
      "logits/chosen": -1.7345165014266968,
      "logits/rejected": -2.8397321701049805,
      "logps/chosen": -124.98909759521484,
      "logps/rejected": -168.25662231445312,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0010051727294922,
      "rewards/margins": 7.947226047515869,
      "rewards/rejected": -6.946220397949219,
      "step": 3502
    },
    {
      "epoch": 1.4012,
      "grad_norm": 0.007875222712755203,
      "learning_rate": 5.330666666666666e-07,
      "logits/chosen": -2.032863140106201,
      "logits/rejected": -3.4777374267578125,
      "logps/chosen": -71.10308837890625,
      "logps/rejected": -162.3477783203125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6536331176757812,
      "rewards/margins": 10.000377655029297,
      "rewards/rejected": -7.346744537353516,
      "step": 3503
    },
    {
      "epoch": 1.4016,
      "grad_norm": 0.01038315612822771,
      "learning_rate": 5.329333333333333e-07,
      "logits/chosen": -1.7684247493743896,
      "logits/rejected": -3.3119544982910156,
      "logps/chosen": -135.66278076171875,
      "logps/rejected": -178.12796020507812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1235885620117188,
      "rewards/margins": 10.008245468139648,
      "rewards/rejected": -6.884657382965088,
      "step": 3504
    },
    {
      "epoch": 1.4020000000000001,
      "grad_norm": 0.0019452010747045279,
      "learning_rate": 5.328e-07,
      "logits/chosen": -2.7389519214630127,
      "logits/rejected": -3.31276273727417,
      "logps/chosen": -160.44102478027344,
      "logps/rejected": -241.70248413085938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.73268461227417,
      "rewards/margins": 11.065685272216797,
      "rewards/rejected": -8.333001136779785,
      "step": 3505
    },
    {
      "epoch": 1.4024,
      "grad_norm": 2.2675042152404785,
      "learning_rate": 5.326666666666666e-07,
      "logits/chosen": -2.2111620903015137,
      "logits/rejected": -3.5962955951690674,
      "logps/chosen": -160.3455810546875,
      "logps/rejected": -160.63125610351562,
      "loss": 0.0205,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.44866833090782166,
      "rewards/margins": 7.581571578979492,
      "rewards/rejected": -7.132903099060059,
      "step": 3506
    },
    {
      "epoch": 1.4028,
      "grad_norm": 0.06853834539651871,
      "learning_rate": 5.325333333333333e-07,
      "logits/chosen": -1.387387752532959,
      "logits/rejected": -2.7090742588043213,
      "logps/chosen": -94.41427612304688,
      "logps/rejected": -141.78903198242188,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0472172498703003,
      "rewards/margins": 7.233329772949219,
      "rewards/rejected": -6.186112403869629,
      "step": 3507
    },
    {
      "epoch": 1.4032,
      "grad_norm": 0.0087807085365057,
      "learning_rate": 5.324e-07,
      "logits/chosen": -2.237420082092285,
      "logits/rejected": -2.873861312866211,
      "logps/chosen": -121.0084228515625,
      "logps/rejected": -165.19830322265625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.69013786315918,
      "rewards/margins": 10.40382194519043,
      "rewards/rejected": -5.71368408203125,
      "step": 3508
    },
    {
      "epoch": 1.4036,
      "grad_norm": 0.23953093588352203,
      "learning_rate": 5.322666666666667e-07,
      "logits/chosen": -2.2360239028930664,
      "logits/rejected": -2.962322235107422,
      "logps/chosen": -203.65884399414062,
      "logps/rejected": -133.9984130859375,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0289733409881592,
      "rewards/margins": 7.115084171295166,
      "rewards/rejected": -6.086111068725586,
      "step": 3509
    },
    {
      "epoch": 1.404,
      "grad_norm": 0.09855102747678757,
      "learning_rate": 5.321333333333334e-07,
      "logits/chosen": -2.357898235321045,
      "logits/rejected": -2.6935954093933105,
      "logps/chosen": -91.18276977539062,
      "logps/rejected": -298.27874755859375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.908555269241333,
      "rewards/margins": 8.690641403198242,
      "rewards/rejected": -5.782086372375488,
      "step": 3510
    },
    {
      "epoch": 1.4043999999999999,
      "grad_norm": 0.11210813373327255,
      "learning_rate": 5.32e-07,
      "logits/chosen": -1.9733167886734009,
      "logits/rejected": -3.0587997436523438,
      "logps/chosen": -154.66004943847656,
      "logps/rejected": -170.22662353515625,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.204925537109375,
      "rewards/margins": 8.201425552368164,
      "rewards/rejected": -6.996500015258789,
      "step": 3511
    },
    {
      "epoch": 1.4048,
      "grad_norm": 0.011318431235849857,
      "learning_rate": 5.318666666666666e-07,
      "logits/chosen": -2.291456460952759,
      "logits/rejected": -3.4874820709228516,
      "logps/chosen": -84.81192016601562,
      "logps/rejected": -159.4016571044922,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2705676555633545,
      "rewards/margins": 9.242759704589844,
      "rewards/rejected": -6.97219181060791,
      "step": 3512
    },
    {
      "epoch": 1.4052,
      "grad_norm": 0.09226370602846146,
      "learning_rate": 5.317333333333332e-07,
      "logits/chosen": -2.7092409133911133,
      "logits/rejected": -3.1014037132263184,
      "logps/chosen": -182.17755126953125,
      "logps/rejected": -215.1410675048828,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3984971046447754,
      "rewards/margins": 9.973211288452148,
      "rewards/rejected": -8.574714660644531,
      "step": 3513
    },
    {
      "epoch": 1.4056,
      "grad_norm": 0.015002020634710789,
      "learning_rate": 5.315999999999999e-07,
      "logits/chosen": -1.7682881355285645,
      "logits/rejected": -3.507143259048462,
      "logps/chosen": -83.73682403564453,
      "logps/rejected": -159.98583984375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6937923431396484,
      "rewards/margins": 9.900876998901367,
      "rewards/rejected": -6.207084655761719,
      "step": 3514
    },
    {
      "epoch": 1.4060000000000001,
      "grad_norm": 0.2698279917240143,
      "learning_rate": 5.314666666666666e-07,
      "logits/chosen": -1.5784862041473389,
      "logits/rejected": -2.842622995376587,
      "logps/chosen": -101.8988037109375,
      "logps/rejected": -152.87400817871094,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5522785186767578,
      "rewards/margins": 7.10966682434082,
      "rewards/rejected": -5.5573883056640625,
      "step": 3515
    },
    {
      "epoch": 1.4064,
      "grad_norm": 1.3077272176742554,
      "learning_rate": 5.313333333333333e-07,
      "logits/chosen": -1.8379480838775635,
      "logits/rejected": -3.0716347694396973,
      "logps/chosen": -165.37490844726562,
      "logps/rejected": -153.4149169921875,
      "loss": 0.0094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2594619691371918,
      "rewards/margins": 6.385880470275879,
      "rewards/rejected": -6.645342826843262,
      "step": 3516
    },
    {
      "epoch": 1.4068,
      "grad_norm": 0.018734963610768318,
      "learning_rate": 5.312e-07,
      "logits/chosen": -2.170729637145996,
      "logits/rejected": -2.8754982948303223,
      "logps/chosen": -131.39569091796875,
      "logps/rejected": -226.65267944335938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9921460151672363,
      "rewards/margins": 9.793184280395508,
      "rewards/rejected": -6.801037788391113,
      "step": 3517
    },
    {
      "epoch": 1.4072,
      "grad_norm": 0.37102675437927246,
      "learning_rate": 5.310666666666667e-07,
      "logits/chosen": -1.8265199661254883,
      "logits/rejected": -2.8427417278289795,
      "logps/chosen": -102.00349426269531,
      "logps/rejected": -156.60963439941406,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4977184534072876,
      "rewards/margins": 7.989832878112793,
      "rewards/rejected": -6.492114067077637,
      "step": 3518
    },
    {
      "epoch": 1.4076,
      "grad_norm": 0.18741723895072937,
      "learning_rate": 5.309333333333334e-07,
      "logits/chosen": -1.7115432024002075,
      "logits/rejected": -2.7198753356933594,
      "logps/chosen": -71.41377258300781,
      "logps/rejected": -135.7890625,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2964541912078857,
      "rewards/margins": 7.878140926361084,
      "rewards/rejected": -5.581686496734619,
      "step": 3519
    },
    {
      "epoch": 1.408,
      "grad_norm": 0.07031948864459991,
      "learning_rate": 5.308000000000001e-07,
      "logits/chosen": -2.5526769161224365,
      "logits/rejected": -3.681669235229492,
      "logps/chosen": -173.7128448486328,
      "logps/rejected": -171.49095153808594,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.28727495670318604,
      "rewards/margins": 8.039615631103516,
      "rewards/rejected": -8.32689094543457,
      "step": 3520
    },
    {
      "epoch": 1.4083999999999999,
      "grad_norm": 0.01137070544064045,
      "learning_rate": 5.306666666666665e-07,
      "logits/chosen": -2.432135581970215,
      "logits/rejected": -3.4620089530944824,
      "logps/chosen": -110.38331604003906,
      "logps/rejected": -161.0764617919922,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8817105293273926,
      "rewards/margins": 9.714947700500488,
      "rewards/rejected": -5.833237171173096,
      "step": 3521
    },
    {
      "epoch": 1.4088,
      "grad_norm": 0.04079268500208855,
      "learning_rate": 5.305333333333332e-07,
      "logits/chosen": -1.8947359323501587,
      "logits/rejected": -3.0411388874053955,
      "logps/chosen": -109.90542602539062,
      "logps/rejected": -194.28506469726562,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.726062297821045,
      "rewards/margins": 9.649984359741211,
      "rewards/rejected": -5.923922538757324,
      "step": 3522
    },
    {
      "epoch": 1.4092,
      "grad_norm": 0.08476394414901733,
      "learning_rate": 5.303999999999999e-07,
      "logits/chosen": -2.6025948524475098,
      "logits/rejected": -4.010771751403809,
      "logps/chosen": -209.25454711914062,
      "logps/rejected": -181.51797485351562,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4197918176651,
      "rewards/margins": 9.073630332946777,
      "rewards/rejected": -7.653838157653809,
      "step": 3523
    },
    {
      "epoch": 1.4096,
      "grad_norm": 0.0036311738658696413,
      "learning_rate": 5.302666666666666e-07,
      "logits/chosen": -1.5772508382797241,
      "logits/rejected": -2.773036241531372,
      "logps/chosen": -129.93603515625,
      "logps/rejected": -193.00369262695312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.03263521194458,
      "rewards/margins": 10.709959030151367,
      "rewards/rejected": -8.677323341369629,
      "step": 3524
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.0057275909930467606,
      "learning_rate": 5.301333333333333e-07,
      "logits/chosen": -2.4535017013549805,
      "logits/rejected": -3.344900608062744,
      "logps/chosen": -181.1474609375,
      "logps/rejected": -191.77944946289062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3562748432159424,
      "rewards/margins": 11.117326736450195,
      "rewards/rejected": -8.761052131652832,
      "step": 3525
    },
    {
      "epoch": 1.4104,
      "grad_norm": 0.02505858615040779,
      "learning_rate": 5.3e-07,
      "logits/chosen": -2.2179718017578125,
      "logits/rejected": -3.679412603378296,
      "logps/chosen": -109.93900299072266,
      "logps/rejected": -192.7008514404297,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.153458595275879,
      "rewards/margins": 10.32275390625,
      "rewards/rejected": -7.169295310974121,
      "step": 3526
    },
    {
      "epoch": 1.4108,
      "grad_norm": 0.02479538880288601,
      "learning_rate": 5.298666666666667e-07,
      "logits/chosen": -1.4228646755218506,
      "logits/rejected": -2.5300114154815674,
      "logps/chosen": -140.9107666015625,
      "logps/rejected": -141.4127655029297,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.037595748901367,
      "rewards/margins": 9.718193054199219,
      "rewards/rejected": -5.68059778213501,
      "step": 3527
    },
    {
      "epoch": 1.4112,
      "grad_norm": 6.4593825340271,
      "learning_rate": 5.297333333333333e-07,
      "logits/chosen": -2.7006990909576416,
      "logits/rejected": -2.9914662837982178,
      "logps/chosen": -149.49354553222656,
      "logps/rejected": -152.21006774902344,
      "loss": 0.0801,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1366729736328125,
      "rewards/margins": 6.556314468383789,
      "rewards/rejected": -6.419641494750977,
      "step": 3528
    },
    {
      "epoch": 1.4116,
      "grad_norm": 0.006300707813352346,
      "learning_rate": 5.296e-07,
      "logits/chosen": -1.4940900802612305,
      "logits/rejected": -3.2671737670898438,
      "logps/chosen": -150.35501098632812,
      "logps/rejected": -176.2843780517578,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6116156578063965,
      "rewards/margins": 10.928556442260742,
      "rewards/rejected": -7.316941738128662,
      "step": 3529
    },
    {
      "epoch": 1.412,
      "grad_norm": 0.10920002311468124,
      "learning_rate": 5.294666666666667e-07,
      "logits/chosen": -2.1814491748809814,
      "logits/rejected": -3.2452569007873535,
      "logps/chosen": -146.12403869628906,
      "logps/rejected": -181.33880615234375,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.501090943813324,
      "rewards/margins": 7.840705871582031,
      "rewards/rejected": -8.341796875,
      "step": 3530
    },
    {
      "epoch": 1.4123999999999999,
      "grad_norm": 0.09639398008584976,
      "learning_rate": 5.293333333333333e-07,
      "logits/chosen": -2.540457248687744,
      "logits/rejected": -3.2598094940185547,
      "logps/chosen": -104.47967529296875,
      "logps/rejected": -166.0748291015625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8262290954589844,
      "rewards/margins": 8.670417785644531,
      "rewards/rejected": -6.844188690185547,
      "step": 3531
    },
    {
      "epoch": 1.4128,
      "grad_norm": 0.4760083854198456,
      "learning_rate": 5.292e-07,
      "logits/chosen": -1.684788703918457,
      "logits/rejected": -3.1964426040649414,
      "logps/chosen": -140.91769409179688,
      "logps/rejected": -204.00021362304688,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2310872077941895,
      "rewards/margins": 7.738704204559326,
      "rewards/rejected": -5.507616996765137,
      "step": 3532
    },
    {
      "epoch": 1.4132,
      "grad_norm": 2.880875825881958,
      "learning_rate": 5.290666666666666e-07,
      "logits/chosen": -3.205592632293701,
      "logits/rejected": -2.6884899139404297,
      "logps/chosen": -126.7641372680664,
      "logps/rejected": -165.92654418945312,
      "loss": 0.0229,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.31338006258010864,
      "rewards/margins": 6.42391300201416,
      "rewards/rejected": -6.737293243408203,
      "step": 3533
    },
    {
      "epoch": 1.4136,
      "grad_norm": 0.004883318208158016,
      "learning_rate": 5.289333333333333e-07,
      "logits/chosen": -1.9474589824676514,
      "logits/rejected": -2.7608635425567627,
      "logps/chosen": -95.1297607421875,
      "logps/rejected": -147.14056396484375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8203024864196777,
      "rewards/margins": 9.834365844726562,
      "rewards/rejected": -6.014062881469727,
      "step": 3534
    },
    {
      "epoch": 1.414,
      "grad_norm": 0.027137011289596558,
      "learning_rate": 5.288e-07,
      "logits/chosen": -2.157370090484619,
      "logits/rejected": -2.8826990127563477,
      "logps/chosen": -170.2803497314453,
      "logps/rejected": -184.7006072998047,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.960127353668213,
      "rewards/margins": 10.599918365478516,
      "rewards/rejected": -7.639791488647461,
      "step": 3535
    },
    {
      "epoch": 1.4144,
      "grad_norm": 0.03598792478442192,
      "learning_rate": 5.286666666666666e-07,
      "logits/chosen": -2.072704553604126,
      "logits/rejected": -3.5668020248413086,
      "logps/chosen": -131.35357666015625,
      "logps/rejected": -180.66859436035156,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1001689434051514,
      "rewards/margins": 8.546037673950195,
      "rewards/rejected": -7.445868968963623,
      "step": 3536
    },
    {
      "epoch": 1.4148,
      "grad_norm": 0.0330297127366066,
      "learning_rate": 5.285333333333333e-07,
      "logits/chosen": -2.40439510345459,
      "logits/rejected": -3.502894401550293,
      "logps/chosen": -234.89930725097656,
      "logps/rejected": -178.59933471679688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3151543140411377,
      "rewards/margins": 9.78465461730957,
      "rewards/rejected": -7.469500541687012,
      "step": 3537
    },
    {
      "epoch": 1.4152,
      "grad_norm": 0.0074259620159864426,
      "learning_rate": 5.284e-07,
      "logits/chosen": -2.1602892875671387,
      "logits/rejected": -3.5179250240325928,
      "logps/chosen": -162.5535430908203,
      "logps/rejected": -274.44140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.101346254348755,
      "rewards/margins": 11.732403755187988,
      "rewards/rejected": -8.631057739257812,
      "step": 3538
    },
    {
      "epoch": 1.4156,
      "grad_norm": 0.16054414212703705,
      "learning_rate": 5.282666666666667e-07,
      "logits/chosen": -1.86027193069458,
      "logits/rejected": -3.3903918266296387,
      "logps/chosen": -138.30389404296875,
      "logps/rejected": -190.3087921142578,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.05480766296386719,
      "rewards/margins": 8.139293670654297,
      "rewards/rejected": -8.194100379943848,
      "step": 3539
    },
    {
      "epoch": 1.416,
      "grad_norm": 0.009522869251668453,
      "learning_rate": 5.281333333333333e-07,
      "logits/chosen": -1.9832338094711304,
      "logits/rejected": -3.9012653827667236,
      "logps/chosen": -125.35200500488281,
      "logps/rejected": -200.6091766357422,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7405388355255127,
      "rewards/margins": 10.645744323730469,
      "rewards/rejected": -8.905205726623535,
      "step": 3540
    },
    {
      "epoch": 1.4163999999999999,
      "grad_norm": 0.7268916964530945,
      "learning_rate": 5.28e-07,
      "logits/chosen": -2.2348506450653076,
      "logits/rejected": -3.19909930229187,
      "logps/chosen": -108.08419036865234,
      "logps/rejected": -143.24493408203125,
      "loss": 0.0075,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9397922158241272,
      "rewards/margins": 7.168713569641113,
      "rewards/rejected": -6.228920936584473,
      "step": 3541
    },
    {
      "epoch": 1.4168,
      "grad_norm": 0.13069391250610352,
      "learning_rate": 5.278666666666667e-07,
      "logits/chosen": -2.6534605026245117,
      "logits/rejected": -3.028970241546631,
      "logps/chosen": -191.53773498535156,
      "logps/rejected": -205.50140380859375,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5709701776504517,
      "rewards/margins": 8.400918960571289,
      "rewards/rejected": -7.829948425292969,
      "step": 3542
    },
    {
      "epoch": 1.4172,
      "grad_norm": 3.724768877029419,
      "learning_rate": 5.277333333333333e-07,
      "logits/chosen": -2.850839614868164,
      "logits/rejected": -3.1086268424987793,
      "logps/chosen": -178.30230712890625,
      "logps/rejected": -168.62554931640625,
      "loss": 0.0275,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1235984563827515,
      "rewards/margins": 8.391984939575195,
      "rewards/rejected": -7.2683868408203125,
      "step": 3543
    },
    {
      "epoch": 1.4176,
      "grad_norm": 0.0018282688688486814,
      "learning_rate": 5.275999999999999e-07,
      "logits/chosen": -1.855616569519043,
      "logits/rejected": -3.7973852157592773,
      "logps/chosen": -74.62855529785156,
      "logps/rejected": -184.93331909179688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.986321449279785,
      "rewards/margins": 11.144706726074219,
      "rewards/rejected": -8.15838623046875,
      "step": 3544
    },
    {
      "epoch": 1.418,
      "grad_norm": 0.03245028853416443,
      "learning_rate": 5.274666666666666e-07,
      "logits/chosen": -2.336210250854492,
      "logits/rejected": -3.538264751434326,
      "logps/chosen": -109.19070434570312,
      "logps/rejected": -175.22842407226562,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9240453243255615,
      "rewards/margins": 9.737003326416016,
      "rewards/rejected": -7.812957763671875,
      "step": 3545
    },
    {
      "epoch": 1.4184,
      "grad_norm": 0.054678257554769516,
      "learning_rate": 5.273333333333333e-07,
      "logits/chosen": -2.6762492656707764,
      "logits/rejected": -3.276108503341675,
      "logps/chosen": -132.53353881835938,
      "logps/rejected": -205.68145751953125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.62416672706604,
      "rewards/margins": 10.257190704345703,
      "rewards/rejected": -7.633023262023926,
      "step": 3546
    },
    {
      "epoch": 1.4188,
      "grad_norm": 0.03881364315748215,
      "learning_rate": 5.272e-07,
      "logits/chosen": -2.3199987411499023,
      "logits/rejected": -3.491647720336914,
      "logps/chosen": -109.25526428222656,
      "logps/rejected": -207.4986572265625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9234918355941772,
      "rewards/margins": 10.662616729736328,
      "rewards/rejected": -8.739126205444336,
      "step": 3547
    },
    {
      "epoch": 1.4192,
      "grad_norm": 0.005778722930699587,
      "learning_rate": 5.270666666666667e-07,
      "logits/chosen": -2.4587693214416504,
      "logits/rejected": -3.5759968757629395,
      "logps/chosen": -182.1366729736328,
      "logps/rejected": -327.1719970703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5499985218048096,
      "rewards/margins": 10.549911499023438,
      "rewards/rejected": -7.999913215637207,
      "step": 3548
    },
    {
      "epoch": 1.4196,
      "grad_norm": 0.09714579582214355,
      "learning_rate": 5.269333333333334e-07,
      "logits/chosen": -1.9526175260543823,
      "logits/rejected": -2.8164424896240234,
      "logps/chosen": -178.48348999023438,
      "logps/rejected": -170.60623168945312,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6473278403282166,
      "rewards/margins": 7.346254348754883,
      "rewards/rejected": -6.69892692565918,
      "step": 3549
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.0011713821440935135,
      "learning_rate": 5.268e-07,
      "logits/chosen": -2.2008485794067383,
      "logits/rejected": -3.165311336517334,
      "logps/chosen": -148.71826171875,
      "logps/rejected": -185.68922424316406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7770090103149414,
      "rewards/margins": 12.116279602050781,
      "rewards/rejected": -8.339269638061523,
      "step": 3550
    },
    {
      "epoch": 1.4203999999999999,
      "grad_norm": 0.036831244826316833,
      "learning_rate": 5.266666666666666e-07,
      "logits/chosen": -1.991811752319336,
      "logits/rejected": -3.7037625312805176,
      "logps/chosen": -64.70732116699219,
      "logps/rejected": -174.73171997070312,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2109851837158203,
      "rewards/margins": 9.417689323425293,
      "rewards/rejected": -6.206704139709473,
      "step": 3551
    },
    {
      "epoch": 1.4208,
      "grad_norm": 0.0001597100927028805,
      "learning_rate": 5.265333333333333e-07,
      "logits/chosen": -2.2478532791137695,
      "logits/rejected": -3.335235118865967,
      "logps/chosen": -147.7405242919922,
      "logps/rejected": -257.2965087890625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.289811611175537,
      "rewards/margins": 13.752664566040039,
      "rewards/rejected": -9.462852478027344,
      "step": 3552
    },
    {
      "epoch": 1.4212,
      "grad_norm": 0.009529042057693005,
      "learning_rate": 5.264e-07,
      "logits/chosen": -1.925419569015503,
      "logits/rejected": -3.354395627975464,
      "logps/chosen": -79.68827819824219,
      "logps/rejected": -153.7674102783203,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.563016414642334,
      "rewards/margins": 9.30307388305664,
      "rewards/rejected": -6.740056991577148,
      "step": 3553
    },
    {
      "epoch": 1.4216,
      "grad_norm": 0.0031611176673322916,
      "learning_rate": 5.262666666666666e-07,
      "logits/chosen": -1.551544427871704,
      "logits/rejected": -3.2816944122314453,
      "logps/chosen": -121.35638427734375,
      "logps/rejected": -222.63919067382812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3268115520477295,
      "rewards/margins": 11.37983512878418,
      "rewards/rejected": -9.053023338317871,
      "step": 3554
    },
    {
      "epoch": 1.422,
      "grad_norm": 0.003008665284141898,
      "learning_rate": 5.261333333333333e-07,
      "logits/chosen": -2.270040988922119,
      "logits/rejected": -3.040247917175293,
      "logps/chosen": -115.7260513305664,
      "logps/rejected": -163.6707763671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.495462894439697,
      "rewards/margins": 10.596757888793945,
      "rewards/rejected": -6.101294040679932,
      "step": 3555
    },
    {
      "epoch": 1.4224,
      "grad_norm": 0.005244095344096422,
      "learning_rate": 5.26e-07,
      "logits/chosen": -1.676267385482788,
      "logits/rejected": -3.195155143737793,
      "logps/chosen": -149.9549102783203,
      "logps/rejected": -295.5054931640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.058403968811035,
      "rewards/margins": 12.514918327331543,
      "rewards/rejected": -8.456514358520508,
      "step": 3556
    },
    {
      "epoch": 1.4228,
      "grad_norm": 0.058216992765665054,
      "learning_rate": 5.258666666666667e-07,
      "logits/chosen": -2.606630325317383,
      "logits/rejected": -3.467487096786499,
      "logps/chosen": -112.76817321777344,
      "logps/rejected": -164.9859161376953,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.46005403995513916,
      "rewards/margins": 8.698383331298828,
      "rewards/rejected": -8.23832893371582,
      "step": 3557
    },
    {
      "epoch": 1.4232,
      "grad_norm": 0.0013300749706104398,
      "learning_rate": 5.257333333333334e-07,
      "logits/chosen": -2.06892991065979,
      "logits/rejected": -3.3935348987579346,
      "logps/chosen": -92.63470458984375,
      "logps/rejected": -189.18150329589844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.79134464263916,
      "rewards/margins": 11.852861404418945,
      "rewards/rejected": -7.061516761779785,
      "step": 3558
    },
    {
      "epoch": 1.4236,
      "grad_norm": 0.1979421079158783,
      "learning_rate": 5.255999999999999e-07,
      "logits/chosen": -1.7725805044174194,
      "logits/rejected": -3.269831657409668,
      "logps/chosen": -96.98714447021484,
      "logps/rejected": -185.52584838867188,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6714526414871216,
      "rewards/margins": 8.473066329956055,
      "rewards/rejected": -7.801613807678223,
      "step": 3559
    },
    {
      "epoch": 1.424,
      "grad_norm": 0.0009149375837296247,
      "learning_rate": 5.254666666666666e-07,
      "logits/chosen": -2.4930949211120605,
      "logits/rejected": -3.813587188720703,
      "logps/chosen": -107.38578796386719,
      "logps/rejected": -204.0548095703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.165604829788208,
      "rewards/margins": 11.9346923828125,
      "rewards/rejected": -9.769087791442871,
      "step": 3560
    },
    {
      "epoch": 1.4243999999999999,
      "grad_norm": 0.9624793529510498,
      "learning_rate": 5.253333333333333e-07,
      "logits/chosen": -2.6631529331207275,
      "logits/rejected": -3.524905204772949,
      "logps/chosen": -178.03134155273438,
      "logps/rejected": -186.16566467285156,
      "loss": 0.0089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.202002763748169,
      "rewards/margins": 6.193962097167969,
      "rewards/rejected": -4.991959571838379,
      "step": 3561
    },
    {
      "epoch": 1.4248,
      "grad_norm": 0.008901337161660194,
      "learning_rate": 5.252e-07,
      "logits/chosen": -2.614112377166748,
      "logits/rejected": -3.1571314334869385,
      "logps/chosen": -173.50698852539062,
      "logps/rejected": -244.256103515625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.137056827545166,
      "rewards/margins": 11.661149024963379,
      "rewards/rejected": -8.524091720581055,
      "step": 3562
    },
    {
      "epoch": 1.4252,
      "grad_norm": 0.023822952061891556,
      "learning_rate": 5.250666666666667e-07,
      "logits/chosen": -1.8471462726593018,
      "logits/rejected": -2.6866955757141113,
      "logps/chosen": -66.37310028076172,
      "logps/rejected": -174.510009765625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5222344398498535,
      "rewards/margins": 8.59048080444336,
      "rewards/rejected": -5.068245887756348,
      "step": 3563
    },
    {
      "epoch": 1.4256,
      "grad_norm": 0.006195071153342724,
      "learning_rate": 5.249333333333333e-07,
      "logits/chosen": -1.9867873191833496,
      "logits/rejected": -3.2476706504821777,
      "logps/chosen": -119.3958511352539,
      "logps/rejected": -202.94635009765625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.328234910964966,
      "rewards/margins": 11.065054893493652,
      "rewards/rejected": -7.736819267272949,
      "step": 3564
    },
    {
      "epoch": 1.426,
      "grad_norm": 0.029468653723597527,
      "learning_rate": 5.248e-07,
      "logits/chosen": -2.1691408157348633,
      "logits/rejected": -3.4719817638397217,
      "logps/chosen": -106.45539855957031,
      "logps/rejected": -184.5440673828125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.470386028289795,
      "rewards/margins": 9.56911849975586,
      "rewards/rejected": -7.0987324714660645,
      "step": 3565
    },
    {
      "epoch": 1.4264000000000001,
      "grad_norm": 0.07711124420166016,
      "learning_rate": 5.246666666666666e-07,
      "logits/chosen": -2.332057237625122,
      "logits/rejected": -2.851059675216675,
      "logps/chosen": -122.65603637695312,
      "logps/rejected": -173.8916015625,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9794368743896484,
      "rewards/margins": 8.850225448608398,
      "rewards/rejected": -7.870788097381592,
      "step": 3566
    },
    {
      "epoch": 1.4268,
      "grad_norm": 0.030565986409783363,
      "learning_rate": 5.245333333333333e-07,
      "logits/chosen": -1.756653070449829,
      "logits/rejected": -3.5306804180145264,
      "logps/chosen": -96.93963623046875,
      "logps/rejected": -170.75234985351562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6110451221466064,
      "rewards/margins": 10.566995620727539,
      "rewards/rejected": -8.955950736999512,
      "step": 3567
    },
    {
      "epoch": 1.4272,
      "grad_norm": 0.7220338582992554,
      "learning_rate": 5.243999999999999e-07,
      "logits/chosen": -2.244443893432617,
      "logits/rejected": -2.7827513217926025,
      "logps/chosen": -216.1092529296875,
      "logps/rejected": -204.72427368164062,
      "loss": 0.0075,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40810853242874146,
      "rewards/margins": 5.3978471755981445,
      "rewards/rejected": -4.989738464355469,
      "step": 3568
    },
    {
      "epoch": 1.4276,
      "grad_norm": 0.6188711524009705,
      "learning_rate": 5.242666666666666e-07,
      "logits/chosen": -1.6591179370880127,
      "logits/rejected": -3.6905007362365723,
      "logps/chosen": -167.24752807617188,
      "logps/rejected": -178.17007446289062,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1286163330078125,
      "rewards/margins": 9.127700805664062,
      "rewards/rejected": -8.999085426330566,
      "step": 3569
    },
    {
      "epoch": 1.428,
      "grad_norm": 0.03027377277612686,
      "learning_rate": 5.241333333333333e-07,
      "logits/chosen": -2.096160411834717,
      "logits/rejected": -3.4548914432525635,
      "logps/chosen": -141.6936492919922,
      "logps/rejected": -181.9282989501953,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8964176177978516,
      "rewards/margins": 8.641291618347168,
      "rewards/rejected": -7.744874000549316,
      "step": 3570
    },
    {
      "epoch": 1.4284,
      "grad_norm": 0.00022856610303279012,
      "learning_rate": 5.24e-07,
      "logits/chosen": -2.1139774322509766,
      "logits/rejected": -3.4165048599243164,
      "logps/chosen": -135.86727905273438,
      "logps/rejected": -225.5869903564453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7385623455047607,
      "rewards/margins": 13.483264923095703,
      "rewards/rejected": -10.744702339172363,
      "step": 3571
    },
    {
      "epoch": 1.4288,
      "grad_norm": 0.0032920166850090027,
      "learning_rate": 5.238666666666667e-07,
      "logits/chosen": -2.276808738708496,
      "logits/rejected": -3.401679039001465,
      "logps/chosen": -183.4066162109375,
      "logps/rejected": -213.56825256347656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.496852159500122,
      "rewards/margins": 11.234314918518066,
      "rewards/rejected": -8.737462997436523,
      "step": 3572
    },
    {
      "epoch": 1.4292,
      "grad_norm": 0.006278539542108774,
      "learning_rate": 5.237333333333334e-07,
      "logits/chosen": -2.1008684635162354,
      "logits/rejected": -3.602785110473633,
      "logps/chosen": -92.41758728027344,
      "logps/rejected": -177.48287963867188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7512009143829346,
      "rewards/margins": 9.540792465209961,
      "rewards/rejected": -7.789590835571289,
      "step": 3573
    },
    {
      "epoch": 1.4296,
      "grad_norm": 0.12387613952159882,
      "learning_rate": 5.236e-07,
      "logits/chosen": -2.184478759765625,
      "logits/rejected": -3.132701873779297,
      "logps/chosen": -152.08023071289062,
      "logps/rejected": -171.87234497070312,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.320439338684082,
      "rewards/margins": 8.998088836669922,
      "rewards/rejected": -6.677649974822998,
      "step": 3574
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.04248424619436264,
      "learning_rate": 5.234666666666666e-07,
      "logits/chosen": -1.6365439891815186,
      "logits/rejected": -3.189319610595703,
      "logps/chosen": -75.23890686035156,
      "logps/rejected": -156.90689086914062,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9743428230285645,
      "rewards/margins": 9.06462287902832,
      "rewards/rejected": -6.090279579162598,
      "step": 3575
    },
    {
      "epoch": 1.4304000000000001,
      "grad_norm": 0.06590937823057175,
      "learning_rate": 5.233333333333333e-07,
      "logits/chosen": -1.9048097133636475,
      "logits/rejected": -3.71681809425354,
      "logps/chosen": -94.81045532226562,
      "logps/rejected": -179.14024353027344,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.991826593875885,
      "rewards/margins": 9.470319747924805,
      "rewards/rejected": -8.478492736816406,
      "step": 3576
    },
    {
      "epoch": 1.4308,
      "grad_norm": 0.9343558549880981,
      "learning_rate": 5.232e-07,
      "logits/chosen": -1.9304068088531494,
      "logits/rejected": -3.6166670322418213,
      "logps/chosen": -139.99618530273438,
      "logps/rejected": -152.21572875976562,
      "loss": 0.0089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.045492172241211,
      "rewards/margins": 4.7893385887146,
      "rewards/rejected": -6.8348307609558105,
      "step": 3577
    },
    {
      "epoch": 1.4312,
      "grad_norm": 0.011977453716099262,
      "learning_rate": 5.230666666666666e-07,
      "logits/chosen": -2.0893702507019043,
      "logits/rejected": -3.503570079803467,
      "logps/chosen": -135.02371215820312,
      "logps/rejected": -181.49684143066406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5846152305603027,
      "rewards/margins": 10.433124542236328,
      "rewards/rejected": -7.848509788513184,
      "step": 3578
    },
    {
      "epoch": 1.4316,
      "grad_norm": 0.0023479163646698,
      "learning_rate": 5.229333333333333e-07,
      "logits/chosen": -2.2454137802124023,
      "logits/rejected": -3.105194330215454,
      "logps/chosen": -116.30923461914062,
      "logps/rejected": -181.41253662109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.4132280349731445,
      "rewards/margins": 13.288949012756348,
      "rewards/rejected": -8.875720977783203,
      "step": 3579
    },
    {
      "epoch": 1.432,
      "grad_norm": 0.07328314334154129,
      "learning_rate": 5.228e-07,
      "logits/chosen": -2.526942729949951,
      "logits/rejected": -3.6116156578063965,
      "logps/chosen": -234.46322631835938,
      "logps/rejected": -203.91064453125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3778831362724304,
      "rewards/margins": 8.867432594299316,
      "rewards/rejected": -8.48954963684082,
      "step": 3580
    },
    {
      "epoch": 1.4324,
      "grad_norm": 0.0002923707652371377,
      "learning_rate": 5.226666666666666e-07,
      "logits/chosen": -1.8330059051513672,
      "logits/rejected": -3.281646251678467,
      "logps/chosen": -90.67445373535156,
      "logps/rejected": -212.36007690429688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.567257881164551,
      "rewards/margins": 13.403868675231934,
      "rewards/rejected": -9.836610794067383,
      "step": 3581
    },
    {
      "epoch": 1.4328,
      "grad_norm": 0.06392155587673187,
      "learning_rate": 5.225333333333333e-07,
      "logits/chosen": -1.650373935699463,
      "logits/rejected": -2.996206760406494,
      "logps/chosen": -121.10735321044922,
      "logps/rejected": -148.69015502929688,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.252815246582031,
      "rewards/margins": 8.900315284729004,
      "rewards/rejected": -4.647500038146973,
      "step": 3582
    },
    {
      "epoch": 1.4332,
      "grad_norm": 0.0013970695436000824,
      "learning_rate": 5.224e-07,
      "logits/chosen": -2.0035226345062256,
      "logits/rejected": -3.5004475116729736,
      "logps/chosen": -143.84268188476562,
      "logps/rejected": -192.04371643066406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0985329151153564,
      "rewards/margins": 11.610567092895508,
      "rewards/rejected": -8.512033462524414,
      "step": 3583
    },
    {
      "epoch": 1.4336,
      "grad_norm": 0.004637961275875568,
      "learning_rate": 5.222666666666667e-07,
      "logits/chosen": -1.9504766464233398,
      "logits/rejected": -3.3978512287139893,
      "logps/chosen": -187.5155029296875,
      "logps/rejected": -185.96310424804688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.367880344390869,
      "rewards/margins": 10.723737716674805,
      "rewards/rejected": -7.355856895446777,
      "step": 3584
    },
    {
      "epoch": 1.434,
      "grad_norm": 0.013539575971662998,
      "learning_rate": 5.221333333333334e-07,
      "logits/chosen": -2.2645914554595947,
      "logits/rejected": -3.107837200164795,
      "logps/chosen": -194.75625610351562,
      "logps/rejected": -284.6562194824219,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.235611081123352,
      "rewards/margins": 9.755426406860352,
      "rewards/rejected": -8.519815444946289,
      "step": 3585
    },
    {
      "epoch": 1.4344000000000001,
      "grad_norm": 0.09818150103092194,
      "learning_rate": 5.22e-07,
      "logits/chosen": -2.126176357269287,
      "logits/rejected": -3.2094950675964355,
      "logps/chosen": -151.00833129882812,
      "logps/rejected": -199.23858642578125,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1039183139801025,
      "rewards/margins": 9.454023361206055,
      "rewards/rejected": -7.350105285644531,
      "step": 3586
    },
    {
      "epoch": 1.4348,
      "grad_norm": 0.0006634632009081542,
      "learning_rate": 5.218666666666666e-07,
      "logits/chosen": -2.430443048477173,
      "logits/rejected": -3.432739734649658,
      "logps/chosen": -122.25767517089844,
      "logps/rejected": -237.8525390625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.453095436096191,
      "rewards/margins": 12.268594741821289,
      "rewards/rejected": -7.815499305725098,
      "step": 3587
    },
    {
      "epoch": 1.4352,
      "grad_norm": 0.001114225247874856,
      "learning_rate": 5.217333333333333e-07,
      "logits/chosen": -2.4031174182891846,
      "logits/rejected": -3.5241944789886475,
      "logps/chosen": -250.97418212890625,
      "logps/rejected": -232.32962036132812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9845619201660156,
      "rewards/margins": 11.803383827209473,
      "rewards/rejected": -7.818821907043457,
      "step": 3588
    },
    {
      "epoch": 1.4356,
      "grad_norm": 0.0941651239991188,
      "learning_rate": 5.215999999999999e-07,
      "logits/chosen": -2.153980255126953,
      "logits/rejected": -2.2450766563415527,
      "logps/chosen": -132.0086669921875,
      "logps/rejected": -180.2855987548828,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.513427734375,
      "rewards/margins": 7.990421772003174,
      "rewards/rejected": -6.476994037628174,
      "step": 3589
    },
    {
      "epoch": 1.436,
      "grad_norm": 0.07877587527036667,
      "learning_rate": 5.214666666666666e-07,
      "logits/chosen": -2.3931617736816406,
      "logits/rejected": -3.1746628284454346,
      "logps/chosen": -143.6610107421875,
      "logps/rejected": -140.95855712890625,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3623909950256348,
      "rewards/margins": 7.544079780578613,
      "rewards/rejected": -5.1816887855529785,
      "step": 3590
    },
    {
      "epoch": 1.4364,
      "grad_norm": 0.17652922868728638,
      "learning_rate": 5.213333333333333e-07,
      "logits/chosen": -3.306804656982422,
      "logits/rejected": -3.174790143966675,
      "logps/chosen": -226.90614318847656,
      "logps/rejected": -287.1290283203125,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8844985961914062,
      "rewards/margins": 7.6954426765441895,
      "rewards/rejected": -5.810944080352783,
      "step": 3591
    },
    {
      "epoch": 1.4368,
      "grad_norm": 0.2545560300350189,
      "learning_rate": 5.212e-07,
      "logits/chosen": -2.36336088180542,
      "logits/rejected": -3.423196792602539,
      "logps/chosen": -114.2479248046875,
      "logps/rejected": -244.764404296875,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.790659785270691,
      "rewards/margins": 9.083223342895508,
      "rewards/rejected": -7.292564392089844,
      "step": 3592
    },
    {
      "epoch": 1.4372,
      "grad_norm": 0.03717605769634247,
      "learning_rate": 5.210666666666667e-07,
      "logits/chosen": -1.9828686714172363,
      "logits/rejected": -3.5784826278686523,
      "logps/chosen": -126.60610961914062,
      "logps/rejected": -189.3717041015625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9400242567062378,
      "rewards/margins": 9.680295944213867,
      "rewards/rejected": -7.740272045135498,
      "step": 3593
    },
    {
      "epoch": 1.4376,
      "grad_norm": 0.0031599653884768486,
      "learning_rate": 5.209333333333334e-07,
      "logits/chosen": -2.243445873260498,
      "logits/rejected": -3.7337193489074707,
      "logps/chosen": -110.61459350585938,
      "logps/rejected": -193.09564208984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1633617877960205,
      "rewards/margins": 10.876806259155273,
      "rewards/rejected": -7.713444709777832,
      "step": 3594
    },
    {
      "epoch": 1.438,
      "grad_norm": 0.007942256517708302,
      "learning_rate": 5.208000000000001e-07,
      "logits/chosen": -2.5862622261047363,
      "logits/rejected": -2.9978368282318115,
      "logps/chosen": -107.42543029785156,
      "logps/rejected": -134.1920166015625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.688103199005127,
      "rewards/margins": 9.490243911743164,
      "rewards/rejected": -5.802141189575195,
      "step": 3595
    },
    {
      "epoch": 1.4384000000000001,
      "grad_norm": 0.03764498606324196,
      "learning_rate": 5.206666666666667e-07,
      "logits/chosen": -2.46425724029541,
      "logits/rejected": -3.5958542823791504,
      "logps/chosen": -172.2587890625,
      "logps/rejected": -150.72427368164062,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.10725736618042,
      "rewards/margins": 7.937868595123291,
      "rewards/rejected": -5.830611228942871,
      "step": 3596
    },
    {
      "epoch": 1.4388,
      "grad_norm": 0.053358811885118484,
      "learning_rate": 5.205333333333332e-07,
      "logits/chosen": -2.2791857719421387,
      "logits/rejected": -3.0792789459228516,
      "logps/chosen": -193.63665771484375,
      "logps/rejected": -190.0773468017578,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6776092648506165,
      "rewards/margins": 9.022843360900879,
      "rewards/rejected": -8.345233917236328,
      "step": 3597
    },
    {
      "epoch": 1.4392,
      "grad_norm": 0.011628890410065651,
      "learning_rate": 5.203999999999999e-07,
      "logits/chosen": -1.6705291271209717,
      "logits/rejected": -2.8882694244384766,
      "logps/chosen": -122.15540313720703,
      "logps/rejected": -153.8856201171875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2821985483169556,
      "rewards/margins": 8.954310417175293,
      "rewards/rejected": -7.672111511230469,
      "step": 3598
    },
    {
      "epoch": 1.4396,
      "grad_norm": 0.5244653820991516,
      "learning_rate": 5.202666666666666e-07,
      "logits/chosen": -2.030111312866211,
      "logits/rejected": -2.9549944400787354,
      "logps/chosen": -139.013427734375,
      "logps/rejected": -181.83517456054688,
      "loss": 0.0051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5288673639297485,
      "rewards/margins": 7.894640922546387,
      "rewards/rejected": -8.423508644104004,
      "step": 3599
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.005269432906061411,
      "learning_rate": 5.201333333333333e-07,
      "logits/chosen": -2.1798181533813477,
      "logits/rejected": -3.107454299926758,
      "logps/chosen": -138.78480529785156,
      "logps/rejected": -170.2283477783203,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2319083213806152,
      "rewards/margins": 10.228546142578125,
      "rewards/rejected": -6.996637344360352,
      "step": 3600
    },
    {
      "epoch": 1.4404,
      "grad_norm": 0.01157105341553688,
      "learning_rate": 5.2e-07,
      "logits/chosen": -2.2421226501464844,
      "logits/rejected": -3.5113120079040527,
      "logps/chosen": -115.57891845703125,
      "logps/rejected": -158.6717529296875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3485844135284424,
      "rewards/margins": 9.203435897827148,
      "rewards/rejected": -7.854852199554443,
      "step": 3601
    },
    {
      "epoch": 1.4408,
      "grad_norm": 0.0034638301003724337,
      "learning_rate": 5.198666666666667e-07,
      "logits/chosen": -2.3336756229400635,
      "logits/rejected": -2.8358349800109863,
      "logps/chosen": -98.25981903076172,
      "logps/rejected": -181.12551879882812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4715473651885986,
      "rewards/margins": 10.767167091369629,
      "rewards/rejected": -7.295619964599609,
      "step": 3602
    },
    {
      "epoch": 1.4412,
      "grad_norm": 0.036762163043022156,
      "learning_rate": 5.197333333333334e-07,
      "logits/chosen": -2.1411194801330566,
      "logits/rejected": -3.3518409729003906,
      "logps/chosen": -149.6245880126953,
      "logps/rejected": -186.91055297851562,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9124069213867188,
      "rewards/margins": 9.016737937927246,
      "rewards/rejected": -7.104331016540527,
      "step": 3603
    },
    {
      "epoch": 1.4416,
      "grad_norm": 0.04726612940430641,
      "learning_rate": 5.196e-07,
      "logits/chosen": -2.384795665740967,
      "logits/rejected": -3.152712821960449,
      "logps/chosen": -160.62205505371094,
      "logps/rejected": -165.05343627929688,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2268319129943848,
      "rewards/margins": 7.595309257507324,
      "rewards/rejected": -6.368477821350098,
      "step": 3604
    },
    {
      "epoch": 1.442,
      "grad_norm": 0.24766291677951813,
      "learning_rate": 5.194666666666667e-07,
      "logits/chosen": -2.4506311416625977,
      "logits/rejected": -3.0698800086975098,
      "logps/chosen": -109.06387329101562,
      "logps/rejected": -182.19509887695312,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8927662372589111,
      "rewards/margins": 6.348696231842041,
      "rewards/rejected": -5.455929756164551,
      "step": 3605
    },
    {
      "epoch": 1.4424000000000001,
      "grad_norm": 0.019336851313710213,
      "learning_rate": 5.193333333333332e-07,
      "logits/chosen": -2.0787510871887207,
      "logits/rejected": -3.5336365699768066,
      "logps/chosen": -108.15638732910156,
      "logps/rejected": -167.5221710205078,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.665250062942505,
      "rewards/margins": 10.030570030212402,
      "rewards/rejected": -7.365320205688477,
      "step": 3606
    },
    {
      "epoch": 1.4428,
      "grad_norm": 0.0006428712513297796,
      "learning_rate": 5.191999999999999e-07,
      "logits/chosen": -1.8848011493682861,
      "logits/rejected": -3.5464205741882324,
      "logps/chosen": -186.19244384765625,
      "logps/rejected": -198.18258666992188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.24882698059082,
      "rewards/margins": 13.040781021118164,
      "rewards/rejected": -8.791954040527344,
      "step": 3607
    },
    {
      "epoch": 1.4432,
      "grad_norm": 0.014554690569639206,
      "learning_rate": 5.190666666666666e-07,
      "logits/chosen": -2.348489284515381,
      "logits/rejected": -3.344059467315674,
      "logps/chosen": -159.05709838867188,
      "logps/rejected": -184.17633056640625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2714624404907227,
      "rewards/margins": 9.785520553588867,
      "rewards/rejected": -7.5140581130981445,
      "step": 3608
    },
    {
      "epoch": 1.4436,
      "grad_norm": 0.6496952772140503,
      "learning_rate": 5.189333333333333e-07,
      "logits/chosen": -2.2893424034118652,
      "logits/rejected": -2.9527831077575684,
      "logps/chosen": -129.12655639648438,
      "logps/rejected": -152.54379272460938,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7098076343536377,
      "rewards/margins": 8.050304412841797,
      "rewards/rejected": -6.340497016906738,
      "step": 3609
    },
    {
      "epoch": 1.444,
      "grad_norm": 0.32407891750335693,
      "learning_rate": 5.188e-07,
      "logits/chosen": -1.903181791305542,
      "logits/rejected": -3.2549731731414795,
      "logps/chosen": -118.41707611083984,
      "logps/rejected": -168.19424438476562,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7096834182739258,
      "rewards/margins": 9.925820350646973,
      "rewards/rejected": -8.216136932373047,
      "step": 3610
    },
    {
      "epoch": 1.4444,
      "grad_norm": 0.0018700845539569855,
      "learning_rate": 5.186666666666667e-07,
      "logits/chosen": -2.3368337154388428,
      "logits/rejected": -3.282866954803467,
      "logps/chosen": -149.0604248046875,
      "logps/rejected": -197.71168518066406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.036350965499878,
      "rewards/margins": 11.32442855834961,
      "rewards/rejected": -8.288077354431152,
      "step": 3611
    },
    {
      "epoch": 1.4447999999999999,
      "grad_norm": 0.05958704650402069,
      "learning_rate": 5.185333333333333e-07,
      "logits/chosen": -2.1179206371307373,
      "logits/rejected": -3.7277917861938477,
      "logps/chosen": -93.90005493164062,
      "logps/rejected": -203.65362548828125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5967715978622437,
      "rewards/margins": 9.847296714782715,
      "rewards/rejected": -8.25052547454834,
      "step": 3612
    },
    {
      "epoch": 1.4452,
      "grad_norm": 0.11579858511686325,
      "learning_rate": 5.184e-07,
      "logits/chosen": -2.5967798233032227,
      "logits/rejected": -4.010653495788574,
      "logps/chosen": -92.06253051757812,
      "logps/rejected": -185.57203674316406,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.07409821450710297,
      "rewards/margins": 7.5190887451171875,
      "rewards/rejected": -7.59318733215332,
      "step": 3613
    },
    {
      "epoch": 1.4456,
      "grad_norm": 0.005843902472406626,
      "learning_rate": 5.182666666666667e-07,
      "logits/chosen": -2.0215940475463867,
      "logits/rejected": -3.158970355987549,
      "logps/chosen": -110.99702453613281,
      "logps/rejected": -226.410400390625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7486090660095215,
      "rewards/margins": 12.438786506652832,
      "rewards/rejected": -9.690177917480469,
      "step": 3614
    },
    {
      "epoch": 1.446,
      "grad_norm": 0.19637614488601685,
      "learning_rate": 5.181333333333333e-07,
      "logits/chosen": -1.6957314014434814,
      "logits/rejected": -3.300863265991211,
      "logps/chosen": -115.34110260009766,
      "logps/rejected": -168.4835205078125,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7357872128486633,
      "rewards/margins": 8.5144681930542,
      "rewards/rejected": -7.778680801391602,
      "step": 3615
    },
    {
      "epoch": 1.4464000000000001,
      "grad_norm": 0.10538386553525925,
      "learning_rate": 5.18e-07,
      "logits/chosen": -2.1751768589019775,
      "logits/rejected": -3.3792967796325684,
      "logps/chosen": -143.71981811523438,
      "logps/rejected": -153.47509765625,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8498783111572266,
      "rewards/margins": 7.200278282165527,
      "rewards/rejected": -6.350399971008301,
      "step": 3616
    },
    {
      "epoch": 1.4468,
      "grad_norm": 0.0009850579081103206,
      "learning_rate": 5.178666666666666e-07,
      "logits/chosen": -2.140984296798706,
      "logits/rejected": -3.155235767364502,
      "logps/chosen": -123.21251678466797,
      "logps/rejected": -191.2457733154297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.386744976043701,
      "rewards/margins": 12.089027404785156,
      "rewards/rejected": -7.702282428741455,
      "step": 3617
    },
    {
      "epoch": 1.4472,
      "grad_norm": 6.391268107108772e-05,
      "learning_rate": 5.177333333333333e-07,
      "logits/chosen": -2.3254246711730957,
      "logits/rejected": -3.312955856323242,
      "logps/chosen": -110.77374267578125,
      "logps/rejected": -294.4056396484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.4667887687683105,
      "rewards/margins": 15.023698806762695,
      "rewards/rejected": -10.556910514831543,
      "step": 3618
    },
    {
      "epoch": 1.4476,
      "grad_norm": 0.0011872340692207217,
      "learning_rate": 5.175999999999999e-07,
      "logits/chosen": -2.104985475540161,
      "logits/rejected": -3.2521252632141113,
      "logps/chosen": -93.06942749023438,
      "logps/rejected": -188.8018798828125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.553252935409546,
      "rewards/margins": 11.691971778869629,
      "rewards/rejected": -9.138718605041504,
      "step": 3619
    },
    {
      "epoch": 1.448,
      "grad_norm": 0.016631707549095154,
      "learning_rate": 5.174666666666666e-07,
      "logits/chosen": -2.3859074115753174,
      "logits/rejected": -2.9012880325317383,
      "logps/chosen": -154.79598999023438,
      "logps/rejected": -175.15005493164062,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.115616798400879,
      "rewards/margins": 9.592903137207031,
      "rewards/rejected": -7.477287292480469,
      "step": 3620
    },
    {
      "epoch": 1.4484,
      "grad_norm": 0.08511574566364288,
      "learning_rate": 5.173333333333333e-07,
      "logits/chosen": -2.420609951019287,
      "logits/rejected": -2.8690860271453857,
      "logps/chosen": -167.45326232910156,
      "logps/rejected": -174.72000122070312,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8821473121643066,
      "rewards/margins": 8.95106315612793,
      "rewards/rejected": -7.068915367126465,
      "step": 3621
    },
    {
      "epoch": 1.4487999999999999,
      "grad_norm": 0.05624448135495186,
      "learning_rate": 5.172e-07,
      "logits/chosen": -1.989635944366455,
      "logits/rejected": -3.279116630554199,
      "logps/chosen": -93.03290557861328,
      "logps/rejected": -152.79522705078125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8043845891952515,
      "rewards/margins": 8.106720924377441,
      "rewards/rejected": -6.3023362159729,
      "step": 3622
    },
    {
      "epoch": 1.4492,
      "grad_norm": 5.593713283538818,
      "learning_rate": 5.170666666666667e-07,
      "logits/chosen": -2.7786083221435547,
      "logits/rejected": -3.2729711532592773,
      "logps/chosen": -178.63185119628906,
      "logps/rejected": -214.1193389892578,
      "loss": 0.0292,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.252760171890259,
      "rewards/margins": 4.750333786010742,
      "rewards/rejected": -7.003093719482422,
      "step": 3623
    },
    {
      "epoch": 1.4496,
      "grad_norm": 0.03439287841320038,
      "learning_rate": 5.169333333333334e-07,
      "logits/chosen": -1.9939303398132324,
      "logits/rejected": -2.9533181190490723,
      "logps/chosen": -100.86500549316406,
      "logps/rejected": -173.24549865722656,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.192570924758911,
      "rewards/margins": 10.713573455810547,
      "rewards/rejected": -7.521001815795898,
      "step": 3624
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.6437622308731079,
      "learning_rate": 5.168e-07,
      "logits/chosen": -1.6456544399261475,
      "logits/rejected": -3.495028018951416,
      "logps/chosen": -128.1865692138672,
      "logps/rejected": -151.0859832763672,
      "loss": 0.006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.659023642539978,
      "rewards/margins": 6.360065460205078,
      "rewards/rejected": -7.0190887451171875,
      "step": 3625
    },
    {
      "epoch": 1.4504000000000001,
      "grad_norm": 0.08010036498308182,
      "learning_rate": 5.166666666666667e-07,
      "logits/chosen": -2.744870185852051,
      "logits/rejected": -3.7345170974731445,
      "logps/chosen": -112.7643814086914,
      "logps/rejected": -197.81280517578125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.942117691040039,
      "rewards/margins": 10.561635971069336,
      "rewards/rejected": -8.619518280029297,
      "step": 3626
    },
    {
      "epoch": 1.4508,
      "grad_norm": 2.968123197555542,
      "learning_rate": 5.165333333333332e-07,
      "logits/chosen": -2.6167707443237305,
      "logits/rejected": -2.7353458404541016,
      "logps/chosen": -129.26583862304688,
      "logps/rejected": -159.8057861328125,
      "loss": 0.0164,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8775177001953125,
      "rewards/margins": 4.774936676025391,
      "rewards/rejected": -6.652454376220703,
      "step": 3627
    },
    {
      "epoch": 1.4512,
      "grad_norm": 0.0060433209873735905,
      "learning_rate": 5.163999999999999e-07,
      "logits/chosen": -1.7829281091690063,
      "logits/rejected": -3.2092766761779785,
      "logps/chosen": -119.08443450927734,
      "logps/rejected": -186.10914611816406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6526541709899902,
      "rewards/margins": 11.375225067138672,
      "rewards/rejected": -8.72257137298584,
      "step": 3628
    },
    {
      "epoch": 1.4516,
      "grad_norm": 2.302743673324585,
      "learning_rate": 5.162666666666666e-07,
      "logits/chosen": -2.3626480102539062,
      "logits/rejected": -3.066524028778076,
      "logps/chosen": -176.60989379882812,
      "logps/rejected": -178.69068908691406,
      "loss": 0.0149,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2021031379699707,
      "rewards/margins": 9.407416343688965,
      "rewards/rejected": -8.205313682556152,
      "step": 3629
    },
    {
      "epoch": 1.452,
      "grad_norm": 0.014174340292811394,
      "learning_rate": 5.161333333333333e-07,
      "logits/chosen": -1.6498863697052002,
      "logits/rejected": -3.0274500846862793,
      "logps/chosen": -94.58967590332031,
      "logps/rejected": -152.49961853027344,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.678966999053955,
      "rewards/margins": 9.33040714263916,
      "rewards/rejected": -7.651440143585205,
      "step": 3630
    },
    {
      "epoch": 1.4524,
      "grad_norm": 0.023989811539649963,
      "learning_rate": 5.16e-07,
      "logits/chosen": -1.8082098960876465,
      "logits/rejected": -3.1466593742370605,
      "logps/chosen": -118.0839614868164,
      "logps/rejected": -193.88150024414062,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4438660144805908,
      "rewards/margins": 9.42544937133789,
      "rewards/rejected": -7.981583595275879,
      "step": 3631
    },
    {
      "epoch": 1.4527999999999999,
      "grad_norm": 0.030403995886445045,
      "learning_rate": 5.158666666666667e-07,
      "logits/chosen": -1.5900440216064453,
      "logits/rejected": -3.95828914642334,
      "logps/chosen": -81.75917053222656,
      "logps/rejected": -188.92123413085938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4644386768341064,
      "rewards/margins": 10.123536109924316,
      "rewards/rejected": -8.659097671508789,
      "step": 3632
    },
    {
      "epoch": 1.4532,
      "grad_norm": 0.003509510774165392,
      "learning_rate": 5.157333333333334e-07,
      "logits/chosen": -2.2834632396698,
      "logits/rejected": -3.2632079124450684,
      "logps/chosen": -146.24972534179688,
      "logps/rejected": -219.59226989746094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.423262596130371,
      "rewards/margins": 10.452522277832031,
      "rewards/rejected": -7.029260635375977,
      "step": 3633
    },
    {
      "epoch": 1.4536,
      "grad_norm": 0.4065285623073578,
      "learning_rate": 5.155999999999999e-07,
      "logits/chosen": -1.573662519454956,
      "logits/rejected": -2.7184019088745117,
      "logps/chosen": -90.58049011230469,
      "logps/rejected": -170.1043701171875,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3285272121429443,
      "rewards/margins": 7.997091293334961,
      "rewards/rejected": -5.668564796447754,
      "step": 3634
    },
    {
      "epoch": 1.454,
      "grad_norm": 0.0029608558397740126,
      "learning_rate": 5.154666666666666e-07,
      "logits/chosen": -1.9185688495635986,
      "logits/rejected": -3.317859411239624,
      "logps/chosen": -110.1605453491211,
      "logps/rejected": -197.02157592773438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.319525957107544,
      "rewards/margins": 10.995491027832031,
      "rewards/rejected": -7.67596435546875,
      "step": 3635
    },
    {
      "epoch": 1.4544000000000001,
      "grad_norm": 0.0399518720805645,
      "learning_rate": 5.153333333333333e-07,
      "logits/chosen": -2.355191230773926,
      "logits/rejected": -3.265976667404175,
      "logps/chosen": -132.12759399414062,
      "logps/rejected": -163.34109497070312,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.867969512939453,
      "rewards/margins": 9.471698760986328,
      "rewards/rejected": -5.603729724884033,
      "step": 3636
    },
    {
      "epoch": 1.4548,
      "grad_norm": 0.01822776347398758,
      "learning_rate": 5.152e-07,
      "logits/chosen": -2.240809679031372,
      "logits/rejected": -3.014188289642334,
      "logps/chosen": -119.95928955078125,
      "logps/rejected": -172.78199768066406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0028457641601562,
      "rewards/margins": 9.69717788696289,
      "rewards/rejected": -7.694331169128418,
      "step": 3637
    },
    {
      "epoch": 1.4552,
      "grad_norm": 0.044681742787361145,
      "learning_rate": 5.150666666666666e-07,
      "logits/chosen": -2.465880870819092,
      "logits/rejected": -3.2852752208709717,
      "logps/chosen": -110.16106414794922,
      "logps/rejected": -179.27157592773438,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23552930355072021,
      "rewards/margins": 8.56008243560791,
      "rewards/rejected": -8.324552536010742,
      "step": 3638
    },
    {
      "epoch": 1.4556,
      "grad_norm": 0.017231283709406853,
      "learning_rate": 5.149333333333333e-07,
      "logits/chosen": -1.9097404479980469,
      "logits/rejected": -3.1556921005249023,
      "logps/chosen": -52.27054214477539,
      "logps/rejected": -160.75244140625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.508511781692505,
      "rewards/margins": 9.548629760742188,
      "rewards/rejected": -7.040118217468262,
      "step": 3639
    },
    {
      "epoch": 1.456,
      "grad_norm": 0.0046416353434324265,
      "learning_rate": 5.148e-07,
      "logits/chosen": -1.6763560771942139,
      "logits/rejected": -3.356905937194824,
      "logps/chosen": -111.39471435546875,
      "logps/rejected": -211.40460205078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.72007417678833,
      "rewards/margins": 11.958520889282227,
      "rewards/rejected": -8.238447189331055,
      "step": 3640
    },
    {
      "epoch": 1.4564,
      "grad_norm": 0.018667493015527725,
      "learning_rate": 5.146666666666667e-07,
      "logits/chosen": -1.6611928939819336,
      "logits/rejected": -3.2373032569885254,
      "logps/chosen": -107.30928802490234,
      "logps/rejected": -206.95166015625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.170071840286255,
      "rewards/margins": 9.717235565185547,
      "rewards/rejected": -6.547163963317871,
      "step": 3641
    },
    {
      "epoch": 1.4567999999999999,
      "grad_norm": 0.007287825457751751,
      "learning_rate": 5.145333333333333e-07,
      "logits/chosen": -2.5148630142211914,
      "logits/rejected": -3.2101426124572754,
      "logps/chosen": -182.28445434570312,
      "logps/rejected": -168.22506713867188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7916359901428223,
      "rewards/margins": 10.848285675048828,
      "rewards/rejected": -7.056650161743164,
      "step": 3642
    },
    {
      "epoch": 1.4572,
      "grad_norm": 0.060706134885549545,
      "learning_rate": 5.143999999999999e-07,
      "logits/chosen": -1.7398457527160645,
      "logits/rejected": -3.250735282897949,
      "logps/chosen": -140.89804077148438,
      "logps/rejected": -166.53509521484375,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0193012952804565,
      "rewards/margins": 8.127067565917969,
      "rewards/rejected": -7.107766151428223,
      "step": 3643
    },
    {
      "epoch": 1.4576,
      "grad_norm": 0.004968420602381229,
      "learning_rate": 5.142666666666666e-07,
      "logits/chosen": -1.3136290311813354,
      "logits/rejected": -3.6571874618530273,
      "logps/chosen": -97.00041198730469,
      "logps/rejected": -165.09765625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1448025703430176,
      "rewards/margins": 10.110403060913086,
      "rewards/rejected": -6.965600967407227,
      "step": 3644
    },
    {
      "epoch": 1.458,
      "grad_norm": 0.0026331981644034386,
      "learning_rate": 5.141333333333333e-07,
      "logits/chosen": -2.178201198577881,
      "logits/rejected": -3.5674426555633545,
      "logps/chosen": -122.21903991699219,
      "logps/rejected": -207.5928955078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.191064357757568,
      "rewards/margins": 14.495330810546875,
      "rewards/rejected": -10.304265975952148,
      "step": 3645
    },
    {
      "epoch": 1.4584,
      "grad_norm": 0.0035772391129285097,
      "learning_rate": 5.14e-07,
      "logits/chosen": -2.2374072074890137,
      "logits/rejected": -3.882241725921631,
      "logps/chosen": -143.16091918945312,
      "logps/rejected": -180.2220916748047,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0184326171875,
      "rewards/margins": 10.585338592529297,
      "rewards/rejected": -8.566905975341797,
      "step": 3646
    },
    {
      "epoch": 1.4588,
      "grad_norm": 0.020877722650766373,
      "learning_rate": 5.138666666666667e-07,
      "logits/chosen": -2.268310785293579,
      "logits/rejected": -3.0352158546447754,
      "logps/chosen": -144.9073944091797,
      "logps/rejected": -166.240966796875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.734670639038086,
      "rewards/margins": 8.984158515930176,
      "rewards/rejected": -7.24948787689209,
      "step": 3647
    },
    {
      "epoch": 1.4592,
      "grad_norm": 0.029494192451238632,
      "learning_rate": 5.137333333333334e-07,
      "logits/chosen": -1.6857949495315552,
      "logits/rejected": -3.605205535888672,
      "logps/chosen": -145.15484619140625,
      "logps/rejected": -194.8744354248047,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5079560279846191,
      "rewards/margins": 9.120534896850586,
      "rewards/rejected": -7.612579345703125,
      "step": 3648
    },
    {
      "epoch": 1.4596,
      "grad_norm": 0.0010305183241143823,
      "learning_rate": 5.135999999999999e-07,
      "logits/chosen": -2.767202138900757,
      "logits/rejected": -3.3924717903137207,
      "logps/chosen": -130.3372802734375,
      "logps/rejected": -193.66226196289062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9487853050231934,
      "rewards/margins": 11.773127555847168,
      "rewards/rejected": -7.824341773986816,
      "step": 3649
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.0024189960677176714,
      "learning_rate": 5.134666666666666e-07,
      "logits/chosen": -2.0544018745422363,
      "logits/rejected": -3.6478381156921387,
      "logps/chosen": -114.57836151123047,
      "logps/rejected": -216.45196533203125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4663286209106445,
      "rewards/margins": 11.157976150512695,
      "rewards/rejected": -8.69164752960205,
      "step": 3650
    },
    {
      "epoch": 1.4604,
      "grad_norm": 0.16019918024539948,
      "learning_rate": 5.133333333333333e-07,
      "logits/chosen": -2.0568695068359375,
      "logits/rejected": -2.1768343448638916,
      "logps/chosen": -62.50431823730469,
      "logps/rejected": -144.853759765625,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.034942626953125,
      "rewards/margins": 9.416656494140625,
      "rewards/rejected": -6.3817138671875,
      "step": 3651
    },
    {
      "epoch": 1.4607999999999999,
      "grad_norm": 0.06961091607809067,
      "learning_rate": 5.132e-07,
      "logits/chosen": -2.066716432571411,
      "logits/rejected": -3.5278236865997314,
      "logps/chosen": -129.943603515625,
      "logps/rejected": -159.096923828125,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.16909179091453552,
      "rewards/margins": 7.389666557312012,
      "rewards/rejected": -7.55875825881958,
      "step": 3652
    },
    {
      "epoch": 1.4612,
      "grad_norm": 1.0152716636657715,
      "learning_rate": 5.130666666666666e-07,
      "logits/chosen": -2.443448781967163,
      "logits/rejected": -3.9455726146698,
      "logps/chosen": -162.0478973388672,
      "logps/rejected": -253.25595092773438,
      "loss": 0.0103,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8100239634513855,
      "rewards/margins": 8.533628463745117,
      "rewards/rejected": -7.723604202270508,
      "step": 3653
    },
    {
      "epoch": 1.4616,
      "grad_norm": 0.0769072100520134,
      "learning_rate": 5.129333333333333e-07,
      "logits/chosen": -1.5630810260772705,
      "logits/rejected": -2.924009323120117,
      "logps/chosen": -111.80471801757812,
      "logps/rejected": -144.21087646484375,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7159218788146973,
      "rewards/margins": 7.857400894165039,
      "rewards/rejected": -6.1414794921875,
      "step": 3654
    },
    {
      "epoch": 1.462,
      "grad_norm": 0.16719265282154083,
      "learning_rate": 5.128e-07,
      "logits/chosen": -2.1727466583251953,
      "logits/rejected": -3.489966630935669,
      "logps/chosen": -98.60972595214844,
      "logps/rejected": -195.9148406982422,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7010570764541626,
      "rewards/margins": 7.747849941253662,
      "rewards/rejected": -8.448906898498535,
      "step": 3655
    },
    {
      "epoch": 1.4624,
      "grad_norm": 0.047890111804008484,
      "learning_rate": 5.126666666666667e-07,
      "logits/chosen": -2.03094482421875,
      "logits/rejected": -3.3785033226013184,
      "logps/chosen": -86.09068298339844,
      "logps/rejected": -155.7465362548828,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0818190574645996,
      "rewards/margins": 7.978764533996582,
      "rewards/rejected": -5.896945476531982,
      "step": 3656
    },
    {
      "epoch": 1.4628,
      "grad_norm": 0.010587627068161964,
      "learning_rate": 5.125333333333333e-07,
      "logits/chosen": -1.8067419528961182,
      "logits/rejected": -3.286139965057373,
      "logps/chosen": -140.90167236328125,
      "logps/rejected": -181.99844360351562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0405263900756836,
      "rewards/margins": 10.096399307250977,
      "rewards/rejected": -7.055873394012451,
      "step": 3657
    },
    {
      "epoch": 1.4632,
      "grad_norm": 1.124733567237854,
      "learning_rate": 5.124e-07,
      "logits/chosen": -2.0766754150390625,
      "logits/rejected": -2.6541810035705566,
      "logps/chosen": -102.56871032714844,
      "logps/rejected": -120.15296936035156,
      "loss": 0.0113,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3401973247528076,
      "rewards/margins": 5.711549758911133,
      "rewards/rejected": -4.371352195739746,
      "step": 3658
    },
    {
      "epoch": 1.4636,
      "grad_norm": 0.006315900012850761,
      "learning_rate": 5.122666666666666e-07,
      "logits/chosen": -2.1671829223632812,
      "logits/rejected": -3.121083974838257,
      "logps/chosen": -91.78240203857422,
      "logps/rejected": -235.7812957763672,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.888233184814453,
      "rewards/margins": 10.205747604370117,
      "rewards/rejected": -7.317514419555664,
      "step": 3659
    },
    {
      "epoch": 1.464,
      "grad_norm": 0.016455745324492455,
      "learning_rate": 5.121333333333333e-07,
      "logits/chosen": -1.4531731605529785,
      "logits/rejected": -3.164602756500244,
      "logps/chosen": -91.41629028320312,
      "logps/rejected": -155.66029357910156,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1291656494140625,
      "rewards/margins": 8.73794174194336,
      "rewards/rejected": -7.608776092529297,
      "step": 3660
    },
    {
      "epoch": 1.4644,
      "grad_norm": 0.047677990049123764,
      "learning_rate": 5.12e-07,
      "logits/chosen": -2.099721908569336,
      "logits/rejected": -3.116466522216797,
      "logps/chosen": -133.7535858154297,
      "logps/rejected": -174.00856018066406,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1684563159942627,
      "rewards/margins": 10.0972900390625,
      "rewards/rejected": -6.928833961486816,
      "step": 3661
    },
    {
      "epoch": 1.4647999999999999,
      "grad_norm": 0.03696064651012421,
      "learning_rate": 5.118666666666666e-07,
      "logits/chosen": -2.2267143726348877,
      "logits/rejected": -3.8684945106506348,
      "logps/chosen": -227.80825805664062,
      "logps/rejected": -204.66290283203125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7439529299736023,
      "rewards/margins": 9.794191360473633,
      "rewards/rejected": -9.050237655639648,
      "step": 3662
    },
    {
      "epoch": 1.4652,
      "grad_norm": 0.008817262947559357,
      "learning_rate": 5.117333333333333e-07,
      "logits/chosen": -2.049006938934326,
      "logits/rejected": -3.1265251636505127,
      "logps/chosen": -137.36273193359375,
      "logps/rejected": -170.7240753173828,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.0472092628479,
      "rewards/margins": 11.00744915008545,
      "rewards/rejected": -6.960239887237549,
      "step": 3663
    },
    {
      "epoch": 1.4656,
      "grad_norm": 0.010331989265978336,
      "learning_rate": 5.116e-07,
      "logits/chosen": -2.0369462966918945,
      "logits/rejected": -3.635977268218994,
      "logps/chosen": -135.67388916015625,
      "logps/rejected": -206.6710205078125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4973655641078949,
      "rewards/margins": 11.444889068603516,
      "rewards/rejected": -10.94752311706543,
      "step": 3664
    },
    {
      "epoch": 1.466,
      "grad_norm": 0.024975184351205826,
      "learning_rate": 5.114666666666666e-07,
      "logits/chosen": -2.221575975418091,
      "logits/rejected": -3.6057302951812744,
      "logps/chosen": -124.5896987915039,
      "logps/rejected": -180.15313720703125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9180465936660767,
      "rewards/margins": 9.43681812286377,
      "rewards/rejected": -7.518771648406982,
      "step": 3665
    },
    {
      "epoch": 1.4664,
      "grad_norm": 0.07851457595825195,
      "learning_rate": 5.113333333333333e-07,
      "logits/chosen": -2.790835380554199,
      "logits/rejected": -3.5819268226623535,
      "logps/chosen": -197.75979614257812,
      "logps/rejected": -221.73257446289062,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7324761152267456,
      "rewards/margins": 10.893141746520996,
      "rewards/rejected": -9.160665512084961,
      "step": 3666
    },
    {
      "epoch": 1.4668,
      "grad_norm": 0.10813457518815994,
      "learning_rate": 5.112e-07,
      "logits/chosen": -2.3473825454711914,
      "logits/rejected": -3.587595224380493,
      "logps/chosen": -222.06570434570312,
      "logps/rejected": -186.53530883789062,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3668159544467926,
      "rewards/margins": 7.589082717895508,
      "rewards/rejected": -7.22226619720459,
      "step": 3667
    },
    {
      "epoch": 1.4672,
      "grad_norm": 0.015420474112033844,
      "learning_rate": 5.110666666666667e-07,
      "logits/chosen": -2.2660186290740967,
      "logits/rejected": -2.974038600921631,
      "logps/chosen": -158.16966247558594,
      "logps/rejected": -176.19085693359375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.073960542678833,
      "rewards/margins": 9.826047897338867,
      "rewards/rejected": -6.752087116241455,
      "step": 3668
    },
    {
      "epoch": 1.4676,
      "grad_norm": 1.446858286857605,
      "learning_rate": 5.109333333333334e-07,
      "logits/chosen": -1.9837990999221802,
      "logits/rejected": -3.3283677101135254,
      "logps/chosen": -109.75162506103516,
      "logps/rejected": -148.8572998046875,
      "loss": 0.0091,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7828774452209473,
      "rewards/margins": 7.239409923553467,
      "rewards/rejected": -6.4565324783325195,
      "step": 3669
    },
    {
      "epoch": 1.468,
      "grad_norm": 0.001311072031967342,
      "learning_rate": 5.108e-07,
      "logits/chosen": -2.102156639099121,
      "logits/rejected": -3.230128288269043,
      "logps/chosen": -108.5010757446289,
      "logps/rejected": -204.74755859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7427940368652344,
      "rewards/margins": 11.858627319335938,
      "rewards/rejected": -8.115833282470703,
      "step": 3670
    },
    {
      "epoch": 1.4684,
      "grad_norm": 2.1011195182800293,
      "learning_rate": 5.106666666666667e-07,
      "logits/chosen": -2.51322078704834,
      "logits/rejected": -3.592890739440918,
      "logps/chosen": -253.2827606201172,
      "logps/rejected": -205.0927734375,
      "loss": 0.0162,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.29056715965271,
      "rewards/margins": 5.137957572937012,
      "rewards/rejected": -7.428524494171143,
      "step": 3671
    },
    {
      "epoch": 1.4687999999999999,
      "grad_norm": 0.004435814917087555,
      "learning_rate": 5.105333333333332e-07,
      "logits/chosen": -2.2997353076934814,
      "logits/rejected": -3.073298215866089,
      "logps/chosen": -97.83534240722656,
      "logps/rejected": -179.1454620361328,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.374335289001465,
      "rewards/margins": 10.475237846374512,
      "rewards/rejected": -6.1009016036987305,
      "step": 3672
    },
    {
      "epoch": 1.4692,
      "grad_norm": 0.34231123328208923,
      "learning_rate": 5.103999999999999e-07,
      "logits/chosen": -1.8614047765731812,
      "logits/rejected": -2.720125913619995,
      "logps/chosen": -102.7293472290039,
      "logps/rejected": -152.82803344726562,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2779209613800049,
      "rewards/margins": 7.003029823303223,
      "rewards/rejected": -5.725109100341797,
      "step": 3673
    },
    {
      "epoch": 1.4696,
      "grad_norm": 0.040346771478652954,
      "learning_rate": 5.102666666666666e-07,
      "logits/chosen": -2.051670551300049,
      "logits/rejected": -3.0720040798187256,
      "logps/chosen": -155.60198974609375,
      "logps/rejected": -158.50723266601562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.604470133781433,
      "rewards/margins": 9.015664100646973,
      "rewards/rejected": -7.41119384765625,
      "step": 3674
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.06914009898900986,
      "learning_rate": 5.101333333333333e-07,
      "logits/chosen": -2.461291790008545,
      "logits/rejected": -3.5448055267333984,
      "logps/chosen": -142.22128295898438,
      "logps/rejected": -172.25332641601562,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.05588531494140625,
      "rewards/margins": 7.902374267578125,
      "rewards/rejected": -7.958259582519531,
      "step": 3675
    },
    {
      "epoch": 1.4704,
      "grad_norm": 0.1497413069009781,
      "learning_rate": 5.1e-07,
      "logits/chosen": -2.427213430404663,
      "logits/rejected": -3.1722609996795654,
      "logps/chosen": -150.49667358398438,
      "logps/rejected": -153.6318359375,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.06538462638855,
      "rewards/margins": 9.985037803649902,
      "rewards/rejected": -7.91965389251709,
      "step": 3676
    },
    {
      "epoch": 1.4708,
      "grad_norm": 20.733722686767578,
      "learning_rate": 5.098666666666667e-07,
      "logits/chosen": -3.0349483489990234,
      "logits/rejected": -3.5154824256896973,
      "logps/chosen": -181.73324584960938,
      "logps/rejected": -149.47430419921875,
      "loss": 0.147,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8494735956192017,
      "rewards/margins": 4.189282417297363,
      "rewards/rejected": -6.038755893707275,
      "step": 3677
    },
    {
      "epoch": 1.4712,
      "grad_norm": 0.005676974542438984,
      "learning_rate": 5.097333333333334e-07,
      "logits/chosen": -1.941692590713501,
      "logits/rejected": -3.150567054748535,
      "logps/chosen": -143.3234100341797,
      "logps/rejected": -198.46444702148438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.68398380279541,
      "rewards/margins": 10.93370246887207,
      "rewards/rejected": -8.24971866607666,
      "step": 3678
    },
    {
      "epoch": 1.4716,
      "grad_norm": 0.19429437816143036,
      "learning_rate": 5.096000000000001e-07,
      "logits/chosen": -2.359005928039551,
      "logits/rejected": -3.515310287475586,
      "logps/chosen": -250.85507202148438,
      "logps/rejected": -211.2698516845703,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1552406549453735,
      "rewards/margins": 7.627936363220215,
      "rewards/rejected": -8.783177375793457,
      "step": 3679
    },
    {
      "epoch": 1.472,
      "grad_norm": 0.11147597432136536,
      "learning_rate": 5.094666666666666e-07,
      "logits/chosen": -1.5008066892623901,
      "logits/rejected": -2.7548558712005615,
      "logps/chosen": -83.42045593261719,
      "logps/rejected": -144.50848388671875,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8226547241210938,
      "rewards/margins": 9.141711235046387,
      "rewards/rejected": -6.319056510925293,
      "step": 3680
    },
    {
      "epoch": 1.4724,
      "grad_norm": 0.024978848174214363,
      "learning_rate": 5.093333333333332e-07,
      "logits/chosen": -2.2401599884033203,
      "logits/rejected": -3.2416560649871826,
      "logps/chosen": -173.2920379638672,
      "logps/rejected": -195.8123779296875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7304794788360596,
      "rewards/margins": 9.326709747314453,
      "rewards/rejected": -8.596229553222656,
      "step": 3681
    },
    {
      "epoch": 1.4727999999999999,
      "grad_norm": 0.00910880882292986,
      "learning_rate": 5.091999999999999e-07,
      "logits/chosen": -2.007180690765381,
      "logits/rejected": -3.7959704399108887,
      "logps/chosen": -163.52027893066406,
      "logps/rejected": -200.97842407226562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3215938806533813,
      "rewards/margins": 9.671825408935547,
      "rewards/rejected": -8.350231170654297,
      "step": 3682
    },
    {
      "epoch": 1.4732,
      "grad_norm": 0.014977461658418179,
      "learning_rate": 5.090666666666666e-07,
      "logits/chosen": -2.359050989151001,
      "logits/rejected": -2.837682008743286,
      "logps/chosen": -134.0299072265625,
      "logps/rejected": -157.35113525390625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9260056018829346,
      "rewards/margins": 8.812643051147461,
      "rewards/rejected": -5.886638164520264,
      "step": 3683
    },
    {
      "epoch": 1.4736,
      "grad_norm": 0.6664167046546936,
      "learning_rate": 5.089333333333333e-07,
      "logits/chosen": -2.201190948486328,
      "logits/rejected": -3.3615894317626953,
      "logps/chosen": -91.53363037109375,
      "logps/rejected": -167.1025390625,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.971927285194397,
      "rewards/margins": 7.944594383239746,
      "rewards/rejected": -6.9726667404174805,
      "step": 3684
    },
    {
      "epoch": 1.474,
      "grad_norm": 0.0003686128475237638,
      "learning_rate": 5.088e-07,
      "logits/chosen": -1.8837368488311768,
      "logits/rejected": -3.758075714111328,
      "logps/chosen": -98.32213592529297,
      "logps/rejected": -203.17396545410156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.340853214263916,
      "rewards/margins": 12.83965015411377,
      "rewards/rejected": -9.498797416687012,
      "step": 3685
    },
    {
      "epoch": 1.4744,
      "grad_norm": 0.005614391528069973,
      "learning_rate": 5.086666666666667e-07,
      "logits/chosen": -1.7851588726043701,
      "logits/rejected": -3.2132017612457275,
      "logps/chosen": -105.70771789550781,
      "logps/rejected": -180.73155212402344,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1295690536499023,
      "rewards/margins": 9.827484130859375,
      "rewards/rejected": -6.697915077209473,
      "step": 3686
    },
    {
      "epoch": 1.4748,
      "grad_norm": 0.00013598974328488111,
      "learning_rate": 5.085333333333333e-07,
      "logits/chosen": -2.0246591567993164,
      "logits/rejected": -3.739210844039917,
      "logps/chosen": -81.96766662597656,
      "logps/rejected": -233.46389770507812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.215766906738281,
      "rewards/margins": 13.940864562988281,
      "rewards/rejected": -9.72509765625,
      "step": 3687
    },
    {
      "epoch": 1.4752,
      "grad_norm": 0.03824377432465553,
      "learning_rate": 5.084e-07,
      "logits/chosen": -2.2653708457946777,
      "logits/rejected": -3.56530499458313,
      "logps/chosen": -154.13909912109375,
      "logps/rejected": -176.23745727539062,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7063247561454773,
      "rewards/margins": 8.141460418701172,
      "rewards/rejected": -7.435135841369629,
      "step": 3688
    },
    {
      "epoch": 1.4756,
      "grad_norm": 0.006353391800075769,
      "learning_rate": 5.082666666666667e-07,
      "logits/chosen": -2.07234525680542,
      "logits/rejected": -3.3878018856048584,
      "logps/chosen": -115.59378051757812,
      "logps/rejected": -185.93643188476562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.611469268798828,
      "rewards/margins": 10.412067413330078,
      "rewards/rejected": -7.80059814453125,
      "step": 3689
    },
    {
      "epoch": 1.476,
      "grad_norm": 0.0032337827142328024,
      "learning_rate": 5.081333333333333e-07,
      "logits/chosen": -1.7266795635223389,
      "logits/rejected": -3.59824800491333,
      "logps/chosen": -102.84329223632812,
      "logps/rejected": -177.43670654296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8158788681030273,
      "rewards/margins": 10.56463623046875,
      "rewards/rejected": -6.748757362365723,
      "step": 3690
    },
    {
      "epoch": 1.4764,
      "grad_norm": 0.012740745209157467,
      "learning_rate": 5.079999999999999e-07,
      "logits/chosen": -1.7329630851745605,
      "logits/rejected": -3.2353780269622803,
      "logps/chosen": -184.45347595214844,
      "logps/rejected": -184.41366577148438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.691783905029297,
      "rewards/margins": 9.47783088684082,
      "rewards/rejected": -6.786046981811523,
      "step": 3691
    },
    {
      "epoch": 1.4768,
      "grad_norm": 0.002009799238294363,
      "learning_rate": 5.078666666666666e-07,
      "logits/chosen": -2.1469616889953613,
      "logits/rejected": -2.518341541290283,
      "logps/chosen": -82.4950942993164,
      "logps/rejected": -162.86614990234375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.169551849365234,
      "rewards/margins": 12.087691307067871,
      "rewards/rejected": -7.918139457702637,
      "step": 3692
    },
    {
      "epoch": 1.4772,
      "grad_norm": 0.01151309534907341,
      "learning_rate": 5.077333333333333e-07,
      "logits/chosen": -2.552863597869873,
      "logits/rejected": -3.2111902236938477,
      "logps/chosen": -90.00855255126953,
      "logps/rejected": -149.47482299804688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3040637969970703,
      "rewards/margins": 9.862249374389648,
      "rewards/rejected": -6.558186054229736,
      "step": 3693
    },
    {
      "epoch": 1.4776,
      "grad_norm": 0.012277629226446152,
      "learning_rate": 5.076e-07,
      "logits/chosen": -2.2348079681396484,
      "logits/rejected": -3.2220873832702637,
      "logps/chosen": -113.71861267089844,
      "logps/rejected": -194.26390075683594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.652311086654663,
      "rewards/margins": 10.943049430847168,
      "rewards/rejected": -8.290738105773926,
      "step": 3694
    },
    {
      "epoch": 1.478,
      "grad_norm": 0.0041712382808327675,
      "learning_rate": 5.074666666666666e-07,
      "logits/chosen": -2.44722318649292,
      "logits/rejected": -2.556826114654541,
      "logps/chosen": -91.6522216796875,
      "logps/rejected": -202.50390625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.805522918701172,
      "rewards/margins": 12.407413482666016,
      "rewards/rejected": -7.60189151763916,
      "step": 3695
    },
    {
      "epoch": 1.4784,
      "grad_norm": 0.005577553529292345,
      "learning_rate": 5.073333333333333e-07,
      "logits/chosen": -1.7008888721466064,
      "logits/rejected": -3.789536952972412,
      "logps/chosen": -101.67630004882812,
      "logps/rejected": -207.7854461669922,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.919771671295166,
      "rewards/margins": 11.12928581237793,
      "rewards/rejected": -8.209514617919922,
      "step": 3696
    },
    {
      "epoch": 1.4788000000000001,
      "grad_norm": 0.0023743256460875273,
      "learning_rate": 5.072e-07,
      "logits/chosen": -2.738790988922119,
      "logits/rejected": -3.3879642486572266,
      "logps/chosen": -196.6043243408203,
      "logps/rejected": -198.85484313964844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3977885246276855,
      "rewards/margins": 11.084589004516602,
      "rewards/rejected": -7.686800003051758,
      "step": 3697
    },
    {
      "epoch": 1.4792,
      "grad_norm": 0.009420372545719147,
      "learning_rate": 5.070666666666667e-07,
      "logits/chosen": -2.28414249420166,
      "logits/rejected": -3.3789243698120117,
      "logps/chosen": -144.38275146484375,
      "logps/rejected": -184.90994262695312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8099945187568665,
      "rewards/margins": 9.39857292175293,
      "rewards/rejected": -8.588579177856445,
      "step": 3698
    },
    {
      "epoch": 1.4796,
      "grad_norm": 0.045302629470825195,
      "learning_rate": 5.069333333333334e-07,
      "logits/chosen": -1.648500680923462,
      "logits/rejected": -3.766514778137207,
      "logps/chosen": -115.26373291015625,
      "logps/rejected": -176.77532958984375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1180274486541748,
      "rewards/margins": 9.784585952758789,
      "rewards/rejected": -8.666559219360352,
      "step": 3699
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.0011815056204795837,
      "learning_rate": 5.068e-07,
      "logits/chosen": -2.2836995124816895,
      "logits/rejected": -3.4127726554870605,
      "logps/chosen": -138.95010375976562,
      "logps/rejected": -192.0983123779297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.57991361618042,
      "rewards/margins": 12.54258918762207,
      "rewards/rejected": -8.962675094604492,
      "step": 3700
    },
    {
      "epoch": 1.4804,
      "grad_norm": 0.1252458691596985,
      "learning_rate": 5.066666666666667e-07,
      "logits/chosen": -2.3016629219055176,
      "logits/rejected": -3.4618899822235107,
      "logps/chosen": -137.3330078125,
      "logps/rejected": -242.5548095703125,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.603846788406372,
      "rewards/margins": 8.395955085754395,
      "rewards/rejected": -6.792108535766602,
      "step": 3701
    },
    {
      "epoch": 1.4808,
      "grad_norm": 0.4080749452114105,
      "learning_rate": 5.065333333333332e-07,
      "logits/chosen": -1.7219583988189697,
      "logits/rejected": -3.5395045280456543,
      "logps/chosen": -106.77061462402344,
      "logps/rejected": -147.03306579589844,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6878864765167236,
      "rewards/margins": 8.27003288269043,
      "rewards/rejected": -6.582146644592285,
      "step": 3702
    },
    {
      "epoch": 1.4812,
      "grad_norm": 0.018630770966410637,
      "learning_rate": 5.063999999999999e-07,
      "logits/chosen": -2.5879836082458496,
      "logits/rejected": -3.2623729705810547,
      "logps/chosen": -98.94860076904297,
      "logps/rejected": -148.18435668945312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.821864604949951,
      "rewards/margins": 9.231599807739258,
      "rewards/rejected": -6.409735679626465,
      "step": 3703
    },
    {
      "epoch": 1.4816,
      "grad_norm": 0.010700661689043045,
      "learning_rate": 5.062666666666666e-07,
      "logits/chosen": -2.2082901000976562,
      "logits/rejected": -3.1213533878326416,
      "logps/chosen": -151.86767578125,
      "logps/rejected": -193.1453857421875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9023644924163818,
      "rewards/margins": 9.340553283691406,
      "rewards/rejected": -7.438189506530762,
      "step": 3704
    },
    {
      "epoch": 1.482,
      "grad_norm": 0.02658286690711975,
      "learning_rate": 5.061333333333333e-07,
      "logits/chosen": -1.9574017524719238,
      "logits/rejected": -2.6079463958740234,
      "logps/chosen": -89.38327026367188,
      "logps/rejected": -153.52342224121094,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6254401206970215,
      "rewards/margins": 10.251069068908691,
      "rewards/rejected": -6.625629425048828,
      "step": 3705
    },
    {
      "epoch": 1.4824,
      "grad_norm": 0.012468202039599419,
      "learning_rate": 5.06e-07,
      "logits/chosen": -2.564742088317871,
      "logits/rejected": -3.668677806854248,
      "logps/chosen": -201.18150329589844,
      "logps/rejected": -198.30389404296875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.49096107482910156,
      "rewards/margins": 9.723749160766602,
      "rewards/rejected": -10.214710235595703,
      "step": 3706
    },
    {
      "epoch": 1.4828000000000001,
      "grad_norm": 0.004948893561959267,
      "learning_rate": 5.058666666666667e-07,
      "logits/chosen": -2.201759099960327,
      "logits/rejected": -3.7583651542663574,
      "logps/chosen": -187.66856384277344,
      "logps/rejected": -175.84283447265625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.124157428741455,
      "rewards/margins": 10.510480880737305,
      "rewards/rejected": -7.38632345199585,
      "step": 3707
    },
    {
      "epoch": 1.4832,
      "grad_norm": 0.0034054189454764128,
      "learning_rate": 5.057333333333334e-07,
      "logits/chosen": -1.9243581295013428,
      "logits/rejected": -3.092390537261963,
      "logps/chosen": -62.02449035644531,
      "logps/rejected": -149.58651733398438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6495532989501953,
      "rewards/margins": 10.717035293579102,
      "rewards/rejected": -7.067481994628906,
      "step": 3708
    },
    {
      "epoch": 1.4836,
      "grad_norm": 0.012344090268015862,
      "learning_rate": 5.056e-07,
      "logits/chosen": -2.1646182537078857,
      "logits/rejected": -3.9335992336273193,
      "logps/chosen": -100.83230590820312,
      "logps/rejected": -194.72463989257812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8572323322296143,
      "rewards/margins": 10.158109664916992,
      "rewards/rejected": -7.300877571105957,
      "step": 3709
    },
    {
      "epoch": 1.484,
      "grad_norm": 0.10394497960805893,
      "learning_rate": 5.054666666666666e-07,
      "logits/chosen": -1.956174612045288,
      "logits/rejected": -3.4754467010498047,
      "logps/chosen": -170.80018615722656,
      "logps/rejected": -215.41116333007812,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5097649097442627,
      "rewards/margins": 9.124955177307129,
      "rewards/rejected": -7.615190029144287,
      "step": 3710
    },
    {
      "epoch": 1.4844,
      "grad_norm": 0.05798935145139694,
      "learning_rate": 5.053333333333333e-07,
      "logits/chosen": -2.085240602493286,
      "logits/rejected": -3.256319046020508,
      "logps/chosen": -114.72013092041016,
      "logps/rejected": -184.72271728515625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.33530887961387634,
      "rewards/margins": 8.557016372680664,
      "rewards/rejected": -8.892325401306152,
      "step": 3711
    },
    {
      "epoch": 1.4848,
      "grad_norm": 0.07000266760587692,
      "learning_rate": 5.051999999999999e-07,
      "logits/chosen": -2.202275514602661,
      "logits/rejected": -3.4896388053894043,
      "logps/chosen": -123.46641540527344,
      "logps/rejected": -192.6094207763672,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.816093921661377,
      "rewards/margins": 9.603433609008789,
      "rewards/rejected": -7.78734016418457,
      "step": 3712
    },
    {
      "epoch": 1.4852,
      "grad_norm": 0.04519803076982498,
      "learning_rate": 5.050666666666666e-07,
      "logits/chosen": -1.509476661682129,
      "logits/rejected": -3.4915714263916016,
      "logps/chosen": -131.49459838867188,
      "logps/rejected": -180.1370849609375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7288079261779785,
      "rewards/margins": 10.126294136047363,
      "rewards/rejected": -7.397486209869385,
      "step": 3713
    },
    {
      "epoch": 1.4856,
      "grad_norm": 0.028490230441093445,
      "learning_rate": 5.049333333333333e-07,
      "logits/chosen": -2.5119833946228027,
      "logits/rejected": -2.7681875228881836,
      "logps/chosen": -199.3377685546875,
      "logps/rejected": -204.95652770996094,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2722702026367188,
      "rewards/margins": 9.657831192016602,
      "rewards/rejected": -7.385560989379883,
      "step": 3714
    },
    {
      "epoch": 1.486,
      "grad_norm": 0.004819952882826328,
      "learning_rate": 5.048e-07,
      "logits/chosen": -2.2674872875213623,
      "logits/rejected": -3.499378204345703,
      "logps/chosen": -132.7560272216797,
      "logps/rejected": -171.58114624023438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6458494663238525,
      "rewards/margins": 10.392524719238281,
      "rewards/rejected": -7.746675491333008,
      "step": 3715
    },
    {
      "epoch": 1.4864,
      "grad_norm": 1.073799729347229,
      "learning_rate": 5.046666666666667e-07,
      "logits/chosen": -1.5096912384033203,
      "logits/rejected": -3.043447971343994,
      "logps/chosen": -91.19660186767578,
      "logps/rejected": -146.92214965820312,
      "loss": 0.0075,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45757827162742615,
      "rewards/margins": 6.740516185760498,
      "rewards/rejected": -6.282938003540039,
      "step": 3716
    },
    {
      "epoch": 1.4868000000000001,
      "grad_norm": 0.309937447309494,
      "learning_rate": 5.045333333333333e-07,
      "logits/chosen": -2.4536828994750977,
      "logits/rejected": -2.7928099632263184,
      "logps/chosen": -144.35704040527344,
      "logps/rejected": -153.84336853027344,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0668895244598389,
      "rewards/margins": 8.048639297485352,
      "rewards/rejected": -6.981750011444092,
      "step": 3717
    },
    {
      "epoch": 1.4872,
      "grad_norm": 0.0024997908622026443,
      "learning_rate": 5.043999999999999e-07,
      "logits/chosen": -2.394186019897461,
      "logits/rejected": -3.4995369911193848,
      "logps/chosen": -176.65570068359375,
      "logps/rejected": -181.47625732421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.581996917724609,
      "rewards/margins": 11.656445503234863,
      "rewards/rejected": -7.074448585510254,
      "step": 3718
    },
    {
      "epoch": 1.4876,
      "grad_norm": 0.0024390574544668198,
      "learning_rate": 5.042666666666666e-07,
      "logits/chosen": -1.9907760620117188,
      "logits/rejected": -3.37363862991333,
      "logps/chosen": -98.72328186035156,
      "logps/rejected": -208.475830078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.295823812484741,
      "rewards/margins": 11.256468772888184,
      "rewards/rejected": -8.960644721984863,
      "step": 3719
    },
    {
      "epoch": 1.488,
      "grad_norm": 0.14684320986270905,
      "learning_rate": 5.041333333333333e-07,
      "logits/chosen": -2.7999267578125,
      "logits/rejected": -3.09213924407959,
      "logps/chosen": -83.0318603515625,
      "logps/rejected": -135.63929748535156,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9559834003448486,
      "rewards/margins": 7.869804382324219,
      "rewards/rejected": -5.913820743560791,
      "step": 3720
    },
    {
      "epoch": 1.4884,
      "grad_norm": 0.003903323318809271,
      "learning_rate": 5.04e-07,
      "logits/chosen": -2.3791818618774414,
      "logits/rejected": -3.0267598628997803,
      "logps/chosen": -106.10870361328125,
      "logps/rejected": -177.3910675048828,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.832091808319092,
      "rewards/margins": 10.589231491088867,
      "rewards/rejected": -7.757139205932617,
      "step": 3721
    },
    {
      "epoch": 1.4888,
      "grad_norm": 0.0037661322858184576,
      "learning_rate": 5.038666666666667e-07,
      "logits/chosen": -2.6457159519195557,
      "logits/rejected": -2.8350296020507812,
      "logps/chosen": -89.28330993652344,
      "logps/rejected": -196.0419158935547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3958507776260376,
      "rewards/margins": 10.652786254882812,
      "rewards/rejected": -9.256935119628906,
      "step": 3722
    },
    {
      "epoch": 1.4892,
      "grad_norm": 0.0005563159356825054,
      "learning_rate": 5.037333333333333e-07,
      "logits/chosen": -2.3515615463256836,
      "logits/rejected": -3.2569639682769775,
      "logps/chosen": -99.04957580566406,
      "logps/rejected": -175.84088134765625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.228862762451172,
      "rewards/margins": 12.627093315124512,
      "rewards/rejected": -9.39823055267334,
      "step": 3723
    },
    {
      "epoch": 1.4896,
      "grad_norm": 0.29230475425720215,
      "learning_rate": 5.036e-07,
      "logits/chosen": -2.4179654121398926,
      "logits/rejected": -3.3079833984375,
      "logps/chosen": -115.31742858886719,
      "logps/rejected": -137.0970458984375,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4418972134590149,
      "rewards/margins": 6.828317642211914,
      "rewards/rejected": -6.386420249938965,
      "step": 3724
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.7975692749023438,
      "learning_rate": 5.034666666666666e-07,
      "logits/chosen": -2.060170888900757,
      "logits/rejected": -2.7826192378997803,
      "logps/chosen": -123.52128601074219,
      "logps/rejected": -143.70028686523438,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1782822608947754,
      "rewards/margins": 8.204039573669434,
      "rewards/rejected": -6.025757312774658,
      "step": 3725
    },
    {
      "epoch": 1.4904,
      "grad_norm": 0.78814297914505,
      "learning_rate": 5.033333333333333e-07,
      "logits/chosen": -2.20186710357666,
      "logits/rejected": -3.1935696601867676,
      "logps/chosen": -176.08181762695312,
      "logps/rejected": -217.46986389160156,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.56777423620224,
      "rewards/margins": 10.848514556884766,
      "rewards/rejected": -10.280739784240723,
      "step": 3726
    },
    {
      "epoch": 1.4908000000000001,
      "grad_norm": 0.007168625481426716,
      "learning_rate": 5.032e-07,
      "logits/chosen": -2.2712924480438232,
      "logits/rejected": -3.2308764457702637,
      "logps/chosen": -191.56259155273438,
      "logps/rejected": -209.31784057617188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4832634925842285,
      "rewards/margins": 12.274494171142578,
      "rewards/rejected": -8.791230201721191,
      "step": 3727
    },
    {
      "epoch": 1.4912,
      "grad_norm": 0.16820067167282104,
      "learning_rate": 5.030666666666666e-07,
      "logits/chosen": -1.714983582496643,
      "logits/rejected": -3.0427258014678955,
      "logps/chosen": -145.52206420898438,
      "logps/rejected": -158.1136474609375,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6454377174377441,
      "rewards/margins": 7.489038467407227,
      "rewards/rejected": -5.843600749969482,
      "step": 3728
    },
    {
      "epoch": 1.4916,
      "grad_norm": 0.0052241128869354725,
      "learning_rate": 5.029333333333333e-07,
      "logits/chosen": -1.8644320964813232,
      "logits/rejected": -3.6219987869262695,
      "logps/chosen": -108.5699462890625,
      "logps/rejected": -197.8417205810547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0281333923339844,
      "rewards/margins": 11.444440841674805,
      "rewards/rejected": -9.41630744934082,
      "step": 3729
    },
    {
      "epoch": 1.492,
      "grad_norm": 0.0022637841757386923,
      "learning_rate": 5.028e-07,
      "logits/chosen": -1.8173866271972656,
      "logits/rejected": -3.859529972076416,
      "logps/chosen": -113.5957260131836,
      "logps/rejected": -176.4776611328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4093456268310547,
      "rewards/margins": 11.518867492675781,
      "rewards/rejected": -8.109521865844727,
      "step": 3730
    },
    {
      "epoch": 1.4924,
      "grad_norm": 0.003653351217508316,
      "learning_rate": 5.026666666666667e-07,
      "logits/chosen": -2.1052920818328857,
      "logits/rejected": -2.7861905097961426,
      "logps/chosen": -85.40176391601562,
      "logps/rejected": -157.09585571289062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.381124973297119,
      "rewards/margins": 11.135551452636719,
      "rewards/rejected": -6.754426956176758,
      "step": 3731
    },
    {
      "epoch": 1.4928,
      "grad_norm": 1.3376569747924805,
      "learning_rate": 5.025333333333334e-07,
      "logits/chosen": -2.16115665435791,
      "logits/rejected": -2.8785767555236816,
      "logps/chosen": -122.19985961914062,
      "logps/rejected": -144.9869384765625,
      "loss": 0.009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2216088771820068,
      "rewards/margins": 8.695175170898438,
      "rewards/rejected": -7.473565578460693,
      "step": 3732
    },
    {
      "epoch": 1.4932,
      "grad_norm": 0.10466625541448593,
      "learning_rate": 5.023999999999999e-07,
      "logits/chosen": -2.3342862129211426,
      "logits/rejected": -2.895535469055176,
      "logps/chosen": -105.50453186035156,
      "logps/rejected": -143.82208251953125,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1295413970947266,
      "rewards/margins": 9.393211364746094,
      "rewards/rejected": -6.263669967651367,
      "step": 3733
    },
    {
      "epoch": 1.4936,
      "grad_norm": 0.016040967777371407,
      "learning_rate": 5.022666666666666e-07,
      "logits/chosen": -2.4515633583068848,
      "logits/rejected": -3.427462339401245,
      "logps/chosen": -122.68030548095703,
      "logps/rejected": -181.6407470703125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.627601385116577,
      "rewards/margins": 10.52872085571289,
      "rewards/rejected": -7.901119232177734,
      "step": 3734
    },
    {
      "epoch": 1.494,
      "grad_norm": 0.0013943355297669768,
      "learning_rate": 5.021333333333333e-07,
      "logits/chosen": -2.467656135559082,
      "logits/rejected": -3.687577247619629,
      "logps/chosen": -178.62794494628906,
      "logps/rejected": -187.31842041015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0073137283325195,
      "rewards/margins": 11.419708251953125,
      "rewards/rejected": -8.412395477294922,
      "step": 3735
    },
    {
      "epoch": 1.4944,
      "grad_norm": 0.3248438239097595,
      "learning_rate": 5.02e-07,
      "logits/chosen": -2.5970265865325928,
      "logits/rejected": -3.162674903869629,
      "logps/chosen": -192.21286010742188,
      "logps/rejected": -199.1615447998047,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.665194034576416,
      "rewards/margins": 7.657049179077148,
      "rewards/rejected": -5.991855621337891,
      "step": 3736
    },
    {
      "epoch": 1.4948000000000001,
      "grad_norm": 0.22274507582187653,
      "learning_rate": 5.018666666666666e-07,
      "logits/chosen": -1.9307420253753662,
      "logits/rejected": -3.251051902770996,
      "logps/chosen": -125.22535705566406,
      "logps/rejected": -189.47698974609375,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5764129757881165,
      "rewards/margins": 6.856040954589844,
      "rewards/rejected": -7.4324541091918945,
      "step": 3737
    },
    {
      "epoch": 1.4952,
      "grad_norm": 0.0023753924760967493,
      "learning_rate": 5.017333333333333e-07,
      "logits/chosen": -2.019387722015381,
      "logits/rejected": -3.406372547149658,
      "logps/chosen": -98.6668701171875,
      "logps/rejected": -169.16915893554688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3433220386505127,
      "rewards/margins": 11.140944480895996,
      "rewards/rejected": -7.7976226806640625,
      "step": 3738
    },
    {
      "epoch": 1.4956,
      "grad_norm": 0.08857784420251846,
      "learning_rate": 5.016e-07,
      "logits/chosen": -2.1786129474639893,
      "logits/rejected": -3.1431283950805664,
      "logps/chosen": -84.98968505859375,
      "logps/rejected": -158.01576232910156,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06123962998390198,
      "rewards/margins": 7.127791404724121,
      "rewards/rejected": -7.066551685333252,
      "step": 3739
    },
    {
      "epoch": 1.496,
      "grad_norm": 0.013600979000329971,
      "learning_rate": 5.014666666666666e-07,
      "logits/chosen": -1.9739080667495728,
      "logits/rejected": -2.9590771198272705,
      "logps/chosen": -120.288330078125,
      "logps/rejected": -163.72869873046875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5869556665420532,
      "rewards/margins": 8.873766899108887,
      "rewards/rejected": -7.286810874938965,
      "step": 3740
    },
    {
      "epoch": 1.4964,
      "grad_norm": 0.057336919009685516,
      "learning_rate": 5.013333333333333e-07,
      "logits/chosen": -1.930083990097046,
      "logits/rejected": -3.3343734741210938,
      "logps/chosen": -106.29415893554688,
      "logps/rejected": -152.7965545654297,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2494916915893555,
      "rewards/margins": 9.682302474975586,
      "rewards/rejected": -7.4328107833862305,
      "step": 3741
    },
    {
      "epoch": 1.4968,
      "grad_norm": 0.06928592920303345,
      "learning_rate": 5.012e-07,
      "logits/chosen": -1.840610146522522,
      "logits/rejected": -3.505812168121338,
      "logps/chosen": -144.8469696044922,
      "logps/rejected": -167.4056396484375,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8656352758407593,
      "rewards/margins": 7.243356227874756,
      "rewards/rejected": -6.377720832824707,
      "step": 3742
    },
    {
      "epoch": 1.4971999999999999,
      "grad_norm": 0.08305943757295609,
      "learning_rate": 5.010666666666667e-07,
      "logits/chosen": -2.777263641357422,
      "logits/rejected": -3.6417744159698486,
      "logps/chosen": -117.89248657226562,
      "logps/rejected": -182.7650146484375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2009119987487793,
      "rewards/margins": 9.614815711975098,
      "rewards/rejected": -7.413904190063477,
      "step": 3743
    },
    {
      "epoch": 1.4976,
      "grad_norm": 0.02879757434129715,
      "learning_rate": 5.009333333333333e-07,
      "logits/chosen": -2.082212448120117,
      "logits/rejected": -3.591846466064453,
      "logps/chosen": -82.83294677734375,
      "logps/rejected": -148.105224609375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.980532169342041,
      "rewards/margins": 8.890079498291016,
      "rewards/rejected": -5.909548282623291,
      "step": 3744
    },
    {
      "epoch": 1.498,
      "grad_norm": 0.01953691802918911,
      "learning_rate": 5.008e-07,
      "logits/chosen": -2.1769728660583496,
      "logits/rejected": -2.7580604553222656,
      "logps/chosen": -142.61410522460938,
      "logps/rejected": -154.41949462890625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6973514556884766,
      "rewards/margins": 8.956005096435547,
      "rewards/rejected": -6.25865364074707,
      "step": 3745
    },
    {
      "epoch": 1.4984,
      "grad_norm": 0.2786654829978943,
      "learning_rate": 5.006666666666667e-07,
      "logits/chosen": -2.7885072231292725,
      "logits/rejected": -2.864872455596924,
      "logps/chosen": -117.9390869140625,
      "logps/rejected": -143.3627166748047,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.44241100549697876,
      "rewards/margins": 7.319257736206055,
      "rewards/rejected": -6.8768463134765625,
      "step": 3746
    },
    {
      "epoch": 1.4988000000000001,
      "grad_norm": 0.0008532873471267521,
      "learning_rate": 5.005333333333333e-07,
      "logits/chosen": -1.9047514200210571,
      "logits/rejected": -3.348719596862793,
      "logps/chosen": -128.1287841796875,
      "logps/rejected": -192.51812744140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8596115112304688,
      "rewards/margins": 12.627220153808594,
      "rewards/rejected": -8.767607688903809,
      "step": 3747
    },
    {
      "epoch": 1.4992,
      "grad_norm": 0.009709769859910011,
      "learning_rate": 5.003999999999999e-07,
      "logits/chosen": -2.142454147338867,
      "logits/rejected": -3.731151819229126,
      "logps/chosen": -105.60248565673828,
      "logps/rejected": -222.66375732421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2379974126815796,
      "rewards/margins": 10.576702117919922,
      "rewards/rejected": -10.81470012664795,
      "step": 3748
    },
    {
      "epoch": 1.4996,
      "grad_norm": 0.25571855902671814,
      "learning_rate": 5.002666666666666e-07,
      "logits/chosen": -2.286289691925049,
      "logits/rejected": -3.454315662384033,
      "logps/chosen": -207.09735107421875,
      "logps/rejected": -149.66171264648438,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7956245541572571,
      "rewards/margins": 7.172024726867676,
      "rewards/rejected": -6.376399993896484,
      "step": 3749
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.003869531210511923,
      "learning_rate": 5.001333333333333e-07,
      "logits/chosen": -2.0773191452026367,
      "logits/rejected": -2.895813465118408,
      "logps/chosen": -135.15933227539062,
      "logps/rejected": -241.2653045654297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3942315578460693,
      "rewards/margins": 12.285783767700195,
      "rewards/rejected": -8.891552925109863,
      "step": 3750
    },
    {
      "epoch": 1.5004,
      "grad_norm": 0.018873438239097595,
      "learning_rate": 5e-07,
      "logits/chosen": -2.4063358306884766,
      "logits/rejected": -3.426783800125122,
      "logps/chosen": -204.72142028808594,
      "logps/rejected": -175.79510498046875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.255140781402588,
      "rewards/margins": 9.368610382080078,
      "rewards/rejected": -7.113470077514648,
      "step": 3751
    },
    {
      "epoch": 1.5008,
      "grad_norm": 0.039607174694538116,
      "learning_rate": 4.998666666666667e-07,
      "logits/chosen": -2.5575408935546875,
      "logits/rejected": -3.3791565895080566,
      "logps/chosen": -171.23861694335938,
      "logps/rejected": -241.5758056640625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22223129868507385,
      "rewards/margins": 8.25441837310791,
      "rewards/rejected": -8.032186508178711,
      "step": 3752
    },
    {
      "epoch": 1.5011999999999999,
      "grad_norm": 0.001537629752419889,
      "learning_rate": 4.997333333333333e-07,
      "logits/chosen": -2.193596839904785,
      "logits/rejected": -3.2939257621765137,
      "logps/chosen": -124.18809509277344,
      "logps/rejected": -172.96141052246094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.799956321716309,
      "rewards/margins": 11.483128547668457,
      "rewards/rejected": -6.683172225952148,
      "step": 3753
    },
    {
      "epoch": 1.5016,
      "grad_norm": 0.07530248910188675,
      "learning_rate": 4.996e-07,
      "logits/chosen": -2.713991165161133,
      "logits/rejected": -3.5851359367370605,
      "logps/chosen": -119.61023712158203,
      "logps/rejected": -188.21812438964844,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1678485870361328,
      "rewards/margins": 8.338006019592285,
      "rewards/rejected": -8.170157432556152,
      "step": 3754
    },
    {
      "epoch": 1.502,
      "grad_norm": 0.12452705204486847,
      "learning_rate": 4.994666666666666e-07,
      "logits/chosen": -1.9832005500793457,
      "logits/rejected": -2.9815468788146973,
      "logps/chosen": -75.843994140625,
      "logps/rejected": -176.41119384765625,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2012627124786377,
      "rewards/margins": 9.92137336730957,
      "rewards/rejected": -7.720110893249512,
      "step": 3755
    },
    {
      "epoch": 1.5024,
      "grad_norm": 0.027874164283275604,
      "learning_rate": 4.993333333333333e-07,
      "logits/chosen": -2.184967041015625,
      "logits/rejected": -3.8339037895202637,
      "logps/chosen": -166.3623504638672,
      "logps/rejected": -171.9508056640625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1561081409454346,
      "rewards/margins": 9.371435165405273,
      "rewards/rejected": -7.215327739715576,
      "step": 3756
    },
    {
      "epoch": 1.5028000000000001,
      "grad_norm": 0.04692965745925903,
      "learning_rate": 4.991999999999999e-07,
      "logits/chosen": -2.404046058654785,
      "logits/rejected": -3.4375312328338623,
      "logps/chosen": -123.72533416748047,
      "logps/rejected": -180.01344299316406,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7992428541183472,
      "rewards/margins": 9.703237533569336,
      "rewards/rejected": -8.9039945602417,
      "step": 3757
    },
    {
      "epoch": 1.5032,
      "grad_norm": 0.00041729205986484885,
      "learning_rate": 4.990666666666666e-07,
      "logits/chosen": -2.1716485023498535,
      "logits/rejected": -3.398789405822754,
      "logps/chosen": -126.0552749633789,
      "logps/rejected": -224.09600830078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 5.147853851318359,
      "rewards/margins": 12.690193176269531,
      "rewards/rejected": -7.542338848114014,
      "step": 3758
    },
    {
      "epoch": 1.5036,
      "grad_norm": 0.005902675911784172,
      "learning_rate": 4.989333333333333e-07,
      "logits/chosen": -1.5958302021026611,
      "logits/rejected": -3.380307674407959,
      "logps/chosen": -110.38101196289062,
      "logps/rejected": -240.38192749023438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1543984413146973,
      "rewards/margins": 11.011941909790039,
      "rewards/rejected": -9.8575439453125,
      "step": 3759
    },
    {
      "epoch": 1.504,
      "grad_norm": 0.0009562593186274171,
      "learning_rate": 4.988e-07,
      "logits/chosen": -1.934356689453125,
      "logits/rejected": -3.254751682281494,
      "logps/chosen": -156.5623779296875,
      "logps/rejected": -209.87237548828125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.11966872215271,
      "rewards/margins": 12.06527042388916,
      "rewards/rejected": -8.945601463317871,
      "step": 3760
    },
    {
      "epoch": 1.5044,
      "grad_norm": 0.0007065701647661626,
      "learning_rate": 4.986666666666666e-07,
      "logits/chosen": -2.0237176418304443,
      "logits/rejected": -3.560006618499756,
      "logps/chosen": -95.4853515625,
      "logps/rejected": -195.12371826171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.807343006134033,
      "rewards/margins": 12.153848648071289,
      "rewards/rejected": -8.346506118774414,
      "step": 3761
    },
    {
      "epoch": 1.5048,
      "grad_norm": 0.01826881431043148,
      "learning_rate": 4.985333333333333e-07,
      "logits/chosen": -1.9855780601501465,
      "logits/rejected": -3.5050694942474365,
      "logps/chosen": -136.06256103515625,
      "logps/rejected": -236.93722534179688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7991464138031006,
      "rewards/margins": 10.386541366577148,
      "rewards/rejected": -7.587394714355469,
      "step": 3762
    },
    {
      "epoch": 1.5051999999999999,
      "grad_norm": 0.19943362474441528,
      "learning_rate": 4.984e-07,
      "logits/chosen": -2.3484106063842773,
      "logits/rejected": -2.979367733001709,
      "logps/chosen": -150.944091796875,
      "logps/rejected": -194.18701171875,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.148291826248169,
      "rewards/margins": 7.35440731048584,
      "rewards/rejected": -6.206115245819092,
      "step": 3763
    },
    {
      "epoch": 1.5056,
      "grad_norm": 0.050715696066617966,
      "learning_rate": 4.982666666666667e-07,
      "logits/chosen": -2.190580368041992,
      "logits/rejected": -3.269181251525879,
      "logps/chosen": -105.59408569335938,
      "logps/rejected": -177.478759765625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8195236325263977,
      "rewards/margins": 8.990609169006348,
      "rewards/rejected": -8.171085357666016,
      "step": 3764
    },
    {
      "epoch": 1.506,
      "grad_norm": 0.0009479423752054572,
      "learning_rate": 4.981333333333333e-07,
      "logits/chosen": -2.052746295928955,
      "logits/rejected": -3.711881637573242,
      "logps/chosen": -174.8482208251953,
      "logps/rejected": -184.85220336914062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.010235786437988,
      "rewards/margins": 12.041255950927734,
      "rewards/rejected": -8.031020164489746,
      "step": 3765
    },
    {
      "epoch": 1.5064,
      "grad_norm": 0.6578479409217834,
      "learning_rate": 4.979999999999999e-07,
      "logits/chosen": -2.4125494956970215,
      "logits/rejected": -2.9748644828796387,
      "logps/chosen": -142.7273712158203,
      "logps/rejected": -129.83250427246094,
      "loss": 0.0069,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5372326374053955,
      "rewards/margins": 6.179495811462402,
      "rewards/rejected": -5.642262935638428,
      "step": 3766
    },
    {
      "epoch": 1.5068000000000001,
      "grad_norm": 0.0051439255475997925,
      "learning_rate": 4.978666666666666e-07,
      "logits/chosen": -1.8743993043899536,
      "logits/rejected": -3.6475648880004883,
      "logps/chosen": -75.66145324707031,
      "logps/rejected": -168.46994018554688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.901235580444336,
      "rewards/margins": 10.342475891113281,
      "rewards/rejected": -7.441240310668945,
      "step": 3767
    },
    {
      "epoch": 1.5072,
      "grad_norm": 0.8517786264419556,
      "learning_rate": 4.977333333333333e-07,
      "logits/chosen": -2.155369281768799,
      "logits/rejected": -3.1365017890930176,
      "logps/chosen": -179.57968139648438,
      "logps/rejected": -170.3477325439453,
      "loss": 0.0108,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7174148559570312,
      "rewards/margins": 7.846336364746094,
      "rewards/rejected": -7.1289215087890625,
      "step": 3768
    },
    {
      "epoch": 1.5076,
      "grad_norm": 0.7333018183708191,
      "learning_rate": 4.976e-07,
      "logits/chosen": -2.116936206817627,
      "logits/rejected": -3.084211826324463,
      "logps/chosen": -149.91549682617188,
      "logps/rejected": -140.5553436279297,
      "loss": 0.0065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5803794860839844,
      "rewards/margins": 8.404452323913574,
      "rewards/rejected": -6.82407283782959,
      "step": 3769
    },
    {
      "epoch": 1.508,
      "grad_norm": 0.2958548665046692,
      "learning_rate": 4.974666666666666e-07,
      "logits/chosen": -2.523167610168457,
      "logits/rejected": -3.328158378601074,
      "logps/chosen": -113.28665924072266,
      "logps/rejected": -180.48550415039062,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5317668914794922,
      "rewards/margins": 9.829743385314941,
      "rewards/rejected": -8.29797649383545,
      "step": 3770
    },
    {
      "epoch": 1.5084,
      "grad_norm": 0.005600831937044859,
      "learning_rate": 4.973333333333333e-07,
      "logits/chosen": -2.334144115447998,
      "logits/rejected": -3.1322243213653564,
      "logps/chosen": -181.60269165039062,
      "logps/rejected": -176.10195922851562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.22979736328125,
      "rewards/margins": 9.973822593688965,
      "rewards/rejected": -7.744025230407715,
      "step": 3771
    },
    {
      "epoch": 1.5088,
      "grad_norm": 0.011319988407194614,
      "learning_rate": 4.972e-07,
      "logits/chosen": -2.4618725776672363,
      "logits/rejected": -3.272106409072876,
      "logps/chosen": -128.89920043945312,
      "logps/rejected": -150.274169921875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8776795864105225,
      "rewards/margins": 9.783529281616211,
      "rewards/rejected": -6.905849933624268,
      "step": 3772
    },
    {
      "epoch": 1.5091999999999999,
      "grad_norm": 0.005904864985495806,
      "learning_rate": 4.970666666666667e-07,
      "logits/chosen": -2.1600396633148193,
      "logits/rejected": -3.315701484680176,
      "logps/chosen": -112.19438171386719,
      "logps/rejected": -184.29452514648438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.938735008239746,
      "rewards/margins": 10.911846160888672,
      "rewards/rejected": -7.973111152648926,
      "step": 3773
    },
    {
      "epoch": 1.5096,
      "grad_norm": 0.0571325458586216,
      "learning_rate": 4.969333333333334e-07,
      "logits/chosen": -2.5037899017333984,
      "logits/rejected": -3.053356885910034,
      "logps/chosen": -260.3743896484375,
      "logps/rejected": -271.4930114746094,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5690758228302,
      "rewards/margins": 11.208667755126953,
      "rewards/rejected": -8.639592170715332,
      "step": 3774
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.1146545261144638,
      "learning_rate": 4.968e-07,
      "logits/chosen": -2.7085354328155518,
      "logits/rejected": -2.631082773208618,
      "logps/chosen": -126.10336303710938,
      "logps/rejected": -148.84503173828125,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6051876544952393,
      "rewards/margins": 8.061753273010254,
      "rewards/rejected": -5.456565856933594,
      "step": 3775
    },
    {
      "epoch": 1.5104,
      "grad_norm": 0.05274464935064316,
      "learning_rate": 4.966666666666666e-07,
      "logits/chosen": -1.7985461950302124,
      "logits/rejected": -3.0486836433410645,
      "logps/chosen": -87.94873046875,
      "logps/rejected": -150.94619750976562,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2423009872436523,
      "rewards/margins": 9.823074340820312,
      "rewards/rejected": -6.580774307250977,
      "step": 3776
    },
    {
      "epoch": 1.5108000000000001,
      "grad_norm": 0.00810118205845356,
      "learning_rate": 4.965333333333333e-07,
      "logits/chosen": -1.7453174591064453,
      "logits/rejected": -3.482292890548706,
      "logps/chosen": -71.400634765625,
      "logps/rejected": -199.97940063476562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7405597567558289,
      "rewards/margins": 9.728351593017578,
      "rewards/rejected": -8.987792015075684,
      "step": 3777
    },
    {
      "epoch": 1.5112,
      "grad_norm": 0.006358072627335787,
      "learning_rate": 4.964e-07,
      "logits/chosen": -2.1164145469665527,
      "logits/rejected": -3.3356146812438965,
      "logps/chosen": -162.91317749023438,
      "logps/rejected": -178.12127685546875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9574050903320312,
      "rewards/margins": 10.398673057556152,
      "rewards/rejected": -8.441267967224121,
      "step": 3778
    },
    {
      "epoch": 1.5116,
      "grad_norm": 0.031266674399375916,
      "learning_rate": 4.962666666666667e-07,
      "logits/chosen": -1.6626718044281006,
      "logits/rejected": -3.290214776992798,
      "logps/chosen": -128.8671875,
      "logps/rejected": -158.8395538330078,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.900240421295166,
      "rewards/margins": 8.293516159057617,
      "rewards/rejected": -7.393276214599609,
      "step": 3779
    },
    {
      "epoch": 1.512,
      "grad_norm": 0.003724153619259596,
      "learning_rate": 4.961333333333333e-07,
      "logits/chosen": -2.337730646133423,
      "logits/rejected": -3.1868693828582764,
      "logps/chosen": -123.7588882446289,
      "logps/rejected": -181.49850463867188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.159150123596191,
      "rewards/margins": 12.303669929504395,
      "rewards/rejected": -8.144519805908203,
      "step": 3780
    },
    {
      "epoch": 1.5124,
      "grad_norm": 0.011386740021407604,
      "learning_rate": 4.96e-07,
      "logits/chosen": -2.2084548473358154,
      "logits/rejected": -3.306378126144409,
      "logps/chosen": -113.8166275024414,
      "logps/rejected": -194.26510620117188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2737762928009033,
      "rewards/margins": 9.57305908203125,
      "rewards/rejected": -7.299283027648926,
      "step": 3781
    },
    {
      "epoch": 1.5128,
      "grad_norm": 0.03469899669289589,
      "learning_rate": 4.958666666666667e-07,
      "logits/chosen": -1.5383808612823486,
      "logits/rejected": -3.2660491466522217,
      "logps/chosen": -71.6534423828125,
      "logps/rejected": -152.4747314453125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2041308879852295,
      "rewards/margins": 9.207538604736328,
      "rewards/rejected": -7.0034074783325195,
      "step": 3782
    },
    {
      "epoch": 1.5131999999999999,
      "grad_norm": 0.275272399187088,
      "learning_rate": 4.957333333333334e-07,
      "logits/chosen": -2.432053565979004,
      "logits/rejected": -2.9449241161346436,
      "logps/chosen": -125.55799865722656,
      "logps/rejected": -216.25698852539062,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8779001235961914,
      "rewards/margins": 9.282764434814453,
      "rewards/rejected": -5.40486478805542,
      "step": 3783
    },
    {
      "epoch": 1.5135999999999998,
      "grad_norm": 0.09384610503911972,
      "learning_rate": 4.956e-07,
      "logits/chosen": -2.3322653770446777,
      "logits/rejected": -3.5231995582580566,
      "logps/chosen": -134.5796661376953,
      "logps/rejected": -156.4873504638672,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6254208087921143,
      "rewards/margins": 7.966211318969727,
      "rewards/rejected": -6.340790748596191,
      "step": 3784
    },
    {
      "epoch": 1.514,
      "grad_norm": 0.11693044006824493,
      "learning_rate": 4.954666666666667e-07,
      "logits/chosen": -2.3081541061401367,
      "logits/rejected": -3.495429039001465,
      "logps/chosen": -66.31689453125,
      "logps/rejected": -156.2992401123047,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8227169513702393,
      "rewards/margins": 8.89242935180664,
      "rewards/rejected": -6.069712162017822,
      "step": 3785
    },
    {
      "epoch": 1.5144,
      "grad_norm": 0.005622544325888157,
      "learning_rate": 4.953333333333333e-07,
      "logits/chosen": -2.4145336151123047,
      "logits/rejected": -3.0779104232788086,
      "logps/chosen": -126.5122299194336,
      "logps/rejected": -215.39151000976562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8692196011543274,
      "rewards/margins": 11.413073539733887,
      "rewards/rejected": -10.543853759765625,
      "step": 3786
    },
    {
      "epoch": 1.5148000000000001,
      "grad_norm": 0.31192684173583984,
      "learning_rate": 4.951999999999999e-07,
      "logits/chosen": -2.1297175884246826,
      "logits/rejected": -3.138014078140259,
      "logps/chosen": -134.76943969726562,
      "logps/rejected": -140.37106323242188,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7676277160644531,
      "rewards/margins": 6.911656379699707,
      "rewards/rejected": -6.144028663635254,
      "step": 3787
    },
    {
      "epoch": 1.5152,
      "grad_norm": 0.004161038435995579,
      "learning_rate": 4.950666666666666e-07,
      "logits/chosen": -2.2685508728027344,
      "logits/rejected": -3.053467273712158,
      "logps/chosen": -99.61532592773438,
      "logps/rejected": -155.24729919433594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.2631659507751465,
      "rewards/margins": 11.12059497833252,
      "rewards/rejected": -6.857428550720215,
      "step": 3788
    },
    {
      "epoch": 1.5156,
      "grad_norm": 0.0034974361769855022,
      "learning_rate": 4.949333333333333e-07,
      "logits/chosen": -2.5861752033233643,
      "logits/rejected": -3.3664517402648926,
      "logps/chosen": -242.49172973632812,
      "logps/rejected": -192.4180908203125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0485756397247314,
      "rewards/margins": 11.525266647338867,
      "rewards/rejected": -8.476692199707031,
      "step": 3789
    },
    {
      "epoch": 1.516,
      "grad_norm": 0.01911388710141182,
      "learning_rate": 4.948e-07,
      "logits/chosen": -1.05423104763031,
      "logits/rejected": -3.2457306385040283,
      "logps/chosen": -66.20610046386719,
      "logps/rejected": -148.2593231201172,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1453607082366943,
      "rewards/margins": 9.276556015014648,
      "rewards/rejected": -6.131196022033691,
      "step": 3790
    },
    {
      "epoch": 1.5164,
      "grad_norm": 0.00828881748020649,
      "learning_rate": 4.946666666666666e-07,
      "logits/chosen": -2.0211148262023926,
      "logits/rejected": -3.1763739585876465,
      "logps/chosen": -120.1768569946289,
      "logps/rejected": -157.3586883544922,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8424408435821533,
      "rewards/margins": 10.893264770507812,
      "rewards/rejected": -7.050824165344238,
      "step": 3791
    },
    {
      "epoch": 1.5168,
      "grad_norm": 0.06693201512098312,
      "learning_rate": 4.945333333333333e-07,
      "logits/chosen": -2.4095804691314697,
      "logits/rejected": -3.9808855056762695,
      "logps/chosen": -153.33309936523438,
      "logps/rejected": -218.0242919921875,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4713985919952393,
      "rewards/margins": 11.345303535461426,
      "rewards/rejected": -9.87390422821045,
      "step": 3792
    },
    {
      "epoch": 1.5171999999999999,
      "grad_norm": 0.048060521483421326,
      "learning_rate": 4.944e-07,
      "logits/chosen": -2.4234461784362793,
      "logits/rejected": -3.3577849864959717,
      "logps/chosen": -117.9917984008789,
      "logps/rejected": -192.28843688964844,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6148388385772705,
      "rewards/margins": 10.772981643676758,
      "rewards/rejected": -9.158143043518066,
      "step": 3793
    },
    {
      "epoch": 1.5175999999999998,
      "grad_norm": 0.003975884057581425,
      "learning_rate": 4.942666666666667e-07,
      "logits/chosen": -2.304271697998047,
      "logits/rejected": -2.752333164215088,
      "logps/chosen": -92.8110122680664,
      "logps/rejected": -165.4442138671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.28986930847168,
      "rewards/margins": 10.434484481811523,
      "rewards/rejected": -6.144615173339844,
      "step": 3794
    },
    {
      "epoch": 1.518,
      "grad_norm": 1.7338192462921143,
      "learning_rate": 4.941333333333333e-07,
      "logits/chosen": -2.7971725463867188,
      "logits/rejected": -2.2609682083129883,
      "logps/chosen": -97.11207580566406,
      "logps/rejected": -130.77442932128906,
      "loss": 0.0085,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.13253402709960938,
      "rewards/margins": 5.477816104888916,
      "rewards/rejected": -5.610350131988525,
      "step": 3795
    },
    {
      "epoch": 1.5184,
      "grad_norm": 0.243843212723732,
      "learning_rate": 4.94e-07,
      "logits/chosen": -2.2154057025909424,
      "logits/rejected": -3.2739434242248535,
      "logps/chosen": -175.982421875,
      "logps/rejected": -186.17672729492188,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9904167056083679,
      "rewards/margins": 7.790925979614258,
      "rewards/rejected": -6.800508975982666,
      "step": 3796
    },
    {
      "epoch": 1.5188000000000001,
      "grad_norm": 0.045250847935676575,
      "learning_rate": 4.938666666666666e-07,
      "logits/chosen": -2.190640926361084,
      "logits/rejected": -3.036966323852539,
      "logps/chosen": -157.45404052734375,
      "logps/rejected": -172.02182006835938,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8587799072265625,
      "rewards/margins": 9.404998779296875,
      "rewards/rejected": -6.546219348907471,
      "step": 3797
    },
    {
      "epoch": 1.5192,
      "grad_norm": 0.7071503400802612,
      "learning_rate": 4.937333333333333e-07,
      "logits/chosen": -2.099478244781494,
      "logits/rejected": -2.8798577785491943,
      "logps/chosen": -114.41682434082031,
      "logps/rejected": -142.61264038085938,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9918258786201477,
      "rewards/margins": 7.303553581237793,
      "rewards/rejected": -6.311727523803711,
      "step": 3798
    },
    {
      "epoch": 1.5196,
      "grad_norm": 0.29701709747314453,
      "learning_rate": 4.935999999999999e-07,
      "logits/chosen": -2.8849968910217285,
      "logits/rejected": -2.764383554458618,
      "logps/chosen": -95.11750793457031,
      "logps/rejected": -130.4276123046875,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8755111694335938,
      "rewards/margins": 6.173035621643066,
      "rewards/rejected": -4.297524452209473,
      "step": 3799
    },
    {
      "epoch": 1.52,
      "grad_norm": 3.108489751815796,
      "learning_rate": 4.934666666666666e-07,
      "logits/chosen": -2.5283706188201904,
      "logits/rejected": -3.377598524093628,
      "logps/chosen": -142.0721893310547,
      "logps/rejected": -174.23635864257812,
      "loss": 0.0235,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15395474433898926,
      "rewards/margins": 6.405613422393799,
      "rewards/rejected": -6.2516584396362305,
      "step": 3800
    },
    {
      "epoch": 1.5204,
      "grad_norm": 0.0018606011290103197,
      "learning_rate": 4.933333333333333e-07,
      "logits/chosen": -1.8872594833374023,
      "logits/rejected": -3.2504029273986816,
      "logps/chosen": -175.5394744873047,
      "logps/rejected": -211.46719360351562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2537577152252197,
      "rewards/margins": 11.210575103759766,
      "rewards/rejected": -7.956817150115967,
      "step": 3801
    },
    {
      "epoch": 1.5208,
      "grad_norm": 4.810999393463135,
      "learning_rate": 4.932e-07,
      "logits/chosen": -2.1711339950561523,
      "logits/rejected": -3.339055061340332,
      "logps/chosen": -111.67233276367188,
      "logps/rejected": -169.2356414794922,
      "loss": 0.0526,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5325287580490112,
      "rewards/margins": 5.265030384063721,
      "rewards/rejected": -6.797558784484863,
      "step": 3802
    },
    {
      "epoch": 1.5211999999999999,
      "grad_norm": 0.000696385046467185,
      "learning_rate": 4.930666666666666e-07,
      "logits/chosen": -2.7645370960235596,
      "logits/rejected": -3.7596402168273926,
      "logps/chosen": -139.868408203125,
      "logps/rejected": -217.88035583496094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9640207290649414,
      "rewards/margins": 12.325065612792969,
      "rewards/rejected": -8.361043930053711,
      "step": 3803
    },
    {
      "epoch": 1.5215999999999998,
      "grad_norm": 0.0062349336221814156,
      "learning_rate": 4.929333333333333e-07,
      "logits/chosen": -1.989695429801941,
      "logits/rejected": -3.7182629108428955,
      "logps/chosen": -95.17466735839844,
      "logps/rejected": -208.7327880859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4001758098602295,
      "rewards/margins": 11.427724838256836,
      "rewards/rejected": -10.027548789978027,
      "step": 3804
    },
    {
      "epoch": 1.522,
      "grad_norm": 0.01007689256221056,
      "learning_rate": 4.928e-07,
      "logits/chosen": -1.4493674039840698,
      "logits/rejected": -3.018394947052002,
      "logps/chosen": -88.17996215820312,
      "logps/rejected": -166.07833862304688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3715965747833252,
      "rewards/margins": 9.412805557250977,
      "rewards/rejected": -8.04120922088623,
      "step": 3805
    },
    {
      "epoch": 1.5224,
      "grad_norm": 0.0027304196264594793,
      "learning_rate": 4.926666666666667e-07,
      "logits/chosen": -2.0177876949310303,
      "logits/rejected": -3.2533888816833496,
      "logps/chosen": -88.03327941894531,
      "logps/rejected": -178.60752868652344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6980791091918945,
      "rewards/margins": 12.392848014831543,
      "rewards/rejected": -8.694768905639648,
      "step": 3806
    },
    {
      "epoch": 1.5228000000000002,
      "grad_norm": 0.005284883547574282,
      "learning_rate": 4.925333333333333e-07,
      "logits/chosen": -2.0772154331207275,
      "logits/rejected": -3.490610122680664,
      "logps/chosen": -91.4456787109375,
      "logps/rejected": -212.20957946777344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.636453628540039,
      "rewards/margins": 11.050878524780273,
      "rewards/rejected": -9.414424896240234,
      "step": 3807
    },
    {
      "epoch": 1.5232,
      "grad_norm": 0.003350510261952877,
      "learning_rate": 4.923999999999999e-07,
      "logits/chosen": -1.8291125297546387,
      "logits/rejected": -3.0498404502868652,
      "logps/chosen": -72.0767822265625,
      "logps/rejected": -198.1311798095703,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6043834686279297,
      "rewards/margins": 11.455778121948242,
      "rewards/rejected": -7.8513946533203125,
      "step": 3808
    },
    {
      "epoch": 1.5236,
      "grad_norm": 1.3649710416793823,
      "learning_rate": 4.922666666666666e-07,
      "logits/chosen": -2.8754353523254395,
      "logits/rejected": -3.4588913917541504,
      "logps/chosen": -137.2843017578125,
      "logps/rejected": -165.95513916015625,
      "loss": 0.0115,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.185574531555176,
      "rewards/margins": 7.764781951904297,
      "rewards/rejected": -5.579206943511963,
      "step": 3809
    },
    {
      "epoch": 1.524,
      "grad_norm": 0.005623804405331612,
      "learning_rate": 4.921333333333333e-07,
      "logits/chosen": -2.4073023796081543,
      "logits/rejected": -3.4129843711853027,
      "logps/chosen": -241.7622528076172,
      "logps/rejected": -202.0265655517578,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3707497119903564,
      "rewards/margins": 10.082962989807129,
      "rewards/rejected": -8.712213516235352,
      "step": 3810
    },
    {
      "epoch": 1.5244,
      "grad_norm": 0.009731164202094078,
      "learning_rate": 4.92e-07,
      "logits/chosen": -2.5625534057617188,
      "logits/rejected": -2.9836740493774414,
      "logps/chosen": -177.8494873046875,
      "logps/rejected": -200.71224975585938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8689682483673096,
      "rewards/margins": 10.110147476196289,
      "rewards/rejected": -7.241179466247559,
      "step": 3811
    },
    {
      "epoch": 1.5248,
      "grad_norm": 0.013606378808617592,
      "learning_rate": 4.918666666666667e-07,
      "logits/chosen": -2.507721424102783,
      "logits/rejected": -2.8907392024993896,
      "logps/chosen": -97.52969360351562,
      "logps/rejected": -150.3065185546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0343422889709473,
      "rewards/margins": 9.885675430297852,
      "rewards/rejected": -6.851334095001221,
      "step": 3812
    },
    {
      "epoch": 1.5252,
      "grad_norm": 0.04203719645738602,
      "learning_rate": 4.917333333333333e-07,
      "logits/chosen": -2.6868486404418945,
      "logits/rejected": -2.941357135772705,
      "logps/chosen": -120.69031524658203,
      "logps/rejected": -203.25100708007812,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.004721068777143955,
      "rewards/margins": 8.252141952514648,
      "rewards/rejected": -8.25686264038086,
      "step": 3813
    },
    {
      "epoch": 1.5255999999999998,
      "grad_norm": 0.3071042597293854,
      "learning_rate": 4.916e-07,
      "logits/chosen": -2.606304168701172,
      "logits/rejected": -3.4719715118408203,
      "logps/chosen": -192.74520874023438,
      "logps/rejected": -205.7504119873047,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.28386765718460083,
      "rewards/margins": 5.764892578125,
      "rewards/rejected": -6.048760414123535,
      "step": 3814
    },
    {
      "epoch": 1.526,
      "grad_norm": 0.040198083966970444,
      "learning_rate": 4.914666666666667e-07,
      "logits/chosen": -2.0495173931121826,
      "logits/rejected": -3.3088626861572266,
      "logps/chosen": -96.58869171142578,
      "logps/rejected": -132.55348205566406,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1860899925231934,
      "rewards/margins": 8.02314567565918,
      "rewards/rejected": -5.837055683135986,
      "step": 3815
    },
    {
      "epoch": 1.5264,
      "grad_norm": 0.01051478274166584,
      "learning_rate": 4.913333333333334e-07,
      "logits/chosen": -2.176090717315674,
      "logits/rejected": -3.3983445167541504,
      "logps/chosen": -94.97114562988281,
      "logps/rejected": -160.97836303710938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8704776763916016,
      "rewards/margins": 9.60440444946289,
      "rewards/rejected": -6.7339277267456055,
      "step": 3816
    },
    {
      "epoch": 1.5268000000000002,
      "grad_norm": 0.0019452093401923776,
      "learning_rate": 4.912e-07,
      "logits/chosen": -1.894077181816101,
      "logits/rejected": -4.149657249450684,
      "logps/chosen": -119.90765380859375,
      "logps/rejected": -250.35264587402344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08235625922679901,
      "rewards/margins": 12.595083236694336,
      "rewards/rejected": -12.512727737426758,
      "step": 3817
    },
    {
      "epoch": 1.5272000000000001,
      "grad_norm": 0.6254821419715881,
      "learning_rate": 4.910666666666666e-07,
      "logits/chosen": -2.404083728790283,
      "logits/rejected": -1.973373532295227,
      "logps/chosen": -93.91661071777344,
      "logps/rejected": -130.02420043945312,
      "loss": 0.0061,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9025826454162598,
      "rewards/margins": 7.344326972961426,
      "rewards/rejected": -5.441743850708008,
      "step": 3818
    },
    {
      "epoch": 1.5276,
      "grad_norm": 0.011174075305461884,
      "learning_rate": 4.909333333333333e-07,
      "logits/chosen": -2.284147262573242,
      "logits/rejected": -3.614056348800659,
      "logps/chosen": -95.29257202148438,
      "logps/rejected": -169.1605224609375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4845997095108032,
      "rewards/margins": 9.356650352478027,
      "rewards/rejected": -7.8720502853393555,
      "step": 3819
    },
    {
      "epoch": 1.528,
      "grad_norm": 0.7006902098655701,
      "learning_rate": 4.908e-07,
      "logits/chosen": -2.2913384437561035,
      "logits/rejected": -3.047658681869507,
      "logps/chosen": -121.79747772216797,
      "logps/rejected": -144.47328186035156,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2030720710754395,
      "rewards/margins": 7.682792663574219,
      "rewards/rejected": -5.479720115661621,
      "step": 3820
    },
    {
      "epoch": 1.5284,
      "grad_norm": 1.389042854309082,
      "learning_rate": 4.906666666666666e-07,
      "logits/chosen": -1.5583088397979736,
      "logits/rejected": -3.274296283721924,
      "logps/chosen": -159.48867797851562,
      "logps/rejected": -161.93539428710938,
      "loss": 0.0133,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.44228747487068176,
      "rewards/margins": 5.112753868103027,
      "rewards/rejected": -5.555041790008545,
      "step": 3821
    },
    {
      "epoch": 1.5288,
      "grad_norm": 0.0024731929879635572,
      "learning_rate": 4.905333333333333e-07,
      "logits/chosen": -2.2944157123565674,
      "logits/rejected": -3.4977588653564453,
      "logps/chosen": -83.68572998046875,
      "logps/rejected": -170.6764678955078,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.104963302612305,
      "rewards/margins": 11.107307434082031,
      "rewards/rejected": -7.002344131469727,
      "step": 3822
    },
    {
      "epoch": 1.5292,
      "grad_norm": 0.0030431607738137245,
      "learning_rate": 4.904e-07,
      "logits/chosen": -2.465766668319702,
      "logits/rejected": -3.573843002319336,
      "logps/chosen": -104.24520874023438,
      "logps/rejected": -174.8611297607422,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7306506633758545,
      "rewards/margins": 10.514411926269531,
      "rewards/rejected": -7.783761501312256,
      "step": 3823
    },
    {
      "epoch": 1.5295999999999998,
      "grad_norm": 0.08990078419446945,
      "learning_rate": 4.902666666666667e-07,
      "logits/chosen": -2.2147696018218994,
      "logits/rejected": -2.6994829177856445,
      "logps/chosen": -104.51239013671875,
      "logps/rejected": -148.9643096923828,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5209499597549438,
      "rewards/margins": 9.220636367797852,
      "rewards/rejected": -7.699686050415039,
      "step": 3824
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.03424637392163277,
      "learning_rate": 4.901333333333333e-07,
      "logits/chosen": -2.5135581493377686,
      "logits/rejected": -3.831439256668091,
      "logps/chosen": -157.8795928955078,
      "logps/rejected": -206.31797790527344,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07799911499023438,
      "rewards/margins": 9.585038185119629,
      "rewards/rejected": -9.507039070129395,
      "step": 3825
    },
    {
      "epoch": 1.5304,
      "grad_norm": 0.23867657780647278,
      "learning_rate": 4.9e-07,
      "logits/chosen": -1.957383155822754,
      "logits/rejected": -3.2826337814331055,
      "logps/chosen": -146.6876220703125,
      "logps/rejected": -164.58177185058594,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6731574535369873,
      "rewards/margins": 9.515213012695312,
      "rewards/rejected": -6.842055797576904,
      "step": 3826
    },
    {
      "epoch": 1.5308000000000002,
      "grad_norm": 0.004124688915908337,
      "learning_rate": 4.898666666666667e-07,
      "logits/chosen": -1.7107239961624146,
      "logits/rejected": -3.0520224571228027,
      "logps/chosen": -73.41822814941406,
      "logps/rejected": -197.45721435546875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4286061525344849,
      "rewards/margins": 10.37628173828125,
      "rewards/rejected": -8.947675704956055,
      "step": 3827
    },
    {
      "epoch": 1.5312000000000001,
      "grad_norm": 0.0008476224611513317,
      "learning_rate": 4.897333333333334e-07,
      "logits/chosen": -2.2331347465515137,
      "logits/rejected": -3.297623634338379,
      "logps/chosen": -111.79824829101562,
      "logps/rejected": -206.83294677734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.971710205078125,
      "rewards/margins": 12.674631118774414,
      "rewards/rejected": -8.702920913696289,
      "step": 3828
    },
    {
      "epoch": 1.5316,
      "grad_norm": 0.059677451848983765,
      "learning_rate": 4.895999999999999e-07,
      "logits/chosen": -1.8253285884857178,
      "logits/rejected": -3.303988218307495,
      "logps/chosen": -122.59026336669922,
      "logps/rejected": -174.55499267578125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5550481081008911,
      "rewards/margins": 8.500807762145996,
      "rewards/rejected": -6.9457597732543945,
      "step": 3829
    },
    {
      "epoch": 1.532,
      "grad_norm": 0.06333599984645844,
      "learning_rate": 4.894666666666666e-07,
      "logits/chosen": -1.658470630645752,
      "logits/rejected": -2.873046398162842,
      "logps/chosen": -109.97911071777344,
      "logps/rejected": -120.27772521972656,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9358606338500977,
      "rewards/margins": 7.774613380432129,
      "rewards/rejected": -4.838752746582031,
      "step": 3830
    },
    {
      "epoch": 1.5324,
      "grad_norm": 0.27337098121643066,
      "learning_rate": 4.893333333333333e-07,
      "logits/chosen": -2.4469666481018066,
      "logits/rejected": -2.734692096710205,
      "logps/chosen": -119.07530212402344,
      "logps/rejected": -150.17405700683594,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.32261061668396,
      "rewards/margins": 7.97714900970459,
      "rewards/rejected": -5.654539108276367,
      "step": 3831
    },
    {
      "epoch": 1.5328,
      "grad_norm": 0.20397894084453583,
      "learning_rate": 4.892e-07,
      "logits/chosen": -2.2092647552490234,
      "logits/rejected": -3.454464912414551,
      "logps/chosen": -118.13732147216797,
      "logps/rejected": -169.40724182128906,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7421570420265198,
      "rewards/margins": 8.364612579345703,
      "rewards/rejected": -7.622455596923828,
      "step": 3832
    },
    {
      "epoch": 1.5332,
      "grad_norm": 0.006758915260434151,
      "learning_rate": 4.890666666666666e-07,
      "logits/chosen": -1.589167833328247,
      "logits/rejected": -3.542933464050293,
      "logps/chosen": -105.12594604492188,
      "logps/rejected": -182.41656494140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3497695922851562,
      "rewards/margins": 10.119881629943848,
      "rewards/rejected": -8.770112037658691,
      "step": 3833
    },
    {
      "epoch": 1.5335999999999999,
      "grad_norm": 0.0048830220475792885,
      "learning_rate": 4.889333333333333e-07,
      "logits/chosen": -2.063788414001465,
      "logits/rejected": -2.958204746246338,
      "logps/chosen": -141.83160400390625,
      "logps/rejected": -247.6438446044922,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8008346557617188,
      "rewards/margins": 10.261520385742188,
      "rewards/rejected": -7.460685729980469,
      "step": 3834
    },
    {
      "epoch": 1.534,
      "grad_norm": 0.001010764273814857,
      "learning_rate": 4.888e-07,
      "logits/chosen": -1.9620022773742676,
      "logits/rejected": -3.015739917755127,
      "logps/chosen": -89.15654754638672,
      "logps/rejected": -210.2627716064453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.861042022705078,
      "rewards/margins": 11.717222213745117,
      "rewards/rejected": -6.856179714202881,
      "step": 3835
    },
    {
      "epoch": 1.5344,
      "grad_norm": 0.0005977092077955604,
      "learning_rate": 4.886666666666667e-07,
      "logits/chosen": -2.372802734375,
      "logits/rejected": -3.5875396728515625,
      "logps/chosen": -85.21792602539062,
      "logps/rejected": -211.37596130371094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6999731063842773,
      "rewards/margins": 13.310199737548828,
      "rewards/rejected": -9.61022663116455,
      "step": 3836
    },
    {
      "epoch": 1.5348000000000002,
      "grad_norm": 0.6763489246368408,
      "learning_rate": 4.885333333333333e-07,
      "logits/chosen": -2.0365750789642334,
      "logits/rejected": -2.9449658393859863,
      "logps/chosen": -147.5259246826172,
      "logps/rejected": -148.9351806640625,
      "loss": 0.0071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8256233334541321,
      "rewards/margins": 5.117264747619629,
      "rewards/rejected": -5.942888259887695,
      "step": 3837
    },
    {
      "epoch": 1.5352000000000001,
      "grad_norm": 0.0003074400301557034,
      "learning_rate": 4.884e-07,
      "logits/chosen": -2.2964344024658203,
      "logits/rejected": -3.501926898956299,
      "logps/chosen": -125.7309341430664,
      "logps/rejected": -193.06268310546875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9723663330078125,
      "rewards/margins": 13.097240447998047,
      "rewards/rejected": -9.124874114990234,
      "step": 3838
    },
    {
      "epoch": 1.5356,
      "grad_norm": 0.3789888322353363,
      "learning_rate": 4.882666666666666e-07,
      "logits/chosen": -2.7030014991760254,
      "logits/rejected": -2.9448249340057373,
      "logps/chosen": -133.12916564941406,
      "logps/rejected": -163.76858520507812,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.28965070843696594,
      "rewards/margins": 6.136682987213135,
      "rewards/rejected": -6.426333427429199,
      "step": 3839
    },
    {
      "epoch": 1.536,
      "grad_norm": 0.20100635290145874,
      "learning_rate": 4.881333333333333e-07,
      "logits/chosen": -2.3431460857391357,
      "logits/rejected": -3.4930410385131836,
      "logps/chosen": -162.5871124267578,
      "logps/rejected": -161.82479858398438,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7158676385879517,
      "rewards/margins": 6.504534721374512,
      "rewards/rejected": -5.788667678833008,
      "step": 3840
    },
    {
      "epoch": 1.5364,
      "grad_norm": 0.04986388981342316,
      "learning_rate": 4.879999999999999e-07,
      "logits/chosen": -1.8381474018096924,
      "logits/rejected": -2.8139123916625977,
      "logps/chosen": -95.82720947265625,
      "logps/rejected": -153.61117553710938,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8649810552597046,
      "rewards/margins": 8.844210624694824,
      "rewards/rejected": -6.97922945022583,
      "step": 3841
    },
    {
      "epoch": 1.5368,
      "grad_norm": 0.005520121194422245,
      "learning_rate": 4.878666666666666e-07,
      "logits/chosen": -2.051974296569824,
      "logits/rejected": -3.1693553924560547,
      "logps/chosen": -92.64228820800781,
      "logps/rejected": -163.39227294921875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4481096267700195,
      "rewards/margins": 10.368268966674805,
      "rewards/rejected": -7.920159339904785,
      "step": 3842
    },
    {
      "epoch": 1.5372,
      "grad_norm": 0.00037821586010977626,
      "learning_rate": 4.877333333333333e-07,
      "logits/chosen": -2.3239264488220215,
      "logits/rejected": -3.6371777057647705,
      "logps/chosen": -116.134521484375,
      "logps/rejected": -191.0384521484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.631770133972168,
      "rewards/margins": 12.720211029052734,
      "rewards/rejected": -9.08843994140625,
      "step": 3843
    },
    {
      "epoch": 1.5375999999999999,
      "grad_norm": 0.002548260847106576,
      "learning_rate": 4.876e-07,
      "logits/chosen": -2.13084077835083,
      "logits/rejected": -3.6753549575805664,
      "logps/chosen": -139.08160400390625,
      "logps/rejected": -224.3170623779297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5577077865600586,
      "rewards/margins": 10.849544525146484,
      "rewards/rejected": -8.291836738586426,
      "step": 3844
    },
    {
      "epoch": 1.538,
      "grad_norm": 0.012459599412977695,
      "learning_rate": 4.874666666666666e-07,
      "logits/chosen": -2.179372787475586,
      "logits/rejected": -3.045109748840332,
      "logps/chosen": -104.02186584472656,
      "logps/rejected": -195.9822998046875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8990941047668457,
      "rewards/margins": 11.2711181640625,
      "rewards/rejected": -9.372024536132812,
      "step": 3845
    },
    {
      "epoch": 1.5384,
      "grad_norm": 0.21139824390411377,
      "learning_rate": 4.873333333333333e-07,
      "logits/chosen": -1.9913811683654785,
      "logits/rejected": -3.144192695617676,
      "logps/chosen": -122.27622985839844,
      "logps/rejected": -150.54440307617188,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04101257026195526,
      "rewards/margins": 6.911022186279297,
      "rewards/rejected": -6.870009422302246,
      "step": 3846
    },
    {
      "epoch": 1.5388,
      "grad_norm": 0.09209141135215759,
      "learning_rate": 4.872e-07,
      "logits/chosen": -1.84938383102417,
      "logits/rejected": -3.267937660217285,
      "logps/chosen": -177.01821899414062,
      "logps/rejected": -154.90512084960938,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0157005786895752,
      "rewards/margins": 8.04063892364502,
      "rewards/rejected": -7.024938583374023,
      "step": 3847
    },
    {
      "epoch": 1.5392000000000001,
      "grad_norm": 0.000677928444929421,
      "learning_rate": 4.870666666666667e-07,
      "logits/chosen": -2.33558988571167,
      "logits/rejected": -3.5521368980407715,
      "logps/chosen": -82.65015411376953,
      "logps/rejected": -240.96343994140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.180644989013672,
      "rewards/margins": 12.851764678955078,
      "rewards/rejected": -8.671119689941406,
      "step": 3848
    },
    {
      "epoch": 1.5396,
      "grad_norm": 0.001064434414729476,
      "learning_rate": 4.869333333333334e-07,
      "logits/chosen": -2.5941152572631836,
      "logits/rejected": -3.1756210327148438,
      "logps/chosen": -120.92601776123047,
      "logps/rejected": -262.10052490234375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.275667667388916,
      "rewards/margins": 12.645048141479492,
      "rewards/rejected": -9.369379997253418,
      "step": 3849
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.0010316079715266824,
      "learning_rate": 4.867999999999999e-07,
      "logits/chosen": -2.0963919162750244,
      "logits/rejected": -3.201073169708252,
      "logps/chosen": -150.4561767578125,
      "logps/rejected": -210.9916229248047,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.0271124839782715,
      "rewards/margins": 13.503443717956543,
      "rewards/rejected": -9.47633171081543,
      "step": 3850
    },
    {
      "epoch": 1.5404,
      "grad_norm": 0.0010800921590998769,
      "learning_rate": 4.866666666666666e-07,
      "logits/chosen": -1.774025797843933,
      "logits/rejected": -3.228487253189087,
      "logps/chosen": -115.40361022949219,
      "logps/rejected": -168.99615478515625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.313077449798584,
      "rewards/margins": 11.865421295166016,
      "rewards/rejected": -7.552343845367432,
      "step": 3851
    },
    {
      "epoch": 1.5408,
      "grad_norm": 0.004569766111671925,
      "learning_rate": 4.865333333333333e-07,
      "logits/chosen": -2.192809581756592,
      "logits/rejected": -3.260615110397339,
      "logps/chosen": -86.57125854492188,
      "logps/rejected": -167.106201171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.606945514678955,
      "rewards/margins": 10.764446258544922,
      "rewards/rejected": -7.157501220703125,
      "step": 3852
    },
    {
      "epoch": 1.5412,
      "grad_norm": 0.04452034831047058,
      "learning_rate": 4.864e-07,
      "logits/chosen": -2.207742214202881,
      "logits/rejected": -3.5341403484344482,
      "logps/chosen": -108.65852355957031,
      "logps/rejected": -171.73049926757812,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5436277389526367,
      "rewards/margins": 10.245916366577148,
      "rewards/rejected": -6.702288627624512,
      "step": 3853
    },
    {
      "epoch": 1.5415999999999999,
      "grad_norm": 0.19997668266296387,
      "learning_rate": 4.862666666666667e-07,
      "logits/chosen": -1.6924582719802856,
      "logits/rejected": -3.1803488731384277,
      "logps/chosen": -110.20652770996094,
      "logps/rejected": -189.01966857910156,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2387579679489136,
      "rewards/margins": 6.454383850097656,
      "rewards/rejected": -7.693141937255859,
      "step": 3854
    },
    {
      "epoch": 1.542,
      "grad_norm": 0.0003308779851067811,
      "learning_rate": 4.861333333333333e-07,
      "logits/chosen": -2.4612865447998047,
      "logits/rejected": -3.6843905448913574,
      "logps/chosen": -176.07733154296875,
      "logps/rejected": -202.32994079589844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 5.336926460266113,
      "rewards/margins": 13.345083236694336,
      "rewards/rejected": -8.008156776428223,
      "step": 3855
    },
    {
      "epoch": 1.5424,
      "grad_norm": 0.05978211760520935,
      "learning_rate": 4.86e-07,
      "logits/chosen": -1.9166251420974731,
      "logits/rejected": -3.5884976387023926,
      "logps/chosen": -102.0858383178711,
      "logps/rejected": -174.91949462890625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.152111053466797,
      "rewards/margins": 9.515902519226074,
      "rewards/rejected": -7.3637919425964355,
      "step": 3856
    },
    {
      "epoch": 1.5428,
      "grad_norm": 0.00025832332903519273,
      "learning_rate": 4.858666666666667e-07,
      "logits/chosen": -2.3250784873962402,
      "logits/rejected": -3.6255950927734375,
      "logps/chosen": -138.96946716308594,
      "logps/rejected": -218.9949493408203,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.256030559539795,
      "rewards/margins": 13.26939582824707,
      "rewards/rejected": -10.013364791870117,
      "step": 3857
    },
    {
      "epoch": 1.5432000000000001,
      "grad_norm": 0.03217662498354912,
      "learning_rate": 4.857333333333334e-07,
      "logits/chosen": -2.538482904434204,
      "logits/rejected": -3.9960477352142334,
      "logps/chosen": -207.04278564453125,
      "logps/rejected": -186.1845245361328,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.881986141204834,
      "rewards/margins": 10.081417083740234,
      "rewards/rejected": -8.199430465698242,
      "step": 3858
    },
    {
      "epoch": 1.5436,
      "grad_norm": 0.003318180562928319,
      "learning_rate": 4.856e-07,
      "logits/chosen": -2.2505970001220703,
      "logits/rejected": -2.97139835357666,
      "logps/chosen": -98.96501159667969,
      "logps/rejected": -183.08177185058594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4109103679656982,
      "rewards/margins": 11.662322998046875,
      "rewards/rejected": -8.251413345336914,
      "step": 3859
    },
    {
      "epoch": 1.544,
      "grad_norm": 0.008945951238274574,
      "learning_rate": 4.854666666666666e-07,
      "logits/chosen": -2.383390426635742,
      "logits/rejected": -3.522042751312256,
      "logps/chosen": -177.64486694335938,
      "logps/rejected": -204.50164794921875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.43951115012168884,
      "rewards/margins": 9.60991096496582,
      "rewards/rejected": -9.170398712158203,
      "step": 3860
    },
    {
      "epoch": 1.5444,
      "grad_norm": 0.0051939114928245544,
      "learning_rate": 4.853333333333333e-07,
      "logits/chosen": -2.3642210960388184,
      "logits/rejected": -3.5765738487243652,
      "logps/chosen": -99.47810363769531,
      "logps/rejected": -130.32106018066406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5317790508270264,
      "rewards/margins": 10.322607040405273,
      "rewards/rejected": -6.790828227996826,
      "step": 3861
    },
    {
      "epoch": 1.5448,
      "grad_norm": 0.05214746296405792,
      "learning_rate": 4.852e-07,
      "logits/chosen": -2.2898550033569336,
      "logits/rejected": -3.4733781814575195,
      "logps/chosen": -152.91700744628906,
      "logps/rejected": -202.06988525390625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1585795879364014,
      "rewards/margins": 7.5861053466796875,
      "rewards/rejected": -6.427525997161865,
      "step": 3862
    },
    {
      "epoch": 1.5452,
      "grad_norm": 0.0003448030329309404,
      "learning_rate": 4.850666666666666e-07,
      "logits/chosen": -1.8425791263580322,
      "logits/rejected": -3.325841188430786,
      "logps/chosen": -160.2654266357422,
      "logps/rejected": -220.1303253173828,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1658787727355957,
      "rewards/margins": 13.732666015625,
      "rewards/rejected": -11.566787719726562,
      "step": 3863
    },
    {
      "epoch": 1.5455999999999999,
      "grad_norm": 0.01556247379630804,
      "learning_rate": 4.849333333333333e-07,
      "logits/chosen": -2.035616159439087,
      "logits/rejected": -3.6345272064208984,
      "logps/chosen": -108.45407104492188,
      "logps/rejected": -152.08229064941406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.841676712036133,
      "rewards/margins": 9.54881477355957,
      "rewards/rejected": -5.707137584686279,
      "step": 3864
    },
    {
      "epoch": 1.546,
      "grad_norm": 2.377701759338379,
      "learning_rate": 4.848e-07,
      "logits/chosen": -2.0375404357910156,
      "logits/rejected": -3.4525372982025146,
      "logps/chosen": -192.0069122314453,
      "logps/rejected": -167.3802490234375,
      "loss": 0.015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6198413968086243,
      "rewards/margins": 6.692445755004883,
      "rewards/rejected": -7.312287330627441,
      "step": 3865
    },
    {
      "epoch": 1.5464,
      "grad_norm": 0.620551586151123,
      "learning_rate": 4.846666666666667e-07,
      "logits/chosen": -2.3089990615844727,
      "logits/rejected": -2.678816080093384,
      "logps/chosen": -135.0147705078125,
      "logps/rejected": -139.95822143554688,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3215692043304443,
      "rewards/margins": 7.675961971282959,
      "rewards/rejected": -6.354393005371094,
      "step": 3866
    },
    {
      "epoch": 1.5468,
      "grad_norm": 0.08972079306840897,
      "learning_rate": 4.845333333333333e-07,
      "logits/chosen": -2.22157621383667,
      "logits/rejected": -3.187272787094116,
      "logps/chosen": -113.4924545288086,
      "logps/rejected": -153.58741760253906,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4261776208877563,
      "rewards/margins": 8.136941909790039,
      "rewards/rejected": -6.710763931274414,
      "step": 3867
    },
    {
      "epoch": 1.5472000000000001,
      "grad_norm": 0.004083522595465183,
      "learning_rate": 4.844e-07,
      "logits/chosen": -2.000767707824707,
      "logits/rejected": -3.630098819732666,
      "logps/chosen": -92.76138305664062,
      "logps/rejected": -175.803466796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7240253686904907,
      "rewards/margins": 10.621737480163574,
      "rewards/rejected": -8.897712707519531,
      "step": 3868
    },
    {
      "epoch": 1.5476,
      "grad_norm": 0.678430438041687,
      "learning_rate": 4.842666666666667e-07,
      "logits/chosen": -1.5343998670578003,
      "logits/rejected": -2.7945804595947266,
      "logps/chosen": -107.94987487792969,
      "logps/rejected": -138.05091857910156,
      "loss": 0.0067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.03092232346534729,
      "rewards/margins": 5.345213413238525,
      "rewards/rejected": -5.37613582611084,
      "step": 3869
    },
    {
      "epoch": 1.548,
      "grad_norm": 0.12734362483024597,
      "learning_rate": 4.841333333333334e-07,
      "logits/chosen": -2.209123373031616,
      "logits/rejected": -3.7011475563049316,
      "logps/chosen": -108.98399353027344,
      "logps/rejected": -221.69549560546875,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2245526313781738,
      "rewards/margins": 10.763065338134766,
      "rewards/rejected": -9.53851318359375,
      "step": 3870
    },
    {
      "epoch": 1.5484,
      "grad_norm": 0.0049257781356573105,
      "learning_rate": 4.839999999999999e-07,
      "logits/chosen": -1.7812321186065674,
      "logits/rejected": -3.228058338165283,
      "logps/chosen": -118.54659271240234,
      "logps/rejected": -152.56271362304688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.388810634613037,
      "rewards/margins": 10.228797912597656,
      "rewards/rejected": -6.839986801147461,
      "step": 3871
    },
    {
      "epoch": 1.5488,
      "grad_norm": 0.04369117692112923,
      "learning_rate": 4.838666666666666e-07,
      "logits/chosen": -2.4367568492889404,
      "logits/rejected": -3.0638394355773926,
      "logps/chosen": -91.6021728515625,
      "logps/rejected": -151.1410369873047,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7427711486816406,
      "rewards/margins": 8.895347595214844,
      "rewards/rejected": -7.152576923370361,
      "step": 3872
    },
    {
      "epoch": 1.5492,
      "grad_norm": 0.0014995983801782131,
      "learning_rate": 4.837333333333333e-07,
      "logits/chosen": -2.234464645385742,
      "logits/rejected": -3.570399761199951,
      "logps/chosen": -137.38320922851562,
      "logps/rejected": -217.32418823242188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5150318145751953,
      "rewards/margins": 11.928691864013672,
      "rewards/rejected": -10.413660049438477,
      "step": 3873
    },
    {
      "epoch": 1.5495999999999999,
      "grad_norm": 0.06474640220403671,
      "learning_rate": 4.835999999999999e-07,
      "logits/chosen": -1.4934946298599243,
      "logits/rejected": -3.1405141353607178,
      "logps/chosen": -78.94100952148438,
      "logps/rejected": -175.22930908203125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1819792985916138,
      "rewards/margins": 9.387063980102539,
      "rewards/rejected": -8.205084800720215,
      "step": 3874
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.025481577962636948,
      "learning_rate": 4.834666666666666e-07,
      "logits/chosen": -2.2252559661865234,
      "logits/rejected": -3.1372690200805664,
      "logps/chosen": -153.00941467285156,
      "logps/rejected": -317.72406005859375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.36443638801574707,
      "rewards/margins": 8.78410530090332,
      "rewards/rejected": -9.148541450500488,
      "step": 3875
    },
    {
      "epoch": 1.5504,
      "grad_norm": 0.005239178892225027,
      "learning_rate": 4.833333333333333e-07,
      "logits/chosen": -2.2693519592285156,
      "logits/rejected": -3.131531238555908,
      "logps/chosen": -146.80029296875,
      "logps/rejected": -174.2047882080078,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3683719635009766,
      "rewards/margins": 10.02921199798584,
      "rewards/rejected": -7.660840034484863,
      "step": 3876
    },
    {
      "epoch": 1.5508,
      "grad_norm": 0.001184851978905499,
      "learning_rate": 4.832e-07,
      "logits/chosen": -1.8938465118408203,
      "logits/rejected": -3.5892868041992188,
      "logps/chosen": -98.14459991455078,
      "logps/rejected": -269.52459716796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8650012016296387,
      "rewards/margins": 12.489079475402832,
      "rewards/rejected": -8.624077796936035,
      "step": 3877
    },
    {
      "epoch": 1.5512000000000001,
      "grad_norm": 0.006710462737828493,
      "learning_rate": 4.830666666666666e-07,
      "logits/chosen": -2.2618842124938965,
      "logits/rejected": -3.251058578491211,
      "logps/chosen": -122.77088928222656,
      "logps/rejected": -170.49383544921875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.542323350906372,
      "rewards/margins": 9.734697341918945,
      "rewards/rejected": -7.192374229431152,
      "step": 3878
    },
    {
      "epoch": 1.5516,
      "grad_norm": 0.002583491150289774,
      "learning_rate": 4.829333333333333e-07,
      "logits/chosen": -2.1426033973693848,
      "logits/rejected": -3.606346845626831,
      "logps/chosen": -110.16867065429688,
      "logps/rejected": -172.72042846679688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.459500789642334,
      "rewards/margins": 11.28233528137207,
      "rewards/rejected": -7.8228349685668945,
      "step": 3879
    },
    {
      "epoch": 1.552,
      "grad_norm": 0.01162180956453085,
      "learning_rate": 4.828e-07,
      "logits/chosen": -1.987541675567627,
      "logits/rejected": -3.4354844093322754,
      "logps/chosen": -122.28996276855469,
      "logps/rejected": -203.28578186035156,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5732941627502441,
      "rewards/margins": 11.904581069946289,
      "rewards/rejected": -10.331287384033203,
      "step": 3880
    },
    {
      "epoch": 1.5524,
      "grad_norm": 0.014972959645092487,
      "learning_rate": 4.826666666666666e-07,
      "logits/chosen": -2.054624557495117,
      "logits/rejected": -3.338764190673828,
      "logps/chosen": -80.00694274902344,
      "logps/rejected": -161.4013671875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0699055194854736,
      "rewards/margins": 9.0479736328125,
      "rewards/rejected": -6.9780683517456055,
      "step": 3881
    },
    {
      "epoch": 1.5528,
      "grad_norm": 0.0013620645040646195,
      "learning_rate": 4.825333333333333e-07,
      "logits/chosen": -2.226637840270996,
      "logits/rejected": -3.2267937660217285,
      "logps/chosen": -94.84632110595703,
      "logps/rejected": -163.2088623046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.336276054382324,
      "rewards/margins": 11.313206672668457,
      "rewards/rejected": -6.976930618286133,
      "step": 3882
    },
    {
      "epoch": 1.5532,
      "grad_norm": 0.009033706970512867,
      "learning_rate": 4.823999999999999e-07,
      "logits/chosen": -2.111280679702759,
      "logits/rejected": -3.420572519302368,
      "logps/chosen": -156.72247314453125,
      "logps/rejected": -206.27159118652344,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0019783973693848,
      "rewards/margins": 10.420259475708008,
      "rewards/rejected": -8.418280601501465,
      "step": 3883
    },
    {
      "epoch": 1.5535999999999999,
      "grad_norm": 3.3176181316375732,
      "learning_rate": 4.822666666666666e-07,
      "logits/chosen": -2.208759069442749,
      "logits/rejected": -3.090237617492676,
      "logps/chosen": -95.17921447753906,
      "logps/rejected": -147.52931213378906,
      "loss": 0.0177,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.656479597091675,
      "rewards/margins": 7.362123489379883,
      "rewards/rejected": -4.705643653869629,
      "step": 3884
    },
    {
      "epoch": 1.554,
      "grad_norm": 0.3529191017150879,
      "learning_rate": 4.821333333333333e-07,
      "logits/chosen": -2.636418342590332,
      "logits/rejected": -3.192391872406006,
      "logps/chosen": -156.64593505859375,
      "logps/rejected": -180.62005615234375,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5603947043418884,
      "rewards/margins": 7.7340826988220215,
      "rewards/rejected": -7.173687934875488,
      "step": 3885
    },
    {
      "epoch": 1.5544,
      "grad_norm": 0.029762137681245804,
      "learning_rate": 4.82e-07,
      "logits/chosen": -2.457488536834717,
      "logits/rejected": -3.589310884475708,
      "logps/chosen": -206.73126220703125,
      "logps/rejected": -220.30078125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3585166931152344,
      "rewards/margins": 11.89564323425293,
      "rewards/rejected": -9.537126541137695,
      "step": 3886
    },
    {
      "epoch": 1.5548,
      "grad_norm": 0.05393382906913757,
      "learning_rate": 4.818666666666667e-07,
      "logits/chosen": -1.6327242851257324,
      "logits/rejected": -2.8175413608551025,
      "logps/chosen": -116.17144775390625,
      "logps/rejected": -170.475830078125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.284456968307495,
      "rewards/margins": 9.930962562561035,
      "rewards/rejected": -7.646505355834961,
      "step": 3887
    },
    {
      "epoch": 1.5552000000000001,
      "grad_norm": 0.06408354640007019,
      "learning_rate": 4.817333333333333e-07,
      "logits/chosen": -2.0763134956359863,
      "logits/rejected": -3.001858711242676,
      "logps/chosen": -159.088623046875,
      "logps/rejected": -163.68988037109375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.014129161834717,
      "rewards/margins": 8.599749565124512,
      "rewards/rejected": -6.585620403289795,
      "step": 3888
    },
    {
      "epoch": 1.5556,
      "grad_norm": 0.007856542244553566,
      "learning_rate": 4.816e-07,
      "logits/chosen": -2.405146598815918,
      "logits/rejected": -3.083461284637451,
      "logps/chosen": -80.54540252685547,
      "logps/rejected": -141.35565185546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5945281982421875,
      "rewards/margins": 9.665252685546875,
      "rewards/rejected": -6.070725440979004,
      "step": 3889
    },
    {
      "epoch": 1.556,
      "grad_norm": 0.05852911248803139,
      "learning_rate": 4.814666666666667e-07,
      "logits/chosen": -1.6037236452102661,
      "logits/rejected": -3.3437697887420654,
      "logps/chosen": -113.94742584228516,
      "logps/rejected": -169.9646453857422,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7607097625732422,
      "rewards/margins": 7.777716636657715,
      "rewards/rejected": -7.017006874084473,
      "step": 3890
    },
    {
      "epoch": 1.5564,
      "grad_norm": 0.004727870225906372,
      "learning_rate": 4.813333333333334e-07,
      "logits/chosen": -1.9866044521331787,
      "logits/rejected": -3.1325011253356934,
      "logps/chosen": -65.49951171875,
      "logps/rejected": -157.87661743164062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.466339111328125,
      "rewards/margins": 10.983145713806152,
      "rewards/rejected": -7.516806602478027,
      "step": 3891
    },
    {
      "epoch": 1.5568,
      "grad_norm": 0.010577875189483166,
      "learning_rate": 4.812e-07,
      "logits/chosen": -1.7563972473144531,
      "logits/rejected": -3.4964208602905273,
      "logps/chosen": -93.02389526367188,
      "logps/rejected": -207.99658203125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.541341781616211,
      "rewards/margins": 10.147489547729492,
      "rewards/rejected": -8.606147766113281,
      "step": 3892
    },
    {
      "epoch": 1.5572,
      "grad_norm": 0.17093001306056976,
      "learning_rate": 4.810666666666666e-07,
      "logits/chosen": -1.9427626132965088,
      "logits/rejected": -3.602602481842041,
      "logps/chosen": -113.96038818359375,
      "logps/rejected": -223.63827514648438,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6393848657608032,
      "rewards/margins": 10.541485786437988,
      "rewards/rejected": -8.902100563049316,
      "step": 3893
    },
    {
      "epoch": 1.5575999999999999,
      "grad_norm": 0.15133802592754364,
      "learning_rate": 4.809333333333333e-07,
      "logits/chosen": -2.093440055847168,
      "logits/rejected": -3.390315532684326,
      "logps/chosen": -165.46292114257812,
      "logps/rejected": -186.40396118164062,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.48970264196395874,
      "rewards/margins": 7.975879669189453,
      "rewards/rejected": -7.486176490783691,
      "step": 3894
    },
    {
      "epoch": 1.558,
      "grad_norm": 0.0008628173382021487,
      "learning_rate": 4.808e-07,
      "logits/chosen": -2.5785281658172607,
      "logits/rejected": -3.0065531730651855,
      "logps/chosen": -167.57855224609375,
      "logps/rejected": -185.1548309326172,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.758894920349121,
      "rewards/margins": 12.097050666809082,
      "rewards/rejected": -8.338155746459961,
      "step": 3895
    },
    {
      "epoch": 1.5584,
      "grad_norm": 0.0013871063711121678,
      "learning_rate": 4.806666666666667e-07,
      "logits/chosen": -2.263833999633789,
      "logits/rejected": -3.1750216484069824,
      "logps/chosen": -98.54542541503906,
      "logps/rejected": -190.80355834960938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6352248191833496,
      "rewards/margins": 12.54190731048584,
      "rewards/rejected": -8.906682968139648,
      "step": 3896
    },
    {
      "epoch": 1.5588,
      "grad_norm": 0.03853878378868103,
      "learning_rate": 4.805333333333333e-07,
      "logits/chosen": -2.5789589881896973,
      "logits/rejected": -3.65470552444458,
      "logps/chosen": -189.81019592285156,
      "logps/rejected": -188.5951385498047,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7423689365386963,
      "rewards/margins": 11.200655937194824,
      "rewards/rejected": -8.45828628540039,
      "step": 3897
    },
    {
      "epoch": 1.5592000000000001,
      "grad_norm": 0.010567176155745983,
      "learning_rate": 4.804e-07,
      "logits/chosen": -2.4285521507263184,
      "logits/rejected": -3.465078115463257,
      "logps/chosen": -121.92925262451172,
      "logps/rejected": -184.30841064453125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.43988037109375,
      "rewards/margins": 11.42223072052002,
      "rewards/rejected": -8.98235034942627,
      "step": 3898
    },
    {
      "epoch": 1.5596,
      "grad_norm": 0.011698187328875065,
      "learning_rate": 4.802666666666667e-07,
      "logits/chosen": -2.3157758712768555,
      "logits/rejected": -3.0684590339660645,
      "logps/chosen": -94.74150848388672,
      "logps/rejected": -217.4212646484375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.112774848937988,
      "rewards/margins": 10.715618133544922,
      "rewards/rejected": -6.602842330932617,
      "step": 3899
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.30840155482292175,
      "learning_rate": 4.801333333333334e-07,
      "logits/chosen": -2.5474753379821777,
      "logits/rejected": -3.0584025382995605,
      "logps/chosen": -146.25279235839844,
      "logps/rejected": -172.14434814453125,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1650612354278564,
      "rewards/margins": 8.18089771270752,
      "rewards/rejected": -7.015836715698242,
      "step": 3900
    },
    {
      "epoch": 1.5604,
      "grad_norm": 0.03468659147620201,
      "learning_rate": 4.8e-07,
      "logits/chosen": -2.290818214416504,
      "logits/rejected": -3.2481367588043213,
      "logps/chosen": -163.32272338867188,
      "logps/rejected": -167.83731079101562,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.602307915687561,
      "rewards/margins": 8.642097473144531,
      "rewards/rejected": -8.039789199829102,
      "step": 3901
    },
    {
      "epoch": 1.5608,
      "grad_norm": 0.09977506101131439,
      "learning_rate": 4.798666666666666e-07,
      "logits/chosen": -1.9727308750152588,
      "logits/rejected": -3.019421100616455,
      "logps/chosen": -149.69561767578125,
      "logps/rejected": -274.4483642578125,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.44570887088775635,
      "rewards/margins": 7.576349258422852,
      "rewards/rejected": -7.130640506744385,
      "step": 3902
    },
    {
      "epoch": 1.5612,
      "grad_norm": 0.012496490962803364,
      "learning_rate": 4.797333333333333e-07,
      "logits/chosen": -2.271981716156006,
      "logits/rejected": -3.643012523651123,
      "logps/chosen": -138.20523071289062,
      "logps/rejected": -179.3705291748047,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5070220232009888,
      "rewards/margins": 10.373555183410645,
      "rewards/rejected": -8.866533279418945,
      "step": 3903
    },
    {
      "epoch": 1.5615999999999999,
      "grad_norm": 0.0142076900228858,
      "learning_rate": 4.796e-07,
      "logits/chosen": -1.991133213043213,
      "logits/rejected": -3.202693462371826,
      "logps/chosen": -122.40376281738281,
      "logps/rejected": -166.9932861328125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8565540313720703,
      "rewards/margins": 9.086048126220703,
      "rewards/rejected": -7.229494094848633,
      "step": 3904
    },
    {
      "epoch": 1.562,
      "grad_norm": 0.08235398679971695,
      "learning_rate": 4.794666666666666e-07,
      "logits/chosen": -1.6175110340118408,
      "logits/rejected": -3.1160168647766113,
      "logps/chosen": -145.96363830566406,
      "logps/rejected": -175.3660430908203,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4320231676101685,
      "rewards/margins": 7.940359115600586,
      "rewards/rejected": -6.508336067199707,
      "step": 3905
    },
    {
      "epoch": 1.5624,
      "grad_norm": 0.021827686578035355,
      "learning_rate": 4.793333333333333e-07,
      "logits/chosen": -2.068399667739868,
      "logits/rejected": -3.369946002960205,
      "logps/chosen": -85.37754821777344,
      "logps/rejected": -151.10580444335938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.428513526916504,
      "rewards/margins": 9.741344451904297,
      "rewards/rejected": -6.312831878662109,
      "step": 3906
    },
    {
      "epoch": 1.5628,
      "grad_norm": 0.017768731340765953,
      "learning_rate": 4.792e-07,
      "logits/chosen": -1.8236712217330933,
      "logits/rejected": -3.217456817626953,
      "logps/chosen": -148.97186279296875,
      "logps/rejected": -215.644287109375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0023937225341797,
      "rewards/margins": 10.160106658935547,
      "rewards/rejected": -8.157712936401367,
      "step": 3907
    },
    {
      "epoch": 1.5632000000000001,
      "grad_norm": 0.00873126182705164,
      "learning_rate": 4.790666666666666e-07,
      "logits/chosen": -3.1179728507995605,
      "logits/rejected": -2.857640266418457,
      "logps/chosen": -174.8250274658203,
      "logps/rejected": -261.27032470703125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20948100090026855,
      "rewards/margins": 9.762653350830078,
      "rewards/rejected": -9.553173065185547,
      "step": 3908
    },
    {
      "epoch": 1.5636,
      "grad_norm": 0.19135434925556183,
      "learning_rate": 4.789333333333333e-07,
      "logits/chosen": -2.0862255096435547,
      "logits/rejected": -3.449660062789917,
      "logps/chosen": -160.7661590576172,
      "logps/rejected": -158.93841552734375,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.739362359046936,
      "rewards/margins": 7.466331481933594,
      "rewards/rejected": -5.726969242095947,
      "step": 3909
    },
    {
      "epoch": 1.564,
      "grad_norm": 0.0007439851760864258,
      "learning_rate": 4.788e-07,
      "logits/chosen": -2.2246475219726562,
      "logits/rejected": -3.4330878257751465,
      "logps/chosen": -214.01095581054688,
      "logps/rejected": -229.72007751464844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2490906715393066,
      "rewards/margins": 12.524482727050781,
      "rewards/rejected": -10.275392532348633,
      "step": 3910
    },
    {
      "epoch": 1.5644,
      "grad_norm": 0.033081021159887314,
      "learning_rate": 4.786666666666667e-07,
      "logits/chosen": -2.1335058212280273,
      "logits/rejected": -3.009892463684082,
      "logps/chosen": -132.26821899414062,
      "logps/rejected": -161.72317504882812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8928589820861816,
      "rewards/margins": 8.484696388244629,
      "rewards/rejected": -6.591837406158447,
      "step": 3911
    },
    {
      "epoch": 1.5648,
      "grad_norm": 0.0021368637681007385,
      "learning_rate": 4.785333333333333e-07,
      "logits/chosen": -1.9177565574645996,
      "logits/rejected": -3.3354620933532715,
      "logps/chosen": -133.36611938476562,
      "logps/rejected": -224.2172088623047,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9541015625,
      "rewards/margins": 11.848302841186523,
      "rewards/rejected": -9.894201278686523,
      "step": 3912
    },
    {
      "epoch": 1.5652,
      "grad_norm": 0.016728969290852547,
      "learning_rate": 4.783999999999999e-07,
      "logits/chosen": -2.0398426055908203,
      "logits/rejected": -3.297008514404297,
      "logps/chosen": -124.12458038330078,
      "logps/rejected": -190.42822265625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.855542778968811,
      "rewards/margins": 11.192204475402832,
      "rewards/rejected": -9.336662292480469,
      "step": 3913
    },
    {
      "epoch": 1.5655999999999999,
      "grad_norm": 0.05512329190969467,
      "learning_rate": 4.782666666666666e-07,
      "logits/chosen": -2.479320526123047,
      "logits/rejected": -3.6385045051574707,
      "logps/chosen": -210.70635986328125,
      "logps/rejected": -207.2313232421875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.180293560028076,
      "rewards/margins": 9.532649040222168,
      "rewards/rejected": -7.352355480194092,
      "step": 3914
    },
    {
      "epoch": 1.5659999999999998,
      "grad_norm": 0.010841850191354752,
      "learning_rate": 4.781333333333333e-07,
      "logits/chosen": -1.558415412902832,
      "logits/rejected": -3.6207892894744873,
      "logps/chosen": -163.78775024414062,
      "logps/rejected": -193.22900390625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0869569778442383,
      "rewards/margins": 10.221136093139648,
      "rewards/rejected": -8.13417911529541,
      "step": 3915
    },
    {
      "epoch": 1.5664,
      "grad_norm": 0.010714027099311352,
      "learning_rate": 4.779999999999999e-07,
      "logits/chosen": -2.4572806358337402,
      "logits/rejected": -2.622570753097534,
      "logps/chosen": -123.7708740234375,
      "logps/rejected": -175.70799255371094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2204957008361816,
      "rewards/margins": 10.032011032104492,
      "rewards/rejected": -6.811514854431152,
      "step": 3916
    },
    {
      "epoch": 1.5668,
      "grad_norm": 0.0011314192088320851,
      "learning_rate": 4.778666666666666e-07,
      "logits/chosen": -1.958418607711792,
      "logits/rejected": -3.411215305328369,
      "logps/chosen": -113.67497253417969,
      "logps/rejected": -183.7699737548828,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3378636837005615,
      "rewards/margins": 11.896276473999023,
      "rewards/rejected": -8.558412551879883,
      "step": 3917
    },
    {
      "epoch": 1.5672000000000001,
      "grad_norm": 0.26766443252563477,
      "learning_rate": 4.777333333333333e-07,
      "logits/chosen": -1.754658818244934,
      "logits/rejected": -3.1014416217803955,
      "logps/chosen": -153.48936462402344,
      "logps/rejected": -147.92897033691406,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2510342597961426,
      "rewards/margins": 7.405703067779541,
      "rewards/rejected": -6.154668807983398,
      "step": 3918
    },
    {
      "epoch": 1.5676,
      "grad_norm": 0.21848994493484497,
      "learning_rate": 4.776e-07,
      "logits/chosen": -2.3833847045898438,
      "logits/rejected": -2.9883267879486084,
      "logps/chosen": -98.1166000366211,
      "logps/rejected": -126.2147445678711,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9842731356620789,
      "rewards/margins": 6.3220672607421875,
      "rewards/rejected": -5.337794303894043,
      "step": 3919
    },
    {
      "epoch": 1.568,
      "grad_norm": 0.1448034644126892,
      "learning_rate": 4.774666666666667e-07,
      "logits/chosen": -2.687070369720459,
      "logits/rejected": -3.684674024581909,
      "logps/chosen": -265.0805969238281,
      "logps/rejected": -220.3767852783203,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.10341739654541,
      "rewards/margins": 9.410246849060059,
      "rewards/rejected": -7.306829452514648,
      "step": 3920
    },
    {
      "epoch": 1.5684,
      "grad_norm": 0.18370221555233002,
      "learning_rate": 4.773333333333333e-07,
      "logits/chosen": -1.8084056377410889,
      "logits/rejected": -2.4501802921295166,
      "logps/chosen": -85.56204223632812,
      "logps/rejected": -129.81655883789062,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2192257046699524,
      "rewards/margins": 6.782125473022461,
      "rewards/rejected": -6.562900066375732,
      "step": 3921
    },
    {
      "epoch": 1.5688,
      "grad_norm": 0.004411245230585337,
      "learning_rate": 4.772e-07,
      "logits/chosen": -1.5556492805480957,
      "logits/rejected": -3.25602388381958,
      "logps/chosen": -94.18138122558594,
      "logps/rejected": -173.75436401367188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.672783613204956,
      "rewards/margins": 10.748693466186523,
      "rewards/rejected": -7.0759100914001465,
      "step": 3922
    },
    {
      "epoch": 1.5692,
      "grad_norm": 0.014910905621945858,
      "learning_rate": 4.770666666666667e-07,
      "logits/chosen": -2.5014588832855225,
      "logits/rejected": -2.959567070007324,
      "logps/chosen": -157.03240966796875,
      "logps/rejected": -225.05154418945312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0053749084472656,
      "rewards/margins": 11.551231384277344,
      "rewards/rejected": -8.545856475830078,
      "step": 3923
    },
    {
      "epoch": 1.5695999999999999,
      "grad_norm": 0.016136644408106804,
      "learning_rate": 4.769333333333333e-07,
      "logits/chosen": -1.7232482433319092,
      "logits/rejected": -3.4539904594421387,
      "logps/chosen": -75.5140609741211,
      "logps/rejected": -155.76742553710938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.135089874267578,
      "rewards/margins": 9.247428894042969,
      "rewards/rejected": -7.112338066101074,
      "step": 3924
    },
    {
      "epoch": 1.5699999999999998,
      "grad_norm": 0.2337241917848587,
      "learning_rate": 4.768e-07,
      "logits/chosen": -2.1533443927764893,
      "logits/rejected": -3.2551276683807373,
      "logps/chosen": -124.88772583007812,
      "logps/rejected": -170.63352966308594,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5437159538269043,
      "rewards/margins": 9.687935829162598,
      "rewards/rejected": -8.144220352172852,
      "step": 3925
    },
    {
      "epoch": 1.5704,
      "grad_norm": 1.653485655784607,
      "learning_rate": 4.7666666666666667e-07,
      "logits/chosen": -2.263815402984619,
      "logits/rejected": -3.359556198120117,
      "logps/chosen": -139.24441528320312,
      "logps/rejected": -207.87020874023438,
      "loss": 0.0122,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3536616563796997,
      "rewards/margins": 7.478902339935303,
      "rewards/rejected": -6.125240325927734,
      "step": 3926
    },
    {
      "epoch": 1.5708,
      "grad_norm": 0.08463341742753983,
      "learning_rate": 4.765333333333333e-07,
      "logits/chosen": -2.2711238861083984,
      "logits/rejected": -3.815185546875,
      "logps/chosen": -130.80776977539062,
      "logps/rejected": -228.01992797851562,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13891029357910156,
      "rewards/margins": 7.530786037445068,
      "rewards/rejected": -7.391875743865967,
      "step": 3927
    },
    {
      "epoch": 1.5712000000000002,
      "grad_norm": 0.0018718531355261803,
      "learning_rate": 4.7639999999999995e-07,
      "logits/chosen": -1.728570580482483,
      "logits/rejected": -3.3937296867370605,
      "logps/chosen": -150.81776428222656,
      "logps/rejected": -218.75527954101562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4278995990753174,
      "rewards/margins": 11.49077320098877,
      "rewards/rejected": -9.062873840332031,
      "step": 3928
    },
    {
      "epoch": 1.5716,
      "grad_norm": 0.07511715590953827,
      "learning_rate": 4.7626666666666664e-07,
      "logits/chosen": -2.271573066711426,
      "logits/rejected": -3.151273250579834,
      "logps/chosen": -71.02787017822266,
      "logps/rejected": -189.59124755859375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5785980224609375,
      "rewards/margins": 10.273531913757324,
      "rewards/rejected": -8.694933891296387,
      "step": 3929
    },
    {
      "epoch": 1.572,
      "grad_norm": 0.00961043406277895,
      "learning_rate": 4.7613333333333334e-07,
      "logits/chosen": -2.4595370292663574,
      "logits/rejected": -3.3125100135803223,
      "logps/chosen": -113.78311157226562,
      "logps/rejected": -168.93380737304688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.071014881134033,
      "rewards/margins": 11.794187545776367,
      "rewards/rejected": -7.723173141479492,
      "step": 3930
    },
    {
      "epoch": 1.5724,
      "grad_norm": 0.09111010283231735,
      "learning_rate": 4.76e-07,
      "logits/chosen": -1.8421286344528198,
      "logits/rejected": -3.3316574096679688,
      "logps/chosen": -96.10195922851562,
      "logps/rejected": -166.51925659179688,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5469684600830078,
      "rewards/margins": 9.607291221618652,
      "rewards/rejected": -8.060322761535645,
      "step": 3931
    },
    {
      "epoch": 1.5728,
      "grad_norm": 0.24445083737373352,
      "learning_rate": 4.758666666666666e-07,
      "logits/chosen": -1.9458043575286865,
      "logits/rejected": -2.8391661643981934,
      "logps/chosen": -161.3649444580078,
      "logps/rejected": -155.65426635742188,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.683615803718567,
      "rewards/margins": 7.930120944976807,
      "rewards/rejected": -6.246505260467529,
      "step": 3932
    },
    {
      "epoch": 1.5732,
      "grad_norm": 0.0022529293783009052,
      "learning_rate": 4.757333333333333e-07,
      "logits/chosen": -2.102994203567505,
      "logits/rejected": -3.567336320877075,
      "logps/chosen": -118.21591186523438,
      "logps/rejected": -235.82183837890625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6812251806259155,
      "rewards/margins": 11.925705909729004,
      "rewards/rejected": -11.244481086730957,
      "step": 3933
    },
    {
      "epoch": 1.5735999999999999,
      "grad_norm": 0.0030398776289075613,
      "learning_rate": 4.756e-07,
      "logits/chosen": -2.533806324005127,
      "logits/rejected": -3.7524595260620117,
      "logps/chosen": -135.9835968017578,
      "logps/rejected": -193.81954956054688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5116984844207764,
      "rewards/margins": 11.039857864379883,
      "rewards/rejected": -8.528159141540527,
      "step": 3934
    },
    {
      "epoch": 1.5739999999999998,
      "grad_norm": 0.014337984845042229,
      "learning_rate": 4.7546666666666664e-07,
      "logits/chosen": -2.173074722290039,
      "logits/rejected": -3.69374680519104,
      "logps/chosen": -235.3054656982422,
      "logps/rejected": -182.7783966064453,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5573684573173523,
      "rewards/margins": 9.71310806274414,
      "rewards/rejected": -9.155739784240723,
      "step": 3935
    },
    {
      "epoch": 1.5744,
      "grad_norm": 0.007434857077896595,
      "learning_rate": 4.7533333333333333e-07,
      "logits/chosen": -2.0358998775482178,
      "logits/rejected": -3.340773105621338,
      "logps/chosen": -99.44564819335938,
      "logps/rejected": -165.2564239501953,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2782819271087646,
      "rewards/margins": 9.562887191772461,
      "rewards/rejected": -7.284605979919434,
      "step": 3936
    },
    {
      "epoch": 1.5748,
      "grad_norm": 0.16896729171276093,
      "learning_rate": 4.7519999999999997e-07,
      "logits/chosen": -1.7768480777740479,
      "logits/rejected": -3.2648534774780273,
      "logps/chosen": -144.28167724609375,
      "logps/rejected": -157.04029846191406,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5891075730323792,
      "rewards/margins": 6.631378173828125,
      "rewards/rejected": -7.220485687255859,
      "step": 3937
    },
    {
      "epoch": 1.5752000000000002,
      "grad_norm": 0.5445955991744995,
      "learning_rate": 4.7506666666666666e-07,
      "logits/chosen": -1.9814568758010864,
      "logits/rejected": -3.2725491523742676,
      "logps/chosen": -99.23213195800781,
      "logps/rejected": -153.75579833984375,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.697228193283081,
      "rewards/margins": 8.82452392578125,
      "rewards/rejected": -7.12729549407959,
      "step": 3938
    },
    {
      "epoch": 1.5756000000000001,
      "grad_norm": 0.027923448011279106,
      "learning_rate": 4.749333333333333e-07,
      "logits/chosen": -2.28464937210083,
      "logits/rejected": -3.667520523071289,
      "logps/chosen": -91.3603744506836,
      "logps/rejected": -174.1982421875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.580560326576233,
      "rewards/margins": 8.69577407836914,
      "rewards/rejected": -7.115212917327881,
      "step": 3939
    },
    {
      "epoch": 1.576,
      "grad_norm": 0.2890479266643524,
      "learning_rate": 4.748e-07,
      "logits/chosen": -2.542634963989258,
      "logits/rejected": -3.0612049102783203,
      "logps/chosen": -119.50292205810547,
      "logps/rejected": -215.72299194335938,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6736236810684204,
      "rewards/margins": 9.144453048706055,
      "rewards/rejected": -8.470829963684082,
      "step": 3940
    },
    {
      "epoch": 1.5764,
      "grad_norm": 0.35800302028656006,
      "learning_rate": 4.746666666666667e-07,
      "logits/chosen": -2.8771533966064453,
      "logits/rejected": -2.9081130027770996,
      "logps/chosen": -152.756591796875,
      "logps/rejected": -213.23455810546875,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5774296522140503,
      "rewards/margins": 8.32827091217041,
      "rewards/rejected": -7.75084114074707,
      "step": 3941
    },
    {
      "epoch": 1.5768,
      "grad_norm": 0.002816166263073683,
      "learning_rate": 4.7453333333333327e-07,
      "logits/chosen": -1.5347967147827148,
      "logits/rejected": -3.0198769569396973,
      "logps/chosen": -64.63113403320312,
      "logps/rejected": -188.4689483642578,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9441620111465454,
      "rewards/margins": 10.892505645751953,
      "rewards/rejected": -8.948344230651855,
      "step": 3942
    },
    {
      "epoch": 1.5772,
      "grad_norm": 0.042760223150253296,
      "learning_rate": 4.7439999999999996e-07,
      "logits/chosen": -1.8415640592575073,
      "logits/rejected": -2.998955249786377,
      "logps/chosen": -100.55699157714844,
      "logps/rejected": -167.1179962158203,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7805657386779785,
      "rewards/margins": 9.375560760498047,
      "rewards/rejected": -7.594995498657227,
      "step": 3943
    },
    {
      "epoch": 1.5776,
      "grad_norm": 0.22670157253742218,
      "learning_rate": 4.7426666666666665e-07,
      "logits/chosen": -2.0138823986053467,
      "logits/rejected": -3.016881227493286,
      "logps/chosen": -130.018798828125,
      "logps/rejected": -170.22647094726562,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1299498081207275,
      "rewards/margins": 9.203853607177734,
      "rewards/rejected": -7.073904037475586,
      "step": 3944
    },
    {
      "epoch": 1.5779999999999998,
      "grad_norm": 4.666893005371094,
      "learning_rate": 4.7413333333333334e-07,
      "logits/chosen": -2.3835628032684326,
      "logits/rejected": -4.035396575927734,
      "logps/chosen": -224.277099609375,
      "logps/rejected": -189.94854736328125,
      "loss": 0.0267,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4338585138320923,
      "rewards/margins": 8.615033149719238,
      "rewards/rejected": -9.0488920211792,
      "step": 3945
    },
    {
      "epoch": 1.5784,
      "grad_norm": 0.023580390959978104,
      "learning_rate": 4.7399999999999993e-07,
      "logits/chosen": -2.113095760345459,
      "logits/rejected": -2.5789084434509277,
      "logps/chosen": -167.29051208496094,
      "logps/rejected": -199.89955139160156,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0875191688537598,
      "rewards/margins": 9.64857292175293,
      "rewards/rejected": -7.561054229736328,
      "step": 3946
    },
    {
      "epoch": 1.5788,
      "grad_norm": 0.1351233571767807,
      "learning_rate": 4.738666666666666e-07,
      "logits/chosen": -2.501537799835205,
      "logits/rejected": -3.8313252925872803,
      "logps/chosen": -154.7493896484375,
      "logps/rejected": -181.75942993164062,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0759735107421875,
      "rewards/margins": 7.5762457847595215,
      "rewards/rejected": -7.652219772338867,
      "step": 3947
    },
    {
      "epoch": 1.5792000000000002,
      "grad_norm": 0.025726547464728355,
      "learning_rate": 4.737333333333333e-07,
      "logits/chosen": -2.4109621047973633,
      "logits/rejected": -3.875462055206299,
      "logps/chosen": -239.94015502929688,
      "logps/rejected": -187.34927368164062,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4530458450317383,
      "rewards/margins": 9.452495574951172,
      "rewards/rejected": -6.999449729919434,
      "step": 3948
    },
    {
      "epoch": 1.5796000000000001,
      "grad_norm": 0.002407953841611743,
      "learning_rate": 4.736e-07,
      "logits/chosen": -2.5007119178771973,
      "logits/rejected": -3.3809890747070312,
      "logps/chosen": -157.5856170654297,
      "logps/rejected": -204.84072875976562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.689692735671997,
      "rewards/margins": 11.406707763671875,
      "rewards/rejected": -8.71701431274414,
      "step": 3949
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.1894179582595825,
      "learning_rate": 4.7346666666666664e-07,
      "logits/chosen": -2.1314597129821777,
      "logits/rejected": -3.0321645736694336,
      "logps/chosen": -121.07991027832031,
      "logps/rejected": -156.94757080078125,
      "loss": 0.0051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5128933191299438,
      "rewards/margins": 5.773804664611816,
      "rewards/rejected": -6.2866973876953125,
      "step": 3950
    },
    {
      "epoch": 1.5804,
      "grad_norm": 0.006550812162458897,
      "learning_rate": 4.733333333333333e-07,
      "logits/chosen": -2.594083309173584,
      "logits/rejected": -3.5950937271118164,
      "logps/chosen": -167.35964965820312,
      "logps/rejected": -207.615234375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4830565452575684,
      "rewards/margins": 11.457939147949219,
      "rewards/rejected": -8.974883079528809,
      "step": 3951
    },
    {
      "epoch": 1.5808,
      "grad_norm": 0.0937238484621048,
      "learning_rate": 4.732e-07,
      "logits/chosen": -2.1972923278808594,
      "logits/rejected": -2.5795578956604004,
      "logps/chosen": -152.85678100585938,
      "logps/rejected": -246.09869384765625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3676254749298096,
      "rewards/margins": 8.030767440795898,
      "rewards/rejected": -6.663142204284668,
      "step": 3952
    },
    {
      "epoch": 1.5812,
      "grad_norm": 0.14959441125392914,
      "learning_rate": 4.7306666666666667e-07,
      "logits/chosen": -2.0670673847198486,
      "logits/rejected": -2.899354934692383,
      "logps/chosen": -152.6522216796875,
      "logps/rejected": -172.75698852539062,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6692177057266235,
      "rewards/margins": 8.259490013122559,
      "rewards/rejected": -7.590272426605225,
      "step": 3953
    },
    {
      "epoch": 1.5816,
      "grad_norm": 0.017292391508817673,
      "learning_rate": 4.729333333333333e-07,
      "logits/chosen": -2.378228187561035,
      "logits/rejected": -3.7688827514648438,
      "logps/chosen": -110.38047790527344,
      "logps/rejected": -159.69175720214844,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3864128589630127,
      "rewards/margins": 8.849251747131348,
      "rewards/rejected": -7.462839126586914,
      "step": 3954
    },
    {
      "epoch": 1.5819999999999999,
      "grad_norm": 1.5327287912368774,
      "learning_rate": 4.728e-07,
      "logits/chosen": -2.3010294437408447,
      "logits/rejected": -2.956855535507202,
      "logps/chosen": -127.92416381835938,
      "logps/rejected": -129.01785278320312,
      "loss": 0.0111,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5049992203712463,
      "rewards/margins": 5.1722869873046875,
      "rewards/rejected": -5.677286148071289,
      "step": 3955
    },
    {
      "epoch": 1.5824,
      "grad_norm": 5.5403157602995634e-05,
      "learning_rate": 4.7266666666666664e-07,
      "logits/chosen": -2.3154244422912598,
      "logits/rejected": -3.814028263092041,
      "logps/chosen": -117.94377136230469,
      "logps/rejected": -233.22244262695312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 6.07301664352417,
      "rewards/margins": 15.674227714538574,
      "rewards/rejected": -9.601210594177246,
      "step": 3956
    },
    {
      "epoch": 1.5828,
      "grad_norm": 0.004485039040446281,
      "learning_rate": 4.7253333333333333e-07,
      "logits/chosen": -2.2890429496765137,
      "logits/rejected": -3.474445343017578,
      "logps/chosen": -73.49455261230469,
      "logps/rejected": -163.00628662109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.551365852355957,
      "rewards/margins": 10.893285751342773,
      "rewards/rejected": -7.341920852661133,
      "step": 3957
    },
    {
      "epoch": 1.5832000000000002,
      "grad_norm": 0.5207690596580505,
      "learning_rate": 4.7239999999999997e-07,
      "logits/chosen": -2.0871713161468506,
      "logits/rejected": -3.1617064476013184,
      "logps/chosen": -147.71295166015625,
      "logps/rejected": -196.97134399414062,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.768022298812866,
      "rewards/margins": 11.25214672088623,
      "rewards/rejected": -8.484124183654785,
      "step": 3958
    },
    {
      "epoch": 1.5836000000000001,
      "grad_norm": 0.47506895661354065,
      "learning_rate": 4.7226666666666666e-07,
      "logits/chosen": -2.1342525482177734,
      "logits/rejected": -3.427374839782715,
      "logps/chosen": -102.96343231201172,
      "logps/rejected": -178.98338317871094,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3104889392852783,
      "rewards/margins": 7.7018938064575195,
      "rewards/rejected": -8.012382507324219,
      "step": 3959
    },
    {
      "epoch": 1.584,
      "grad_norm": 0.001826004241593182,
      "learning_rate": 4.7213333333333335e-07,
      "logits/chosen": -2.259305953979492,
      "logits/rejected": -3.1339802742004395,
      "logps/chosen": -148.9390106201172,
      "logps/rejected": -171.78456115722656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.737506151199341,
      "rewards/margins": 11.146478652954102,
      "rewards/rejected": -8.408973693847656,
      "step": 3960
    },
    {
      "epoch": 1.5844,
      "grad_norm": 0.014900938607752323,
      "learning_rate": 4.7199999999999994e-07,
      "logits/chosen": -1.8371005058288574,
      "logits/rejected": -3.111948013305664,
      "logps/chosen": -97.73365020751953,
      "logps/rejected": -160.0568389892578,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3904495239257812,
      "rewards/margins": 9.643548011779785,
      "rewards/rejected": -7.253098487854004,
      "step": 3961
    },
    {
      "epoch": 1.5848,
      "grad_norm": 0.0006341373082250357,
      "learning_rate": 4.7186666666666663e-07,
      "logits/chosen": -2.416769504547119,
      "logits/rejected": -3.487065315246582,
      "logps/chosen": -129.8424530029297,
      "logps/rejected": -199.80670166015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2043683528900146,
      "rewards/margins": 13.034730911254883,
      "rewards/rejected": -9.830362319946289,
      "step": 3962
    },
    {
      "epoch": 1.5852,
      "grad_norm": 0.0017179300775751472,
      "learning_rate": 4.717333333333333e-07,
      "logits/chosen": -2.37054443359375,
      "logits/rejected": -3.242581844329834,
      "logps/chosen": -161.7388916015625,
      "logps/rejected": -209.1246795654297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.790431261062622,
      "rewards/margins": 11.185730934143066,
      "rewards/rejected": -9.395299911499023,
      "step": 3963
    },
    {
      "epoch": 1.5856,
      "grad_norm": 0.02293459139764309,
      "learning_rate": 4.716e-07,
      "logits/chosen": -2.447096347808838,
      "logits/rejected": -3.6486144065856934,
      "logps/chosen": -237.13369750976562,
      "logps/rejected": -204.2664794921875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6587257385253906,
      "rewards/margins": 8.931958198547363,
      "rewards/rejected": -10.590683937072754,
      "step": 3964
    },
    {
      "epoch": 1.5859999999999999,
      "grad_norm": 0.1641302853822708,
      "learning_rate": 4.714666666666666e-07,
      "logits/chosen": -1.9233921766281128,
      "logits/rejected": -3.706907033920288,
      "logps/chosen": -124.41465759277344,
      "logps/rejected": -168.92440795898438,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2504638731479645,
      "rewards/margins": 6.784425258636475,
      "rewards/rejected": -7.034889221191406,
      "step": 3965
    },
    {
      "epoch": 1.5864,
      "grad_norm": 0.10574320703744888,
      "learning_rate": 4.713333333333333e-07,
      "logits/chosen": -2.488239288330078,
      "logits/rejected": -3.026237964630127,
      "logps/chosen": -242.04837036132812,
      "logps/rejected": -235.21450805664062,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8421058654785156,
      "rewards/margins": 8.73755931854248,
      "rewards/rejected": -7.895453453063965,
      "step": 3966
    },
    {
      "epoch": 1.5868,
      "grad_norm": 0.02198965474963188,
      "learning_rate": 4.712e-07,
      "logits/chosen": -2.207193374633789,
      "logits/rejected": -2.357599973678589,
      "logps/chosen": -111.63337707519531,
      "logps/rejected": -205.77178955078125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7565701007843018,
      "rewards/margins": 9.385350227355957,
      "rewards/rejected": -7.628779888153076,
      "step": 3967
    },
    {
      "epoch": 1.5872000000000002,
      "grad_norm": 0.4985838234424591,
      "learning_rate": 4.710666666666667e-07,
      "logits/chosen": -1.9799423217773438,
      "logits/rejected": -2.833555221557617,
      "logps/chosen": -87.80391693115234,
      "logps/rejected": -171.4968719482422,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.460553765296936,
      "rewards/margins": 8.505735397338867,
      "rewards/rejected": -7.045181751251221,
      "step": 3968
    },
    {
      "epoch": 1.5876000000000001,
      "grad_norm": 0.25444892048835754,
      "learning_rate": 4.709333333333333e-07,
      "logits/chosen": -2.3089308738708496,
      "logits/rejected": -3.5723586082458496,
      "logps/chosen": -115.64277648925781,
      "logps/rejected": -139.47410583496094,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7462475299835205,
      "rewards/margins": 5.999900817871094,
      "rewards/rejected": -5.253653526306152,
      "step": 3969
    },
    {
      "epoch": 1.588,
      "grad_norm": 0.36751610040664673,
      "learning_rate": 4.7079999999999995e-07,
      "logits/chosen": -2.039597511291504,
      "logits/rejected": -3.2501931190490723,
      "logps/chosen": -123.29139709472656,
      "logps/rejected": -161.488525390625,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7878315448760986,
      "rewards/margins": 7.853367328643799,
      "rewards/rejected": -6.065535545349121,
      "step": 3970
    },
    {
      "epoch": 1.5884,
      "grad_norm": 0.25364452600479126,
      "learning_rate": 4.7066666666666665e-07,
      "logits/chosen": -2.1761584281921387,
      "logits/rejected": -2.8441085815429688,
      "logps/chosen": -150.66673278808594,
      "logps/rejected": -176.96343994140625,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.20677757263183594,
      "rewards/margins": 7.392602920532227,
      "rewards/rejected": -7.5993804931640625,
      "step": 3971
    },
    {
      "epoch": 1.5888,
      "grad_norm": 0.1163359135389328,
      "learning_rate": 4.7053333333333334e-07,
      "logits/chosen": -2.286536931991577,
      "logits/rejected": -2.62538480758667,
      "logps/chosen": -76.20182800292969,
      "logps/rejected": -114.79734802246094,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.305896759033203,
      "rewards/margins": 6.776484489440918,
      "rewards/rejected": -3.470587968826294,
      "step": 3972
    },
    {
      "epoch": 1.5892,
      "grad_norm": 0.017839660868048668,
      "learning_rate": 4.704e-07,
      "logits/chosen": -1.95839262008667,
      "logits/rejected": -2.7304630279541016,
      "logps/chosen": -72.00434875488281,
      "logps/rejected": -134.4582977294922,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.932511329650879,
      "rewards/margins": 8.701468467712402,
      "rewards/rejected": -5.768957138061523,
      "step": 3973
    },
    {
      "epoch": 1.5896,
      "grad_norm": 0.00203454727306962,
      "learning_rate": 4.7026666666666667e-07,
      "logits/chosen": -1.7072193622589111,
      "logits/rejected": -3.546384334564209,
      "logps/chosen": -91.80960845947266,
      "logps/rejected": -173.86013793945312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.465817451477051,
      "rewards/margins": 11.127569198608398,
      "rewards/rejected": -8.661751747131348,
      "step": 3974
    },
    {
      "epoch": 1.5899999999999999,
      "grad_norm": 1.3541587591171265,
      "learning_rate": 4.701333333333333e-07,
      "logits/chosen": -1.817264199256897,
      "logits/rejected": -2.5722100734710693,
      "logps/chosen": -109.74991607666016,
      "logps/rejected": -136.00732421875,
      "loss": 0.0129,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.131558418273926,
      "rewards/margins": 4.751891613006592,
      "rewards/rejected": -6.883450031280518,
      "step": 3975
    },
    {
      "epoch": 1.5904,
      "grad_norm": 0.0014285296201705933,
      "learning_rate": 4.6999999999999995e-07,
      "logits/chosen": -2.0420312881469727,
      "logits/rejected": -3.6477127075195312,
      "logps/chosen": -139.65774536132812,
      "logps/rejected": -183.10650634765625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.696838855743408,
      "rewards/margins": 11.655811309814453,
      "rewards/rejected": -7.958972454071045,
      "step": 3976
    },
    {
      "epoch": 1.5908,
      "grad_norm": 0.016710713505744934,
      "learning_rate": 4.6986666666666664e-07,
      "logits/chosen": -2.546759843826294,
      "logits/rejected": -2.9035496711730957,
      "logps/chosen": -147.29241943359375,
      "logps/rejected": -177.2111358642578,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.645155668258667,
      "rewards/margins": 8.937946319580078,
      "rewards/rejected": -6.292790412902832,
      "step": 3977
    },
    {
      "epoch": 1.5912,
      "grad_norm": 0.0006649766000919044,
      "learning_rate": 4.6973333333333333e-07,
      "logits/chosen": -1.9164254665374756,
      "logits/rejected": -3.977617025375366,
      "logps/chosen": -93.82830810546875,
      "logps/rejected": -205.2669677734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.982924222946167,
      "rewards/margins": 12.730056762695312,
      "rewards/rejected": -9.747132301330566,
      "step": 3978
    },
    {
      "epoch": 1.5916000000000001,
      "grad_norm": 0.003310584696009755,
      "learning_rate": 4.6959999999999997e-07,
      "logits/chosen": -1.9274370670318604,
      "logits/rejected": -3.5166268348693848,
      "logps/chosen": -168.07261657714844,
      "logps/rejected": -209.73023986816406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41431307792663574,
      "rewards/margins": 10.729713439941406,
      "rewards/rejected": -10.315401077270508,
      "step": 3979
    },
    {
      "epoch": 1.592,
      "grad_norm": 0.0008890285971574485,
      "learning_rate": 4.694666666666666e-07,
      "logits/chosen": -2.1581382751464844,
      "logits/rejected": -3.683152198791504,
      "logps/chosen": -111.30799865722656,
      "logps/rejected": -204.9684600830078,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4121601581573486,
      "rewards/margins": 12.96870231628418,
      "rewards/rejected": -9.556541442871094,
      "step": 3980
    },
    {
      "epoch": 1.5924,
      "grad_norm": 0.0033272176515311003,
      "learning_rate": 4.693333333333333e-07,
      "logits/chosen": -1.4802273511886597,
      "logits/rejected": -3.603166341781616,
      "logps/chosen": -89.78605651855469,
      "logps/rejected": -190.42041015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6282756328582764,
      "rewards/margins": 10.410014152526855,
      "rewards/rejected": -7.78173828125,
      "step": 3981
    },
    {
      "epoch": 1.5928,
      "grad_norm": 0.0008544103475287557,
      "learning_rate": 4.692e-07,
      "logits/chosen": -2.168592929840088,
      "logits/rejected": -3.462974786758423,
      "logps/chosen": -134.73971557617188,
      "logps/rejected": -218.1566162109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5079619884490967,
      "rewards/margins": 12.36005973815918,
      "rewards/rejected": -8.852096557617188,
      "step": 3982
    },
    {
      "epoch": 1.5932,
      "grad_norm": 0.003398666623979807,
      "learning_rate": 4.690666666666667e-07,
      "logits/chosen": -2.021235942840576,
      "logits/rejected": -3.811001777648926,
      "logps/chosen": -91.81608581542969,
      "logps/rejected": -205.38885498046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3574912548065186,
      "rewards/margins": 11.22116756439209,
      "rewards/rejected": -9.863676071166992,
      "step": 3983
    },
    {
      "epoch": 1.5936,
      "grad_norm": 0.0021053373347967863,
      "learning_rate": 4.6893333333333327e-07,
      "logits/chosen": -2.190802812576294,
      "logits/rejected": -3.400470733642578,
      "logps/chosen": -95.60527038574219,
      "logps/rejected": -173.8252410888672,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1843390464782715,
      "rewards/margins": 11.12070083618164,
      "rewards/rejected": -7.936361312866211,
      "step": 3984
    },
    {
      "epoch": 1.5939999999999999,
      "grad_norm": 0.0010874755680561066,
      "learning_rate": 4.6879999999999996e-07,
      "logits/chosen": -1.9115800857543945,
      "logits/rejected": -3.6368064880371094,
      "logps/chosen": -76.86859893798828,
      "logps/rejected": -209.8984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0009427070617676,
      "rewards/margins": 13.01138973236084,
      "rewards/rejected": -10.010446548461914,
      "step": 3985
    },
    {
      "epoch": 1.5944,
      "grad_norm": 0.005911712534725666,
      "learning_rate": 4.6866666666666665e-07,
      "logits/chosen": -2.3575668334960938,
      "logits/rejected": -3.3908169269561768,
      "logps/chosen": -181.98504638671875,
      "logps/rejected": -194.67474365234375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.036266326904297,
      "rewards/margins": 11.042285919189453,
      "rewards/rejected": -9.006019592285156,
      "step": 3986
    },
    {
      "epoch": 1.5948,
      "grad_norm": 0.008233982138335705,
      "learning_rate": 4.6853333333333335e-07,
      "logits/chosen": -2.1013965606689453,
      "logits/rejected": -3.0795340538024902,
      "logps/chosen": -102.39785766601562,
      "logps/rejected": -148.53738403320312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7805347442626953,
      "rewards/margins": 9.486111640930176,
      "rewards/rejected": -6.705576419830322,
      "step": 3987
    },
    {
      "epoch": 1.5952,
      "grad_norm": 0.03440231829881668,
      "learning_rate": 4.684e-07,
      "logits/chosen": -2.195868492126465,
      "logits/rejected": -3.3913559913635254,
      "logps/chosen": -137.30764770507812,
      "logps/rejected": -181.31549072265625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7983429431915283,
      "rewards/margins": 9.63287353515625,
      "rewards/rejected": -7.834530353546143,
      "step": 3988
    },
    {
      "epoch": 1.5956000000000001,
      "grad_norm": 0.003676749300211668,
      "learning_rate": 4.682666666666666e-07,
      "logits/chosen": -2.5739474296569824,
      "logits/rejected": -3.917055130004883,
      "logps/chosen": -106.30126953125,
      "logps/rejected": -194.0261993408203,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.661618947982788,
      "rewards/margins": 11.107236862182617,
      "rewards/rejected": -8.44561767578125,
      "step": 3989
    },
    {
      "epoch": 1.596,
      "grad_norm": 0.0016578821232542396,
      "learning_rate": 4.681333333333333e-07,
      "logits/chosen": -1.7194297313690186,
      "logits/rejected": -3.414351463317871,
      "logps/chosen": -125.23242950439453,
      "logps/rejected": -195.3564910888672,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.722123622894287,
      "rewards/margins": 11.870458602905273,
      "rewards/rejected": -9.148335456848145,
      "step": 3990
    },
    {
      "epoch": 1.5964,
      "grad_norm": 0.0076913246884942055,
      "learning_rate": 4.68e-07,
      "logits/chosen": -2.307605266571045,
      "logits/rejected": -3.5682692527770996,
      "logps/chosen": -80.63776397705078,
      "logps/rejected": -166.79293823242188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.132578372955322,
      "rewards/margins": 12.195475578308105,
      "rewards/rejected": -8.062896728515625,
      "step": 3991
    },
    {
      "epoch": 1.5968,
      "grad_norm": 0.012482364661991596,
      "learning_rate": 4.6786666666666665e-07,
      "logits/chosen": -1.773828387260437,
      "logits/rejected": -3.2565810680389404,
      "logps/chosen": -75.58090209960938,
      "logps/rejected": -163.6571807861328,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3463833332061768,
      "rewards/margins": 10.197381019592285,
      "rewards/rejected": -6.850997447967529,
      "step": 3992
    },
    {
      "epoch": 1.5972,
      "grad_norm": 0.05616858974099159,
      "learning_rate": 4.6773333333333334e-07,
      "logits/chosen": -2.24086856842041,
      "logits/rejected": -3.8307430744171143,
      "logps/chosen": -159.27671813964844,
      "logps/rejected": -212.38134765625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4994415044784546,
      "rewards/margins": 9.981277465820312,
      "rewards/rejected": -9.481836318969727,
      "step": 3993
    },
    {
      "epoch": 1.5976,
      "grad_norm": 0.01185006182640791,
      "learning_rate": 4.676e-07,
      "logits/chosen": -2.217231512069702,
      "logits/rejected": -3.6175479888916016,
      "logps/chosen": -152.28378295898438,
      "logps/rejected": -218.90284729003906,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.658344268798828,
      "rewards/margins": 10.289457321166992,
      "rewards/rejected": -7.631112575531006,
      "step": 3994
    },
    {
      "epoch": 1.5979999999999999,
      "grad_norm": 0.1998092085123062,
      "learning_rate": 4.674666666666666e-07,
      "logits/chosen": -2.5016555786132812,
      "logits/rejected": -3.474149703979492,
      "logps/chosen": -165.94142150878906,
      "logps/rejected": -207.86163330078125,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.20560836791992188,
      "rewards/margins": 7.606437683105469,
      "rewards/rejected": -7.812046051025391,
      "step": 3995
    },
    {
      "epoch": 1.5984,
      "grad_norm": 0.041955575346946716,
      "learning_rate": 4.673333333333333e-07,
      "logits/chosen": -2.4593305587768555,
      "logits/rejected": -3.096811056137085,
      "logps/chosen": -240.30104064941406,
      "logps/rejected": -223.51185607910156,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1979784965515137,
      "rewards/margins": 10.392717361450195,
      "rewards/rejected": -7.194738864898682,
      "step": 3996
    },
    {
      "epoch": 1.5988,
      "grad_norm": 0.01564786396920681,
      "learning_rate": 4.672e-07,
      "logits/chosen": -1.8316148519515991,
      "logits/rejected": -2.9925341606140137,
      "logps/chosen": -127.82650756835938,
      "logps/rejected": -168.48309326171875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8300949335098267,
      "rewards/margins": 9.568275451660156,
      "rewards/rejected": -7.738180637359619,
      "step": 3997
    },
    {
      "epoch": 1.5992,
      "grad_norm": 0.001231766538694501,
      "learning_rate": 4.6706666666666664e-07,
      "logits/chosen": -1.8983707427978516,
      "logits/rejected": -3.141021966934204,
      "logps/chosen": -100.66929626464844,
      "logps/rejected": -163.25558471679688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8191685676574707,
      "rewards/margins": 11.522116661071777,
      "rewards/rejected": -7.702948093414307,
      "step": 3998
    },
    {
      "epoch": 1.5996000000000001,
      "grad_norm": 0.0030940587166696787,
      "learning_rate": 4.669333333333333e-07,
      "logits/chosen": -2.1757407188415527,
      "logits/rejected": -3.6950430870056152,
      "logps/chosen": -88.76232147216797,
      "logps/rejected": -232.05014038085938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9476261138916016,
      "rewards/margins": 11.532187461853027,
      "rewards/rejected": -8.584561347961426,
      "step": 3999
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.008699591271579266,
      "learning_rate": 4.6679999999999997e-07,
      "logits/chosen": -2.2980997562408447,
      "logits/rejected": -3.316422939300537,
      "logps/chosen": -123.88359069824219,
      "logps/rejected": -192.59286499023438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.205531358718872,
      "rewards/margins": 10.52290153503418,
      "rewards/rejected": -8.31736946105957,
      "step": 4000
    },
    {
      "epoch": 1.6004,
      "grad_norm": 0.010197270661592484,
      "learning_rate": 4.6666666666666666e-07,
      "logits/chosen": -2.342771053314209,
      "logits/rejected": -3.4505770206451416,
      "logps/chosen": -140.13394165039062,
      "logps/rejected": -150.43930053710938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.538900852203369,
      "rewards/margins": 10.26490592956543,
      "rewards/rejected": -6.726005554199219,
      "step": 4001
    },
    {
      "epoch": 1.6008,
      "grad_norm": 0.08224349468946457,
      "learning_rate": 4.6653333333333336e-07,
      "logits/chosen": -2.40614652633667,
      "logits/rejected": -3.7765026092529297,
      "logps/chosen": -110.03466033935547,
      "logps/rejected": -210.33682250976562,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4130654335021973,
      "rewards/margins": 8.224855422973633,
      "rewards/rejected": -5.811789512634277,
      "step": 4002
    },
    {
      "epoch": 1.6012,
      "grad_norm": 0.03569543734192848,
      "learning_rate": 4.6639999999999994e-07,
      "logits/chosen": -1.7265605926513672,
      "logits/rejected": -3.9432709217071533,
      "logps/chosen": -106.54685974121094,
      "logps/rejected": -195.468017578125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.644769310951233,
      "rewards/margins": 9.767026901245117,
      "rewards/rejected": -8.122257232666016,
      "step": 4003
    },
    {
      "epoch": 1.6016,
      "grad_norm": 1.4331755638122559,
      "learning_rate": 4.6626666666666663e-07,
      "logits/chosen": -2.8683676719665527,
      "logits/rejected": -3.2640950679779053,
      "logps/chosen": -113.38716125488281,
      "logps/rejected": -177.93310546875,
      "loss": 0.0065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3729824423789978,
      "rewards/margins": 7.288101673126221,
      "rewards/rejected": -6.915119171142578,
      "step": 4004
    },
    {
      "epoch": 1.6019999999999999,
      "grad_norm": 0.005145966075360775,
      "learning_rate": 4.661333333333333e-07,
      "logits/chosen": -2.1272478103637695,
      "logits/rejected": -2.8302221298217773,
      "logps/chosen": -152.50711059570312,
      "logps/rejected": -170.04452514648438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7829322814941406,
      "rewards/margins": 10.192062377929688,
      "rewards/rejected": -7.409130096435547,
      "step": 4005
    },
    {
      "epoch": 1.6024,
      "grad_norm": 0.069338858127594,
      "learning_rate": 4.66e-07,
      "logits/chosen": -2.410212278366089,
      "logits/rejected": -3.309485912322998,
      "logps/chosen": -110.30194091796875,
      "logps/rejected": -170.35096740722656,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7800339460372925,
      "rewards/margins": 9.661945343017578,
      "rewards/rejected": -7.881911277770996,
      "step": 4006
    },
    {
      "epoch": 1.6028,
      "grad_norm": 0.07906683534383774,
      "learning_rate": 4.6586666666666666e-07,
      "logits/chosen": -2.374650716781616,
      "logits/rejected": -2.629142999649048,
      "logps/chosen": -181.6909637451172,
      "logps/rejected": -186.56727600097656,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1032376289367676,
      "rewards/margins": 9.744312286376953,
      "rewards/rejected": -7.641074180603027,
      "step": 4007
    },
    {
      "epoch": 1.6032,
      "grad_norm": 4.018860816955566,
      "learning_rate": 4.657333333333333e-07,
      "logits/chosen": -2.2861218452453613,
      "logits/rejected": -3.4113337993621826,
      "logps/chosen": -83.53253173828125,
      "logps/rejected": -134.43820190429688,
      "loss": 0.0274,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.354659080505371,
      "rewards/margins": 6.6010332107543945,
      "rewards/rejected": -4.246374130249023,
      "step": 4008
    },
    {
      "epoch": 1.6036000000000001,
      "grad_norm": 0.001450625597499311,
      "learning_rate": 4.656e-07,
      "logits/chosen": -1.8306841850280762,
      "logits/rejected": -3.0098090171813965,
      "logps/chosen": -145.04473876953125,
      "logps/rejected": -173.53982543945312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.814992904663086,
      "rewards/margins": 11.445829391479492,
      "rewards/rejected": -8.630837440490723,
      "step": 4009
    },
    {
      "epoch": 1.604,
      "grad_norm": 0.10267459601163864,
      "learning_rate": 4.654666666666666e-07,
      "logits/chosen": -2.1026439666748047,
      "logits/rejected": -3.5470404624938965,
      "logps/chosen": -177.2826385498047,
      "logps/rejected": -153.88221740722656,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5581214427947998,
      "rewards/margins": 8.448312759399414,
      "rewards/rejected": -6.890191078186035,
      "step": 4010
    },
    {
      "epoch": 1.6044,
      "grad_norm": 0.016282640397548676,
      "learning_rate": 4.653333333333333e-07,
      "logits/chosen": -2.245443820953369,
      "logits/rejected": -3.337769031524658,
      "logps/chosen": -107.79536437988281,
      "logps/rejected": -182.06787109375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.143251895904541,
      "rewards/margins": 9.406993865966797,
      "rewards/rejected": -8.263742446899414,
      "step": 4011
    },
    {
      "epoch": 1.6048,
      "grad_norm": 0.004083635285496712,
      "learning_rate": 4.6519999999999996e-07,
      "logits/chosen": -2.1747889518737793,
      "logits/rejected": -2.8464438915252686,
      "logps/chosen": -95.07552337646484,
      "logps/rejected": -150.17233276367188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.009453296661377,
      "rewards/margins": 10.37294864654541,
      "rewards/rejected": -7.363495349884033,
      "step": 4012
    },
    {
      "epoch": 1.6052,
      "grad_norm": 0.08653383702039719,
      "learning_rate": 4.6506666666666665e-07,
      "logits/chosen": -1.3619513511657715,
      "logits/rejected": -3.0510191917419434,
      "logps/chosen": -112.73554992675781,
      "logps/rejected": -145.4447784423828,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2949137687683105,
      "rewards/margins": 7.495462417602539,
      "rewards/rejected": -6.2005486488342285,
      "step": 4013
    },
    {
      "epoch": 1.6056,
      "grad_norm": 0.04644360393285751,
      "learning_rate": 4.649333333333333e-07,
      "logits/chosen": -2.592803955078125,
      "logits/rejected": -3.160935878753662,
      "logps/chosen": -153.72889709472656,
      "logps/rejected": -161.68124389648438,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0347790718078613,
      "rewards/margins": 8.820242881774902,
      "rewards/rejected": -6.785463809967041,
      "step": 4014
    },
    {
      "epoch": 1.6059999999999999,
      "grad_norm": 0.022877298295497894,
      "learning_rate": 4.648e-07,
      "logits/chosen": -2.0917091369628906,
      "logits/rejected": -3.490565776824951,
      "logps/chosen": -110.67957305908203,
      "logps/rejected": -183.22515869140625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0405454635620117,
      "rewards/margins": 9.512273788452148,
      "rewards/rejected": -7.471728324890137,
      "step": 4015
    },
    {
      "epoch": 1.6064,
      "grad_norm": 0.09642061591148376,
      "learning_rate": 4.6466666666666667e-07,
      "logits/chosen": -2.0463438034057617,
      "logits/rejected": -3.643340826034546,
      "logps/chosen": -172.1998291015625,
      "logps/rejected": -164.54208374023438,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0078003406524658,
      "rewards/margins": 7.279929161071777,
      "rewards/rejected": -6.272129058837891,
      "step": 4016
    },
    {
      "epoch": 1.6068,
      "grad_norm": 0.11156010627746582,
      "learning_rate": 4.645333333333333e-07,
      "logits/chosen": -1.770735502243042,
      "logits/rejected": -3.2125563621520996,
      "logps/chosen": -124.96117401123047,
      "logps/rejected": -186.7559814453125,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.014544725418091,
      "rewards/margins": 9.778639793395996,
      "rewards/rejected": -7.764095306396484,
      "step": 4017
    },
    {
      "epoch": 1.6072,
      "grad_norm": 0.03506777435541153,
      "learning_rate": 4.6439999999999995e-07,
      "logits/chosen": -2.1251022815704346,
      "logits/rejected": -3.6341872215270996,
      "logps/chosen": -118.51717376708984,
      "logps/rejected": -188.23521423339844,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31234055757522583,
      "rewards/margins": 8.515377044677734,
      "rewards/rejected": -8.203036308288574,
      "step": 4018
    },
    {
      "epoch": 1.6076000000000001,
      "grad_norm": 0.0007308946806006134,
      "learning_rate": 4.6426666666666664e-07,
      "logits/chosen": -2.5227670669555664,
      "logits/rejected": -3.5697503089904785,
      "logps/chosen": -160.12503051757812,
      "logps/rejected": -171.02774047851562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.452432155609131,
      "rewards/margins": 12.1104097366333,
      "rewards/rejected": -7.65797758102417,
      "step": 4019
    },
    {
      "epoch": 1.608,
      "grad_norm": 0.015312215313315392,
      "learning_rate": 4.6413333333333333e-07,
      "logits/chosen": -1.736262321472168,
      "logits/rejected": -3.559769630432129,
      "logps/chosen": -74.53174591064453,
      "logps/rejected": -189.864501953125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.745500087738037,
      "rewards/margins": 11.797504425048828,
      "rewards/rejected": -9.05200481414795,
      "step": 4020
    },
    {
      "epoch": 1.6084,
      "grad_norm": 0.01025636401027441,
      "learning_rate": 4.64e-07,
      "logits/chosen": -2.1715950965881348,
      "logits/rejected": -3.514953136444092,
      "logps/chosen": -114.19186401367188,
      "logps/rejected": -178.549560546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.126166820526123,
      "rewards/margins": 9.526653289794922,
      "rewards/rejected": -7.400485992431641,
      "step": 4021
    },
    {
      "epoch": 1.6088,
      "grad_norm": 0.1963260918855667,
      "learning_rate": 4.638666666666666e-07,
      "logits/chosen": -2.6058897972106934,
      "logits/rejected": -3.3125810623168945,
      "logps/chosen": -231.2202606201172,
      "logps/rejected": -208.05889892578125,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.744165062904358,
      "rewards/margins": 10.031249046325684,
      "rewards/rejected": -8.287083625793457,
      "step": 4022
    },
    {
      "epoch": 1.6092,
      "grad_norm": 0.9268405437469482,
      "learning_rate": 4.637333333333333e-07,
      "logits/chosen": -2.3812148571014404,
      "logits/rejected": -3.3448052406311035,
      "logps/chosen": -142.40835571289062,
      "logps/rejected": -158.07666015625,
      "loss": 0.0088,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5264530181884766,
      "rewards/margins": 5.381186485290527,
      "rewards/rejected": -5.907639503479004,
      "step": 4023
    },
    {
      "epoch": 1.6096,
      "grad_norm": 0.002306843176484108,
      "learning_rate": 4.636e-07,
      "logits/chosen": -1.7525825500488281,
      "logits/rejected": -3.955305814743042,
      "logps/chosen": -75.39214324951172,
      "logps/rejected": -186.86358642578125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.680905818939209,
      "rewards/margins": 11.115598678588867,
      "rewards/rejected": -7.434691905975342,
      "step": 4024
    },
    {
      "epoch": 1.6099999999999999,
      "grad_norm": 0.019730595871806145,
      "learning_rate": 4.634666666666667e-07,
      "logits/chosen": -2.1097288131713867,
      "logits/rejected": -3.1969778537750244,
      "logps/chosen": -92.31114196777344,
      "logps/rejected": -198.31597900390625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.614623785018921,
      "rewards/margins": 9.305109977722168,
      "rewards/rejected": -6.690485954284668,
      "step": 4025
    },
    {
      "epoch": 1.6104,
      "grad_norm": 0.04786796122789383,
      "learning_rate": 4.633333333333333e-07,
      "logits/chosen": -1.5502502918243408,
      "logits/rejected": -3.51613187789917,
      "logps/chosen": -120.0843734741211,
      "logps/rejected": -162.6856689453125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7562508583068848,
      "rewards/margins": 9.661893844604492,
      "rewards/rejected": -7.905642509460449,
      "step": 4026
    },
    {
      "epoch": 1.6108,
      "grad_norm": 6.0288737586233765e-05,
      "learning_rate": 4.6319999999999997e-07,
      "logits/chosen": -2.2033510208129883,
      "logits/rejected": -3.4753355979919434,
      "logps/chosen": -218.09109497070312,
      "logps/rejected": -278.61279296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 5.526760101318359,
      "rewards/margins": 15.309077262878418,
      "rewards/rejected": -9.782318115234375,
      "step": 4027
    },
    {
      "epoch": 1.6112,
      "grad_norm": 0.002513122046366334,
      "learning_rate": 4.6306666666666666e-07,
      "logits/chosen": -1.9441444873809814,
      "logits/rejected": -3.454280376434326,
      "logps/chosen": -142.00692749023438,
      "logps/rejected": -258.1258239746094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7549843788146973,
      "rewards/margins": 11.729619979858398,
      "rewards/rejected": -7.974635601043701,
      "step": 4028
    },
    {
      "epoch": 1.6116000000000001,
      "grad_norm": 0.03601396828889847,
      "learning_rate": 4.629333333333333e-07,
      "logits/chosen": -1.38126802444458,
      "logits/rejected": -3.3064215183258057,
      "logps/chosen": -150.47659301757812,
      "logps/rejected": -155.97906494140625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6050939559936523,
      "rewards/margins": 9.124125480651855,
      "rewards/rejected": -6.519031524658203,
      "step": 4029
    },
    {
      "epoch": 1.612,
      "grad_norm": 0.005686343181878328,
      "learning_rate": 4.628e-07,
      "logits/chosen": -2.525895118713379,
      "logits/rejected": -3.2805099487304688,
      "logps/chosen": -130.5157928466797,
      "logps/rejected": -167.27459716796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7947139739990234,
      "rewards/margins": 10.404023170471191,
      "rewards/rejected": -8.609308242797852,
      "step": 4030
    },
    {
      "epoch": 1.6124,
      "grad_norm": 0.03800652548670769,
      "learning_rate": 4.6266666666666663e-07,
      "logits/chosen": -2.4719369411468506,
      "logits/rejected": -3.67207407951355,
      "logps/chosen": -227.90292358398438,
      "logps/rejected": -204.61019897460938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3505280017852783,
      "rewards/margins": 10.938667297363281,
      "rewards/rejected": -8.588138580322266,
      "step": 4031
    },
    {
      "epoch": 1.6128,
      "grad_norm": 3.4460854530334473,
      "learning_rate": 4.625333333333333e-07,
      "logits/chosen": -2.7185916900634766,
      "logits/rejected": -3.3044369220733643,
      "logps/chosen": -190.295166015625,
      "logps/rejected": -187.6023712158203,
      "loss": 0.0168,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -3.014824628829956,
      "rewards/margins": 5.668923377990723,
      "rewards/rejected": -8.683748245239258,
      "step": 4032
    },
    {
      "epoch": 1.6132,
      "grad_norm": 0.0232422836124897,
      "learning_rate": 4.6239999999999996e-07,
      "logits/chosen": -1.9785690307617188,
      "logits/rejected": -3.365205764770508,
      "logps/chosen": -119.74540710449219,
      "logps/rejected": -195.55389404296875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5432289838790894,
      "rewards/margins": 10.266195297241211,
      "rewards/rejected": -8.722967147827148,
      "step": 4033
    },
    {
      "epoch": 1.6136,
      "grad_norm": 0.0007627093582414091,
      "learning_rate": 4.6226666666666665e-07,
      "logits/chosen": -2.2280125617980957,
      "logits/rejected": -2.812739849090576,
      "logps/chosen": -175.77984619140625,
      "logps/rejected": -198.55274963378906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.536609649658203,
      "rewards/margins": 12.094579696655273,
      "rewards/rejected": -7.557969093322754,
      "step": 4034
    },
    {
      "epoch": 1.6139999999999999,
      "grad_norm": 0.028863033279776573,
      "learning_rate": 4.6213333333333334e-07,
      "logits/chosen": -1.9167070388793945,
      "logits/rejected": -3.387357711791992,
      "logps/chosen": -108.35774230957031,
      "logps/rejected": -180.61192321777344,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.053200125694275,
      "rewards/margins": 8.277194023132324,
      "rewards/rejected": -7.22399377822876,
      "step": 4035
    },
    {
      "epoch": 1.6143999999999998,
      "grad_norm": 5.6754608154296875,
      "learning_rate": 4.62e-07,
      "logits/chosen": -2.344822406768799,
      "logits/rejected": -2.716618061065674,
      "logps/chosen": -131.2490692138672,
      "logps/rejected": -167.3621826171875,
      "loss": 0.0312,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3251049518585205,
      "rewards/margins": 6.250056743621826,
      "rewards/rejected": -6.575161933898926,
      "step": 4036
    },
    {
      "epoch": 1.6148,
      "grad_norm": 0.03543178737163544,
      "learning_rate": 4.618666666666666e-07,
      "logits/chosen": -1.797365665435791,
      "logits/rejected": -3.107203960418701,
      "logps/chosen": -130.0087127685547,
      "logps/rejected": -168.88897705078125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8407818078994751,
      "rewards/margins": 9.35251235961914,
      "rewards/rejected": -8.511731147766113,
      "step": 4037
    },
    {
      "epoch": 1.6152,
      "grad_norm": 0.06217740848660469,
      "learning_rate": 4.617333333333333e-07,
      "logits/chosen": -1.9869599342346191,
      "logits/rejected": -3.2350640296936035,
      "logps/chosen": -87.643798828125,
      "logps/rejected": -234.503173828125,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.14441180229187,
      "rewards/margins": 9.829597473144531,
      "rewards/rejected": -6.685185432434082,
      "step": 4038
    },
    {
      "epoch": 1.6156000000000001,
      "grad_norm": 0.05858099088072777,
      "learning_rate": 4.616e-07,
      "logits/chosen": -1.693448543548584,
      "logits/rejected": -2.8219404220581055,
      "logps/chosen": -191.8936309814453,
      "logps/rejected": -199.91079711914062,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9049347043037415,
      "rewards/margins": 9.22506332397461,
      "rewards/rejected": -8.32012939453125,
      "step": 4039
    },
    {
      "epoch": 1.616,
      "grad_norm": 0.1864481121301651,
      "learning_rate": 4.614666666666667e-07,
      "logits/chosen": -1.3054938316345215,
      "logits/rejected": -2.6485252380371094,
      "logps/chosen": -112.82350158691406,
      "logps/rejected": -131.56137084960938,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3403229713439941,
      "rewards/margins": 7.736169815063477,
      "rewards/rejected": -6.395846366882324,
      "step": 4040
    },
    {
      "epoch": 1.6164,
      "grad_norm": 0.058466654270887375,
      "learning_rate": 4.613333333333333e-07,
      "logits/chosen": -2.291849136352539,
      "logits/rejected": -3.312124729156494,
      "logps/chosen": -83.2002182006836,
      "logps/rejected": -169.78189086914062,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5851925015449524,
      "rewards/margins": 7.665138244628906,
      "rewards/rejected": -7.079946041107178,
      "step": 4041
    },
    {
      "epoch": 1.6168,
      "grad_norm": 0.0038993244525045156,
      "learning_rate": 4.612e-07,
      "logits/chosen": -2.2584142684936523,
      "logits/rejected": -3.6947238445281982,
      "logps/chosen": -158.7531280517578,
      "logps/rejected": -179.87127685546875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7467386722564697,
      "rewards/margins": 10.634042739868164,
      "rewards/rejected": -8.887304306030273,
      "step": 4042
    },
    {
      "epoch": 1.6172,
      "grad_norm": 0.009672675281763077,
      "learning_rate": 4.6106666666666667e-07,
      "logits/chosen": -1.7304942607879639,
      "logits/rejected": -3.180917739868164,
      "logps/chosen": -107.79893493652344,
      "logps/rejected": -202.24087524414062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0285248756408691,
      "rewards/margins": 10.62347412109375,
      "rewards/rejected": -9.594949722290039,
      "step": 4043
    },
    {
      "epoch": 1.6176,
      "grad_norm": 0.026495138183236122,
      "learning_rate": 4.609333333333333e-07,
      "logits/chosen": -2.1310973167419434,
      "logits/rejected": -3.2542333602905273,
      "logps/chosen": -120.63877868652344,
      "logps/rejected": -182.1076202392578,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0535030364990234,
      "rewards/margins": 9.294130325317383,
      "rewards/rejected": -7.240626811981201,
      "step": 4044
    },
    {
      "epoch": 1.6179999999999999,
      "grad_norm": 0.010974262841045856,
      "learning_rate": 4.6079999999999994e-07,
      "logits/chosen": -2.2556657791137695,
      "logits/rejected": -3.323003053665161,
      "logps/chosen": -200.49554443359375,
      "logps/rejected": -265.8050231933594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.803985595703125,
      "rewards/margins": 10.183892250061035,
      "rewards/rejected": -9.37990665435791,
      "step": 4045
    },
    {
      "epoch": 1.6183999999999998,
      "grad_norm": 0.0005592844099737704,
      "learning_rate": 4.6066666666666664e-07,
      "logits/chosen": -2.2900028228759766,
      "logits/rejected": -3.5760154724121094,
      "logps/chosen": -121.26910400390625,
      "logps/rejected": -209.8750457763672,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.06607723236084,
      "rewards/margins": 12.632184982299805,
      "rewards/rejected": -8.566108703613281,
      "step": 4046
    },
    {
      "epoch": 1.6188,
      "grad_norm": 0.021937698125839233,
      "learning_rate": 4.6053333333333333e-07,
      "logits/chosen": -2.5831894874572754,
      "logits/rejected": -3.9194765090942383,
      "logps/chosen": -166.20394897460938,
      "logps/rejected": -183.10211181640625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6440443992614746,
      "rewards/margins": 9.75936508178711,
      "rewards/rejected": -7.115321159362793,
      "step": 4047
    },
    {
      "epoch": 1.6192,
      "grad_norm": 0.08669992536306381,
      "learning_rate": 4.6039999999999997e-07,
      "logits/chosen": -1.886646032333374,
      "logits/rejected": -2.750777244567871,
      "logps/chosen": -116.78007507324219,
      "logps/rejected": -195.55892944335938,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3262617588043213,
      "rewards/margins": 9.159679412841797,
      "rewards/rejected": -6.833418369293213,
      "step": 4048
    },
    {
      "epoch": 1.6196000000000002,
      "grad_norm": 0.0005001859972253442,
      "learning_rate": 4.6026666666666666e-07,
      "logits/chosen": -2.3368701934814453,
      "logits/rejected": -3.722369909286499,
      "logps/chosen": -171.78131103515625,
      "logps/rejected": -180.92550659179688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.023723602294922,
      "rewards/margins": 12.586682319641113,
      "rewards/rejected": -8.562958717346191,
      "step": 4049
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.0871889740228653,
      "learning_rate": 4.601333333333333e-07,
      "logits/chosen": -1.886392593383789,
      "logits/rejected": -3.277432680130005,
      "logps/chosen": -207.60122680664062,
      "logps/rejected": -162.03221130371094,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5613243579864502,
      "rewards/margins": 7.062839984893799,
      "rewards/rejected": -6.5015153884887695,
      "step": 4050
    },
    {
      "epoch": 1.6204,
      "grad_norm": 0.003230320056900382,
      "learning_rate": 4.6e-07,
      "logits/chosen": -1.58013916015625,
      "logits/rejected": -3.0179953575134277,
      "logps/chosen": -102.74116516113281,
      "logps/rejected": -148.91026306152344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8206167221069336,
      "rewards/margins": 11.187643051147461,
      "rewards/rejected": -7.367025852203369,
      "step": 4051
    },
    {
      "epoch": 1.6208,
      "grad_norm": 0.047519437968730927,
      "learning_rate": 4.5986666666666663e-07,
      "logits/chosen": -2.488769054412842,
      "logits/rejected": -2.7646889686584473,
      "logps/chosen": -108.80894470214844,
      "logps/rejected": -160.80364990234375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.20835798978805542,
      "rewards/margins": 7.862521171569824,
      "rewards/rejected": -8.070878982543945,
      "step": 4052
    },
    {
      "epoch": 1.6212,
      "grad_norm": 0.0017426975537091494,
      "learning_rate": 4.597333333333333e-07,
      "logits/chosen": -2.450775146484375,
      "logits/rejected": -3.3454103469848633,
      "logps/chosen": -137.2414093017578,
      "logps/rejected": -196.03013610839844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.538992404937744,
      "rewards/margins": 11.681365966796875,
      "rewards/rejected": -9.142373085021973,
      "step": 4053
    },
    {
      "epoch": 1.6216,
      "grad_norm": 0.021297112107276917,
      "learning_rate": 4.596e-07,
      "logits/chosen": -2.431027889251709,
      "logits/rejected": -3.1902694702148438,
      "logps/chosen": -79.38717651367188,
      "logps/rejected": -164.173583984375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5776878595352173,
      "rewards/margins": 8.641229629516602,
      "rewards/rejected": -7.063541412353516,
      "step": 4054
    },
    {
      "epoch": 1.6219999999999999,
      "grad_norm": 0.08652831614017487,
      "learning_rate": 4.5946666666666665e-07,
      "logits/chosen": -1.9318525791168213,
      "logits/rejected": -3.5494112968444824,
      "logps/chosen": -129.87237548828125,
      "logps/rejected": -177.7998046875,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5922172665596008,
      "rewards/margins": 8.550601959228516,
      "rewards/rejected": -7.9583845138549805,
      "step": 4055
    },
    {
      "epoch": 1.6223999999999998,
      "grad_norm": 0.0007618376985192299,
      "learning_rate": 4.593333333333333e-07,
      "logits/chosen": -2.1472084522247314,
      "logits/rejected": -3.3795132637023926,
      "logps/chosen": -103.85621643066406,
      "logps/rejected": -223.45193481445312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4426510334014893,
      "rewards/margins": 12.125199317932129,
      "rewards/rejected": -8.682548522949219,
      "step": 4056
    },
    {
      "epoch": 1.6228,
      "grad_norm": 0.05874686315655708,
      "learning_rate": 4.592e-07,
      "logits/chosen": -2.094815254211426,
      "logits/rejected": -3.230084180831909,
      "logps/chosen": -159.35171508789062,
      "logps/rejected": -195.47994995117188,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6475422382354736,
      "rewards/margins": 9.184557914733887,
      "rewards/rejected": -7.537015438079834,
      "step": 4057
    },
    {
      "epoch": 1.6232,
      "grad_norm": 0.0006194600719027221,
      "learning_rate": 4.590666666666667e-07,
      "logits/chosen": -1.5549659729003906,
      "logits/rejected": -3.4552268981933594,
      "logps/chosen": -57.69425964355469,
      "logps/rejected": -157.62493896484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.310151100158691,
      "rewards/margins": 12.168761253356934,
      "rewards/rejected": -7.858610153198242,
      "step": 4058
    },
    {
      "epoch": 1.6236000000000002,
      "grad_norm": 0.02672921121120453,
      "learning_rate": 4.589333333333333e-07,
      "logits/chosen": -1.5151774883270264,
      "logits/rejected": -3.054166793823242,
      "logps/chosen": -80.54828643798828,
      "logps/rejected": -168.7139892578125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.524306535720825,
      "rewards/margins": 8.479275703430176,
      "rewards/rejected": -5.9549689292907715,
      "step": 4059
    },
    {
      "epoch": 1.624,
      "grad_norm": 0.014364533126354218,
      "learning_rate": 4.5879999999999995e-07,
      "logits/chosen": -1.6592721939086914,
      "logits/rejected": -2.4593303203582764,
      "logps/chosen": -78.34440612792969,
      "logps/rejected": -172.4047088623047,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7144691944122314,
      "rewards/margins": 9.183114051818848,
      "rewards/rejected": -6.468645095825195,
      "step": 4060
    },
    {
      "epoch": 1.6244,
      "grad_norm": 0.07730759680271149,
      "learning_rate": 4.5866666666666664e-07,
      "logits/chosen": -1.868695616722107,
      "logits/rejected": -2.9263482093811035,
      "logps/chosen": -91.79095458984375,
      "logps/rejected": -169.82476806640625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8641724586486816,
      "rewards/margins": 9.528846740722656,
      "rewards/rejected": -7.664674282073975,
      "step": 4061
    },
    {
      "epoch": 1.6248,
      "grad_norm": 0.02490762434899807,
      "learning_rate": 4.5853333333333334e-07,
      "logits/chosen": -1.863976240158081,
      "logits/rejected": -2.9110171794891357,
      "logps/chosen": -111.03202056884766,
      "logps/rejected": -144.55084228515625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1034202575683594,
      "rewards/margins": 8.36431884765625,
      "rewards/rejected": -7.260899066925049,
      "step": 4062
    },
    {
      "epoch": 1.6252,
      "grad_norm": 0.38241225481033325,
      "learning_rate": 4.584e-07,
      "logits/chosen": -2.2409956455230713,
      "logits/rejected": -3.525254726409912,
      "logps/chosen": -146.40695190429688,
      "logps/rejected": -172.72915649414062,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1399768590927124,
      "rewards/margins": 8.331878662109375,
      "rewards/rejected": -8.471855163574219,
      "step": 4063
    },
    {
      "epoch": 1.6256,
      "grad_norm": 0.0028965675737708807,
      "learning_rate": 4.582666666666666e-07,
      "logits/chosen": -2.2679715156555176,
      "logits/rejected": -3.6798720359802246,
      "logps/chosen": -126.7689437866211,
      "logps/rejected": -201.18898010253906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.023240089416504,
      "rewards/margins": 11.720218658447266,
      "rewards/rejected": -8.696979522705078,
      "step": 4064
    },
    {
      "epoch": 1.626,
      "grad_norm": 0.004667835310101509,
      "learning_rate": 4.581333333333333e-07,
      "logits/chosen": -1.865060806274414,
      "logits/rejected": -3.612200975418091,
      "logps/chosen": -123.54098510742188,
      "logps/rejected": -212.1361541748047,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0711678266525269,
      "rewards/margins": 10.688064575195312,
      "rewards/rejected": -9.61689567565918,
      "step": 4065
    },
    {
      "epoch": 1.6263999999999998,
      "grad_norm": 0.03020641952753067,
      "learning_rate": 4.58e-07,
      "logits/chosen": -2.358588695526123,
      "logits/rejected": -3.22698974609375,
      "logps/chosen": -273.03369140625,
      "logps/rejected": -199.33584594726562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5802574157714844,
      "rewards/margins": 9.88473892211914,
      "rewards/rejected": -8.304481506347656,
      "step": 4066
    },
    {
      "epoch": 1.6268,
      "grad_norm": 0.015546299517154694,
      "learning_rate": 4.5786666666666664e-07,
      "logits/chosen": -2.209974527359009,
      "logits/rejected": -3.543588876724243,
      "logps/chosen": -125.9065933227539,
      "logps/rejected": -184.410888671875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2639007568359375,
      "rewards/margins": 9.373774528503418,
      "rewards/rejected": -9.10987377166748,
      "step": 4067
    },
    {
      "epoch": 1.6272,
      "grad_norm": 0.0033985390327870846,
      "learning_rate": 4.5773333333333333e-07,
      "logits/chosen": -1.7389098405838013,
      "logits/rejected": -3.3793387413024902,
      "logps/chosen": -92.67466735839844,
      "logps/rejected": -143.52659606933594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5985500812530518,
      "rewards/margins": 10.411979675292969,
      "rewards/rejected": -6.813429832458496,
      "step": 4068
    },
    {
      "epoch": 1.6276000000000002,
      "grad_norm": 0.022948186844587326,
      "learning_rate": 4.5759999999999997e-07,
      "logits/chosen": -2.2311501502990723,
      "logits/rejected": -3.019164800643921,
      "logps/chosen": -135.40158081054688,
      "logps/rejected": -188.4954071044922,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1036813259124756,
      "rewards/margins": 10.921018600463867,
      "rewards/rejected": -8.817337036132812,
      "step": 4069
    },
    {
      "epoch": 1.6280000000000001,
      "grad_norm": 0.12630698084831238,
      "learning_rate": 4.5746666666666666e-07,
      "logits/chosen": -2.447941780090332,
      "logits/rejected": -3.3875155448913574,
      "logps/chosen": -134.3292236328125,
      "logps/rejected": -189.2777099609375,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6031356453895569,
      "rewards/margins": 7.750332832336426,
      "rewards/rejected": -7.1471967697143555,
      "step": 4070
    },
    {
      "epoch": 1.6284,
      "grad_norm": 0.023082397878170013,
      "learning_rate": 4.573333333333333e-07,
      "logits/chosen": -2.3323755264282227,
      "logits/rejected": -3.631868362426758,
      "logps/chosen": -155.821533203125,
      "logps/rejected": -174.7423095703125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0847396850585938,
      "rewards/margins": 8.484952926635742,
      "rewards/rejected": -7.400213241577148,
      "step": 4071
    },
    {
      "epoch": 1.6288,
      "grad_norm": 0.0009560877806507051,
      "learning_rate": 4.572e-07,
      "logits/chosen": -1.7711868286132812,
      "logits/rejected": -3.64945650100708,
      "logps/chosen": -92.46578979492188,
      "logps/rejected": -223.77554321289062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.200530529022217,
      "rewards/margins": 13.08047103881836,
      "rewards/rejected": -8.8799409866333,
      "step": 4072
    },
    {
      "epoch": 1.6292,
      "grad_norm": 0.018687747418880463,
      "learning_rate": 4.5706666666666663e-07,
      "logits/chosen": -2.7259957790374756,
      "logits/rejected": -3.3628339767456055,
      "logps/chosen": -133.40272521972656,
      "logps/rejected": -197.17527770996094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.123010158538818,
      "rewards/margins": 11.919459342956543,
      "rewards/rejected": -7.796449184417725,
      "step": 4073
    },
    {
      "epoch": 1.6296,
      "grad_norm": 0.01547862496227026,
      "learning_rate": 4.569333333333333e-07,
      "logits/chosen": -2.3016109466552734,
      "logits/rejected": -3.6609349250793457,
      "logps/chosen": -147.47686767578125,
      "logps/rejected": -184.34925842285156,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7916557192802429,
      "rewards/margins": 9.1713285446167,
      "rewards/rejected": -8.37967300415039,
      "step": 4074
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.10040513426065445,
      "learning_rate": 4.5679999999999996e-07,
      "logits/chosen": -1.9843002557754517,
      "logits/rejected": -3.068924903869629,
      "logps/chosen": -119.12179565429688,
      "logps/rejected": -173.0847930908203,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0222736597061157,
      "rewards/margins": 8.265396118164062,
      "rewards/rejected": -7.2431230545043945,
      "step": 4075
    },
    {
      "epoch": 1.6303999999999998,
      "grad_norm": 0.00979312602430582,
      "learning_rate": 4.5666666666666665e-07,
      "logits/chosen": -2.0780229568481445,
      "logits/rejected": -3.020897388458252,
      "logps/chosen": -128.30458068847656,
      "logps/rejected": -148.593994140625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.837906837463379,
      "rewards/margins": 9.854242324829102,
      "rewards/rejected": -6.0163350105285645,
      "step": 4076
    },
    {
      "epoch": 1.6308,
      "grad_norm": 0.208542600274086,
      "learning_rate": 4.5653333333333335e-07,
      "logits/chosen": -2.3641672134399414,
      "logits/rejected": -3.2384281158447266,
      "logps/chosen": -100.85906982421875,
      "logps/rejected": -172.1927947998047,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.241276502609253,
      "rewards/margins": 10.415903091430664,
      "rewards/rejected": -7.174626350402832,
      "step": 4077
    },
    {
      "epoch": 1.6312,
      "grad_norm": 0.010171381756663322,
      "learning_rate": 4.5639999999999993e-07,
      "logits/chosen": -1.9399940967559814,
      "logits/rejected": -3.1933701038360596,
      "logps/chosen": -145.01324462890625,
      "logps/rejected": -218.87608337402344,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3322906494140625,
      "rewards/margins": 10.606939315795898,
      "rewards/rejected": -8.274649620056152,
      "step": 4078
    },
    {
      "epoch": 1.6316000000000002,
      "grad_norm": 0.0019495439482852817,
      "learning_rate": 4.562666666666666e-07,
      "logits/chosen": -2.04887056350708,
      "logits/rejected": -2.9536311626434326,
      "logps/chosen": -164.23947143554688,
      "logps/rejected": -189.1324920654297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3516082763671875,
      "rewards/margins": 12.153772354125977,
      "rewards/rejected": -8.802164077758789,
      "step": 4079
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 0.013638635165989399,
      "learning_rate": 4.561333333333333e-07,
      "logits/chosen": -2.2250709533691406,
      "logits/rejected": -3.509305953979492,
      "logps/chosen": -84.51091766357422,
      "logps/rejected": -199.91036987304688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.24288403987884521,
      "rewards/margins": 9.398632049560547,
      "rewards/rejected": -9.64151668548584,
      "step": 4080
    },
    {
      "epoch": 1.6324,
      "grad_norm": 0.0806715190410614,
      "learning_rate": 4.56e-07,
      "logits/chosen": -1.4187511205673218,
      "logits/rejected": -3.356771945953369,
      "logps/chosen": -89.57689666748047,
      "logps/rejected": -193.79452514648438,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1138261556625366,
      "rewards/margins": 8.76438045501709,
      "rewards/rejected": -7.650554180145264,
      "step": 4081
    },
    {
      "epoch": 1.6328,
      "grad_norm": 0.008037992753088474,
      "learning_rate": 4.5586666666666665e-07,
      "logits/chosen": -2.1196205615997314,
      "logits/rejected": -3.1163792610168457,
      "logps/chosen": -152.78695678710938,
      "logps/rejected": -186.06593322753906,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.389751434326172,
      "rewards/margins": 10.010307312011719,
      "rewards/rejected": -7.6205549240112305,
      "step": 4082
    },
    {
      "epoch": 1.6332,
      "grad_norm": 0.004469980951398611,
      "learning_rate": 4.557333333333333e-07,
      "logits/chosen": -1.8787355422973633,
      "logits/rejected": -3.1863579750061035,
      "logps/chosen": -85.35272979736328,
      "logps/rejected": -166.10781860351562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6185994148254395,
      "rewards/margins": 10.230916023254395,
      "rewards/rejected": -6.612317085266113,
      "step": 4083
    },
    {
      "epoch": 1.6336,
      "grad_norm": 0.008272085338830948,
      "learning_rate": 4.556e-07,
      "logits/chosen": -1.99721097946167,
      "logits/rejected": -2.705634355545044,
      "logps/chosen": -121.08258819580078,
      "logps/rejected": -181.64849853515625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.559786319732666,
      "rewards/margins": 11.439399719238281,
      "rewards/rejected": -7.879612922668457,
      "step": 4084
    },
    {
      "epoch": 1.634,
      "grad_norm": 1.4408748149871826,
      "learning_rate": 4.5546666666666667e-07,
      "logits/chosen": -1.751118779182434,
      "logits/rejected": -3.014951705932617,
      "logps/chosen": -141.81033325195312,
      "logps/rejected": -186.66586303710938,
      "loss": 0.0185,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1715770959854126,
      "rewards/margins": 7.234052658081055,
      "rewards/rejected": -7.06247615814209,
      "step": 4085
    },
    {
      "epoch": 1.6343999999999999,
      "grad_norm": 0.006290975958108902,
      "learning_rate": 4.553333333333333e-07,
      "logits/chosen": -1.773911952972412,
      "logits/rejected": -3.290543556213379,
      "logps/chosen": -155.51611328125,
      "logps/rejected": -146.38946533203125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8047797679901123,
      "rewards/margins": 10.671202659606934,
      "rewards/rejected": -7.8664231300354,
      "step": 4086
    },
    {
      "epoch": 1.6348,
      "grad_norm": 10.142115592956543,
      "learning_rate": 4.5519999999999995e-07,
      "logits/chosen": -1.7962335348129272,
      "logits/rejected": -3.1675753593444824,
      "logps/chosen": -119.43763732910156,
      "logps/rejected": -158.50303649902344,
      "loss": 0.0706,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5913715362548828,
      "rewards/margins": 5.682426452636719,
      "rewards/rejected": -6.273797988891602,
      "step": 4087
    },
    {
      "epoch": 1.6352,
      "grad_norm": 0.03274241462349892,
      "learning_rate": 4.5506666666666664e-07,
      "logits/chosen": -1.7965073585510254,
      "logits/rejected": -3.3854246139526367,
      "logps/chosen": -146.28323364257812,
      "logps/rejected": -182.7550048828125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8075672388076782,
      "rewards/margins": 8.83309268951416,
      "rewards/rejected": -8.025525093078613,
      "step": 4088
    },
    {
      "epoch": 1.6356000000000002,
      "grad_norm": 0.0015723423566669226,
      "learning_rate": 4.5493333333333333e-07,
      "logits/chosen": -1.9633426666259766,
      "logits/rejected": -3.5579400062561035,
      "logps/chosen": -164.7808837890625,
      "logps/rejected": -191.35037231445312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2100119590759277,
      "rewards/margins": 12.910493850708008,
      "rewards/rejected": -9.700482368469238,
      "step": 4089
    },
    {
      "epoch": 1.6360000000000001,
      "grad_norm": 0.027037488296628,
      "learning_rate": 4.5479999999999997e-07,
      "logits/chosen": -2.2073404788970947,
      "logits/rejected": -3.2075297832489014,
      "logps/chosen": -128.66680908203125,
      "logps/rejected": -233.16030883789062,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.474461555480957,
      "rewards/margins": 10.521780014038086,
      "rewards/rejected": -7.047318458557129,
      "step": 4090
    },
    {
      "epoch": 1.6364,
      "grad_norm": 0.15932628512382507,
      "learning_rate": 4.5466666666666666e-07,
      "logits/chosen": -2.7102768421173096,
      "logits/rejected": -2.7777938842773438,
      "logps/chosen": -157.53948974609375,
      "logps/rejected": -162.30770874023438,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.891313910484314,
      "rewards/margins": 8.20672607421875,
      "rewards/rejected": -6.315411567687988,
      "step": 4091
    },
    {
      "epoch": 1.6368,
      "grad_norm": 0.057696372270584106,
      "learning_rate": 4.545333333333333e-07,
      "logits/chosen": -1.851688027381897,
      "logits/rejected": -3.6760754585266113,
      "logps/chosen": -60.237586975097656,
      "logps/rejected": -144.96734619140625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7975351810455322,
      "rewards/margins": 8.38296127319336,
      "rewards/rejected": -5.585426330566406,
      "step": 4092
    },
    {
      "epoch": 1.6372,
      "grad_norm": 0.24107491970062256,
      "learning_rate": 4.544e-07,
      "logits/chosen": -2.501786947250366,
      "logits/rejected": -3.420743465423584,
      "logps/chosen": -202.53390502929688,
      "logps/rejected": -177.78445434570312,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13280563056468964,
      "rewards/margins": 6.608153343200684,
      "rewards/rejected": -6.475347995758057,
      "step": 4093
    },
    {
      "epoch": 1.6376,
      "grad_norm": 0.0015043888706713915,
      "learning_rate": 4.5426666666666663e-07,
      "logits/chosen": -2.5238170623779297,
      "logits/rejected": -3.566542148590088,
      "logps/chosen": -164.74337768554688,
      "logps/rejected": -179.73171997070312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.86164927482605,
      "rewards/margins": 11.623632431030273,
      "rewards/rejected": -7.761982440948486,
      "step": 4094
    },
    {
      "epoch": 1.638,
      "grad_norm": 0.013968435116112232,
      "learning_rate": 4.541333333333333e-07,
      "logits/chosen": -1.5615816116333008,
      "logits/rejected": -3.9692203998565674,
      "logps/chosen": -121.53617858886719,
      "logps/rejected": -212.27377319335938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.369348168373108,
      "rewards/margins": 11.804428100585938,
      "rewards/rejected": -10.435079574584961,
      "step": 4095
    },
    {
      "epoch": 1.6383999999999999,
      "grad_norm": 0.13434627652168274,
      "learning_rate": 4.54e-07,
      "logits/chosen": -2.7003931999206543,
      "logits/rejected": -3.5583419799804688,
      "logps/chosen": -262.8890380859375,
      "logps/rejected": -184.87132263183594,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0232490301132202,
      "rewards/margins": 8.815075874328613,
      "rewards/rejected": -7.791826248168945,
      "step": 4096
    },
    {
      "epoch": 1.6388,
      "grad_norm": 0.0591595359146595,
      "learning_rate": 4.538666666666666e-07,
      "logits/chosen": -2.237603187561035,
      "logits/rejected": -3.0147387981414795,
      "logps/chosen": -197.8411102294922,
      "logps/rejected": -199.22930908203125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9245424270629883,
      "rewards/margins": 9.97165584564209,
      "rewards/rejected": -7.047113418579102,
      "step": 4097
    },
    {
      "epoch": 1.6392,
      "grad_norm": 0.0004090233123861253,
      "learning_rate": 4.537333333333333e-07,
      "logits/chosen": -2.2934751510620117,
      "logits/rejected": -3.2423133850097656,
      "logps/chosen": -107.13919067382812,
      "logps/rejected": -294.5835266113281,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.803088665008545,
      "rewards/margins": 13.25684928894043,
      "rewards/rejected": -9.453761100769043,
      "step": 4098
    },
    {
      "epoch": 1.6396,
      "grad_norm": 0.09836126118898392,
      "learning_rate": 4.536e-07,
      "logits/chosen": -2.187404155731201,
      "logits/rejected": -3.0752291679382324,
      "logps/chosen": -91.16764831542969,
      "logps/rejected": -139.26275634765625,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3496475219726562,
      "rewards/margins": 8.644355773925781,
      "rewards/rejected": -5.294708728790283,
      "step": 4099
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.04479840025305748,
      "learning_rate": 4.534666666666667e-07,
      "logits/chosen": -1.8235477209091187,
      "logits/rejected": -2.826542854309082,
      "logps/chosen": -91.8739013671875,
      "logps/rejected": -143.91018676757812,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2715901136398315,
      "rewards/margins": 8.041572570800781,
      "rewards/rejected": -6.769981861114502,
      "step": 4100
    },
    {
      "epoch": 1.6404,
      "grad_norm": 0.01755109429359436,
      "learning_rate": 4.5333333333333326e-07,
      "logits/chosen": -2.588571786880493,
      "logits/rejected": -3.2318451404571533,
      "logps/chosen": -227.54058837890625,
      "logps/rejected": -233.96536254882812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.77703857421875,
      "rewards/margins": 9.153969764709473,
      "rewards/rejected": -8.376931190490723,
      "step": 4101
    },
    {
      "epoch": 1.6408,
      "grad_norm": 0.0008480419055558741,
      "learning_rate": 4.5319999999999996e-07,
      "logits/chosen": -2.1574087142944336,
      "logits/rejected": -3.1183223724365234,
      "logps/chosen": -101.96690368652344,
      "logps/rejected": -213.7489013671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.803952217102051,
      "rewards/margins": 11.721050262451172,
      "rewards/rejected": -8.917097091674805,
      "step": 4102
    },
    {
      "epoch": 1.6412,
      "grad_norm": 0.026564443483948708,
      "learning_rate": 4.5306666666666665e-07,
      "logits/chosen": -2.072923183441162,
      "logits/rejected": -2.9610695838928223,
      "logps/chosen": -123.6207046508789,
      "logps/rejected": -152.536376953125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3175125122070312,
      "rewards/margins": 8.723760604858398,
      "rewards/rejected": -7.406247615814209,
      "step": 4103
    },
    {
      "epoch": 1.6416,
      "grad_norm": 0.34695786237716675,
      "learning_rate": 4.5293333333333334e-07,
      "logits/chosen": -1.753808856010437,
      "logits/rejected": -3.295489549636841,
      "logps/chosen": -103.70329284667969,
      "logps/rejected": -145.26193237304688,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09686833620071411,
      "rewards/margins": 6.203001976013184,
      "rewards/rejected": -6.106133460998535,
      "step": 4104
    },
    {
      "epoch": 1.642,
      "grad_norm": 0.13995131850242615,
      "learning_rate": 4.528e-07,
      "logits/chosen": -1.9593462944030762,
      "logits/rejected": -3.2340188026428223,
      "logps/chosen": -99.6229248046875,
      "logps/rejected": -127.48722839355469,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.64348304271698,
      "rewards/margins": 7.211328506469727,
      "rewards/rejected": -5.567845344543457,
      "step": 4105
    },
    {
      "epoch": 1.6423999999999999,
      "grad_norm": 0.21715648472309113,
      "learning_rate": 4.526666666666666e-07,
      "logits/chosen": -2.0745673179626465,
      "logits/rejected": -3.4118430614471436,
      "logps/chosen": -165.4915771484375,
      "logps/rejected": -249.38845825195312,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.434152364730835,
      "rewards/margins": 6.806663513183594,
      "rewards/rejected": -9.240816116333008,
      "step": 4106
    },
    {
      "epoch": 1.6428,
      "grad_norm": 2.101986885070801,
      "learning_rate": 4.525333333333333e-07,
      "logits/chosen": -2.259650707244873,
      "logits/rejected": -3.4404685497283936,
      "logps/chosen": -186.0618896484375,
      "logps/rejected": -174.92335510253906,
      "loss": 0.0143,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3009907007217407,
      "rewards/margins": 5.356327056884766,
      "rewards/rejected": -6.657317638397217,
      "step": 4107
    },
    {
      "epoch": 1.6432,
      "grad_norm": 0.013037807308137417,
      "learning_rate": 4.524e-07,
      "logits/chosen": -2.122812271118164,
      "logits/rejected": -3.2066287994384766,
      "logps/chosen": -119.90599060058594,
      "logps/rejected": -185.75779724121094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5545455813407898,
      "rewards/margins": 9.077104568481445,
      "rewards/rejected": -8.52255916595459,
      "step": 4108
    },
    {
      "epoch": 1.6436,
      "grad_norm": 0.07714486867189407,
      "learning_rate": 4.5226666666666664e-07,
      "logits/chosen": -2.314225673675537,
      "logits/rejected": -2.8736720085144043,
      "logps/chosen": -123.75111389160156,
      "logps/rejected": -133.99388122558594,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.420816421508789,
      "rewards/margins": 7.75922155380249,
      "rewards/rejected": -5.338405132293701,
      "step": 4109
    },
    {
      "epoch": 1.6440000000000001,
      "grad_norm": 0.007946571335196495,
      "learning_rate": 4.5213333333333333e-07,
      "logits/chosen": -1.9212474822998047,
      "logits/rejected": -3.528073310852051,
      "logps/chosen": -110.69917297363281,
      "logps/rejected": -201.81729125976562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.226632118225098,
      "rewards/margins": 11.493874549865723,
      "rewards/rejected": -7.267242431640625,
      "step": 4110
    },
    {
      "epoch": 1.6444,
      "grad_norm": 0.021311335265636444,
      "learning_rate": 4.5199999999999997e-07,
      "logits/chosen": -2.3490612506866455,
      "logits/rejected": -2.805589199066162,
      "logps/chosen": -126.02178955078125,
      "logps/rejected": -166.6040802001953,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6543693542480469,
      "rewards/margins": 8.526102066040039,
      "rewards/rejected": -7.871732711791992,
      "step": 4111
    },
    {
      "epoch": 1.6448,
      "grad_norm": 0.007554238196462393,
      "learning_rate": 4.5186666666666666e-07,
      "logits/chosen": -1.4831435680389404,
      "logits/rejected": -3.633819103240967,
      "logps/chosen": -112.757080078125,
      "logps/rejected": -186.77838134765625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.06660538166761398,
      "rewards/margins": 9.81332015991211,
      "rewards/rejected": -9.879925727844238,
      "step": 4112
    },
    {
      "epoch": 1.6452,
      "grad_norm": 0.0015424476005136967,
      "learning_rate": 4.517333333333333e-07,
      "logits/chosen": -1.8553285598754883,
      "logits/rejected": -3.7109994888305664,
      "logps/chosen": -99.72482299804688,
      "logps/rejected": -179.8157196044922,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7365920543670654,
      "rewards/margins": 12.043487548828125,
      "rewards/rejected": -8.306896209716797,
      "step": 4113
    },
    {
      "epoch": 1.6456,
      "grad_norm": 0.17223775386810303,
      "learning_rate": 4.516e-07,
      "logits/chosen": -2.4374942779541016,
      "logits/rejected": -3.066333532333374,
      "logps/chosen": -123.39226531982422,
      "logps/rejected": -141.76206970214844,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.147594928741455,
      "rewards/margins": 7.292978286743164,
      "rewards/rejected": -5.145383834838867,
      "step": 4114
    },
    {
      "epoch": 1.646,
      "grad_norm": 0.033521868288517,
      "learning_rate": 4.514666666666667e-07,
      "logits/chosen": -2.1621475219726562,
      "logits/rejected": -3.366036891937256,
      "logps/chosen": -120.0584716796875,
      "logps/rejected": -239.9998779296875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0573582649230957,
      "rewards/margins": 10.19631290435791,
      "rewards/rejected": -7.138955116271973,
      "step": 4115
    },
    {
      "epoch": 1.6463999999999999,
      "grad_norm": 0.0017249356023967266,
      "learning_rate": 4.5133333333333327e-07,
      "logits/chosen": -2.4299893379211426,
      "logits/rejected": -3.561810255050659,
      "logps/chosen": -159.22576904296875,
      "logps/rejected": -179.60922241210938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.673750400543213,
      "rewards/margins": 11.419434547424316,
      "rewards/rejected": -7.745684623718262,
      "step": 4116
    },
    {
      "epoch": 1.6468,
      "grad_norm": 3.0027058124542236,
      "learning_rate": 4.5119999999999996e-07,
      "logits/chosen": -1.781902551651001,
      "logits/rejected": -2.587921619415283,
      "logps/chosen": -105.8463134765625,
      "logps/rejected": -133.640869140625,
      "loss": 0.0178,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08684885501861572,
      "rewards/margins": 5.725918292999268,
      "rewards/rejected": -5.812767028808594,
      "step": 4117
    },
    {
      "epoch": 1.6472,
      "grad_norm": 0.0021809630561619997,
      "learning_rate": 4.5106666666666666e-07,
      "logits/chosen": -1.8155035972595215,
      "logits/rejected": -3.467524766921997,
      "logps/chosen": -111.31590270996094,
      "logps/rejected": -189.41055297851562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.784583568572998,
      "rewards/margins": 12.049057006835938,
      "rewards/rejected": -9.264472961425781,
      "step": 4118
    },
    {
      "epoch": 1.6476,
      "grad_norm": 0.041673608124256134,
      "learning_rate": 4.5093333333333335e-07,
      "logits/chosen": -2.080925941467285,
      "logits/rejected": -2.456019163131714,
      "logps/chosen": -173.91876220703125,
      "logps/rejected": -180.0025177001953,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2649130821228027,
      "rewards/margins": 8.977163314819336,
      "rewards/rejected": -5.712250709533691,
      "step": 4119
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 0.014364996924996376,
      "learning_rate": 4.5079999999999993e-07,
      "logits/chosen": -2.029019355773926,
      "logits/rejected": -3.258364677429199,
      "logps/chosen": -130.68167114257812,
      "logps/rejected": -172.02496337890625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.369204044342041,
      "rewards/margins": 10.768064498901367,
      "rewards/rejected": -7.398860931396484,
      "step": 4120
    },
    {
      "epoch": 1.6484,
      "grad_norm": 0.5204500555992126,
      "learning_rate": 4.506666666666666e-07,
      "logits/chosen": -2.0186867713928223,
      "logits/rejected": -2.4237751960754395,
      "logps/chosen": -218.47833251953125,
      "logps/rejected": -174.1045379638672,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.09551465511322021,
      "rewards/margins": 7.4095234870910645,
      "rewards/rejected": -7.505038261413574,
      "step": 4121
    },
    {
      "epoch": 1.6488,
      "grad_norm": 0.10099504142999649,
      "learning_rate": 4.505333333333333e-07,
      "logits/chosen": -2.274780750274658,
      "logits/rejected": -3.5204195976257324,
      "logps/chosen": -115.64253234863281,
      "logps/rejected": -162.12002563476562,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10648345947265625,
      "rewards/margins": 7.518003463745117,
      "rewards/rejected": -7.411520004272461,
      "step": 4122
    },
    {
      "epoch": 1.6492,
      "grad_norm": 0.0022545848041772842,
      "learning_rate": 4.504e-07,
      "logits/chosen": -2.5007681846618652,
      "logits/rejected": -3.436793804168701,
      "logps/chosen": -148.64532470703125,
      "logps/rejected": -195.44508361816406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.646256446838379,
      "rewards/margins": 11.526548385620117,
      "rewards/rejected": -7.880291938781738,
      "step": 4123
    },
    {
      "epoch": 1.6496,
      "grad_norm": 0.0005028439918532968,
      "learning_rate": 4.5026666666666665e-07,
      "logits/chosen": -1.7714792490005493,
      "logits/rejected": -3.7094740867614746,
      "logps/chosen": -136.07737731933594,
      "logps/rejected": -222.91909790039062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.578514575958252,
      "rewards/margins": 13.584882736206055,
      "rewards/rejected": -11.006368637084961,
      "step": 4124
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.65229332447052,
      "learning_rate": 4.501333333333333e-07,
      "logits/chosen": -1.974684476852417,
      "logits/rejected": -2.694894790649414,
      "logps/chosen": -106.7692642211914,
      "logps/rejected": -160.90721130371094,
      "loss": 0.005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1818270683288574,
      "rewards/margins": 9.115253448486328,
      "rewards/rejected": -6.933426856994629,
      "step": 4125
    },
    {
      "epoch": 1.6503999999999999,
      "grad_norm": 0.04610082507133484,
      "learning_rate": 4.5e-07,
      "logits/chosen": -2.2379026412963867,
      "logits/rejected": -3.397169589996338,
      "logps/chosen": -160.04376220703125,
      "logps/rejected": -164.64694213867188,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7333931922912598,
      "rewards/margins": 8.78171443939209,
      "rewards/rejected": -7.048321723937988,
      "step": 4126
    },
    {
      "epoch": 1.6508,
      "grad_norm": 0.053094252943992615,
      "learning_rate": 4.4986666666666667e-07,
      "logits/chosen": -1.887624740600586,
      "logits/rejected": -2.734445333480835,
      "logps/chosen": -146.49319458007812,
      "logps/rejected": -146.02716064453125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6311420798301697,
      "rewards/margins": 7.60543155670166,
      "rewards/rejected": -6.974289894104004,
      "step": 4127
    },
    {
      "epoch": 1.6512,
      "grad_norm": 0.783719539642334,
      "learning_rate": 4.497333333333333e-07,
      "logits/chosen": -1.8563463687896729,
      "logits/rejected": -3.0510354042053223,
      "logps/chosen": -151.59063720703125,
      "logps/rejected": -193.51824951171875,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8716423511505127,
      "rewards/margins": 6.425015449523926,
      "rewards/rejected": -8.29665756225586,
      "step": 4128
    },
    {
      "epoch": 1.6516,
      "grad_norm": 0.07535264641046524,
      "learning_rate": 4.496e-07,
      "logits/chosen": -2.3593955039978027,
      "logits/rejected": -2.94085693359375,
      "logps/chosen": -81.28594970703125,
      "logps/rejected": -153.69595336914062,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.654116153717041,
      "rewards/margins": 9.787172317504883,
      "rewards/rejected": -6.133056640625,
      "step": 4129
    },
    {
      "epoch": 1.6520000000000001,
      "grad_norm": 0.7390486598014832,
      "learning_rate": 4.4946666666666664e-07,
      "logits/chosen": -1.6910778284072876,
      "logits/rejected": -3.0458993911743164,
      "logps/chosen": -146.72216796875,
      "logps/rejected": -214.06781005859375,
      "loss": 0.0045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3829346001148224,
      "rewards/margins": 6.39219856262207,
      "rewards/rejected": -6.0092644691467285,
      "step": 4130
    },
    {
      "epoch": 1.6524,
      "grad_norm": 3.9633102416992188,
      "learning_rate": 4.493333333333333e-07,
      "logits/chosen": -2.9314651489257812,
      "logits/rejected": -2.9238462448120117,
      "logps/chosen": -188.08920288085938,
      "logps/rejected": -156.1876220703125,
      "loss": 0.037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6432418823242188,
      "rewards/margins": 4.5825018882751465,
      "rewards/rejected": -5.225744247436523,
      "step": 4131
    },
    {
      "epoch": 1.6528,
      "grad_norm": 6.748746818630025e-05,
      "learning_rate": 4.4919999999999997e-07,
      "logits/chosen": -2.1285791397094727,
      "logits/rejected": -3.2044527530670166,
      "logps/chosen": -165.68014526367188,
      "logps/rejected": -241.62911987304688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.367797374725342,
      "rewards/margins": 14.921445846557617,
      "rewards/rejected": -10.55364990234375,
      "step": 4132
    },
    {
      "epoch": 1.6532,
      "grad_norm": 0.09949515014886856,
      "learning_rate": 4.4906666666666666e-07,
      "logits/chosen": -1.5174980163574219,
      "logits/rejected": -3.478754758834839,
      "logps/chosen": -117.92225646972656,
      "logps/rejected": -206.73585510253906,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.13707083463668823,
      "rewards/margins": 9.292266845703125,
      "rewards/rejected": -9.429338455200195,
      "step": 4133
    },
    {
      "epoch": 1.6536,
      "grad_norm": 0.013280666433274746,
      "learning_rate": 4.4893333333333336e-07,
      "logits/chosen": -1.8469480276107788,
      "logits/rejected": -2.8143043518066406,
      "logps/chosen": -76.90377807617188,
      "logps/rejected": -164.8418426513672,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.785060167312622,
      "rewards/margins": 10.817998886108398,
      "rewards/rejected": -8.032938003540039,
      "step": 4134
    },
    {
      "epoch": 1.654,
      "grad_norm": 0.006619621068239212,
      "learning_rate": 4.4879999999999994e-07,
      "logits/chosen": -2.2795422077178955,
      "logits/rejected": -3.2197680473327637,
      "logps/chosen": -132.93540954589844,
      "logps/rejected": -181.39710998535156,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9350795745849609,
      "rewards/margins": 9.719649314880371,
      "rewards/rejected": -8.78456974029541,
      "step": 4135
    },
    {
      "epoch": 1.6543999999999999,
      "grad_norm": 0.01866883412003517,
      "learning_rate": 4.4866666666666663e-07,
      "logits/chosen": -1.9815146923065186,
      "logits/rejected": -3.3601512908935547,
      "logps/chosen": -74.38847351074219,
      "logps/rejected": -165.69480895996094,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6077423095703125,
      "rewards/margins": 10.082550048828125,
      "rewards/rejected": -7.4748077392578125,
      "step": 4136
    },
    {
      "epoch": 1.6548,
      "grad_norm": 1.800112247467041,
      "learning_rate": 4.485333333333333e-07,
      "logits/chosen": -2.629152774810791,
      "logits/rejected": -2.8653688430786133,
      "logps/chosen": -186.4730224609375,
      "logps/rejected": -146.6245880126953,
      "loss": 0.0091,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4650249481201172,
      "rewards/margins": 6.989922046661377,
      "rewards/rejected": -6.52489709854126,
      "step": 4137
    },
    {
      "epoch": 1.6552,
      "grad_norm": 0.012684831395745277,
      "learning_rate": 4.484e-07,
      "logits/chosen": -2.5283102989196777,
      "logits/rejected": -3.3947086334228516,
      "logps/chosen": -227.27610778808594,
      "logps/rejected": -176.1473388671875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.233821153640747,
      "rewards/margins": 9.591983795166016,
      "rewards/rejected": -7.358161926269531,
      "step": 4138
    },
    {
      "epoch": 1.6556,
      "grad_norm": 0.02574280835688114,
      "learning_rate": 4.482666666666666e-07,
      "logits/chosen": -1.7096619606018066,
      "logits/rejected": -2.909925937652588,
      "logps/chosen": -94.51628112792969,
      "logps/rejected": -134.1553955078125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8947067260742188,
      "rewards/margins": 8.813392639160156,
      "rewards/rejected": -5.918686866760254,
      "step": 4139
    },
    {
      "epoch": 1.6560000000000001,
      "grad_norm": 0.26444584131240845,
      "learning_rate": 4.481333333333333e-07,
      "logits/chosen": -2.4501960277557373,
      "logits/rejected": -2.8668203353881836,
      "logps/chosen": -134.13717651367188,
      "logps/rejected": -149.5090789794922,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.09528541564941406,
      "rewards/margins": 6.015427589416504,
      "rewards/rejected": -6.110713005065918,
      "step": 4140
    },
    {
      "epoch": 1.6564,
      "grad_norm": 0.12741033732891083,
      "learning_rate": 4.48e-07,
      "logits/chosen": -1.79921293258667,
      "logits/rejected": -2.9721336364746094,
      "logps/chosen": -79.40608215332031,
      "logps/rejected": -140.20315551757812,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1834301948547363,
      "rewards/margins": 8.216241836547852,
      "rewards/rejected": -6.032811164855957,
      "step": 4141
    },
    {
      "epoch": 1.6568,
      "grad_norm": 0.012712916359305382,
      "learning_rate": 4.478666666666667e-07,
      "logits/chosen": -2.2264740467071533,
      "logits/rejected": -3.433013439178467,
      "logps/chosen": -139.25787353515625,
      "logps/rejected": -194.5197296142578,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.556389331817627,
      "rewards/margins": 12.085926055908203,
      "rewards/rejected": -8.529537200927734,
      "step": 4142
    },
    {
      "epoch": 1.6572,
      "grad_norm": 0.0007071191794238985,
      "learning_rate": 4.477333333333333e-07,
      "logits/chosen": -1.8510633707046509,
      "logits/rejected": -3.55655837059021,
      "logps/chosen": -181.69863891601562,
      "logps/rejected": -240.6901092529297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4647910594940186,
      "rewards/margins": 12.600104331970215,
      "rewards/rejected": -11.135313034057617,
      "step": 4143
    },
    {
      "epoch": 1.6576,
      "grad_norm": 0.14380484819412231,
      "learning_rate": 4.4759999999999996e-07,
      "logits/chosen": -1.4288671016693115,
      "logits/rejected": -3.502715587615967,
      "logps/chosen": -70.16289520263672,
      "logps/rejected": -172.9735107421875,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7238813638687134,
      "rewards/margins": 8.755187034606934,
      "rewards/rejected": -8.031306266784668,
      "step": 4144
    },
    {
      "epoch": 1.658,
      "grad_norm": 0.06492242217063904,
      "learning_rate": 4.4746666666666665e-07,
      "logits/chosen": -1.7871997356414795,
      "logits/rejected": -3.011143207550049,
      "logps/chosen": -105.14509582519531,
      "logps/rejected": -189.24359130859375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.79867023229599,
      "rewards/margins": 8.007505416870117,
      "rewards/rejected": -7.208834648132324,
      "step": 4145
    },
    {
      "epoch": 1.6583999999999999,
      "grad_norm": 0.044886812567710876,
      "learning_rate": 4.4733333333333334e-07,
      "logits/chosen": -2.3481943607330322,
      "logits/rejected": -3.027172565460205,
      "logps/chosen": -79.84222412109375,
      "logps/rejected": -146.3033447265625,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5207706689834595,
      "rewards/margins": 7.992780685424805,
      "rewards/rejected": -6.472010135650635,
      "step": 4146
    },
    {
      "epoch": 1.6588,
      "grad_norm": 0.043443530797958374,
      "learning_rate": 4.472e-07,
      "logits/chosen": -2.285722494125366,
      "logits/rejected": -3.155693531036377,
      "logps/chosen": -267.6551818847656,
      "logps/rejected": -235.89212036132812,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.042806386947632,
      "rewards/margins": 9.879603385925293,
      "rewards/rejected": -7.836796760559082,
      "step": 4147
    },
    {
      "epoch": 1.6592,
      "grad_norm": 0.007805571425706148,
      "learning_rate": 4.4706666666666667e-07,
      "logits/chosen": -2.5836782455444336,
      "logits/rejected": -3.5004220008850098,
      "logps/chosen": -207.42465209960938,
      "logps/rejected": -216.7351531982422,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3899261951446533,
      "rewards/margins": 10.88839054107666,
      "rewards/rejected": -9.498464584350586,
      "step": 4148
    },
    {
      "epoch": 1.6596,
      "grad_norm": 0.037071481347084045,
      "learning_rate": 4.469333333333333e-07,
      "logits/chosen": -2.510478973388672,
      "logits/rejected": -2.8237204551696777,
      "logps/chosen": -169.32046508789062,
      "logps/rejected": -204.0220947265625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8720390796661377,
      "rewards/margins": 9.790322303771973,
      "rewards/rejected": -7.918283462524414,
      "step": 4149
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 0.0009195400052703917,
      "learning_rate": 4.4679999999999995e-07,
      "logits/chosen": -1.7946698665618896,
      "logits/rejected": -3.204270362854004,
      "logps/chosen": -196.1924285888672,
      "logps/rejected": -245.87940979003906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9656165838241577,
      "rewards/margins": 12.313173294067383,
      "rewards/rejected": -11.347556114196777,
      "step": 4150
    },
    {
      "epoch": 1.6604,
      "grad_norm": 0.0009373779757879674,
      "learning_rate": 4.4666666666666664e-07,
      "logits/chosen": -2.2805042266845703,
      "logits/rejected": -3.1863999366760254,
      "logps/chosen": -136.12307739257812,
      "logps/rejected": -190.6756591796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.13436222076416,
      "rewards/margins": 12.111698150634766,
      "rewards/rejected": -7.977334976196289,
      "step": 4151
    },
    {
      "epoch": 1.6608,
      "grad_norm": 0.0032935470808297396,
      "learning_rate": 4.4653333333333333e-07,
      "logits/chosen": -2.254169464111328,
      "logits/rejected": -3.022174835205078,
      "logps/chosen": -134.2982635498047,
      "logps/rejected": -183.63430786132812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8743691444396973,
      "rewards/margins": 12.032058715820312,
      "rewards/rejected": -8.157690048217773,
      "step": 4152
    },
    {
      "epoch": 1.6612,
      "grad_norm": 0.1185019388794899,
      "learning_rate": 4.464e-07,
      "logits/chosen": -2.372314929962158,
      "logits/rejected": -3.8476781845092773,
      "logps/chosen": -146.4765167236328,
      "logps/rejected": -195.8094482421875,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.28648799657821655,
      "rewards/margins": 8.140958786010742,
      "rewards/rejected": -7.854471206665039,
      "step": 4153
    },
    {
      "epoch": 1.6616,
      "grad_norm": 0.023053862154483795,
      "learning_rate": 4.462666666666666e-07,
      "logits/chosen": -2.5558135509490967,
      "logits/rejected": -2.8039965629577637,
      "logps/chosen": -155.93588256835938,
      "logps/rejected": -180.649658203125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3799333572387695,
      "rewards/margins": 9.598599433898926,
      "rewards/rejected": -7.218666076660156,
      "step": 4154
    },
    {
      "epoch": 1.662,
      "grad_norm": 0.0324222594499588,
      "learning_rate": 4.461333333333333e-07,
      "logits/chosen": -1.9861018657684326,
      "logits/rejected": -3.3882198333740234,
      "logps/chosen": -150.47650146484375,
      "logps/rejected": -181.75732421875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7212448120117188,
      "rewards/margins": 8.376331329345703,
      "rewards/rejected": -7.655086517333984,
      "step": 4155
    },
    {
      "epoch": 1.6623999999999999,
      "grad_norm": 0.0008314273436553776,
      "learning_rate": 4.46e-07,
      "logits/chosen": -1.7609531879425049,
      "logits/rejected": -3.0880331993103027,
      "logps/chosen": -107.68345642089844,
      "logps/rejected": -361.39141845703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1682240962982178,
      "rewards/margins": 13.535333633422852,
      "rewards/rejected": -10.367109298706055,
      "step": 4156
    },
    {
      "epoch": 1.6627999999999998,
      "grad_norm": 0.0011732829734683037,
      "learning_rate": 4.458666666666667e-07,
      "logits/chosen": -1.792255163192749,
      "logits/rejected": -3.35176420211792,
      "logps/chosen": -121.10890197753906,
      "logps/rejected": -188.3764190673828,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9494729042053223,
      "rewards/margins": 11.697704315185547,
      "rewards/rejected": -9.748231887817383,
      "step": 4157
    },
    {
      "epoch": 1.6632,
      "grad_norm": 0.001647177035920322,
      "learning_rate": 4.457333333333333e-07,
      "logits/chosen": -1.992185354232788,
      "logits/rejected": -3.7076263427734375,
      "logps/chosen": -151.11322021484375,
      "logps/rejected": -208.0929718017578,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.208022356033325,
      "rewards/margins": 13.327198028564453,
      "rewards/rejected": -11.11917495727539,
      "step": 4158
    },
    {
      "epoch": 1.6636,
      "grad_norm": 0.02914498932659626,
      "learning_rate": 4.4559999999999997e-07,
      "logits/chosen": -2.0271828174591064,
      "logits/rejected": -3.4585442543029785,
      "logps/chosen": -171.9633026123047,
      "logps/rejected": -176.5873565673828,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9112038612365723,
      "rewards/margins": 8.337053298950195,
      "rewards/rejected": -6.425849914550781,
      "step": 4159
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 1.85298752784729,
      "learning_rate": 4.4546666666666666e-07,
      "logits/chosen": -2.386322021484375,
      "logits/rejected": -2.84429931640625,
      "logps/chosen": -190.9613037109375,
      "logps/rejected": -150.30313110351562,
      "loss": 0.0105,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6260818839073181,
      "rewards/margins": 5.9538164138793945,
      "rewards/rejected": -6.579897880554199,
      "step": 4160
    },
    {
      "epoch": 1.6644,
      "grad_norm": 0.007900791242718697,
      "learning_rate": 4.4533333333333335e-07,
      "logits/chosen": -2.22381854057312,
      "logits/rejected": -2.903886556625366,
      "logps/chosen": -147.4903564453125,
      "logps/rejected": -236.8928680419922,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.03666615486145,
      "rewards/margins": 11.118315696716309,
      "rewards/rejected": -8.081649780273438,
      "step": 4161
    },
    {
      "epoch": 1.6648,
      "grad_norm": 0.10909807682037354,
      "learning_rate": 4.452e-07,
      "logits/chosen": -2.3538286685943604,
      "logits/rejected": -3.1522228717803955,
      "logps/chosen": -143.06829833984375,
      "logps/rejected": -133.10879516601562,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1621944904327393,
      "rewards/margins": 6.933132171630859,
      "rewards/rejected": -5.770937919616699,
      "step": 4162
    },
    {
      "epoch": 1.6652,
      "grad_norm": 0.0172975342720747,
      "learning_rate": 4.4506666666666663e-07,
      "logits/chosen": -2.163959503173828,
      "logits/rejected": -3.3607683181762695,
      "logps/chosen": -110.15208435058594,
      "logps/rejected": -234.361083984375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.814466118812561,
      "rewards/margins": 10.104866981506348,
      "rewards/rejected": -8.290401458740234,
      "step": 4163
    },
    {
      "epoch": 1.6656,
      "grad_norm": 0.014026916585862637,
      "learning_rate": 4.449333333333333e-07,
      "logits/chosen": -2.164499521255493,
      "logits/rejected": -3.3167648315429688,
      "logps/chosen": -89.45973205566406,
      "logps/rejected": -186.6561279296875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3661162853240967,
      "rewards/margins": 10.713184356689453,
      "rewards/rejected": -9.347067832946777,
      "step": 4164
    },
    {
      "epoch": 1.666,
      "grad_norm": 0.03249132260680199,
      "learning_rate": 4.4479999999999996e-07,
      "logits/chosen": -1.5993300676345825,
      "logits/rejected": -2.8687047958374023,
      "logps/chosen": -97.06719970703125,
      "logps/rejected": -173.05075073242188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0228066444396973,
      "rewards/margins": 9.109621047973633,
      "rewards/rejected": -8.086814880371094,
      "step": 4165
    },
    {
      "epoch": 1.6663999999999999,
      "grad_norm": 0.06375478953123093,
      "learning_rate": 4.4466666666666665e-07,
      "logits/chosen": -1.7847862243652344,
      "logits/rejected": -3.553314685821533,
      "logps/chosen": -85.66024017333984,
      "logps/rejected": -142.71612548828125,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8591516017913818,
      "rewards/margins": 7.510807991027832,
      "rewards/rejected": -5.651656627655029,
      "step": 4166
    },
    {
      "epoch": 1.6667999999999998,
      "grad_norm": 0.0017170949140563607,
      "learning_rate": 4.445333333333333e-07,
      "logits/chosen": -2.3584396839141846,
      "logits/rejected": -3.80592679977417,
      "logps/chosen": -79.45002746582031,
      "logps/rejected": -183.47683715820312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5760104656219482,
      "rewards/margins": 11.52684211730957,
      "rewards/rejected": -7.950830936431885,
      "step": 4167
    },
    {
      "epoch": 1.6672,
      "grad_norm": 0.018477730453014374,
      "learning_rate": 4.444e-07,
      "logits/chosen": -2.6820483207702637,
      "logits/rejected": -3.13927960395813,
      "logps/chosen": -121.24407958984375,
      "logps/rejected": -172.3152313232422,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.693882942199707,
      "rewards/margins": 11.013786315917969,
      "rewards/rejected": -7.31990385055542,
      "step": 4168
    },
    {
      "epoch": 1.6676,
      "grad_norm": 0.008024790324270725,
      "learning_rate": 4.442666666666666e-07,
      "logits/chosen": -2.0960326194763184,
      "logits/rejected": -3.7458174228668213,
      "logps/chosen": -121.67208099365234,
      "logps/rejected": -228.33998107910156,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.016181182116270065,
      "rewards/margins": 10.490741729736328,
      "rewards/rejected": -10.47456169128418,
      "step": 4169
    },
    {
      "epoch": 1.6680000000000001,
      "grad_norm": 0.003746482077986002,
      "learning_rate": 4.441333333333333e-07,
      "logits/chosen": -2.1540071964263916,
      "logits/rejected": -2.8445682525634766,
      "logps/chosen": -134.33380126953125,
      "logps/rejected": -222.03195190429688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3670971393585205,
      "rewards/margins": 10.658740997314453,
      "rewards/rejected": -7.2916436195373535,
      "step": 4170
    },
    {
      "epoch": 1.6684,
      "grad_norm": 0.1851118952035904,
      "learning_rate": 4.44e-07,
      "logits/chosen": -2.016292095184326,
      "logits/rejected": -3.182471752166748,
      "logps/chosen": -134.25698852539062,
      "logps/rejected": -168.61978149414062,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.18448486924171448,
      "rewards/margins": 7.531641960144043,
      "rewards/rejected": -7.716126441955566,
      "step": 4171
    },
    {
      "epoch": 1.6688,
      "grad_norm": 0.0034246442373842,
      "learning_rate": 4.4386666666666664e-07,
      "logits/chosen": -2.039578676223755,
      "logits/rejected": -3.3717124462127686,
      "logps/chosen": -102.81047821044922,
      "logps/rejected": -163.75088500976562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.48307728767395,
      "rewards/margins": 10.478315353393555,
      "rewards/rejected": -7.995238304138184,
      "step": 4172
    },
    {
      "epoch": 1.6692,
      "grad_norm": 4.126668930053711,
      "learning_rate": 4.437333333333333e-07,
      "logits/chosen": -2.1511693000793457,
      "logits/rejected": -2.7551493644714355,
      "logps/chosen": -146.23727416992188,
      "logps/rejected": -173.55816650390625,
      "loss": 0.0244,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1979278326034546,
      "rewards/margins": 7.605592250823975,
      "rewards/rejected": -6.4076642990112305,
      "step": 4173
    },
    {
      "epoch": 1.6696,
      "grad_norm": 0.0030955367255955935,
      "learning_rate": 4.436e-07,
      "logits/chosen": -2.21187424659729,
      "logits/rejected": -3.1805977821350098,
      "logps/chosen": -163.98568725585938,
      "logps/rejected": -186.66722106933594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7755913734436035,
      "rewards/margins": 11.987367630004883,
      "rewards/rejected": -9.211775779724121,
      "step": 4174
    },
    {
      "epoch": 1.67,
      "grad_norm": 7.398975867545232e-05,
      "learning_rate": 4.4346666666666667e-07,
      "logits/chosen": -2.3496313095092773,
      "logits/rejected": -3.182483196258545,
      "logps/chosen": -171.02212524414062,
      "logps/rejected": -211.27276611328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.9084343910217285,
      "rewards/margins": 14.633584976196289,
      "rewards/rejected": -9.725151062011719,
      "step": 4175
    },
    {
      "epoch": 1.6703999999999999,
      "grad_norm": 0.00535144517198205,
      "learning_rate": 4.4333333333333336e-07,
      "logits/chosen": -2.0645391941070557,
      "logits/rejected": -3.0383777618408203,
      "logps/chosen": -114.86686706542969,
      "logps/rejected": -208.70826721191406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3285374641418457,
      "rewards/margins": 9.936461448669434,
      "rewards/rejected": -7.607923984527588,
      "step": 4176
    },
    {
      "epoch": 1.6707999999999998,
      "grad_norm": 0.007658103480935097,
      "learning_rate": 4.4319999999999995e-07,
      "logits/chosen": -2.140252113342285,
      "logits/rejected": -3.721996784210205,
      "logps/chosen": -95.3779525756836,
      "logps/rejected": -202.2953338623047,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5298302173614502,
      "rewards/margins": 11.107372283935547,
      "rewards/rejected": -9.577542304992676,
      "step": 4177
    },
    {
      "epoch": 1.6712,
      "grad_norm": 0.03204172104597092,
      "learning_rate": 4.4306666666666664e-07,
      "logits/chosen": -2.1426594257354736,
      "logits/rejected": -2.981344699859619,
      "logps/chosen": -111.66626739501953,
      "logps/rejected": -156.90591430664062,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3122894763946533,
      "rewards/margins": 9.57094955444336,
      "rewards/rejected": -7.258660316467285,
      "step": 4178
    },
    {
      "epoch": 1.6716,
      "grad_norm": 0.013135243207216263,
      "learning_rate": 4.4293333333333333e-07,
      "logits/chosen": -2.0859575271606445,
      "logits/rejected": -3.14658784866333,
      "logps/chosen": -73.12677001953125,
      "logps/rejected": -146.1826171875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.64274525642395,
      "rewards/margins": 9.338273048400879,
      "rewards/rejected": -6.695528030395508,
      "step": 4179
    },
    {
      "epoch": 1.6720000000000002,
      "grad_norm": 0.0007768108625896275,
      "learning_rate": 4.428e-07,
      "logits/chosen": -2.270897388458252,
      "logits/rejected": -3.488513946533203,
      "logps/chosen": -117.65776062011719,
      "logps/rejected": -172.32217407226562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8638415336608887,
      "rewards/margins": 12.41701602935791,
      "rewards/rejected": -8.55317497253418,
      "step": 4180
    },
    {
      "epoch": 1.6724,
      "grad_norm": 0.06621317565441132,
      "learning_rate": 4.426666666666666e-07,
      "logits/chosen": -1.5216898918151855,
      "logits/rejected": -3.3106071949005127,
      "logps/chosen": -85.51997375488281,
      "logps/rejected": -170.97430419921875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3927303552627563,
      "rewards/margins": 8.81245231628418,
      "rewards/rejected": -7.419722557067871,
      "step": 4181
    },
    {
      "epoch": 1.6728,
      "grad_norm": 0.06128310784697533,
      "learning_rate": 4.425333333333333e-07,
      "logits/chosen": -2.329735279083252,
      "logits/rejected": -3.4051923751831055,
      "logps/chosen": -96.50138854980469,
      "logps/rejected": -181.39630126953125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5832916498184204,
      "rewards/margins": 7.736135959625244,
      "rewards/rejected": -8.319427490234375,
      "step": 4182
    },
    {
      "epoch": 1.6732,
      "grad_norm": 0.05725233256816864,
      "learning_rate": 4.424e-07,
      "logits/chosen": -2.3097636699676514,
      "logits/rejected": -3.0118393898010254,
      "logps/chosen": -114.32923889160156,
      "logps/rejected": -173.33645629882812,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5762367248535156,
      "rewards/margins": 8.081835746765137,
      "rewards/rejected": -8.658072471618652,
      "step": 4183
    },
    {
      "epoch": 1.6736,
      "grad_norm": 0.00713135302066803,
      "learning_rate": 4.4226666666666663e-07,
      "logits/chosen": -2.1624162197113037,
      "logits/rejected": -3.507861614227295,
      "logps/chosen": -148.00634765625,
      "logps/rejected": -151.7198028564453,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.162087917327881,
      "rewards/margins": 9.958850860595703,
      "rewards/rejected": -6.7967634201049805,
      "step": 4184
    },
    {
      "epoch": 1.674,
      "grad_norm": 0.03522106260061264,
      "learning_rate": 4.421333333333333e-07,
      "logits/chosen": -1.4953954219818115,
      "logits/rejected": -3.598048686981201,
      "logps/chosen": -193.88381958007812,
      "logps/rejected": -197.06468200683594,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9326190948486328,
      "rewards/margins": 8.853008270263672,
      "rewards/rejected": -9.785627365112305,
      "step": 4185
    },
    {
      "epoch": 1.6743999999999999,
      "grad_norm": 0.0032532201148569584,
      "learning_rate": 4.4199999999999996e-07,
      "logits/chosen": -1.917961835861206,
      "logits/rejected": -3.552273750305176,
      "logps/chosen": -143.88558959960938,
      "logps/rejected": -188.68675231933594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6276791095733643,
      "rewards/margins": 10.564016342163086,
      "rewards/rejected": -6.936337471008301,
      "step": 4186
    },
    {
      "epoch": 1.6747999999999998,
      "grad_norm": 0.0034089793916791677,
      "learning_rate": 4.4186666666666665e-07,
      "logits/chosen": -2.292340040206909,
      "logits/rejected": -3.1997265815734863,
      "logps/chosen": -111.62300109863281,
      "logps/rejected": -201.9427490234375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3053066730499268,
      "rewards/margins": 10.876699447631836,
      "rewards/rejected": -8.571393013000488,
      "step": 4187
    },
    {
      "epoch": 1.6752,
      "grad_norm": 0.4113186001777649,
      "learning_rate": 4.417333333333333e-07,
      "logits/chosen": -1.7785892486572266,
      "logits/rejected": -2.949673652648926,
      "logps/chosen": -86.55323028564453,
      "logps/rejected": -160.15382385253906,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27309954166412354,
      "rewards/margins": 7.661463737487793,
      "rewards/rejected": -7.388364315032959,
      "step": 4188
    },
    {
      "epoch": 1.6756,
      "grad_norm": 0.16935542225837708,
      "learning_rate": 4.416e-07,
      "logits/chosen": -2.4436826705932617,
      "logits/rejected": -2.303809642791748,
      "logps/chosen": -208.57798767089844,
      "logps/rejected": -170.68788146972656,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2242889404296875,
      "rewards/margins": 7.135174751281738,
      "rewards/rejected": -7.359463691711426,
      "step": 4189
    },
    {
      "epoch": 1.6760000000000002,
      "grad_norm": 0.011355610564351082,
      "learning_rate": 4.414666666666667e-07,
      "logits/chosen": -2.2392263412475586,
      "logits/rejected": -3.3621482849121094,
      "logps/chosen": -110.08961486816406,
      "logps/rejected": -171.6717071533203,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.143164873123169,
      "rewards/margins": 10.026058197021484,
      "rewards/rejected": -7.882893085479736,
      "step": 4190
    },
    {
      "epoch": 1.6764000000000001,
      "grad_norm": 0.04407597705721855,
      "learning_rate": 4.413333333333333e-07,
      "logits/chosen": -2.0325303077697754,
      "logits/rejected": -3.5324320793151855,
      "logps/chosen": -99.98783874511719,
      "logps/rejected": -161.1529998779297,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3656957149505615,
      "rewards/margins": 9.690675735473633,
      "rewards/rejected": -7.32498025894165,
      "step": 4191
    },
    {
      "epoch": 1.6768,
      "grad_norm": 0.008108987472951412,
      "learning_rate": 4.4119999999999995e-07,
      "logits/chosen": -2.1341183185577393,
      "logits/rejected": -3.6680428981781006,
      "logps/chosen": -133.22515869140625,
      "logps/rejected": -203.49978637695312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7983657717704773,
      "rewards/margins": 9.616683959960938,
      "rewards/rejected": -8.818319320678711,
      "step": 4192
    },
    {
      "epoch": 1.6772,
      "grad_norm": 0.05571539327502251,
      "learning_rate": 4.4106666666666665e-07,
      "logits/chosen": -1.8846454620361328,
      "logits/rejected": -3.5707461833953857,
      "logps/chosen": -100.43502044677734,
      "logps/rejected": -171.04315185546875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8147454261779785,
      "rewards/margins": 8.979090690612793,
      "rewards/rejected": -8.164344787597656,
      "step": 4193
    },
    {
      "epoch": 1.6776,
      "grad_norm": 0.022272678092122078,
      "learning_rate": 4.4093333333333334e-07,
      "logits/chosen": -1.8910611867904663,
      "logits/rejected": -3.210261821746826,
      "logps/chosen": -166.53834533691406,
      "logps/rejected": -183.50794982910156,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4400742053985596,
      "rewards/margins": 9.464786529541016,
      "rewards/rejected": -8.024712562561035,
      "step": 4194
    },
    {
      "epoch": 1.678,
      "grad_norm": 0.11356265097856522,
      "learning_rate": 4.4080000000000003e-07,
      "logits/chosen": -1.6716896295547485,
      "logits/rejected": -3.271618366241455,
      "logps/chosen": -143.85702514648438,
      "logps/rejected": -203.77346801757812,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9004395008087158,
      "rewards/margins": 10.091276168823242,
      "rewards/rejected": -9.190836906433105,
      "step": 4195
    },
    {
      "epoch": 1.6784,
      "grad_norm": 0.20034338533878326,
      "learning_rate": 4.406666666666666e-07,
      "logits/chosen": -2.4341483116149902,
      "logits/rejected": -3.380732536315918,
      "logps/chosen": -111.56295776367188,
      "logps/rejected": -187.50401306152344,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3827145099639893,
      "rewards/margins": 10.0887451171875,
      "rewards/rejected": -7.70603084564209,
      "step": 4196
    },
    {
      "epoch": 1.6787999999999998,
      "grad_norm": 0.007238415535539389,
      "learning_rate": 4.405333333333333e-07,
      "logits/chosen": -1.7559280395507812,
      "logits/rejected": -3.656785488128662,
      "logps/chosen": -124.25188446044922,
      "logps/rejected": -206.43807983398438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3866515159606934,
      "rewards/margins": 10.312385559082031,
      "rewards/rejected": -6.92573356628418,
      "step": 4197
    },
    {
      "epoch": 1.6792,
      "grad_norm": 0.023368898779153824,
      "learning_rate": 4.404e-07,
      "logits/chosen": -1.6313345432281494,
      "logits/rejected": -3.277801513671875,
      "logps/chosen": -62.55007553100586,
      "logps/rejected": -178.22039794921875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8572231531143188,
      "rewards/margins": 10.744171142578125,
      "rewards/rejected": -8.886947631835938,
      "step": 4198
    },
    {
      "epoch": 1.6796,
      "grad_norm": 0.0017685025231912732,
      "learning_rate": 4.4026666666666664e-07,
      "logits/chosen": -1.0827765464782715,
      "logits/rejected": -3.4255452156066895,
      "logps/chosen": -83.28045654296875,
      "logps/rejected": -178.80496215820312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5115158557891846,
      "rewards/margins": 11.04405689239502,
      "rewards/rejected": -8.532541275024414,
      "step": 4199
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.09686470031738281,
      "learning_rate": 4.401333333333333e-07,
      "logits/chosen": -1.9449641704559326,
      "logits/rejected": -3.26824688911438,
      "logps/chosen": -97.07505798339844,
      "logps/rejected": -154.37588500976562,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0891072750091553,
      "rewards/margins": 7.85898494720459,
      "rewards/rejected": -5.7698774337768555,
      "step": 4200
    },
    {
      "epoch": 1.6804000000000001,
      "grad_norm": 0.03518882766366005,
      "learning_rate": 4.3999999999999997e-07,
      "logits/chosen": -2.1451308727264404,
      "logits/rejected": -3.178208589553833,
      "logps/chosen": -137.91378784179688,
      "logps/rejected": -225.03933715820312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6087334156036377,
      "rewards/margins": 8.963542938232422,
      "rewards/rejected": -7.354808807373047,
      "step": 4201
    },
    {
      "epoch": 1.6808,
      "grad_norm": 0.005754435900598764,
      "learning_rate": 4.3986666666666666e-07,
      "logits/chosen": -2.4844937324523926,
      "logits/rejected": -3.469172477722168,
      "logps/chosen": -146.40093994140625,
      "logps/rejected": -201.93679809570312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5440784692764282,
      "rewards/margins": 10.250381469726562,
      "rewards/rejected": -8.706303596496582,
      "step": 4202
    },
    {
      "epoch": 1.6812,
      "grad_norm": 0.0024369945749640465,
      "learning_rate": 4.397333333333333e-07,
      "logits/chosen": -2.1746909618377686,
      "logits/rejected": -3.130674362182617,
      "logps/chosen": -158.1628875732422,
      "logps/rejected": -214.191162109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5116794109344482,
      "rewards/margins": 11.502935409545898,
      "rewards/rejected": -8.991255760192871,
      "step": 4203
    },
    {
      "epoch": 1.6816,
      "grad_norm": 0.006124213337898254,
      "learning_rate": 4.396e-07,
      "logits/chosen": -1.980980396270752,
      "logits/rejected": -3.4708504676818848,
      "logps/chosen": -127.13732147216797,
      "logps/rejected": -201.21661376953125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3482110500335693,
      "rewards/margins": 10.448246002197266,
      "rewards/rejected": -8.100034713745117,
      "step": 4204
    },
    {
      "epoch": 1.682,
      "grad_norm": 0.005925018806010485,
      "learning_rate": 4.3946666666666663e-07,
      "logits/chosen": -2.957625389099121,
      "logits/rejected": -3.630131721496582,
      "logps/chosen": -131.73533630371094,
      "logps/rejected": -183.6124267578125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.485614538192749,
      "rewards/margins": 10.89242172241211,
      "rewards/rejected": -8.406806945800781,
      "step": 4205
    },
    {
      "epoch": 1.6824,
      "grad_norm": 0.0028720134869217873,
      "learning_rate": 4.393333333333333e-07,
      "logits/chosen": -1.623295545578003,
      "logits/rejected": -2.918173313140869,
      "logps/chosen": -98.63882446289062,
      "logps/rejected": -182.7121124267578,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7523608207702637,
      "rewards/margins": 12.280952453613281,
      "rewards/rejected": -8.52859115600586,
      "step": 4206
    },
    {
      "epoch": 1.6827999999999999,
      "grad_norm": 0.0006983142229728401,
      "learning_rate": 4.3919999999999996e-07,
      "logits/chosen": -2.263082981109619,
      "logits/rejected": -3.364625930786133,
      "logps/chosen": -173.09115600585938,
      "logps/rejected": -227.78915405273438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3053619861602783,
      "rewards/margins": 12.518322944641113,
      "rewards/rejected": -9.212961196899414,
      "step": 4207
    },
    {
      "epoch": 1.6832,
      "grad_norm": 0.021338511258363724,
      "learning_rate": 4.3906666666666665e-07,
      "logits/chosen": -2.131702423095703,
      "logits/rejected": -2.865975856781006,
      "logps/chosen": -103.11628723144531,
      "logps/rejected": -292.0255432128906,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.289493203163147,
      "rewards/margins": 12.10987377166748,
      "rewards/rejected": -10.820381164550781,
      "step": 4208
    },
    {
      "epoch": 1.6836,
      "grad_norm": 0.01368923019617796,
      "learning_rate": 4.3893333333333335e-07,
      "logits/chosen": -2.1473820209503174,
      "logits/rejected": -3.5674378871917725,
      "logps/chosen": -111.57682800292969,
      "logps/rejected": -171.61058044433594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2882606983184814,
      "rewards/margins": 9.75149154663086,
      "rewards/rejected": -8.463231086730957,
      "step": 4209
    },
    {
      "epoch": 1.6840000000000002,
      "grad_norm": 0.32253366708755493,
      "learning_rate": 4.388e-07,
      "logits/chosen": -2.631380081176758,
      "logits/rejected": -3.307086706161499,
      "logps/chosen": -135.36428833007812,
      "logps/rejected": -153.68682861328125,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.894622325897217,
      "rewards/margins": 8.330721855163574,
      "rewards/rejected": -5.436099529266357,
      "step": 4210
    },
    {
      "epoch": 1.6844000000000001,
      "grad_norm": 0.01752709224820137,
      "learning_rate": 4.386666666666666e-07,
      "logits/chosen": -2.3397762775421143,
      "logits/rejected": -3.2674789428710938,
      "logps/chosen": -102.85252380371094,
      "logps/rejected": -163.54541015625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.554504871368408,
      "rewards/margins": 9.775554656982422,
      "rewards/rejected": -7.2210493087768555,
      "step": 4211
    },
    {
      "epoch": 1.6848,
      "grad_norm": 0.0010607870062813163,
      "learning_rate": 4.385333333333333e-07,
      "logits/chosen": -1.983675479888916,
      "logits/rejected": -4.005959510803223,
      "logps/chosen": -79.60749816894531,
      "logps/rejected": -207.56219482421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6505333185195923,
      "rewards/margins": 11.646580696105957,
      "rewards/rejected": -9.996047973632812,
      "step": 4212
    },
    {
      "epoch": 1.6852,
      "grad_norm": 9.392986248712987e-05,
      "learning_rate": 4.384e-07,
      "logits/chosen": -2.240978956222534,
      "logits/rejected": -3.2843680381774902,
      "logps/chosen": -91.5230941772461,
      "logps/rejected": -260.8368835449219,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3033154010772705,
      "rewards/margins": 14.687856674194336,
      "rewards/rejected": -11.384540557861328,
      "step": 4213
    },
    {
      "epoch": 1.6856,
      "grad_norm": 2.5448174476623535,
      "learning_rate": 4.3826666666666665e-07,
      "logits/chosen": -2.2049009799957275,
      "logits/rejected": -3.8493175506591797,
      "logps/chosen": -136.90293884277344,
      "logps/rejected": -217.37734985351562,
      "loss": 0.02,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.050348758697509766,
      "rewards/margins": 7.589907169342041,
      "rewards/rejected": -7.539558410644531,
      "step": 4214
    },
    {
      "epoch": 1.686,
      "grad_norm": 0.0021113711409270763,
      "learning_rate": 4.381333333333333e-07,
      "logits/chosen": -2.30937123298645,
      "logits/rejected": -3.6271281242370605,
      "logps/chosen": -92.81462860107422,
      "logps/rejected": -191.5157012939453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.174949645996094,
      "rewards/margins": 12.820765495300293,
      "rewards/rejected": -8.6458158493042,
      "step": 4215
    },
    {
      "epoch": 1.6864,
      "grad_norm": 0.004414593800902367,
      "learning_rate": 4.38e-07,
      "logits/chosen": -2.0438499450683594,
      "logits/rejected": -3.3713245391845703,
      "logps/chosen": -136.02639770507812,
      "logps/rejected": -188.58920288085938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9408555030822754,
      "rewards/margins": 11.326093673706055,
      "rewards/rejected": -8.385238647460938,
      "step": 4216
    },
    {
      "epoch": 1.6867999999999999,
      "grad_norm": 0.022494666278362274,
      "learning_rate": 4.3786666666666667e-07,
      "logits/chosen": -2.5476579666137695,
      "logits/rejected": -3.755263328552246,
      "logps/chosen": -174.4535675048828,
      "logps/rejected": -207.42926025390625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6837615966796875,
      "rewards/margins": 12.144315719604492,
      "rewards/rejected": -10.460554122924805,
      "step": 4217
    },
    {
      "epoch": 1.6872,
      "grad_norm": 0.8594854474067688,
      "learning_rate": 4.377333333333333e-07,
      "logits/chosen": -1.8623569011688232,
      "logits/rejected": -3.229391574859619,
      "logps/chosen": -93.08509826660156,
      "logps/rejected": -174.10540771484375,
      "loss": 0.0084,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0365371704101562,
      "rewards/margins": 8.740964889526367,
      "rewards/rejected": -7.7044267654418945,
      "step": 4218
    },
    {
      "epoch": 1.6876,
      "grad_norm": 0.02451973408460617,
      "learning_rate": 4.3759999999999995e-07,
      "logits/chosen": -2.44630765914917,
      "logits/rejected": -2.625248670578003,
      "logps/chosen": -241.26873779296875,
      "logps/rejected": -212.4078826904297,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0732712745666504,
      "rewards/margins": 8.99111557006836,
      "rewards/rejected": -6.917843818664551,
      "step": 4219
    },
    {
      "epoch": 1.688,
      "grad_norm": 0.006180312484502792,
      "learning_rate": 4.3746666666666664e-07,
      "logits/chosen": -2.11436128616333,
      "logits/rejected": -3.4862253665924072,
      "logps/chosen": -106.21400451660156,
      "logps/rejected": -163.11978149414062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8518686294555664,
      "rewards/margins": 9.940008163452148,
      "rewards/rejected": -7.088139057159424,
      "step": 4220
    },
    {
      "epoch": 1.6884000000000001,
      "grad_norm": 0.06207623705267906,
      "learning_rate": 4.3733333333333333e-07,
      "logits/chosen": -2.0628724098205566,
      "logits/rejected": -3.4542455673217773,
      "logps/chosen": -132.9304962158203,
      "logps/rejected": -214.64089965820312,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5084538459777832,
      "rewards/margins": 11.662281036376953,
      "rewards/rejected": -10.153827667236328,
      "step": 4221
    },
    {
      "epoch": 1.6888,
      "grad_norm": 0.01306951604783535,
      "learning_rate": 4.3719999999999997e-07,
      "logits/chosen": -2.102090835571289,
      "logits/rejected": -3.358689308166504,
      "logps/chosen": -212.16275024414062,
      "logps/rejected": -190.900634765625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.788366675376892,
      "rewards/margins": 9.721582412719727,
      "rewards/rejected": -7.933215141296387,
      "step": 4222
    },
    {
      "epoch": 1.6892,
      "grad_norm": 0.09392724931240082,
      "learning_rate": 4.3706666666666666e-07,
      "logits/chosen": -1.701528549194336,
      "logits/rejected": -3.480985164642334,
      "logps/chosen": -120.07331848144531,
      "logps/rejected": -206.07749938964844,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9006641507148743,
      "rewards/margins": 8.790061950683594,
      "rewards/rejected": -9.690725326538086,
      "step": 4223
    },
    {
      "epoch": 1.6896,
      "grad_norm": 0.09973453730344772,
      "learning_rate": 4.369333333333333e-07,
      "logits/chosen": -2.057596206665039,
      "logits/rejected": -3.0418715476989746,
      "logps/chosen": -74.89863586425781,
      "logps/rejected": -131.83319091796875,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.530273675918579,
      "rewards/margins": 7.370037078857422,
      "rewards/rejected": -4.839763641357422,
      "step": 4224
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.03779451176524162,
      "learning_rate": 4.368e-07,
      "logits/chosen": -2.0234570503234863,
      "logits/rejected": -3.42720627784729,
      "logps/chosen": -157.74725341796875,
      "logps/rejected": -168.81304931640625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9410339593887329,
      "rewards/margins": 8.319695472717285,
      "rewards/rejected": -7.378661632537842,
      "step": 4225
    },
    {
      "epoch": 1.6904,
      "grad_norm": 0.01824638806283474,
      "learning_rate": 4.3666666666666663e-07,
      "logits/chosen": -1.7483878135681152,
      "logits/rejected": -3.4296011924743652,
      "logps/chosen": -90.58448028564453,
      "logps/rejected": -164.2086181640625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7140323519706726,
      "rewards/margins": 8.640893936157227,
      "rewards/rejected": -7.926860809326172,
      "step": 4226
    },
    {
      "epoch": 1.6907999999999999,
      "grad_norm": 0.05637280270457268,
      "learning_rate": 4.365333333333333e-07,
      "logits/chosen": -1.986632227897644,
      "logits/rejected": -2.6672632694244385,
      "logps/chosen": -146.49334716796875,
      "logps/rejected": -149.18614196777344,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3664054870605469,
      "rewards/margins": 8.12925910949707,
      "rewards/rejected": -7.762853622436523,
      "step": 4227
    },
    {
      "epoch": 1.6912,
      "grad_norm": 0.07891016453504562,
      "learning_rate": 4.364e-07,
      "logits/chosen": -2.1313138008117676,
      "logits/rejected": -3.471336841583252,
      "logps/chosen": -108.43742370605469,
      "logps/rejected": -200.04246520996094,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2233680486679077,
      "rewards/margins": 8.064876556396484,
      "rewards/rejected": -9.28824520111084,
      "step": 4228
    },
    {
      "epoch": 1.6916,
      "grad_norm": 0.0612851083278656,
      "learning_rate": 4.3626666666666666e-07,
      "logits/chosen": -2.5309042930603027,
      "logits/rejected": -2.45696759223938,
      "logps/chosen": -110.71802520751953,
      "logps/rejected": -187.38888549804688,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3830106258392334,
      "rewards/margins": 9.833169937133789,
      "rewards/rejected": -7.450159072875977,
      "step": 4229
    },
    {
      "epoch": 1.692,
      "grad_norm": 0.02576018124818802,
      "learning_rate": 4.361333333333333e-07,
      "logits/chosen": -2.02911376953125,
      "logits/rejected": -3.450500965118408,
      "logps/chosen": -85.48532104492188,
      "logps/rejected": -180.74375915527344,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.19481734931468964,
      "rewards/margins": 8.242518424987793,
      "rewards/rejected": -8.437335968017578,
      "step": 4230
    },
    {
      "epoch": 1.6924000000000001,
      "grad_norm": 0.013432045467197895,
      "learning_rate": 4.36e-07,
      "logits/chosen": -2.192002773284912,
      "logits/rejected": -3.5870184898376465,
      "logps/chosen": -127.38216400146484,
      "logps/rejected": -188.27389526367188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.044798374176025,
      "rewards/margins": 11.477309226989746,
      "rewards/rejected": -7.4325103759765625,
      "step": 4231
    },
    {
      "epoch": 1.6928,
      "grad_norm": 0.02398589625954628,
      "learning_rate": 4.358666666666667e-07,
      "logits/chosen": -2.593834400177002,
      "logits/rejected": -2.8746731281280518,
      "logps/chosen": -102.97950744628906,
      "logps/rejected": -152.75857543945312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.499793767929077,
      "rewards/margins": 10.16141128540039,
      "rewards/rejected": -6.661617279052734,
      "step": 4232
    },
    {
      "epoch": 1.6932,
      "grad_norm": 0.05261513218283653,
      "learning_rate": 4.3573333333333326e-07,
      "logits/chosen": -2.165152072906494,
      "logits/rejected": -2.8364439010620117,
      "logps/chosen": -171.35829162597656,
      "logps/rejected": -175.15135192871094,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10941696912050247,
      "rewards/margins": 7.697933197021484,
      "rewards/rejected": -7.807350158691406,
      "step": 4233
    },
    {
      "epoch": 1.6936,
      "grad_norm": 0.029595548287034035,
      "learning_rate": 4.3559999999999996e-07,
      "logits/chosen": -1.4894733428955078,
      "logits/rejected": -3.064349889755249,
      "logps/chosen": -125.77876281738281,
      "logps/rejected": -150.75648498535156,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4698082208633423,
      "rewards/margins": 8.765520095825195,
      "rewards/rejected": -7.295711517333984,
      "step": 4234
    },
    {
      "epoch": 1.694,
      "grad_norm": 0.28405848145484924,
      "learning_rate": 4.3546666666666665e-07,
      "logits/chosen": -2.0229618549346924,
      "logits/rejected": -3.4949827194213867,
      "logps/chosen": -176.18667602539062,
      "logps/rejected": -183.7418212890625,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2559020519256592,
      "rewards/margins": 8.544815063476562,
      "rewards/rejected": -8.28891372680664,
      "step": 4235
    },
    {
      "epoch": 1.6944,
      "grad_norm": 0.004262684378772974,
      "learning_rate": 4.3533333333333334e-07,
      "logits/chosen": -2.0074524879455566,
      "logits/rejected": -3.7281930446624756,
      "logps/chosen": -120.1085433959961,
      "logps/rejected": -176.7715606689453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.501580238342285,
      "rewards/margins": 11.110702514648438,
      "rewards/rejected": -8.609122276306152,
      "step": 4236
    },
    {
      "epoch": 1.6947999999999999,
      "grad_norm": 0.01674247533082962,
      "learning_rate": 4.352e-07,
      "logits/chosen": -1.8503904342651367,
      "logits/rejected": -3.2988786697387695,
      "logps/chosen": -73.56570434570312,
      "logps/rejected": -164.81106567382812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6480634212493896,
      "rewards/margins": 9.764589309692383,
      "rewards/rejected": -7.1165266036987305,
      "step": 4237
    },
    {
      "epoch": 1.6952,
      "grad_norm": 0.006955340038985014,
      "learning_rate": 4.350666666666666e-07,
      "logits/chosen": -1.947880744934082,
      "logits/rejected": -3.662775993347168,
      "logps/chosen": -85.46675109863281,
      "logps/rejected": -222.98489379882812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.708176851272583,
      "rewards/margins": 10.863836288452148,
      "rewards/rejected": -9.155658721923828,
      "step": 4238
    },
    {
      "epoch": 1.6956,
      "grad_norm": 0.010424715466797352,
      "learning_rate": 4.349333333333333e-07,
      "logits/chosen": -1.7489583492279053,
      "logits/rejected": -3.329068660736084,
      "logps/chosen": -126.47525787353516,
      "logps/rejected": -169.6421661376953,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9774773120880127,
      "rewards/margins": 9.219867706298828,
      "rewards/rejected": -7.242390155792236,
      "step": 4239
    },
    {
      "epoch": 1.696,
      "grad_norm": 0.0002727967221289873,
      "learning_rate": 4.348e-07,
      "logits/chosen": -2.366292953491211,
      "logits/rejected": -2.8609681129455566,
      "logps/chosen": -106.1278305053711,
      "logps/rejected": -195.144287109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8671295642852783,
      "rewards/margins": 12.946662902832031,
      "rewards/rejected": -9.079532623291016,
      "step": 4240
    },
    {
      "epoch": 1.6964000000000001,
      "grad_norm": 0.09819579869508743,
      "learning_rate": 4.3466666666666664e-07,
      "logits/chosen": -2.3369760513305664,
      "logits/rejected": -3.0611987113952637,
      "logps/chosen": -164.04953002929688,
      "logps/rejected": -175.50759887695312,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5962905883789062,
      "rewards/margins": 7.172918319702148,
      "rewards/rejected": -6.576627731323242,
      "step": 4241
    },
    {
      "epoch": 1.6968,
      "grad_norm": 0.03679192438721657,
      "learning_rate": 4.3453333333333333e-07,
      "logits/chosen": -2.256072759628296,
      "logits/rejected": -3.275935649871826,
      "logps/chosen": -70.56759643554688,
      "logps/rejected": -159.73440551757812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.30167818069458,
      "rewards/margins": 9.87558650970459,
      "rewards/rejected": -7.57390832901001,
      "step": 4242
    },
    {
      "epoch": 1.6972,
      "grad_norm": 0.10727415233850479,
      "learning_rate": 4.3439999999999997e-07,
      "logits/chosen": -1.6278082132339478,
      "logits/rejected": -3.0629289150238037,
      "logps/chosen": -62.054195404052734,
      "logps/rejected": -178.99673461914062,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1568355560302734,
      "rewards/margins": 9.250626564025879,
      "rewards/rejected": -8.093791007995605,
      "step": 4243
    },
    {
      "epoch": 1.6976,
      "grad_norm": 0.02547568455338478,
      "learning_rate": 4.3426666666666666e-07,
      "logits/chosen": -1.9912887811660767,
      "logits/rejected": -3.388186454772949,
      "logps/chosen": -86.71040344238281,
      "logps/rejected": -139.28094482421875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7172305583953857,
      "rewards/margins": 8.8385009765625,
      "rewards/rejected": -6.121271133422852,
      "step": 4244
    },
    {
      "epoch": 1.698,
      "grad_norm": 0.3847975730895996,
      "learning_rate": 4.341333333333333e-07,
      "logits/chosen": -1.734872579574585,
      "logits/rejected": -2.422196865081787,
      "logps/chosen": -142.38818359375,
      "logps/rejected": -158.95681762695312,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7028831243515015,
      "rewards/margins": 7.009753227233887,
      "rewards/rejected": -6.306869983673096,
      "step": 4245
    },
    {
      "epoch": 1.6984,
      "grad_norm": 0.13502901792526245,
      "learning_rate": 4.34e-07,
      "logits/chosen": -1.9620029926300049,
      "logits/rejected": -2.8807010650634766,
      "logps/chosen": -139.4577178955078,
      "logps/rejected": -183.95973205566406,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.047672748565674,
      "rewards/margins": 8.470475196838379,
      "rewards/rejected": -6.422802448272705,
      "step": 4246
    },
    {
      "epoch": 1.6987999999999999,
      "grad_norm": 0.006393392104655504,
      "learning_rate": 4.3386666666666663e-07,
      "logits/chosen": -1.9950138330459595,
      "logits/rejected": -3.113682270050049,
      "logps/chosen": -98.5474624633789,
      "logps/rejected": -175.3829345703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.499441623687744,
      "rewards/margins": 10.718649864196777,
      "rewards/rejected": -7.219208240509033,
      "step": 4247
    },
    {
      "epoch": 1.6992,
      "grad_norm": 0.06732770800590515,
      "learning_rate": 4.337333333333333e-07,
      "logits/chosen": -2.135167121887207,
      "logits/rejected": -3.401449680328369,
      "logps/chosen": -120.26802825927734,
      "logps/rejected": -162.53224182128906,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9361180067062378,
      "rewards/margins": 8.518505096435547,
      "rewards/rejected": -7.5823869705200195,
      "step": 4248
    },
    {
      "epoch": 1.6996,
      "grad_norm": 0.03230343014001846,
      "learning_rate": 4.3359999999999997e-07,
      "logits/chosen": -2.1705782413482666,
      "logits/rejected": -3.4020097255706787,
      "logps/chosen": -177.60824584960938,
      "logps/rejected": -169.697021484375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2348175048828125,
      "rewards/margins": 8.304887771606445,
      "rewards/rejected": -8.539705276489258,
      "step": 4249
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.06560052931308746,
      "learning_rate": 4.3346666666666666e-07,
      "logits/chosen": -1.8648545742034912,
      "logits/rejected": -3.2827773094177246,
      "logps/chosen": -105.05899047851562,
      "logps/rejected": -171.87893676757812,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1887283325195312,
      "rewards/margins": 9.204614639282227,
      "rewards/rejected": -8.015886306762695,
      "step": 4250
    },
    {
      "epoch": 1.7004000000000001,
      "grad_norm": 0.08645515888929367,
      "learning_rate": 4.3333333333333335e-07,
      "logits/chosen": -1.8884809017181396,
      "logits/rejected": -3.2898788452148438,
      "logps/chosen": -135.57470703125,
      "logps/rejected": -158.51890563964844,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.05155348777771,
      "rewards/margins": 7.358851432800293,
      "rewards/rejected": -5.307297706604004,
      "step": 4251
    },
    {
      "epoch": 1.7008,
      "grad_norm": 0.009251571260392666,
      "learning_rate": 4.3319999999999994e-07,
      "logits/chosen": -1.6843655109405518,
      "logits/rejected": -3.3934926986694336,
      "logps/chosen": -176.52725219726562,
      "logps/rejected": -180.55633544921875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.134152889251709,
      "rewards/margins": 10.576627731323242,
      "rewards/rejected": -7.442474365234375,
      "step": 4252
    },
    {
      "epoch": 1.7012,
      "grad_norm": 0.3023543953895569,
      "learning_rate": 4.3306666666666663e-07,
      "logits/chosen": -2.0210981369018555,
      "logits/rejected": -2.7907562255859375,
      "logps/chosen": -88.6214828491211,
      "logps/rejected": -151.51028442382812,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2220163345336914,
      "rewards/margins": 8.2112455368042,
      "rewards/rejected": -6.989229679107666,
      "step": 4253
    },
    {
      "epoch": 1.7016,
      "grad_norm": 0.027262946590781212,
      "learning_rate": 4.329333333333333e-07,
      "logits/chosen": -1.495260238647461,
      "logits/rejected": -3.0106377601623535,
      "logps/chosen": -116.2103042602539,
      "logps/rejected": -175.39813232421875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1346886157989502,
      "rewards/margins": 9.58893871307373,
      "rewards/rejected": -8.45425033569336,
      "step": 4254
    },
    {
      "epoch": 1.702,
      "grad_norm": 0.05975084751844406,
      "learning_rate": 4.328e-07,
      "logits/chosen": -2.204916477203369,
      "logits/rejected": -2.670942783355713,
      "logps/chosen": -218.56546020507812,
      "logps/rejected": -165.06430053710938,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1008307933807373,
      "rewards/margins": 8.526840209960938,
      "rewards/rejected": -7.426009178161621,
      "step": 4255
    },
    {
      "epoch": 1.7024,
      "grad_norm": 0.0006281561800278723,
      "learning_rate": 4.3266666666666665e-07,
      "logits/chosen": -2.1268832683563232,
      "logits/rejected": -3.535895347595215,
      "logps/chosen": -144.52621459960938,
      "logps/rejected": -274.6437683105469,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.355602264404297,
      "rewards/margins": 15.754251480102539,
      "rewards/rejected": -12.398649215698242,
      "step": 4256
    },
    {
      "epoch": 1.7027999999999999,
      "grad_norm": 0.01753837987780571,
      "learning_rate": 4.325333333333333e-07,
      "logits/chosen": -1.6323646306991577,
      "logits/rejected": -2.9395294189453125,
      "logps/chosen": -160.0963592529297,
      "logps/rejected": -159.44851684570312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.145965576171875,
      "rewards/margins": 9.255842208862305,
      "rewards/rejected": -5.10987663269043,
      "step": 4257
    },
    {
      "epoch": 1.7032,
      "grad_norm": 0.4246770143508911,
      "learning_rate": 4.324e-07,
      "logits/chosen": -2.6447672843933105,
      "logits/rejected": -3.205911159515381,
      "logps/chosen": -163.03936767578125,
      "logps/rejected": -175.2103729248047,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.057928502559661865,
      "rewards/margins": 7.967505931854248,
      "rewards/rejected": -8.025434494018555,
      "step": 4258
    },
    {
      "epoch": 1.7036,
      "grad_norm": 0.07094123959541321,
      "learning_rate": 4.3226666666666667e-07,
      "logits/chosen": -1.6091476678848267,
      "logits/rejected": -3.3365516662597656,
      "logps/chosen": -117.30592346191406,
      "logps/rejected": -164.61553955078125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1048386096954346,
      "rewards/margins": 8.696479797363281,
      "rewards/rejected": -6.591641426086426,
      "step": 4259
    },
    {
      "epoch": 1.704,
      "grad_norm": 0.06329302489757538,
      "learning_rate": 4.321333333333333e-07,
      "logits/chosen": -2.048112630844116,
      "logits/rejected": -3.627718925476074,
      "logps/chosen": -164.5434112548828,
      "logps/rejected": -177.1190185546875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3993972539901733,
      "rewards/margins": 9.508170127868652,
      "rewards/rejected": -8.108773231506348,
      "step": 4260
    },
    {
      "epoch": 1.7044000000000001,
      "grad_norm": 0.022335855290293694,
      "learning_rate": 4.3199999999999995e-07,
      "logits/chosen": -1.774657964706421,
      "logits/rejected": -3.3257861137390137,
      "logps/chosen": -98.95863342285156,
      "logps/rejected": -169.78961181640625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8911793231964111,
      "rewards/margins": 9.429213523864746,
      "rewards/rejected": -7.538034439086914,
      "step": 4261
    },
    {
      "epoch": 1.7048,
      "grad_norm": 0.02206660434603691,
      "learning_rate": 4.3186666666666664e-07,
      "logits/chosen": -1.730233073234558,
      "logits/rejected": -3.583707332611084,
      "logps/chosen": -109.3098373413086,
      "logps/rejected": -169.26339721679688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4186348915100098,
      "rewards/margins": 9.741936683654785,
      "rewards/rejected": -7.323301792144775,
      "step": 4262
    },
    {
      "epoch": 1.7052,
      "grad_norm": 0.0005548787885345519,
      "learning_rate": 4.3173333333333333e-07,
      "logits/chosen": -2.4172167778015137,
      "logits/rejected": -3.8114166259765625,
      "logps/chosen": -155.14747619628906,
      "logps/rejected": -181.90431213378906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9886512756347656,
      "rewards/margins": 12.396397590637207,
      "rewards/rejected": -8.407746315002441,
      "step": 4263
    },
    {
      "epoch": 1.7056,
      "grad_norm": 0.4923163950443268,
      "learning_rate": 4.316e-07,
      "logits/chosen": -1.818061113357544,
      "logits/rejected": -2.8097519874572754,
      "logps/chosen": -105.63424682617188,
      "logps/rejected": -123.3045883178711,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7304401397705078,
      "rewards/margins": 6.857187271118164,
      "rewards/rejected": -5.1267476081848145,
      "step": 4264
    },
    {
      "epoch": 1.706,
      "grad_norm": 0.008769742213189602,
      "learning_rate": 4.3146666666666667e-07,
      "logits/chosen": -2.383779764175415,
      "logits/rejected": -3.2965240478515625,
      "logps/chosen": -118.23664093017578,
      "logps/rejected": -203.37216186523438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5758563876152039,
      "rewards/margins": 9.826300621032715,
      "rewards/rejected": -9.250444412231445,
      "step": 4265
    },
    {
      "epoch": 1.7064,
      "grad_norm": 0.25688591599464417,
      "learning_rate": 4.313333333333333e-07,
      "logits/chosen": -1.6346466541290283,
      "logits/rejected": -3.0241806507110596,
      "logps/chosen": -145.57720947265625,
      "logps/rejected": -174.43060302734375,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1471002101898193,
      "rewards/margins": 8.666328430175781,
      "rewards/rejected": -7.519227981567383,
      "step": 4266
    },
    {
      "epoch": 1.7067999999999999,
      "grad_norm": 0.030337976291775703,
      "learning_rate": 4.312e-07,
      "logits/chosen": -1.7226381301879883,
      "logits/rejected": -2.9541234970092773,
      "logps/chosen": -85.92669677734375,
      "logps/rejected": -141.4953155517578,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5911693572998047,
      "rewards/margins": 8.211504936218262,
      "rewards/rejected": -6.620336055755615,
      "step": 4267
    },
    {
      "epoch": 1.7072,
      "grad_norm": 0.017510853707790375,
      "learning_rate": 4.3106666666666664e-07,
      "logits/chosen": -2.104149341583252,
      "logits/rejected": -2.7439985275268555,
      "logps/chosen": -72.53482055664062,
      "logps/rejected": -154.12356567382812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.713122844696045,
      "rewards/margins": 9.57905101776123,
      "rewards/rejected": -6.865927696228027,
      "step": 4268
    },
    {
      "epoch": 1.7076,
      "grad_norm": 0.4220002293586731,
      "learning_rate": 4.3093333333333333e-07,
      "logits/chosen": -2.1669394969940186,
      "logits/rejected": -3.2695913314819336,
      "logps/chosen": -105.87406921386719,
      "logps/rejected": -143.3636474609375,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.706106662750244,
      "rewards/margins": 8.562917709350586,
      "rewards/rejected": -5.856810569763184,
      "step": 4269
    },
    {
      "epoch": 1.708,
      "grad_norm": 0.9826183319091797,
      "learning_rate": 4.308e-07,
      "logits/chosen": -1.656740427017212,
      "logits/rejected": -2.9166579246520996,
      "logps/chosen": -119.49755859375,
      "logps/rejected": -151.09747314453125,
      "loss": 0.0057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3438282310962677,
      "rewards/margins": 6.451700210571289,
      "rewards/rejected": -6.795528411865234,
      "step": 4270
    },
    {
      "epoch": 1.7084000000000001,
      "grad_norm": 1.6738934516906738,
      "learning_rate": 4.306666666666666e-07,
      "logits/chosen": -2.726750373840332,
      "logits/rejected": -2.996291399002075,
      "logps/chosen": -154.04837036132812,
      "logps/rejected": -142.340087890625,
      "loss": 0.0118,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7328891754150391,
      "rewards/margins": 7.071812152862549,
      "rewards/rejected": -6.33892297744751,
      "step": 4271
    },
    {
      "epoch": 1.7088,
      "grad_norm": 0.02329239621758461,
      "learning_rate": 4.305333333333333e-07,
      "logits/chosen": -2.815610885620117,
      "logits/rejected": -3.0640673637390137,
      "logps/chosen": -129.25784301757812,
      "logps/rejected": -152.41983032226562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.15032958984375,
      "rewards/margins": 9.686277389526367,
      "rewards/rejected": -6.535947799682617,
      "step": 4272
    },
    {
      "epoch": 1.7092,
      "grad_norm": 1.1148885488510132,
      "learning_rate": 4.304e-07,
      "logits/chosen": -1.1033765077590942,
      "logits/rejected": -2.5192084312438965,
      "logps/chosen": -71.50469970703125,
      "logps/rejected": -112.28248596191406,
      "loss": 0.0114,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0490074157714844,
      "rewards/margins": 5.525553226470947,
      "rewards/rejected": -3.476545810699463,
      "step": 4273
    },
    {
      "epoch": 1.7096,
      "grad_norm": 0.004228026140481234,
      "learning_rate": 4.302666666666667e-07,
      "logits/chosen": -2.045518636703491,
      "logits/rejected": -2.8458056449890137,
      "logps/chosen": -117.61955261230469,
      "logps/rejected": -243.28189086914062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7430419921875,
      "rewards/margins": 11.097561836242676,
      "rewards/rejected": -9.354519844055176,
      "step": 4274
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.05044793710112572,
      "learning_rate": 4.3013333333333327e-07,
      "logits/chosen": -1.9315454959869385,
      "logits/rejected": -3.1950345039367676,
      "logps/chosen": -110.26559448242188,
      "logps/rejected": -178.9033660888672,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4557106494903564,
      "rewards/margins": 9.174091339111328,
      "rewards/rejected": -7.718379974365234,
      "step": 4275
    },
    {
      "epoch": 1.7104,
      "grad_norm": 2.2691702842712402,
      "learning_rate": 4.2999999999999996e-07,
      "logits/chosen": -2.1797127723693848,
      "logits/rejected": -3.309762477874756,
      "logps/chosen": -198.71688842773438,
      "logps/rejected": -175.7523956298828,
      "loss": 0.0134,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1888366937637329,
      "rewards/margins": 6.683148384094238,
      "rewards/rejected": -6.871984958648682,
      "step": 4276
    },
    {
      "epoch": 1.7107999999999999,
      "grad_norm": 0.014820613898336887,
      "learning_rate": 4.2986666666666665e-07,
      "logits/chosen": -1.8268967866897583,
      "logits/rejected": -2.6947522163391113,
      "logps/chosen": -82.94635009765625,
      "logps/rejected": -155.66168212890625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.513535737991333,
      "rewards/margins": 9.912880897521973,
      "rewards/rejected": -6.3993449211120605,
      "step": 4277
    },
    {
      "epoch": 1.7112,
      "grad_norm": 0.19083531200885773,
      "learning_rate": 4.2973333333333334e-07,
      "logits/chosen": -1.965713620185852,
      "logits/rejected": -3.1830172538757324,
      "logps/chosen": -152.59786987304688,
      "logps/rejected": -186.24790954589844,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.49719810485839844,
      "rewards/margins": 6.758814811706543,
      "rewards/rejected": -6.2616167068481445,
      "step": 4278
    },
    {
      "epoch": 1.7116,
      "grad_norm": 1.4388254880905151,
      "learning_rate": 4.296e-07,
      "logits/chosen": -2.819631338119507,
      "logits/rejected": -3.507100820541382,
      "logps/chosen": -150.91827392578125,
      "logps/rejected": -176.68649291992188,
      "loss": 0.0108,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.039899587631225586,
      "rewards/margins": 7.9923505783081055,
      "rewards/rejected": -8.032249450683594,
      "step": 4279
    },
    {
      "epoch": 1.712,
      "grad_norm": 0.0091875484213233,
      "learning_rate": 4.294666666666666e-07,
      "logits/chosen": -2.0347700119018555,
      "logits/rejected": -3.748532295227051,
      "logps/chosen": -159.6985321044922,
      "logps/rejected": -172.59347534179688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1017944812774658,
      "rewards/margins": 9.685046195983887,
      "rewards/rejected": -8.583251953125,
      "step": 4280
    },
    {
      "epoch": 1.7124000000000001,
      "grad_norm": 0.0003308879677206278,
      "learning_rate": 4.293333333333333e-07,
      "logits/chosen": -2.425632953643799,
      "logits/rejected": -3.3506317138671875,
      "logps/chosen": -186.61131286621094,
      "logps/rejected": -220.11767578125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.802773952484131,
      "rewards/margins": 12.966375350952148,
      "rewards/rejected": -9.16360092163086,
      "step": 4281
    },
    {
      "epoch": 1.7128,
      "grad_norm": 0.03895920142531395,
      "learning_rate": 4.292e-07,
      "logits/chosen": -2.064025402069092,
      "logits/rejected": -2.7586207389831543,
      "logps/chosen": -141.08782958984375,
      "logps/rejected": -169.50692749023438,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5794346332550049,
      "rewards/margins": 8.305459976196289,
      "rewards/rejected": -6.726025581359863,
      "step": 4282
    },
    {
      "epoch": 1.7132,
      "grad_norm": 0.13083690404891968,
      "learning_rate": 4.2906666666666664e-07,
      "logits/chosen": -1.7833664417266846,
      "logits/rejected": -3.5566391944885254,
      "logps/chosen": -128.90667724609375,
      "logps/rejected": -195.67259216308594,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1587440967559814,
      "rewards/margins": 7.9844207763671875,
      "rewards/rejected": -6.825676441192627,
      "step": 4283
    },
    {
      "epoch": 1.7136,
      "grad_norm": 0.00016090442659333348,
      "learning_rate": 4.2893333333333334e-07,
      "logits/chosen": -2.3146047592163086,
      "logits/rejected": -3.544342279434204,
      "logps/chosen": -132.51730346679688,
      "logps/rejected": -246.26901245117188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.743995666503906,
      "rewards/margins": 14.087255477905273,
      "rewards/rejected": -9.343259811401367,
      "step": 4284
    },
    {
      "epoch": 1.714,
      "grad_norm": 0.00048604983021505177,
      "learning_rate": 4.288e-07,
      "logits/chosen": -2.331756830215454,
      "logits/rejected": -3.2990548610687256,
      "logps/chosen": -182.90670776367188,
      "logps/rejected": -190.5096893310547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.587385654449463,
      "rewards/margins": 12.917555809020996,
      "rewards/rejected": -8.330169677734375,
      "step": 4285
    },
    {
      "epoch": 1.7144,
      "grad_norm": 0.04033074155449867,
      "learning_rate": 4.286666666666666e-07,
      "logits/chosen": -1.83231782913208,
      "logits/rejected": -2.931291341781616,
      "logps/chosen": -97.13690185546875,
      "logps/rejected": -139.33998107910156,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6529899835586548,
      "rewards/margins": 7.969704627990723,
      "rewards/rejected": -6.316715240478516,
      "step": 4286
    },
    {
      "epoch": 1.7147999999999999,
      "grad_norm": 0.0019350877264514565,
      "learning_rate": 4.285333333333333e-07,
      "logits/chosen": -1.7689659595489502,
      "logits/rejected": -2.7330832481384277,
      "logps/chosen": -70.49658966064453,
      "logps/rejected": -158.88934326171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.131269454956055,
      "rewards/margins": 11.197397232055664,
      "rewards/rejected": -7.066128730773926,
      "step": 4287
    },
    {
      "epoch": 1.7151999999999998,
      "grad_norm": 0.06163902208209038,
      "learning_rate": 4.284e-07,
      "logits/chosen": -1.9968775510787964,
      "logits/rejected": -3.3265089988708496,
      "logps/chosen": -73.02577209472656,
      "logps/rejected": -182.71994018554688,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9621990919113159,
      "rewards/margins": 8.142606735229492,
      "rewards/rejected": -7.180407524108887,
      "step": 4288
    },
    {
      "epoch": 1.7156,
      "grad_norm": 0.10670578479766846,
      "learning_rate": 4.282666666666667e-07,
      "logits/chosen": -2.3735053539276123,
      "logits/rejected": -3.5499911308288574,
      "logps/chosen": -90.44599914550781,
      "logps/rejected": -160.00527954101562,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13114242255687714,
      "rewards/margins": 7.34739351272583,
      "rewards/rejected": -7.216250896453857,
      "step": 4289
    },
    {
      "epoch": 1.716,
      "grad_norm": 0.12550096213817596,
      "learning_rate": 4.281333333333333e-07,
      "logits/chosen": -2.068042039871216,
      "logits/rejected": -3.2287044525146484,
      "logps/chosen": -141.32354736328125,
      "logps/rejected": -214.87677001953125,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3453829288482666,
      "rewards/margins": 10.735891342163086,
      "rewards/rejected": -8.390508651733398,
      "step": 4290
    },
    {
      "epoch": 1.7164000000000001,
      "grad_norm": 0.03313923627138138,
      "learning_rate": 4.2799999999999997e-07,
      "logits/chosen": -2.343956232070923,
      "logits/rejected": -3.4602179527282715,
      "logps/chosen": -176.70872497558594,
      "logps/rejected": -255.36895751953125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.553971290588379,
      "rewards/margins": 10.4107666015625,
      "rewards/rejected": -7.856795310974121,
      "step": 4291
    },
    {
      "epoch": 1.7168,
      "grad_norm": 1.2000892162322998,
      "learning_rate": 4.2786666666666666e-07,
      "logits/chosen": -2.3612873554229736,
      "logits/rejected": -2.999950408935547,
      "logps/chosen": -168.4773712158203,
      "logps/rejected": -177.8097381591797,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.32882997393608093,
      "rewards/margins": 6.482662677764893,
      "rewards/rejected": -6.811492919921875,
      "step": 4292
    },
    {
      "epoch": 1.7172,
      "grad_norm": 0.33779147267341614,
      "learning_rate": 4.2773333333333335e-07,
      "logits/chosen": -2.124497890472412,
      "logits/rejected": -3.2349748611450195,
      "logps/chosen": -120.85699462890625,
      "logps/rejected": -188.87144470214844,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.397477388381958,
      "rewards/margins": 9.057526588439941,
      "rewards/rejected": -7.660048961639404,
      "step": 4293
    },
    {
      "epoch": 1.7176,
      "grad_norm": 0.025684904307127,
      "learning_rate": 4.2759999999999994e-07,
      "logits/chosen": -2.0294291973114014,
      "logits/rejected": -3.03695011138916,
      "logps/chosen": -117.01612854003906,
      "logps/rejected": -155.36962890625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5245583057403564,
      "rewards/margins": 8.861342430114746,
      "rewards/rejected": -7.3367838859558105,
      "step": 4294
    },
    {
      "epoch": 1.718,
      "grad_norm": 0.44728368520736694,
      "learning_rate": 4.2746666666666663e-07,
      "logits/chosen": -2.431013584136963,
      "logits/rejected": -3.351691961288452,
      "logps/chosen": -93.46551513671875,
      "logps/rejected": -183.40890502929688,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1902718544006348,
      "rewards/margins": 9.289225578308105,
      "rewards/rejected": -7.0989532470703125,
      "step": 4295
    },
    {
      "epoch": 1.7184,
      "grad_norm": 0.023340748623013496,
      "learning_rate": 4.273333333333333e-07,
      "logits/chosen": -1.7713775634765625,
      "logits/rejected": -3.5988595485687256,
      "logps/chosen": -77.06169128417969,
      "logps/rejected": -196.78152465820312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9188367128372192,
      "rewards/margins": 11.399431228637695,
      "rewards/rejected": -9.480594635009766,
      "step": 4296
    },
    {
      "epoch": 1.7187999999999999,
      "grad_norm": 0.5235134363174438,
      "learning_rate": 4.272e-07,
      "logits/chosen": -2.6823716163635254,
      "logits/rejected": -3.552436351776123,
      "logps/chosen": -136.4849853515625,
      "logps/rejected": -173.85879516601562,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1426963806152344,
      "rewards/margins": 7.156554222106934,
      "rewards/rejected": -6.013857841491699,
      "step": 4297
    },
    {
      "epoch": 1.7191999999999998,
      "grad_norm": 0.01441733818501234,
      "learning_rate": 4.2706666666666665e-07,
      "logits/chosen": -2.3616738319396973,
      "logits/rejected": -2.930929183959961,
      "logps/chosen": -157.0517578125,
      "logps/rejected": -160.10317993164062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2968204021453857,
      "rewards/margins": 9.008705139160156,
      "rewards/rejected": -6.711884498596191,
      "step": 4298
    },
    {
      "epoch": 1.7196,
      "grad_norm": 0.027721693739295006,
      "learning_rate": 4.269333333333333e-07,
      "logits/chosen": -2.4375476837158203,
      "logits/rejected": -3.630223512649536,
      "logps/chosen": -111.1204833984375,
      "logps/rejected": -193.65464782714844,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9148250818252563,
      "rewards/margins": 9.615409851074219,
      "rewards/rejected": -8.700584411621094,
      "step": 4299
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.0919628143310547,
      "learning_rate": 4.268e-07,
      "logits/chosen": -2.6406054496765137,
      "logits/rejected": -2.9105944633483887,
      "logps/chosen": -132.37667846679688,
      "logps/rejected": -137.09608459472656,
      "loss": 0.0074,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3559463322162628,
      "rewards/margins": 5.7536211013793945,
      "rewards/rejected": -6.109567642211914,
      "step": 4300
    },
    {
      "epoch": 1.7204000000000002,
      "grad_norm": 0.030219320207834244,
      "learning_rate": 4.266666666666667e-07,
      "logits/chosen": -2.2128515243530273,
      "logits/rejected": -3.5795066356658936,
      "logps/chosen": -193.63955688476562,
      "logps/rejected": -213.05746459960938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.41201093792915344,
      "rewards/margins": 8.725393295288086,
      "rewards/rejected": -9.13740348815918,
      "step": 4301
    },
    {
      "epoch": 1.7208,
      "grad_norm": 0.2292151153087616,
      "learning_rate": 4.265333333333333e-07,
      "logits/chosen": -1.7426722049713135,
      "logits/rejected": -3.302734136581421,
      "logps/chosen": -109.05302429199219,
      "logps/rejected": -167.03662109375,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.12148511409759521,
      "rewards/margins": 6.751752853393555,
      "rewards/rejected": -6.873237609863281,
      "step": 4302
    },
    {
      "epoch": 1.7212,
      "grad_norm": 0.03828621283173561,
      "learning_rate": 4.264e-07,
      "logits/chosen": -2.1422479152679443,
      "logits/rejected": -3.4134068489074707,
      "logps/chosen": -139.2161407470703,
      "logps/rejected": -182.4921875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.001572370529175,
      "rewards/margins": 11.702765464782715,
      "rewards/rejected": -9.701192855834961,
      "step": 4303
    },
    {
      "epoch": 1.7216,
      "grad_norm": 0.30121856927871704,
      "learning_rate": 4.2626666666666665e-07,
      "logits/chosen": -1.7864017486572266,
      "logits/rejected": -3.3542308807373047,
      "logps/chosen": -124.03117370605469,
      "logps/rejected": -170.0802459716797,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7888900637626648,
      "rewards/margins": 8.172506332397461,
      "rewards/rejected": -7.3836164474487305,
      "step": 4304
    },
    {
      "epoch": 1.722,
      "grad_norm": 0.029897117987275124,
      "learning_rate": 4.261333333333333e-07,
      "logits/chosen": -2.1563096046447754,
      "logits/rejected": -3.6175537109375,
      "logps/chosen": -123.54588317871094,
      "logps/rejected": -213.82937622070312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.889112114906311,
      "rewards/margins": 11.330154418945312,
      "rewards/rejected": -9.441041946411133,
      "step": 4305
    },
    {
      "epoch": 1.7224,
      "grad_norm": 0.001069374498911202,
      "learning_rate": 4.26e-07,
      "logits/chosen": -1.6894841194152832,
      "logits/rejected": -3.169238567352295,
      "logps/chosen": -85.2512435913086,
      "logps/rejected": -191.92897033691406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5875775814056396,
      "rewards/margins": 12.113287925720215,
      "rewards/rejected": -8.525710105895996,
      "step": 4306
    },
    {
      "epoch": 1.7227999999999999,
      "grad_norm": 0.003725437680259347,
      "learning_rate": 4.2586666666666667e-07,
      "logits/chosen": -2.11588191986084,
      "logits/rejected": -3.886592388153076,
      "logps/chosen": -149.9519805908203,
      "logps/rejected": -176.09042358398438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.730975389480591,
      "rewards/margins": 10.889411926269531,
      "rewards/rejected": -7.158436298370361,
      "step": 4307
    },
    {
      "epoch": 1.7231999999999998,
      "grad_norm": 0.11731833964586258,
      "learning_rate": 4.257333333333333e-07,
      "logits/chosen": -2.5752131938934326,
      "logits/rejected": -3.4181485176086426,
      "logps/chosen": -179.284423828125,
      "logps/rejected": -229.84483337402344,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4973275661468506,
      "rewards/margins": 10.563603401184082,
      "rewards/rejected": -8.066275596618652,
      "step": 4308
    },
    {
      "epoch": 1.7236,
      "grad_norm": 0.0044370489194989204,
      "learning_rate": 4.2559999999999995e-07,
      "logits/chosen": -2.1924002170562744,
      "logits/rejected": -3.641429901123047,
      "logps/chosen": -152.07296752929688,
      "logps/rejected": -178.29879760742188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5240120887756348,
      "rewards/margins": 11.370943069458008,
      "rewards/rejected": -7.846931457519531,
      "step": 4309
    },
    {
      "epoch": 1.724,
      "grad_norm": 0.000956523057539016,
      "learning_rate": 4.2546666666666664e-07,
      "logits/chosen": -2.3233771324157715,
      "logits/rejected": -3.664102077484131,
      "logps/chosen": -102.40208435058594,
      "logps/rejected": -183.4203338623047,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.038037300109863,
      "rewards/margins": 12.639721870422363,
      "rewards/rejected": -8.601683616638184,
      "step": 4310
    },
    {
      "epoch": 1.7244000000000002,
      "grad_norm": 0.00241973833180964,
      "learning_rate": 4.2533333333333333e-07,
      "logits/chosen": -1.9537038803100586,
      "logits/rejected": -3.498931884765625,
      "logps/chosen": -91.51934814453125,
      "logps/rejected": -168.0775146484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3453006744384766,
      "rewards/margins": 10.735716819763184,
      "rewards/rejected": -7.390416145324707,
      "step": 4311
    },
    {
      "epoch": 1.7248,
      "grad_norm": 0.004228758160024881,
      "learning_rate": 4.252e-07,
      "logits/chosen": -2.2821881771087646,
      "logits/rejected": -3.332001209259033,
      "logps/chosen": -92.554931640625,
      "logps/rejected": -181.0306396484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.886953353881836,
      "rewards/margins": 11.603279113769531,
      "rewards/rejected": -9.716325759887695,
      "step": 4312
    },
    {
      "epoch": 1.7252,
      "grad_norm": 0.2809494137763977,
      "learning_rate": 4.250666666666666e-07,
      "logits/chosen": -2.160562038421631,
      "logits/rejected": -2.825259208679199,
      "logps/chosen": -120.18475341796875,
      "logps/rejected": -122.12330627441406,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7166829109191895,
      "rewards/margins": 6.21382999420166,
      "rewards/rejected": -4.497147083282471,
      "step": 4313
    },
    {
      "epoch": 1.7256,
      "grad_norm": 0.003597426926717162,
      "learning_rate": 4.249333333333333e-07,
      "logits/chosen": -2.278153896331787,
      "logits/rejected": -3.268367290496826,
      "logps/chosen": -222.27133178710938,
      "logps/rejected": -228.43231201171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.122851610183716,
      "rewards/margins": 11.889520645141602,
      "rewards/rejected": -8.766669273376465,
      "step": 4314
    },
    {
      "epoch": 1.726,
      "grad_norm": 0.16871148347854614,
      "learning_rate": 4.248e-07,
      "logits/chosen": -1.9069478511810303,
      "logits/rejected": -3.1907100677490234,
      "logps/chosen": -128.54122924804688,
      "logps/rejected": -155.0843048095703,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8128070831298828,
      "rewards/margins": 7.735101222991943,
      "rewards/rejected": -6.9222941398620605,
      "step": 4315
    },
    {
      "epoch": 1.7264,
      "grad_norm": 0.029379360377788544,
      "learning_rate": 4.246666666666667e-07,
      "logits/chosen": -1.700120449066162,
      "logits/rejected": -3.4507806301116943,
      "logps/chosen": -123.72827911376953,
      "logps/rejected": -170.1740264892578,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4323692321777344,
      "rewards/margins": 9.342376708984375,
      "rewards/rejected": -8.91000747680664,
      "step": 4316
    },
    {
      "epoch": 1.7268,
      "grad_norm": 0.0004956737975589931,
      "learning_rate": 4.245333333333333e-07,
      "logits/chosen": -2.299330711364746,
      "logits/rejected": -2.936203718185425,
      "logps/chosen": -81.58519744873047,
      "logps/rejected": -160.74832153320312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.421553611755371,
      "rewards/margins": 12.249472618103027,
      "rewards/rejected": -7.827919006347656,
      "step": 4317
    },
    {
      "epoch": 1.7271999999999998,
      "grad_norm": 0.003800945356488228,
      "learning_rate": 4.2439999999999996e-07,
      "logits/chosen": -1.5449552536010742,
      "logits/rejected": -3.4577717781066895,
      "logps/chosen": -87.80635070800781,
      "logps/rejected": -187.55282592773438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1852898597717285,
      "rewards/margins": 10.497247695922852,
      "rewards/rejected": -9.311958312988281,
      "step": 4318
    },
    {
      "epoch": 1.7276,
      "grad_norm": 0.3505575656890869,
      "learning_rate": 4.2426666666666665e-07,
      "logits/chosen": -2.4868576526641846,
      "logits/rejected": -3.2306833267211914,
      "logps/chosen": -123.77348327636719,
      "logps/rejected": -182.76483154296875,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.634579062461853,
      "rewards/margins": 6.64028263092041,
      "rewards/rejected": -7.274861812591553,
      "step": 4319
    },
    {
      "epoch": 1.728,
      "grad_norm": 0.0011420834343880415,
      "learning_rate": 4.241333333333333e-07,
      "logits/chosen": -2.1895196437835693,
      "logits/rejected": -3.2993969917297363,
      "logps/chosen": -157.45811462402344,
      "logps/rejected": -301.9282531738281,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8632827997207642,
      "rewards/margins": 12.039257049560547,
      "rewards/rejected": -11.175973892211914,
      "step": 4320
    },
    {
      "epoch": 1.7284000000000002,
      "grad_norm": 0.02353220246732235,
      "learning_rate": 4.24e-07,
      "logits/chosen": -1.5998387336730957,
      "logits/rejected": -2.956273078918457,
      "logps/chosen": -110.0877914428711,
      "logps/rejected": -159.48931884765625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.633604884147644,
      "rewards/margins": 8.758995056152344,
      "rewards/rejected": -7.125391006469727,
      "step": 4321
    },
    {
      "epoch": 1.7288000000000001,
      "grad_norm": 0.18821001052856445,
      "learning_rate": 4.238666666666666e-07,
      "logits/chosen": -1.5489699840545654,
      "logits/rejected": -3.720149278640747,
      "logps/chosen": -96.81060028076172,
      "logps/rejected": -162.7640380859375,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9776977896690369,
      "rewards/margins": 7.802097320556641,
      "rewards/rejected": -6.824399948120117,
      "step": 4322
    },
    {
      "epoch": 1.7292,
      "grad_norm": 0.0009185174712911248,
      "learning_rate": 4.237333333333333e-07,
      "logits/chosen": -2.236058235168457,
      "logits/rejected": -3.370666027069092,
      "logps/chosen": -175.33612060546875,
      "logps/rejected": -179.060791015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6787734031677246,
      "rewards/margins": 11.838244438171387,
      "rewards/rejected": -8.159470558166504,
      "step": 4323
    },
    {
      "epoch": 1.7296,
      "grad_norm": 0.009776015765964985,
      "learning_rate": 4.2359999999999995e-07,
      "logits/chosen": -2.0695815086364746,
      "logits/rejected": -3.595466136932373,
      "logps/chosen": -104.59729766845703,
      "logps/rejected": -181.01385498046875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.391213893890381,
      "rewards/margins": 10.679350852966309,
      "rewards/rejected": -7.288136959075928,
      "step": 4324
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.006111774127930403,
      "learning_rate": 4.2346666666666665e-07,
      "logits/chosen": -2.4566211700439453,
      "logits/rejected": -3.4175868034362793,
      "logps/chosen": -149.04522705078125,
      "logps/rejected": -187.10504150390625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9783688187599182,
      "rewards/margins": 10.626693725585938,
      "rewards/rejected": -9.648324966430664,
      "step": 4325
    },
    {
      "epoch": 1.7304,
      "grad_norm": 0.0005343315424397588,
      "learning_rate": 4.2333333333333334e-07,
      "logits/chosen": -2.0686471462249756,
      "logits/rejected": -3.3906068801879883,
      "logps/chosen": -74.45111083984375,
      "logps/rejected": -192.57461547851562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8227596282958984,
      "rewards/margins": 12.436549186706543,
      "rewards/rejected": -8.613789558410645,
      "step": 4326
    },
    {
      "epoch": 1.7308,
      "grad_norm": 3.1643407344818115,
      "learning_rate": 4.232e-07,
      "logits/chosen": -3.3061673641204834,
      "logits/rejected": -3.966252088546753,
      "logps/chosen": -183.71803283691406,
      "logps/rejected": -231.68719482421875,
      "loss": 0.0165,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.081545352935791,
      "rewards/margins": 7.0451884269714355,
      "rewards/rejected": -9.126733779907227,
      "step": 4327
    },
    {
      "epoch": 1.7311999999999999,
      "grad_norm": 0.0064734043553471565,
      "learning_rate": 4.230666666666666e-07,
      "logits/chosen": -2.4414443969726562,
      "logits/rejected": -2.7846267223358154,
      "logps/chosen": -188.33148193359375,
      "logps/rejected": -162.9934539794922,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.874373435974121,
      "rewards/margins": 9.908013343811035,
      "rewards/rejected": -7.033639907836914,
      "step": 4328
    },
    {
      "epoch": 1.7316,
      "grad_norm": 0.006011877208948135,
      "learning_rate": 4.229333333333333e-07,
      "logits/chosen": -1.9056293964385986,
      "logits/rejected": -2.7989590167999268,
      "logps/chosen": -126.0560531616211,
      "logps/rejected": -168.0579071044922,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0690689086914062,
      "rewards/margins": 9.802370071411133,
      "rewards/rejected": -6.733301639556885,
      "step": 4329
    },
    {
      "epoch": 1.732,
      "grad_norm": 0.502715528011322,
      "learning_rate": 4.228e-07,
      "logits/chosen": -2.0073704719543457,
      "logits/rejected": -3.763425827026367,
      "logps/chosen": -138.82693481445312,
      "logps/rejected": -190.3080596923828,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9178916811943054,
      "rewards/margins": 7.838409423828125,
      "rewards/rejected": -8.756300926208496,
      "step": 4330
    },
    {
      "epoch": 1.7324000000000002,
      "grad_norm": 0.0015071008820086718,
      "learning_rate": 4.226666666666667e-07,
      "logits/chosen": -2.694026231765747,
      "logits/rejected": -3.2563858032226562,
      "logps/chosen": -198.116943359375,
      "logps/rejected": -213.74163818359375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2172980308532715,
      "rewards/margins": 11.956401824951172,
      "rewards/rejected": -8.739103317260742,
      "step": 4331
    },
    {
      "epoch": 1.7328000000000001,
      "grad_norm": 0.002253404352813959,
      "learning_rate": 4.225333333333333e-07,
      "logits/chosen": -2.078434467315674,
      "logits/rejected": -3.1698780059814453,
      "logps/chosen": -104.72422790527344,
      "logps/rejected": -214.797607421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2508862018585205,
      "rewards/margins": 12.610736846923828,
      "rewards/rejected": -10.359850883483887,
      "step": 4332
    },
    {
      "epoch": 1.7332,
      "grad_norm": 0.2872406840324402,
      "learning_rate": 4.2239999999999997e-07,
      "logits/chosen": -2.4914767742156982,
      "logits/rejected": -3.224252700805664,
      "logps/chosen": -134.34837341308594,
      "logps/rejected": -171.22314453125,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1028014421463013,
      "rewards/margins": 8.727509498596191,
      "rewards/rejected": -7.6247076988220215,
      "step": 4333
    },
    {
      "epoch": 1.7336,
      "grad_norm": 0.006289184559136629,
      "learning_rate": 4.2226666666666666e-07,
      "logits/chosen": -2.0620501041412354,
      "logits/rejected": -3.504486083984375,
      "logps/chosen": -132.19674682617188,
      "logps/rejected": -192.8140106201172,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5436818599700928,
      "rewards/margins": 11.444650650024414,
      "rewards/rejected": -9.900968551635742,
      "step": 4334
    },
    {
      "epoch": 1.734,
      "grad_norm": 0.005605790298432112,
      "learning_rate": 4.2213333333333335e-07,
      "logits/chosen": -1.936722993850708,
      "logits/rejected": -2.9673376083374023,
      "logps/chosen": -118.94389343261719,
      "logps/rejected": -245.1117706298828,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4093799591064453,
      "rewards/margins": 13.29809856414795,
      "rewards/rejected": -10.888718605041504,
      "step": 4335
    },
    {
      "epoch": 1.7344,
      "grad_norm": 0.01919666863977909,
      "learning_rate": 4.2199999999999994e-07,
      "logits/chosen": -1.6087279319763184,
      "logits/rejected": -2.9151968955993652,
      "logps/chosen": -129.49716186523438,
      "logps/rejected": -188.01162719726562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.157915472984314,
      "rewards/margins": 10.48605728149414,
      "rewards/rejected": -9.328141212463379,
      "step": 4336
    },
    {
      "epoch": 1.7348,
      "grad_norm": 0.028110522776842117,
      "learning_rate": 4.2186666666666663e-07,
      "logits/chosen": -1.950737476348877,
      "logits/rejected": -2.898125171661377,
      "logps/chosen": -112.28224182128906,
      "logps/rejected": -195.38482666015625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7980324029922485,
      "rewards/margins": 8.415557861328125,
      "rewards/rejected": -7.617525100708008,
      "step": 4337
    },
    {
      "epoch": 1.7351999999999999,
      "grad_norm": 0.009153032675385475,
      "learning_rate": 4.217333333333333e-07,
      "logits/chosen": -1.631021499633789,
      "logits/rejected": -2.953847885131836,
      "logps/chosen": -101.04995727539062,
      "logps/rejected": -179.8504638671875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8283191919326782,
      "rewards/margins": 10.50031852722168,
      "rewards/rejected": -8.67199993133545,
      "step": 4338
    },
    {
      "epoch": 1.7356,
      "grad_norm": 0.029038602486252785,
      "learning_rate": 4.2159999999999996e-07,
      "logits/chosen": -1.9474880695343018,
      "logits/rejected": -3.409482002258301,
      "logps/chosen": -161.26507568359375,
      "logps/rejected": -206.5543212890625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0454087257385254,
      "rewards/margins": 9.134797096252441,
      "rewards/rejected": -7.089388847351074,
      "step": 4339
    },
    {
      "epoch": 1.736,
      "grad_norm": 0.08858839422464371,
      "learning_rate": 4.2146666666666666e-07,
      "logits/chosen": -1.6906147003173828,
      "logits/rejected": -2.528874158859253,
      "logps/chosen": -155.1670379638672,
      "logps/rejected": -179.61428833007812,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8063416481018066,
      "rewards/margins": 7.752326011657715,
      "rewards/rejected": -4.94598388671875,
      "step": 4340
    },
    {
      "epoch": 1.7364000000000002,
      "grad_norm": 0.03458245471119881,
      "learning_rate": 4.213333333333333e-07,
      "logits/chosen": -2.195059299468994,
      "logits/rejected": -3.708083152770996,
      "logps/chosen": -140.64111328125,
      "logps/rejected": -181.68438720703125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0230979919433594,
      "rewards/margins": 9.534605026245117,
      "rewards/rejected": -8.511507034301758,
      "step": 4341
    },
    {
      "epoch": 1.7368000000000001,
      "grad_norm": 0.0046738446690142155,
      "learning_rate": 4.212e-07,
      "logits/chosen": -2.0750677585601807,
      "logits/rejected": -2.738759994506836,
      "logps/chosen": -243.08203125,
      "logps/rejected": -196.50283813476562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3540741205215454,
      "rewards/margins": 10.76534652709961,
      "rewards/rejected": -9.411272048950195,
      "step": 4342
    },
    {
      "epoch": 1.7372,
      "grad_norm": 0.01887442171573639,
      "learning_rate": 4.210666666666666e-07,
      "logits/chosen": -2.524142026901245,
      "logits/rejected": -2.9399261474609375,
      "logps/chosen": -98.82526397705078,
      "logps/rejected": -194.8743896484375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.667442798614502,
      "rewards/margins": 10.054980278015137,
      "rewards/rejected": -7.387537479400635,
      "step": 4343
    },
    {
      "epoch": 1.7376,
      "grad_norm": 0.013508927077054977,
      "learning_rate": 4.209333333333333e-07,
      "logits/chosen": -1.6898947954177856,
      "logits/rejected": -2.903768539428711,
      "logps/chosen": -135.20785522460938,
      "logps/rejected": -163.2276611328125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1054069995880127,
      "rewards/margins": 9.930852890014648,
      "rewards/rejected": -7.825445175170898,
      "step": 4344
    },
    {
      "epoch": 1.738,
      "grad_norm": 0.027417851611971855,
      "learning_rate": 4.208e-07,
      "logits/chosen": -2.3199386596679688,
      "logits/rejected": -3.4443740844726562,
      "logps/chosen": -108.13397216796875,
      "logps/rejected": -169.98915100097656,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3565967082977295,
      "rewards/margins": 9.829780578613281,
      "rewards/rejected": -8.473183631896973,
      "step": 4345
    },
    {
      "epoch": 1.7384,
      "grad_norm": 0.010982388630509377,
      "learning_rate": 4.2066666666666665e-07,
      "logits/chosen": -2.607238292694092,
      "logits/rejected": -3.43123197555542,
      "logps/chosen": -143.17550659179688,
      "logps/rejected": -170.71902465820312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.375771999359131,
      "rewards/margins": 9.731398582458496,
      "rewards/rejected": -6.355627059936523,
      "step": 4346
    },
    {
      "epoch": 1.7388,
      "grad_norm": 0.0031076634768396616,
      "learning_rate": 4.205333333333333e-07,
      "logits/chosen": -2.1816301345825195,
      "logits/rejected": -3.257852077484131,
      "logps/chosen": -156.11312866210938,
      "logps/rejected": -192.23843383789062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4556283950805664,
      "rewards/margins": 10.480966567993164,
      "rewards/rejected": -8.025339126586914,
      "step": 4347
    },
    {
      "epoch": 1.7391999999999999,
      "grad_norm": 0.07392004132270813,
      "learning_rate": 4.204e-07,
      "logits/chosen": -2.3630833625793457,
      "logits/rejected": -3.427281379699707,
      "logps/chosen": -113.7773208618164,
      "logps/rejected": -165.3868408203125,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2317081689834595,
      "rewards/margins": 8.07313060760498,
      "rewards/rejected": -6.841422080993652,
      "step": 4348
    },
    {
      "epoch": 1.7396,
      "grad_norm": 0.05723186582326889,
      "learning_rate": 4.2026666666666667e-07,
      "logits/chosen": -2.4179391860961914,
      "logits/rejected": -3.3820409774780273,
      "logps/chosen": -106.19734954833984,
      "logps/rejected": -181.8964385986328,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7869411706924438,
      "rewards/margins": 7.71434211730957,
      "rewards/rejected": -8.501282691955566,
      "step": 4349
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.0010981658706441522,
      "learning_rate": 4.2013333333333336e-07,
      "logits/chosen": -1.8066140413284302,
      "logits/rejected": -3.3487586975097656,
      "logps/chosen": -60.52935791015625,
      "logps/rejected": -195.8113250732422,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.048198223114014,
      "rewards/margins": 11.702152252197266,
      "rewards/rejected": -7.65395450592041,
      "step": 4350
    },
    {
      "epoch": 1.7404,
      "grad_norm": 0.0011136314133182168,
      "learning_rate": 4.1999999999999995e-07,
      "logits/chosen": -1.7281523942947388,
      "logits/rejected": -3.5450305938720703,
      "logps/chosen": -73.4942626953125,
      "logps/rejected": -218.54013061523438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1219440698623657,
      "rewards/margins": 12.948776245117188,
      "rewards/rejected": -11.82683277130127,
      "step": 4351
    },
    {
      "epoch": 1.7408000000000001,
      "grad_norm": 0.16844122111797333,
      "learning_rate": 4.1986666666666664e-07,
      "logits/chosen": -2.250627279281616,
      "logits/rejected": -3.233847141265869,
      "logps/chosen": -234.20498657226562,
      "logps/rejected": -235.823486328125,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9866135120391846,
      "rewards/margins": 9.786698341369629,
      "rewards/rejected": -8.800085067749023,
      "step": 4352
    },
    {
      "epoch": 1.7412,
      "grad_norm": 0.13112413883209229,
      "learning_rate": 4.1973333333333333e-07,
      "logits/chosen": -1.9839327335357666,
      "logits/rejected": -3.5163116455078125,
      "logps/chosen": -151.20626831054688,
      "logps/rejected": -198.3039093017578,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5446102619171143,
      "rewards/margins": 9.077482223510742,
      "rewards/rejected": -8.532872200012207,
      "step": 4353
    },
    {
      "epoch": 1.7416,
      "grad_norm": 0.0012145809596404433,
      "learning_rate": 4.1959999999999997e-07,
      "logits/chosen": -2.6210291385650635,
      "logits/rejected": -3.552203416824341,
      "logps/chosen": -114.9980239868164,
      "logps/rejected": -203.69863891601562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.572852611541748,
      "rewards/margins": 12.423657417297363,
      "rewards/rejected": -8.850805282592773,
      "step": 4354
    },
    {
      "epoch": 1.742,
      "grad_norm": 0.01202790904790163,
      "learning_rate": 4.194666666666666e-07,
      "logits/chosen": -2.0475571155548096,
      "logits/rejected": -3.4598240852355957,
      "logps/chosen": -128.68431091308594,
      "logps/rejected": -170.42086791992188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9990358352661133,
      "rewards/margins": 9.425885200500488,
      "rewards/rejected": -6.426849365234375,
      "step": 4355
    },
    {
      "epoch": 1.7424,
      "grad_norm": 0.017649738118052483,
      "learning_rate": 4.193333333333333e-07,
      "logits/chosen": -1.6399412155151367,
      "logits/rejected": -2.91892147064209,
      "logps/chosen": -130.27182006835938,
      "logps/rejected": -176.30819702148438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5151073932647705,
      "rewards/margins": 9.265031814575195,
      "rewards/rejected": -6.7499237060546875,
      "step": 4356
    },
    {
      "epoch": 1.7428,
      "grad_norm": 0.0029074011836200953,
      "learning_rate": 4.192e-07,
      "logits/chosen": -1.5730688571929932,
      "logits/rejected": -3.481355667114258,
      "logps/chosen": -71.98502349853516,
      "logps/rejected": -186.05142211914062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.021890163421631,
      "rewards/margins": 10.686924934387207,
      "rewards/rejected": -8.665035247802734,
      "step": 4357
    },
    {
      "epoch": 1.7431999999999999,
      "grad_norm": 0.005732130259275436,
      "learning_rate": 4.1906666666666663e-07,
      "logits/chosen": -2.181461811065674,
      "logits/rejected": -2.8923499584198,
      "logps/chosen": -79.25762176513672,
      "logps/rejected": -163.1326904296875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5271859169006348,
      "rewards/margins": 10.505663871765137,
      "rewards/rejected": -6.978477478027344,
      "step": 4358
    },
    {
      "epoch": 1.7436,
      "grad_norm": 0.0222275760024786,
      "learning_rate": 4.189333333333333e-07,
      "logits/chosen": -2.055515766143799,
      "logits/rejected": -3.081760883331299,
      "logps/chosen": -140.70596313476562,
      "logps/rejected": -176.6588897705078,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3103034496307373,
      "rewards/margins": 8.894010543823242,
      "rewards/rejected": -6.583707332611084,
      "step": 4359
    },
    {
      "epoch": 1.744,
      "grad_norm": 0.0936097726225853,
      "learning_rate": 4.1879999999999996e-07,
      "logits/chosen": -2.1309144496917725,
      "logits/rejected": -3.7032511234283447,
      "logps/chosen": -126.16829681396484,
      "logps/rejected": -195.35482788085938,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6265029907226562,
      "rewards/margins": 10.536730766296387,
      "rewards/rejected": -9.91022777557373,
      "step": 4360
    },
    {
      "epoch": 1.7444,
      "grad_norm": 0.02507520653307438,
      "learning_rate": 4.1866666666666666e-07,
      "logits/chosen": -1.857717514038086,
      "logits/rejected": -3.173555850982666,
      "logps/chosen": -128.18316650390625,
      "logps/rejected": -168.20852661132812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0708112716674805,
      "rewards/margins": 8.484766006469727,
      "rewards/rejected": -6.413954734802246,
      "step": 4361
    },
    {
      "epoch": 1.7448000000000001,
      "grad_norm": 0.09663933515548706,
      "learning_rate": 4.185333333333333e-07,
      "logits/chosen": -1.9296207427978516,
      "logits/rejected": -2.9836959838867188,
      "logps/chosen": -178.01695251464844,
      "logps/rejected": -169.99563598632812,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18316537141799927,
      "rewards/margins": 7.581469535827637,
      "rewards/rejected": -7.398303985595703,
      "step": 4362
    },
    {
      "epoch": 1.7452,
      "grad_norm": 0.026898732408881187,
      "learning_rate": 4.184e-07,
      "logits/chosen": -2.5765841007232666,
      "logits/rejected": -3.2200052738189697,
      "logps/chosen": -134.4952392578125,
      "logps/rejected": -186.31353759765625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4504043459892273,
      "rewards/margins": 8.591421127319336,
      "rewards/rejected": -8.14101791381836,
      "step": 4363
    },
    {
      "epoch": 1.7456,
      "grad_norm": 0.004620241932570934,
      "learning_rate": 4.182666666666667e-07,
      "logits/chosen": -2.4015085697174072,
      "logits/rejected": -3.3968734741210938,
      "logps/chosen": -112.48124694824219,
      "logps/rejected": -204.72225952148438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2952152490615845,
      "rewards/margins": 11.39303207397461,
      "rewards/rejected": -10.097816467285156,
      "step": 4364
    },
    {
      "epoch": 1.746,
      "grad_norm": 0.0007227525929920375,
      "learning_rate": 4.181333333333333e-07,
      "logits/chosen": -2.07084059715271,
      "logits/rejected": -3.2717509269714355,
      "logps/chosen": -78.23493957519531,
      "logps/rejected": -206.88613891601562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.141724586486816,
      "rewards/margins": 13.789238929748535,
      "rewards/rejected": -9.647514343261719,
      "step": 4365
    },
    {
      "epoch": 1.7464,
      "grad_norm": 0.0018971128156408668,
      "learning_rate": 4.1799999999999996e-07,
      "logits/chosen": -1.4066897630691528,
      "logits/rejected": -3.22178053855896,
      "logps/chosen": -114.61564636230469,
      "logps/rejected": -187.21856689453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7526673078536987,
      "rewards/margins": 11.187700271606445,
      "rewards/rejected": -9.435032844543457,
      "step": 4366
    },
    {
      "epoch": 1.7468,
      "grad_norm": 0.47902125120162964,
      "learning_rate": 4.1786666666666665e-07,
      "logits/chosen": -1.9059861898422241,
      "logits/rejected": -3.138139247894287,
      "logps/chosen": -165.11135864257812,
      "logps/rejected": -182.38270568847656,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7110427618026733,
      "rewards/margins": 8.111632347106934,
      "rewards/rejected": -7.4005889892578125,
      "step": 4367
    },
    {
      "epoch": 1.7471999999999999,
      "grad_norm": 0.004323233384639025,
      "learning_rate": 4.1773333333333334e-07,
      "logits/chosen": -2.2935805320739746,
      "logits/rejected": -3.912713050842285,
      "logps/chosen": -85.05467987060547,
      "logps/rejected": -192.10011291503906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5715081691741943,
      "rewards/margins": 12.025674819946289,
      "rewards/rejected": -8.454166412353516,
      "step": 4368
    },
    {
      "epoch": 1.7476,
      "grad_norm": 0.5284626483917236,
      "learning_rate": 4.1760000000000003e-07,
      "logits/chosen": -2.121473789215088,
      "logits/rejected": -3.4898900985717773,
      "logps/chosen": -162.03167724609375,
      "logps/rejected": -214.29615783691406,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17184370756149292,
      "rewards/margins": 8.646322250366211,
      "rewards/rejected": -8.474477767944336,
      "step": 4369
    },
    {
      "epoch": 1.748,
      "grad_norm": 0.0444536916911602,
      "learning_rate": 4.174666666666666e-07,
      "logits/chosen": -2.298759937286377,
      "logits/rejected": -3.2587811946868896,
      "logps/chosen": -126.30754089355469,
      "logps/rejected": -172.466552734375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.974760890007019,
      "rewards/margins": 10.790844917297363,
      "rewards/rejected": -8.816083908081055,
      "step": 4370
    },
    {
      "epoch": 1.7484,
      "grad_norm": 0.015031088143587112,
      "learning_rate": 4.173333333333333e-07,
      "logits/chosen": -2.0319228172302246,
      "logits/rejected": -3.24692702293396,
      "logps/chosen": -107.77906799316406,
      "logps/rejected": -140.7100372314453,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.204829692840576,
      "rewards/margins": 8.861669540405273,
      "rewards/rejected": -5.6568403244018555,
      "step": 4371
    },
    {
      "epoch": 1.7488000000000001,
      "grad_norm": 0.03913531079888344,
      "learning_rate": 4.172e-07,
      "logits/chosen": -1.7684848308563232,
      "logits/rejected": -3.496737480163574,
      "logps/chosen": -115.68572998046875,
      "logps/rejected": -175.62142944335938,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.528395175933838,
      "rewards/margins": 10.005849838256836,
      "rewards/rejected": -8.477455139160156,
      "step": 4372
    },
    {
      "epoch": 1.7492,
      "grad_norm": 0.0035053014289587736,
      "learning_rate": 4.1706666666666664e-07,
      "logits/chosen": -1.9569498300552368,
      "logits/rejected": -3.1814050674438477,
      "logps/chosen": -68.73040008544922,
      "logps/rejected": -203.12326049804688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.638265609741211,
      "rewards/margins": 11.98696517944336,
      "rewards/rejected": -9.348699569702148,
      "step": 4373
    },
    {
      "epoch": 1.7496,
      "grad_norm": 0.006886055693030357,
      "learning_rate": 4.169333333333333e-07,
      "logits/chosen": -2.385319709777832,
      "logits/rejected": -3.4414329528808594,
      "logps/chosen": -161.4320831298828,
      "logps/rejected": -240.07350158691406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9620499014854431,
      "rewards/margins": 11.238168716430664,
      "rewards/rejected": -10.276118278503418,
      "step": 4374
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.010916451923549175,
      "learning_rate": 4.1679999999999997e-07,
      "logits/chosen": -2.092190980911255,
      "logits/rejected": -3.039173126220703,
      "logps/chosen": -169.95457458496094,
      "logps/rejected": -187.71371459960938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9353485107421875,
      "rewards/margins": 11.049443244934082,
      "rewards/rejected": -9.114094734191895,
      "step": 4375
    },
    {
      "epoch": 1.7504,
      "grad_norm": 0.008934225887060165,
      "learning_rate": 4.1666666666666667e-07,
      "logits/chosen": -2.244713544845581,
      "logits/rejected": -3.5728955268859863,
      "logps/chosen": -156.1008758544922,
      "logps/rejected": -210.3057403564453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8389068841934204,
      "rewards/margins": 11.19363021850586,
      "rewards/rejected": -9.35472297668457,
      "step": 4376
    },
    {
      "epoch": 1.7508,
      "grad_norm": 0.017029641196131706,
      "learning_rate": 4.165333333333333e-07,
      "logits/chosen": -2.5093002319335938,
      "logits/rejected": -3.2718162536621094,
      "logps/chosen": -145.39768981933594,
      "logps/rejected": -199.47299194335938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.061357855796814,
      "rewards/margins": 9.567651748657227,
      "rewards/rejected": -8.506293296813965,
      "step": 4377
    },
    {
      "epoch": 1.7511999999999999,
      "grad_norm": 0.06216886639595032,
      "learning_rate": 4.164e-07,
      "logits/chosen": -2.2678537368774414,
      "logits/rejected": -2.900308609008789,
      "logps/chosen": -133.28594970703125,
      "logps/rejected": -233.999755859375,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7730584144592285,
      "rewards/margins": 10.6304931640625,
      "rewards/rejected": -7.857434272766113,
      "step": 4378
    },
    {
      "epoch": 1.7516,
      "grad_norm": 0.5901321172714233,
      "learning_rate": 4.1626666666666664e-07,
      "logits/chosen": -1.6281921863555908,
      "logits/rejected": -2.777787923812866,
      "logps/chosen": -126.56666564941406,
      "logps/rejected": -159.501708984375,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6433166265487671,
      "rewards/margins": 8.056793212890625,
      "rewards/rejected": -7.413476943969727,
      "step": 4379
    },
    {
      "epoch": 1.752,
      "grad_norm": 0.006385006010532379,
      "learning_rate": 4.1613333333333333e-07,
      "logits/chosen": -2.2972028255462646,
      "logits/rejected": -3.131894588470459,
      "logps/chosen": -137.98521423339844,
      "logps/rejected": -194.5308837890625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9839645624160767,
      "rewards/margins": 10.72998332977295,
      "rewards/rejected": -8.74601936340332,
      "step": 4380
    },
    {
      "epoch": 1.7524,
      "grad_norm": 0.009101425297558308,
      "learning_rate": 4.1599999999999997e-07,
      "logits/chosen": -2.063258171081543,
      "logits/rejected": -3.1171507835388184,
      "logps/chosen": -109.2701416015625,
      "logps/rejected": -286.8253173828125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.857419729232788,
      "rewards/margins": 10.27755355834961,
      "rewards/rejected": -7.420133590698242,
      "step": 4381
    },
    {
      "epoch": 1.7528000000000001,
      "grad_norm": 0.013400057330727577,
      "learning_rate": 4.1586666666666666e-07,
      "logits/chosen": -2.496150255203247,
      "logits/rejected": -3.463717222213745,
      "logps/chosen": -148.98486328125,
      "logps/rejected": -173.202392578125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.316815972328186,
      "rewards/margins": 9.264820098876953,
      "rewards/rejected": -7.948004722595215,
      "step": 4382
    },
    {
      "epoch": 1.7532,
      "grad_norm": 0.07503874599933624,
      "learning_rate": 4.1573333333333335e-07,
      "logits/chosen": -2.1525893211364746,
      "logits/rejected": -3.0035181045532227,
      "logps/chosen": -143.093505859375,
      "logps/rejected": -227.9097900390625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0577239990234375,
      "rewards/margins": 9.501264572143555,
      "rewards/rejected": -8.443540573120117,
      "step": 4383
    },
    {
      "epoch": 1.7536,
      "grad_norm": 0.04342644289135933,
      "learning_rate": 4.156e-07,
      "logits/chosen": -2.691047191619873,
      "logits/rejected": -3.4919004440307617,
      "logps/chosen": -155.03378295898438,
      "logps/rejected": -178.2025146484375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9423913955688477,
      "rewards/margins": 11.71390151977539,
      "rewards/rejected": -7.771510124206543,
      "step": 4384
    },
    {
      "epoch": 1.754,
      "grad_norm": 0.5055413246154785,
      "learning_rate": 4.1546666666666663e-07,
      "logits/chosen": -2.18945050239563,
      "logits/rejected": -3.263031482696533,
      "logps/chosen": -104.15562438964844,
      "logps/rejected": -157.53907775878906,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6674579381942749,
      "rewards/margins": 7.030019760131836,
      "rewards/rejected": -6.362561225891113,
      "step": 4385
    },
    {
      "epoch": 1.7544,
      "grad_norm": 0.002397303469479084,
      "learning_rate": 4.153333333333333e-07,
      "logits/chosen": -2.2200212478637695,
      "logits/rejected": -2.6589174270629883,
      "logps/chosen": -133.97293090820312,
      "logps/rejected": -185.25746154785156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6848392486572266,
      "rewards/margins": 11.668294906616211,
      "rewards/rejected": -7.983455657958984,
      "step": 4386
    },
    {
      "epoch": 1.7548,
      "grad_norm": 0.015520988963544369,
      "learning_rate": 4.152e-07,
      "logits/chosen": -2.390810966491699,
      "logits/rejected": -2.7379727363586426,
      "logps/chosen": -115.47589874267578,
      "logps/rejected": -248.37417602539062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4627461433410645,
      "rewards/margins": 12.864644050598145,
      "rewards/rejected": -9.401898384094238,
      "step": 4387
    },
    {
      "epoch": 1.7551999999999999,
      "grad_norm": 0.0011479813838377595,
      "learning_rate": 4.150666666666666e-07,
      "logits/chosen": -1.8743398189544678,
      "logits/rejected": -2.7713775634765625,
      "logps/chosen": -71.313232421875,
      "logps/rejected": -216.7671356201172,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.494643211364746,
      "rewards/margins": 11.994312286376953,
      "rewards/rejected": -8.499670028686523,
      "step": 4388
    },
    {
      "epoch": 1.7556,
      "grad_norm": 0.006590667646378279,
      "learning_rate": 4.149333333333333e-07,
      "logits/chosen": -1.5214803218841553,
      "logits/rejected": -3.263190269470215,
      "logps/chosen": -115.04471588134766,
      "logps/rejected": -187.73326110839844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0432281494140625,
      "rewards/margins": 12.247292518615723,
      "rewards/rejected": -10.20406436920166,
      "step": 4389
    },
    {
      "epoch": 1.756,
      "grad_norm": 1.0097434520721436,
      "learning_rate": 4.148e-07,
      "logits/chosen": -2.2253575325012207,
      "logits/rejected": -3.0375890731811523,
      "logps/chosen": -140.68869018554688,
      "logps/rejected": -191.6454315185547,
      "loss": 0.0049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.500090479850769,
      "rewards/margins": 5.874453544616699,
      "rewards/rejected": -7.374544143676758,
      "step": 4390
    },
    {
      "epoch": 1.7564,
      "grad_norm": 0.3099895119667053,
      "learning_rate": 4.146666666666667e-07,
      "logits/chosen": -1.706732988357544,
      "logits/rejected": -3.09627628326416,
      "logps/chosen": -133.6468048095703,
      "logps/rejected": -176.07688903808594,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.899534285068512,
      "rewards/margins": 7.421361446380615,
      "rewards/rejected": -6.521827220916748,
      "step": 4391
    },
    {
      "epoch": 1.7568000000000001,
      "grad_norm": 0.016390997916460037,
      "learning_rate": 4.145333333333333e-07,
      "logits/chosen": -1.9788720607757568,
      "logits/rejected": -3.507516860961914,
      "logps/chosen": -127.35740661621094,
      "logps/rejected": -227.73020935058594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3903475999832153,
      "rewards/margins": 11.450407028198242,
      "rewards/rejected": -10.060059547424316,
      "step": 4392
    },
    {
      "epoch": 1.7572,
      "grad_norm": 0.01514778845012188,
      "learning_rate": 4.1439999999999995e-07,
      "logits/chosen": -2.449622631072998,
      "logits/rejected": -2.9463419914245605,
      "logps/chosen": -102.34154510498047,
      "logps/rejected": -149.07440185546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6180648803710938,
      "rewards/margins": 9.808511734008789,
      "rewards/rejected": -7.190446853637695,
      "step": 4393
    },
    {
      "epoch": 1.7576,
      "grad_norm": 0.11473774164915085,
      "learning_rate": 4.1426666666666664e-07,
      "logits/chosen": -1.5077297687530518,
      "logits/rejected": -3.1381819248199463,
      "logps/chosen": -131.97109985351562,
      "logps/rejected": -168.35702514648438,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2506157159805298,
      "rewards/margins": 7.705724239349365,
      "rewards/rejected": -7.956340312957764,
      "step": 4394
    },
    {
      "epoch": 1.758,
      "grad_norm": 0.0020179999992251396,
      "learning_rate": 4.1413333333333334e-07,
      "logits/chosen": -1.9879136085510254,
      "logits/rejected": -2.786562442779541,
      "logps/chosen": -143.12509155273438,
      "logps/rejected": -226.25062561035156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.283459663391113,
      "rewards/margins": 12.03692626953125,
      "rewards/rejected": -7.753466606140137,
      "step": 4395
    },
    {
      "epoch": 1.7584,
      "grad_norm": 0.018760286271572113,
      "learning_rate": 4.14e-07,
      "logits/chosen": -1.6457631587982178,
      "logits/rejected": -3.302673816680908,
      "logps/chosen": -75.37953186035156,
      "logps/rejected": -171.85202026367188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5281093120574951,
      "rewards/margins": 9.329376220703125,
      "rewards/rejected": -7.801267147064209,
      "step": 4396
    },
    {
      "epoch": 1.7588,
      "grad_norm": 0.0015918408753350377,
      "learning_rate": 4.1386666666666667e-07,
      "logits/chosen": -2.1780500411987305,
      "logits/rejected": -3.374080181121826,
      "logps/chosen": -125.23735809326172,
      "logps/rejected": -170.16897583007812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.784345626831055,
      "rewards/margins": 11.104472160339355,
      "rewards/rejected": -6.320126533508301,
      "step": 4397
    },
    {
      "epoch": 1.7591999999999999,
      "grad_norm": 0.09118159860372543,
      "learning_rate": 4.137333333333333e-07,
      "logits/chosen": -2.186328411102295,
      "logits/rejected": -3.639223098754883,
      "logps/chosen": -197.44931030273438,
      "logps/rejected": -189.83267211914062,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9234626293182373,
      "rewards/margins": 7.628284454345703,
      "rewards/rejected": -8.55174732208252,
      "step": 4398
    },
    {
      "epoch": 1.7596,
      "grad_norm": 0.008933578617870808,
      "learning_rate": 4.136e-07,
      "logits/chosen": -2.370004653930664,
      "logits/rejected": -3.6179211139678955,
      "logps/chosen": -145.01885986328125,
      "logps/rejected": -218.96701049804688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.554459571838379,
      "rewards/margins": 12.329898834228516,
      "rewards/rejected": -9.775440216064453,
      "step": 4399
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.12549994885921478,
      "learning_rate": 4.1346666666666664e-07,
      "logits/chosen": -1.450681447982788,
      "logits/rejected": -3.17087984085083,
      "logps/chosen": -104.15791320800781,
      "logps/rejected": -156.40725708007812,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.506866455078125,
      "rewards/margins": 7.645922660827637,
      "rewards/rejected": -7.139056205749512,
      "step": 4400
    },
    {
      "epoch": 1.7604,
      "grad_norm": 0.007792840711772442,
      "learning_rate": 4.1333333333333333e-07,
      "logits/chosen": -1.9634692668914795,
      "logits/rejected": -2.7566404342651367,
      "logps/chosen": -137.5552520751953,
      "logps/rejected": -151.80889892578125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1867876052856445,
      "rewards/margins": 10.111969947814941,
      "rewards/rejected": -6.925182342529297,
      "step": 4401
    },
    {
      "epoch": 1.7608000000000001,
      "grad_norm": 0.13644328713417053,
      "learning_rate": 4.1319999999999997e-07,
      "logits/chosen": -2.253342866897583,
      "logits/rejected": -2.4360973834991455,
      "logps/chosen": -105.53617858886719,
      "logps/rejected": -133.4646453857422,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7824280261993408,
      "rewards/margins": 7.850069999694824,
      "rewards/rejected": -6.067641735076904,
      "step": 4402
    },
    {
      "epoch": 1.7612,
      "grad_norm": 1.9453768730163574,
      "learning_rate": 4.1306666666666666e-07,
      "logits/chosen": -2.156536102294922,
      "logits/rejected": -2.948019027709961,
      "logps/chosen": -176.34466552734375,
      "logps/rejected": -176.9281005859375,
      "loss": 0.0108,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10781979560852051,
      "rewards/margins": 7.363217830657959,
      "rewards/rejected": -7.471037864685059,
      "step": 4403
    },
    {
      "epoch": 1.7616,
      "grad_norm": 0.0028975282330065966,
      "learning_rate": 4.129333333333333e-07,
      "logits/chosen": -2.174078941345215,
      "logits/rejected": -3.562994956970215,
      "logps/chosen": -163.31036376953125,
      "logps/rejected": -174.4134521484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7637100219726562,
      "rewards/margins": 12.581059455871582,
      "rewards/rejected": -8.817349433898926,
      "step": 4404
    },
    {
      "epoch": 1.762,
      "grad_norm": 0.0007887987303547561,
      "learning_rate": 4.128e-07,
      "logits/chosen": -2.1301681995391846,
      "logits/rejected": -3.494539260864258,
      "logps/chosen": -149.21615600585938,
      "logps/rejected": -194.36862182617188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2569522857666016,
      "rewards/margins": 12.599470138549805,
      "rewards/rejected": -9.342517852783203,
      "step": 4405
    },
    {
      "epoch": 1.7624,
      "grad_norm": 0.0030612628906965256,
      "learning_rate": 4.126666666666667e-07,
      "logits/chosen": -2.267247200012207,
      "logits/rejected": -2.944550037384033,
      "logps/chosen": -114.21372985839844,
      "logps/rejected": -186.7080841064453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.217756748199463,
      "rewards/margins": 11.67374038696289,
      "rewards/rejected": -8.45598316192627,
      "step": 4406
    },
    {
      "epoch": 1.7628,
      "grad_norm": 0.0018733972683548927,
      "learning_rate": 4.1253333333333327e-07,
      "logits/chosen": -2.0059995651245117,
      "logits/rejected": -2.700955390930176,
      "logps/chosen": -83.88948059082031,
      "logps/rejected": -240.63323974609375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.156170606613159,
      "rewards/margins": 12.365862846374512,
      "rewards/rejected": -9.209692001342773,
      "step": 4407
    },
    {
      "epoch": 1.7631999999999999,
      "grad_norm": 0.09089328348636627,
      "learning_rate": 4.1239999999999996e-07,
      "logits/chosen": -1.9771500825881958,
      "logits/rejected": -2.9155616760253906,
      "logps/chosen": -147.09866333007812,
      "logps/rejected": -193.32208251953125,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8922600150108337,
      "rewards/margins": 7.411043167114258,
      "rewards/rejected": -8.303302764892578,
      "step": 4408
    },
    {
      "epoch": 1.7635999999999998,
      "grad_norm": 0.004300909116864204,
      "learning_rate": 4.1226666666666665e-07,
      "logits/chosen": -1.885451078414917,
      "logits/rejected": -3.124204635620117,
      "logps/chosen": -154.29901123046875,
      "logps/rejected": -180.90811157226562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.729872226715088,
      "rewards/margins": 10.290014266967773,
      "rewards/rejected": -7.560141563415527,
      "step": 4409
    },
    {
      "epoch": 1.764,
      "grad_norm": 0.007232043892145157,
      "learning_rate": 4.1213333333333334e-07,
      "logits/chosen": -1.9776685237884521,
      "logits/rejected": -3.066971778869629,
      "logps/chosen": -153.05381774902344,
      "logps/rejected": -168.41845703125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0841052532196045,
      "rewards/margins": 10.11417007446289,
      "rewards/rejected": -8.030065536499023,
      "step": 4410
    },
    {
      "epoch": 1.7644,
      "grad_norm": 0.008513000793755054,
      "learning_rate": 4.12e-07,
      "logits/chosen": -1.2003042697906494,
      "logits/rejected": -2.9716620445251465,
      "logps/chosen": -72.56169128417969,
      "logps/rejected": -180.853759765625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.124846935272217,
      "rewards/margins": 11.075299263000488,
      "rewards/rejected": -8.95045280456543,
      "step": 4411
    },
    {
      "epoch": 1.7648000000000001,
      "grad_norm": 0.23591099679470062,
      "learning_rate": 4.118666666666666e-07,
      "logits/chosen": -1.781724452972412,
      "logits/rejected": -2.6290009021759033,
      "logps/chosen": -178.93142700195312,
      "logps/rejected": -170.40216064453125,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2378395050764084,
      "rewards/margins": 7.486539363861084,
      "rewards/rejected": -7.724379062652588,
      "step": 4412
    },
    {
      "epoch": 1.7652,
      "grad_norm": 0.018829679116606712,
      "learning_rate": 4.117333333333333e-07,
      "logits/chosen": -1.7163512706756592,
      "logits/rejected": -3.465667247772217,
      "logps/chosen": -83.7833480834961,
      "logps/rejected": -183.13087463378906,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9297900795936584,
      "rewards/margins": 10.087274551391602,
      "rewards/rejected": -9.157485008239746,
      "step": 4413
    },
    {
      "epoch": 1.7656,
      "grad_norm": 0.034693341702222824,
      "learning_rate": 4.116e-07,
      "logits/chosen": -1.0926954746246338,
      "logits/rejected": -3.78798770904541,
      "logps/chosen": -73.99329376220703,
      "logps/rejected": -208.36721801757812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6524431705474854,
      "rewards/margins": 11.719561576843262,
      "rewards/rejected": -10.067118644714355,
      "step": 4414
    },
    {
      "epoch": 1.766,
      "grad_norm": 0.085089311003685,
      "learning_rate": 4.1146666666666665e-07,
      "logits/chosen": -1.7783193588256836,
      "logits/rejected": -3.222628593444824,
      "logps/chosen": -143.26551818847656,
      "logps/rejected": -172.70101928710938,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2257168292999268,
      "rewards/margins": 9.490781784057617,
      "rewards/rejected": -7.2650651931762695,
      "step": 4415
    },
    {
      "epoch": 1.7664,
      "grad_norm": 4.8144402503967285,
      "learning_rate": 4.113333333333333e-07,
      "logits/chosen": -2.002507448196411,
      "logits/rejected": -2.4820029735565186,
      "logps/chosen": -123.43225860595703,
      "logps/rejected": -138.4002685546875,
      "loss": 0.0176,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8093715906143188,
      "rewards/margins": 6.258619785308838,
      "rewards/rejected": -7.067991256713867,
      "step": 4416
    },
    {
      "epoch": 1.7668,
      "grad_norm": 0.0832848846912384,
      "learning_rate": 4.112e-07,
      "logits/chosen": -2.0704216957092285,
      "logits/rejected": -3.1890335083007812,
      "logps/chosen": -89.6350326538086,
      "logps/rejected": -154.36505126953125,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8876500129699707,
      "rewards/margins": 8.503946304321289,
      "rewards/rejected": -6.616296768188477,
      "step": 4417
    },
    {
      "epoch": 1.7671999999999999,
      "grad_norm": 0.034168437123298645,
      "learning_rate": 4.1106666666666667e-07,
      "logits/chosen": -2.451326847076416,
      "logits/rejected": -3.4762558937072754,
      "logps/chosen": -218.36251831054688,
      "logps/rejected": -183.2618408203125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3759727478027344,
      "rewards/margins": 8.713605880737305,
      "rewards/rejected": -7.33763313293457,
      "step": 4418
    },
    {
      "epoch": 1.7675999999999998,
      "grad_norm": 0.009403237141668797,
      "learning_rate": 4.109333333333333e-07,
      "logits/chosen": -2.3220973014831543,
      "logits/rejected": -3.102550506591797,
      "logps/chosen": -115.0127944946289,
      "logps/rejected": -172.19369506835938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2478814125061035,
      "rewards/margins": 10.130443572998047,
      "rewards/rejected": -7.882561683654785,
      "step": 4419
    },
    {
      "epoch": 1.768,
      "grad_norm": 0.06895888596773148,
      "learning_rate": 4.108e-07,
      "logits/chosen": -2.0263302326202393,
      "logits/rejected": -3.0085129737854004,
      "logps/chosen": -124.3128662109375,
      "logps/rejected": -153.25051879882812,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3317806124687195,
      "rewards/margins": 7.569799423217773,
      "rewards/rejected": -7.238018989562988,
      "step": 4420
    },
    {
      "epoch": 1.7684,
      "grad_norm": 0.006043854169547558,
      "learning_rate": 4.1066666666666664e-07,
      "logits/chosen": -1.8339824676513672,
      "logits/rejected": -3.5143227577209473,
      "logps/chosen": -129.55128479003906,
      "logps/rejected": -162.34268188476562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3147671222686768,
      "rewards/margins": 10.84190559387207,
      "rewards/rejected": -7.527138710021973,
      "step": 4421
    },
    {
      "epoch": 1.7688000000000001,
      "grad_norm": 0.5056872963905334,
      "learning_rate": 4.105333333333333e-07,
      "logits/chosen": -2.7517144680023193,
      "logits/rejected": -2.874556541442871,
      "logps/chosen": -149.1165771484375,
      "logps/rejected": -147.67779541015625,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.14916571974754333,
      "rewards/margins": 6.400602340698242,
      "rewards/rejected": -6.549768447875977,
      "step": 4422
    },
    {
      "epoch": 1.7692,
      "grad_norm": 0.050167251378297806,
      "learning_rate": 4.1039999999999997e-07,
      "logits/chosen": -2.7078425884246826,
      "logits/rejected": -3.4550576210021973,
      "logps/chosen": -144.07147216796875,
      "logps/rejected": -215.7567138671875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8048202991485596,
      "rewards/margins": 9.739648818969727,
      "rewards/rejected": -6.934828758239746,
      "step": 4423
    },
    {
      "epoch": 1.7696,
      "grad_norm": 0.14765198528766632,
      "learning_rate": 4.1026666666666666e-07,
      "logits/chosen": -1.269660472869873,
      "logits/rejected": -3.121277332305908,
      "logps/chosen": -93.5204849243164,
      "logps/rejected": -165.0453643798828,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.449838638305664,
      "rewards/margins": 9.071374893188477,
      "rewards/rejected": -6.6215362548828125,
      "step": 4424
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.004086405970156193,
      "learning_rate": 4.1013333333333335e-07,
      "logits/chosen": -2.4236488342285156,
      "logits/rejected": -3.6793923377990723,
      "logps/chosen": -108.28985595703125,
      "logps/rejected": -187.5800018310547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7658374309539795,
      "rewards/margins": 11.357674598693848,
      "rewards/rejected": -9.591836929321289,
      "step": 4425
    },
    {
      "epoch": 1.7704,
      "grad_norm": 0.0043948739767074585,
      "learning_rate": 4.0999999999999994e-07,
      "logits/chosen": -1.4925551414489746,
      "logits/rejected": -3.103123664855957,
      "logps/chosen": -81.9990234375,
      "logps/rejected": -172.3343505859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6039252281188965,
      "rewards/margins": 10.634233474731445,
      "rewards/rejected": -7.030307769775391,
      "step": 4426
    },
    {
      "epoch": 1.7708,
      "grad_norm": 0.00298902066424489,
      "learning_rate": 4.0986666666666663e-07,
      "logits/chosen": -2.0546796321868896,
      "logits/rejected": -3.4369394779205322,
      "logps/chosen": -134.60208129882812,
      "logps/rejected": -234.85133361816406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8900963068008423,
      "rewards/margins": 12.559386253356934,
      "rewards/rejected": -10.669290542602539,
      "step": 4427
    },
    {
      "epoch": 1.7711999999999999,
      "grad_norm": 0.002064639935269952,
      "learning_rate": 4.097333333333333e-07,
      "logits/chosen": -1.5670366287231445,
      "logits/rejected": -3.410151958465576,
      "logps/chosen": -117.14828491210938,
      "logps/rejected": -170.38519287109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.136791706085205,
      "rewards/margins": 12.288246154785156,
      "rewards/rejected": -9.15145492553711,
      "step": 4428
    },
    {
      "epoch": 1.7715999999999998,
      "grad_norm": 0.04052917659282684,
      "learning_rate": 4.096e-07,
      "logits/chosen": -2.3248744010925293,
      "logits/rejected": -3.1143805980682373,
      "logps/chosen": -164.19387817382812,
      "logps/rejected": -206.01663208007812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6075958609580994,
      "rewards/margins": 8.470682144165039,
      "rewards/rejected": -7.863086700439453,
      "step": 4429
    },
    {
      "epoch": 1.772,
      "grad_norm": 0.15930618345737457,
      "learning_rate": 4.094666666666666e-07,
      "logits/chosen": -1.8117845058441162,
      "logits/rejected": -3.0502490997314453,
      "logps/chosen": -144.58477783203125,
      "logps/rejected": -165.51376342773438,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22596359252929688,
      "rewards/margins": 7.526426315307617,
      "rewards/rejected": -7.30046272277832,
      "step": 4430
    },
    {
      "epoch": 1.7724,
      "grad_norm": 0.11432476341724396,
      "learning_rate": 4.093333333333333e-07,
      "logits/chosen": -2.0812251567840576,
      "logits/rejected": -2.8997879028320312,
      "logps/chosen": -198.10552978515625,
      "logps/rejected": -127.73689270019531,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9453006982803345,
      "rewards/margins": 7.186829566955566,
      "rewards/rejected": -5.2415289878845215,
      "step": 4431
    },
    {
      "epoch": 1.7728000000000002,
      "grad_norm": 0.07696355134248734,
      "learning_rate": 4.092e-07,
      "logits/chosen": -2.25184965133667,
      "logits/rejected": -3.4183218479156494,
      "logps/chosen": -172.42835998535156,
      "logps/rejected": -182.04644775390625,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6744381189346313,
      "rewards/margins": 8.94229507446289,
      "rewards/rejected": -8.26785659790039,
      "step": 4432
    },
    {
      "epoch": 1.7732,
      "grad_norm": 0.001008389052003622,
      "learning_rate": 4.090666666666667e-07,
      "logits/chosen": -2.398366928100586,
      "logits/rejected": -3.507979393005371,
      "logps/chosen": -97.85354614257812,
      "logps/rejected": -181.73373413085938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9413485527038574,
      "rewards/margins": 11.894712448120117,
      "rewards/rejected": -7.953363418579102,
      "step": 4433
    },
    {
      "epoch": 1.7736,
      "grad_norm": 0.0283757746219635,
      "learning_rate": 4.089333333333333e-07,
      "logits/chosen": -2.5231547355651855,
      "logits/rejected": -3.496185779571533,
      "logps/chosen": -156.65249633789062,
      "logps/rejected": -157.84707641601562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.992319107055664,
      "rewards/margins": 8.895536422729492,
      "rewards/rejected": -6.90321683883667,
      "step": 4434
    },
    {
      "epoch": 1.774,
      "grad_norm": 0.13543851673603058,
      "learning_rate": 4.0879999999999995e-07,
      "logits/chosen": -2.45637845993042,
      "logits/rejected": -2.9878735542297363,
      "logps/chosen": -195.6647186279297,
      "logps/rejected": -184.84950256347656,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0598702430725098,
      "rewards/margins": 7.866971969604492,
      "rewards/rejected": -4.807101249694824,
      "step": 4435
    },
    {
      "epoch": 1.7744,
      "grad_norm": 0.1272384226322174,
      "learning_rate": 4.0866666666666665e-07,
      "logits/chosen": -3.131378173828125,
      "logits/rejected": -3.264458656311035,
      "logps/chosen": -213.33277893066406,
      "logps/rejected": -250.28836059570312,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.683190941810608,
      "rewards/margins": 8.009490966796875,
      "rewards/rejected": -6.326300144195557,
      "step": 4436
    },
    {
      "epoch": 1.7748,
      "grad_norm": 0.4298705458641052,
      "learning_rate": 4.0853333333333334e-07,
      "logits/chosen": -2.352654218673706,
      "logits/rejected": -2.9005126953125,
      "logps/chosen": -111.52808380126953,
      "logps/rejected": -126.06550598144531,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08330458402633667,
      "rewards/margins": 5.728857040405273,
      "rewards/rejected": -5.812161445617676,
      "step": 4437
    },
    {
      "epoch": 1.7752,
      "grad_norm": 0.00562842283397913,
      "learning_rate": 4.084e-07,
      "logits/chosen": -2.0255868434906006,
      "logits/rejected": -3.19996976852417,
      "logps/chosen": -88.32579040527344,
      "logps/rejected": -163.23582458496094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7854907512664795,
      "rewards/margins": 9.853521347045898,
      "rewards/rejected": -8.06803035736084,
      "step": 4438
    },
    {
      "epoch": 1.7755999999999998,
      "grad_norm": 0.009057994931936264,
      "learning_rate": 4.0826666666666667e-07,
      "logits/chosen": -1.5898597240447998,
      "logits/rejected": -3.907010078430176,
      "logps/chosen": -108.56982421875,
      "logps/rejected": -188.15846252441406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.061103105545044,
      "rewards/margins": 9.774823188781738,
      "rewards/rejected": -8.713720321655273,
      "step": 4439
    },
    {
      "epoch": 1.776,
      "grad_norm": 0.0025908963289111853,
      "learning_rate": 4.081333333333333e-07,
      "logits/chosen": -2.541360855102539,
      "logits/rejected": -3.483766555786133,
      "logps/chosen": -185.66627502441406,
      "logps/rejected": -187.9840545654297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5560784339904785,
      "rewards/margins": 10.811630249023438,
      "rewards/rejected": -8.2555513381958,
      "step": 4440
    },
    {
      "epoch": 1.7764,
      "grad_norm": 0.4472000002861023,
      "learning_rate": 4.0799999999999995e-07,
      "logits/chosen": -1.6787493228912354,
      "logits/rejected": -2.9530677795410156,
      "logps/chosen": -161.5952606201172,
      "logps/rejected": -153.5768280029297,
      "loss": 0.0045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8821094036102295,
      "rewards/margins": 5.450854301452637,
      "rewards/rejected": -7.332963943481445,
      "step": 4441
    },
    {
      "epoch": 1.7768000000000002,
      "grad_norm": 0.011117166839540005,
      "learning_rate": 4.0786666666666664e-07,
      "logits/chosen": -1.7690045833587646,
      "logits/rejected": -3.493539810180664,
      "logps/chosen": -133.94482421875,
      "logps/rejected": -198.62425231933594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4351249933242798,
      "rewards/margins": 10.76162338256836,
      "rewards/rejected": -9.326498031616211,
      "step": 4442
    },
    {
      "epoch": 1.7772000000000001,
      "grad_norm": 0.00023944146232679486,
      "learning_rate": 4.0773333333333333e-07,
      "logits/chosen": -2.0026938915252686,
      "logits/rejected": -3.698740005493164,
      "logps/chosen": -65.90287017822266,
      "logps/rejected": -216.84136962890625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5355513095855713,
      "rewards/margins": 13.113754272460938,
      "rewards/rejected": -9.578203201293945,
      "step": 4443
    },
    {
      "epoch": 1.7776,
      "grad_norm": 0.0003433501988183707,
      "learning_rate": 4.076e-07,
      "logits/chosen": -2.0013790130615234,
      "logits/rejected": -3.8230154514312744,
      "logps/chosen": -132.5184326171875,
      "logps/rejected": -229.3043212890625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9412736892700195,
      "rewards/margins": 13.596122741699219,
      "rewards/rejected": -10.654850006103516,
      "step": 4444
    },
    {
      "epoch": 1.778,
      "grad_norm": 0.009165072813630104,
      "learning_rate": 4.074666666666666e-07,
      "logits/chosen": -1.3473162651062012,
      "logits/rejected": -3.3319315910339355,
      "logps/chosen": -64.35908508300781,
      "logps/rejected": -170.04495239257812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7854604721069336,
      "rewards/margins": 11.395462036132812,
      "rewards/rejected": -8.610000610351562,
      "step": 4445
    },
    {
      "epoch": 1.7784,
      "grad_norm": 0.009529058821499348,
      "learning_rate": 4.073333333333333e-07,
      "logits/chosen": -1.4360687732696533,
      "logits/rejected": -3.2735595703125,
      "logps/chosen": -166.91737365722656,
      "logps/rejected": -169.85841369628906,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.738560914993286,
      "rewards/margins": 10.3632230758667,
      "rewards/rejected": -7.624661922454834,
      "step": 4446
    },
    {
      "epoch": 1.7788,
      "grad_norm": 0.004412352107465267,
      "learning_rate": 4.072e-07,
      "logits/chosen": -1.9844638109207153,
      "logits/rejected": -3.4459002017974854,
      "logps/chosen": -100.04261779785156,
      "logps/rejected": -200.3745880126953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4022388458251953,
      "rewards/margins": 10.365882873535156,
      "rewards/rejected": -8.963644027709961,
      "step": 4447
    },
    {
      "epoch": 1.7792,
      "grad_norm": 0.008228272199630737,
      "learning_rate": 4.070666666666667e-07,
      "logits/chosen": -2.16776180267334,
      "logits/rejected": -3.1724462509155273,
      "logps/chosen": -132.25778198242188,
      "logps/rejected": -177.54620361328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.236488103866577,
      "rewards/margins": 10.607284545898438,
      "rewards/rejected": -8.370796203613281,
      "step": 4448
    },
    {
      "epoch": 1.7795999999999998,
      "grad_norm": 0.00034208022407256067,
      "learning_rate": 4.0693333333333327e-07,
      "logits/chosen": -2.1726722717285156,
      "logits/rejected": -3.882154941558838,
      "logps/chosen": -124.05671691894531,
      "logps/rejected": -207.93348693847656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9405088424682617,
      "rewards/margins": 13.87753677368164,
      "rewards/rejected": -9.937027931213379,
      "step": 4449
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.26540470123291016,
      "learning_rate": 4.0679999999999996e-07,
      "logits/chosen": -2.6997551918029785,
      "logits/rejected": -3.4877281188964844,
      "logps/chosen": -138.94857788085938,
      "logps/rejected": -149.0709228515625,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.02027740329504013,
      "rewards/margins": 6.4748759269714355,
      "rewards/rejected": -6.495153427124023,
      "step": 4450
    },
    {
      "epoch": 1.7804,
      "grad_norm": 0.03520811349153519,
      "learning_rate": 4.0666666666666666e-07,
      "logits/chosen": -1.751957893371582,
      "logits/rejected": -3.1197147369384766,
      "logps/chosen": -117.25386047363281,
      "logps/rejected": -159.69091796875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9440982341766357,
      "rewards/margins": 9.616331100463867,
      "rewards/rejected": -6.672233581542969,
      "step": 4451
    },
    {
      "epoch": 1.7808000000000002,
      "grad_norm": 0.04161999002099037,
      "learning_rate": 4.0653333333333335e-07,
      "logits/chosen": -2.1046485900878906,
      "logits/rejected": -3.4468512535095215,
      "logps/chosen": -127.87955474853516,
      "logps/rejected": -159.98651123046875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5237650871276855,
      "rewards/margins": 8.699935913085938,
      "rewards/rejected": -6.17617130279541,
      "step": 4452
    },
    {
      "epoch": 1.7812000000000001,
      "grad_norm": 0.007773721124976873,
      "learning_rate": 4.064e-07,
      "logits/chosen": -2.3181557655334473,
      "logits/rejected": -3.4616875648498535,
      "logps/chosen": -152.5242156982422,
      "logps/rejected": -200.6953125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.294062852859497,
      "rewards/margins": 11.710668563842773,
      "rewards/rejected": -9.416604995727539,
      "step": 4453
    },
    {
      "epoch": 1.7816,
      "grad_norm": 0.08651087433099747,
      "learning_rate": 4.062666666666666e-07,
      "logits/chosen": -2.1942334175109863,
      "logits/rejected": -3.3281002044677734,
      "logps/chosen": -131.4521484375,
      "logps/rejected": -163.30633544921875,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.345717191696167,
      "rewards/margins": 9.701884269714355,
      "rewards/rejected": -7.356166839599609,
      "step": 4454
    },
    {
      "epoch": 1.782,
      "grad_norm": 0.005552781745791435,
      "learning_rate": 4.061333333333333e-07,
      "logits/chosen": -2.2064123153686523,
      "logits/rejected": -3.210169553756714,
      "logps/chosen": -110.26484680175781,
      "logps/rejected": -165.98458862304688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5635600090026855,
      "rewards/margins": 10.095020294189453,
      "rewards/rejected": -7.531459808349609,
      "step": 4455
    },
    {
      "epoch": 1.7824,
      "grad_norm": 0.018539302051067352,
      "learning_rate": 4.06e-07,
      "logits/chosen": -2.0219383239746094,
      "logits/rejected": -3.129061698913574,
      "logps/chosen": -108.66758728027344,
      "logps/rejected": -171.88742065429688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2952980995178223,
      "rewards/margins": 11.028348922729492,
      "rewards/rejected": -7.733051300048828,
      "step": 4456
    },
    {
      "epoch": 1.7828,
      "grad_norm": 0.0344206728041172,
      "learning_rate": 4.0586666666666665e-07,
      "logits/chosen": -2.012873888015747,
      "logits/rejected": -3.1475584506988525,
      "logps/chosen": -147.69174194335938,
      "logps/rejected": -162.90333557128906,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1115500926971436,
      "rewards/margins": 8.2334566116333,
      "rewards/rejected": -6.121906280517578,
      "step": 4457
    },
    {
      "epoch": 1.7832,
      "grad_norm": 0.01568945311009884,
      "learning_rate": 4.0573333333333334e-07,
      "logits/chosen": -1.7748931646347046,
      "logits/rejected": -3.337761878967285,
      "logps/chosen": -106.28857421875,
      "logps/rejected": -168.2066650390625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.61869478225708,
      "rewards/margins": 11.310722351074219,
      "rewards/rejected": -8.692028045654297,
      "step": 4458
    },
    {
      "epoch": 1.7835999999999999,
      "grad_norm": 0.10085316002368927,
      "learning_rate": 4.056e-07,
      "logits/chosen": -1.6994564533233643,
      "logits/rejected": -2.96396803855896,
      "logps/chosen": -107.75611877441406,
      "logps/rejected": -148.88858032226562,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3740395307540894,
      "rewards/margins": 7.04583740234375,
      "rewards/rejected": -5.671798229217529,
      "step": 4459
    },
    {
      "epoch": 1.784,
      "grad_norm": 0.548332691192627,
      "learning_rate": 4.054666666666666e-07,
      "logits/chosen": -1.8134379386901855,
      "logits/rejected": -2.1659417152404785,
      "logps/chosen": -101.0739974975586,
      "logps/rejected": -116.53020477294922,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1661782264709473,
      "rewards/margins": 7.500810146331787,
      "rewards/rejected": -5.33463191986084,
      "step": 4460
    },
    {
      "epoch": 1.7844,
      "grad_norm": 0.4508574604988098,
      "learning_rate": 4.053333333333333e-07,
      "logits/chosen": -1.648817777633667,
      "logits/rejected": -3.2420125007629395,
      "logps/chosen": -125.60298156738281,
      "logps/rejected": -152.57366943359375,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35323262214660645,
      "rewards/margins": 7.930463790893555,
      "rewards/rejected": -7.577231407165527,
      "step": 4461
    },
    {
      "epoch": 1.7848000000000002,
      "grad_norm": 0.08349012583494186,
      "learning_rate": 4.052e-07,
      "logits/chosen": -1.9319429397583008,
      "logits/rejected": -3.1948413848876953,
      "logps/chosen": -146.39508056640625,
      "logps/rejected": -153.86245727539062,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7528785467147827,
      "rewards/margins": 7.494848728179932,
      "rewards/rejected": -6.741970062255859,
      "step": 4462
    },
    {
      "epoch": 1.7852000000000001,
      "grad_norm": 0.12712766230106354,
      "learning_rate": 4.050666666666667e-07,
      "logits/chosen": -2.3231394290924072,
      "logits/rejected": -2.5602545738220215,
      "logps/chosen": -115.75196075439453,
      "logps/rejected": -148.59324645996094,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.124602794647217,
      "rewards/margins": 7.7510528564453125,
      "rewards/rejected": -5.6264495849609375,
      "step": 4463
    },
    {
      "epoch": 1.7856,
      "grad_norm": 0.006457032170146704,
      "learning_rate": 4.049333333333333e-07,
      "logits/chosen": -1.7344467639923096,
      "logits/rejected": -3.3198447227478027,
      "logps/chosen": -134.7452850341797,
      "logps/rejected": -170.22264099121094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.02740478515625,
      "rewards/margins": 10.555551528930664,
      "rewards/rejected": -8.528146743774414,
      "step": 4464
    },
    {
      "epoch": 1.786,
      "grad_norm": 0.04047916457056999,
      "learning_rate": 4.0479999999999997e-07,
      "logits/chosen": -2.4437084197998047,
      "logits/rejected": -3.2196388244628906,
      "logps/chosen": -146.1357421875,
      "logps/rejected": -181.5972442626953,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2503982782363892,
      "rewards/margins": 9.396125793457031,
      "rewards/rejected": -8.145727157592773,
      "step": 4465
    },
    {
      "epoch": 1.7864,
      "grad_norm": 5.376394256018102e-05,
      "learning_rate": 4.0466666666666666e-07,
      "logits/chosen": -2.653346538543701,
      "logits/rejected": -3.467103958129883,
      "logps/chosen": -106.11299896240234,
      "logps/rejected": -237.4351043701172,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.720036506652832,
      "rewards/margins": 15.562597274780273,
      "rewards/rejected": -11.842560768127441,
      "step": 4466
    },
    {
      "epoch": 1.7868,
      "grad_norm": 0.007757843006402254,
      "learning_rate": 4.0453333333333336e-07,
      "logits/chosen": -2.0340404510498047,
      "logits/rejected": -2.9394688606262207,
      "logps/chosen": -107.53242492675781,
      "logps/rejected": -151.31558227539062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.255514144897461,
      "rewards/margins": 10.044111251831055,
      "rewards/rejected": -7.788596153259277,
      "step": 4467
    },
    {
      "epoch": 1.7872,
      "grad_norm": 0.764591634273529,
      "learning_rate": 4.0439999999999994e-07,
      "logits/chosen": -2.3200788497924805,
      "logits/rejected": -3.3601832389831543,
      "logps/chosen": -220.16217041015625,
      "logps/rejected": -188.23297119140625,
      "loss": 0.0068,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7956738471984863,
      "rewards/margins": 5.870081901550293,
      "rewards/rejected": -7.665755748748779,
      "step": 4468
    },
    {
      "epoch": 1.7875999999999999,
      "grad_norm": 0.0031373656820505857,
      "learning_rate": 4.0426666666666663e-07,
      "logits/chosen": -1.6792737245559692,
      "logits/rejected": -3.6469168663024902,
      "logps/chosen": -118.55204772949219,
      "logps/rejected": -222.03741455078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9953190088272095,
      "rewards/margins": 11.530829429626465,
      "rewards/rejected": -9.535511016845703,
      "step": 4469
    },
    {
      "epoch": 1.788,
      "grad_norm": 0.08989255875349045,
      "learning_rate": 4.041333333333333e-07,
      "logits/chosen": -2.2562222480773926,
      "logits/rejected": -3.253878593444824,
      "logps/chosen": -119.82091522216797,
      "logps/rejected": -171.5564422607422,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2334907054901123,
      "rewards/margins": 10.032194137573242,
      "rewards/rejected": -8.798704147338867,
      "step": 4470
    },
    {
      "epoch": 1.7884,
      "grad_norm": 0.0042474763467907906,
      "learning_rate": 4.04e-07,
      "logits/chosen": -2.2512691020965576,
      "logits/rejected": -2.951225757598877,
      "logps/chosen": -105.41749572753906,
      "logps/rejected": -173.9900665283203,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.026238203048706,
      "rewards/margins": 10.546792984008789,
      "rewards/rejected": -8.520553588867188,
      "step": 4471
    },
    {
      "epoch": 1.7888,
      "grad_norm": 0.021187331527471542,
      "learning_rate": 4.0386666666666666e-07,
      "logits/chosen": -2.3681581020355225,
      "logits/rejected": -3.2459921836853027,
      "logps/chosen": -163.6507110595703,
      "logps/rejected": -170.12191772460938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1281691789627075,
      "rewards/margins": 8.524246215820312,
      "rewards/rejected": -7.3960771560668945,
      "step": 4472
    },
    {
      "epoch": 1.7892000000000001,
      "grad_norm": 0.0004309533105697483,
      "learning_rate": 4.037333333333333e-07,
      "logits/chosen": -2.0202207565307617,
      "logits/rejected": -3.6375842094421387,
      "logps/chosen": -154.820068359375,
      "logps/rejected": -197.22354125976562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6950135231018066,
      "rewards/margins": 13.145103454589844,
      "rewards/rejected": -10.450090408325195,
      "step": 4473
    },
    {
      "epoch": 1.7896,
      "grad_norm": 0.010400614701211452,
      "learning_rate": 4.036e-07,
      "logits/chosen": -2.1501851081848145,
      "logits/rejected": -2.9872493743896484,
      "logps/chosen": -157.10621643066406,
      "logps/rejected": -181.7044677734375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.741581439971924,
      "rewards/margins": 10.030685424804688,
      "rewards/rejected": -7.289104461669922,
      "step": 4474
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.00513036735355854,
      "learning_rate": 4.0346666666666663e-07,
      "logits/chosen": -1.6005878448486328,
      "logits/rejected": -3.612283706665039,
      "logps/chosen": -121.35215759277344,
      "logps/rejected": -227.38082885742188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.214989423751831,
      "rewards/margins": 10.81890869140625,
      "rewards/rejected": -12.033897399902344,
      "step": 4475
    },
    {
      "epoch": 1.7904,
      "grad_norm": 0.0015788489254191518,
      "learning_rate": 4.033333333333333e-07,
      "logits/chosen": -2.520338296890259,
      "logits/rejected": -3.1778764724731445,
      "logps/chosen": -140.28680419921875,
      "logps/rejected": -260.1473693847656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.862396240234375,
      "rewards/margins": 11.766770362854004,
      "rewards/rejected": -9.904374122619629,
      "step": 4476
    },
    {
      "epoch": 1.7908,
      "grad_norm": 0.029505044221878052,
      "learning_rate": 4.032e-07,
      "logits/chosen": -1.586938500404358,
      "logits/rejected": -3.793203115463257,
      "logps/chosen": -77.48262786865234,
      "logps/rejected": -196.49856567382812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5346291065216064,
      "rewards/margins": 9.90487289428711,
      "rewards/rejected": -9.370243072509766,
      "step": 4477
    },
    {
      "epoch": 1.7912,
      "grad_norm": 0.5028508901596069,
      "learning_rate": 4.0306666666666665e-07,
      "logits/chosen": -1.8614168167114258,
      "logits/rejected": -3.520847797393799,
      "logps/chosen": -111.5399169921875,
      "logps/rejected": -189.7464599609375,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3094528913497925,
      "rewards/margins": 9.782960891723633,
      "rewards/rejected": -10.092412948608398,
      "step": 4478
    },
    {
      "epoch": 1.7915999999999999,
      "grad_norm": 0.2568831741809845,
      "learning_rate": 4.029333333333333e-07,
      "logits/chosen": -1.904092788696289,
      "logits/rejected": -3.1537394523620605,
      "logps/chosen": -105.09037780761719,
      "logps/rejected": -150.86795043945312,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09388923645019531,
      "rewards/margins": 6.349883079528809,
      "rewards/rejected": -6.255993843078613,
      "step": 4479
    },
    {
      "epoch": 1.792,
      "grad_norm": 0.00291098328307271,
      "learning_rate": 4.028e-07,
      "logits/chosen": -2.23519229888916,
      "logits/rejected": -2.843599796295166,
      "logps/chosen": -125.80635070800781,
      "logps/rejected": -191.41921997070312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.738917350769043,
      "rewards/margins": 10.826452255249023,
      "rewards/rejected": -8.08753490447998,
      "step": 4480
    },
    {
      "epoch": 1.7924,
      "grad_norm": 0.004421681631356478,
      "learning_rate": 4.0266666666666667e-07,
      "logits/chosen": -2.215435743331909,
      "logits/rejected": -3.4962470531463623,
      "logps/chosen": -182.29937744140625,
      "logps/rejected": -182.59326171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2059884071350098,
      "rewards/margins": 10.512606620788574,
      "rewards/rejected": -7.306617736816406,
      "step": 4481
    },
    {
      "epoch": 1.7928,
      "grad_norm": 0.008459601551294327,
      "learning_rate": 4.025333333333333e-07,
      "logits/chosen": -2.2941529750823975,
      "logits/rejected": -3.693932056427002,
      "logps/chosen": -109.95697784423828,
      "logps/rejected": -183.30313110351562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.269172430038452,
      "rewards/margins": 9.958918571472168,
      "rewards/rejected": -7.689745903015137,
      "step": 4482
    },
    {
      "epoch": 1.7932000000000001,
      "grad_norm": 0.009514190256595612,
      "learning_rate": 4.0239999999999995e-07,
      "logits/chosen": -2.2440929412841797,
      "logits/rejected": -3.0794425010681152,
      "logps/chosen": -99.58746337890625,
      "logps/rejected": -154.56932067871094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.019580364227295,
      "rewards/margins": 9.328409194946289,
      "rewards/rejected": -7.308829307556152,
      "step": 4483
    },
    {
      "epoch": 1.7936,
      "grad_norm": 0.044952064752578735,
      "learning_rate": 4.0226666666666664e-07,
      "logits/chosen": -2.3472938537597656,
      "logits/rejected": -3.2013983726501465,
      "logps/chosen": -204.49417114257812,
      "logps/rejected": -324.2869873046875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3856384754180908,
      "rewards/margins": 11.227262496948242,
      "rewards/rejected": -9.841623306274414,
      "step": 4484
    },
    {
      "epoch": 1.794,
      "grad_norm": 0.022497033700346947,
      "learning_rate": 4.0213333333333333e-07,
      "logits/chosen": -2.216524124145508,
      "logits/rejected": -3.2377166748046875,
      "logps/chosen": -151.79348754882812,
      "logps/rejected": -173.49285888671875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6298069953918457,
      "rewards/margins": 11.848292350769043,
      "rewards/rejected": -8.218484878540039,
      "step": 4485
    },
    {
      "epoch": 1.7944,
      "grad_norm": 0.027042891830205917,
      "learning_rate": 4.02e-07,
      "logits/chosen": -2.1327555179595947,
      "logits/rejected": -3.522104263305664,
      "logps/chosen": -148.34698486328125,
      "logps/rejected": -241.4998016357422,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.867940902709961,
      "rewards/margins": 10.955108642578125,
      "rewards/rejected": -9.087167739868164,
      "step": 4486
    },
    {
      "epoch": 1.7948,
      "grad_norm": 1.4714605808258057,
      "learning_rate": 4.018666666666666e-07,
      "logits/chosen": -2.2352676391601562,
      "logits/rejected": -2.7467474937438965,
      "logps/chosen": -194.2063751220703,
      "logps/rejected": -141.50601196289062,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7330093383789062,
      "rewards/margins": 6.954668045043945,
      "rewards/rejected": -5.221658706665039,
      "step": 4487
    },
    {
      "epoch": 1.7952,
      "grad_norm": 0.20730313658714294,
      "learning_rate": 4.017333333333333e-07,
      "logits/chosen": -2.1000237464904785,
      "logits/rejected": -3.873988151550293,
      "logps/chosen": -76.000244140625,
      "logps/rejected": -174.5093994140625,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2766865491867065,
      "rewards/margins": 10.096979141235352,
      "rewards/rejected": -8.820292472839355,
      "step": 4488
    },
    {
      "epoch": 1.7955999999999999,
      "grad_norm": 0.7833478450775146,
      "learning_rate": 4.016e-07,
      "logits/chosen": -2.288113594055176,
      "logits/rejected": -3.0877134799957275,
      "logps/chosen": -229.54644775390625,
      "logps/rejected": -191.67111206054688,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9786873459815979,
      "rewards/margins": 6.477507591247559,
      "rewards/rejected": -7.456194877624512,
      "step": 4489
    },
    {
      "epoch": 1.796,
      "grad_norm": 0.1725752055644989,
      "learning_rate": 4.014666666666667e-07,
      "logits/chosen": -2.1119296550750732,
      "logits/rejected": -3.607980728149414,
      "logps/chosen": -142.30709838867188,
      "logps/rejected": -169.58889770507812,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2908203601837158,
      "rewards/margins": 10.261988639831543,
      "rewards/rejected": -8.971168518066406,
      "step": 4490
    },
    {
      "epoch": 1.7964,
      "grad_norm": 0.008599410764873028,
      "learning_rate": 4.0133333333333333e-07,
      "logits/chosen": -1.4584429264068604,
      "logits/rejected": -3.7935972213745117,
      "logps/chosen": -90.45225524902344,
      "logps/rejected": -195.23019409179688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4344189167022705,
      "rewards/margins": 10.25855827331543,
      "rewards/rejected": -9.824140548706055,
      "step": 4491
    },
    {
      "epoch": 1.7968,
      "grad_norm": 0.029271990060806274,
      "learning_rate": 4.0119999999999997e-07,
      "logits/chosen": -2.007052421569824,
      "logits/rejected": -2.9911746978759766,
      "logps/chosen": -112.26408386230469,
      "logps/rejected": -168.43893432617188,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5172033309936523,
      "rewards/margins": 10.938140869140625,
      "rewards/rejected": -8.420938491821289,
      "step": 4492
    },
    {
      "epoch": 1.7972000000000001,
      "grad_norm": 0.34043946862220764,
      "learning_rate": 4.0106666666666666e-07,
      "logits/chosen": -2.171103000640869,
      "logits/rejected": -3.1227941513061523,
      "logps/chosen": -196.45294189453125,
      "logps/rejected": -229.6599884033203,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5754302740097046,
      "rewards/margins": 7.48237943649292,
      "rewards/rejected": -8.057809829711914,
      "step": 4493
    },
    {
      "epoch": 1.7976,
      "grad_norm": 0.005980095360428095,
      "learning_rate": 4.009333333333333e-07,
      "logits/chosen": -2.2646713256835938,
      "logits/rejected": -3.3869054317474365,
      "logps/chosen": -214.02804565429688,
      "logps/rejected": -184.02957153320312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7813316583633423,
      "rewards/margins": 9.919051170349121,
      "rewards/rejected": -8.137720108032227,
      "step": 4494
    },
    {
      "epoch": 1.798,
      "grad_norm": 0.022135477513074875,
      "learning_rate": 4.008e-07,
      "logits/chosen": -1.9942407608032227,
      "logits/rejected": -3.596156597137451,
      "logps/chosen": -107.02337646484375,
      "logps/rejected": -239.96200561523438,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1718257665634155,
      "rewards/margins": 11.535346031188965,
      "rewards/rejected": -10.363519668579102,
      "step": 4495
    },
    {
      "epoch": 1.7984,
      "grad_norm": 0.0019638915546238422,
      "learning_rate": 4.0066666666666663e-07,
      "logits/chosen": -2.283663749694824,
      "logits/rejected": -3.8200764656066895,
      "logps/chosen": -147.01815795898438,
      "logps/rejected": -178.86874389648438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3964309692382812,
      "rewards/margins": 11.063109397888184,
      "rewards/rejected": -9.666678428649902,
      "step": 4496
    },
    {
      "epoch": 1.7988,
      "grad_norm": 0.03148139268159866,
      "learning_rate": 4.005333333333333e-07,
      "logits/chosen": -1.9539844989776611,
      "logits/rejected": -3.0466859340667725,
      "logps/chosen": -114.8466567993164,
      "logps/rejected": -153.85867309570312,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1026298999786377,
      "rewards/margins": 9.949252128601074,
      "rewards/rejected": -6.846621990203857,
      "step": 4497
    },
    {
      "epoch": 1.7992,
      "grad_norm": 0.022006412968039513,
      "learning_rate": 4.0039999999999996e-07,
      "logits/chosen": -2.0580482482910156,
      "logits/rejected": -3.000295877456665,
      "logps/chosen": -134.44956970214844,
      "logps/rejected": -197.1705322265625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9368385076522827,
      "rewards/margins": 11.043176651000977,
      "rewards/rejected": -10.106338500976562,
      "step": 4498
    },
    {
      "epoch": 1.7995999999999999,
      "grad_norm": 0.01677299104630947,
      "learning_rate": 4.0026666666666665e-07,
      "logits/chosen": -1.917372703552246,
      "logits/rejected": -3.026876926422119,
      "logps/chosen": -163.24627685546875,
      "logps/rejected": -152.59519958496094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.48895263671875,
      "rewards/margins": 9.00933837890625,
      "rewards/rejected": -6.520385265350342,
      "step": 4499
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.004241150338202715,
      "learning_rate": 4.0013333333333334e-07,
      "logits/chosen": -2.2811636924743652,
      "logits/rejected": -3.3589682579040527,
      "logps/chosen": -141.46505737304688,
      "logps/rejected": -187.0196533203125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.816795825958252,
      "rewards/margins": 10.688697814941406,
      "rewards/rejected": -8.871901512145996,
      "step": 4500
    },
    {
      "epoch": 1.8004,
      "grad_norm": 0.141585573554039,
      "learning_rate": 4e-07,
      "logits/chosen": -1.8768577575683594,
      "logits/rejected": -3.260007858276367,
      "logps/chosen": -76.24723815917969,
      "logps/rejected": -165.8695068359375,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0782253742218018,
      "rewards/margins": 7.915422439575195,
      "rewards/rejected": -6.8371968269348145,
      "step": 4501
    },
    {
      "epoch": 1.8008,
      "grad_norm": 0.09984952956438065,
      "learning_rate": 3.998666666666666e-07,
      "logits/chosen": -1.7561630010604858,
      "logits/rejected": -3.0913820266723633,
      "logps/chosen": -115.60240936279297,
      "logps/rejected": -176.40476989746094,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6520946621894836,
      "rewards/margins": 7.490230560302734,
      "rewards/rejected": -6.838136672973633,
      "step": 4502
    },
    {
      "epoch": 1.8012000000000001,
      "grad_norm": 0.02340756356716156,
      "learning_rate": 3.997333333333333e-07,
      "logits/chosen": -2.441821813583374,
      "logits/rejected": -3.3379712104797363,
      "logps/chosen": -117.08013916015625,
      "logps/rejected": -163.98428344726562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0805907249450684,
      "rewards/margins": 10.328559875488281,
      "rewards/rejected": -7.247969150543213,
      "step": 4503
    },
    {
      "epoch": 1.8016,
      "grad_norm": 0.009779713116586208,
      "learning_rate": 3.996e-07,
      "logits/chosen": -1.2093886137008667,
      "logits/rejected": -3.2764737606048584,
      "logps/chosen": -93.03096771240234,
      "logps/rejected": -169.34658813476562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6208126544952393,
      "rewards/margins": 10.376215934753418,
      "rewards/rejected": -7.755403518676758,
      "step": 4504
    },
    {
      "epoch": 1.802,
      "grad_norm": 0.08797316998243332,
      "learning_rate": 3.994666666666667e-07,
      "logits/chosen": -2.1566286087036133,
      "logits/rejected": -3.053603410720825,
      "logps/chosen": -107.6777572631836,
      "logps/rejected": -165.66122436523438,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8121780157089233,
      "rewards/margins": 9.245051383972168,
      "rewards/rejected": -8.432873725891113,
      "step": 4505
    },
    {
      "epoch": 1.8024,
      "grad_norm": 0.01135537400841713,
      "learning_rate": 3.993333333333333e-07,
      "logits/chosen": -2.3852598667144775,
      "logits/rejected": -3.5192389488220215,
      "logps/chosen": -192.04104614257812,
      "logps/rejected": -206.12802124023438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6802200078964233,
      "rewards/margins": 10.500808715820312,
      "rewards/rejected": -9.820589065551758,
      "step": 4506
    },
    {
      "epoch": 1.8028,
      "grad_norm": 2.03330659866333,
      "learning_rate": 3.992e-07,
      "logits/chosen": -2.6783595085144043,
      "logits/rejected": -3.5178356170654297,
      "logps/chosen": -186.91461181640625,
      "logps/rejected": -161.00009155273438,
      "loss": 0.0175,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1810730695724487,
      "rewards/margins": 6.129373550415039,
      "rewards/rejected": -7.310446262359619,
      "step": 4507
    },
    {
      "epoch": 1.8032,
      "grad_norm": 2.2154831886291504,
      "learning_rate": 3.9906666666666667e-07,
      "logits/chosen": -1.9432107210159302,
      "logits/rejected": -2.837170124053955,
      "logps/chosen": -115.75216674804688,
      "logps/rejected": -145.9938201904297,
      "loss": 0.0152,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5285805463790894,
      "rewards/margins": 5.926911354064941,
      "rewards/rejected": -7.45549201965332,
      "step": 4508
    },
    {
      "epoch": 1.8035999999999999,
      "grad_norm": 0.019340546801686287,
      "learning_rate": 3.989333333333333e-07,
      "logits/chosen": -2.53261137008667,
      "logits/rejected": -3.5922436714172363,
      "logps/chosen": -210.842529296875,
      "logps/rejected": -181.72279357910156,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.480065107345581,
      "rewards/margins": 9.029205322265625,
      "rewards/rejected": -7.549139976501465,
      "step": 4509
    },
    {
      "epoch": 1.804,
      "grad_norm": 0.798037588596344,
      "learning_rate": 3.9879999999999994e-07,
      "logits/chosen": -2.2798452377319336,
      "logits/rejected": -3.361482620239258,
      "logps/chosen": -89.04894256591797,
      "logps/rejected": -171.98495483398438,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5452336072921753,
      "rewards/margins": 7.9292826652526855,
      "rewards/rejected": -7.384048938751221,
      "step": 4510
    },
    {
      "epoch": 1.8044,
      "grad_norm": 0.03202396631240845,
      "learning_rate": 3.9866666666666664e-07,
      "logits/chosen": -2.080393075942993,
      "logits/rejected": -2.8042774200439453,
      "logps/chosen": -130.168701171875,
      "logps/rejected": -254.68130493164062,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.579725742340088,
      "rewards/margins": 8.774503707885742,
      "rewards/rejected": -7.1947784423828125,
      "step": 4511
    },
    {
      "epoch": 1.8048,
      "grad_norm": 0.01279814075678587,
      "learning_rate": 3.9853333333333333e-07,
      "logits/chosen": -2.0744826793670654,
      "logits/rejected": -2.7298128604888916,
      "logps/chosen": -118.57029724121094,
      "logps/rejected": -201.298095703125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.200904130935669,
      "rewards/margins": 9.342679023742676,
      "rewards/rejected": -7.141775131225586,
      "step": 4512
    },
    {
      "epoch": 1.8052000000000001,
      "grad_norm": 0.08140735328197479,
      "learning_rate": 3.9839999999999997e-07,
      "logits/chosen": -2.020402431488037,
      "logits/rejected": -3.2869553565979004,
      "logps/chosen": -146.7067413330078,
      "logps/rejected": -184.1518096923828,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13332635164260864,
      "rewards/margins": 8.27149772644043,
      "rewards/rejected": -8.138171195983887,
      "step": 4513
    },
    {
      "epoch": 1.8056,
      "grad_norm": 0.05140621215105057,
      "learning_rate": 3.9826666666666666e-07,
      "logits/chosen": -1.9184799194335938,
      "logits/rejected": -3.652040958404541,
      "logps/chosen": -112.31523132324219,
      "logps/rejected": -254.82962036132812,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.41977423429489136,
      "rewards/margins": 8.51053237915039,
      "rewards/rejected": -8.930307388305664,
      "step": 4514
    },
    {
      "epoch": 1.806,
      "grad_norm": 0.04617191106081009,
      "learning_rate": 3.981333333333333e-07,
      "logits/chosen": -2.2817506790161133,
      "logits/rejected": -3.4995899200439453,
      "logps/chosen": -230.3936767578125,
      "logps/rejected": -187.19290161132812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3600921928882599,
      "rewards/margins": 8.979442596435547,
      "rewards/rejected": -9.339534759521484,
      "step": 4515
    },
    {
      "epoch": 1.8064,
      "grad_norm": 0.011274661868810654,
      "learning_rate": 3.98e-07,
      "logits/chosen": -2.1581788063049316,
      "logits/rejected": -3.390934467315674,
      "logps/chosen": -127.15859985351562,
      "logps/rejected": -174.8407745361328,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2180590629577637,
      "rewards/margins": 10.581334114074707,
      "rewards/rejected": -8.363275527954102,
      "step": 4516
    },
    {
      "epoch": 1.8068,
      "grad_norm": 0.19370587170124054,
      "learning_rate": 3.9786666666666663e-07,
      "logits/chosen": -1.5152159929275513,
      "logits/rejected": -2.724790573120117,
      "logps/chosen": -133.40420532226562,
      "logps/rejected": -133.9178466796875,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03642425686120987,
      "rewards/margins": 6.246183395385742,
      "rewards/rejected": -6.20975923538208,
      "step": 4517
    },
    {
      "epoch": 1.8072,
      "grad_norm": 0.012616924941539764,
      "learning_rate": 3.977333333333333e-07,
      "logits/chosen": -2.408845901489258,
      "logits/rejected": -3.558593988418579,
      "logps/chosen": -234.92640686035156,
      "logps/rejected": -226.47601318359375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8589372634887695,
      "rewards/margins": 10.721328735351562,
      "rewards/rejected": -7.862391471862793,
      "step": 4518
    },
    {
      "epoch": 1.8075999999999999,
      "grad_norm": 0.10964067280292511,
      "learning_rate": 3.976e-07,
      "logits/chosen": -1.7956544160842896,
      "logits/rejected": -3.154893636703491,
      "logps/chosen": -165.3162384033203,
      "logps/rejected": -175.01312255859375,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.305712103843689,
      "rewards/margins": 8.604714393615723,
      "rewards/rejected": -7.299002647399902,
      "step": 4519
    },
    {
      "epoch": 1.808,
      "grad_norm": 4.810722020920366e-05,
      "learning_rate": 3.9746666666666665e-07,
      "logits/chosen": -1.903976321220398,
      "logits/rejected": -3.202737808227539,
      "logps/chosen": -105.12386322021484,
      "logps/rejected": -213.47512817382812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.237953186035156,
      "rewards/margins": 15.22186279296875,
      "rewards/rejected": -10.983909606933594,
      "step": 4520
    },
    {
      "epoch": 1.8084,
      "grad_norm": 0.02772107906639576,
      "learning_rate": 3.973333333333333e-07,
      "logits/chosen": -2.1792869567871094,
      "logits/rejected": -3.4021549224853516,
      "logps/chosen": -116.37197875976562,
      "logps/rejected": -152.14434814453125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4500698149204254,
      "rewards/margins": 8.092443466186523,
      "rewards/rejected": -7.642373085021973,
      "step": 4521
    },
    {
      "epoch": 1.8088,
      "grad_norm": 0.0405433252453804,
      "learning_rate": 3.972e-07,
      "logits/chosen": -2.2883591651916504,
      "logits/rejected": -3.1762161254882812,
      "logps/chosen": -128.6732940673828,
      "logps/rejected": -249.26596069335938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9405678510665894,
      "rewards/margins": 9.805194854736328,
      "rewards/rejected": -7.864626884460449,
      "step": 4522
    },
    {
      "epoch": 1.8092000000000001,
      "grad_norm": 0.00198992807418108,
      "learning_rate": 3.970666666666667e-07,
      "logits/chosen": -2.2739434242248535,
      "logits/rejected": -2.7789645195007324,
      "logps/chosen": -60.45370864868164,
      "logps/rejected": -154.1982879638672,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.149965286254883,
      "rewards/margins": 11.007225036621094,
      "rewards/rejected": -6.857260227203369,
      "step": 4523
    },
    {
      "epoch": 1.8096,
      "grad_norm": 0.23206855356693268,
      "learning_rate": 3.9693333333333337e-07,
      "logits/chosen": -2.412283420562744,
      "logits/rejected": -3.3721566200256348,
      "logps/chosen": -121.96490478515625,
      "logps/rejected": -212.16909790039062,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0870780944824219,
      "rewards/margins": 10.762652397155762,
      "rewards/rejected": -9.67557430267334,
      "step": 4524
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.41272053122520447,
      "learning_rate": 3.9679999999999995e-07,
      "logits/chosen": -2.6703267097473145,
      "logits/rejected": -2.933682918548584,
      "logps/chosen": -186.37535095214844,
      "logps/rejected": -188.84422302246094,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1602783054113388,
      "rewards/margins": 7.341438293457031,
      "rewards/rejected": -7.181159973144531,
      "step": 4525
    },
    {
      "epoch": 1.8104,
      "grad_norm": 0.0014144215965643525,
      "learning_rate": 3.9666666666666665e-07,
      "logits/chosen": -2.175865650177002,
      "logits/rejected": -3.541078805923462,
      "logps/chosen": -102.38121032714844,
      "logps/rejected": -182.77210998535156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6331701278686523,
      "rewards/margins": 11.953773498535156,
      "rewards/rejected": -8.32060432434082,
      "step": 4526
    },
    {
      "epoch": 1.8108,
      "grad_norm": 0.0003177981125190854,
      "learning_rate": 3.9653333333333334e-07,
      "logits/chosen": -2.0886056423187256,
      "logits/rejected": -3.8629112243652344,
      "logps/chosen": -81.51022338867188,
      "logps/rejected": -188.12139892578125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.632811546325684,
      "rewards/margins": 13.853250503540039,
      "rewards/rejected": -9.220439910888672,
      "step": 4527
    },
    {
      "epoch": 1.8112,
      "grad_norm": 0.008950961753726006,
      "learning_rate": 3.964e-07,
      "logits/chosen": -2.4579052925109863,
      "logits/rejected": -2.889425277709961,
      "logps/chosen": -195.88796997070312,
      "logps/rejected": -175.35140991210938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9371895790100098,
      "rewards/margins": 9.892102241516113,
      "rewards/rejected": -6.9549126625061035,
      "step": 4528
    },
    {
      "epoch": 1.8115999999999999,
      "grad_norm": 0.001173093682155013,
      "learning_rate": 3.962666666666666e-07,
      "logits/chosen": -2.2128255367279053,
      "logits/rejected": -4.053494453430176,
      "logps/chosen": -111.76129150390625,
      "logps/rejected": -177.737548828125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0054163932800293,
      "rewards/margins": 11.957500457763672,
      "rewards/rejected": -8.952083587646484,
      "step": 4529
    },
    {
      "epoch": 1.812,
      "grad_norm": 0.005035744048655033,
      "learning_rate": 3.961333333333333e-07,
      "logits/chosen": -2.146232843399048,
      "logits/rejected": -3.1871209144592285,
      "logps/chosen": -120.81997680664062,
      "logps/rejected": -171.52871704101562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.365859031677246,
      "rewards/margins": 11.603248596191406,
      "rewards/rejected": -8.23738956451416,
      "step": 4530
    },
    {
      "epoch": 1.8124,
      "grad_norm": 0.17500127851963043,
      "learning_rate": 3.96e-07,
      "logits/chosen": -2.6214075088500977,
      "logits/rejected": -3.7769899368286133,
      "logps/chosen": -144.33180236816406,
      "logps/rejected": -180.0234375,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4947437345981598,
      "rewards/margins": 7.78369140625,
      "rewards/rejected": -8.278434753417969,
      "step": 4531
    },
    {
      "epoch": 1.8128,
      "grad_norm": 0.0005981554859317839,
      "learning_rate": 3.9586666666666664e-07,
      "logits/chosen": -1.8045822381973267,
      "logits/rejected": -2.938570976257324,
      "logps/chosen": -134.05441284179688,
      "logps/rejected": -186.01170349121094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5138020515441895,
      "rewards/margins": 12.45628547668457,
      "rewards/rejected": -8.942483901977539,
      "step": 4532
    },
    {
      "epoch": 1.8132000000000001,
      "grad_norm": 0.0151523994281888,
      "learning_rate": 3.9573333333333333e-07,
      "logits/chosen": -2.5893330574035645,
      "logits/rejected": -3.280689239501953,
      "logps/chosen": -139.11740112304688,
      "logps/rejected": -189.95196533203125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3609405755996704,
      "rewards/margins": 9.064725875854492,
      "rewards/rejected": -8.703784942626953,
      "step": 4533
    },
    {
      "epoch": 1.8136,
      "grad_norm": 0.0026263573672622442,
      "learning_rate": 3.9559999999999997e-07,
      "logits/chosen": -2.1084327697753906,
      "logits/rejected": -3.518012285232544,
      "logps/chosen": -98.60609436035156,
      "logps/rejected": -168.01309204101562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9858174324035645,
      "rewards/margins": 11.247869491577148,
      "rewards/rejected": -8.262052536010742,
      "step": 4534
    },
    {
      "epoch": 1.814,
      "grad_norm": 0.00016745887114666402,
      "learning_rate": 3.9546666666666666e-07,
      "logits/chosen": -1.6696504354476929,
      "logits/rejected": -3.860170841217041,
      "logps/chosen": -82.62120056152344,
      "logps/rejected": -221.26583862304688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.140871524810791,
      "rewards/margins": 13.787766456604004,
      "rewards/rejected": -10.646894454956055,
      "step": 4535
    },
    {
      "epoch": 1.8144,
      "grad_norm": 0.006681864149868488,
      "learning_rate": 3.953333333333333e-07,
      "logits/chosen": -1.6994576454162598,
      "logits/rejected": -3.445559501647949,
      "logps/chosen": -74.32211303710938,
      "logps/rejected": -165.80337524414062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.34714674949646,
      "rewards/margins": 10.063745498657227,
      "rewards/rejected": -7.7165985107421875,
      "step": 4536
    },
    {
      "epoch": 1.8148,
      "grad_norm": 0.0014769609551876783,
      "learning_rate": 3.952e-07,
      "logits/chosen": -2.1835527420043945,
      "logits/rejected": -3.774768590927124,
      "logps/chosen": -113.13859558105469,
      "logps/rejected": -219.69610595703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2264413833618164,
      "rewards/margins": 12.86114501953125,
      "rewards/rejected": -9.634702682495117,
      "step": 4537
    },
    {
      "epoch": 1.8152,
      "grad_norm": 0.004660086240619421,
      "learning_rate": 3.950666666666667e-07,
      "logits/chosen": -1.9036486148834229,
      "logits/rejected": -3.3025565147399902,
      "logps/chosen": -145.3569793701172,
      "logps/rejected": -178.11456298828125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9767346382141113,
      "rewards/margins": 10.139092445373535,
      "rewards/rejected": -8.162358283996582,
      "step": 4538
    },
    {
      "epoch": 1.8155999999999999,
      "grad_norm": 0.007140932139009237,
      "learning_rate": 3.949333333333333e-07,
      "logits/chosen": -1.8820443153381348,
      "logits/rejected": -2.9902830123901367,
      "logps/chosen": -85.28876495361328,
      "logps/rejected": -141.7345733642578,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.534264326095581,
      "rewards/margins": 10.263504028320312,
      "rewards/rejected": -7.7292399406433105,
      "step": 4539
    },
    {
      "epoch": 1.8159999999999998,
      "grad_norm": 0.002841738285496831,
      "learning_rate": 3.9479999999999996e-07,
      "logits/chosen": -1.1720300912857056,
      "logits/rejected": -3.4610257148742676,
      "logps/chosen": -103.67019653320312,
      "logps/rejected": -188.1646728515625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9842708110809326,
      "rewards/margins": 10.913214683532715,
      "rewards/rejected": -8.928943634033203,
      "step": 4540
    },
    {
      "epoch": 1.8164,
      "grad_norm": 0.01528484933078289,
      "learning_rate": 3.9466666666666665e-07,
      "logits/chosen": -2.208589553833008,
      "logits/rejected": -3.4209561347961426,
      "logps/chosen": -144.03179931640625,
      "logps/rejected": -172.14476013183594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6609046459197998,
      "rewards/margins": 10.234603881835938,
      "rewards/rejected": -8.573698997497559,
      "step": 4541
    },
    {
      "epoch": 1.8168,
      "grad_norm": 0.4837873578071594,
      "learning_rate": 3.9453333333333335e-07,
      "logits/chosen": -2.7094082832336426,
      "logits/rejected": -2.8067264556884766,
      "logps/chosen": -181.66912841796875,
      "logps/rejected": -190.69061279296875,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.09999504685401917,
      "rewards/margins": 7.461665153503418,
      "rewards/rejected": -7.5616607666015625,
      "step": 4542
    },
    {
      "epoch": 1.8172000000000001,
      "grad_norm": 0.058697160333395004,
      "learning_rate": 3.9439999999999993e-07,
      "logits/chosen": -2.177877902984619,
      "logits/rejected": -3.3793089389801025,
      "logps/chosen": -130.2293701171875,
      "logps/rejected": -211.7012176513672,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7427017092704773,
      "rewards/margins": 11.009699821472168,
      "rewards/rejected": -10.266998291015625,
      "step": 4543
    },
    {
      "epoch": 1.8176,
      "grad_norm": 0.040519606322050095,
      "learning_rate": 3.942666666666666e-07,
      "logits/chosen": -2.6717138290405273,
      "logits/rejected": -3.7888846397399902,
      "logps/chosen": -151.433349609375,
      "logps/rejected": -168.7308349609375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0890754461288452,
      "rewards/margins": 8.607625961303711,
      "rewards/rejected": -7.518550872802734,
      "step": 4544
    },
    {
      "epoch": 1.818,
      "grad_norm": 0.04971102625131607,
      "learning_rate": 3.941333333333333e-07,
      "logits/chosen": -2.220775842666626,
      "logits/rejected": -2.634392261505127,
      "logps/chosen": -153.61219787597656,
      "logps/rejected": -158.21844482421875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.369006395339966,
      "rewards/margins": 11.731048583984375,
      "rewards/rejected": -8.362042427062988,
      "step": 4545
    },
    {
      "epoch": 1.8184,
      "grad_norm": 6.792649269104004,
      "learning_rate": 3.94e-07,
      "logits/chosen": -2.0778703689575195,
      "logits/rejected": -3.467717170715332,
      "logps/chosen": -80.21671295166016,
      "logps/rejected": -145.86029052734375,
      "loss": 0.0306,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4322375059127808,
      "rewards/margins": 5.519740104675293,
      "rewards/rejected": -6.951977729797363,
      "step": 4546
    },
    {
      "epoch": 1.8188,
      "grad_norm": 0.001092245220206678,
      "learning_rate": 3.9386666666666665e-07,
      "logits/chosen": -1.953810214996338,
      "logits/rejected": -3.6992008686065674,
      "logps/chosen": -113.85609436035156,
      "logps/rejected": -164.78378295898438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.867465019226074,
      "rewards/margins": 11.86999797821045,
      "rewards/rejected": -8.002532958984375,
      "step": 4547
    },
    {
      "epoch": 1.8192,
      "grad_norm": 0.010043982416391373,
      "learning_rate": 3.937333333333333e-07,
      "logits/chosen": -2.291435956954956,
      "logits/rejected": -3.4669768810272217,
      "logps/chosen": -122.05870819091797,
      "logps/rejected": -177.1720733642578,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8993031978607178,
      "rewards/margins": 9.625088691711426,
      "rewards/rejected": -7.725785255432129,
      "step": 4548
    },
    {
      "epoch": 1.8195999999999999,
      "grad_norm": 0.2189779132604599,
      "learning_rate": 3.936e-07,
      "logits/chosen": -2.0584940910339355,
      "logits/rejected": -3.1186017990112305,
      "logps/chosen": -229.20419311523438,
      "logps/rejected": -182.95838928222656,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5420494079589844,
      "rewards/margins": 10.337699890136719,
      "rewards/rejected": -7.795651435852051,
      "step": 4549
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 5.668206214904785,
      "learning_rate": 3.9346666666666667e-07,
      "logits/chosen": -1.9305222034454346,
      "logits/rejected": -2.7813048362731934,
      "logps/chosen": -125.83258819580078,
      "logps/rejected": -157.23892211914062,
      "loss": 0.0504,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5427665710449219,
      "rewards/margins": 6.699808120727539,
      "rewards/rejected": -6.157041549682617,
      "step": 4550
    },
    {
      "epoch": 1.8204,
      "grad_norm": 2.5285942554473877,
      "learning_rate": 3.933333333333333e-07,
      "logits/chosen": -1.6932828426361084,
      "logits/rejected": -3.2858071327209473,
      "logps/chosen": -149.0327911376953,
      "logps/rejected": -167.64752197265625,
      "loss": 0.0137,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8965328335762024,
      "rewards/margins": 7.515523910522461,
      "rewards/rejected": -6.618990898132324,
      "step": 4551
    },
    {
      "epoch": 1.8208,
      "grad_norm": 0.6033941507339478,
      "learning_rate": 3.932e-07,
      "logits/chosen": -1.8133130073547363,
      "logits/rejected": -3.017733573913574,
      "logps/chosen": -108.87982177734375,
      "logps/rejected": -146.35585021972656,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4688152074813843,
      "rewards/margins": 6.963513374328613,
      "rewards/rejected": -7.432328224182129,
      "step": 4552
    },
    {
      "epoch": 1.8212000000000002,
      "grad_norm": 0.025690043345093727,
      "learning_rate": 3.9306666666666664e-07,
      "logits/chosen": -2.229820966720581,
      "logits/rejected": -3.0296437740325928,
      "logps/chosen": -160.37081909179688,
      "logps/rejected": -221.76348876953125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3556801080703735,
      "rewards/margins": 9.209819793701172,
      "rewards/rejected": -7.85413932800293,
      "step": 4553
    },
    {
      "epoch": 1.8216,
      "grad_norm": 0.048149846494197845,
      "learning_rate": 3.9293333333333333e-07,
      "logits/chosen": -2.2130231857299805,
      "logits/rejected": -3.300952911376953,
      "logps/chosen": -109.2507095336914,
      "logps/rejected": -174.40078735351562,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.010621607303619385,
      "rewards/margins": 8.488042831420898,
      "rewards/rejected": -8.498664855957031,
      "step": 4554
    },
    {
      "epoch": 1.822,
      "grad_norm": 0.004682088736444712,
      "learning_rate": 3.9279999999999997e-07,
      "logits/chosen": -1.9979702234268188,
      "logits/rejected": -3.36161470413208,
      "logps/chosen": -134.25192260742188,
      "logps/rejected": -189.97750854492188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8199093341827393,
      "rewards/margins": 10.537004470825195,
      "rewards/rejected": -8.717095375061035,
      "step": 4555
    },
    {
      "epoch": 1.8224,
      "grad_norm": 0.10969112068414688,
      "learning_rate": 3.9266666666666666e-07,
      "logits/chosen": -2.4003710746765137,
      "logits/rejected": -3.2097113132476807,
      "logps/chosen": -128.22866821289062,
      "logps/rejected": -207.31875610351562,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2110038995742798,
      "rewards/margins": 8.820647239685059,
      "rewards/rejected": -7.609643936157227,
      "step": 4556
    },
    {
      "epoch": 1.8228,
      "grad_norm": 0.0070707290433347225,
      "learning_rate": 3.925333333333333e-07,
      "logits/chosen": -1.8453195095062256,
      "logits/rejected": -3.720137596130371,
      "logps/chosen": -85.40836334228516,
      "logps/rejected": -211.09854125976562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.614236831665039,
      "rewards/margins": 12.311029434204102,
      "rewards/rejected": -8.696792602539062,
      "step": 4557
    },
    {
      "epoch": 1.8232,
      "grad_norm": 0.0015101454919204116,
      "learning_rate": 3.924e-07,
      "logits/chosen": -1.710381031036377,
      "logits/rejected": -3.6571342945098877,
      "logps/chosen": -96.98237609863281,
      "logps/rejected": -194.15762329101562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1364177465438843,
      "rewards/margins": 11.19024658203125,
      "rewards/rejected": -10.053828239440918,
      "step": 4558
    },
    {
      "epoch": 1.8235999999999999,
      "grad_norm": 0.007603929843753576,
      "learning_rate": 3.9226666666666663e-07,
      "logits/chosen": -1.1511486768722534,
      "logits/rejected": -4.154292106628418,
      "logps/chosen": -124.26966857910156,
      "logps/rejected": -188.64089965820312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.553727626800537,
      "rewards/margins": 10.461368560791016,
      "rewards/rejected": -7.907641410827637,
      "step": 4559
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 0.010166577994823456,
      "learning_rate": 3.921333333333333e-07,
      "logits/chosen": -1.9620497226715088,
      "logits/rejected": -2.9117393493652344,
      "logps/chosen": -202.23487854003906,
      "logps/rejected": -178.92364501953125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.570758104324341,
      "rewards/margins": 9.827863693237305,
      "rewards/rejected": -7.257105827331543,
      "step": 4560
    },
    {
      "epoch": 1.8244,
      "grad_norm": 1.3340224027633667,
      "learning_rate": 3.92e-07,
      "logits/chosen": -2.2993295192718506,
      "logits/rejected": -3.0934853553771973,
      "logps/chosen": -96.34967803955078,
      "logps/rejected": -133.95053100585938,
      "loss": 0.0075,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6975330710411072,
      "rewards/margins": 5.686227798461914,
      "rewards/rejected": -4.988694667816162,
      "step": 4561
    },
    {
      "epoch": 1.8248,
      "grad_norm": 1.7839488983154297,
      "learning_rate": 3.918666666666666e-07,
      "logits/chosen": -2.146110773086548,
      "logits/rejected": -2.885913372039795,
      "logps/chosen": -172.27975463867188,
      "logps/rejected": -173.94317626953125,
      "loss": 0.0133,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.521296739578247,
      "rewards/margins": 4.544523239135742,
      "rewards/rejected": -7.06581974029541,
      "step": 4562
    },
    {
      "epoch": 1.8252000000000002,
      "grad_norm": 0.48510101437568665,
      "learning_rate": 3.917333333333333e-07,
      "logits/chosen": -1.8013379573822021,
      "logits/rejected": -2.7688398361206055,
      "logps/chosen": -183.45965576171875,
      "logps/rejected": -165.2765350341797,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4948456287384033,
      "rewards/margins": 5.5341715812683105,
      "rewards/rejected": -6.029017448425293,
      "step": 4563
    },
    {
      "epoch": 1.8256000000000001,
      "grad_norm": 0.003252568654716015,
      "learning_rate": 3.916e-07,
      "logits/chosen": -1.5599145889282227,
      "logits/rejected": -3.5558037757873535,
      "logps/chosen": -102.3309326171875,
      "logps/rejected": -175.6213836669922,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1138906478881836,
      "rewards/margins": 11.741437911987305,
      "rewards/rejected": -8.627547264099121,
      "step": 4564
    },
    {
      "epoch": 1.826,
      "grad_norm": 0.0034044983331114054,
      "learning_rate": 3.914666666666667e-07,
      "logits/chosen": -1.9136162996292114,
      "logits/rejected": -2.8678982257843018,
      "logps/chosen": -124.3087158203125,
      "logps/rejected": -158.0467529296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.65150785446167,
      "rewards/margins": 11.20647144317627,
      "rewards/rejected": -7.554964065551758,
      "step": 4565
    },
    {
      "epoch": 1.8264,
      "grad_norm": 0.04679706320166588,
      "learning_rate": 3.913333333333333e-07,
      "logits/chosen": -2.0761876106262207,
      "logits/rejected": -3.455911636352539,
      "logps/chosen": -121.30865478515625,
      "logps/rejected": -174.56289672851562,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.231757402420044,
      "rewards/margins": 10.549894332885742,
      "rewards/rejected": -8.318137168884277,
      "step": 4566
    },
    {
      "epoch": 1.8268,
      "grad_norm": 0.0004217387759126723,
      "learning_rate": 3.9119999999999996e-07,
      "logits/chosen": -1.9402164220809937,
      "logits/rejected": -3.8105478286743164,
      "logps/chosen": -141.18194580078125,
      "logps/rejected": -234.41519165039062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1837542057037354,
      "rewards/margins": 13.137393951416016,
      "rewards/rejected": -9.95363998413086,
      "step": 4567
    },
    {
      "epoch": 1.8272,
      "grad_norm": 0.003766210749745369,
      "learning_rate": 3.9106666666666665e-07,
      "logits/chosen": -1.7322224378585815,
      "logits/rejected": -3.346674919128418,
      "logps/chosen": -147.71426391601562,
      "logps/rejected": -176.64175415039062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2191243171691895,
      "rewards/margins": 11.13023567199707,
      "rewards/rejected": -7.911110877990723,
      "step": 4568
    },
    {
      "epoch": 1.8276,
      "grad_norm": 0.0006957397563382983,
      "learning_rate": 3.9093333333333334e-07,
      "logits/chosen": -2.454991340637207,
      "logits/rejected": -3.328118324279785,
      "logps/chosen": -119.05522918701172,
      "logps/rejected": -249.68896484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.793074131011963,
      "rewards/margins": 12.48983097076416,
      "rewards/rejected": -9.696756362915039,
      "step": 4569
    },
    {
      "epoch": 1.8279999999999998,
      "grad_norm": 0.021266797557473183,
      "learning_rate": 3.908e-07,
      "logits/chosen": -2.0122385025024414,
      "logits/rejected": -3.1262502670288086,
      "logps/chosen": -202.86082458496094,
      "logps/rejected": -168.4171600341797,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.533621609210968,
      "rewards/margins": 9.75152587890625,
      "rewards/rejected": -9.217905044555664,
      "step": 4570
    },
    {
      "epoch": 1.8284,
      "grad_norm": 0.13952556252479553,
      "learning_rate": 3.906666666666666e-07,
      "logits/chosen": -1.9119157791137695,
      "logits/rejected": -3.1370487213134766,
      "logps/chosen": -136.1309051513672,
      "logps/rejected": -167.06674194335938,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4868240356445312,
      "rewards/margins": 8.664834976196289,
      "rewards/rejected": -7.178010940551758,
      "step": 4571
    },
    {
      "epoch": 1.8288,
      "grad_norm": 0.010307051241397858,
      "learning_rate": 3.905333333333333e-07,
      "logits/chosen": -1.8535947799682617,
      "logits/rejected": -2.7800817489624023,
      "logps/chosen": -136.1126708984375,
      "logps/rejected": -191.553955078125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5329484939575195,
      "rewards/margins": 11.180248260498047,
      "rewards/rejected": -7.6473002433776855,
      "step": 4572
    },
    {
      "epoch": 1.8292000000000002,
      "grad_norm": 0.0005379763897508383,
      "learning_rate": 3.904e-07,
      "logits/chosen": -2.088536262512207,
      "logits/rejected": -3.4134702682495117,
      "logps/chosen": -156.75128173828125,
      "logps/rejected": -259.8370361328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5979397296905518,
      "rewards/margins": 13.084166526794434,
      "rewards/rejected": -10.486227035522461,
      "step": 4573
    },
    {
      "epoch": 1.8296000000000001,
      "grad_norm": 0.02257414162158966,
      "learning_rate": 3.9026666666666664e-07,
      "logits/chosen": -1.6172889471054077,
      "logits/rejected": -2.552302598953247,
      "logps/chosen": -100.44591522216797,
      "logps/rejected": -141.86627197265625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2533910274505615,
      "rewards/margins": 8.529712677001953,
      "rewards/rejected": -6.2763214111328125,
      "step": 4574
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.03140444681048393,
      "learning_rate": 3.9013333333333333e-07,
      "logits/chosen": -2.111370086669922,
      "logits/rejected": -3.100025177001953,
      "logps/chosen": -100.45867919921875,
      "logps/rejected": -182.79586791992188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4006807804107666,
      "rewards/margins": 9.773784637451172,
      "rewards/rejected": -7.373104095458984,
      "step": 4575
    },
    {
      "epoch": 1.8304,
      "grad_norm": 0.00859835185110569,
      "learning_rate": 3.8999999999999997e-07,
      "logits/chosen": -2.6634509563446045,
      "logits/rejected": -3.3556315898895264,
      "logps/chosen": -173.96897888183594,
      "logps/rejected": -216.53024291992188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3112754821777344,
      "rewards/margins": 10.044412612915039,
      "rewards/rejected": -8.733137130737305,
      "step": 4576
    },
    {
      "epoch": 1.8308,
      "grad_norm": 0.010367551818490028,
      "learning_rate": 3.898666666666666e-07,
      "logits/chosen": -2.1599154472351074,
      "logits/rejected": -3.6415834426879883,
      "logps/chosen": -188.57440185546875,
      "logps/rejected": -245.3227996826172,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1962502002716064,
      "rewards/margins": 11.69479751586914,
      "rewards/rejected": -9.498546600341797,
      "step": 4577
    },
    {
      "epoch": 1.8312,
      "grad_norm": 0.0023120660334825516,
      "learning_rate": 3.897333333333333e-07,
      "logits/chosen": -2.2906742095947266,
      "logits/rejected": -3.2200698852539062,
      "logps/chosen": -204.8844757080078,
      "logps/rejected": -205.70050048828125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3747739791870117,
      "rewards/margins": 12.457493782043457,
      "rewards/rejected": -9.082719802856445,
      "step": 4578
    },
    {
      "epoch": 1.8316,
      "grad_norm": 0.010308340191841125,
      "learning_rate": 3.896e-07,
      "logits/chosen": -2.1876749992370605,
      "logits/rejected": -3.7658886909484863,
      "logps/chosen": -139.28518676757812,
      "logps/rejected": -192.4512939453125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6062958240509033,
      "rewards/margins": 10.148974418640137,
      "rewards/rejected": -8.542678833007812,
      "step": 4579
    },
    {
      "epoch": 1.8319999999999999,
      "grad_norm": 0.0007490531424991786,
      "learning_rate": 3.894666666666667e-07,
      "logits/chosen": -2.381446123123169,
      "logits/rejected": -3.0547685623168945,
      "logps/chosen": -160.300048828125,
      "logps/rejected": -231.90455627441406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0853816270828247,
      "rewards/margins": 12.201160430908203,
      "rewards/rejected": -11.115777969360352,
      "step": 4580
    },
    {
      "epoch": 1.8324,
      "grad_norm": 0.4449179172515869,
      "learning_rate": 3.8933333333333327e-07,
      "logits/chosen": -2.1928067207336426,
      "logits/rejected": -2.9962382316589355,
      "logps/chosen": -97.60753631591797,
      "logps/rejected": -189.23291015625,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.491999626159668,
      "rewards/margins": 8.060892105102539,
      "rewards/rejected": -6.568892478942871,
      "step": 4581
    },
    {
      "epoch": 1.8328,
      "grad_norm": 0.0015560189494863153,
      "learning_rate": 3.8919999999999996e-07,
      "logits/chosen": -2.535565137863159,
      "logits/rejected": -3.35471773147583,
      "logps/chosen": -169.1747283935547,
      "logps/rejected": -197.18966674804688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0755393505096436,
      "rewards/margins": 11.226905822753906,
      "rewards/rejected": -9.1513671875,
      "step": 4582
    },
    {
      "epoch": 1.8332000000000002,
      "grad_norm": 0.03891203925013542,
      "learning_rate": 3.8906666666666666e-07,
      "logits/chosen": -1.8989455699920654,
      "logits/rejected": -3.7155656814575195,
      "logps/chosen": -167.87677001953125,
      "logps/rejected": -187.66299438476562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2739285230636597,
      "rewards/margins": 10.457273483276367,
      "rewards/rejected": -9.183344841003418,
      "step": 4583
    },
    {
      "epoch": 1.8336000000000001,
      "grad_norm": 0.0038752625696361065,
      "learning_rate": 3.8893333333333335e-07,
      "logits/chosen": -2.0875332355499268,
      "logits/rejected": -3.4913382530212402,
      "logps/chosen": -132.32229614257812,
      "logps/rejected": -198.0865478515625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.494335889816284,
      "rewards/margins": 11.185747146606445,
      "rewards/rejected": -7.691411972045898,
      "step": 4584
    },
    {
      "epoch": 1.834,
      "grad_norm": 0.0003564640355762094,
      "learning_rate": 3.888e-07,
      "logits/chosen": -1.965160608291626,
      "logits/rejected": -3.690753936767578,
      "logps/chosen": -141.5420684814453,
      "logps/rejected": -248.4783477783203,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.687283992767334,
      "rewards/margins": 13.206070899963379,
      "rewards/rejected": -9.518787384033203,
      "step": 4585
    },
    {
      "epoch": 1.8344,
      "grad_norm": 0.04277202486991882,
      "learning_rate": 3.8866666666666663e-07,
      "logits/chosen": -2.531299114227295,
      "logits/rejected": -3.172055721282959,
      "logps/chosen": -248.7400665283203,
      "logps/rejected": -203.77227783203125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6671876907348633,
      "rewards/margins": 10.886068344116211,
      "rewards/rejected": -8.218880653381348,
      "step": 4586
    },
    {
      "epoch": 1.8348,
      "grad_norm": 0.0003085369535256177,
      "learning_rate": 3.885333333333333e-07,
      "logits/chosen": -2.3341917991638184,
      "logits/rejected": -3.1332571506500244,
      "logps/chosen": -89.9277114868164,
      "logps/rejected": -187.79127502441406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.545706272125244,
      "rewards/margins": 12.914960861206055,
      "rewards/rejected": -9.369255065917969,
      "step": 4587
    },
    {
      "epoch": 1.8352,
      "grad_norm": 0.006198082584887743,
      "learning_rate": 3.884e-07,
      "logits/chosen": -1.8738842010498047,
      "logits/rejected": -2.935396909713745,
      "logps/chosen": -93.78278350830078,
      "logps/rejected": -160.38612365722656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8458292484283447,
      "rewards/margins": 11.165704727172852,
      "rewards/rejected": -7.319875717163086,
      "step": 4588
    },
    {
      "epoch": 1.8356,
      "grad_norm": 0.019607525318861008,
      "learning_rate": 3.8826666666666665e-07,
      "logits/chosen": -2.0187549591064453,
      "logits/rejected": -3.0370090007781982,
      "logps/chosen": -141.6414794921875,
      "logps/rejected": -173.9258575439453,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4251857995986938,
      "rewards/margins": 10.457075119018555,
      "rewards/rejected": -9.031889915466309,
      "step": 4589
    },
    {
      "epoch": 1.8359999999999999,
      "grad_norm": 0.23832078278064728,
      "learning_rate": 3.881333333333333e-07,
      "logits/chosen": -2.717207431793213,
      "logits/rejected": -3.188258647918701,
      "logps/chosen": -263.80657958984375,
      "logps/rejected": -184.78359985351562,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2619903087615967,
      "rewards/margins": 6.447014331817627,
      "rewards/rejected": -7.7090044021606445,
      "step": 4590
    },
    {
      "epoch": 1.8364,
      "grad_norm": 0.018064117059111595,
      "learning_rate": 3.88e-07,
      "logits/chosen": -1.7338533401489258,
      "logits/rejected": -3.3498451709747314,
      "logps/chosen": -105.35369110107422,
      "logps/rejected": -158.23281860351562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1629035472869873,
      "rewards/margins": 8.974148750305176,
      "rewards/rejected": -6.811244964599609,
      "step": 4591
    },
    {
      "epoch": 1.8368,
      "grad_norm": 0.00044036086183041334,
      "learning_rate": 3.8786666666666667e-07,
      "logits/chosen": -2.324249267578125,
      "logits/rejected": -2.8942196369171143,
      "logps/chosen": -74.17399597167969,
      "logps/rejected": -196.39784240722656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8724145889282227,
      "rewards/margins": 13.12320327758789,
      "rewards/rejected": -9.250788688659668,
      "step": 4592
    },
    {
      "epoch": 1.8372000000000002,
      "grad_norm": 0.034909263253211975,
      "learning_rate": 3.877333333333333e-07,
      "logits/chosen": -2.3860583305358887,
      "logits/rejected": -3.4110965728759766,
      "logps/chosen": -126.26688385009766,
      "logps/rejected": -201.6702423095703,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9906582236289978,
      "rewards/margins": 10.62544059753418,
      "rewards/rejected": -9.634781837463379,
      "step": 4593
    },
    {
      "epoch": 1.8376000000000001,
      "grad_norm": 0.002602554392069578,
      "learning_rate": 3.876e-07,
      "logits/chosen": -2.34126353263855,
      "logits/rejected": -3.05265212059021,
      "logps/chosen": -162.73260498046875,
      "logps/rejected": -185.44815063476562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3337526321411133,
      "rewards/margins": 11.066997528076172,
      "rewards/rejected": -7.733245849609375,
      "step": 4594
    },
    {
      "epoch": 1.838,
      "grad_norm": 0.2369072288274765,
      "learning_rate": 3.8746666666666664e-07,
      "logits/chosen": -2.703603744506836,
      "logits/rejected": -3.5685906410217285,
      "logps/chosen": -149.89346313476562,
      "logps/rejected": -247.13320922851562,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.254220724105835,
      "rewards/margins": 9.951745986938477,
      "rewards/rejected": -11.20596694946289,
      "step": 4595
    },
    {
      "epoch": 1.8384,
      "grad_norm": 0.004403349012136459,
      "learning_rate": 3.873333333333333e-07,
      "logits/chosen": -1.9528727531433105,
      "logits/rejected": -3.48213529586792,
      "logps/chosen": -97.55928039550781,
      "logps/rejected": -167.61500549316406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.079709529876709,
      "rewards/margins": 10.102851867675781,
      "rewards/rejected": -8.02314281463623,
      "step": 4596
    },
    {
      "epoch": 1.8388,
      "grad_norm": 0.008562963455915451,
      "learning_rate": 3.8719999999999997e-07,
      "logits/chosen": -2.2903506755828857,
      "logits/rejected": -3.162855863571167,
      "logps/chosen": -127.78878784179688,
      "logps/rejected": -258.5174865722656,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7986221313476562,
      "rewards/margins": 14.000693321228027,
      "rewards/rejected": -11.202071189880371,
      "step": 4597
    },
    {
      "epoch": 1.8392,
      "grad_norm": 0.0058693126775324345,
      "learning_rate": 3.8706666666666667e-07,
      "logits/chosen": -2.1101760864257812,
      "logits/rejected": -3.461029052734375,
      "logps/chosen": -76.06267547607422,
      "logps/rejected": -199.55734252929688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1240692138671875,
      "rewards/margins": 12.552985191345215,
      "rewards/rejected": -9.428916931152344,
      "step": 4598
    },
    {
      "epoch": 1.8396,
      "grad_norm": 0.009569069370627403,
      "learning_rate": 3.8693333333333336e-07,
      "logits/chosen": -1.8946516513824463,
      "logits/rejected": -3.336024284362793,
      "logps/chosen": -148.39993286132812,
      "logps/rejected": -188.18614196777344,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9691085815429688,
      "rewards/margins": 10.029988288879395,
      "rewards/rejected": -7.060879707336426,
      "step": 4599
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.002115870825946331,
      "learning_rate": 3.8679999999999994e-07,
      "logits/chosen": -2.002744674682617,
      "logits/rejected": -3.2925777435302734,
      "logps/chosen": -143.64505004882812,
      "logps/rejected": -193.25814819335938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.01961612701416,
      "rewards/margins": 11.171245574951172,
      "rewards/rejected": -8.151629447937012,
      "step": 4600
    },
    {
      "epoch": 1.8404,
      "grad_norm": 0.0006984314532019198,
      "learning_rate": 3.8666666666666664e-07,
      "logits/chosen": -2.2705821990966797,
      "logits/rejected": -3.074863910675049,
      "logps/chosen": -117.94401550292969,
      "logps/rejected": -219.1014404296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0246284008026123,
      "rewards/margins": 12.273515701293945,
      "rewards/rejected": -10.248887062072754,
      "step": 4601
    },
    {
      "epoch": 1.8408,
      "grad_norm": 0.5544524192810059,
      "learning_rate": 3.8653333333333333e-07,
      "logits/chosen": -1.923280119895935,
      "logits/rejected": -3.0797135829925537,
      "logps/chosen": -110.63768005371094,
      "logps/rejected": -158.98980712890625,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2371387481689453,
      "rewards/margins": 8.786941528320312,
      "rewards/rejected": -7.549802303314209,
      "step": 4602
    },
    {
      "epoch": 1.8412,
      "grad_norm": 0.2195146083831787,
      "learning_rate": 3.864e-07,
      "logits/chosen": -1.9882962703704834,
      "logits/rejected": -3.433225154876709,
      "logps/chosen": -83.4596176147461,
      "logps/rejected": -167.3238525390625,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3466322422027588,
      "rewards/margins": 9.749122619628906,
      "rewards/rejected": -8.402490615844727,
      "step": 4603
    },
    {
      "epoch": 1.8416000000000001,
      "grad_norm": 0.24316081404685974,
      "learning_rate": 3.862666666666666e-07,
      "logits/chosen": -2.7852749824523926,
      "logits/rejected": -3.356358766555786,
      "logps/chosen": -95.56413269042969,
      "logps/rejected": -184.65330505371094,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6233673095703125,
      "rewards/margins": 8.005411148071289,
      "rewards/rejected": -7.382043838500977,
      "step": 4604
    },
    {
      "epoch": 1.842,
      "grad_norm": 0.006482207681983709,
      "learning_rate": 3.861333333333333e-07,
      "logits/chosen": -2.2655742168426514,
      "logits/rejected": -3.640693187713623,
      "logps/chosen": -133.16064453125,
      "logps/rejected": -212.0615234375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5692135095596313,
      "rewards/margins": 10.753164291381836,
      "rewards/rejected": -9.183950424194336,
      "step": 4605
    },
    {
      "epoch": 1.8424,
      "grad_norm": 0.01012326404452324,
      "learning_rate": 3.86e-07,
      "logits/chosen": -1.9998060464859009,
      "logits/rejected": -3.788931369781494,
      "logps/chosen": -116.56449890136719,
      "logps/rejected": -211.1333770751953,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.767235517501831,
      "rewards/margins": 12.17388916015625,
      "rewards/rejected": -11.406654357910156,
      "step": 4606
    },
    {
      "epoch": 1.8428,
      "grad_norm": 0.021113554015755653,
      "learning_rate": 3.858666666666667e-07,
      "logits/chosen": -1.8067643642425537,
      "logits/rejected": -3.1957106590270996,
      "logps/chosen": -148.39633178710938,
      "logps/rejected": -214.05593872070312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0466530323028564,
      "rewards/margins": 10.189992904663086,
      "rewards/rejected": -9.143340110778809,
      "step": 4607
    },
    {
      "epoch": 1.8432,
      "grad_norm": 0.013286913745105267,
      "learning_rate": 3.857333333333333e-07,
      "logits/chosen": -1.9662606716156006,
      "logits/rejected": -3.2892556190490723,
      "logps/chosen": -163.86544799804688,
      "logps/rejected": -185.99905395507812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1570541858673096,
      "rewards/margins": 10.85543441772461,
      "rewards/rejected": -8.698380470275879,
      "step": 4608
    },
    {
      "epoch": 1.8436,
      "grad_norm": 0.0003835810348391533,
      "learning_rate": 3.8559999999999996e-07,
      "logits/chosen": -2.1577467918395996,
      "logits/rejected": -3.5059814453125,
      "logps/chosen": -131.0811767578125,
      "logps/rejected": -203.1509246826172,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.086065292358398,
      "rewards/margins": 13.38044261932373,
      "rewards/rejected": -9.294377326965332,
      "step": 4609
    },
    {
      "epoch": 1.8439999999999999,
      "grad_norm": 0.02482369728386402,
      "learning_rate": 3.8546666666666665e-07,
      "logits/chosen": -2.21140193939209,
      "logits/rejected": -3.535808801651001,
      "logps/chosen": -136.84405517578125,
      "logps/rejected": -185.11770629882812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6641872525215149,
      "rewards/margins": 8.483377456665039,
      "rewards/rejected": -7.81919002532959,
      "step": 4610
    },
    {
      "epoch": 1.8444,
      "grad_norm": 0.006142458878457546,
      "learning_rate": 3.8533333333333334e-07,
      "logits/chosen": -1.8732304573059082,
      "logits/rejected": -3.522078514099121,
      "logps/chosen": -124.09219360351562,
      "logps/rejected": -195.40078735351562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3799588680267334,
      "rewards/margins": 10.58188247680664,
      "rewards/rejected": -7.2019243240356445,
      "step": 4611
    },
    {
      "epoch": 1.8448,
      "grad_norm": 0.2555137574672699,
      "learning_rate": 3.852e-07,
      "logits/chosen": -2.3214385509490967,
      "logits/rejected": -3.5569028854370117,
      "logps/chosen": -114.61954498291016,
      "logps/rejected": -197.84596252441406,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2613261938095093,
      "rewards/margins": 7.3667192459106445,
      "rewards/rejected": -7.628045082092285,
      "step": 4612
    },
    {
      "epoch": 1.8452,
      "grad_norm": 0.04463419318199158,
      "learning_rate": 3.850666666666667e-07,
      "logits/chosen": -2.263733148574829,
      "logits/rejected": -3.3242063522338867,
      "logps/chosen": -131.71783447265625,
      "logps/rejected": -155.73797607421875,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3480663299560547,
      "rewards/margins": 9.020544052124023,
      "rewards/rejected": -7.672476768493652,
      "step": 4613
    },
    {
      "epoch": 1.8456000000000001,
      "grad_norm": 0.00022001309844199568,
      "learning_rate": 3.849333333333333e-07,
      "logits/chosen": -2.1286823749542236,
      "logits/rejected": -3.2758402824401855,
      "logps/chosen": -119.25259399414062,
      "logps/rejected": -222.2535858154297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.87724232673645,
      "rewards/margins": 13.304096221923828,
      "rewards/rejected": -10.42685317993164,
      "step": 4614
    },
    {
      "epoch": 1.846,
      "grad_norm": 0.06947126984596252,
      "learning_rate": 3.8479999999999995e-07,
      "logits/chosen": -2.0063560009002686,
      "logits/rejected": -3.431485176086426,
      "logps/chosen": -176.6046905517578,
      "logps/rejected": -188.90447998046875,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1653900444507599,
      "rewards/margins": 8.70037841796875,
      "rewards/rejected": -8.534988403320312,
      "step": 4615
    },
    {
      "epoch": 1.8464,
      "grad_norm": 0.02863706834614277,
      "learning_rate": 3.8466666666666664e-07,
      "logits/chosen": -2.425874948501587,
      "logits/rejected": -3.3872971534729004,
      "logps/chosen": -157.4134063720703,
      "logps/rejected": -151.1811981201172,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1488056182861328,
      "rewards/margins": 8.389490127563477,
      "rewards/rejected": -7.2406840324401855,
      "step": 4616
    },
    {
      "epoch": 1.8468,
      "grad_norm": 0.01755867898464203,
      "learning_rate": 3.8453333333333334e-07,
      "logits/chosen": -2.520801067352295,
      "logits/rejected": -3.4365382194519043,
      "logps/chosen": -150.56361389160156,
      "logps/rejected": -212.30836486816406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0157191753387451,
      "rewards/margins": 10.023128509521484,
      "rewards/rejected": -9.00740909576416,
      "step": 4617
    },
    {
      "epoch": 1.8472,
      "grad_norm": 0.004417873919010162,
      "learning_rate": 3.8440000000000003e-07,
      "logits/chosen": -2.255373239517212,
      "logits/rejected": -3.1920385360717773,
      "logps/chosen": -112.94084167480469,
      "logps/rejected": -180.46470642089844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.531391143798828,
      "rewards/margins": 11.846336364746094,
      "rewards/rejected": -8.314945220947266,
      "step": 4618
    },
    {
      "epoch": 1.8476,
      "grad_norm": 0.008846803568303585,
      "learning_rate": 3.842666666666666e-07,
      "logits/chosen": -2.0842607021331787,
      "logits/rejected": -3.24530029296875,
      "logps/chosen": -131.55044555664062,
      "logps/rejected": -224.6212615966797,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0602226257324219,
      "rewards/margins": 10.165532112121582,
      "rewards/rejected": -9.10530948638916,
      "step": 4619
    },
    {
      "epoch": 1.8479999999999999,
      "grad_norm": 0.001609231112524867,
      "learning_rate": 3.841333333333333e-07,
      "logits/chosen": -2.457122802734375,
      "logits/rejected": -3.7212696075439453,
      "logps/chosen": -132.7602996826172,
      "logps/rejected": -231.03427124023438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0194759368896484,
      "rewards/margins": 11.69849967956543,
      "rewards/rejected": -10.679023742675781,
      "step": 4620
    },
    {
      "epoch": 1.8484,
      "grad_norm": 0.08800993114709854,
      "learning_rate": 3.84e-07,
      "logits/chosen": -2.375386953353882,
      "logits/rejected": -3.3903417587280273,
      "logps/chosen": -129.43634033203125,
      "logps/rejected": -172.5816650390625,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.512163519859314,
      "rewards/margins": 8.972825050354004,
      "rewards/rejected": -8.460660934448242,
      "step": 4621
    },
    {
      "epoch": 1.8488,
      "grad_norm": 0.006715924479067326,
      "learning_rate": 3.838666666666667e-07,
      "logits/chosen": -2.128345489501953,
      "logits/rejected": -3.2909421920776367,
      "logps/chosen": -83.94781494140625,
      "logps/rejected": -177.8925323486328,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1426002979278564,
      "rewards/margins": 9.749948501586914,
      "rewards/rejected": -8.60734748840332,
      "step": 4622
    },
    {
      "epoch": 1.8492,
      "grad_norm": 0.007218841928988695,
      "learning_rate": 3.837333333333333e-07,
      "logits/chosen": -2.0151448249816895,
      "logits/rejected": -3.4186415672302246,
      "logps/chosen": -168.98690795898438,
      "logps/rejected": -243.41592407226562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019178032875061035,
      "rewards/margins": 10.167842864990234,
      "rewards/rejected": -10.148664474487305,
      "step": 4623
    },
    {
      "epoch": 1.8496000000000001,
      "grad_norm": 0.003434768645092845,
      "learning_rate": 3.8359999999999997e-07,
      "logits/chosen": -2.3258843421936035,
      "logits/rejected": -3.6994190216064453,
      "logps/chosen": -61.85553741455078,
      "logps/rejected": -171.79400634765625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4757983684539795,
      "rewards/margins": 10.369842529296875,
      "rewards/rejected": -7.894043922424316,
      "step": 4624
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.01380146760493517,
      "learning_rate": 3.8346666666666666e-07,
      "logits/chosen": -2.346334457397461,
      "logits/rejected": -3.402892827987671,
      "logps/chosen": -194.80523681640625,
      "logps/rejected": -202.89291381835938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.582512617111206,
      "rewards/margins": 10.422852516174316,
      "rewards/rejected": -8.840339660644531,
      "step": 4625
    },
    {
      "epoch": 1.8504,
      "grad_norm": 0.0012741419486701488,
      "learning_rate": 3.8333333333333335e-07,
      "logits/chosen": -1.9678127765655518,
      "logits/rejected": -3.886605739593506,
      "logps/chosen": -186.8135223388672,
      "logps/rejected": -191.73428344726562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5393528938293457,
      "rewards/margins": 11.628631591796875,
      "rewards/rejected": -8.089278221130371,
      "step": 4626
    },
    {
      "epoch": 1.8508,
      "grad_norm": 0.03795323148369789,
      "learning_rate": 3.832e-07,
      "logits/chosen": -2.4545559883117676,
      "logits/rejected": -3.0886240005493164,
      "logps/chosen": -186.73736572265625,
      "logps/rejected": -163.15728759765625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6190086603164673,
      "rewards/margins": 7.803550720214844,
      "rewards/rejected": -7.184541702270508,
      "step": 4627
    },
    {
      "epoch": 1.8512,
      "grad_norm": 0.004478180781006813,
      "learning_rate": 3.8306666666666663e-07,
      "logits/chosen": -2.681461811065674,
      "logits/rejected": -3.498709201812744,
      "logps/chosen": -123.69190979003906,
      "logps/rejected": -180.57791137695312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2020485401153564,
      "rewards/margins": 11.264345169067383,
      "rewards/rejected": -9.062296867370605,
      "step": 4628
    },
    {
      "epoch": 1.8516,
      "grad_norm": 0.005005575250834227,
      "learning_rate": 3.829333333333333e-07,
      "logits/chosen": -2.195744037628174,
      "logits/rejected": -4.066545486450195,
      "logps/chosen": -167.97218322753906,
      "logps/rejected": -200.345947265625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6876507997512817,
      "rewards/margins": 10.302066802978516,
      "rewards/rejected": -8.614416122436523,
      "step": 4629
    },
    {
      "epoch": 1.8519999999999999,
      "grad_norm": 0.018436890095472336,
      "learning_rate": 3.8279999999999996e-07,
      "logits/chosen": -1.7780768871307373,
      "logits/rejected": -3.046670913696289,
      "logps/chosen": -112.4608154296875,
      "logps/rejected": -209.58560180664062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.101496934890747,
      "rewards/margins": 11.680059432983398,
      "rewards/rejected": -8.578563690185547,
      "step": 4630
    },
    {
      "epoch": 1.8524,
      "grad_norm": 0.45837387442588806,
      "learning_rate": 3.8266666666666665e-07,
      "logits/chosen": -2.2497761249542236,
      "logits/rejected": -3.083726644515991,
      "logps/chosen": -255.67034912109375,
      "logps/rejected": -161.5671844482422,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3273170590400696,
      "rewards/margins": 5.846453666687012,
      "rewards/rejected": -5.519136428833008,
      "step": 4631
    },
    {
      "epoch": 1.8528,
      "grad_norm": 0.002611503005027771,
      "learning_rate": 3.8253333333333334e-07,
      "logits/chosen": -2.3721001148223877,
      "logits/rejected": -4.221258640289307,
      "logps/chosen": -165.81228637695312,
      "logps/rejected": -176.7581787109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.647247314453125,
      "rewards/margins": 11.582338333129883,
      "rewards/rejected": -7.935091495513916,
      "step": 4632
    },
    {
      "epoch": 1.8532,
      "grad_norm": 0.0002308343246113509,
      "learning_rate": 3.824e-07,
      "logits/chosen": -1.7808750867843628,
      "logits/rejected": -3.6160287857055664,
      "logps/chosen": -74.73983764648438,
      "logps/rejected": -222.170166015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.21125864982605,
      "rewards/margins": 14.142557144165039,
      "rewards/rejected": -10.931299209594727,
      "step": 4633
    },
    {
      "epoch": 1.8536000000000001,
      "grad_norm": 0.051965996623039246,
      "learning_rate": 3.822666666666666e-07,
      "logits/chosen": -2.1724724769592285,
      "logits/rejected": -3.153024435043335,
      "logps/chosen": -228.89486694335938,
      "logps/rejected": -196.50103759765625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40595555305480957,
      "rewards/margins": 9.01083755493164,
      "rewards/rejected": -8.60488224029541,
      "step": 4634
    },
    {
      "epoch": 1.854,
      "grad_norm": 0.05054555460810661,
      "learning_rate": 3.821333333333333e-07,
      "logits/chosen": -2.195887565612793,
      "logits/rejected": -3.4319632053375244,
      "logps/chosen": -169.92103576660156,
      "logps/rejected": -199.9964599609375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5841788649559021,
      "rewards/margins": 8.557251930236816,
      "rewards/rejected": -9.141430854797363,
      "step": 4635
    },
    {
      "epoch": 1.8544,
      "grad_norm": 0.003962629474699497,
      "learning_rate": 3.82e-07,
      "logits/chosen": -2.205446243286133,
      "logits/rejected": -3.6589179039001465,
      "logps/chosen": -203.853271484375,
      "logps/rejected": -189.66455078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.576045274734497,
      "rewards/margins": 10.549348831176758,
      "rewards/rejected": -7.97330379486084,
      "step": 4636
    },
    {
      "epoch": 1.8548,
      "grad_norm": 0.02452472224831581,
      "learning_rate": 3.8186666666666665e-07,
      "logits/chosen": -1.6556862592697144,
      "logits/rejected": -3.571624279022217,
      "logps/chosen": -114.11480712890625,
      "logps/rejected": -155.70169067382812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8615635633468628,
      "rewards/margins": 9.470820426940918,
      "rewards/rejected": -7.609256744384766,
      "step": 4637
    },
    {
      "epoch": 1.8552,
      "grad_norm": 0.05980392545461655,
      "learning_rate": 3.817333333333333e-07,
      "logits/chosen": -2.1711435317993164,
      "logits/rejected": -2.5033700466156006,
      "logps/chosen": -124.45274353027344,
      "logps/rejected": -198.6789093017578,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8592987656593323,
      "rewards/margins": 8.20500659942627,
      "rewards/rejected": -7.345707893371582,
      "step": 4638
    },
    {
      "epoch": 1.8556,
      "grad_norm": 0.03314837068319321,
      "learning_rate": 3.816e-07,
      "logits/chosen": -2.05511212348938,
      "logits/rejected": -3.1351654529571533,
      "logps/chosen": -128.57305908203125,
      "logps/rejected": -173.99009704589844,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5415754318237305,
      "rewards/margins": 11.14277458190918,
      "rewards/rejected": -7.601198673248291,
      "step": 4639
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 0.061270471662282944,
      "learning_rate": 3.8146666666666667e-07,
      "logits/chosen": -2.0191941261291504,
      "logits/rejected": -3.4087533950805664,
      "logps/chosen": -159.29669189453125,
      "logps/rejected": -188.31982421875,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.45577776432037354,
      "rewards/margins": 7.757358551025391,
      "rewards/rejected": -8.213136672973633,
      "step": 4640
    },
    {
      "epoch": 1.8564,
      "grad_norm": 0.0011907719308510423,
      "learning_rate": 3.8133333333333336e-07,
      "logits/chosen": -2.0032689571380615,
      "logits/rejected": -3.0382485389709473,
      "logps/chosen": -72.2698745727539,
      "logps/rejected": -181.06265258789062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7902750968933105,
      "rewards/margins": 12.498258590698242,
      "rewards/rejected": -8.70798397064209,
      "step": 4641
    },
    {
      "epoch": 1.8568,
      "grad_norm": 0.0020191504154354334,
      "learning_rate": 3.8119999999999995e-07,
      "logits/chosen": -1.7206413745880127,
      "logits/rejected": -3.3466219902038574,
      "logps/chosen": -98.04560852050781,
      "logps/rejected": -162.90634155273438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.90812349319458,
      "rewards/margins": 10.983024597167969,
      "rewards/rejected": -7.074901580810547,
      "step": 4642
    },
    {
      "epoch": 1.8572,
      "grad_norm": 0.03316387161612511,
      "learning_rate": 3.8106666666666664e-07,
      "logits/chosen": -1.7695412635803223,
      "logits/rejected": -3.0249719619750977,
      "logps/chosen": -130.4027557373047,
      "logps/rejected": -157.3271484375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3285385370254517,
      "rewards/margins": 8.496623992919922,
      "rewards/rejected": -7.168085098266602,
      "step": 4643
    },
    {
      "epoch": 1.8576000000000001,
      "grad_norm": 0.005903701763600111,
      "learning_rate": 3.8093333333333333e-07,
      "logits/chosen": -1.7833824157714844,
      "logits/rejected": -3.354952573776245,
      "logps/chosen": -131.80030822753906,
      "logps/rejected": -204.33111572265625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31093406677246094,
      "rewards/margins": 10.731571197509766,
      "rewards/rejected": -10.420637130737305,
      "step": 4644
    },
    {
      "epoch": 1.858,
      "grad_norm": 7.001703262329102,
      "learning_rate": 3.808e-07,
      "logits/chosen": -2.687722682952881,
      "logits/rejected": -3.3906636238098145,
      "logps/chosen": -123.45388793945312,
      "logps/rejected": -174.04522705078125,
      "loss": 0.045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.213649034500122,
      "rewards/margins": 8.584735870361328,
      "rewards/rejected": -6.371087074279785,
      "step": 4645
    },
    {
      "epoch": 1.8584,
      "grad_norm": 0.004782321397215128,
      "learning_rate": 3.8066666666666666e-07,
      "logits/chosen": -2.2679390907287598,
      "logits/rejected": -3.3061580657958984,
      "logps/chosen": -157.31890869140625,
      "logps/rejected": -263.5741271972656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.833667755126953,
      "rewards/margins": 11.560911178588867,
      "rewards/rejected": -8.72724437713623,
      "step": 4646
    },
    {
      "epoch": 1.8588,
      "grad_norm": 0.08611751347780228,
      "learning_rate": 3.805333333333333e-07,
      "logits/chosen": -1.6530834436416626,
      "logits/rejected": -2.7232861518859863,
      "logps/chosen": -125.6986312866211,
      "logps/rejected": -142.09555053710938,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9434967041015625,
      "rewards/margins": 7.677516937255859,
      "rewards/rejected": -6.734020233154297,
      "step": 4647
    },
    {
      "epoch": 1.8592,
      "grad_norm": 0.0007350858068093657,
      "learning_rate": 3.804e-07,
      "logits/chosen": -1.9574615955352783,
      "logits/rejected": -2.6905746459960938,
      "logps/chosen": -96.18732452392578,
      "logps/rejected": -185.0501708984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.0336833000183105,
      "rewards/margins": 12.174450874328613,
      "rewards/rejected": -8.140768051147461,
      "step": 4648
    },
    {
      "epoch": 1.8596,
      "grad_norm": 0.00140199507586658,
      "learning_rate": 3.8026666666666663e-07,
      "logits/chosen": -2.29231858253479,
      "logits/rejected": -3.553948402404785,
      "logps/chosen": -204.6182861328125,
      "logps/rejected": -206.48098754882812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2059578895568848,
      "rewards/margins": 12.822250366210938,
      "rewards/rejected": -9.616291999816895,
      "step": 4649
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 0.0008676758734509349,
      "learning_rate": 3.801333333333333e-07,
      "logits/chosen": -2.4134087562561035,
      "logits/rejected": -3.437432050704956,
      "logps/chosen": -149.94265747070312,
      "logps/rejected": -237.51036071777344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0959373712539673,
      "rewards/margins": 12.042550086975098,
      "rewards/rejected": -10.946612358093262,
      "step": 4650
    },
    {
      "epoch": 1.8604,
      "grad_norm": 0.005015567876398563,
      "learning_rate": 3.7999999999999996e-07,
      "logits/chosen": -2.636523723602295,
      "logits/rejected": -3.618438243865967,
      "logps/chosen": -253.22998046875,
      "logps/rejected": -227.5076904296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.22427523136138916,
      "rewards/margins": 10.486804008483887,
      "rewards/rejected": -10.711078643798828,
      "step": 4651
    },
    {
      "epoch": 1.8608,
      "grad_norm": 0.01611560583114624,
      "learning_rate": 3.7986666666666665e-07,
      "logits/chosen": -1.8688315153121948,
      "logits/rejected": -3.2003254890441895,
      "logps/chosen": -112.58161926269531,
      "logps/rejected": -184.94418334960938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0477206707000732,
      "rewards/margins": 9.383100509643555,
      "rewards/rejected": -8.335379600524902,
      "step": 4652
    },
    {
      "epoch": 1.8612,
      "grad_norm": 0.02109103836119175,
      "learning_rate": 3.797333333333333e-07,
      "logits/chosen": -2.0056209564208984,
      "logits/rejected": -2.9759697914123535,
      "logps/chosen": -85.1192398071289,
      "logps/rejected": -139.961669921875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8480732440948486,
      "rewards/margins": 9.085296630859375,
      "rewards/rejected": -6.237222671508789,
      "step": 4653
    },
    {
      "epoch": 1.8616000000000001,
      "grad_norm": 0.000792560400441289,
      "learning_rate": 3.796e-07,
      "logits/chosen": -1.8756368160247803,
      "logits/rejected": -2.7923836708068848,
      "logps/chosen": -73.46202087402344,
      "logps/rejected": -177.91482543945312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0639755725860596,
      "rewards/margins": 12.45536994934082,
      "rewards/rejected": -9.39139461517334,
      "step": 4654
    },
    {
      "epoch": 1.862,
      "grad_norm": 0.14265957474708557,
      "learning_rate": 3.794666666666667e-07,
      "logits/chosen": -2.01460862159729,
      "logits/rejected": -3.0389060974121094,
      "logps/chosen": -165.24365234375,
      "logps/rejected": -200.38096618652344,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5993057489395142,
      "rewards/margins": 8.377954483032227,
      "rewards/rejected": -7.778648376464844,
      "step": 4655
    },
    {
      "epoch": 1.8624,
      "grad_norm": 0.002325326669961214,
      "learning_rate": 3.793333333333333e-07,
      "logits/chosen": -2.316098213195801,
      "logits/rejected": -3.3065710067749023,
      "logps/chosen": -161.46444702148438,
      "logps/rejected": -225.37619018554688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2627174854278564,
      "rewards/margins": 11.546436309814453,
      "rewards/rejected": -8.283719062805176,
      "step": 4656
    },
    {
      "epoch": 1.8628,
      "grad_norm": 0.0012561081675812602,
      "learning_rate": 3.7919999999999995e-07,
      "logits/chosen": -2.054274559020996,
      "logits/rejected": -3.3658037185668945,
      "logps/chosen": -99.77703857421875,
      "logps/rejected": -201.82559204101562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7755508422851562,
      "rewards/margins": 12.688499450683594,
      "rewards/rejected": -9.912948608398438,
      "step": 4657
    },
    {
      "epoch": 1.8632,
      "grad_norm": 0.00016786152264103293,
      "learning_rate": 3.7906666666666665e-07,
      "logits/chosen": -1.9684524536132812,
      "logits/rejected": -3.84256649017334,
      "logps/chosen": -199.7869873046875,
      "logps/rejected": -242.29788208007812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9462547302246094,
      "rewards/margins": 14.484857559204102,
      "rewards/rejected": -10.538602828979492,
      "step": 4658
    },
    {
      "epoch": 1.8636,
      "grad_norm": 0.1972339004278183,
      "learning_rate": 3.7893333333333334e-07,
      "logits/chosen": -2.0478687286376953,
      "logits/rejected": -3.361351490020752,
      "logps/chosen": -165.78265380859375,
      "logps/rejected": -189.15261840820312,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6964080333709717,
      "rewards/margins": 9.597216606140137,
      "rewards/rejected": -7.900808334350586,
      "step": 4659
    },
    {
      "epoch": 1.8639999999999999,
      "grad_norm": 0.011435105465352535,
      "learning_rate": 3.7880000000000003e-07,
      "logits/chosen": -2.206847667694092,
      "logits/rejected": -2.808436393737793,
      "logps/chosen": -171.64137268066406,
      "logps/rejected": -198.21141052246094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6984741687774658,
      "rewards/margins": 10.493335723876953,
      "rewards/rejected": -8.79486083984375,
      "step": 4660
    },
    {
      "epoch": 1.8643999999999998,
      "grad_norm": 0.004294657148420811,
      "learning_rate": 3.786666666666666e-07,
      "logits/chosen": -1.7346694469451904,
      "logits/rejected": -2.8047099113464355,
      "logps/chosen": -84.78675842285156,
      "logps/rejected": -188.42642211914062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9511032104492188,
      "rewards/margins": 10.74658489227295,
      "rewards/rejected": -6.7954816818237305,
      "step": 4661
    },
    {
      "epoch": 1.8648,
      "grad_norm": 0.017471425235271454,
      "learning_rate": 3.785333333333333e-07,
      "logits/chosen": -2.3536553382873535,
      "logits/rejected": -3.252079963684082,
      "logps/chosen": -152.5651397705078,
      "logps/rejected": -220.9285888671875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3644654750823975,
      "rewards/margins": 10.967510223388672,
      "rewards/rejected": -7.603045463562012,
      "step": 4662
    },
    {
      "epoch": 1.8652,
      "grad_norm": 0.0012867465848103166,
      "learning_rate": 3.784e-07,
      "logits/chosen": -1.9319992065429688,
      "logits/rejected": -3.581906318664551,
      "logps/chosen": -109.59893798828125,
      "logps/rejected": -189.65625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.222132444381714,
      "rewards/margins": 11.960742950439453,
      "rewards/rejected": -9.738611221313477,
      "step": 4663
    },
    {
      "epoch": 1.8656000000000001,
      "grad_norm": 1.1875606775283813,
      "learning_rate": 3.7826666666666664e-07,
      "logits/chosen": -2.848888635635376,
      "logits/rejected": -3.342398166656494,
      "logps/chosen": -199.7645263671875,
      "logps/rejected": -207.92189025878906,
      "loss": 0.007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9584861993789673,
      "rewards/margins": 8.391490936279297,
      "rewards/rejected": -7.433004379272461,
      "step": 4664
    },
    {
      "epoch": 1.866,
      "grad_norm": 0.06364158540964127,
      "learning_rate": 3.781333333333333e-07,
      "logits/chosen": -1.9725017547607422,
      "logits/rejected": -2.648909568786621,
      "logps/chosen": -167.11663818359375,
      "logps/rejected": -183.38307189941406,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9856423139572144,
      "rewards/margins": 9.905488967895508,
      "rewards/rejected": -8.919846534729004,
      "step": 4665
    },
    {
      "epoch": 1.8664,
      "grad_norm": 0.0006269972072914243,
      "learning_rate": 3.7799999999999997e-07,
      "logits/chosen": -1.941284418106079,
      "logits/rejected": -3.9748990535736084,
      "logps/chosen": -82.43124389648438,
      "logps/rejected": -218.79730224609375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1581125259399414,
      "rewards/margins": 14.65003776550293,
      "rewards/rejected": -11.491926193237305,
      "step": 4666
    },
    {
      "epoch": 1.8668,
      "grad_norm": 0.0014860500814393163,
      "learning_rate": 3.7786666666666666e-07,
      "logits/chosen": -2.6793594360351562,
      "logits/rejected": -2.977259635925293,
      "logps/chosen": -194.39910888671875,
      "logps/rejected": -280.0643615722656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.658538818359375,
      "rewards/margins": 11.652837753295898,
      "rewards/rejected": -8.994298934936523,
      "step": 4667
    },
    {
      "epoch": 1.8672,
      "grad_norm": 0.0010970884468406439,
      "learning_rate": 3.777333333333333e-07,
      "logits/chosen": -2.2432312965393066,
      "logits/rejected": -3.302403450012207,
      "logps/chosen": -222.7188720703125,
      "logps/rejected": -190.326171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 5.579188823699951,
      "rewards/margins": 14.599943161010742,
      "rewards/rejected": -9.020753860473633,
      "step": 4668
    },
    {
      "epoch": 1.8676,
      "grad_norm": 0.0059356689453125,
      "learning_rate": 3.776e-07,
      "logits/chosen": -2.0171689987182617,
      "logits/rejected": -3.529613494873047,
      "logps/chosen": -120.54135131835938,
      "logps/rejected": -212.65744018554688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.394125372171402,
      "rewards/margins": 11.352055549621582,
      "rewards/rejected": -10.957929611206055,
      "step": 4669
    },
    {
      "epoch": 1.8679999999999999,
      "grad_norm": 0.0008923870627768338,
      "learning_rate": 3.7746666666666663e-07,
      "logits/chosen": -1.9228391647338867,
      "logits/rejected": -3.5004427433013916,
      "logps/chosen": -90.2130355834961,
      "logps/rejected": -186.7288055419922,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3485374450683594,
      "rewards/margins": 12.276605606079102,
      "rewards/rejected": -8.928068161010742,
      "step": 4670
    },
    {
      "epoch": 1.8683999999999998,
      "grad_norm": 8.743072248762473e-05,
      "learning_rate": 3.773333333333333e-07,
      "logits/chosen": -2.2269370555877686,
      "logits/rejected": -3.2638602256774902,
      "logps/chosen": -92.1923599243164,
      "logps/rejected": -187.39576721191406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.624852180480957,
      "rewards/margins": 14.207880020141602,
      "rewards/rejected": -9.583027839660645,
      "step": 4671
    },
    {
      "epoch": 1.8688,
      "grad_norm": 0.01735122874379158,
      "learning_rate": 3.7719999999999996e-07,
      "logits/chosen": -2.270577907562256,
      "logits/rejected": -3.321702480316162,
      "logps/chosen": -150.31570434570312,
      "logps/rejected": -169.93112182617188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.285259962081909,
      "rewards/margins": 10.630226135253906,
      "rewards/rejected": -7.344966411590576,
      "step": 4672
    },
    {
      "epoch": 1.8692,
      "grad_norm": 0.00229649874381721,
      "learning_rate": 3.7706666666666665e-07,
      "logits/chosen": -2.0668652057647705,
      "logits/rejected": -3.121058464050293,
      "logps/chosen": -131.19659423828125,
      "logps/rejected": -199.48678588867188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.732892632484436,
      "rewards/margins": 12.067451477050781,
      "rewards/rejected": -10.334558486938477,
      "step": 4673
    },
    {
      "epoch": 1.8696000000000002,
      "grad_norm": 0.015464982949197292,
      "learning_rate": 3.7693333333333335e-07,
      "logits/chosen": -2.0532126426696777,
      "logits/rejected": -3.192302703857422,
      "logps/chosen": -145.32199096679688,
      "logps/rejected": -181.6270751953125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5018157958984375,
      "rewards/margins": 9.924135208129883,
      "rewards/rejected": -8.422319412231445,
      "step": 4674
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.01388750784099102,
      "learning_rate": 3.768e-07,
      "logits/chosen": -1.7634859085083008,
      "logits/rejected": -3.2555270195007324,
      "logps/chosen": -80.24113464355469,
      "logps/rejected": -171.08978271484375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9934239387512207,
      "rewards/margins": 8.941932678222656,
      "rewards/rejected": -6.948508262634277,
      "step": 4675
    },
    {
      "epoch": 1.8704,
      "grad_norm": 0.0012524346821010113,
      "learning_rate": 3.766666666666666e-07,
      "logits/chosen": -1.8863052129745483,
      "logits/rejected": -3.1679720878601074,
      "logps/chosen": -110.96220397949219,
      "logps/rejected": -171.59512329101562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7191498279571533,
      "rewards/margins": 11.818532943725586,
      "rewards/rejected": -9.099382400512695,
      "step": 4676
    },
    {
      "epoch": 1.8708,
      "grad_norm": 0.0034655146300792694,
      "learning_rate": 3.765333333333333e-07,
      "logits/chosen": -2.28985595703125,
      "logits/rejected": -3.0894601345062256,
      "logps/chosen": -110.75846862792969,
      "logps/rejected": -240.95362854003906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6076881885528564,
      "rewards/margins": 10.91887092590332,
      "rewards/rejected": -8.311182022094727,
      "step": 4677
    },
    {
      "epoch": 1.8712,
      "grad_norm": 0.20082734525203705,
      "learning_rate": 3.764e-07,
      "logits/chosen": -1.615623116493225,
      "logits/rejected": -3.2219104766845703,
      "logps/chosen": -102.80680847167969,
      "logps/rejected": -180.6363983154297,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5290252566337585,
      "rewards/margins": 8.69795036315918,
      "rewards/rejected": -8.168925285339355,
      "step": 4678
    },
    {
      "epoch": 1.8716,
      "grad_norm": 0.00018220306083094329,
      "learning_rate": 3.762666666666667e-07,
      "logits/chosen": -2.249011993408203,
      "logits/rejected": -3.0439112186431885,
      "logps/chosen": -117.95944213867188,
      "logps/rejected": -192.61422729492188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.546179294586182,
      "rewards/margins": 13.678709030151367,
      "rewards/rejected": -9.132530212402344,
      "step": 4679
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 0.05338972061872482,
      "learning_rate": 3.761333333333333e-07,
      "logits/chosen": -2.6474456787109375,
      "logits/rejected": -3.1322574615478516,
      "logps/chosen": -127.85005187988281,
      "logps/rejected": -183.6974334716797,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2324614524841309,
      "rewards/margins": 8.370335578918457,
      "rewards/rejected": -7.137874126434326,
      "step": 4680
    },
    {
      "epoch": 1.8723999999999998,
      "grad_norm": 7.261696737259626e-05,
      "learning_rate": 3.76e-07,
      "logits/chosen": -2.1366043090820312,
      "logits/rejected": -3.6117281913757324,
      "logps/chosen": -156.16793823242188,
      "logps/rejected": -216.83352661132812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.432509183883667,
      "rewards/margins": 14.950428009033203,
      "rewards/rejected": -11.517919540405273,
      "step": 4681
    },
    {
      "epoch": 1.8728,
      "grad_norm": 0.00079590012319386,
      "learning_rate": 3.7586666666666667e-07,
      "logits/chosen": -2.2006030082702637,
      "logits/rejected": -3.0696656703948975,
      "logps/chosen": -134.2884979248047,
      "logps/rejected": -191.59629821777344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.1673455238342285,
      "rewards/margins": 12.763508796691895,
      "rewards/rejected": -8.596162796020508,
      "step": 4682
    },
    {
      "epoch": 1.8732,
      "grad_norm": 0.0731176808476448,
      "learning_rate": 3.757333333333333e-07,
      "logits/chosen": -2.373720645904541,
      "logits/rejected": -3.2348387241363525,
      "logps/chosen": -116.4090576171875,
      "logps/rejected": -158.82675170898438,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.07760201394557953,
      "rewards/margins": 7.838305950164795,
      "rewards/rejected": -7.915907859802246,
      "step": 4683
    },
    {
      "epoch": 1.8736000000000002,
      "grad_norm": 0.03205694258213043,
      "learning_rate": 3.7559999999999995e-07,
      "logits/chosen": -1.9550631046295166,
      "logits/rejected": -3.1558027267456055,
      "logps/chosen": -98.49817657470703,
      "logps/rejected": -224.687255859375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.001079559326172,
      "rewards/margins": 10.889119148254395,
      "rewards/rejected": -7.888039588928223,
      "step": 4684
    },
    {
      "epoch": 1.874,
      "grad_norm": 0.018485968932509422,
      "learning_rate": 3.7546666666666664e-07,
      "logits/chosen": -2.1399683952331543,
      "logits/rejected": -3.355916738510132,
      "logps/chosen": -113.94798278808594,
      "logps/rejected": -189.89163208007812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.726811170578003,
      "rewards/margins": 9.752366065979004,
      "rewards/rejected": -8.025554656982422,
      "step": 4685
    },
    {
      "epoch": 1.8744,
      "grad_norm": 0.0018084676703438163,
      "learning_rate": 3.7533333333333333e-07,
      "logits/chosen": -2.0138304233551025,
      "logits/rejected": -3.9017043113708496,
      "logps/chosen": -106.10247039794922,
      "logps/rejected": -231.29672241210938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.159458875656128,
      "rewards/margins": 11.160970687866211,
      "rewards/rejected": -9.001511573791504,
      "step": 4686
    },
    {
      "epoch": 1.8748,
      "grad_norm": 0.006381402723491192,
      "learning_rate": 3.7519999999999997e-07,
      "logits/chosen": -1.6764464378356934,
      "logits/rejected": -2.8428049087524414,
      "logps/chosen": -121.28797912597656,
      "logps/rejected": -163.20533752441406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.008998870849609,
      "rewards/margins": 10.209728240966797,
      "rewards/rejected": -6.2007293701171875,
      "step": 4687
    },
    {
      "epoch": 1.8752,
      "grad_norm": 0.03207554295659065,
      "learning_rate": 3.7506666666666666e-07,
      "logits/chosen": -2.38706636428833,
      "logits/rejected": -2.4428606033325195,
      "logps/chosen": -121.80227661132812,
      "logps/rejected": -136.62889099121094,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.149930238723755,
      "rewards/margins": 8.584081649780273,
      "rewards/rejected": -6.434151649475098,
      "step": 4688
    },
    {
      "epoch": 1.8756,
      "grad_norm": 0.2311106026172638,
      "learning_rate": 3.749333333333333e-07,
      "logits/chosen": -2.360342502593994,
      "logits/rejected": -3.0282959938049316,
      "logps/chosen": -100.32161712646484,
      "logps/rejected": -150.69009399414062,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8457584977149963,
      "rewards/margins": 7.502923965454102,
      "rewards/rejected": -6.65716552734375,
      "step": 4689
    },
    {
      "epoch": 1.876,
      "grad_norm": 0.08747877925634384,
      "learning_rate": 3.748e-07,
      "logits/chosen": -1.913451910018921,
      "logits/rejected": -2.9969258308410645,
      "logps/chosen": -78.99386596679688,
      "logps/rejected": -134.7518310546875,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6534759998321533,
      "rewards/margins": 8.362537384033203,
      "rewards/rejected": -5.7090606689453125,
      "step": 4690
    },
    {
      "epoch": 1.8763999999999998,
      "grad_norm": 0.1255665272474289,
      "learning_rate": 3.7466666666666663e-07,
      "logits/chosen": -2.1845672130584717,
      "logits/rejected": -2.6889586448669434,
      "logps/chosen": -118.6534194946289,
      "logps/rejected": -165.25799560546875,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9001107215881348,
      "rewards/margins": 8.365499496459961,
      "rewards/rejected": -6.465389251708984,
      "step": 4691
    },
    {
      "epoch": 1.8768,
      "grad_norm": 0.10971123725175858,
      "learning_rate": 3.745333333333333e-07,
      "logits/chosen": -2.9441776275634766,
      "logits/rejected": -3.8927829265594482,
      "logps/chosen": -102.73912048339844,
      "logps/rejected": -155.74807739257812,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6273998022079468,
      "rewards/margins": 7.336887359619141,
      "rewards/rejected": -6.7094879150390625,
      "step": 4692
    },
    {
      "epoch": 1.8772,
      "grad_norm": 0.0014655147679150105,
      "learning_rate": 3.744e-07,
      "logits/chosen": -1.724517822265625,
      "logits/rejected": -3.158224105834961,
      "logps/chosen": -76.38105773925781,
      "logps/rejected": -163.3672637939453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8885068893432617,
      "rewards/margins": 11.38792610168457,
      "rewards/rejected": -8.499419212341309,
      "step": 4693
    },
    {
      "epoch": 1.8776000000000002,
      "grad_norm": 0.0722581222653389,
      "learning_rate": 3.7426666666666666e-07,
      "logits/chosen": -2.685028076171875,
      "logits/rejected": -3.449113368988037,
      "logps/chosen": -148.5384063720703,
      "logps/rejected": -163.94244384765625,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2509875297546387,
      "rewards/margins": 10.020172119140625,
      "rewards/rejected": -7.7691850662231445,
      "step": 4694
    },
    {
      "epoch": 1.8780000000000001,
      "grad_norm": 0.06024786829948425,
      "learning_rate": 3.741333333333333e-07,
      "logits/chosen": -2.2246694564819336,
      "logits/rejected": -2.904858112335205,
      "logps/chosen": -106.76443481445312,
      "logps/rejected": -120.20803833007812,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.048543930053711,
      "rewards/margins": 7.246554374694824,
      "rewards/rejected": -5.198010444641113,
      "step": 4695
    },
    {
      "epoch": 1.8784,
      "grad_norm": 0.0036156047135591507,
      "learning_rate": 3.74e-07,
      "logits/chosen": -2.6251044273376465,
      "logits/rejected": -3.3471622467041016,
      "logps/chosen": -133.44699096679688,
      "logps/rejected": -201.85247802734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0568480491638184,
      "rewards/margins": 11.396099090576172,
      "rewards/rejected": -9.339251518249512,
      "step": 4696
    },
    {
      "epoch": 1.8788,
      "grad_norm": 0.18903867900371552,
      "learning_rate": 3.738666666666667e-07,
      "logits/chosen": -2.3524746894836426,
      "logits/rejected": -3.521712303161621,
      "logps/chosen": -149.87283325195312,
      "logps/rejected": -171.0551300048828,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6667167544364929,
      "rewards/margins": 8.13009262084961,
      "rewards/rejected": -7.463376045227051,
      "step": 4697
    },
    {
      "epoch": 1.8792,
      "grad_norm": 1.4170085191726685,
      "learning_rate": 3.7373333333333327e-07,
      "logits/chosen": -2.653956651687622,
      "logits/rejected": -2.645765781402588,
      "logps/chosen": -168.76296997070312,
      "logps/rejected": -154.01927185058594,
      "loss": 0.0084,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5704255104064941,
      "rewards/margins": 6.387237548828125,
      "rewards/rejected": -6.957663059234619,
      "step": 4698
    },
    {
      "epoch": 1.8796,
      "grad_norm": 0.0027311574667692184,
      "learning_rate": 3.7359999999999996e-07,
      "logits/chosen": -2.5595974922180176,
      "logits/rejected": -3.4789390563964844,
      "logps/chosen": -119.14385223388672,
      "logps/rejected": -173.68104553222656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7634376287460327,
      "rewards/margins": 10.870030403137207,
      "rewards/rejected": -9.106593132019043,
      "step": 4699
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.004820480477064848,
      "learning_rate": 3.7346666666666665e-07,
      "logits/chosen": -1.9932466745376587,
      "logits/rejected": -3.1636300086975098,
      "logps/chosen": -102.5864486694336,
      "logps/rejected": -170.49349975585938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1940884590148926,
      "rewards/margins": 10.143798828125,
      "rewards/rejected": -7.949710845947266,
      "step": 4700
    },
    {
      "epoch": 1.8803999999999998,
      "grad_norm": 0.05188233032822609,
      "learning_rate": 3.7333333333333334e-07,
      "logits/chosen": -2.1210250854492188,
      "logits/rejected": -3.2304296493530273,
      "logps/chosen": -86.47151184082031,
      "logps/rejected": -161.146728515625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.438534140586853,
      "rewards/margins": 8.224685668945312,
      "rewards/rejected": -6.786150932312012,
      "step": 4701
    },
    {
      "epoch": 1.8808,
      "grad_norm": 0.06858949363231659,
      "learning_rate": 3.732e-07,
      "logits/chosen": -2.44769287109375,
      "logits/rejected": -3.0259523391723633,
      "logps/chosen": -115.59619903564453,
      "logps/rejected": -143.24032592773438,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9963600635528564,
      "rewards/margins": 8.753015518188477,
      "rewards/rejected": -6.756655693054199,
      "step": 4702
    },
    {
      "epoch": 1.8812,
      "grad_norm": 0.016319502145051956,
      "learning_rate": 3.730666666666666e-07,
      "logits/chosen": -2.4187159538269043,
      "logits/rejected": -2.990966796875,
      "logps/chosen": -141.13296508789062,
      "logps/rejected": -194.11383056640625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3604774475097656,
      "rewards/margins": 8.734151840209961,
      "rewards/rejected": -8.373674392700195,
      "step": 4703
    },
    {
      "epoch": 1.8816000000000002,
      "grad_norm": 0.0018529657972976565,
      "learning_rate": 3.729333333333333e-07,
      "logits/chosen": -1.967127799987793,
      "logits/rejected": -3.140944480895996,
      "logps/chosen": -104.0243911743164,
      "logps/rejected": -228.64962768554688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9914345741271973,
      "rewards/margins": 11.462224960327148,
      "rewards/rejected": -8.47079086303711,
      "step": 4704
    },
    {
      "epoch": 1.8820000000000001,
      "grad_norm": 0.0786546915769577,
      "learning_rate": 3.728e-07,
      "logits/chosen": -2.331139087677002,
      "logits/rejected": -3.3145618438720703,
      "logps/chosen": -103.70130920410156,
      "logps/rejected": -181.28323364257812,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2282772064208984,
      "rewards/margins": 8.926437377929688,
      "rewards/rejected": -7.698159694671631,
      "step": 4705
    },
    {
      "epoch": 1.8824,
      "grad_norm": 0.0012524188496172428,
      "learning_rate": 3.7266666666666664e-07,
      "logits/chosen": -2.1432952880859375,
      "logits/rejected": -3.0158276557922363,
      "logps/chosen": -75.49980926513672,
      "logps/rejected": -196.75723266601562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.239820957183838,
      "rewards/margins": 12.545146942138672,
      "rewards/rejected": -9.305326461791992,
      "step": 4706
    },
    {
      "epoch": 1.8828,
      "grad_norm": 0.00030353397596627474,
      "learning_rate": 3.7253333333333333e-07,
      "logits/chosen": -2.4158778190612793,
      "logits/rejected": -3.622528553009033,
      "logps/chosen": -129.52438354492188,
      "logps/rejected": -232.44570922851562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.3016533851623535,
      "rewards/margins": 13.516495704650879,
      "rewards/rejected": -9.214842796325684,
      "step": 4707
    },
    {
      "epoch": 1.8832,
      "grad_norm": 6.617365215788595e-06,
      "learning_rate": 3.7239999999999997e-07,
      "logits/chosen": -2.1955950260162354,
      "logits/rejected": -3.6520509719848633,
      "logps/chosen": -171.47927856445312,
      "logps/rejected": -275.4295959472656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.319428443908691,
      "rewards/margins": 17.257598876953125,
      "rewards/rejected": -12.93817138671875,
      "step": 4708
    },
    {
      "epoch": 1.8836,
      "grad_norm": 0.237908735871315,
      "learning_rate": 3.7226666666666666e-07,
      "logits/chosen": -2.701277732849121,
      "logits/rejected": -3.750147819519043,
      "logps/chosen": -147.8490447998047,
      "logps/rejected": -231.23699951171875,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7641063332557678,
      "rewards/margins": 10.020833969116211,
      "rewards/rejected": -9.256728172302246,
      "step": 4709
    },
    {
      "epoch": 1.884,
      "grad_norm": 0.052304916083812714,
      "learning_rate": 3.721333333333333e-07,
      "logits/chosen": -1.9703073501586914,
      "logits/rejected": -3.292234420776367,
      "logps/chosen": -109.89371490478516,
      "logps/rejected": -171.04583740234375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6140990853309631,
      "rewards/margins": 8.938665390014648,
      "rewards/rejected": -8.324565887451172,
      "step": 4710
    },
    {
      "epoch": 1.8843999999999999,
      "grad_norm": 0.005729713011533022,
      "learning_rate": 3.72e-07,
      "logits/chosen": -1.8927857875823975,
      "logits/rejected": -3.6385490894317627,
      "logps/chosen": -199.2517852783203,
      "logps/rejected": -201.59463500976562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3035271167755127,
      "rewards/margins": 11.570391654968262,
      "rewards/rejected": -9.266864776611328,
      "step": 4711
    },
    {
      "epoch": 1.8848,
      "grad_norm": 0.25564318895339966,
      "learning_rate": 3.718666666666667e-07,
      "logits/chosen": -2.6166062355041504,
      "logits/rejected": -3.110125780105591,
      "logps/chosen": -110.40890502929688,
      "logps/rejected": -175.68865966796875,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3097022771835327,
      "rewards/margins": 9.098678588867188,
      "rewards/rejected": -7.788976192474365,
      "step": 4712
    },
    {
      "epoch": 1.8852,
      "grad_norm": 0.00018028078193310648,
      "learning_rate": 3.7173333333333333e-07,
      "logits/chosen": -2.001802682876587,
      "logits/rejected": -3.5967490673065186,
      "logps/chosen": -133.82150268554688,
      "logps/rejected": -214.6400146484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4922561645507812,
      "rewards/margins": 14.294179916381836,
      "rewards/rejected": -10.801923751831055,
      "step": 4713
    },
    {
      "epoch": 1.8856000000000002,
      "grad_norm": 0.24189497530460358,
      "learning_rate": 3.7159999999999997e-07,
      "logits/chosen": -2.7896575927734375,
      "logits/rejected": -3.5221707820892334,
      "logps/chosen": -192.27076721191406,
      "logps/rejected": -180.27114868164062,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.22747540473938,
      "rewards/margins": 8.429194450378418,
      "rewards/rejected": -6.201718807220459,
      "step": 4714
    },
    {
      "epoch": 1.8860000000000001,
      "grad_norm": 0.0363178513944149,
      "learning_rate": 3.7146666666666666e-07,
      "logits/chosen": -2.1934256553649902,
      "logits/rejected": -3.7152979373931885,
      "logps/chosen": -141.1128692626953,
      "logps/rejected": -174.5626220703125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.20638732612133026,
      "rewards/margins": 7.906728267669678,
      "rewards/rejected": -8.113115310668945,
      "step": 4715
    },
    {
      "epoch": 1.8864,
      "grad_norm": 0.004719345830380917,
      "learning_rate": 3.7133333333333335e-07,
      "logits/chosen": -2.1473188400268555,
      "logits/rejected": -3.1226444244384766,
      "logps/chosen": -112.86540222167969,
      "logps/rejected": -188.89564514160156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.285280227661133,
      "rewards/margins": 11.625948905944824,
      "rewards/rejected": -9.340668678283691,
      "step": 4716
    },
    {
      "epoch": 1.8868,
      "grad_norm": 0.5657097697257996,
      "learning_rate": 3.7119999999999994e-07,
      "logits/chosen": -2.1760478019714355,
      "logits/rejected": -3.352814197540283,
      "logps/chosen": -158.9661865234375,
      "logps/rejected": -173.56478881835938,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.71908038854599,
      "rewards/margins": 7.642006874084473,
      "rewards/rejected": -6.922926425933838,
      "step": 4717
    },
    {
      "epoch": 1.8872,
      "grad_norm": 0.0001148046285379678,
      "learning_rate": 3.7106666666666663e-07,
      "logits/chosen": -2.5571060180664062,
      "logits/rejected": -4.116583824157715,
      "logps/chosen": -153.45938110351562,
      "logps/rejected": -240.1860809326172,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.301236629486084,
      "rewards/margins": 14.274484634399414,
      "rewards/rejected": -9.973247528076172,
      "step": 4718
    },
    {
      "epoch": 1.8876,
      "grad_norm": 0.05707019940018654,
      "learning_rate": 3.709333333333333e-07,
      "logits/chosen": -2.221837282180786,
      "logits/rejected": -3.376436948776245,
      "logps/chosen": -233.86468505859375,
      "logps/rejected": -187.1882781982422,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6825988292694092,
      "rewards/margins": 9.878355979919434,
      "rewards/rejected": -8.195756912231445,
      "step": 4719
    },
    {
      "epoch": 1.888,
      "grad_norm": 0.0011281550396233797,
      "learning_rate": 3.708e-07,
      "logits/chosen": -1.930027961730957,
      "logits/rejected": -3.1090927124023438,
      "logps/chosen": -136.80886840820312,
      "logps/rejected": -202.14431762695312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.509565830230713,
      "rewards/margins": 12.412010192871094,
      "rewards/rejected": -9.902443885803223,
      "step": 4720
    },
    {
      "epoch": 1.8883999999999999,
      "grad_norm": 0.08474134653806686,
      "learning_rate": 3.7066666666666665e-07,
      "logits/chosen": -2.1711277961730957,
      "logits/rejected": -3.2051138877868652,
      "logps/chosen": -136.9520263671875,
      "logps/rejected": -179.23080444335938,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0091263055801392,
      "rewards/margins": 10.367158889770508,
      "rewards/rejected": -9.3580322265625,
      "step": 4721
    },
    {
      "epoch": 1.8888,
      "grad_norm": 0.0021824496798217297,
      "learning_rate": 3.705333333333333e-07,
      "logits/chosen": -2.312190532684326,
      "logits/rejected": -3.412743091583252,
      "logps/chosen": -126.43838500976562,
      "logps/rejected": -158.4513702392578,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6345109939575195,
      "rewards/margins": 11.23503303527832,
      "rewards/rejected": -7.600522518157959,
      "step": 4722
    },
    {
      "epoch": 1.8892,
      "grad_norm": 0.0010467831743881106,
      "learning_rate": 3.704e-07,
      "logits/chosen": -2.41538667678833,
      "logits/rejected": -3.0918402671813965,
      "logps/chosen": -142.1925506591797,
      "logps/rejected": -209.4625244140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.023322105407715,
      "rewards/margins": 11.6765718460083,
      "rewards/rejected": -7.653249740600586,
      "step": 4723
    },
    {
      "epoch": 1.8896,
      "grad_norm": 0.03488575667142868,
      "learning_rate": 3.7026666666666667e-07,
      "logits/chosen": -2.430675506591797,
      "logits/rejected": -3.5007758140563965,
      "logps/chosen": -146.4283905029297,
      "logps/rejected": -185.09024047851562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6229263544082642,
      "rewards/margins": 10.333146095275879,
      "rewards/rejected": -8.710219383239746,
      "step": 4724
    },
    {
      "epoch": 1.8900000000000001,
      "grad_norm": 0.026979666203260422,
      "learning_rate": 3.701333333333333e-07,
      "logits/chosen": -2.151813268661499,
      "logits/rejected": -3.736754894256592,
      "logps/chosen": -95.11090087890625,
      "logps/rejected": -182.3270263671875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.171143054962158,
      "rewards/margins": 10.196127891540527,
      "rewards/rejected": -8.024984359741211,
      "step": 4725
    },
    {
      "epoch": 1.8904,
      "grad_norm": 0.012422238476574421,
      "learning_rate": 3.7e-07,
      "logits/chosen": -2.210554599761963,
      "logits/rejected": -3.140895128250122,
      "logps/chosen": -151.20443725585938,
      "logps/rejected": -191.28750610351562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8257527351379395,
      "rewards/margins": 10.825462341308594,
      "rewards/rejected": -7.9997100830078125,
      "step": 4726
    },
    {
      "epoch": 1.8908,
      "grad_norm": 0.010684511624276638,
      "learning_rate": 3.6986666666666664e-07,
      "logits/chosen": -1.9515447616577148,
      "logits/rejected": -3.295179843902588,
      "logps/chosen": -125.0285873413086,
      "logps/rejected": -169.60623168945312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3993425369262695,
      "rewards/margins": 9.643645286560059,
      "rewards/rejected": -7.244302749633789,
      "step": 4727
    },
    {
      "epoch": 1.8912,
      "grad_norm": 0.026593998074531555,
      "learning_rate": 3.6973333333333334e-07,
      "logits/chosen": -1.9885075092315674,
      "logits/rejected": -2.9069786071777344,
      "logps/chosen": -122.54049682617188,
      "logps/rejected": -149.55445861816406,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.573272705078125,
      "rewards/margins": 9.394132614135742,
      "rewards/rejected": -7.820860862731934,
      "step": 4728
    },
    {
      "epoch": 1.8916,
      "grad_norm": 0.00861338246613741,
      "learning_rate": 3.696e-07,
      "logits/chosen": -2.243589401245117,
      "logits/rejected": -3.000802993774414,
      "logps/chosen": -97.32655334472656,
      "logps/rejected": -209.542236328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3916802406311035,
      "rewards/margins": 10.77096939086914,
      "rewards/rejected": -8.379289627075195,
      "step": 4729
    },
    {
      "epoch": 1.892,
      "grad_norm": 0.016709161922335625,
      "learning_rate": 3.6946666666666667e-07,
      "logits/chosen": -2.5532054901123047,
      "logits/rejected": -3.469600200653076,
      "logps/chosen": -128.6014404296875,
      "logps/rejected": -207.58969116210938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3697715997695923,
      "rewards/margins": 8.852006912231445,
      "rewards/rejected": -8.482234954833984,
      "step": 4730
    },
    {
      "epoch": 1.8923999999999999,
      "grad_norm": 0.03620846942067146,
      "learning_rate": 3.693333333333333e-07,
      "logits/chosen": -2.2742795944213867,
      "logits/rejected": -3.750485897064209,
      "logps/chosen": -202.6805419921875,
      "logps/rejected": -172.75363159179688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6253211498260498,
      "rewards/margins": 9.09450626373291,
      "rewards/rejected": -7.469184875488281,
      "step": 4731
    },
    {
      "epoch": 1.8928,
      "grad_norm": 0.006075488403439522,
      "learning_rate": 3.6919999999999994e-07,
      "logits/chosen": -2.2739996910095215,
      "logits/rejected": -3.04677677154541,
      "logps/chosen": -150.8477783203125,
      "logps/rejected": -190.66281127929688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3936840295791626,
      "rewards/margins": 10.424028396606445,
      "rewards/rejected": -9.03034496307373,
      "step": 4732
    },
    {
      "epoch": 1.8932,
      "grad_norm": 0.15731361508369446,
      "learning_rate": 3.6906666666666664e-07,
      "logits/chosen": -1.835636854171753,
      "logits/rejected": -3.021634340286255,
      "logps/chosen": -134.79119873046875,
      "logps/rejected": -161.26048278808594,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5308799743652344,
      "rewards/margins": 7.510865211486816,
      "rewards/rejected": -8.041746139526367,
      "step": 4733
    },
    {
      "epoch": 1.8936,
      "grad_norm": 0.06222948059439659,
      "learning_rate": 3.6893333333333333e-07,
      "logits/chosen": -2.0771243572235107,
      "logits/rejected": -3.1577868461608887,
      "logps/chosen": -138.2865447998047,
      "logps/rejected": -163.87667846679688,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5898838043212891,
      "rewards/margins": 7.8670806884765625,
      "rewards/rejected": -7.277196884155273,
      "step": 4734
    },
    {
      "epoch": 1.8940000000000001,
      "grad_norm": 0.12597686052322388,
      "learning_rate": 3.688e-07,
      "logits/chosen": -2.2794437408447266,
      "logits/rejected": -3.3778302669525146,
      "logps/chosen": -113.94314575195312,
      "logps/rejected": -164.95529174804688,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8783737421035767,
      "rewards/margins": 8.702519416809082,
      "rewards/rejected": -7.824145317077637,
      "step": 4735
    },
    {
      "epoch": 1.8944,
      "grad_norm": 0.0003632341977208853,
      "learning_rate": 3.686666666666666e-07,
      "logits/chosen": -2.650376081466675,
      "logits/rejected": -3.5322937965393066,
      "logps/chosen": -166.043701171875,
      "logps/rejected": -191.40716552734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.087244033813477,
      "rewards/margins": 12.8275146484375,
      "rewards/rejected": -8.740270614624023,
      "step": 4736
    },
    {
      "epoch": 1.8948,
      "grad_norm": 0.0044201998971402645,
      "learning_rate": 3.685333333333333e-07,
      "logits/chosen": -2.0839757919311523,
      "logits/rejected": -3.4310972690582275,
      "logps/chosen": -83.08598327636719,
      "logps/rejected": -172.00807189941406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.309786319732666,
      "rewards/margins": 10.532671928405762,
      "rewards/rejected": -8.222886085510254,
      "step": 4737
    },
    {
      "epoch": 1.8952,
      "grad_norm": 0.008098180405795574,
      "learning_rate": 3.684e-07,
      "logits/chosen": -2.042786121368408,
      "logits/rejected": -3.652980089187622,
      "logps/chosen": -128.26217651367188,
      "logps/rejected": -193.94265747070312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4256644248962402,
      "rewards/margins": 11.046812057495117,
      "rewards/rejected": -8.621147155761719,
      "step": 4738
    },
    {
      "epoch": 1.8956,
      "grad_norm": 0.0048514013178646564,
      "learning_rate": 3.682666666666667e-07,
      "logits/chosen": -2.211284875869751,
      "logits/rejected": -3.5618886947631836,
      "logps/chosen": -128.3852996826172,
      "logps/rejected": -185.30117797851562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9167938232421875,
      "rewards/margins": 11.353178024291992,
      "rewards/rejected": -10.436384201049805,
      "step": 4739
    },
    {
      "epoch": 1.896,
      "grad_norm": 8.490549087524414,
      "learning_rate": 3.681333333333333e-07,
      "logits/chosen": -1.9117708206176758,
      "logits/rejected": -2.563887357711792,
      "logps/chosen": -115.29251098632812,
      "logps/rejected": -115.5483627319336,
      "loss": 0.0889,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10989990830421448,
      "rewards/margins": 4.957369327545166,
      "rewards/rejected": -4.847469329833984,
      "step": 4740
    },
    {
      "epoch": 1.8963999999999999,
      "grad_norm": 0.0074208760634064674,
      "learning_rate": 3.6799999999999996e-07,
      "logits/chosen": -1.7014861106872559,
      "logits/rejected": -3.482985019683838,
      "logps/chosen": -169.59152221679688,
      "logps/rejected": -195.7945098876953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1122184991836548,
      "rewards/margins": 10.573261260986328,
      "rewards/rejected": -9.461043357849121,
      "step": 4741
    },
    {
      "epoch": 1.8968,
      "grad_norm": 0.008056443184614182,
      "learning_rate": 3.6786666666666665e-07,
      "logits/chosen": -2.4642412662506104,
      "logits/rejected": -3.653813362121582,
      "logps/chosen": -181.78684997558594,
      "logps/rejected": -297.3887939453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0306243896484375,
      "rewards/margins": 11.418313980102539,
      "rewards/rejected": -9.387689590454102,
      "step": 4742
    },
    {
      "epoch": 1.8972,
      "grad_norm": 0.010873701423406601,
      "learning_rate": 3.6773333333333334e-07,
      "logits/chosen": -2.4528722763061523,
      "logits/rejected": -3.3771207332611084,
      "logps/chosen": -129.89955139160156,
      "logps/rejected": -181.64276123046875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8472237586975098,
      "rewards/margins": 10.488211631774902,
      "rewards/rejected": -8.640987396240234,
      "step": 4743
    },
    {
      "epoch": 1.8976,
      "grad_norm": 0.05032036826014519,
      "learning_rate": 3.676e-07,
      "logits/chosen": -2.424522876739502,
      "logits/rejected": -3.0178627967834473,
      "logps/chosen": -170.02809143066406,
      "logps/rejected": -179.17935180664062,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9805054664611816,
      "rewards/margins": 10.594198226928711,
      "rewards/rejected": -8.613693237304688,
      "step": 4744
    },
    {
      "epoch": 1.8980000000000001,
      "grad_norm": 0.3574758470058441,
      "learning_rate": 3.674666666666666e-07,
      "logits/chosen": -1.5976390838623047,
      "logits/rejected": -3.626295566558838,
      "logps/chosen": -114.56770324707031,
      "logps/rejected": -180.22366333007812,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1216599941253662,
      "rewards/margins": 8.50433349609375,
      "rewards/rejected": -7.382673263549805,
      "step": 4745
    },
    {
      "epoch": 1.8984,
      "grad_norm": 0.017321335151791573,
      "learning_rate": 3.673333333333333e-07,
      "logits/chosen": -1.9248945713043213,
      "logits/rejected": -3.404947280883789,
      "logps/chosen": -116.80289459228516,
      "logps/rejected": -267.8814697265625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.46334803104400635,
      "rewards/margins": 11.364191055297852,
      "rewards/rejected": -10.900842666625977,
      "step": 4746
    },
    {
      "epoch": 1.8988,
      "grad_norm": 0.007099013309925795,
      "learning_rate": 3.672e-07,
      "logits/chosen": -2.2938060760498047,
      "logits/rejected": -2.995129108428955,
      "logps/chosen": -201.46627807617188,
      "logps/rejected": -190.29270935058594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.760089159011841,
      "rewards/margins": 11.866630554199219,
      "rewards/rejected": -9.106541633605957,
      "step": 4747
    },
    {
      "epoch": 1.8992,
      "grad_norm": 0.01120687834918499,
      "learning_rate": 3.6706666666666664e-07,
      "logits/chosen": -1.778548002243042,
      "logits/rejected": -3.419224262237549,
      "logps/chosen": -104.44866180419922,
      "logps/rejected": -179.34991455078125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0873574018478394,
      "rewards/margins": 9.185731887817383,
      "rewards/rejected": -8.098374366760254,
      "step": 4748
    },
    {
      "epoch": 1.8996,
      "grad_norm": 0.20717628300189972,
      "learning_rate": 3.6693333333333334e-07,
      "logits/chosen": -2.1735916137695312,
      "logits/rejected": -3.2183876037597656,
      "logps/chosen": -179.09237670898438,
      "logps/rejected": -161.86563110351562,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7463455200195312,
      "rewards/margins": 6.4393463134765625,
      "rewards/rejected": -7.185691833496094,
      "step": 4749
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.01390666700899601,
      "learning_rate": 3.668e-07,
      "logits/chosen": -2.3054006099700928,
      "logits/rejected": -3.9822654724121094,
      "logps/chosen": -96.03118896484375,
      "logps/rejected": -243.12173461914062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7294303774833679,
      "rewards/margins": 9.545228004455566,
      "rewards/rejected": -8.815797805786133,
      "step": 4750
    },
    {
      "epoch": 1.9003999999999999,
      "grad_norm": 0.39024049043655396,
      "learning_rate": 3.666666666666666e-07,
      "logits/chosen": -2.6047749519348145,
      "logits/rejected": -2.761298656463623,
      "logps/chosen": -142.16842651367188,
      "logps/rejected": -152.8614044189453,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7094581127166748,
      "rewards/margins": 5.631140232086182,
      "rewards/rejected": -6.340598106384277,
      "step": 4751
    },
    {
      "epoch": 1.9008,
      "grad_norm": 0.042023878544569016,
      "learning_rate": 3.665333333333333e-07,
      "logits/chosen": -2.9946374893188477,
      "logits/rejected": -3.4007461071014404,
      "logps/chosen": -214.83384704589844,
      "logps/rejected": -208.29132080078125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.009661853313446045,
      "rewards/margins": 7.991097927093506,
      "rewards/rejected": -8.000760078430176,
      "step": 4752
    },
    {
      "epoch": 1.9012,
      "grad_norm": 0.03935421258211136,
      "learning_rate": 3.664e-07,
      "logits/chosen": -2.3634142875671387,
      "logits/rejected": -3.4909558296203613,
      "logps/chosen": -187.68470764160156,
      "logps/rejected": -206.43634033203125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5179111361503601,
      "rewards/margins": 8.803890228271484,
      "rewards/rejected": -8.285979270935059,
      "step": 4753
    },
    {
      "epoch": 1.9016,
      "grad_norm": 0.01780359447002411,
      "learning_rate": 3.662666666666667e-07,
      "logits/chosen": -2.3737659454345703,
      "logits/rejected": -2.8980541229248047,
      "logps/chosen": -101.829833984375,
      "logps/rejected": -147.18479919433594,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.875924825668335,
      "rewards/margins": 8.527054786682129,
      "rewards/rejected": -6.651130199432373,
      "step": 4754
    },
    {
      "epoch": 1.9020000000000001,
      "grad_norm": 0.0006061281310394406,
      "learning_rate": 3.661333333333333e-07,
      "logits/chosen": -2.156432867050171,
      "logits/rejected": -3.352623462677002,
      "logps/chosen": -113.88074493408203,
      "logps/rejected": -222.60977172851562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.254603862762451,
      "rewards/margins": 14.217450141906738,
      "rewards/rejected": -9.962846755981445,
      "step": 4755
    },
    {
      "epoch": 1.9024,
      "grad_norm": 0.0320030115544796,
      "learning_rate": 3.6599999999999997e-07,
      "logits/chosen": -1.6269237995147705,
      "logits/rejected": -3.5836381912231445,
      "logps/chosen": -128.32040405273438,
      "logps/rejected": -198.79251098632812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1725926399230957,
      "rewards/margins": 9.86905288696289,
      "rewards/rejected": -8.696459770202637,
      "step": 4756
    },
    {
      "epoch": 1.9028,
      "grad_norm": 0.007043734658509493,
      "learning_rate": 3.6586666666666666e-07,
      "logits/chosen": -2.2835447788238525,
      "logits/rejected": -3.0778286457061768,
      "logps/chosen": -135.52432250976562,
      "logps/rejected": -205.54811096191406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.026538074016571045,
      "rewards/margins": 9.638008117675781,
      "rewards/rejected": -9.664546012878418,
      "step": 4757
    },
    {
      "epoch": 1.9032,
      "grad_norm": 0.018646301701664925,
      "learning_rate": 3.6573333333333335e-07,
      "logits/chosen": -2.682842254638672,
      "logits/rejected": -3.175723075866699,
      "logps/chosen": -130.57005310058594,
      "logps/rejected": -165.59927368164062,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8104736804962158,
      "rewards/margins": 8.638216972351074,
      "rewards/rejected": -6.8277435302734375,
      "step": 4758
    },
    {
      "epoch": 1.9036,
      "grad_norm": 0.058137696236371994,
      "learning_rate": 3.6559999999999994e-07,
      "logits/chosen": -2.284701108932495,
      "logits/rejected": -3.6222925186157227,
      "logps/chosen": -131.3843231201172,
      "logps/rejected": -188.94544982910156,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0719010829925537,
      "rewards/margins": 10.184536933898926,
      "rewards/rejected": -8.112635612487793,
      "step": 4759
    },
    {
      "epoch": 1.904,
      "grad_norm": 0.004152997396886349,
      "learning_rate": 3.6546666666666663e-07,
      "logits/chosen": -2.3949427604675293,
      "logits/rejected": -3.479678153991699,
      "logps/chosen": -188.90274047851562,
      "logps/rejected": -179.08218383789062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.720787525177002,
      "rewards/margins": 11.165273666381836,
      "rewards/rejected": -7.444486618041992,
      "step": 4760
    },
    {
      "epoch": 1.9043999999999999,
      "grad_norm": 0.004440487362444401,
      "learning_rate": 3.653333333333333e-07,
      "logits/chosen": -2.4757256507873535,
      "logits/rejected": -3.591973304748535,
      "logps/chosen": -177.08670043945312,
      "logps/rejected": -243.20555114746094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1010291576385498,
      "rewards/margins": 11.771577835083008,
      "rewards/rejected": -11.670548439025879,
      "step": 4761
    },
    {
      "epoch": 1.9048,
      "grad_norm": 0.02847752906382084,
      "learning_rate": 3.652e-07,
      "logits/chosen": -2.4121456146240234,
      "logits/rejected": -3.2397541999816895,
      "logps/chosen": -201.5371551513672,
      "logps/rejected": -182.01461791992188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2924712896347046,
      "rewards/margins": 8.643319129943848,
      "rewards/rejected": -8.350848197937012,
      "step": 4762
    },
    {
      "epoch": 1.9052,
      "grad_norm": 0.05568840354681015,
      "learning_rate": 3.6506666666666665e-07,
      "logits/chosen": -2.0437839031219482,
      "logits/rejected": -2.9023830890655518,
      "logps/chosen": -95.17000579833984,
      "logps/rejected": -174.54464721679688,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1723785400390625,
      "rewards/margins": 9.312617301940918,
      "rewards/rejected": -7.1402387619018555,
      "step": 4763
    },
    {
      "epoch": 1.9056,
      "grad_norm": 0.002699380274862051,
      "learning_rate": 3.649333333333333e-07,
      "logits/chosen": -1.9845874309539795,
      "logits/rejected": -3.522144317626953,
      "logps/chosen": -73.24986267089844,
      "logps/rejected": -175.76060485839844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.427393913269043,
      "rewards/margins": 11.86463737487793,
      "rewards/rejected": -8.437243461608887,
      "step": 4764
    },
    {
      "epoch": 1.9060000000000001,
      "grad_norm": 0.005543228704482317,
      "learning_rate": 3.648e-07,
      "logits/chosen": -2.216737747192383,
      "logits/rejected": -3.460907459259033,
      "logps/chosen": -125.45375061035156,
      "logps/rejected": -160.12435913085938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9997055530548096,
      "rewards/margins": 9.942611694335938,
      "rewards/rejected": -6.942906379699707,
      "step": 4765
    },
    {
      "epoch": 1.9064,
      "grad_norm": 0.006875208113342524,
      "learning_rate": 3.646666666666666e-07,
      "logits/chosen": -2.1800923347473145,
      "logits/rejected": -3.486078977584839,
      "logps/chosen": -69.45413208007812,
      "logps/rejected": -148.33883666992188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.112200975418091,
      "rewards/margins": 10.803728103637695,
      "rewards/rejected": -7.691526889801025,
      "step": 4766
    },
    {
      "epoch": 1.9068,
      "grad_norm": 0.06560904532670975,
      "learning_rate": 3.645333333333333e-07,
      "logits/chosen": -2.192999839782715,
      "logits/rejected": -3.521763324737549,
      "logps/chosen": -178.81626892089844,
      "logps/rejected": -283.2374267578125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.998060941696167,
      "rewards/margins": 9.340141296386719,
      "rewards/rejected": -7.3420796394348145,
      "step": 4767
    },
    {
      "epoch": 1.9072,
      "grad_norm": 3.3649260997772217,
      "learning_rate": 3.644e-07,
      "logits/chosen": -2.531101703643799,
      "logits/rejected": -3.15914249420166,
      "logps/chosen": -123.98954772949219,
      "logps/rejected": -224.13116455078125,
      "loss": 0.0162,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07625508308410645,
      "rewards/margins": 8.336543083190918,
      "rewards/rejected": -8.26028823852539,
      "step": 4768
    },
    {
      "epoch": 1.9076,
      "grad_norm": 0.0012643001973628998,
      "learning_rate": 3.6426666666666665e-07,
      "logits/chosen": -2.0135695934295654,
      "logits/rejected": -3.2015156745910645,
      "logps/chosen": -99.5592041015625,
      "logps/rejected": -205.94216918945312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4463114738464355,
      "rewards/margins": 12.057369232177734,
      "rewards/rejected": -9.61105728149414,
      "step": 4769
    },
    {
      "epoch": 1.908,
      "grad_norm": 0.0005331847351044416,
      "learning_rate": 3.641333333333333e-07,
      "logits/chosen": -2.3968653678894043,
      "logits/rejected": -3.41458797454834,
      "logps/chosen": -134.64678955078125,
      "logps/rejected": -219.3748779296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7689809799194336,
      "rewards/margins": 14.161664962768555,
      "rewards/rejected": -11.392683029174805,
      "step": 4770
    },
    {
      "epoch": 1.9083999999999999,
      "grad_norm": 0.06961779296398163,
      "learning_rate": 3.64e-07,
      "logits/chosen": -2.6287035942077637,
      "logits/rejected": -3.243187665939331,
      "logps/chosen": -127.54290008544922,
      "logps/rejected": -189.77261352539062,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0257065296173096,
      "rewards/margins": 10.078681945800781,
      "rewards/rejected": -8.052974700927734,
      "step": 4771
    },
    {
      "epoch": 1.9088,
      "grad_norm": 0.21210622787475586,
      "learning_rate": 3.6386666666666667e-07,
      "logits/chosen": -2.3038434982299805,
      "logits/rejected": -3.230050563812256,
      "logps/chosen": -120.87091064453125,
      "logps/rejected": -233.23983764648438,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7182472944259644,
      "rewards/margins": 11.404250144958496,
      "rewards/rejected": -9.686003684997559,
      "step": 4772
    },
    {
      "epoch": 1.9092,
      "grad_norm": 0.006774584297090769,
      "learning_rate": 3.6373333333333336e-07,
      "logits/chosen": -2.2352633476257324,
      "logits/rejected": -3.3882832527160645,
      "logps/chosen": -154.6394805908203,
      "logps/rejected": -243.1957244873047,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.27285635471344,
      "rewards/margins": 9.895843505859375,
      "rewards/rejected": -8.622987747192383,
      "step": 4773
    },
    {
      "epoch": 1.9096,
      "grad_norm": 0.2355906069278717,
      "learning_rate": 3.6359999999999995e-07,
      "logits/chosen": -1.7338814735412598,
      "logits/rejected": -3.7707440853118896,
      "logps/chosen": -150.87783813476562,
      "logps/rejected": -200.51951599121094,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1865009069442749,
      "rewards/margins": 9.690134048461914,
      "rewards/rejected": -9.87663459777832,
      "step": 4774
    },
    {
      "epoch": 1.9100000000000001,
      "grad_norm": 0.012394970282912254,
      "learning_rate": 3.6346666666666664e-07,
      "logits/chosen": -2.0014913082122803,
      "logits/rejected": -3.206501007080078,
      "logps/chosen": -161.09219360351562,
      "logps/rejected": -200.1859588623047,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9760537147521973,
      "rewards/margins": 10.532651901245117,
      "rewards/rejected": -8.556597709655762,
      "step": 4775
    },
    {
      "epoch": 1.9104,
      "grad_norm": 0.019964559003710747,
      "learning_rate": 3.6333333333333333e-07,
      "logits/chosen": -1.9670501947402954,
      "logits/rejected": -3.3045856952667236,
      "logps/chosen": -144.20143127441406,
      "logps/rejected": -243.84742736816406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.874053955078125,
      "rewards/margins": 10.269201278686523,
      "rewards/rejected": -7.395147323608398,
      "step": 4776
    },
    {
      "epoch": 1.9108,
      "grad_norm": 2.741981029510498,
      "learning_rate": 3.632e-07,
      "logits/chosen": -2.8298449516296387,
      "logits/rejected": -3.3164472579956055,
      "logps/chosen": -135.59544372558594,
      "logps/rejected": -222.68048095703125,
      "loss": 0.0162,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9348976612091064,
      "rewards/margins": 6.975855827331543,
      "rewards/rejected": -8.91075325012207,
      "step": 4777
    },
    {
      "epoch": 1.9112,
      "grad_norm": 0.016874808818101883,
      "learning_rate": 3.630666666666666e-07,
      "logits/chosen": -2.4335553646087646,
      "logits/rejected": -3.570106267929077,
      "logps/chosen": -147.8272705078125,
      "logps/rejected": -174.36807250976562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9036452770233154,
      "rewards/margins": 10.942981719970703,
      "rewards/rejected": -9.039337158203125,
      "step": 4778
    },
    {
      "epoch": 1.9116,
      "grad_norm": 0.0007296361145563424,
      "learning_rate": 3.629333333333333e-07,
      "logits/chosen": -1.975907325744629,
      "logits/rejected": -3.200772523880005,
      "logps/chosen": -133.239501953125,
      "logps/rejected": -210.2093505859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9400172233581543,
      "rewards/margins": 13.889446258544922,
      "rewards/rejected": -9.94942855834961,
      "step": 4779
    },
    {
      "epoch": 1.912,
      "grad_norm": 0.00700755650177598,
      "learning_rate": 3.628e-07,
      "logits/chosen": -2.090334892272949,
      "logits/rejected": -3.947831630706787,
      "logps/chosen": -185.5788116455078,
      "logps/rejected": -236.21409606933594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5627349615097046,
      "rewards/margins": 12.149438858032227,
      "rewards/rejected": -11.58670425415039,
      "step": 4780
    },
    {
      "epoch": 1.9123999999999999,
      "grad_norm": 0.07567644119262695,
      "learning_rate": 3.626666666666667e-07,
      "logits/chosen": -2.0949435234069824,
      "logits/rejected": -2.242412805557251,
      "logps/chosen": -99.9034652709961,
      "logps/rejected": -130.41802978515625,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8488705158233643,
      "rewards/margins": 7.650091171264648,
      "rewards/rejected": -5.801220893859863,
      "step": 4781
    },
    {
      "epoch": 1.9127999999999998,
      "grad_norm": 0.004883963614702225,
      "learning_rate": 3.625333333333333e-07,
      "logits/chosen": -2.1284408569335938,
      "logits/rejected": -3.366649627685547,
      "logps/chosen": -130.84213256835938,
      "logps/rejected": -194.36886596679688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.163072347640991,
      "rewards/margins": 10.402945518493652,
      "rewards/rejected": -8.239872932434082,
      "step": 4782
    },
    {
      "epoch": 1.9132,
      "grad_norm": 0.01364880334585905,
      "learning_rate": 3.6239999999999996e-07,
      "logits/chosen": -2.285616397857666,
      "logits/rejected": -2.630941390991211,
      "logps/chosen": -131.64947509765625,
      "logps/rejected": -157.45303344726562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.867536187171936,
      "rewards/margins": 9.237720489501953,
      "rewards/rejected": -7.370184898376465,
      "step": 4783
    },
    {
      "epoch": 1.9136,
      "grad_norm": 0.007500580977648497,
      "learning_rate": 3.6226666666666665e-07,
      "logits/chosen": -1.9061321020126343,
      "logits/rejected": -3.9146251678466797,
      "logps/chosen": -256.0267028808594,
      "logps/rejected": -218.98602294921875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17568586766719818,
      "rewards/margins": 10.636221885681152,
      "rewards/rejected": -10.460536003112793,
      "step": 4784
    },
    {
      "epoch": 1.9140000000000001,
      "grad_norm": 0.0021421839483082294,
      "learning_rate": 3.621333333333333e-07,
      "logits/chosen": -2.258697509765625,
      "logits/rejected": -3.591474771499634,
      "logps/chosen": -114.52729034423828,
      "logps/rejected": -220.595947265625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5106711387634277,
      "rewards/margins": 11.991390228271484,
      "rewards/rejected": -8.480718612670898,
      "step": 4785
    },
    {
      "epoch": 1.9144,
      "grad_norm": 0.02528434246778488,
      "learning_rate": 3.62e-07,
      "logits/chosen": -1.8586657047271729,
      "logits/rejected": -2.6797847747802734,
      "logps/chosen": -95.94588470458984,
      "logps/rejected": -161.4755401611328,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1457479000091553,
      "rewards/margins": 9.56810474395752,
      "rewards/rejected": -7.422357559204102,
      "step": 4786
    },
    {
      "epoch": 1.9148,
      "grad_norm": 0.007562755607068539,
      "learning_rate": 3.618666666666667e-07,
      "logits/chosen": -2.027737617492676,
      "logits/rejected": -3.2336831092834473,
      "logps/chosen": -120.39125061035156,
      "logps/rejected": -201.79690551757812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6974475979804993,
      "rewards/margins": 9.794113159179688,
      "rewards/rejected": -10.491560935974121,
      "step": 4787
    },
    {
      "epoch": 1.9152,
      "grad_norm": 1.555572509765625,
      "learning_rate": 3.617333333333333e-07,
      "logits/chosen": -2.0621535778045654,
      "logits/rejected": -3.4187684059143066,
      "logps/chosen": -123.29652404785156,
      "logps/rejected": -179.1497802734375,
      "loss": 0.0101,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2363346815109253,
      "rewards/margins": 6.9010186195373535,
      "rewards/rejected": -8.13735294342041,
      "step": 4788
    },
    {
      "epoch": 1.9156,
      "grad_norm": 0.0004953487659804523,
      "learning_rate": 3.6159999999999996e-07,
      "logits/chosen": -2.7119483947753906,
      "logits/rejected": -3.6003074645996094,
      "logps/chosen": -168.97433471679688,
      "logps/rejected": -267.3049011230469,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4022910594940186,
      "rewards/margins": 13.5420560836792,
      "rewards/rejected": -11.139764785766602,
      "step": 4789
    },
    {
      "epoch": 1.916,
      "grad_norm": 0.0007181984256021678,
      "learning_rate": 3.6146666666666665e-07,
      "logits/chosen": -1.9671274423599243,
      "logits/rejected": -3.272921323776245,
      "logps/chosen": -123.3360366821289,
      "logps/rejected": -200.1951904296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6803183555603027,
      "rewards/margins": 12.532572746276855,
      "rewards/rejected": -8.852254867553711,
      "step": 4790
    },
    {
      "epoch": 1.9163999999999999,
      "grad_norm": 0.011232376098632812,
      "learning_rate": 3.6133333333333334e-07,
      "logits/chosen": -1.9554517269134521,
      "logits/rejected": -2.693115711212158,
      "logps/chosen": -72.91004943847656,
      "logps/rejected": -136.57730102539062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.703681230545044,
      "rewards/margins": 9.63255500793457,
      "rewards/rejected": -6.928873538970947,
      "step": 4791
    },
    {
      "epoch": 1.9167999999999998,
      "grad_norm": 0.015939826145768166,
      "learning_rate": 3.612e-07,
      "logits/chosen": -2.87392520904541,
      "logits/rejected": -3.3388733863830566,
      "logps/chosen": -141.2869873046875,
      "logps/rejected": -206.810546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.178347587585449,
      "rewards/margins": 10.255703926086426,
      "rewards/rejected": -8.077356338500977,
      "step": 4792
    },
    {
      "epoch": 1.9172,
      "grad_norm": 0.0004056328907608986,
      "learning_rate": 3.610666666666666e-07,
      "logits/chosen": -1.8251261711120605,
      "logits/rejected": -3.3956196308135986,
      "logps/chosen": -73.01246643066406,
      "logps/rejected": -180.043212890625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9970908164978027,
      "rewards/margins": 12.923648834228516,
      "rewards/rejected": -8.926557540893555,
      "step": 4793
    },
    {
      "epoch": 1.9176,
      "grad_norm": 0.08549917489290237,
      "learning_rate": 3.609333333333333e-07,
      "logits/chosen": -2.177671432495117,
      "logits/rejected": -2.7384514808654785,
      "logps/chosen": -94.16636657714844,
      "logps/rejected": -146.46389770507812,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4949920177459717,
      "rewards/margins": 8.818633079528809,
      "rewards/rejected": -7.323641300201416,
      "step": 4794
    },
    {
      "epoch": 1.9180000000000001,
      "grad_norm": 0.34204021096229553,
      "learning_rate": 3.608e-07,
      "logits/chosen": -2.1690561771392822,
      "logits/rejected": -3.586883306503296,
      "logps/chosen": -85.20100402832031,
      "logps/rejected": -164.05728149414062,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.093923568725586,
      "rewards/margins": 8.17847728729248,
      "rewards/rejected": -7.0845537185668945,
      "step": 4795
    },
    {
      "epoch": 1.9184,
      "grad_norm": 0.0013638812815770507,
      "learning_rate": 3.606666666666667e-07,
      "logits/chosen": -2.021324396133423,
      "logits/rejected": -2.9633212089538574,
      "logps/chosen": -152.98309326171875,
      "logps/rejected": -190.95880126953125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.104991912841797,
      "rewards/margins": 13.085416793823242,
      "rewards/rejected": -8.980424880981445,
      "step": 4796
    },
    {
      "epoch": 1.9188,
      "grad_norm": 0.001538365613669157,
      "learning_rate": 3.605333333333333e-07,
      "logits/chosen": -1.7977163791656494,
      "logits/rejected": -3.7250447273254395,
      "logps/chosen": -89.96878814697266,
      "logps/rejected": -232.6125946044922,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0232605934143066,
      "rewards/margins": 14.731168746948242,
      "rewards/rejected": -11.707907676696777,
      "step": 4797
    },
    {
      "epoch": 1.9192,
      "grad_norm": 0.006092749070376158,
      "learning_rate": 3.6039999999999997e-07,
      "logits/chosen": -1.9299380779266357,
      "logits/rejected": -3.0995869636535645,
      "logps/chosen": -99.54771423339844,
      "logps/rejected": -172.8661346435547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.355227470397949,
      "rewards/margins": 10.07016372680664,
      "rewards/rejected": -7.714935779571533,
      "step": 4798
    },
    {
      "epoch": 1.9196,
      "grad_norm": 0.00182876898907125,
      "learning_rate": 3.6026666666666666e-07,
      "logits/chosen": -1.9372222423553467,
      "logits/rejected": -2.8566293716430664,
      "logps/chosen": -193.005126953125,
      "logps/rejected": -185.77349853515625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.206451416015625,
      "rewards/margins": 11.76208782196045,
      "rewards/rejected": -8.555635452270508,
      "step": 4799
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.010459860786795616,
      "learning_rate": 3.6013333333333336e-07,
      "logits/chosen": -2.0333094596862793,
      "logits/rejected": -3.480545997619629,
      "logps/chosen": -181.6444091796875,
      "logps/rejected": -202.71310424804688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1306989192962646,
      "rewards/margins": 10.076903343200684,
      "rewards/rejected": -7.94620418548584,
      "step": 4800
    },
    {
      "epoch": 1.9203999999999999,
      "grad_norm": 0.022632595151662827,
      "learning_rate": 3.6e-07,
      "logits/chosen": -2.4490153789520264,
      "logits/rejected": -3.721525192260742,
      "logps/chosen": -88.86022186279297,
      "logps/rejected": -212.58258056640625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.663302421569824,
      "rewards/margins": 12.42430305480957,
      "rewards/rejected": -9.76099967956543,
      "step": 4801
    },
    {
      "epoch": 1.9207999999999998,
      "grad_norm": 0.026611972600221634,
      "learning_rate": 3.5986666666666663e-07,
      "logits/chosen": -1.7207520008087158,
      "logits/rejected": -3.2254161834716797,
      "logps/chosen": -48.383094787597656,
      "logps/rejected": -174.77630615234375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.546694278717041,
      "rewards/margins": 9.789392471313477,
      "rewards/rejected": -7.242697715759277,
      "step": 4802
    },
    {
      "epoch": 1.9212,
      "grad_norm": 0.0026949511375278234,
      "learning_rate": 3.597333333333333e-07,
      "logits/chosen": -2.6051182746887207,
      "logits/rejected": -3.578835964202881,
      "logps/chosen": -131.25662231445312,
      "logps/rejected": -180.96453857421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.794764757156372,
      "rewards/margins": 10.683998107910156,
      "rewards/rejected": -8.889232635498047,
      "step": 4803
    },
    {
      "epoch": 1.9216,
      "grad_norm": 0.005925958044826984,
      "learning_rate": 3.5959999999999996e-07,
      "logits/chosen": -2.2314038276672363,
      "logits/rejected": -3.449197292327881,
      "logps/chosen": -86.43901062011719,
      "logps/rejected": -167.3846893310547,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.551926851272583,
      "rewards/margins": 10.137540817260742,
      "rewards/rejected": -7.585614204406738,
      "step": 4804
    },
    {
      "epoch": 1.9220000000000002,
      "grad_norm": 0.0008082273998297751,
      "learning_rate": 3.5946666666666666e-07,
      "logits/chosen": -1.571911334991455,
      "logits/rejected": -3.9801437854766846,
      "logps/chosen": -110.85760498046875,
      "logps/rejected": -189.261474609375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.891653060913086,
      "rewards/margins": 12.358881950378418,
      "rewards/rejected": -9.467227935791016,
      "step": 4805
    },
    {
      "epoch": 1.9224,
      "grad_norm": 0.18181174993515015,
      "learning_rate": 3.5933333333333335e-07,
      "logits/chosen": -2.5614185333251953,
      "logits/rejected": -3.2502760887145996,
      "logps/chosen": -96.81661987304688,
      "logps/rejected": -154.32705688476562,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8424729108810425,
      "rewards/margins": 9.356693267822266,
      "rewards/rejected": -7.514220237731934,
      "step": 4806
    },
    {
      "epoch": 1.9228,
      "grad_norm": 0.09991642087697983,
      "learning_rate": 3.592e-07,
      "logits/chosen": -2.1601405143737793,
      "logits/rejected": -3.52365779876709,
      "logps/chosen": -81.32839965820312,
      "logps/rejected": -167.48458862304688,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4645969867706299,
      "rewards/margins": 8.678422927856445,
      "rewards/rejected": -7.213825702667236,
      "step": 4807
    },
    {
      "epoch": 1.9232,
      "grad_norm": 0.005235289689153433,
      "learning_rate": 3.590666666666666e-07,
      "logits/chosen": -2.6043879985809326,
      "logits/rejected": -3.323129177093506,
      "logps/chosen": -118.47340393066406,
      "logps/rejected": -203.9575653076172,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3395566940307617,
      "rewards/margins": 11.719751358032227,
      "rewards/rejected": -8.380194664001465,
      "step": 4808
    },
    {
      "epoch": 1.9236,
      "grad_norm": 0.004004793707281351,
      "learning_rate": 3.589333333333333e-07,
      "logits/chosen": -1.8812110424041748,
      "logits/rejected": -3.51115083694458,
      "logps/chosen": -142.4488525390625,
      "logps/rejected": -210.86793518066406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2674057483673096,
      "rewards/margins": 10.991414070129395,
      "rewards/rejected": -9.724008560180664,
      "step": 4809
    },
    {
      "epoch": 1.924,
      "grad_norm": 0.010219158604741096,
      "learning_rate": 3.588e-07,
      "logits/chosen": -2.424191951751709,
      "logits/rejected": -3.6995716094970703,
      "logps/chosen": -136.78610229492188,
      "logps/rejected": -182.2906951904297,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.841555595397949,
      "rewards/margins": 11.57382583618164,
      "rewards/rejected": -8.732270240783691,
      "step": 4810
    },
    {
      "epoch": 1.9243999999999999,
      "grad_norm": 0.0062584225088357925,
      "learning_rate": 3.5866666666666665e-07,
      "logits/chosen": -1.9873546361923218,
      "logits/rejected": -3.4823222160339355,
      "logps/chosen": -142.93948364257812,
      "logps/rejected": -206.68081665039062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2075042724609375,
      "rewards/margins": 11.102497100830078,
      "rewards/rejected": -7.894992828369141,
      "step": 4811
    },
    {
      "epoch": 1.9247999999999998,
      "grad_norm": 0.023623552173376083,
      "learning_rate": 3.585333333333333e-07,
      "logits/chosen": -2.234808921813965,
      "logits/rejected": -3.5640203952789307,
      "logps/chosen": -180.3436279296875,
      "logps/rejected": -211.1858367919922,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2829887270927429,
      "rewards/margins": 8.977680206298828,
      "rewards/rejected": -9.260668754577637,
      "step": 4812
    },
    {
      "epoch": 1.9252,
      "grad_norm": 1.051013469696045,
      "learning_rate": 3.584e-07,
      "logits/chosen": -2.5090558528900146,
      "logits/rejected": -3.6495437622070312,
      "logps/chosen": -126.74649047851562,
      "logps/rejected": -183.63229370117188,
      "loss": 0.0077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.58502995967865,
      "rewards/margins": 7.475132465362549,
      "rewards/rejected": -9.060162544250488,
      "step": 4813
    },
    {
      "epoch": 1.9256,
      "grad_norm": 0.003070313949137926,
      "learning_rate": 3.5826666666666667e-07,
      "logits/chosen": -2.2526698112487793,
      "logits/rejected": -2.9786148071289062,
      "logps/chosen": -77.427734375,
      "logps/rejected": -196.95945739746094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1918606758117676,
      "rewards/margins": 12.488441467285156,
      "rewards/rejected": -9.296581268310547,
      "step": 4814
    },
    {
      "epoch": 1.9260000000000002,
      "grad_norm": 0.02573631890118122,
      "learning_rate": 3.5813333333333336e-07,
      "logits/chosen": -2.1458654403686523,
      "logits/rejected": -3.781630039215088,
      "logps/chosen": -102.511962890625,
      "logps/rejected": -191.4431915283203,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4790844917297363,
      "rewards/margins": 11.270435333251953,
      "rewards/rejected": -8.791350364685059,
      "step": 4815
    },
    {
      "epoch": 1.9264000000000001,
      "grad_norm": 0.04279623553156853,
      "learning_rate": 3.5799999999999995e-07,
      "logits/chosen": -2.291841983795166,
      "logits/rejected": -3.034010887145996,
      "logps/chosen": -107.6040267944336,
      "logps/rejected": -179.4916534423828,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.171910285949707,
      "rewards/margins": 10.56245231628418,
      "rewards/rejected": -7.390542030334473,
      "step": 4816
    },
    {
      "epoch": 1.9268,
      "grad_norm": 0.011574812233448029,
      "learning_rate": 3.5786666666666664e-07,
      "logits/chosen": -2.5087766647338867,
      "logits/rejected": -3.4842886924743652,
      "logps/chosen": -213.82481384277344,
      "logps/rejected": -294.26617431640625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0891640186309814,
      "rewards/margins": 10.097491264343262,
      "rewards/rejected": -12.186655044555664,
      "step": 4817
    },
    {
      "epoch": 1.9272,
      "grad_norm": 0.023471398279070854,
      "learning_rate": 3.5773333333333333e-07,
      "logits/chosen": -2.644066333770752,
      "logits/rejected": -3.8558669090270996,
      "logps/chosen": -120.2725830078125,
      "logps/rejected": -215.60260009765625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1707329750061035,
      "rewards/margins": 10.002946853637695,
      "rewards/rejected": -8.832213401794434,
      "step": 4818
    },
    {
      "epoch": 1.9276,
      "grad_norm": 1.0110251903533936,
      "learning_rate": 3.5759999999999997e-07,
      "logits/chosen": -1.9903090000152588,
      "logits/rejected": -2.613692045211792,
      "logps/chosen": -117.51241302490234,
      "logps/rejected": -151.6356201171875,
      "loss": 0.011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.02484428882598877,
      "rewards/margins": 7.025970935821533,
      "rewards/rejected": -7.050815582275391,
      "step": 4819
    },
    {
      "epoch": 1.928,
      "grad_norm": 0.0009786038426682353,
      "learning_rate": 3.5746666666666666e-07,
      "logits/chosen": -2.2514514923095703,
      "logits/rejected": -3.2091293334960938,
      "logps/chosen": -137.14195251464844,
      "logps/rejected": -210.05386352539062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.502403259277344,
      "rewards/margins": 13.42320728302002,
      "rewards/rejected": -8.920804977416992,
      "step": 4820
    },
    {
      "epoch": 1.9284,
      "grad_norm": 0.11418092995882034,
      "learning_rate": 3.573333333333333e-07,
      "logits/chosen": -2.1387765407562256,
      "logits/rejected": -3.6088552474975586,
      "logps/chosen": -95.18913269042969,
      "logps/rejected": -199.86187744140625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4648960828781128,
      "rewards/margins": 9.20256519317627,
      "rewards/rejected": -7.737668991088867,
      "step": 4821
    },
    {
      "epoch": 1.9287999999999998,
      "grad_norm": 0.03968659043312073,
      "learning_rate": 3.572e-07,
      "logits/chosen": -2.242859363555908,
      "logits/rejected": -3.6597166061401367,
      "logps/chosen": -91.87921142578125,
      "logps/rejected": -183.52578735351562,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7820450067520142,
      "rewards/margins": 10.151162147521973,
      "rewards/rejected": -8.369117736816406,
      "step": 4822
    },
    {
      "epoch": 1.9292,
      "grad_norm": 7.225923764053732e-05,
      "learning_rate": 3.5706666666666663e-07,
      "logits/chosen": -2.4442758560180664,
      "logits/rejected": -3.810621500015259,
      "logps/chosen": -92.38795471191406,
      "logps/rejected": -190.45982360839844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.748847007751465,
      "rewards/margins": 14.65086555480957,
      "rewards/rejected": -10.902018547058105,
      "step": 4823
    },
    {
      "epoch": 1.9296,
      "grad_norm": 0.04202675074338913,
      "learning_rate": 3.5693333333333333e-07,
      "logits/chosen": -1.8292794227600098,
      "logits/rejected": -3.669827461242676,
      "logps/chosen": -107.95189666748047,
      "logps/rejected": -273.8949279785156,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2402617931365967,
      "rewards/margins": 13.148515701293945,
      "rewards/rejected": -10.90825366973877,
      "step": 4824
    },
    {
      "epoch": 1.9300000000000002,
      "grad_norm": 0.0014708839589729905,
      "learning_rate": 3.5679999999999997e-07,
      "logits/chosen": -2.047602653503418,
      "logits/rejected": -3.642120122909546,
      "logps/chosen": -158.06654357910156,
      "logps/rejected": -182.96160888671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.618893623352051,
      "rewards/margins": 11.242637634277344,
      "rewards/rejected": -8.62374496459961,
      "step": 4825
    },
    {
      "epoch": 1.9304000000000001,
      "grad_norm": 0.0009045128826983273,
      "learning_rate": 3.5666666666666666e-07,
      "logits/chosen": -1.9965689182281494,
      "logits/rejected": -2.980675220489502,
      "logps/chosen": -79.66038513183594,
      "logps/rejected": -178.4458770751953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.0789055824279785,
      "rewards/margins": 11.840559005737305,
      "rewards/rejected": -7.761652946472168,
      "step": 4826
    },
    {
      "epoch": 1.9308,
      "grad_norm": 0.06312210112810135,
      "learning_rate": 3.565333333333333e-07,
      "logits/chosen": -1.959442138671875,
      "logits/rejected": -3.3207945823669434,
      "logps/chosen": -156.1799774169922,
      "logps/rejected": -165.90574645996094,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4775943756103516,
      "rewards/margins": 7.785778999328613,
      "rewards/rejected": -5.308184623718262,
      "step": 4827
    },
    {
      "epoch": 1.9312,
      "grad_norm": 0.0009561418555676937,
      "learning_rate": 3.564e-07,
      "logits/chosen": -1.4800469875335693,
      "logits/rejected": -2.9905309677124023,
      "logps/chosen": -92.99104309082031,
      "logps/rejected": -187.8833465576172,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.49702787399292,
      "rewards/margins": 12.061594009399414,
      "rewards/rejected": -8.564566612243652,
      "step": 4828
    },
    {
      "epoch": 1.9316,
      "grad_norm": 0.0706033930182457,
      "learning_rate": 3.562666666666667e-07,
      "logits/chosen": -2.333935022354126,
      "logits/rejected": -3.683497428894043,
      "logps/chosen": -157.779052734375,
      "logps/rejected": -165.7042694091797,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5273205041885376,
      "rewards/margins": 7.503048419952393,
      "rewards/rejected": -8.03036880493164,
      "step": 4829
    },
    {
      "epoch": 1.932,
      "grad_norm": 0.6562922596931458,
      "learning_rate": 3.561333333333333e-07,
      "logits/chosen": -1.9191721677780151,
      "logits/rejected": -3.566053867340088,
      "logps/chosen": -89.14476013183594,
      "logps/rejected": -171.52781677246094,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7607429623603821,
      "rewards/margins": 9.225973129272461,
      "rewards/rejected": -8.465230941772461,
      "step": 4830
    },
    {
      "epoch": 1.9324,
      "grad_norm": 0.05085434764623642,
      "learning_rate": 3.5599999999999996e-07,
      "logits/chosen": -1.9447963237762451,
      "logits/rejected": -3.292569160461426,
      "logps/chosen": -90.97439575195312,
      "logps/rejected": -159.54400634765625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.314561128616333,
      "rewards/margins": 10.25593376159668,
      "rewards/rejected": -8.941373825073242,
      "step": 4831
    },
    {
      "epoch": 1.9327999999999999,
      "grad_norm": 0.020832451060414314,
      "learning_rate": 3.5586666666666665e-07,
      "logits/chosen": -3.2014503479003906,
      "logits/rejected": -4.043457508087158,
      "logps/chosen": -187.32090759277344,
      "logps/rejected": -204.16104125976562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5964787006378174,
      "rewards/margins": 9.723209381103516,
      "rewards/rejected": -9.126730918884277,
      "step": 4832
    },
    {
      "epoch": 1.9332,
      "grad_norm": 0.1820593923330307,
      "learning_rate": 3.5573333333333334e-07,
      "logits/chosen": -1.9836032390594482,
      "logits/rejected": -3.17128849029541,
      "logps/chosen": -130.4571075439453,
      "logps/rejected": -171.11294555664062,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07275694608688354,
      "rewards/margins": 7.594809532165527,
      "rewards/rejected": -7.522052764892578,
      "step": 4833
    },
    {
      "epoch": 1.9336,
      "grad_norm": 0.009803781285881996,
      "learning_rate": 3.5560000000000003e-07,
      "logits/chosen": -1.597191572189331,
      "logits/rejected": -3.199702262878418,
      "logps/chosen": -85.4288330078125,
      "logps/rejected": -160.75296020507812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7968727350234985,
      "rewards/margins": 9.288208961486816,
      "rewards/rejected": -7.491335868835449,
      "step": 4834
    },
    {
      "epoch": 1.9340000000000002,
      "grad_norm": 0.01652560383081436,
      "learning_rate": 3.554666666666666e-07,
      "logits/chosen": -2.081627368927002,
      "logits/rejected": -3.7370824813842773,
      "logps/chosen": -132.2510528564453,
      "logps/rejected": -200.41488647460938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.483210802078247,
      "rewards/margins": 11.146660804748535,
      "rewards/rejected": -8.663450241088867,
      "step": 4835
    },
    {
      "epoch": 1.9344000000000001,
      "grad_norm": 0.00047145714052021503,
      "learning_rate": 3.553333333333333e-07,
      "logits/chosen": -2.1601271629333496,
      "logits/rejected": -3.5884346961975098,
      "logps/chosen": -104.04594421386719,
      "logps/rejected": -211.98397827148438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.867975234985352,
      "rewards/margins": 13.536643981933594,
      "rewards/rejected": -8.668668746948242,
      "step": 4836
    },
    {
      "epoch": 1.9348,
      "grad_norm": 0.0014335268642753363,
      "learning_rate": 3.552e-07,
      "logits/chosen": -2.337100028991699,
      "logits/rejected": -3.0720250606536865,
      "logps/chosen": -148.64979553222656,
      "logps/rejected": -243.1027374267578,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.172782897949219,
      "rewards/margins": 11.879158020019531,
      "rewards/rejected": -7.7063751220703125,
      "step": 4837
    },
    {
      "epoch": 1.9352,
      "grad_norm": 0.011183411814272404,
      "learning_rate": 3.5506666666666664e-07,
      "logits/chosen": -2.6980605125427246,
      "logits/rejected": -3.207937002182007,
      "logps/chosen": -251.1343536376953,
      "logps/rejected": -201.73455810546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.040815830230713,
      "rewards/margins": 10.516300201416016,
      "rewards/rejected": -7.4754838943481445,
      "step": 4838
    },
    {
      "epoch": 1.9356,
      "grad_norm": 0.023830298334360123,
      "learning_rate": 3.549333333333333e-07,
      "logits/chosen": -2.145282030105591,
      "logits/rejected": -3.3064396381378174,
      "logps/chosen": -103.90113830566406,
      "logps/rejected": -182.2783966064453,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1276111602783203,
      "rewards/margins": 10.03105354309082,
      "rewards/rejected": -8.9034423828125,
      "step": 4839
    },
    {
      "epoch": 1.936,
      "grad_norm": 0.056751854717731476,
      "learning_rate": 3.548e-07,
      "logits/chosen": -2.1558282375335693,
      "logits/rejected": -3.51609468460083,
      "logps/chosen": -126.13117980957031,
      "logps/rejected": -169.34963989257812,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7506134510040283,
      "rewards/margins": 10.19295883178711,
      "rewards/rejected": -8.442346572875977,
      "step": 4840
    },
    {
      "epoch": 1.9364,
      "grad_norm": 0.007039990276098251,
      "learning_rate": 3.5466666666666667e-07,
      "logits/chosen": -1.434300184249878,
      "logits/rejected": -3.3065760135650635,
      "logps/chosen": -86.03986358642578,
      "logps/rejected": -177.79391479492188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3699533939361572,
      "rewards/margins": 10.24437141418457,
      "rewards/rejected": -7.874417304992676,
      "step": 4841
    },
    {
      "epoch": 1.9367999999999999,
      "grad_norm": 0.0072260270826518536,
      "learning_rate": 3.545333333333333e-07,
      "logits/chosen": -2.284384250640869,
      "logits/rejected": -3.424525260925293,
      "logps/chosen": -203.7214813232422,
      "logps/rejected": -188.0608673095703,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8480849862098694,
      "rewards/margins": 10.161579132080078,
      "rewards/rejected": -9.313494682312012,
      "step": 4842
    },
    {
      "epoch": 1.9372,
      "grad_norm": 0.008898802101612091,
      "learning_rate": 3.544e-07,
      "logits/chosen": -2.346541404724121,
      "logits/rejected": -3.8722145557403564,
      "logps/chosen": -169.7933807373047,
      "logps/rejected": -230.59201049804688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3121169805526733,
      "rewards/margins": 11.05972671508789,
      "rewards/rejected": -9.747610092163086,
      "step": 4843
    },
    {
      "epoch": 1.9376,
      "grad_norm": 0.028103452175855637,
      "learning_rate": 3.5426666666666664e-07,
      "logits/chosen": -2.4042346477508545,
      "logits/rejected": -3.5414042472839355,
      "logps/chosen": -125.53302764892578,
      "logps/rejected": -207.48281860351562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1883884072303772,
      "rewards/margins": 9.6093111038208,
      "rewards/rejected": -9.420923233032227,
      "step": 4844
    },
    {
      "epoch": 1.938,
      "grad_norm": 0.0006434117094613612,
      "learning_rate": 3.5413333333333333e-07,
      "logits/chosen": -2.0407958030700684,
      "logits/rejected": -3.095261573791504,
      "logps/chosen": -132.09622192382812,
      "logps/rejected": -211.88232421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.226586818695068,
      "rewards/margins": 13.190061569213867,
      "rewards/rejected": -8.96347427368164,
      "step": 4845
    },
    {
      "epoch": 1.9384000000000001,
      "grad_norm": 0.0024677650071680546,
      "learning_rate": 3.5399999999999997e-07,
      "logits/chosen": -1.8489435911178589,
      "logits/rejected": -3.653515338897705,
      "logps/chosen": -106.49838256835938,
      "logps/rejected": -174.23170471191406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.791062116622925,
      "rewards/margins": 11.39181137084961,
      "rewards/rejected": -8.600749015808105,
      "step": 4846
    },
    {
      "epoch": 1.9388,
      "grad_norm": 0.00502150971442461,
      "learning_rate": 3.5386666666666666e-07,
      "logits/chosen": -2.0744338035583496,
      "logits/rejected": -2.7069039344787598,
      "logps/chosen": -125.1791763305664,
      "logps/rejected": -160.6568145751953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2028908729553223,
      "rewards/margins": 10.099983215332031,
      "rewards/rejected": -6.897091865539551,
      "step": 4847
    },
    {
      "epoch": 1.9392,
      "grad_norm": 0.010433890856802464,
      "learning_rate": 3.5373333333333335e-07,
      "logits/chosen": -2.199850559234619,
      "logits/rejected": -3.2036166191101074,
      "logps/chosen": -130.45980834960938,
      "logps/rejected": -197.48912048339844,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0427597761154175,
      "rewards/margins": 9.51076889038086,
      "rewards/rejected": -8.468009948730469,
      "step": 4848
    },
    {
      "epoch": 1.9396,
      "grad_norm": 0.0003925920755136758,
      "learning_rate": 3.536e-07,
      "logits/chosen": -2.265064239501953,
      "logits/rejected": -3.7070088386535645,
      "logps/chosen": -131.73587036132812,
      "logps/rejected": -215.2516326904297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7556800842285156,
      "rewards/margins": 12.716392517089844,
      "rewards/rejected": -9.960712432861328,
      "step": 4849
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.0008844755357131362,
      "learning_rate": 3.5346666666666663e-07,
      "logits/chosen": -2.180375099182129,
      "logits/rejected": -3.2498507499694824,
      "logps/chosen": -112.73248291015625,
      "logps/rejected": -183.6293182373047,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.065713405609131,
      "rewards/margins": 12.18686580657959,
      "rewards/rejected": -8.121152877807617,
      "step": 4850
    },
    {
      "epoch": 1.9404,
      "grad_norm": 0.00021910732903052121,
      "learning_rate": 3.533333333333333e-07,
      "logits/chosen": -2.481323480606079,
      "logits/rejected": -4.137401580810547,
      "logps/chosen": -147.64869689941406,
      "logps/rejected": -199.61448669433594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.815279960632324,
      "rewards/margins": 13.337995529174805,
      "rewards/rejected": -9.522714614868164,
      "step": 4851
    },
    {
      "epoch": 1.9407999999999999,
      "grad_norm": 0.0003954326966777444,
      "learning_rate": 3.532e-07,
      "logits/chosen": -2.8414602279663086,
      "logits/rejected": -3.7178051471710205,
      "logps/chosen": -178.42938232421875,
      "logps/rejected": -240.6641387939453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.062899112701416,
      "rewards/margins": 12.733413696289062,
      "rewards/rejected": -10.670515060424805,
      "step": 4852
    },
    {
      "epoch": 1.9412,
      "grad_norm": 0.00015665273531340063,
      "learning_rate": 3.530666666666666e-07,
      "logits/chosen": -1.798352599143982,
      "logits/rejected": -4.104042053222656,
      "logps/chosen": -85.33761596679688,
      "logps/rejected": -212.57943725585938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.535975217819214,
      "rewards/margins": 14.768688201904297,
      "rewards/rejected": -12.23271369934082,
      "step": 4853
    },
    {
      "epoch": 1.9416,
      "grad_norm": 0.0027149158995598555,
      "learning_rate": 3.529333333333333e-07,
      "logits/chosen": -2.1879236698150635,
      "logits/rejected": -3.1939425468444824,
      "logps/chosen": -136.01028442382812,
      "logps/rejected": -180.85581970214844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.1095476150512695,
      "rewards/margins": 13.207965850830078,
      "rewards/rejected": -9.098418235778809,
      "step": 4854
    },
    {
      "epoch": 1.942,
      "grad_norm": 0.03945782780647278,
      "learning_rate": 3.528e-07,
      "logits/chosen": -1.7984986305236816,
      "logits/rejected": -2.66817045211792,
      "logps/chosen": -116.86430358886719,
      "logps/rejected": -154.56581115722656,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0936757326126099,
      "rewards/margins": 8.495925903320312,
      "rewards/rejected": -7.402249813079834,
      "step": 4855
    },
    {
      "epoch": 1.9424000000000001,
      "grad_norm": 0.006140778306871653,
      "learning_rate": 3.526666666666667e-07,
      "logits/chosen": -2.0606188774108887,
      "logits/rejected": -3.506950855255127,
      "logps/chosen": -162.4602508544922,
      "logps/rejected": -196.28736877441406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.981964111328125,
      "rewards/margins": 11.019198417663574,
      "rewards/rejected": -10.03723430633545,
      "step": 4856
    },
    {
      "epoch": 1.9428,
      "grad_norm": 0.0016008130041882396,
      "learning_rate": 3.525333333333333e-07,
      "logits/chosen": -1.9647669792175293,
      "logits/rejected": -3.7567577362060547,
      "logps/chosen": -108.15751647949219,
      "logps/rejected": -212.33155822753906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6572999954223633,
      "rewards/margins": 11.971443176269531,
      "rewards/rejected": -9.314144134521484,
      "step": 4857
    },
    {
      "epoch": 1.9432,
      "grad_norm": 0.006462048273533583,
      "learning_rate": 3.5239999999999995e-07,
      "logits/chosen": -2.4289417266845703,
      "logits/rejected": -3.3753039836883545,
      "logps/chosen": -59.66252136230469,
      "logps/rejected": -192.49514770507812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.633208990097046,
      "rewards/margins": 13.00717544555664,
      "rewards/rejected": -9.373966217041016,
      "step": 4858
    },
    {
      "epoch": 1.9436,
      "grad_norm": 0.001893359120003879,
      "learning_rate": 3.5226666666666664e-07,
      "logits/chosen": -1.9971511363983154,
      "logits/rejected": -3.2329394817352295,
      "logps/chosen": -202.503173828125,
      "logps/rejected": -190.98953247070312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5833046436309814,
      "rewards/margins": 11.251976013183594,
      "rewards/rejected": -7.668671607971191,
      "step": 4859
    },
    {
      "epoch": 1.944,
      "grad_norm": 0.004583117552101612,
      "learning_rate": 3.5213333333333334e-07,
      "logits/chosen": -1.6091439723968506,
      "logits/rejected": -3.4246060848236084,
      "logps/chosen": -171.16314697265625,
      "logps/rejected": -190.83111572265625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.071152925491333,
      "rewards/margins": 11.694318771362305,
      "rewards/rejected": -9.62316608428955,
      "step": 4860
    },
    {
      "epoch": 1.9444,
      "grad_norm": 0.0045631760731339455,
      "learning_rate": 3.52e-07,
      "logits/chosen": -2.5290331840515137,
      "logits/rejected": -3.4322991371154785,
      "logps/chosen": -142.9436492919922,
      "logps/rejected": -184.75003051757812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9667067527770996,
      "rewards/margins": 10.592796325683594,
      "rewards/rejected": -8.626090049743652,
      "step": 4861
    },
    {
      "epoch": 1.9447999999999999,
      "grad_norm": 0.01969234086573124,
      "learning_rate": 3.5186666666666667e-07,
      "logits/chosen": -2.752216339111328,
      "logits/rejected": -3.7482802867889404,
      "logps/chosen": -204.06674194335938,
      "logps/rejected": -220.938720703125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5033218264579773,
      "rewards/margins": 10.325946807861328,
      "rewards/rejected": -10.829268455505371,
      "step": 4862
    },
    {
      "epoch": 1.9452,
      "grad_norm": 0.27423378825187683,
      "learning_rate": 3.517333333333333e-07,
      "logits/chosen": -2.8847575187683105,
      "logits/rejected": -3.3221793174743652,
      "logps/chosen": -180.05055236816406,
      "logps/rejected": -163.5491180419922,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.23433947563171387,
      "rewards/margins": 6.140499114990234,
      "rewards/rejected": -6.374838829040527,
      "step": 4863
    },
    {
      "epoch": 1.9456,
      "grad_norm": 4.97915506362915,
      "learning_rate": 3.516e-07,
      "logits/chosen": -2.0386486053466797,
      "logits/rejected": -3.2723498344421387,
      "logps/chosen": -121.90009307861328,
      "logps/rejected": -203.4283905029297,
      "loss": 0.0216,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0013988018035888672,
      "rewards/margins": 5.7666425704956055,
      "rewards/rejected": -5.768041610717773,
      "step": 4864
    },
    {
      "epoch": 1.946,
      "grad_norm": 0.05679420754313469,
      "learning_rate": 3.5146666666666664e-07,
      "logits/chosen": -2.371610164642334,
      "logits/rejected": -3.186621904373169,
      "logps/chosen": -102.09503173828125,
      "logps/rejected": -196.91015625,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9414589405059814,
      "rewards/margins": 9.829309463500977,
      "rewards/rejected": -7.887850284576416,
      "step": 4865
    },
    {
      "epoch": 1.9464000000000001,
      "grad_norm": 0.005027505103498697,
      "learning_rate": 3.5133333333333333e-07,
      "logits/chosen": -2.0383870601654053,
      "logits/rejected": -3.3649954795837402,
      "logps/chosen": -105.6220703125,
      "logps/rejected": -194.08184814453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.576911449432373,
      "rewards/margins": 12.857534408569336,
      "rewards/rejected": -9.280622482299805,
      "step": 4866
    },
    {
      "epoch": 1.9468,
      "grad_norm": 0.04741750657558441,
      "learning_rate": 3.512e-07,
      "logits/chosen": -1.6509838104248047,
      "logits/rejected": -2.8949999809265137,
      "logps/chosen": -111.16960144042969,
      "logps/rejected": -200.25564575195312,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2705328464508057,
      "rewards/margins": 11.39792537689209,
      "rewards/rejected": -9.127392768859863,
      "step": 4867
    },
    {
      "epoch": 1.9472,
      "grad_norm": 0.018408380448818207,
      "learning_rate": 3.5106666666666666e-07,
      "logits/chosen": -1.8035099506378174,
      "logits/rejected": -3.005235195159912,
      "logps/chosen": -133.8102264404297,
      "logps/rejected": -158.361572265625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4494061470031738,
      "rewards/margins": 8.830665588378906,
      "rewards/rejected": -7.381259918212891,
      "step": 4868
    },
    {
      "epoch": 1.9476,
      "grad_norm": 0.000757245987188071,
      "learning_rate": 3.509333333333333e-07,
      "logits/chosen": -2.3583037853240967,
      "logits/rejected": -2.904508113861084,
      "logps/chosen": -126.81812286376953,
      "logps/rejected": -189.0436248779297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.21088171005249,
      "rewards/margins": 12.693038940429688,
      "rewards/rejected": -8.482156753540039,
      "step": 4869
    },
    {
      "epoch": 1.948,
      "grad_norm": 0.029191331937909126,
      "learning_rate": 3.508e-07,
      "logits/chosen": -2.088512420654297,
      "logits/rejected": -3.1573638916015625,
      "logps/chosen": -141.05833435058594,
      "logps/rejected": -166.97891235351562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7374931573867798,
      "rewards/margins": 9.150358200073242,
      "rewards/rejected": -7.41286563873291,
      "step": 4870
    },
    {
      "epoch": 1.9484,
      "grad_norm": 0.007769174408167601,
      "learning_rate": 3.506666666666667e-07,
      "logits/chosen": -2.584237813949585,
      "logits/rejected": -3.7386999130249023,
      "logps/chosen": -273.5174560546875,
      "logps/rejected": -211.109130859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1664825677871704,
      "rewards/margins": 10.44265365600586,
      "rewards/rejected": -9.27617073059082,
      "step": 4871
    },
    {
      "epoch": 1.9487999999999999,
      "grad_norm": 0.016278812661767006,
      "learning_rate": 3.5053333333333327e-07,
      "logits/chosen": -1.9573920965194702,
      "logits/rejected": -3.34934663772583,
      "logps/chosen": -144.02532958984375,
      "logps/rejected": -164.22039794921875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5269039869308472,
      "rewards/margins": 9.394143104553223,
      "rewards/rejected": -7.867238998413086,
      "step": 4872
    },
    {
      "epoch": 1.9492,
      "grad_norm": 0.032135721296072006,
      "learning_rate": 3.5039999999999996e-07,
      "logits/chosen": -2.2067034244537354,
      "logits/rejected": -3.1263234615325928,
      "logps/chosen": -89.72280883789062,
      "logps/rejected": -161.8831787109375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9859840869903564,
      "rewards/margins": 10.26534366607666,
      "rewards/rejected": -7.279358863830566,
      "step": 4873
    },
    {
      "epoch": 1.9496,
      "grad_norm": 0.09086830914020538,
      "learning_rate": 3.5026666666666665e-07,
      "logits/chosen": -2.750626564025879,
      "logits/rejected": -3.1807639598846436,
      "logps/chosen": -120.19664001464844,
      "logps/rejected": -160.55569458007812,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31089556217193604,
      "rewards/margins": 7.359618186950684,
      "rewards/rejected": -7.048723220825195,
      "step": 4874
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.008068264462053776,
      "learning_rate": 3.5013333333333335e-07,
      "logits/chosen": -2.28767466545105,
      "logits/rejected": -3.1504862308502197,
      "logps/chosen": -138.59999084472656,
      "logps/rejected": -233.10989379882812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.093864917755127,
      "rewards/margins": 11.691746711730957,
      "rewards/rejected": -9.597882270812988,
      "step": 4875
    },
    {
      "epoch": 1.9504000000000001,
      "grad_norm": 0.0030645057559013367,
      "learning_rate": 3.5e-07,
      "logits/chosen": -2.1639418601989746,
      "logits/rejected": -3.876354694366455,
      "logps/chosen": -170.85430908203125,
      "logps/rejected": -224.64608764648438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3074944019317627,
      "rewards/margins": 12.028535842895508,
      "rewards/rejected": -10.721041679382324,
      "step": 4876
    },
    {
      "epoch": 1.9508,
      "grad_norm": 6.711613178253174,
      "learning_rate": 3.498666666666666e-07,
      "logits/chosen": -1.754316806793213,
      "logits/rejected": -3.0338845252990723,
      "logps/chosen": -136.7783660888672,
      "logps/rejected": -132.08102416992188,
      "loss": 0.0426,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0934501588344574,
      "rewards/margins": 5.744243621826172,
      "rewards/rejected": -5.83769416809082,
      "step": 4877
    },
    {
      "epoch": 1.9512,
      "grad_norm": 0.0011417185887694359,
      "learning_rate": 3.497333333333333e-07,
      "logits/chosen": -2.414904832839966,
      "logits/rejected": -3.268378973007202,
      "logps/chosen": -115.978759765625,
      "logps/rejected": -206.762451171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.071497678756714,
      "rewards/margins": 12.36428451538086,
      "rewards/rejected": -10.292786598205566,
      "step": 4878
    },
    {
      "epoch": 1.9516,
      "grad_norm": 0.007718413602560759,
      "learning_rate": 3.496e-07,
      "logits/chosen": -1.7818745374679565,
      "logits/rejected": -3.7338547706604004,
      "logps/chosen": -84.19561767578125,
      "logps/rejected": -197.08013916015625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6510816812515259,
      "rewards/margins": 11.114095687866211,
      "rewards/rejected": -10.463014602661133,
      "step": 4879
    },
    {
      "epoch": 1.952,
      "grad_norm": 0.0006248498102650046,
      "learning_rate": 3.4946666666666665e-07,
      "logits/chosen": -2.2183375358581543,
      "logits/rejected": -3.2057607173919678,
      "logps/chosen": -110.33396911621094,
      "logps/rejected": -274.349853515625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.945849657058716,
      "rewards/margins": 13.253312110900879,
      "rewards/rejected": -10.307462692260742,
      "step": 4880
    },
    {
      "epoch": 1.9524,
      "grad_norm": 0.14664433896541595,
      "learning_rate": 3.4933333333333334e-07,
      "logits/chosen": -1.9762405157089233,
      "logits/rejected": -3.3638439178466797,
      "logps/chosen": -136.30758666992188,
      "logps/rejected": -195.7277374267578,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5338440537452698,
      "rewards/margins": 8.764326095581055,
      "rewards/rejected": -8.230481147766113,
      "step": 4881
    },
    {
      "epoch": 1.9527999999999999,
      "grad_norm": 0.004990259651094675,
      "learning_rate": 3.492e-07,
      "logits/chosen": -1.6452592611312866,
      "logits/rejected": -3.0795655250549316,
      "logps/chosen": -93.19985961914062,
      "logps/rejected": -216.00830078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4363796710968018,
      "rewards/margins": 11.872892379760742,
      "rewards/rejected": -9.43651294708252,
      "step": 4882
    },
    {
      "epoch": 1.9532,
      "grad_norm": 0.0018784304847940803,
      "learning_rate": 3.4906666666666667e-07,
      "logits/chosen": -2.167356252670288,
      "logits/rejected": -3.300684928894043,
      "logps/chosen": -138.7317657470703,
      "logps/rejected": -193.4557342529297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6824398040771484,
      "rewards/margins": 11.527204513549805,
      "rewards/rejected": -8.844764709472656,
      "step": 4883
    },
    {
      "epoch": 1.9536,
      "grad_norm": 0.028192145749926567,
      "learning_rate": 3.489333333333333e-07,
      "logits/chosen": -1.8500171899795532,
      "logits/rejected": -3.498070478439331,
      "logps/chosen": -153.1195068359375,
      "logps/rejected": -211.19802856445312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3937538266181946,
      "rewards/margins": 10.307583808898926,
      "rewards/rejected": -9.913829803466797,
      "step": 4884
    },
    {
      "epoch": 1.954,
      "grad_norm": 0.03047986701130867,
      "learning_rate": 3.488e-07,
      "logits/chosen": -1.7591896057128906,
      "logits/rejected": -3.635571002960205,
      "logps/chosen": -90.19873046875,
      "logps/rejected": -167.86973571777344,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3441425561904907,
      "rewards/margins": 8.09228229522705,
      "rewards/rejected": -7.74813985824585,
      "step": 4885
    },
    {
      "epoch": 1.9544000000000001,
      "grad_norm": 0.03813554719090462,
      "learning_rate": 3.4866666666666664e-07,
      "logits/chosen": -1.9714698791503906,
      "logits/rejected": -3.653946876525879,
      "logps/chosen": -92.37214660644531,
      "logps/rejected": -175.01040649414062,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.445537805557251,
      "rewards/margins": 9.989225387573242,
      "rewards/rejected": -8.54368782043457,
      "step": 4886
    },
    {
      "epoch": 1.9548,
      "grad_norm": 0.02378479205071926,
      "learning_rate": 3.485333333333333e-07,
      "logits/chosen": -2.4825565814971924,
      "logits/rejected": -3.0665345191955566,
      "logps/chosen": -223.39894104003906,
      "logps/rejected": -199.60133361816406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6485366821289062,
      "rewards/margins": 9.187520027160645,
      "rewards/rejected": -7.538983345031738,
      "step": 4887
    },
    {
      "epoch": 1.9552,
      "grad_norm": 0.012470055371522903,
      "learning_rate": 3.4839999999999997e-07,
      "logits/chosen": -1.6962655782699585,
      "logits/rejected": -3.5412697792053223,
      "logps/chosen": -165.14434814453125,
      "logps/rejected": -193.3544464111328,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6069763898849487,
      "rewards/margins": 11.012958526611328,
      "rewards/rejected": -9.40598201751709,
      "step": 4888
    },
    {
      "epoch": 1.9556,
      "grad_norm": 0.02181214839220047,
      "learning_rate": 3.4826666666666666e-07,
      "logits/chosen": -1.4932889938354492,
      "logits/rejected": -3.6766366958618164,
      "logps/chosen": -96.76057434082031,
      "logps/rejected": -188.11935424804688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0346248149871826,
      "rewards/margins": 9.634675979614258,
      "rewards/rejected": -8.600051879882812,
      "step": 4889
    },
    {
      "epoch": 1.956,
      "grad_norm": 0.01996857114136219,
      "learning_rate": 3.4813333333333335e-07,
      "logits/chosen": -1.6543655395507812,
      "logits/rejected": -2.4530818462371826,
      "logps/chosen": -134.35086059570312,
      "logps/rejected": -154.72637939453125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.559001922607422,
      "rewards/margins": 9.922260284423828,
      "rewards/rejected": -7.36325740814209,
      "step": 4890
    },
    {
      "epoch": 1.9564,
      "grad_norm": 0.004166923929005861,
      "learning_rate": 3.4799999999999994e-07,
      "logits/chosen": -2.3986525535583496,
      "logits/rejected": -3.2945504188537598,
      "logps/chosen": -136.82217407226562,
      "logps/rejected": -196.54042053222656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2141098976135254,
      "rewards/margins": 10.961493492126465,
      "rewards/rejected": -7.747384071350098,
      "step": 4891
    },
    {
      "epoch": 1.9567999999999999,
      "grad_norm": 0.06674500554800034,
      "learning_rate": 3.4786666666666663e-07,
      "logits/chosen": -2.217097043991089,
      "logits/rejected": -3.266284465789795,
      "logps/chosen": -105.85443115234375,
      "logps/rejected": -162.8338623046875,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.919581949710846,
      "rewards/margins": 7.569136619567871,
      "rewards/rejected": -6.649554252624512,
      "step": 4892
    },
    {
      "epoch": 1.9572,
      "grad_norm": 0.002523054601624608,
      "learning_rate": 3.477333333333333e-07,
      "logits/chosen": -1.4753539562225342,
      "logits/rejected": -3.103731632232666,
      "logps/chosen": -87.48544311523438,
      "logps/rejected": -178.20089721679688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.571107864379883,
      "rewards/margins": 11.531707763671875,
      "rewards/rejected": -8.960599899291992,
      "step": 4893
    },
    {
      "epoch": 1.9576,
      "grad_norm": 0.000763121759518981,
      "learning_rate": 3.476e-07,
      "logits/chosen": -2.2486958503723145,
      "logits/rejected": -3.8648204803466797,
      "logps/chosen": -99.50598907470703,
      "logps/rejected": -182.87986755371094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6210498809814453,
      "rewards/margins": 12.090225219726562,
      "rewards/rejected": -9.469175338745117,
      "step": 4894
    },
    {
      "epoch": 1.958,
      "grad_norm": 0.35574713349342346,
      "learning_rate": 3.4746666666666665e-07,
      "logits/chosen": -2.1860015392303467,
      "logits/rejected": -3.1493330001831055,
      "logps/chosen": -110.78760528564453,
      "logps/rejected": -129.47596740722656,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.590719699859619,
      "rewards/margins": 7.718029975891113,
      "rewards/rejected": -5.127310752868652,
      "step": 4895
    },
    {
      "epoch": 1.9584000000000001,
      "grad_norm": 0.003824754850938916,
      "learning_rate": 3.473333333333333e-07,
      "logits/chosen": -2.394148588180542,
      "logits/rejected": -3.3547773361206055,
      "logps/chosen": -185.59078979492188,
      "logps/rejected": -190.66409301757812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3112740516662598,
      "rewards/margins": 10.498163223266602,
      "rewards/rejected": -7.186888694763184,
      "step": 4896
    },
    {
      "epoch": 1.9588,
      "grad_norm": 0.014867172576487064,
      "learning_rate": 3.472e-07,
      "logits/chosen": -2.059413194656372,
      "logits/rejected": -3.445330858230591,
      "logps/chosen": -143.20407104492188,
      "logps/rejected": -191.50494384765625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.995997667312622,
      "rewards/margins": 10.06562614440918,
      "rewards/rejected": -8.06962776184082,
      "step": 4897
    },
    {
      "epoch": 1.9592,
      "grad_norm": 0.010466971434652805,
      "learning_rate": 3.470666666666667e-07,
      "logits/chosen": -2.013038158416748,
      "logits/rejected": -2.949545383453369,
      "logps/chosen": -126.30980682373047,
      "logps/rejected": -164.89593505859375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9183791875839233,
      "rewards/margins": 9.799118041992188,
      "rewards/rejected": -7.880739212036133,
      "step": 4898
    },
    {
      "epoch": 1.9596,
      "grad_norm": 0.0050973109900951385,
      "learning_rate": 3.469333333333333e-07,
      "logits/chosen": -2.7117016315460205,
      "logits/rejected": -3.29226016998291,
      "logps/chosen": -182.45635986328125,
      "logps/rejected": -256.47509765625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8413621187210083,
      "rewards/margins": 10.621755599975586,
      "rewards/rejected": -8.780393600463867,
      "step": 4899
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.0012419902486726642,
      "learning_rate": 3.4679999999999996e-07,
      "logits/chosen": -2.7856321334838867,
      "logits/rejected": -3.2076194286346436,
      "logps/chosen": -142.78150939941406,
      "logps/rejected": -193.9358367919922,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.913611650466919,
      "rewards/margins": 11.985208511352539,
      "rewards/rejected": -9.0715970993042,
      "step": 4900
    },
    {
      "epoch": 1.9604,
      "grad_norm": 0.014296730048954487,
      "learning_rate": 3.4666666666666665e-07,
      "logits/chosen": -1.9709677696228027,
      "logits/rejected": -3.5330896377563477,
      "logps/chosen": -182.15638732910156,
      "logps/rejected": -215.37387084960938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.263232469558716,
      "rewards/margins": 9.358329772949219,
      "rewards/rejected": -7.095096588134766,
      "step": 4901
    },
    {
      "epoch": 1.9607999999999999,
      "grad_norm": 0.002607792615890503,
      "learning_rate": 3.4653333333333334e-07,
      "logits/chosen": -1.9744369983673096,
      "logits/rejected": -3.4363155364990234,
      "logps/chosen": -82.06245422363281,
      "logps/rejected": -170.64553833007812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.150101900100708,
      "rewards/margins": 10.908848762512207,
      "rewards/rejected": -8.758747100830078,
      "step": 4902
    },
    {
      "epoch": 1.9612,
      "grad_norm": 0.0022825226187705994,
      "learning_rate": 3.464e-07,
      "logits/chosen": -2.2683796882629395,
      "logits/rejected": -3.4718003273010254,
      "logps/chosen": -129.78240966796875,
      "logps/rejected": -254.3736114501953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8059773445129395,
      "rewards/margins": 11.816728591918945,
      "rewards/rejected": -11.010750770568848,
      "step": 4903
    },
    {
      "epoch": 1.9616,
      "grad_norm": 0.021176312118768692,
      "learning_rate": 3.4626666666666667e-07,
      "logits/chosen": -2.0156917572021484,
      "logits/rejected": -3.0532944202423096,
      "logps/chosen": -134.88877868652344,
      "logps/rejected": -210.6239013671875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3987793922424316,
      "rewards/margins": 8.81074333190918,
      "rewards/rejected": -6.411964416503906,
      "step": 4904
    },
    {
      "epoch": 1.962,
      "grad_norm": 0.004120052792131901,
      "learning_rate": 3.461333333333333e-07,
      "logits/chosen": -1.7849246263504028,
      "logits/rejected": -3.5545814037323,
      "logps/chosen": -87.84807586669922,
      "logps/rejected": -234.5337677001953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3646007776260376,
      "rewards/margins": 11.954416275024414,
      "rewards/rejected": -10.589815139770508,
      "step": 4905
    },
    {
      "epoch": 1.9624000000000001,
      "grad_norm": 0.001409680349752307,
      "learning_rate": 3.4599999999999995e-07,
      "logits/chosen": -2.6608328819274902,
      "logits/rejected": -3.2292919158935547,
      "logps/chosen": -199.80160522460938,
      "logps/rejected": -196.05528259277344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7456436157226562,
      "rewards/margins": 12.02220344543457,
      "rewards/rejected": -9.276559829711914,
      "step": 4906
    },
    {
      "epoch": 1.9628,
      "grad_norm": 0.006188415922224522,
      "learning_rate": 3.4586666666666664e-07,
      "logits/chosen": -2.449885845184326,
      "logits/rejected": -3.4317545890808105,
      "logps/chosen": -169.5198516845703,
      "logps/rejected": -204.43617248535156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.716468095779419,
      "rewards/margins": 11.319265365600586,
      "rewards/rejected": -8.60279655456543,
      "step": 4907
    },
    {
      "epoch": 1.9632,
      "grad_norm": 0.006183199118822813,
      "learning_rate": 3.4573333333333333e-07,
      "logits/chosen": -2.4930260181427,
      "logits/rejected": -3.4486820697784424,
      "logps/chosen": -204.30661010742188,
      "logps/rejected": -176.62147521972656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8723573684692383,
      "rewards/margins": 10.98254680633545,
      "rewards/rejected": -8.110189437866211,
      "step": 4908
    },
    {
      "epoch": 1.9636,
      "grad_norm": 0.0003796236705966294,
      "learning_rate": 3.456e-07,
      "logits/chosen": -2.200094699859619,
      "logits/rejected": -3.35487699508667,
      "logps/chosen": -105.72048950195312,
      "logps/rejected": -243.62747192382812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4732446670532227,
      "rewards/margins": 12.82597541809082,
      "rewards/rejected": -9.352731704711914,
      "step": 4909
    },
    {
      "epoch": 1.964,
      "grad_norm": 0.0019936186727136374,
      "learning_rate": 3.454666666666666e-07,
      "logits/chosen": -2.473461627960205,
      "logits/rejected": -3.1241726875305176,
      "logps/chosen": -147.7366180419922,
      "logps/rejected": -243.20912170410156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1078903675079346,
      "rewards/margins": 11.614082336425781,
      "rewards/rejected": -8.506192207336426,
      "step": 4910
    },
    {
      "epoch": 1.9644,
      "grad_norm": 0.012459526769816875,
      "learning_rate": 3.453333333333333e-07,
      "logits/chosen": -2.2445015907287598,
      "logits/rejected": -3.047905445098877,
      "logps/chosen": -90.02761840820312,
      "logps/rejected": -183.20755004882812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2086284160614014,
      "rewards/margins": 10.672178268432617,
      "rewards/rejected": -8.463550567626953,
      "step": 4911
    },
    {
      "epoch": 1.9647999999999999,
      "grad_norm": 0.034484390169382095,
      "learning_rate": 3.452e-07,
      "logits/chosen": -2.132962226867676,
      "logits/rejected": -3.55672550201416,
      "logps/chosen": -159.89920043945312,
      "logps/rejected": -198.3467559814453,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6446300745010376,
      "rewards/margins": 8.291304588317871,
      "rewards/rejected": -6.646674633026123,
      "step": 4912
    },
    {
      "epoch": 1.9651999999999998,
      "grad_norm": 0.00434865104034543,
      "learning_rate": 3.450666666666667e-07,
      "logits/chosen": -2.336735963821411,
      "logits/rejected": -3.2706995010375977,
      "logps/chosen": -158.76687622070312,
      "logps/rejected": -217.65847778320312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0415077209472656,
      "rewards/margins": 11.913684844970703,
      "rewards/rejected": -10.872177124023438,
      "step": 4913
    },
    {
      "epoch": 1.9656,
      "grad_norm": 0.0010224817087873816,
      "learning_rate": 3.4493333333333327e-07,
      "logits/chosen": -1.7244070768356323,
      "logits/rejected": -4.058351993560791,
      "logps/chosen": -76.14994812011719,
      "logps/rejected": -189.53009033203125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7935428619384766,
      "rewards/margins": 12.29703140258789,
      "rewards/rejected": -9.503488540649414,
      "step": 4914
    },
    {
      "epoch": 1.966,
      "grad_norm": 0.012963936664164066,
      "learning_rate": 3.4479999999999996e-07,
      "logits/chosen": -1.180715799331665,
      "logits/rejected": -3.583737373352051,
      "logps/chosen": -97.07669067382812,
      "logps/rejected": -183.30838012695312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.317422866821289,
      "rewards/margins": 10.33453369140625,
      "rewards/rejected": -9.017110824584961,
      "step": 4915
    },
    {
      "epoch": 1.9664000000000001,
      "grad_norm": 0.0012785124126821756,
      "learning_rate": 3.4466666666666666e-07,
      "logits/chosen": -1.6272790431976318,
      "logits/rejected": -2.503058671951294,
      "logps/chosen": -77.22335815429688,
      "logps/rejected": -175.03414916992188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0020840167999268,
      "rewards/margins": 11.769800186157227,
      "rewards/rejected": -8.767715454101562,
      "step": 4916
    },
    {
      "epoch": 1.9668,
      "grad_norm": 0.002933739684522152,
      "learning_rate": 3.4453333333333335e-07,
      "logits/chosen": -1.989248275756836,
      "logits/rejected": -2.624164342880249,
      "logps/chosen": -99.8880386352539,
      "logps/rejected": -248.5983123779297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6792314052581787,
      "rewards/margins": 10.831964492797852,
      "rewards/rejected": -8.152732849121094,
      "step": 4917
    },
    {
      "epoch": 1.9672,
      "grad_norm": 0.004351943731307983,
      "learning_rate": 3.444e-07,
      "logits/chosen": -1.8453166484832764,
      "logits/rejected": -3.8010222911834717,
      "logps/chosen": -108.76255798339844,
      "logps/rejected": -182.89842224121094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1620346307754517,
      "rewards/margins": 9.951643943786621,
      "rewards/rejected": -8.7896089553833,
      "step": 4918
    },
    {
      "epoch": 1.9676,
      "grad_norm": 0.0015573629643768072,
      "learning_rate": 3.442666666666666e-07,
      "logits/chosen": -1.5887919664382935,
      "logits/rejected": -2.9902851581573486,
      "logps/chosen": -77.40116882324219,
      "logps/rejected": -236.3657989501953,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8855462074279785,
      "rewards/margins": 12.669747352600098,
      "rewards/rejected": -8.784201622009277,
      "step": 4919
    },
    {
      "epoch": 1.968,
      "grad_norm": 0.01397646777331829,
      "learning_rate": 3.441333333333333e-07,
      "logits/chosen": -2.332054615020752,
      "logits/rejected": -3.693662166595459,
      "logps/chosen": -182.7783660888672,
      "logps/rejected": -212.46688842773438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0219032764434814,
      "rewards/margins": 9.4071044921875,
      "rewards/rejected": -8.385201454162598,
      "step": 4920
    },
    {
      "epoch": 1.9684,
      "grad_norm": 0.0006650092545896769,
      "learning_rate": 3.4399999999999996e-07,
      "logits/chosen": -2.171834707260132,
      "logits/rejected": -3.6625871658325195,
      "logps/chosen": -133.6907958984375,
      "logps/rejected": -274.3038330078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06990587711334229,
      "rewards/margins": 13.360815048217773,
      "rewards/rejected": -13.290908813476562,
      "step": 4921
    },
    {
      "epoch": 1.9687999999999999,
      "grad_norm": 0.48780548572540283,
      "learning_rate": 3.4386666666666665e-07,
      "logits/chosen": -2.706831455230713,
      "logits/rejected": -2.623055934906006,
      "logps/chosen": -137.7897491455078,
      "logps/rejected": -157.923095703125,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.531338095664978,
      "rewards/margins": 6.992362976074219,
      "rewards/rejected": -7.523701190948486,
      "step": 4922
    },
    {
      "epoch": 1.9691999999999998,
      "grad_norm": 0.000559224805328995,
      "learning_rate": 3.4373333333333334e-07,
      "logits/chosen": -1.8818089962005615,
      "logits/rejected": -3.065122604370117,
      "logps/chosen": -113.96022033691406,
      "logps/rejected": -185.79368591308594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.819044589996338,
      "rewards/margins": 13.337207794189453,
      "rewards/rejected": -9.518163681030273,
      "step": 4923
    },
    {
      "epoch": 1.9696,
      "grad_norm": 0.05848352983593941,
      "learning_rate": 3.436e-07,
      "logits/chosen": -1.9978375434875488,
      "logits/rejected": -3.582601308822632,
      "logps/chosen": -100.69156646728516,
      "logps/rejected": -182.48114013671875,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.441445827484131,
      "rewards/margins": 9.970489501953125,
      "rewards/rejected": -7.529044151306152,
      "step": 4924
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.008470498025417328,
      "learning_rate": 3.434666666666666e-07,
      "logits/chosen": -1.7707219123840332,
      "logits/rejected": -3.500873565673828,
      "logps/chosen": -94.68864440917969,
      "logps/rejected": -194.7596435546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.437758684158325,
      "rewards/margins": 11.405433654785156,
      "rewards/rejected": -8.96767520904541,
      "step": 4925
    },
    {
      "epoch": 1.9704000000000002,
      "grad_norm": 0.002447124570608139,
      "learning_rate": 3.433333333333333e-07,
      "logits/chosen": -1.8430057764053345,
      "logits/rejected": -3.1948137283325195,
      "logps/chosen": -103.92465209960938,
      "logps/rejected": -195.99209594726562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2362747192382812,
      "rewards/margins": 12.158145904541016,
      "rewards/rejected": -8.921871185302734,
      "step": 4926
    },
    {
      "epoch": 1.9708,
      "grad_norm": 0.005241016391664743,
      "learning_rate": 3.432e-07,
      "logits/chosen": -1.771496295928955,
      "logits/rejected": -3.690868854522705,
      "logps/chosen": -99.75608825683594,
      "logps/rejected": -202.31280517578125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1257137060165405,
      "rewards/margins": 11.540958404541016,
      "rewards/rejected": -10.415244102478027,
      "step": 4927
    },
    {
      "epoch": 1.9712,
      "grad_norm": 0.0035568843595683575,
      "learning_rate": 3.430666666666667e-07,
      "logits/chosen": -2.7614147663116455,
      "logits/rejected": -3.423006057739258,
      "logps/chosen": -170.41319274902344,
      "logps/rejected": -290.1165771484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2996288537979126,
      "rewards/margins": 11.11910629272461,
      "rewards/rejected": -12.41873550415039,
      "step": 4928
    },
    {
      "epoch": 1.9716,
      "grad_norm": 0.02109111286699772,
      "learning_rate": 3.429333333333333e-07,
      "logits/chosen": -1.7668657302856445,
      "logits/rejected": -3.1982715129852295,
      "logps/chosen": -105.12368774414062,
      "logps/rejected": -170.9461669921875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0601673126220703,
      "rewards/margins": 10.024371147155762,
      "rewards/rejected": -7.964203834533691,
      "step": 4929
    },
    {
      "epoch": 1.972,
      "grad_norm": 0.031147632747888565,
      "learning_rate": 3.4279999999999997e-07,
      "logits/chosen": -1.9196319580078125,
      "logits/rejected": -3.2102651596069336,
      "logps/chosen": -156.70065307617188,
      "logps/rejected": -256.11029052734375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9226127862930298,
      "rewards/margins": 8.63614273071289,
      "rewards/rejected": -6.71353006362915,
      "step": 4930
    },
    {
      "epoch": 1.9724,
      "grad_norm": 0.0005017213406972587,
      "learning_rate": 3.4266666666666666e-07,
      "logits/chosen": -1.9532666206359863,
      "logits/rejected": -3.742556095123291,
      "logps/chosen": -69.30754852294922,
      "logps/rejected": -201.80963134765625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.271286725997925,
      "rewards/margins": 12.4281005859375,
      "rewards/rejected": -9.156814575195312,
      "step": 4931
    },
    {
      "epoch": 1.9727999999999999,
      "grad_norm": 0.4786457419395447,
      "learning_rate": 3.4253333333333336e-07,
      "logits/chosen": -1.6137185096740723,
      "logits/rejected": -2.527132511138916,
      "logps/chosen": -242.3272705078125,
      "logps/rejected": -138.6638946533203,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6405655741691589,
      "rewards/margins": 7.880064964294434,
      "rewards/rejected": -7.239499092102051,
      "step": 4932
    },
    {
      "epoch": 1.9731999999999998,
      "grad_norm": 0.13248643279075623,
      "learning_rate": 3.4239999999999994e-07,
      "logits/chosen": -2.14212703704834,
      "logits/rejected": -3.0437588691711426,
      "logps/chosen": -88.15498352050781,
      "logps/rejected": -170.37857055664062,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.738999366760254,
      "rewards/margins": 9.752716064453125,
      "rewards/rejected": -7.013716697692871,
      "step": 4933
    },
    {
      "epoch": 1.9736,
      "grad_norm": 0.0548848994076252,
      "learning_rate": 3.4226666666666663e-07,
      "logits/chosen": -1.9871795177459717,
      "logits/rejected": -3.1077158451080322,
      "logps/chosen": -135.9762725830078,
      "logps/rejected": -211.91900634765625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9902858734130859,
      "rewards/margins": 8.660926818847656,
      "rewards/rejected": -7.67064094543457,
      "step": 4934
    },
    {
      "epoch": 1.974,
      "grad_norm": 0.0026379493065178394,
      "learning_rate": 3.421333333333333e-07,
      "logits/chosen": -1.7646273374557495,
      "logits/rejected": -3.4446768760681152,
      "logps/chosen": -130.70681762695312,
      "logps/rejected": -187.70054626464844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4576003551483154,
      "rewards/margins": 11.069326400756836,
      "rewards/rejected": -8.611725807189941,
      "step": 4935
    },
    {
      "epoch": 1.9744000000000002,
      "grad_norm": 0.03182735666632652,
      "learning_rate": 3.42e-07,
      "logits/chosen": -2.145176887512207,
      "logits/rejected": -2.7533154487609863,
      "logps/chosen": -89.90345764160156,
      "logps/rejected": -151.96810913085938,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0267441272735596,
      "rewards/margins": 8.529742240905762,
      "rewards/rejected": -6.502998352050781,
      "step": 4936
    },
    {
      "epoch": 1.9748,
      "grad_norm": 0.009271486662328243,
      "learning_rate": 3.4186666666666666e-07,
      "logits/chosen": -1.6689836978912354,
      "logits/rejected": -3.398660182952881,
      "logps/chosen": -85.37852478027344,
      "logps/rejected": -200.98529052734375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9982504844665527,
      "rewards/margins": 10.285691261291504,
      "rewards/rejected": -8.28744125366211,
      "step": 4937
    },
    {
      "epoch": 1.9752,
      "grad_norm": 0.048614513128995895,
      "learning_rate": 3.417333333333333e-07,
      "logits/chosen": -2.2616167068481445,
      "logits/rejected": -2.3719353675842285,
      "logps/chosen": -103.3202133178711,
      "logps/rejected": -127.138916015625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5259461402893066,
      "rewards/margins": 8.29786491394043,
      "rewards/rejected": -4.771919250488281,
      "step": 4938
    },
    {
      "epoch": 1.9756,
      "grad_norm": 0.18310922384262085,
      "learning_rate": 3.416e-07,
      "logits/chosen": -2.5061402320861816,
      "logits/rejected": -3.851428508758545,
      "logps/chosen": -184.04652404785156,
      "logps/rejected": -190.40640258789062,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.794262707233429,
      "rewards/margins": 7.3083271980285645,
      "rewards/rejected": -8.10258960723877,
      "step": 4939
    },
    {
      "epoch": 1.976,
      "grad_norm": 0.37201619148254395,
      "learning_rate": 3.4146666666666663e-07,
      "logits/chosen": -1.8138904571533203,
      "logits/rejected": -3.1857521533966064,
      "logps/chosen": -153.49720764160156,
      "logps/rejected": -148.0461883544922,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2761966586112976,
      "rewards/margins": 6.944226264953613,
      "rewards/rejected": -7.220422744750977,
      "step": 4940
    },
    {
      "epoch": 1.9764,
      "grad_norm": 0.03131093457341194,
      "learning_rate": 3.413333333333333e-07,
      "logits/chosen": -2.124877452850342,
      "logits/rejected": -3.051828145980835,
      "logps/chosen": -126.10124206542969,
      "logps/rejected": -186.61395263671875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.019549936056137085,
      "rewards/margins": 8.699769020080566,
      "rewards/rejected": -8.719319343566895,
      "step": 4941
    },
    {
      "epoch": 1.9768,
      "grad_norm": 0.17659011483192444,
      "learning_rate": 3.412e-07,
      "logits/chosen": -2.055046796798706,
      "logits/rejected": -3.026754379272461,
      "logps/chosen": -157.66094970703125,
      "logps/rejected": -129.052734375,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3162720203399658,
      "rewards/margins": 7.06906795501709,
      "rewards/rejected": -5.752796173095703,
      "step": 4942
    },
    {
      "epoch": 1.9771999999999998,
      "grad_norm": 0.026567697525024414,
      "learning_rate": 3.4106666666666665e-07,
      "logits/chosen": -2.544037103652954,
      "logits/rejected": -3.488851547241211,
      "logps/chosen": -107.86004638671875,
      "logps/rejected": -150.02157592773438,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9171978235244751,
      "rewards/margins": 8.443187713623047,
      "rewards/rejected": -7.525989532470703,
      "step": 4943
    },
    {
      "epoch": 1.9776,
      "grad_norm": 0.11426632106304169,
      "learning_rate": 3.409333333333333e-07,
      "logits/chosen": -2.7123475074768066,
      "logits/rejected": -3.2625882625579834,
      "logps/chosen": -120.72721099853516,
      "logps/rejected": -167.3776092529297,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.158250093460083,
      "rewards/margins": 7.6284589767456055,
      "rewards/rejected": -7.786708831787109,
      "step": 4944
    },
    {
      "epoch": 1.978,
      "grad_norm": 0.0030061444267630577,
      "learning_rate": 3.408e-07,
      "logits/chosen": -1.7340235710144043,
      "logits/rejected": -3.112081527709961,
      "logps/chosen": -106.68307495117188,
      "logps/rejected": -183.0631866455078,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.460688352584839,
      "rewards/margins": 11.815435409545898,
      "rewards/rejected": -8.354745864868164,
      "step": 4945
    },
    {
      "epoch": 1.9784000000000002,
      "grad_norm": 0.0015859659761190414,
      "learning_rate": 3.4066666666666667e-07,
      "logits/chosen": -1.1492069959640503,
      "logits/rejected": -3.1510534286499023,
      "logps/chosen": -79.30470275878906,
      "logps/rejected": -190.56906127929688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.813556671142578,
      "rewards/margins": 12.243210792541504,
      "rewards/rejected": -9.429654121398926,
      "step": 4946
    },
    {
      "epoch": 1.9788000000000001,
      "grad_norm": 0.03005802631378174,
      "learning_rate": 3.4053333333333337e-07,
      "logits/chosen": -1.9810521602630615,
      "logits/rejected": -3.2934272289276123,
      "logps/chosen": -176.07675170898438,
      "logps/rejected": -176.76800537109375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6636786460876465,
      "rewards/margins": 11.426145553588867,
      "rewards/rejected": -8.762466430664062,
      "step": 4947
    },
    {
      "epoch": 1.9792,
      "grad_norm": 0.0106996800750494,
      "learning_rate": 3.4039999999999995e-07,
      "logits/chosen": -2.5518264770507812,
      "logits/rejected": -3.823245048522949,
      "logps/chosen": -162.808837890625,
      "logps/rejected": -205.00631713867188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.05458030104637146,
      "rewards/margins": 9.631793975830078,
      "rewards/rejected": -9.68637466430664,
      "step": 4948
    },
    {
      "epoch": 1.9796,
      "grad_norm": 0.000437398673966527,
      "learning_rate": 3.4026666666666664e-07,
      "logits/chosen": -1.8498448133468628,
      "logits/rejected": -3.2168991565704346,
      "logps/chosen": -128.7423095703125,
      "logps/rejected": -278.38494873046875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3851404190063477,
      "rewards/margins": 13.064786911010742,
      "rewards/rejected": -9.679647445678711,
      "step": 4949
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.0014051159378141165,
      "learning_rate": 3.4013333333333334e-07,
      "logits/chosen": -1.945995569229126,
      "logits/rejected": -3.3909683227539062,
      "logps/chosen": -120.36661529541016,
      "logps/rejected": -199.31610107421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.810098648071289,
      "rewards/margins": 11.73164176940918,
      "rewards/rejected": -8.92154312133789,
      "step": 4950
    },
    {
      "epoch": 1.9804,
      "grad_norm": 1.1652299165725708,
      "learning_rate": 3.4000000000000003e-07,
      "logits/chosen": -2.315568447113037,
      "logits/rejected": -3.119441032409668,
      "logps/chosen": -120.90924072265625,
      "logps/rejected": -296.14208984375,
      "loss": 0.0068,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2032413482666016,
      "rewards/margins": 9.895146369934082,
      "rewards/rejected": -8.69190502166748,
      "step": 4951
    },
    {
      "epoch": 1.9808,
      "grad_norm": 0.007939305156469345,
      "learning_rate": 3.398666666666666e-07,
      "logits/chosen": -2.2491321563720703,
      "logits/rejected": -3.0701904296875,
      "logps/chosen": -167.61849975585938,
      "logps/rejected": -278.66546630859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9997390508651733,
      "rewards/margins": 10.194305419921875,
      "rewards/rejected": -8.194565773010254,
      "step": 4952
    },
    {
      "epoch": 1.9811999999999999,
      "grad_norm": 0.0037669865414500237,
      "learning_rate": 3.397333333333333e-07,
      "logits/chosen": -1.7133461236953735,
      "logits/rejected": -3.190873622894287,
      "logps/chosen": -161.14622497558594,
      "logps/rejected": -208.16644287109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.268714189529419,
      "rewards/margins": 11.735136032104492,
      "rewards/rejected": -9.466421127319336,
      "step": 4953
    },
    {
      "epoch": 1.9816,
      "grad_norm": 0.06007932871580124,
      "learning_rate": 3.396e-07,
      "logits/chosen": -2.1030688285827637,
      "logits/rejected": -3.3076162338256836,
      "logps/chosen": -110.64258575439453,
      "logps/rejected": -173.6759033203125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7498424053192139,
      "rewards/margins": 9.339256286621094,
      "rewards/rejected": -7.589413642883301,
      "step": 4954
    },
    {
      "epoch": 1.982,
      "grad_norm": 0.0018323783297091722,
      "learning_rate": 3.394666666666667e-07,
      "logits/chosen": -1.9970982074737549,
      "logits/rejected": -3.479848623275757,
      "logps/chosen": -137.608642578125,
      "logps/rejected": -169.33567810058594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6791794300079346,
      "rewards/margins": 11.028054237365723,
      "rewards/rejected": -7.348875045776367,
      "step": 4955
    },
    {
      "epoch": 1.9824000000000002,
      "grad_norm": 0.08366552740335464,
      "learning_rate": 3.3933333333333333e-07,
      "logits/chosen": -1.945998191833496,
      "logits/rejected": -2.826585292816162,
      "logps/chosen": -125.69474029541016,
      "logps/rejected": -212.20205688476562,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4016449451446533,
      "rewards/margins": 9.745593070983887,
      "rewards/rejected": -7.3439483642578125,
      "step": 4956
    },
    {
      "epoch": 1.9828000000000001,
      "grad_norm": 0.3579343557357788,
      "learning_rate": 3.3919999999999997e-07,
      "logits/chosen": -2.1411256790161133,
      "logits/rejected": -3.3146376609802246,
      "logps/chosen": -146.78500366210938,
      "logps/rejected": -176.6192626953125,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7869553565979004,
      "rewards/margins": 6.147163391113281,
      "rewards/rejected": -7.934118747711182,
      "step": 4957
    },
    {
      "epoch": 1.9832,
      "grad_norm": 0.3530026078224182,
      "learning_rate": 3.3906666666666666e-07,
      "logits/chosen": -2.862590789794922,
      "logits/rejected": -4.131651878356934,
      "logps/chosen": -269.68115234375,
      "logps/rejected": -227.0967559814453,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0138678550720215,
      "rewards/margins": 8.366095542907715,
      "rewards/rejected": -10.379962921142578,
      "step": 4958
    },
    {
      "epoch": 1.9836,
      "grad_norm": 0.05334249138832092,
      "learning_rate": 3.389333333333333e-07,
      "logits/chosen": -1.492706298828125,
      "logits/rejected": -3.4298336505889893,
      "logps/chosen": -115.83872985839844,
      "logps/rejected": -197.43312072753906,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.304226279258728,
      "rewards/margins": 8.765054702758789,
      "rewards/rejected": -10.069281578063965,
      "step": 4959
    },
    {
      "epoch": 1.984,
      "grad_norm": 0.010395681485533714,
      "learning_rate": 3.388e-07,
      "logits/chosen": -2.1451668739318848,
      "logits/rejected": -3.468315839767456,
      "logps/chosen": -82.13460540771484,
      "logps/rejected": -164.95718383789062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.286313056945801,
      "rewards/margins": 11.83227825164795,
      "rewards/rejected": -7.545965194702148,
      "step": 4960
    },
    {
      "epoch": 1.9844,
      "grad_norm": 0.003944049589335918,
      "learning_rate": 3.386666666666667e-07,
      "logits/chosen": -1.8961782455444336,
      "logits/rejected": -3.72147536277771,
      "logps/chosen": -87.76046752929688,
      "logps/rejected": -202.48855590820312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2112491130828857,
      "rewards/margins": 12.774456024169922,
      "rewards/rejected": -9.563206672668457,
      "step": 4961
    },
    {
      "epoch": 1.9848,
      "grad_norm": 0.0026639101561158895,
      "learning_rate": 3.385333333333333e-07,
      "logits/chosen": -1.599975347518921,
      "logits/rejected": -3.269460678100586,
      "logps/chosen": -112.73062133789062,
      "logps/rejected": -218.6377410888672,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1310238242149353,
      "rewards/margins": 10.820413589477539,
      "rewards/rejected": -10.951437950134277,
      "step": 4962
    },
    {
      "epoch": 1.9851999999999999,
      "grad_norm": 0.0009950008243322372,
      "learning_rate": 3.3839999999999996e-07,
      "logits/chosen": -2.183962345123291,
      "logits/rejected": -3.5200278759002686,
      "logps/chosen": -226.2090301513672,
      "logps/rejected": -221.77626037597656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3574737310409546,
      "rewards/margins": 12.051515579223633,
      "rewards/rejected": -10.694042205810547,
      "step": 4963
    },
    {
      "epoch": 1.9856,
      "grad_norm": 0.006886505521833897,
      "learning_rate": 3.3826666666666665e-07,
      "logits/chosen": -1.6116986274719238,
      "logits/rejected": -2.9017395973205566,
      "logps/chosen": -108.82403564453125,
      "logps/rejected": -171.71957397460938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3966431617736816,
      "rewards/margins": 10.451263427734375,
      "rewards/rejected": -8.054619789123535,
      "step": 4964
    },
    {
      "epoch": 1.986,
      "grad_norm": 0.0045156339183449745,
      "learning_rate": 3.3813333333333334e-07,
      "logits/chosen": -2.135780096054077,
      "logits/rejected": -3.1928462982177734,
      "logps/chosen": -211.7993927001953,
      "logps/rejected": -166.30201721191406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.619349718093872,
      "rewards/margins": 10.216156005859375,
      "rewards/rejected": -7.596806049346924,
      "step": 4965
    },
    {
      "epoch": 1.9864000000000002,
      "grad_norm": 0.016258234158158302,
      "learning_rate": 3.38e-07,
      "logits/chosen": -2.595360517501831,
      "logits/rejected": -3.662445306777954,
      "logps/chosen": -138.78829956054688,
      "logps/rejected": -179.2738494873047,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9126319885253906,
      "rewards/margins": 9.277350425720215,
      "rewards/rejected": -8.364718437194824,
      "step": 4966
    },
    {
      "epoch": 1.9868000000000001,
      "grad_norm": 0.011784650385379791,
      "learning_rate": 3.378666666666666e-07,
      "logits/chosen": -2.26057767868042,
      "logits/rejected": -3.3272156715393066,
      "logps/chosen": -99.81553649902344,
      "logps/rejected": -192.9443359375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6768192648887634,
      "rewards/margins": 11.145134925842285,
      "rewards/rejected": -10.468315124511719,
      "step": 4967
    },
    {
      "epoch": 1.9872,
      "grad_norm": 0.13394156098365784,
      "learning_rate": 3.377333333333333e-07,
      "logits/chosen": -1.539449691772461,
      "logits/rejected": -3.048626661300659,
      "logps/chosen": -110.43799591064453,
      "logps/rejected": -169.187744140625,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6704872846603394,
      "rewards/margins": 9.646621704101562,
      "rewards/rejected": -7.976134300231934,
      "step": 4968
    },
    {
      "epoch": 1.9876,
      "grad_norm": 0.15178848803043365,
      "learning_rate": 3.376e-07,
      "logits/chosen": -2.1697444915771484,
      "logits/rejected": -3.060664176940918,
      "logps/chosen": -219.14031982421875,
      "logps/rejected": -199.06793212890625,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3359642028808594,
      "rewards/margins": 7.7539963722229,
      "rewards/rejected": -7.418032169342041,
      "step": 4969
    },
    {
      "epoch": 1.988,
      "grad_norm": 0.00313477567397058,
      "learning_rate": 3.374666666666667e-07,
      "logits/chosen": -2.218111991882324,
      "logits/rejected": -3.463271141052246,
      "logps/chosen": -105.87275695800781,
      "logps/rejected": -213.4207000732422,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.533703327178955,
      "rewards/margins": 12.037933349609375,
      "rewards/rejected": -8.504229545593262,
      "step": 4970
    },
    {
      "epoch": 1.9884,
      "grad_norm": 0.0072461869567632675,
      "learning_rate": 3.373333333333333e-07,
      "logits/chosen": -1.9339888095855713,
      "logits/rejected": -3.225433349609375,
      "logps/chosen": -98.34210205078125,
      "logps/rejected": -146.5603485107422,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9561352729797363,
      "rewards/margins": 11.219301223754883,
      "rewards/rejected": -7.263166427612305,
      "step": 4971
    },
    {
      "epoch": 1.9888,
      "grad_norm": 0.0020371684804558754,
      "learning_rate": 3.372e-07,
      "logits/chosen": -1.7305667400360107,
      "logits/rejected": -3.6673059463500977,
      "logps/chosen": -138.587890625,
      "logps/rejected": -190.09432983398438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.401571750640869,
      "rewards/margins": 12.701751708984375,
      "rewards/rejected": -10.300179481506348,
      "step": 4972
    },
    {
      "epoch": 1.9891999999999999,
      "grad_norm": 0.09280966222286224,
      "learning_rate": 3.3706666666666667e-07,
      "logits/chosen": -2.2566285133361816,
      "logits/rejected": -3.275881290435791,
      "logps/chosen": -184.4253692626953,
      "logps/rejected": -171.464599609375,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8634341955184937,
      "rewards/margins": 8.939783096313477,
      "rewards/rejected": -7.076348304748535,
      "step": 4973
    },
    {
      "epoch": 1.9896,
      "grad_norm": 0.025196025148034096,
      "learning_rate": 3.369333333333333e-07,
      "logits/chosen": -2.070634365081787,
      "logits/rejected": -3.5044476985931396,
      "logps/chosen": -139.1989288330078,
      "logps/rejected": -213.87283325195312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8282489776611328,
      "rewards/margins": 10.769892692565918,
      "rewards/rejected": -9.941643714904785,
      "step": 4974
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.004121100064367056,
      "learning_rate": 3.368e-07,
      "logits/chosen": -2.6269423961639404,
      "logits/rejected": -3.0163817405700684,
      "logps/chosen": -153.18862915039062,
      "logps/rejected": -209.18313598632812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6491775512695312,
      "rewards/margins": 10.844503402709961,
      "rewards/rejected": -8.19532585144043,
      "step": 4975
    },
    {
      "epoch": 1.9904,
      "grad_norm": 0.007729704491794109,
      "learning_rate": 3.3666666666666664e-07,
      "logits/chosen": -2.356959342956543,
      "logits/rejected": -2.3684587478637695,
      "logps/chosen": -137.1300811767578,
      "logps/rejected": -269.5759582519531,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3798530101776123,
      "rewards/margins": 10.024554252624512,
      "rewards/rejected": -8.64470100402832,
      "step": 4976
    },
    {
      "epoch": 1.9908000000000001,
      "grad_norm": 0.0005456194630824029,
      "learning_rate": 3.3653333333333333e-07,
      "logits/chosen": -1.9207773208618164,
      "logits/rejected": -3.4798026084899902,
      "logps/chosen": -162.70001220703125,
      "logps/rejected": -223.36915588378906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0132408142089844,
      "rewards/margins": 13.057188034057617,
      "rewards/rejected": -10.043946266174316,
      "step": 4977
    },
    {
      "epoch": 1.9912,
      "grad_norm": 0.0018222056096419692,
      "learning_rate": 3.3639999999999997e-07,
      "logits/chosen": -1.865262508392334,
      "logits/rejected": -2.398247241973877,
      "logps/chosen": -131.2842559814453,
      "logps/rejected": -191.99856567382812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1956939697265625,
      "rewards/margins": 11.5088529586792,
      "rewards/rejected": -8.313158988952637,
      "step": 4978
    },
    {
      "epoch": 1.9916,
      "grad_norm": 0.035621292889118195,
      "learning_rate": 3.3626666666666666e-07,
      "logits/chosen": -1.8156846761703491,
      "logits/rejected": -3.392871856689453,
      "logps/chosen": -96.37931823730469,
      "logps/rejected": -206.44564819335938,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14077985286712646,
      "rewards/margins": 9.260437965393066,
      "rewards/rejected": -9.119658470153809,
      "step": 4979
    },
    {
      "epoch": 1.992,
      "grad_norm": 0.027919379994273186,
      "learning_rate": 3.361333333333333e-07,
      "logits/chosen": -1.8908610343933105,
      "logits/rejected": -1.9061775207519531,
      "logps/chosen": -88.84530639648438,
      "logps/rejected": -152.18992614746094,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8122849464416504,
      "rewards/margins": 8.46987533569336,
      "rewards/rejected": -6.657590866088867,
      "step": 4980
    },
    {
      "epoch": 1.9924,
      "grad_norm": 0.0005059909890405834,
      "learning_rate": 3.36e-07,
      "logits/chosen": -2.3730592727661133,
      "logits/rejected": -3.180389642715454,
      "logps/chosen": -128.84515380859375,
      "logps/rejected": -200.75660705566406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.309004306793213,
      "rewards/margins": 12.957681655883789,
      "rewards/rejected": -9.648676872253418,
      "step": 4981
    },
    {
      "epoch": 1.9928,
      "grad_norm": 0.0008528095204383135,
      "learning_rate": 3.3586666666666663e-07,
      "logits/chosen": -1.9543368816375732,
      "logits/rejected": -3.3555960655212402,
      "logps/chosen": -95.04656982421875,
      "logps/rejected": -190.62245178222656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.266486167907715,
      "rewards/margins": 12.792000770568848,
      "rewards/rejected": -9.525514602661133,
      "step": 4982
    },
    {
      "epoch": 1.9931999999999999,
      "grad_norm": 0.001379123074002564,
      "learning_rate": 3.357333333333333e-07,
      "logits/chosen": -1.8431386947631836,
      "logits/rejected": -3.781097173690796,
      "logps/chosen": -82.8925552368164,
      "logps/rejected": -213.52920532226562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9458466172218323,
      "rewards/margins": 11.833288192749023,
      "rewards/rejected": -10.887441635131836,
      "step": 4983
    },
    {
      "epoch": 1.9936,
      "grad_norm": 0.44122305512428284,
      "learning_rate": 3.356e-07,
      "logits/chosen": -1.8223192691802979,
      "logits/rejected": -3.0263943672180176,
      "logps/chosen": -145.21377563476562,
      "logps/rejected": -148.470703125,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07247310876846313,
      "rewards/margins": 7.448620319366455,
      "rewards/rejected": -7.376147270202637,
      "step": 4984
    },
    {
      "epoch": 1.994,
      "grad_norm": 0.0003843719605356455,
      "learning_rate": 3.3546666666666665e-07,
      "logits/chosen": -1.6910791397094727,
      "logits/rejected": -3.8113718032836914,
      "logps/chosen": -91.57318878173828,
      "logps/rejected": -208.55410766601562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5655455589294434,
      "rewards/margins": 13.092010498046875,
      "rewards/rejected": -10.526464462280273,
      "step": 4985
    },
    {
      "epoch": 1.9944,
      "grad_norm": 0.010343269445002079,
      "learning_rate": 3.353333333333333e-07,
      "logits/chosen": -2.0932536125183105,
      "logits/rejected": -3.032968759536743,
      "logps/chosen": -156.62930297851562,
      "logps/rejected": -163.73590087890625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.428796410560608,
      "rewards/margins": 9.391712188720703,
      "rewards/rejected": -7.962916374206543,
      "step": 4986
    },
    {
      "epoch": 1.9948000000000001,
      "grad_norm": 0.024735745042562485,
      "learning_rate": 3.352e-07,
      "logits/chosen": -2.233144760131836,
      "logits/rejected": -2.604212522506714,
      "logps/chosen": -85.13365173339844,
      "logps/rejected": -146.27911376953125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8094398975372314,
      "rewards/margins": 9.656662940979004,
      "rewards/rejected": -6.847223281860352,
      "step": 4987
    },
    {
      "epoch": 1.9952,
      "grad_norm": 0.0008595592807978392,
      "learning_rate": 3.350666666666667e-07,
      "logits/chosen": -1.9349168539047241,
      "logits/rejected": -3.329531192779541,
      "logps/chosen": -125.41098022460938,
      "logps/rejected": -208.1192626953125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.3969831466674805,
      "rewards/margins": 13.44091796875,
      "rewards/rejected": -9.04393482208252,
      "step": 4988
    },
    {
      "epoch": 1.9956,
      "grad_norm": 0.010205495171248913,
      "learning_rate": 3.3493333333333337e-07,
      "logits/chosen": -1.9275182485580444,
      "logits/rejected": -3.4900259971618652,
      "logps/chosen": -122.9129638671875,
      "logps/rejected": -172.89724731445312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2920265197753906,
      "rewards/margins": 11.18360710144043,
      "rewards/rejected": -7.891580581665039,
      "step": 4989
    },
    {
      "epoch": 1.996,
      "grad_norm": 0.00954354926943779,
      "learning_rate": 3.3479999999999995e-07,
      "logits/chosen": -1.8734638690948486,
      "logits/rejected": -3.188281774520874,
      "logps/chosen": -166.0930938720703,
      "logps/rejected": -142.26321411132812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.422445058822632,
      "rewards/margins": 9.72343635559082,
      "rewards/rejected": -6.300991535186768,
      "step": 4990
    },
    {
      "epoch": 1.9964,
      "grad_norm": 0.015260443091392517,
      "learning_rate": 3.3466666666666665e-07,
      "logits/chosen": -1.8124721050262451,
      "logits/rejected": -3.4289534091949463,
      "logps/chosen": -203.99583435058594,
      "logps/rejected": -188.48391723632812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1355034112930298,
      "rewards/margins": 9.748313903808594,
      "rewards/rejected": -8.612811088562012,
      "step": 4991
    },
    {
      "epoch": 1.9968,
      "grad_norm": 0.0006349539034999907,
      "learning_rate": 3.3453333333333334e-07,
      "logits/chosen": -2.0455245971679688,
      "logits/rejected": -3.5850071907043457,
      "logps/chosen": -106.5951919555664,
      "logps/rejected": -199.49839782714844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.341228485107422,
      "rewards/margins": 14.346026420593262,
      "rewards/rejected": -11.004796981811523,
      "step": 4992
    },
    {
      "epoch": 1.9971999999999999,
      "grad_norm": 0.004886073060333729,
      "learning_rate": 3.344e-07,
      "logits/chosen": -2.2311768531799316,
      "logits/rejected": -3.372858762741089,
      "logps/chosen": -97.00921630859375,
      "logps/rejected": -150.46749877929688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.231234550476074,
      "rewards/margins": 10.392171859741211,
      "rewards/rejected": -7.160938262939453,
      "step": 4993
    },
    {
      "epoch": 1.9976,
      "grad_norm": 0.0014757568715140224,
      "learning_rate": 3.342666666666666e-07,
      "logits/chosen": -2.5754923820495605,
      "logits/rejected": -3.1692779064178467,
      "logps/chosen": -163.47201538085938,
      "logps/rejected": -189.6632537841797,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.029247760772705,
      "rewards/margins": 11.334577560424805,
      "rewards/rejected": -7.305329322814941,
      "step": 4994
    },
    {
      "epoch": 1.998,
      "grad_norm": 0.14609403908252716,
      "learning_rate": 3.341333333333333e-07,
      "logits/chosen": -1.4341683387756348,
      "logits/rejected": -3.074298858642578,
      "logps/chosen": -98.67630004882812,
      "logps/rejected": -169.68272399902344,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.33094102144241333,
      "rewards/margins": 6.552778720855713,
      "rewards/rejected": -6.883719444274902,
      "step": 4995
    },
    {
      "epoch": 1.9984,
      "grad_norm": 0.0009252672898583114,
      "learning_rate": 3.34e-07,
      "logits/chosen": -2.6296210289001465,
      "logits/rejected": -3.159435272216797,
      "logps/chosen": -138.98419189453125,
      "logps/rejected": -227.89776611328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5289626121520996,
      "rewards/margins": 12.041888236999512,
      "rewards/rejected": -8.51292610168457,
      "step": 4996
    },
    {
      "epoch": 1.9988000000000001,
      "grad_norm": 0.003678601700812578,
      "learning_rate": 3.3386666666666664e-07,
      "logits/chosen": -2.3935036659240723,
      "logits/rejected": -3.8395614624023438,
      "logps/chosen": -104.54777526855469,
      "logps/rejected": -207.88095092773438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.027878999710083,
      "rewards/margins": 11.846429824829102,
      "rewards/rejected": -9.818550109863281,
      "step": 4997
    },
    {
      "epoch": 1.9992,
      "grad_norm": 0.0017036785138770938,
      "learning_rate": 3.3373333333333333e-07,
      "logits/chosen": -1.6636836528778076,
      "logits/rejected": -2.881356716156006,
      "logps/chosen": -120.59591674804688,
      "logps/rejected": -210.003173828125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3759121000766754,
      "rewards/margins": 11.404975891113281,
      "rewards/rejected": -11.780887603759766,
      "step": 4998
    },
    {
      "epoch": 1.9996,
      "grad_norm": 0.020158227533102036,
      "learning_rate": 3.3359999999999997e-07,
      "logits/chosen": -2.3113765716552734,
      "logits/rejected": -3.566039562225342,
      "logps/chosen": -110.3930892944336,
      "logps/rejected": -188.70657348632812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.171189308166504,
      "rewards/margins": 11.312948226928711,
      "rewards/rejected": -9.141759872436523,
      "step": 4999
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.018913477659225464,
      "learning_rate": 3.3346666666666666e-07,
      "logits/chosen": -1.797281265258789,
      "logits/rejected": -3.3413867950439453,
      "logps/chosen": -96.83007049560547,
      "logps/rejected": -185.1614532470703,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1708579063415527,
      "rewards/margins": 10.581761360168457,
      "rewards/rejected": -7.410902976989746,
      "step": 5000
    }
  ],
  "logging_steps": 1,
  "max_steps": 7500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
