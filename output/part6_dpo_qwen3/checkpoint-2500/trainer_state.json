{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 2500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0004,
      "grad_norm": 15.268645286560059,
      "learning_rate": 1e-06,
      "logits/chosen": -2.0962538719177246,
      "logits/rejected": -1.5989779233932495,
      "logps/chosen": -141.30502319335938,
      "logps/rejected": -97.38442993164062,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 1
    },
    {
      "epoch": 0.0008,
      "grad_norm": 18.559490203857422,
      "learning_rate": 9.998666666666665e-07,
      "logits/chosen": -1.7126741409301758,
      "logits/rejected": -1.8161518573760986,
      "logps/chosen": -139.18313598632812,
      "logps/rejected": -95.85646057128906,
      "loss": 0.6952,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.02568512037396431,
      "rewards/margins": -0.0036640167236328125,
      "rewards/rejected": -0.022021103650331497,
      "step": 2
    },
    {
      "epoch": 0.0012,
      "grad_norm": 20.533489227294922,
      "learning_rate": 9.997333333333333e-07,
      "logits/chosen": -2.177920341491699,
      "logits/rejected": -2.4348926544189453,
      "logps/chosen": -169.28517150878906,
      "logps/rejected": -124.09404754638672,
      "loss": 0.7149,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.002748871222138405,
      "rewards/margins": -0.04219131916761398,
      "rewards/rejected": 0.03944244235754013,
      "step": 3
    },
    {
      "epoch": 0.0016,
      "grad_norm": 15.507535934448242,
      "learning_rate": 9.996e-07,
      "logits/chosen": -1.7446495294570923,
      "logits/rejected": -1.632487177848816,
      "logps/chosen": -130.4578857421875,
      "logps/rejected": -86.64102172851562,
      "loss": 0.7189,
      "rewards/accuracies": 0.0,
      "rewards/chosen": -0.005595779046416283,
      "rewards/margins": -0.050760649144649506,
      "rewards/rejected": 0.04516487196087837,
      "step": 4
    },
    {
      "epoch": 0.002,
      "grad_norm": 15.394692420959473,
      "learning_rate": 9.994666666666665e-07,
      "logits/chosen": -2.273918867111206,
      "logits/rejected": -1.559133529663086,
      "logps/chosen": -124.44734191894531,
      "logps/rejected": -126.39563751220703,
      "loss": 0.6834,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.035858917981386185,
      "rewards/margins": 0.02031593583524227,
      "rewards/rejected": 0.015542984008789062,
      "step": 5
    },
    {
      "epoch": 0.0024,
      "grad_norm": 18.38969612121582,
      "learning_rate": 9.993333333333333e-07,
      "logits/chosen": -1.7581608295440674,
      "logits/rejected": -2.2266016006469727,
      "logps/chosen": -126.73479461669922,
      "logps/rejected": -96.23471069335938,
      "loss": 0.7004,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0033397674560546875,
      "rewards/margins": -0.012259293347597122,
      "rewards/rejected": 0.008919524028897285,
      "step": 6
    },
    {
      "epoch": 0.0028,
      "grad_norm": 17.38357162475586,
      "learning_rate": 9.992e-07,
      "logits/chosen": -1.8269122838974,
      "logits/rejected": -1.7972356081008911,
      "logps/chosen": -141.53372192382812,
      "logps/rejected": -126.15385437011719,
      "loss": 0.6665,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07202110439538956,
      "rewards/margins": 0.05435600504279137,
      "rewards/rejected": 0.01766509935259819,
      "step": 7
    },
    {
      "epoch": 0.0032,
      "grad_norm": 18.870851516723633,
      "learning_rate": 9.990666666666667e-07,
      "logits/chosen": -1.7665770053863525,
      "logits/rejected": -1.974238395690918,
      "logps/chosen": -133.5233154296875,
      "logps/rejected": -133.27151489257812,
      "loss": 0.6895,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0028987883124500513,
      "rewards/margins": 0.007365417201071978,
      "rewards/rejected": -0.00446662912145257,
      "step": 8
    },
    {
      "epoch": 0.0036,
      "grad_norm": 13.048956871032715,
      "learning_rate": 9.989333333333333e-07,
      "logits/chosen": -1.7168858051300049,
      "logits/rejected": -1.8025894165039062,
      "logps/chosen": -134.64039611816406,
      "logps/rejected": -104.56708526611328,
      "loss": 0.6712,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020360182970762253,
      "rewards/margins": 0.044315338134765625,
      "rewards/rejected": -0.023955155164003372,
      "step": 9
    },
    {
      "epoch": 0.004,
      "grad_norm": 13.940608024597168,
      "learning_rate": 9.988e-07,
      "logits/chosen": -1.7688770294189453,
      "logits/rejected": -1.8757812976837158,
      "logps/chosen": -116.80616760253906,
      "logps/rejected": -78.88996124267578,
      "loss": 0.6877,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.018634416162967682,
      "rewards/margins": 0.010954665951430798,
      "rewards/rejected": -0.029589081183075905,
      "step": 10
    },
    {
      "epoch": 0.0044,
      "grad_norm": 22.395299911499023,
      "learning_rate": 9.986666666666667e-07,
      "logits/chosen": -1.8239552974700928,
      "logits/rejected": -2.7285313606262207,
      "logps/chosen": -199.5662384033203,
      "logps/rejected": -157.8272705078125,
      "loss": 0.6664,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06701354682445526,
      "rewards/margins": 0.054311372339725494,
      "rewards/rejected": 0.012702180072665215,
      "step": 11
    },
    {
      "epoch": 0.0048,
      "grad_norm": 17.99517822265625,
      "learning_rate": 9.985333333333332e-07,
      "logits/chosen": -2.072694778442383,
      "logits/rejected": -2.5550262928009033,
      "logps/chosen": -142.35650634765625,
      "logps/rejected": -147.95098876953125,
      "loss": 0.6832,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0028808601200580597,
      "rewards/margins": 0.020740129053592682,
      "rewards/rejected": -0.017859268933534622,
      "step": 12
    },
    {
      "epoch": 0.0052,
      "grad_norm": 16.15470314025879,
      "learning_rate": 9.983999999999998e-07,
      "logits/chosen": -1.6167486906051636,
      "logits/rejected": -1.5138400793075562,
      "logps/chosen": -130.76853942871094,
      "logps/rejected": -88.59736633300781,
      "loss": 0.6808,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.00668678293004632,
      "rewards/margins": 0.024772262200713158,
      "rewards/rejected": -0.03145904466509819,
      "step": 13
    },
    {
      "epoch": 0.0056,
      "grad_norm": 15.526069641113281,
      "learning_rate": 9.982666666666666e-07,
      "logits/chosen": -1.855992078781128,
      "logits/rejected": -1.3738099336624146,
      "logps/chosen": -148.4079132080078,
      "logps/rejected": -91.90140533447266,
      "loss": 0.6657,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.055754851549863815,
      "rewards/margins": 0.05648994445800781,
      "rewards/rejected": -0.0007350919768214226,
      "step": 14
    },
    {
      "epoch": 0.006,
      "grad_norm": 16.91189956665039,
      "learning_rate": 9.981333333333332e-07,
      "logits/chosen": -2.034663200378418,
      "logits/rejected": -1.628522515296936,
      "logps/chosen": -129.13966369628906,
      "logps/rejected": -93.59890747070312,
      "loss": 0.6893,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.014293290674686432,
      "rewards/margins": 0.007852554321289062,
      "rewards/rejected": 0.006440735422074795,
      "step": 15
    },
    {
      "epoch": 0.0064,
      "grad_norm": 17.97140121459961,
      "learning_rate": 9.98e-07,
      "logits/chosen": -1.9350566864013672,
      "logits/rejected": -1.5779852867126465,
      "logps/chosen": -129.540283203125,
      "logps/rejected": -86.20384216308594,
      "loss": 0.6755,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.011561967432498932,
      "rewards/margins": 0.03553657606244087,
      "rewards/rejected": -0.02397460862994194,
      "step": 16
    },
    {
      "epoch": 0.0068,
      "grad_norm": 16.75215721130371,
      "learning_rate": 9.978666666666666e-07,
      "logits/chosen": -1.766183614730835,
      "logits/rejected": -2.2132043838500977,
      "logps/chosen": -124.06391143798828,
      "logps/rejected": -108.18140411376953,
      "loss": 0.705,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.02003936842083931,
      "rewards/margins": -0.02303924411535263,
      "rewards/rejected": 0.0029998784884810448,
      "step": 17
    },
    {
      "epoch": 0.0072,
      "grad_norm": 18.881425857543945,
      "learning_rate": 9.977333333333334e-07,
      "logits/chosen": -1.9784189462661743,
      "logits/rejected": -2.3239870071411133,
      "logps/chosen": -165.9981689453125,
      "logps/rejected": -114.57511901855469,
      "loss": 0.6597,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.025995636358857155,
      "rewards/margins": 0.06869659572839737,
      "rewards/rejected": -0.042700957506895065,
      "step": 18
    },
    {
      "epoch": 0.0076,
      "grad_norm": 14.448744773864746,
      "learning_rate": 9.976e-07,
      "logits/chosen": -1.8071515560150146,
      "logits/rejected": -1.889855980873108,
      "logps/chosen": -128.1116485595703,
      "logps/rejected": -91.82168579101562,
      "loss": 0.6835,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.008287429809570312,
      "rewards/margins": 0.019606400281190872,
      "rewards/rejected": -0.027893828228116035,
      "step": 19
    },
    {
      "epoch": 0.008,
      "grad_norm": 18.2933406829834,
      "learning_rate": 9.974666666666666e-07,
      "logits/chosen": -1.5390557050704956,
      "logits/rejected": -1.9970080852508545,
      "logps/chosen": -117.3240737915039,
      "logps/rejected": -123.45561981201172,
      "loss": 0.6855,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.030649185180664062,
      "rewards/margins": 0.015288161113858223,
      "rewards/rejected": 0.01536102406680584,
      "step": 20
    },
    {
      "epoch": 0.0084,
      "grad_norm": 12.873006820678711,
      "learning_rate": 9.973333333333332e-07,
      "logits/chosen": -1.898914098739624,
      "logits/rejected": -1.7070127725601196,
      "logps/chosen": -109.45529174804688,
      "logps/rejected": -84.67681884765625,
      "loss": 0.7054,
      "rewards/accuracies": 0.0,
      "rewards/chosen": -0.03913498297333717,
      "rewards/margins": -0.024189379066228867,
      "rewards/rejected": -0.014945602975785732,
      "step": 21
    },
    {
      "epoch": 0.0088,
      "grad_norm": 19.545398712158203,
      "learning_rate": 9.972e-07,
      "logits/chosen": -1.7529393434524536,
      "logits/rejected": -2.02059268951416,
      "logps/chosen": -147.76353454589844,
      "logps/rejected": -114.94943237304688,
      "loss": 0.6594,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08001403510570526,
      "rewards/margins": 0.06916351616382599,
      "rewards/rejected": 0.010850525461137295,
      "step": 22
    },
    {
      "epoch": 0.0092,
      "grad_norm": 19.397075653076172,
      "learning_rate": 9.970666666666665e-07,
      "logits/chosen": -2.4685115814208984,
      "logits/rejected": -2.187530279159546,
      "logps/chosen": -215.649658203125,
      "logps/rejected": -111.81138610839844,
      "loss": 0.6663,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.028031159192323685,
      "rewards/margins": 0.05489311367273331,
      "rewards/rejected": -0.026861954480409622,
      "step": 23
    },
    {
      "epoch": 0.0096,
      "grad_norm": 15.801180839538574,
      "learning_rate": 9.969333333333333e-07,
      "logits/chosen": -1.7768816947937012,
      "logits/rejected": -1.8414264917373657,
      "logps/chosen": -126.51141357421875,
      "logps/rejected": -85.896240234375,
      "loss": 0.711,
      "rewards/accuracies": 0.0,
      "rewards/chosen": -0.03930091857910156,
      "rewards/margins": -0.03543281555175781,
      "rewards/rejected": -0.00386810302734375,
      "step": 24
    },
    {
      "epoch": 0.01,
      "grad_norm": 16.18854522705078,
      "learning_rate": 9.968e-07,
      "logits/chosen": -2.1684629917144775,
      "logits/rejected": -1.6804865598678589,
      "logps/chosen": -163.31649780273438,
      "logps/rejected": -106.45844268798828,
      "loss": 0.6711,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03536529839038849,
      "rewards/margins": 0.044553376734256744,
      "rewards/rejected": -0.009188080206513405,
      "step": 25
    },
    {
      "epoch": 0.0104,
      "grad_norm": 22.206920623779297,
      "learning_rate": 9.966666666666667e-07,
      "logits/chosen": -2.4919862747192383,
      "logits/rejected": -2.34519100189209,
      "logps/chosen": -218.3912811279297,
      "logps/rejected": -129.6809539794922,
      "loss": 0.6925,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.007659912109375,
      "rewards/margins": 0.0018981937319040298,
      "rewards/rejected": 0.0057617188431322575,
      "step": 26
    },
    {
      "epoch": 0.0108,
      "grad_norm": 17.785036087036133,
      "learning_rate": 9.965333333333333e-07,
      "logits/chosen": -1.7693232297897339,
      "logits/rejected": -1.965179204940796,
      "logps/chosen": -140.98226928710938,
      "logps/rejected": -85.98965454101562,
      "loss": 0.7028,
      "rewards/accuracies": 0.0,
      "rewards/chosen": -0.006244277581572533,
      "rewards/margins": -0.01911010779440403,
      "rewards/rejected": 0.012865829281508923,
      "step": 27
    },
    {
      "epoch": 0.0112,
      "grad_norm": 16.0792179107666,
      "learning_rate": 9.964e-07,
      "logits/chosen": -2.009298324584961,
      "logits/rejected": -2.608586549758911,
      "logps/chosen": -110.61824035644531,
      "logps/rejected": -90.97868347167969,
      "loss": 0.7047,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.01475448627024889,
      "rewards/margins": -0.022517776116728783,
      "rewards/rejected": 0.03727226331830025,
      "step": 28
    },
    {
      "epoch": 0.0116,
      "grad_norm": 14.745043754577637,
      "learning_rate": 9.962666666666667e-07,
      "logits/chosen": -2.267284393310547,
      "logits/rejected": -1.7393840551376343,
      "logps/chosen": -138.57550048828125,
      "logps/rejected": -93.46116638183594,
      "loss": 0.6822,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.016648102551698685,
      "rewards/margins": 0.021984100341796875,
      "rewards/rejected": -0.005335998721420765,
      "step": 29
    },
    {
      "epoch": 0.012,
      "grad_norm": 18.98749542236328,
      "learning_rate": 9.961333333333333e-07,
      "logits/chosen": -1.769726037979126,
      "logits/rejected": -1.8742523193359375,
      "logps/chosen": -131.3254852294922,
      "logps/rejected": -107.02200317382812,
      "loss": 0.6856,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.058469776064157486,
      "rewards/margins": 0.015188600867986679,
      "rewards/rejected": 0.04328117147088051,
      "step": 30
    },
    {
      "epoch": 0.0124,
      "grad_norm": 19.522212982177734,
      "learning_rate": 9.959999999999999e-07,
      "logits/chosen": -2.2330358028411865,
      "logits/rejected": -2.1218183040618896,
      "logps/chosen": -237.57534790039062,
      "logps/rejected": -114.80904388427734,
      "loss": 0.6729,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.00352325476706028,
      "rewards/margins": 0.04116630554199219,
      "rewards/rejected": -0.04468956217169762,
      "step": 31
    },
    {
      "epoch": 0.0128,
      "grad_norm": 19.63932228088379,
      "learning_rate": 9.958666666666667e-07,
      "logits/chosen": -2.412781238555908,
      "logits/rejected": -1.7499345541000366,
      "logps/chosen": -206.09365844726562,
      "logps/rejected": -67.52679443359375,
      "loss": 0.6589,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04961395263671875,
      "rewards/margins": 0.06969451904296875,
      "rewards/rejected": -0.02008056640625,
      "step": 32
    },
    {
      "epoch": 0.0132,
      "grad_norm": 17.69650650024414,
      "learning_rate": 9.957333333333332e-07,
      "logits/chosen": -1.6253671646118164,
      "logits/rejected": -2.033331871032715,
      "logps/chosen": -113.88346862792969,
      "logps/rejected": -85.34220886230469,
      "loss": 0.6979,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.030107498168945312,
      "rewards/margins": -0.009000398218631744,
      "rewards/rejected": 0.03910789638757706,
      "step": 33
    },
    {
      "epoch": 0.0136,
      "grad_norm": 19.4537296295166,
      "learning_rate": 9.956e-07,
      "logits/chosen": -2.076167345046997,
      "logits/rejected": -2.3828537464141846,
      "logps/chosen": -161.0933837890625,
      "logps/rejected": -115.01722717285156,
      "loss": 0.6896,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019722746685147285,
      "rewards/margins": 0.007160949055105448,
      "rewards/rejected": 0.012561798095703125,
      "step": 34
    },
    {
      "epoch": 0.014,
      "grad_norm": 22.96538543701172,
      "learning_rate": 9.954666666666666e-07,
      "logits/chosen": -2.3133888244628906,
      "logits/rejected": -2.6402382850646973,
      "logps/chosen": -209.50311279296875,
      "logps/rejected": -127.80835723876953,
      "loss": 0.6735,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.007847595028579235,
      "rewards/margins": 0.040604401379823685,
      "rewards/rejected": -0.032756805419921875,
      "step": 35
    },
    {
      "epoch": 0.0144,
      "grad_norm": 23.46953010559082,
      "learning_rate": 9.953333333333332e-07,
      "logits/chosen": -1.634922981262207,
      "logits/rejected": -2.367600917816162,
      "logps/chosen": -125.64468383789062,
      "logps/rejected": -189.32369995117188,
      "loss": 0.6942,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.03695335611701012,
      "rewards/margins": -0.0020725224167108536,
      "rewards/rejected": 0.03902588039636612,
      "step": 36
    },
    {
      "epoch": 0.0148,
      "grad_norm": 14.803617477416992,
      "learning_rate": 9.952e-07,
      "logits/chosen": -1.7581226825714111,
      "logits/rejected": -1.3446294069290161,
      "logps/chosen": -121.99390411376953,
      "logps/rejected": -98.12307739257812,
      "loss": 0.6683,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0010826103389263153,
      "rewards/margins": 0.050516895949840546,
      "rewards/rejected": -0.05159950256347656,
      "step": 37
    },
    {
      "epoch": 0.0152,
      "grad_norm": 14.754836082458496,
      "learning_rate": 9.950666666666666e-07,
      "logits/chosen": -1.575131893157959,
      "logits/rejected": -1.665920376777649,
      "logps/chosen": -101.79885864257812,
      "logps/rejected": -84.91105651855469,
      "loss": 0.6709,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01482238806784153,
      "rewards/margins": 0.045107267796993256,
      "rewards/rejected": -0.030284881591796875,
      "step": 38
    },
    {
      "epoch": 0.0156,
      "grad_norm": 18.52816390991211,
      "learning_rate": 9.949333333333332e-07,
      "logits/chosen": -1.7090415954589844,
      "logits/rejected": -1.9603424072265625,
      "logps/chosen": -177.39813232421875,
      "logps/rejected": -105.76730346679688,
      "loss": 0.659,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08289527893066406,
      "rewards/margins": 0.06985321640968323,
      "rewards/rejected": 0.013042068108916283,
      "step": 39
    },
    {
      "epoch": 0.016,
      "grad_norm": 18.07594108581543,
      "learning_rate": 9.948e-07,
      "logits/chosen": -1.9365999698638916,
      "logits/rejected": -2.733116865158081,
      "logps/chosen": -167.9061279296875,
      "logps/rejected": -158.46560668945312,
      "loss": 0.663,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04372558742761612,
      "rewards/margins": 0.06185455247759819,
      "rewards/rejected": -0.01812896691262722,
      "step": 40
    },
    {
      "epoch": 0.0164,
      "grad_norm": 28.139802932739258,
      "learning_rate": 9.946666666666666e-07,
      "logits/chosen": -2.7157182693481445,
      "logits/rejected": -2.0608575344085693,
      "logps/chosen": -240.67324829101562,
      "logps/rejected": -160.4871826171875,
      "loss": 0.6837,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.034554291516542435,
      "rewards/margins": 0.019081879407167435,
      "rewards/rejected": 0.015472412109375,
      "step": 41
    },
    {
      "epoch": 0.0168,
      "grad_norm": 26.66353988647461,
      "learning_rate": 9.945333333333334e-07,
      "logits/chosen": -2.552783489227295,
      "logits/rejected": -2.6458077430725098,
      "logps/chosen": -286.088134765625,
      "logps/rejected": -99.53726196289062,
      "loss": 0.6683,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04709625244140625,
      "rewards/margins": 0.0504859983921051,
      "rewards/rejected": -0.0033897398971021175,
      "step": 42
    },
    {
      "epoch": 0.0172,
      "grad_norm": 15.103856086730957,
      "learning_rate": 9.944e-07,
      "logits/chosen": -1.8241989612579346,
      "logits/rejected": -2.387251377105713,
      "logps/chosen": -146.152587890625,
      "logps/rejected": -113.26583099365234,
      "loss": 0.6544,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09020271897315979,
      "rewards/margins": 0.07922706753015518,
      "rewards/rejected": 0.010975646786391735,
      "step": 43
    },
    {
      "epoch": 0.0176,
      "grad_norm": 17.608186721801758,
      "learning_rate": 9.942666666666665e-07,
      "logits/chosen": -2.0570569038391113,
      "logits/rejected": -1.9006211757659912,
      "logps/chosen": -135.58775329589844,
      "logps/rejected": -94.543701171875,
      "loss": 0.674,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01442489679902792,
      "rewards/margins": 0.03878059610724449,
      "rewards/rejected": -0.024355698376893997,
      "step": 44
    },
    {
      "epoch": 0.018,
      "grad_norm": 16.249309539794922,
      "learning_rate": 9.941333333333333e-07,
      "logits/chosen": -1.7012863159179688,
      "logits/rejected": -2.4735844135284424,
      "logps/chosen": -154.8673553466797,
      "logps/rejected": -103.80404663085938,
      "loss": 0.666,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06349410861730576,
      "rewards/margins": 0.055002592504024506,
      "rewards/rejected": 0.00849151611328125,
      "step": 45
    },
    {
      "epoch": 0.0184,
      "grad_norm": 14.00233268737793,
      "learning_rate": 9.94e-07,
      "logits/chosen": -1.9254735708236694,
      "logits/rejected": -1.9299339056015015,
      "logps/chosen": -132.3321533203125,
      "logps/rejected": -104.31640625,
      "loss": 0.6873,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.02253417670726776,
      "rewards/margins": 0.012893673032522202,
      "rewards/rejected": 0.00964050367474556,
      "step": 46
    },
    {
      "epoch": 0.0188,
      "grad_norm": 26.015302658081055,
      "learning_rate": 9.938666666666667e-07,
      "logits/chosen": -1.9186015129089355,
      "logits/rejected": -2.4075851440429688,
      "logps/chosen": -150.0072479248047,
      "logps/rejected": -225.1713409423828,
      "loss": 0.6628,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06930770725011826,
      "rewards/margins": 0.062042236328125,
      "rewards/rejected": 0.0072654723189771175,
      "step": 47
    },
    {
      "epoch": 0.0192,
      "grad_norm": 18.922983169555664,
      "learning_rate": 9.937333333333333e-07,
      "logits/chosen": -2.0237221717834473,
      "logits/rejected": -1.920959234237671,
      "logps/chosen": -166.958251953125,
      "logps/rejected": -81.97706604003906,
      "loss": 0.6518,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07478408515453339,
      "rewards/margins": 0.08478470146656036,
      "rewards/rejected": -0.01000061072409153,
      "step": 48
    },
    {
      "epoch": 0.0196,
      "grad_norm": 17.02379608154297,
      "learning_rate": 9.936e-07,
      "logits/chosen": -2.1564223766326904,
      "logits/rejected": -2.026033878326416,
      "logps/chosen": -143.2440185546875,
      "logps/rejected": -97.61506652832031,
      "loss": 0.6755,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.01055984478443861,
      "rewards/margins": 0.03626212850213051,
      "rewards/rejected": -0.04682197794318199,
      "step": 49
    },
    {
      "epoch": 0.02,
      "grad_norm": 17.77133560180664,
      "learning_rate": 9.934666666666667e-07,
      "logits/chosen": -1.6027106046676636,
      "logits/rejected": -2.0677852630615234,
      "logps/chosen": -91.84933471679688,
      "logps/rejected": -101.90319061279297,
      "loss": 0.6699,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.05220756679773331,
      "rewards/margins": 0.04782600700855255,
      "rewards/rejected": 0.0043815611861646175,
      "step": 50
    },
    {
      "epoch": 0.0204,
      "grad_norm": 28.90410614013672,
      "learning_rate": 9.933333333333333e-07,
      "logits/chosen": -2.1330180168151855,
      "logits/rejected": -2.8160853385925293,
      "logps/chosen": -275.0372619628906,
      "logps/rejected": -194.62237548828125,
      "loss": 0.6836,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03525543212890625,
      "rewards/margins": 0.01934356614947319,
      "rewards/rejected": 0.01591186597943306,
      "step": 51
    },
    {
      "epoch": 0.0208,
      "grad_norm": 20.151111602783203,
      "learning_rate": 9.931999999999999e-07,
      "logits/chosen": -2.281667709350586,
      "logits/rejected": -2.1183063983917236,
      "logps/chosen": -256.320556640625,
      "logps/rejected": -89.94184875488281,
      "loss": 0.6999,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.01470108050853014,
      "rewards/margins": -0.012873077765107155,
      "rewards/rejected": -0.001828002743422985,
      "step": 52
    },
    {
      "epoch": 0.0212,
      "grad_norm": 17.802396774291992,
      "learning_rate": 9.930666666666667e-07,
      "logits/chosen": -2.1729109287261963,
      "logits/rejected": -2.3027310371398926,
      "logps/chosen": -125.382568359375,
      "logps/rejected": -104.61614990234375,
      "loss": 0.7013,
      "rewards/accuracies": 0.0,
      "rewards/chosen": -0.015759658068418503,
      "rewards/margins": -0.016231916844844818,
      "rewards/rejected": 0.0004722587764263153,
      "step": 53
    },
    {
      "epoch": 0.0216,
      "grad_norm": 15.116493225097656,
      "learning_rate": 9.929333333333333e-07,
      "logits/chosen": -1.6753242015838623,
      "logits/rejected": -1.476914405822754,
      "logps/chosen": -130.230224609375,
      "logps/rejected": -78.7014389038086,
      "loss": 0.6874,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.007488632574677467,
      "rewards/margins": 0.0115203857421875,
      "rewards/rejected": -0.019009018316864967,
      "step": 54
    },
    {
      "epoch": 0.022,
      "grad_norm": 16.937232971191406,
      "learning_rate": 9.928e-07,
      "logits/chosen": -1.8340983390808105,
      "logits/rejected": -2.377750873565674,
      "logps/chosen": -150.10707092285156,
      "logps/rejected": -131.81777954101562,
      "loss": 0.6534,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06528015434741974,
      "rewards/margins": 0.0814308226108551,
      "rewards/rejected": -0.016150664538145065,
      "step": 55
    },
    {
      "epoch": 0.0224,
      "grad_norm": 20.31101417541504,
      "learning_rate": 9.926666666666666e-07,
      "logits/chosen": -2.332122802734375,
      "logits/rejected": -2.5658206939697266,
      "logps/chosen": -232.4404296875,
      "logps/rejected": -100.7155990600586,
      "loss": 0.6372,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10222168266773224,
      "rewards/margins": 0.11526603996753693,
      "rewards/rejected": -0.013044358231127262,
      "step": 56
    },
    {
      "epoch": 0.0228,
      "grad_norm": 15.842887878417969,
      "learning_rate": 9.925333333333334e-07,
      "logits/chosen": -1.8553822040557861,
      "logits/rejected": -1.6204549074172974,
      "logps/chosen": -132.67355346679688,
      "logps/rejected": -113.84458923339844,
      "loss": 0.6595,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.048065185546875,
      "rewards/margins": 0.06971053779125214,
      "rewards/rejected": -0.021645354107022285,
      "step": 57
    },
    {
      "epoch": 0.0232,
      "grad_norm": 14.077000617980957,
      "learning_rate": 9.923999999999998e-07,
      "logits/chosen": -2.0795702934265137,
      "logits/rejected": -2.0205037593841553,
      "logps/chosen": -114.88067626953125,
      "logps/rejected": -88.38291931152344,
      "loss": 0.6731,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.034580230712890625,
      "rewards/margins": 0.04043465107679367,
      "rewards/rejected": -0.00585441617295146,
      "step": 58
    },
    {
      "epoch": 0.0236,
      "grad_norm": 12.676863670349121,
      "learning_rate": 9.922666666666666e-07,
      "logits/chosen": -1.5518436431884766,
      "logits/rejected": -1.1851948499679565,
      "logps/chosen": -115.12754821777344,
      "logps/rejected": -78.93302154541016,
      "loss": 0.6566,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0667518600821495,
      "rewards/margins": 0.07456283271312714,
      "rewards/rejected": -0.00781097449362278,
      "step": 59
    },
    {
      "epoch": 0.024,
      "grad_norm": 17.23594093322754,
      "learning_rate": 9.921333333333332e-07,
      "logits/chosen": -1.828049659729004,
      "logits/rejected": -2.867356061935425,
      "logps/chosen": -125.35696411132812,
      "logps/rejected": -108.71138000488281,
      "loss": 0.6362,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10068587958812714,
      "rewards/margins": 0.117401123046875,
      "rewards/rejected": -0.016715239733457565,
      "step": 60
    },
    {
      "epoch": 0.0244,
      "grad_norm": 17.488977432250977,
      "learning_rate": 9.92e-07,
      "logits/chosen": -1.9849358797073364,
      "logits/rejected": -2.3513412475585938,
      "logps/chosen": -142.21914672851562,
      "logps/rejected": -114.14791870117188,
      "loss": 0.6758,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.035797882825136185,
      "rewards/margins": 0.03527183458209038,
      "rewards/rejected": 0.0005260473117232323,
      "step": 61
    },
    {
      "epoch": 0.0248,
      "grad_norm": 15.173555374145508,
      "learning_rate": 9.918666666666666e-07,
      "logits/chosen": -1.553051233291626,
      "logits/rejected": -1.2227493524551392,
      "logps/chosen": -143.1680145263672,
      "logps/rejected": -94.0614013671875,
      "loss": 0.6518,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05357170104980469,
      "rewards/margins": 0.08518867939710617,
      "rewards/rejected": -0.031616974622011185,
      "step": 62
    },
    {
      "epoch": 0.0252,
      "grad_norm": 20.562759399414062,
      "learning_rate": 9.917333333333334e-07,
      "logits/chosen": -2.055173873901367,
      "logits/rejected": -1.8441481590270996,
      "logps/chosen": -169.99073791503906,
      "logps/rejected": -103.92961120605469,
      "loss": 0.6329,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09799766540527344,
      "rewards/margins": 0.12439727783203125,
      "rewards/rejected": -0.026399612426757812,
      "step": 63
    },
    {
      "epoch": 0.0256,
      "grad_norm": 22.30881118774414,
      "learning_rate": 9.916e-07,
      "logits/chosen": -2.46634578704834,
      "logits/rejected": -2.5149569511413574,
      "logps/chosen": -210.63673400878906,
      "logps/rejected": -112.09579467773438,
      "loss": 0.6602,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.004399871453642845,
      "rewards/margins": 0.06797905266284943,
      "rewards/rejected": -0.07237891852855682,
      "step": 64
    },
    {
      "epoch": 0.026,
      "grad_norm": 14.843899726867676,
      "learning_rate": 9.914666666666668e-07,
      "logits/chosen": -1.829179286956787,
      "logits/rejected": -1.9911881685256958,
      "logps/chosen": -161.7623291015625,
      "logps/rejected": -110.47225952148438,
      "loss": 0.6592,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01631317101418972,
      "rewards/margins": 0.07014846801757812,
      "rewards/rejected": -0.053835298866033554,
      "step": 65
    },
    {
      "epoch": 0.0264,
      "grad_norm": 19.764955520629883,
      "learning_rate": 9.913333333333333e-07,
      "logits/chosen": -2.2900290489196777,
      "logits/rejected": -2.396500587463379,
      "logps/chosen": -148.09092712402344,
      "logps/rejected": -148.50753784179688,
      "loss": 0.6542,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05524139478802681,
      "rewards/margins": 0.07956542819738388,
      "rewards/rejected": -0.02432403527200222,
      "step": 66
    },
    {
      "epoch": 0.0268,
      "grad_norm": 24.845687866210938,
      "learning_rate": 9.912e-07,
      "logits/chosen": -2.068051815032959,
      "logits/rejected": -2.160712957382202,
      "logps/chosen": -180.23828125,
      "logps/rejected": -170.91012573242188,
      "loss": 0.6355,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.042337801307439804,
      "rewards/margins": 0.11898232251405716,
      "rewards/rejected": -0.07664451748132706,
      "step": 67
    },
    {
      "epoch": 0.0272,
      "grad_norm": 14.874155044555664,
      "learning_rate": 9.910666666666665e-07,
      "logits/chosen": -1.7558984756469727,
      "logits/rejected": -1.6776914596557617,
      "logps/chosen": -120.3953857421875,
      "logps/rejected": -97.99595642089844,
      "loss": 0.6484,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08037300407886505,
      "rewards/margins": 0.09183350205421448,
      "rewards/rejected": -0.011460496112704277,
      "step": 68
    },
    {
      "epoch": 0.0276,
      "grad_norm": 16.714710235595703,
      "learning_rate": 9.909333333333333e-07,
      "logits/chosen": -2.105867862701416,
      "logits/rejected": -1.7474136352539062,
      "logps/chosen": -131.31967163085938,
      "logps/rejected": -95.01858520507812,
      "loss": 0.6717,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.13812561333179474,
      "rewards/margins": 0.04423561319708824,
      "rewards/rejected": 0.0938899964094162,
      "step": 69
    },
    {
      "epoch": 0.028,
      "grad_norm": 22.11811637878418,
      "learning_rate": 9.908e-07,
      "logits/chosen": -2.5218067169189453,
      "logits/rejected": -3.0962352752685547,
      "logps/chosen": -252.256103515625,
      "logps/rejected": -146.64378356933594,
      "loss": 0.6412,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06695175170898438,
      "rewards/margins": 0.10682182013988495,
      "rewards/rejected": -0.03987007215619087,
      "step": 70
    },
    {
      "epoch": 0.0284,
      "grad_norm": 12.963066101074219,
      "learning_rate": 9.906666666666667e-07,
      "logits/chosen": -1.8854413032531738,
      "logits/rejected": -2.2844231128692627,
      "logps/chosen": -130.07159423828125,
      "logps/rejected": -90.880859375,
      "loss": 0.664,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.034569550305604935,
      "rewards/margins": 0.0590946227312088,
      "rewards/rejected": -0.024525070562958717,
      "step": 71
    },
    {
      "epoch": 0.0288,
      "grad_norm": 18.709592819213867,
      "learning_rate": 9.905333333333333e-07,
      "logits/chosen": -1.9021315574645996,
      "logits/rejected": -1.7508814334869385,
      "logps/chosen": -146.32740783691406,
      "logps/rejected": -106.37086486816406,
      "loss": 0.6439,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11481171101331711,
      "rewards/margins": 0.10113830864429474,
      "rewards/rejected": 0.01367340236902237,
      "step": 72
    },
    {
      "epoch": 0.0292,
      "grad_norm": 19.694570541381836,
      "learning_rate": 9.903999999999999e-07,
      "logits/chosen": -2.229421854019165,
      "logits/rejected": -2.2215378284454346,
      "logps/chosen": -165.1767120361328,
      "logps/rejected": -136.94815063476562,
      "loss": 0.657,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.04168663173913956,
      "rewards/margins": 0.07518959045410156,
      "rewards/rejected": -0.033502958714962006,
      "step": 73
    },
    {
      "epoch": 0.0296,
      "grad_norm": 17.84062957763672,
      "learning_rate": 9.902666666666667e-07,
      "logits/chosen": -1.838245153427124,
      "logits/rejected": -2.0767107009887695,
      "logps/chosen": -205.581787109375,
      "logps/rejected": -120.64607238769531,
      "loss": 0.6661,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03529052808880806,
      "rewards/margins": 0.05486908182501793,
      "rewards/rejected": -0.01957855373620987,
      "step": 74
    },
    {
      "epoch": 0.03,
      "grad_norm": 15.731291770935059,
      "learning_rate": 9.901333333333333e-07,
      "logits/chosen": -2.0329017639160156,
      "logits/rejected": -1.7718348503112793,
      "logps/chosen": -136.8147430419922,
      "logps/rejected": -83.40031433105469,
      "loss": 0.6685,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06049766391515732,
      "rewards/margins": 0.04989662021398544,
      "rewards/rejected": 0.010601043701171875,
      "step": 75
    },
    {
      "epoch": 0.0304,
      "grad_norm": 19.705913543701172,
      "learning_rate": 9.9e-07,
      "logits/chosen": -1.9686598777770996,
      "logits/rejected": -0.6899585723876953,
      "logps/chosen": -150.36831665039062,
      "logps/rejected": -90.32443237304688,
      "loss": 0.6831,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01732788048684597,
      "rewards/margins": 0.020177077502012253,
      "rewards/rejected": -0.00284919748082757,
      "step": 76
    },
    {
      "epoch": 0.0308,
      "grad_norm": 13.857951164245605,
      "learning_rate": 9.898666666666666e-07,
      "logits/chosen": -1.7545959949493408,
      "logits/rejected": -2.328512668609619,
      "logps/chosen": -98.66815185546875,
      "logps/rejected": -89.36514282226562,
      "loss": 0.6828,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.029914094135165215,
      "rewards/margins": 0.02077026292681694,
      "rewards/rejected": 0.009143829345703125,
      "step": 77
    },
    {
      "epoch": 0.0312,
      "grad_norm": 17.667057037353516,
      "learning_rate": 9.897333333333332e-07,
      "logits/chosen": -1.9052948951721191,
      "logits/rejected": -2.7356977462768555,
      "logps/chosen": -134.87713623046875,
      "logps/rejected": -109.49652099609375,
      "loss": 0.613,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09220504760742188,
      "rewards/margins": 0.16733360290527344,
      "rewards/rejected": -0.07512855529785156,
      "step": 78
    },
    {
      "epoch": 0.0316,
      "grad_norm": 15.39405345916748,
      "learning_rate": 9.896e-07,
      "logits/chosen": -1.70086669921875,
      "logits/rejected": -1.9838168621063232,
      "logps/chosen": -117.1656723022461,
      "logps/rejected": -95.73876953125,
      "loss": 0.6874,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0034526826348155737,
      "rewards/margins": 0.011592102237045765,
      "rewards/rejected": -0.015044784173369408,
      "step": 79
    },
    {
      "epoch": 0.032,
      "grad_norm": 14.087607383728027,
      "learning_rate": 9.894666666666666e-07,
      "logits/chosen": -1.9575486183166504,
      "logits/rejected": -1.1111326217651367,
      "logps/chosen": -141.99407958984375,
      "logps/rejected": -91.0013427734375,
      "loss": 0.6428,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.102686308324337,
      "rewards/margins": 0.10444411635398865,
      "rewards/rejected": -0.001757812686264515,
      "step": 80
    },
    {
      "epoch": 0.0324,
      "grad_norm": 15.958888053894043,
      "learning_rate": 9.893333333333332e-07,
      "logits/chosen": -1.6057820320129395,
      "logits/rejected": -2.064767599105835,
      "logps/chosen": -94.27120971679688,
      "logps/rejected": -87.64957427978516,
      "loss": 0.6481,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03683318942785263,
      "rewards/margins": 0.09215393662452698,
      "rewards/rejected": -0.05532074347138405,
      "step": 81
    },
    {
      "epoch": 0.0328,
      "grad_norm": 16.293102264404297,
      "learning_rate": 9.892e-07,
      "logits/chosen": -1.5957437753677368,
      "logits/rejected": -1.8465337753295898,
      "logps/chosen": -119.57984924316406,
      "logps/rejected": -88.26005554199219,
      "loss": 0.6893,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.004384231753647327,
      "rewards/margins": 0.007747269235551357,
      "rewards/rejected": -0.00336303748190403,
      "step": 82
    },
    {
      "epoch": 0.0332,
      "grad_norm": 12.743635177612305,
      "learning_rate": 9.890666666666666e-07,
      "logits/chosen": -1.608886480331421,
      "logits/rejected": -1.7567203044891357,
      "logps/chosen": -90.18060302734375,
      "logps/rejected": -75.48092651367188,
      "loss": 0.6602,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07611121982336044,
      "rewards/margins": 0.06724701076745987,
      "rewards/rejected": 0.008864211849868298,
      "step": 83
    },
    {
      "epoch": 0.0336,
      "grad_norm": 17.19230842590332,
      "learning_rate": 9.889333333333334e-07,
      "logits/chosen": -1.568068504333496,
      "logits/rejected": -1.3784832954406738,
      "logps/chosen": -110.80276489257812,
      "logps/rejected": -85.98505401611328,
      "loss": 0.6522,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1103740707039833,
      "rewards/margins": 0.08369942009449005,
      "rewards/rejected": 0.026674650609493256,
      "step": 84
    },
    {
      "epoch": 0.034,
      "grad_norm": 14.33228588104248,
      "learning_rate": 9.888e-07,
      "logits/chosen": -2.0637664794921875,
      "logits/rejected": -1.5569608211517334,
      "logps/chosen": -126.31349182128906,
      "logps/rejected": -99.03831481933594,
      "loss": 0.6052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16483306884765625,
      "rewards/margins": 0.1844886839389801,
      "rewards/rejected": -0.019655609503388405,
      "step": 85
    },
    {
      "epoch": 0.0344,
      "grad_norm": 14.69825267791748,
      "learning_rate": 9.886666666666665e-07,
      "logits/chosen": -1.5927397012710571,
      "logits/rejected": -1.7374259233474731,
      "logps/chosen": -122.82614135742188,
      "logps/rejected": -82.06378173828125,
      "loss": 0.6525,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026733780279755592,
      "rewards/margins": 0.08368492126464844,
      "rewards/rejected": -0.056951142847537994,
      "step": 86
    },
    {
      "epoch": 0.0348,
      "grad_norm": 20.375770568847656,
      "learning_rate": 9.885333333333333e-07,
      "logits/chosen": -2.048142910003662,
      "logits/rejected": -1.8018927574157715,
      "logps/chosen": -143.46107482910156,
      "logps/rejected": -112.17155456542969,
      "loss": 0.5996,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15129432082176208,
      "rewards/margins": 0.19732627272605896,
      "rewards/rejected": -0.046031951904296875,
      "step": 87
    },
    {
      "epoch": 0.0352,
      "grad_norm": 19.477373123168945,
      "learning_rate": 9.884e-07,
      "logits/chosen": -1.7977895736694336,
      "logits/rejected": -2.172156810760498,
      "logps/chosen": -160.9176483154297,
      "logps/rejected": -79.54032897949219,
      "loss": 0.6106,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14735642075538635,
      "rewards/margins": 0.1725563108921051,
      "rewards/rejected": -0.02519989013671875,
      "step": 88
    },
    {
      "epoch": 0.0356,
      "grad_norm": 16.732576370239258,
      "learning_rate": 9.882666666666665e-07,
      "logits/chosen": -2.046168804168701,
      "logits/rejected": -1.484595537185669,
      "logps/chosen": -144.45005798339844,
      "logps/rejected": -85.40672302246094,
      "loss": 0.658,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07279892265796661,
      "rewards/margins": 0.07154503464698792,
      "rewards/rejected": 0.0012538908049464226,
      "step": 89
    },
    {
      "epoch": 0.036,
      "grad_norm": 12.772564888000488,
      "learning_rate": 9.881333333333333e-07,
      "logits/chosen": -1.839338779449463,
      "logits/rejected": -1.7328921556472778,
      "logps/chosen": -105.72523498535156,
      "logps/rejected": -94.20047760009766,
      "loss": 0.6471,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08348732441663742,
      "rewards/margins": 0.09457817673683167,
      "rewards/rejected": -0.01109085138887167,
      "step": 90
    },
    {
      "epoch": 0.0364,
      "grad_norm": 18.13473892211914,
      "learning_rate": 9.88e-07,
      "logits/chosen": -1.6932276487350464,
      "logits/rejected": -2.6458075046539307,
      "logps/chosen": -143.515380859375,
      "logps/rejected": -123.06657409667969,
      "loss": 0.6363,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10314521938562393,
      "rewards/margins": 0.11795349419116974,
      "rewards/rejected": -0.014808272942900658,
      "step": 91
    },
    {
      "epoch": 0.0368,
      "grad_norm": 21.661787033081055,
      "learning_rate": 9.878666666666667e-07,
      "logits/chosen": -2.432231903076172,
      "logits/rejected": -1.718930721282959,
      "logps/chosen": -279.097900390625,
      "logps/rejected": -102.74058532714844,
      "loss": 0.5476,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.237091064453125,
      "rewards/margins": 0.31601715087890625,
      "rewards/rejected": -0.07892608642578125,
      "step": 92
    },
    {
      "epoch": 0.0372,
      "grad_norm": 13.998065948486328,
      "learning_rate": 9.877333333333333e-07,
      "logits/chosen": -1.7183303833007812,
      "logits/rejected": -2.075889825820923,
      "logps/chosen": -103.90614318847656,
      "logps/rejected": -98.4964370727539,
      "loss": 0.6837,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0732646957039833,
      "rewards/margins": 0.018997954204678535,
      "rewards/rejected": 0.05426674336194992,
      "step": 93
    },
    {
      "epoch": 0.0376,
      "grad_norm": 13.255802154541016,
      "learning_rate": 9.876e-07,
      "logits/chosen": -1.629063367843628,
      "logits/rejected": -1.3524420261383057,
      "logps/chosen": -129.51748657226562,
      "logps/rejected": -88.32110595703125,
      "loss": 0.6221,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06403236836194992,
      "rewards/margins": 0.1475570797920227,
      "rewards/rejected": -0.08352470397949219,
      "step": 94
    },
    {
      "epoch": 0.038,
      "grad_norm": 15.666373252868652,
      "learning_rate": 9.874666666666667e-07,
      "logits/chosen": -1.5227608680725098,
      "logits/rejected": -1.709985613822937,
      "logps/chosen": -102.67716979980469,
      "logps/rejected": -74.5689697265625,
      "loss": 0.65,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.04401397705078125,
      "rewards/margins": 0.09072533249855042,
      "rewards/rejected": -0.04671135172247887,
      "step": 95
    },
    {
      "epoch": 0.0384,
      "grad_norm": 18.292804718017578,
      "learning_rate": 9.873333333333333e-07,
      "logits/chosen": -2.000744342803955,
      "logits/rejected": -2.0697855949401855,
      "logps/chosen": -177.24237060546875,
      "logps/rejected": -124.65414428710938,
      "loss": 0.6231,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.068090058863163,
      "rewards/margins": 0.14673499763011932,
      "rewards/rejected": -0.07864494621753693,
      "step": 96
    },
    {
      "epoch": 0.0388,
      "grad_norm": 13.980618476867676,
      "learning_rate": 9.871999999999998e-07,
      "logits/chosen": -1.7916755676269531,
      "logits/rejected": -1.7037749290466309,
      "logps/chosen": -144.85272216796875,
      "logps/rejected": -93.83772277832031,
      "loss": 0.6107,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11533279716968536,
      "rewards/margins": 0.17354965209960938,
      "rewards/rejected": -0.05821686238050461,
      "step": 97
    },
    {
      "epoch": 0.0392,
      "grad_norm": 16.345590591430664,
      "learning_rate": 9.870666666666666e-07,
      "logits/chosen": -1.9776489734649658,
      "logits/rejected": -2.353071689605713,
      "logps/chosen": -163.74359130859375,
      "logps/rejected": -117.38883972167969,
      "loss": 0.6493,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11024323105812073,
      "rewards/margins": 0.08994331955909729,
      "rewards/rejected": 0.020299911499023438,
      "step": 98
    },
    {
      "epoch": 0.0396,
      "grad_norm": 18.39475440979004,
      "learning_rate": 9.869333333333332e-07,
      "logits/chosen": -1.7298741340637207,
      "logits/rejected": -2.0405936241149902,
      "logps/chosen": -145.92327880859375,
      "logps/rejected": -123.8099365234375,
      "loss": 0.6391,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13484573364257812,
      "rewards/margins": 0.11129799485206604,
      "rewards/rejected": 0.023547744378447533,
      "step": 99
    },
    {
      "epoch": 0.04,
      "grad_norm": 18.886127471923828,
      "learning_rate": 9.868e-07,
      "logits/chosen": -1.6741081476211548,
      "logits/rejected": -2.3774328231811523,
      "logps/chosen": -139.03604125976562,
      "logps/rejected": -141.11602783203125,
      "loss": 0.6239,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1066841185092926,
      "rewards/margins": 0.1436203122138977,
      "rewards/rejected": -0.036936189979314804,
      "step": 100
    },
    {
      "epoch": 0.0404,
      "grad_norm": 19.56816291809082,
      "learning_rate": 9.866666666666666e-07,
      "logits/chosen": -1.8933100700378418,
      "logits/rejected": -2.4314823150634766,
      "logps/chosen": -152.89767456054688,
      "logps/rejected": -106.08081817626953,
      "loss": 0.6222,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09491425007581711,
      "rewards/margins": 0.14737015962600708,
      "rewards/rejected": -0.052455902099609375,
      "step": 101
    },
    {
      "epoch": 0.0408,
      "grad_norm": 16.520334243774414,
      "learning_rate": 9.865333333333334e-07,
      "logits/chosen": -1.8958203792572021,
      "logits/rejected": -2.0363762378692627,
      "logps/chosen": -122.16990661621094,
      "logps/rejected": -97.57208251953125,
      "loss": 0.6312,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08582305908203125,
      "rewards/margins": 0.12985363602638245,
      "rewards/rejected": -0.0440305732190609,
      "step": 102
    },
    {
      "epoch": 0.0412,
      "grad_norm": 18.3576602935791,
      "learning_rate": 9.864e-07,
      "logits/chosen": -1.419433355331421,
      "logits/rejected": -2.140188217163086,
      "logps/chosen": -183.26040649414062,
      "logps/rejected": -135.98756408691406,
      "loss": 0.6334,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04486045613884926,
      "rewards/margins": 0.12506599724292755,
      "rewards/rejected": -0.080205537378788,
      "step": 103
    },
    {
      "epoch": 0.0416,
      "grad_norm": 21.300661087036133,
      "learning_rate": 9.862666666666666e-07,
      "logits/chosen": -2.4994099140167236,
      "logits/rejected": -2.2457401752471924,
      "logps/chosen": -211.32351684570312,
      "logps/rejected": -91.309814453125,
      "loss": 0.575,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21860963106155396,
      "rewards/margins": 0.25278663635253906,
      "rewards/rejected": -0.0341770201921463,
      "step": 104
    },
    {
      "epoch": 0.042,
      "grad_norm": 12.334599494934082,
      "learning_rate": 9.861333333333332e-07,
      "logits/chosen": -1.6656514406204224,
      "logits/rejected": -1.077675461769104,
      "logps/chosen": -114.31867980957031,
      "logps/rejected": -79.24226379394531,
      "loss": 0.6386,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11570052802562714,
      "rewards/margins": 0.11301612854003906,
      "rewards/rejected": 0.002684403210878372,
      "step": 105
    },
    {
      "epoch": 0.0424,
      "grad_norm": 14.970508575439453,
      "learning_rate": 9.86e-07,
      "logits/chosen": -1.445604681968689,
      "logits/rejected": -0.9720816612243652,
      "logps/chosen": -156.21939086914062,
      "logps/rejected": -71.15359497070312,
      "loss": 0.6528,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04674339294433594,
      "rewards/margins": 0.08315467834472656,
      "rewards/rejected": -0.036411285400390625,
      "step": 106
    },
    {
      "epoch": 0.0428,
      "grad_norm": 22.000452041625977,
      "learning_rate": 9.858666666666665e-07,
      "logits/chosen": -2.3113765716552734,
      "logits/rejected": -2.401641368865967,
      "logps/chosen": -229.74722290039062,
      "logps/rejected": -145.42892456054688,
      "loss": 0.6542,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12602311372756958,
      "rewards/margins": 0.07960586994886398,
      "rewards/rejected": 0.046417236328125,
      "step": 107
    },
    {
      "epoch": 0.0432,
      "grad_norm": 13.101555824279785,
      "learning_rate": 9.857333333333333e-07,
      "logits/chosen": -1.3077367544174194,
      "logits/rejected": -1.9646720886230469,
      "logps/chosen": -95.53903198242188,
      "logps/rejected": -104.07557678222656,
      "loss": 0.6654,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02707367017865181,
      "rewards/margins": 0.056795503944158554,
      "rewards/rejected": -0.029721833765506744,
      "step": 108
    },
    {
      "epoch": 0.0436,
      "grad_norm": 16.839040756225586,
      "learning_rate": 9.856e-07,
      "logits/chosen": -2.109894275665283,
      "logits/rejected": -2.1068825721740723,
      "logps/chosen": -132.70985412597656,
      "logps/rejected": -108.37861633300781,
      "loss": 0.6411,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07268676906824112,
      "rewards/margins": 0.10908546298742294,
      "rewards/rejected": -0.03639869764447212,
      "step": 109
    },
    {
      "epoch": 0.044,
      "grad_norm": 20.03768539428711,
      "learning_rate": 9.854666666666667e-07,
      "logits/chosen": -2.3207902908325195,
      "logits/rejected": -2.1836650371551514,
      "logps/chosen": -187.83773803710938,
      "logps/rejected": -115.78532409667969,
      "loss": 0.5884,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15940171480178833,
      "rewards/margins": 0.22201958298683167,
      "rewards/rejected": -0.06261787563562393,
      "step": 110
    },
    {
      "epoch": 0.0444,
      "grad_norm": 16.243183135986328,
      "learning_rate": 9.853333333333333e-07,
      "logits/chosen": -2.057976245880127,
      "logits/rejected": -2.0548839569091797,
      "logps/chosen": -142.3499755859375,
      "logps/rejected": -93.60911560058594,
      "loss": 0.6171,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0777561217546463,
      "rewards/margins": 0.15998879075050354,
      "rewards/rejected": -0.08223266899585724,
      "step": 111
    },
    {
      "epoch": 0.0448,
      "grad_norm": 15.276758193969727,
      "learning_rate": 9.852e-07,
      "logits/chosen": -2.180441379547119,
      "logits/rejected": -0.6790106892585754,
      "logps/chosen": -130.08984375,
      "logps/rejected": -63.86539840698242,
      "loss": 0.6457,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09185562282800674,
      "rewards/margins": 0.09835243225097656,
      "rewards/rejected": -0.006496811285614967,
      "step": 112
    },
    {
      "epoch": 0.0452,
      "grad_norm": 21.796789169311523,
      "learning_rate": 9.850666666666667e-07,
      "logits/chosen": -2.3623909950256348,
      "logits/rejected": -2.7811007499694824,
      "logps/chosen": -237.7881317138672,
      "logps/rejected": -153.8236846923828,
      "loss": 0.5839,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2023361325263977,
      "rewards/margins": 0.23209229111671448,
      "rewards/rejected": -0.02975616417825222,
      "step": 113
    },
    {
      "epoch": 0.0456,
      "grad_norm": 15.595510482788086,
      "learning_rate": 9.849333333333333e-07,
      "logits/chosen": -2.125636339187622,
      "logits/rejected": -2.245238780975342,
      "logps/chosen": -161.5030517578125,
      "logps/rejected": -85.53143310546875,
      "loss": 0.6132,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11492843925952911,
      "rewards/margins": 0.16689491271972656,
      "rewards/rejected": -0.05196647718548775,
      "step": 114
    },
    {
      "epoch": 0.046,
      "grad_norm": 26.26072883605957,
      "learning_rate": 9.847999999999999e-07,
      "logits/chosen": -2.0711257457733154,
      "logits/rejected": -2.204113245010376,
      "logps/chosen": -204.3936767578125,
      "logps/rejected": -182.1153564453125,
      "loss": 0.5935,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20060577988624573,
      "rewards/margins": 0.21036683022975922,
      "rewards/rejected": -0.00976104661822319,
      "step": 115
    },
    {
      "epoch": 0.0464,
      "grad_norm": 14.486900329589844,
      "learning_rate": 9.846666666666667e-07,
      "logits/chosen": -2.221343994140625,
      "logits/rejected": -2.0165634155273438,
      "logps/chosen": -146.66693115234375,
      "logps/rejected": -107.51242065429688,
      "loss": 0.5988,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15962372720241547,
      "rewards/margins": 0.19892846047878265,
      "rewards/rejected": -0.03930473327636719,
      "step": 116
    },
    {
      "epoch": 0.0468,
      "grad_norm": 18.305198669433594,
      "learning_rate": 9.845333333333333e-07,
      "logits/chosen": -1.8502734899520874,
      "logits/rejected": -2.7396020889282227,
      "logps/chosen": -155.7273406982422,
      "logps/rejected": -120.23420715332031,
      "loss": 0.5519,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12648430466651917,
      "rewards/margins": 0.3064125180244446,
      "rewards/rejected": -0.17992821335792542,
      "step": 117
    },
    {
      "epoch": 0.0472,
      "grad_norm": 15.908095359802246,
      "learning_rate": 9.844e-07,
      "logits/chosen": -1.7377122640609741,
      "logits/rejected": -1.5911084413528442,
      "logps/chosen": -120.967041015625,
      "logps/rejected": -98.99386596679688,
      "loss": 0.6453,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04794349893927574,
      "rewards/margins": 0.0989101454615593,
      "rewards/rejected": -0.050966646522283554,
      "step": 118
    },
    {
      "epoch": 0.0476,
      "grad_norm": 15.962641716003418,
      "learning_rate": 9.842666666666666e-07,
      "logits/chosen": -1.6771297454833984,
      "logits/rejected": -2.0074148178100586,
      "logps/chosen": -139.32168579101562,
      "logps/rejected": -81.22798919677734,
      "loss": 0.5998,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17242127656936646,
      "rewards/margins": 0.19646377861499786,
      "rewards/rejected": -0.024042509496212006,
      "step": 119
    },
    {
      "epoch": 0.048,
      "grad_norm": 17.576963424682617,
      "learning_rate": 9.841333333333332e-07,
      "logits/chosen": -1.8365471363067627,
      "logits/rejected": -1.9910356998443604,
      "logps/chosen": -156.4036865234375,
      "logps/rejected": -99.62088012695312,
      "loss": 0.6486,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09878578782081604,
      "rewards/margins": 0.09112358093261719,
      "rewards/rejected": 0.007662201300263405,
      "step": 120
    },
    {
      "epoch": 0.0484,
      "grad_norm": 19.981935501098633,
      "learning_rate": 9.84e-07,
      "logits/chosen": -1.4530558586120605,
      "logits/rejected": -2.2601699829101562,
      "logps/chosen": -102.81451416015625,
      "logps/rejected": -117.30548095703125,
      "loss": 0.5956,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08140335232019424,
      "rewards/margins": 0.20608064532279968,
      "rewards/rejected": -0.12467728555202484,
      "step": 121
    },
    {
      "epoch": 0.0488,
      "grad_norm": 21.89099884033203,
      "learning_rate": 9.838666666666666e-07,
      "logits/chosen": -2.3285040855407715,
      "logits/rejected": -2.631226062774658,
      "logps/chosen": -274.4410095214844,
      "logps/rejected": -96.0296630859375,
      "loss": 0.5562,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20077896118164062,
      "rewards/margins": 0.2968257963657379,
      "rewards/rejected": -0.0960468277335167,
      "step": 122
    },
    {
      "epoch": 0.0492,
      "grad_norm": 19.490921020507812,
      "learning_rate": 9.837333333333334e-07,
      "logits/chosen": -2.6520438194274902,
      "logits/rejected": -2.310559034347534,
      "logps/chosen": -184.15594482421875,
      "logps/rejected": -172.6906280517578,
      "loss": 0.5817,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19271165132522583,
      "rewards/margins": 0.23771438002586365,
      "rewards/rejected": -0.04500274360179901,
      "step": 123
    },
    {
      "epoch": 0.0496,
      "grad_norm": 15.697385787963867,
      "learning_rate": 9.836e-07,
      "logits/chosen": -1.557201862335205,
      "logits/rejected": -2.0135326385498047,
      "logps/chosen": -103.99072265625,
      "logps/rejected": -91.6646957397461,
      "loss": 0.5952,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11811714619398117,
      "rewards/margins": 0.21274642646312714,
      "rewards/rejected": -0.09462929517030716,
      "step": 124
    },
    {
      "epoch": 0.05,
      "grad_norm": 13.952727317810059,
      "learning_rate": 9.834666666666666e-07,
      "logits/chosen": -1.929701328277588,
      "logits/rejected": -1.1438987255096436,
      "logps/chosen": -142.57223510742188,
      "logps/rejected": -82.155517578125,
      "loss": 0.5768,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19206085801124573,
      "rewards/margins": 0.2485988587141037,
      "rewards/rejected": -0.05653801187872887,
      "step": 125
    },
    {
      "epoch": 0.0504,
      "grad_norm": 15.0107421875,
      "learning_rate": 9.833333333333332e-07,
      "logits/chosen": -2.189079999923706,
      "logits/rejected": -2.02347993850708,
      "logps/chosen": -118.85124206542969,
      "logps/rejected": -90.61763000488281,
      "loss": 0.6432,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09380455315113068,
      "rewards/margins": 0.1029537245631218,
      "rewards/rejected": -0.00914916954934597,
      "step": 126
    },
    {
      "epoch": 0.0508,
      "grad_norm": 17.011873245239258,
      "learning_rate": 9.832e-07,
      "logits/chosen": -2.054011583328247,
      "logits/rejected": -2.403829574584961,
      "logps/chosen": -166.46905517578125,
      "logps/rejected": -87.9356689453125,
      "loss": 0.6325,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.058249667286872864,
      "rewards/margins": 0.12618140876293182,
      "rewards/rejected": -0.06793174892663956,
      "step": 127
    },
    {
      "epoch": 0.0512,
      "grad_norm": 11.702942848205566,
      "learning_rate": 9.830666666666665e-07,
      "logits/chosen": -1.3431546688079834,
      "logits/rejected": -1.3693511486053467,
      "logps/chosen": -101.6780776977539,
      "logps/rejected": -78.43663787841797,
      "loss": 0.6175,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1922042965888977,
      "rewards/margins": 0.157477006316185,
      "rewards/rejected": 0.03472728654742241,
      "step": 128
    },
    {
      "epoch": 0.0516,
      "grad_norm": 25.791763305664062,
      "learning_rate": 9.829333333333333e-07,
      "logits/chosen": -2.6555137634277344,
      "logits/rejected": -2.8192639350891113,
      "logps/chosen": -311.8077392578125,
      "logps/rejected": -145.9608612060547,
      "loss": 0.5698,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.208384707570076,
      "rewards/margins": 0.2727977931499481,
      "rewards/rejected": -0.06441307067871094,
      "step": 129
    },
    {
      "epoch": 0.052,
      "grad_norm": 15.89791202545166,
      "learning_rate": 9.828e-07,
      "logits/chosen": -1.8406221866607666,
      "logits/rejected": -1.9640171527862549,
      "logps/chosen": -139.01805114746094,
      "logps/rejected": -104.70498657226562,
      "loss": 0.5819,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15753594040870667,
      "rewards/margins": 0.23655778169631958,
      "rewards/rejected": -0.07902184128761292,
      "step": 130
    },
    {
      "epoch": 0.0524,
      "grad_norm": 14.179627418518066,
      "learning_rate": 9.826666666666667e-07,
      "logits/chosen": -1.7563591003417969,
      "logits/rejected": -1.4206898212432861,
      "logps/chosen": -129.05917358398438,
      "logps/rejected": -85.9144287109375,
      "loss": 0.5749,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1758296936750412,
      "rewards/margins": 0.25250929594039917,
      "rewards/rejected": -0.07667960971593857,
      "step": 131
    },
    {
      "epoch": 0.0528,
      "grad_norm": 14.063115119934082,
      "learning_rate": 9.825333333333333e-07,
      "logits/chosen": -2.0387840270996094,
      "logits/rejected": -1.6896064281463623,
      "logps/chosen": -179.62429809570312,
      "logps/rejected": -79.63372802734375,
      "loss": 0.576,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2864517271518707,
      "rewards/margins": 0.2516910433769226,
      "rewards/rejected": 0.03476066514849663,
      "step": 132
    },
    {
      "epoch": 0.0532,
      "grad_norm": 13.622482299804688,
      "learning_rate": 9.824e-07,
      "logits/chosen": -1.8548057079315186,
      "logits/rejected": -1.6043614149093628,
      "logps/chosen": -144.44952392578125,
      "logps/rejected": -83.07308959960938,
      "loss": 0.6573,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07315750420093536,
      "rewards/margins": 0.07394561916589737,
      "rewards/rejected": -0.0007881163619458675,
      "step": 133
    },
    {
      "epoch": 0.0536,
      "grad_norm": 19.27880096435547,
      "learning_rate": 9.822666666666665e-07,
      "logits/chosen": -2.188555955886841,
      "logits/rejected": -2.5962328910827637,
      "logps/chosen": -251.93218994140625,
      "logps/rejected": -136.022705078125,
      "loss": 0.6102,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1306350827217102,
      "rewards/margins": 0.17752686142921448,
      "rewards/rejected": -0.04689178615808487,
      "step": 134
    },
    {
      "epoch": 0.054,
      "grad_norm": 16.98014259338379,
      "learning_rate": 9.821333333333333e-07,
      "logits/chosen": -1.9756762981414795,
      "logits/rejected": -2.4651503562927246,
      "logps/chosen": -166.1409454345703,
      "logps/rejected": -118.79713439941406,
      "loss": 0.5748,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15307465195655823,
      "rewards/margins": 0.25335121154785156,
      "rewards/rejected": -0.10027657449245453,
      "step": 135
    },
    {
      "epoch": 0.0544,
      "grad_norm": 22.63155174255371,
      "learning_rate": 9.819999999999999e-07,
      "logits/chosen": -1.6490697860717773,
      "logits/rejected": -2.213749885559082,
      "logps/chosen": -114.50428771972656,
      "logps/rejected": -122.80213928222656,
      "loss": 0.5784,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17385903000831604,
      "rewards/margins": 0.24683494865894318,
      "rewards/rejected": -0.07297592610120773,
      "step": 136
    },
    {
      "epoch": 0.0548,
      "grad_norm": 15.556617736816406,
      "learning_rate": 9.818666666666667e-07,
      "logits/chosen": -1.60704505443573,
      "logits/rejected": -1.962072491645813,
      "logps/chosen": -111.97550201416016,
      "logps/rejected": -89.14640808105469,
      "loss": 0.5682,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1753585785627365,
      "rewards/margins": 0.2734626829624176,
      "rewards/rejected": -0.0981040969491005,
      "step": 137
    },
    {
      "epoch": 0.0552,
      "grad_norm": 12.877341270446777,
      "learning_rate": 9.817333333333333e-07,
      "logits/chosen": -1.8117485046386719,
      "logits/rejected": -2.168675184249878,
      "logps/chosen": -125.15906524658203,
      "logps/rejected": -77.50230407714844,
      "loss": 0.615,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12182235717773438,
      "rewards/margins": 0.1632007658481598,
      "rewards/rejected": -0.04137840121984482,
      "step": 138
    },
    {
      "epoch": 0.0556,
      "grad_norm": 19.220170974731445,
      "learning_rate": 9.816e-07,
      "logits/chosen": -2.188631296157837,
      "logits/rejected": -2.877505302429199,
      "logps/chosen": -187.6610107421875,
      "logps/rejected": -126.01800537109375,
      "loss": 0.5613,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16644859313964844,
      "rewards/margins": 0.28391990065574646,
      "rewards/rejected": -0.11747130751609802,
      "step": 139
    },
    {
      "epoch": 0.056,
      "grad_norm": 16.20087432861328,
      "learning_rate": 9.814666666666666e-07,
      "logits/chosen": -0.8425953388214111,
      "logits/rejected": -1.5475273132324219,
      "logps/chosen": -74.40362548828125,
      "logps/rejected": -89.17984008789062,
      "loss": 0.6714,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020931243896484375,
      "rewards/margins": 0.04391022026538849,
      "rewards/rejected": -0.022978972643613815,
      "step": 140
    },
    {
      "epoch": 0.0564,
      "grad_norm": 16.840490341186523,
      "learning_rate": 9.813333333333332e-07,
      "logits/chosen": -2.192967176437378,
      "logits/rejected": -2.0997726917266846,
      "logps/chosen": -205.1632537841797,
      "logps/rejected": -109.11978149414062,
      "loss": 0.5763,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25127488374710083,
      "rewards/margins": 0.2496509552001953,
      "rewards/rejected": 0.0016239164397120476,
      "step": 141
    },
    {
      "epoch": 0.0568,
      "grad_norm": 17.08500862121582,
      "learning_rate": 9.811999999999998e-07,
      "logits/chosen": -2.263871669769287,
      "logits/rejected": -2.0736634731292725,
      "logps/chosen": -207.9578857421875,
      "logps/rejected": -127.64493560791016,
      "loss": 0.5358,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2606254518032074,
      "rewards/margins": 0.34419745206832886,
      "rewards/rejected": -0.08357200771570206,
      "step": 142
    },
    {
      "epoch": 0.0572,
      "grad_norm": 18.429752349853516,
      "learning_rate": 9.810666666666666e-07,
      "logits/chosen": -2.571035861968994,
      "logits/rejected": -2.8539562225341797,
      "logps/chosen": -196.5228271484375,
      "logps/rejected": -128.70339965820312,
      "loss": 0.5437,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22439804673194885,
      "rewards/margins": 0.3252830505371094,
      "rewards/rejected": -0.10088501125574112,
      "step": 143
    },
    {
      "epoch": 0.0576,
      "grad_norm": 16.15090560913086,
      "learning_rate": 9.809333333333332e-07,
      "logits/chosen": -2.034083366394043,
      "logits/rejected": -2.313743829727173,
      "logps/chosen": -182.19390869140625,
      "logps/rejected": -132.27133178710938,
      "loss": 0.5807,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18238678574562073,
      "rewards/margins": 0.24390333890914917,
      "rewards/rejected": -0.061516571789979935,
      "step": 144
    },
    {
      "epoch": 0.058,
      "grad_norm": 18.955289840698242,
      "learning_rate": 9.808e-07,
      "logits/chosen": -1.7546772956848145,
      "logits/rejected": -3.003480911254883,
      "logps/chosen": -172.38414001464844,
      "logps/rejected": -153.219482421875,
      "loss": 0.5714,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19987717270851135,
      "rewards/margins": 0.2604011595249176,
      "rewards/rejected": -0.06052398681640625,
      "step": 145
    },
    {
      "epoch": 0.0584,
      "grad_norm": 16.100811004638672,
      "learning_rate": 9.806666666666666e-07,
      "logits/chosen": -1.650451421737671,
      "logits/rejected": -1.8339166641235352,
      "logps/chosen": -137.22622680664062,
      "logps/rejected": -108.16848754882812,
      "loss": 0.5691,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2737136781215668,
      "rewards/margins": 0.269461065530777,
      "rewards/rejected": 0.004252624697983265,
      "step": 146
    },
    {
      "epoch": 0.0588,
      "grad_norm": 16.062238693237305,
      "learning_rate": 9.805333333333334e-07,
      "logits/chosen": -2.0108327865600586,
      "logits/rejected": -1.9688408374786377,
      "logps/chosen": -147.32965087890625,
      "logps/rejected": -106.92489624023438,
      "loss": 0.5429,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2516532838344574,
      "rewards/margins": 0.3275165557861328,
      "rewards/rejected": -0.07586327195167542,
      "step": 147
    },
    {
      "epoch": 0.0592,
      "grad_norm": 19.41815185546875,
      "learning_rate": 9.804e-07,
      "logits/chosen": -1.88361656665802,
      "logits/rejected": -2.537898063659668,
      "logps/chosen": -164.31126403808594,
      "logps/rejected": -124.55421447753906,
      "loss": 0.5687,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16668397188186646,
      "rewards/margins": 0.26656532287597656,
      "rewards/rejected": -0.0998813658952713,
      "step": 148
    },
    {
      "epoch": 0.0596,
      "grad_norm": 16.076560974121094,
      "learning_rate": 9.802666666666666e-07,
      "logits/chosen": -2.641026496887207,
      "logits/rejected": -1.3925323486328125,
      "logps/chosen": -173.63626098632812,
      "logps/rejected": -89.8122787475586,
      "loss": 0.5625,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22151756286621094,
      "rewards/margins": 0.2833747863769531,
      "rewards/rejected": -0.06185722351074219,
      "step": 149
    },
    {
      "epoch": 0.06,
      "grad_norm": 16.512855529785156,
      "learning_rate": 9.801333333333333e-07,
      "logits/chosen": -1.6614898443222046,
      "logits/rejected": -2.7015652656555176,
      "logps/chosen": -141.14886474609375,
      "logps/rejected": -127.87471771240234,
      "loss": 0.5778,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.202616885304451,
      "rewards/margins": 0.24678954482078552,
      "rewards/rejected": -0.04417266696691513,
      "step": 150
    },
    {
      "epoch": 0.0604,
      "grad_norm": 18.047340393066406,
      "learning_rate": 9.8e-07,
      "logits/chosen": -1.652674674987793,
      "logits/rejected": -2.7260563373565674,
      "logps/chosen": -194.11416625976562,
      "logps/rejected": -141.75668334960938,
      "loss": 0.5161,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3393501341342926,
      "rewards/margins": 0.39276808500289917,
      "rewards/rejected": -0.05341796949505806,
      "step": 151
    },
    {
      "epoch": 0.0608,
      "grad_norm": 14.638249397277832,
      "learning_rate": 9.798666666666665e-07,
      "logits/chosen": -1.8058282136917114,
      "logits/rejected": -2.0847957134246826,
      "logps/chosen": -132.90631103515625,
      "logps/rejected": -103.008056640625,
      "loss": 0.5548,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2041977047920227,
      "rewards/margins": 0.2990760803222656,
      "rewards/rejected": -0.09487839043140411,
      "step": 152
    },
    {
      "epoch": 0.0612,
      "grad_norm": 15.180319786071777,
      "learning_rate": 9.797333333333333e-07,
      "logits/chosen": -1.8054167032241821,
      "logits/rejected": -1.2182873487472534,
      "logps/chosen": -104.54069519042969,
      "logps/rejected": -79.49069213867188,
      "loss": 0.5733,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20556221902370453,
      "rewards/margins": 0.2564014494419098,
      "rewards/rejected": -0.05083923414349556,
      "step": 153
    },
    {
      "epoch": 0.0616,
      "grad_norm": 12.9650239944458,
      "learning_rate": 9.796e-07,
      "logits/chosen": -2.1349174976348877,
      "logits/rejected": -1.8102164268493652,
      "logps/chosen": -129.23423767089844,
      "logps/rejected": -79.31046295166016,
      "loss": 0.5921,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08696365356445312,
      "rewards/margins": 0.2139057219028473,
      "rewards/rejected": -0.12694206833839417,
      "step": 154
    },
    {
      "epoch": 0.062,
      "grad_norm": 15.669412612915039,
      "learning_rate": 9.794666666666667e-07,
      "logits/chosen": -1.8290032148361206,
      "logits/rejected": -2.4571051597595215,
      "logps/chosen": -142.26760864257812,
      "logps/rejected": -111.42227172851562,
      "loss": 0.5143,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1999797821044922,
      "rewards/margins": 0.4084823727607727,
      "rewards/rejected": -0.20850259065628052,
      "step": 155
    },
    {
      "epoch": 0.0624,
      "grad_norm": 14.61257553100586,
      "learning_rate": 9.793333333333333e-07,
      "logits/chosen": -1.7019667625427246,
      "logits/rejected": -2.0564043521881104,
      "logps/chosen": -126.24273681640625,
      "logps/rejected": -111.01832580566406,
      "loss": 0.5895,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2014152556657791,
      "rewards/margins": 0.2200828492641449,
      "rewards/rejected": -0.01866760291159153,
      "step": 156
    },
    {
      "epoch": 0.0628,
      "grad_norm": 16.338693618774414,
      "learning_rate": 9.791999999999999e-07,
      "logits/chosen": -2.012239456176758,
      "logits/rejected": -2.1166462898254395,
      "logps/chosen": -146.27285766601562,
      "logps/rejected": -111.22502136230469,
      "loss": 0.6308,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14533615112304688,
      "rewards/margins": 0.13078002631664276,
      "rewards/rejected": 0.01455612201243639,
      "step": 157
    },
    {
      "epoch": 0.0632,
      "grad_norm": 16.779497146606445,
      "learning_rate": 9.790666666666667e-07,
      "logits/chosen": -1.960517168045044,
      "logits/rejected": -2.7365355491638184,
      "logps/chosen": -151.17686462402344,
      "logps/rejected": -145.17361450195312,
      "loss": 0.516,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2662929594516754,
      "rewards/margins": 0.39287757873535156,
      "rewards/rejected": -0.12658463418483734,
      "step": 158
    },
    {
      "epoch": 0.0636,
      "grad_norm": 11.858336448669434,
      "learning_rate": 9.789333333333333e-07,
      "logits/chosen": -2.1855359077453613,
      "logits/rejected": -1.7295805215835571,
      "logps/chosen": -110.62324523925781,
      "logps/rejected": -82.30279541015625,
      "loss": 0.6174,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13471832871437073,
      "rewards/margins": 0.16103097796440125,
      "rewards/rejected": -0.026312638074159622,
      "step": 159
    },
    {
      "epoch": 0.064,
      "grad_norm": 17.028392791748047,
      "learning_rate": 9.788e-07,
      "logits/chosen": -2.2083301544189453,
      "logits/rejected": -2.9642767906188965,
      "logps/chosen": -227.50674438476562,
      "logps/rejected": -107.16842651367188,
      "loss": 0.5259,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33281248807907104,
      "rewards/margins": 0.36922532320022583,
      "rewards/rejected": -0.036412812769412994,
      "step": 160
    },
    {
      "epoch": 0.0644,
      "grad_norm": 17.649633407592773,
      "learning_rate": 9.786666666666666e-07,
      "logits/chosen": -1.765994906425476,
      "logits/rejected": -1.3423244953155518,
      "logps/chosen": -110.0899429321289,
      "logps/rejected": -100.90400695800781,
      "loss": 0.5782,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1041717529296875,
      "rewards/margins": 0.24951058626174927,
      "rewards/rejected": -0.14533881843090057,
      "step": 161
    },
    {
      "epoch": 0.0648,
      "grad_norm": 12.647132873535156,
      "learning_rate": 9.785333333333332e-07,
      "logits/chosen": -2.211967945098877,
      "logits/rejected": -2.005005359649658,
      "logps/chosen": -111.91612243652344,
      "logps/rejected": -89.70962524414062,
      "loss": 0.5165,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2811824679374695,
      "rewards/margins": 0.3919239044189453,
      "rewards/rejected": -0.11074142903089523,
      "step": 162
    },
    {
      "epoch": 0.0652,
      "grad_norm": 16.61075210571289,
      "learning_rate": 9.784e-07,
      "logits/chosen": -2.4071669578552246,
      "logits/rejected": -2.184173107147217,
      "logps/chosen": -173.39834594726562,
      "logps/rejected": -117.89629364013672,
      "loss": 0.5164,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3299964964389801,
      "rewards/margins": 0.392190158367157,
      "rewards/rejected": -0.06219368055462837,
      "step": 163
    },
    {
      "epoch": 0.0656,
      "grad_norm": 19.198423385620117,
      "learning_rate": 9.782666666666666e-07,
      "logits/chosen": -1.9441978931427002,
      "logits/rejected": -2.3099210262298584,
      "logps/chosen": -123.56977081298828,
      "logps/rejected": -107.15276336669922,
      "loss": 0.5267,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2631179988384247,
      "rewards/margins": 0.36734962463378906,
      "rewards/rejected": -0.10423164814710617,
      "step": 164
    },
    {
      "epoch": 0.066,
      "grad_norm": 19.69503402709961,
      "learning_rate": 9.781333333333332e-07,
      "logits/chosen": -2.1997952461242676,
      "logits/rejected": -2.33231520652771,
      "logps/chosen": -174.5355224609375,
      "logps/rejected": -100.70094299316406,
      "loss": 0.5456,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.273651123046875,
      "rewards/margins": 0.3210411071777344,
      "rewards/rejected": -0.047389984130859375,
      "step": 165
    },
    {
      "epoch": 0.0664,
      "grad_norm": 19.390872955322266,
      "learning_rate": 9.78e-07,
      "logits/chosen": -1.8328014612197876,
      "logits/rejected": -2.6837551593780518,
      "logps/chosen": -182.2578582763672,
      "logps/rejected": -102.48872375488281,
      "loss": 0.5862,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2382461577653885,
      "rewards/margins": 0.2267223298549652,
      "rewards/rejected": 0.011523818597197533,
      "step": 166
    },
    {
      "epoch": 0.0668,
      "grad_norm": 11.696626663208008,
      "learning_rate": 9.778666666666666e-07,
      "logits/chosen": -1.4906256198883057,
      "logits/rejected": -1.4851430654525757,
      "logps/chosen": -91.81202697753906,
      "logps/rejected": -75.73088073730469,
      "loss": 0.5813,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17421264946460724,
      "rewards/margins": 0.23778611421585083,
      "rewards/rejected": -0.063573457300663,
      "step": 167
    },
    {
      "epoch": 0.0672,
      "grad_norm": 15.718013763427734,
      "learning_rate": 9.777333333333334e-07,
      "logits/chosen": -1.5250873565673828,
      "logits/rejected": -1.8478777408599854,
      "logps/chosen": -88.44502258300781,
      "logps/rejected": -95.0108871459961,
      "loss": 0.5783,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15121689438819885,
      "rewards/margins": 0.25579607486724854,
      "rewards/rejected": -0.10457916557788849,
      "step": 168
    },
    {
      "epoch": 0.0676,
      "grad_norm": 15.467487335205078,
      "learning_rate": 9.776e-07,
      "logits/chosen": -1.7737884521484375,
      "logits/rejected": -2.1716063022613525,
      "logps/chosen": -148.76531982421875,
      "logps/rejected": -96.52543640136719,
      "loss": 0.5815,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14743728935718536,
      "rewards/margins": 0.23884201049804688,
      "rewards/rejected": -0.09140472114086151,
      "step": 169
    },
    {
      "epoch": 0.068,
      "grad_norm": 11.654568672180176,
      "learning_rate": 9.774666666666668e-07,
      "logits/chosen": -1.7390048503875732,
      "logits/rejected": -1.4214506149291992,
      "logps/chosen": -107.29423522949219,
      "logps/rejected": -104.99266052246094,
      "loss": 0.5643,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27152901887893677,
      "rewards/margins": 0.28374141454696655,
      "rewards/rejected": -0.012212377041578293,
      "step": 170
    },
    {
      "epoch": 0.0684,
      "grad_norm": 14.616536140441895,
      "learning_rate": 9.773333333333333e-07,
      "logits/chosen": -1.59368896484375,
      "logits/rejected": -2.0859522819519043,
      "logps/chosen": -109.82626342773438,
      "logps/rejected": -105.86161804199219,
      "loss": 0.5249,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13855209946632385,
      "rewards/margins": 0.371524453163147,
      "rewards/rejected": -0.23297233879566193,
      "step": 171
    },
    {
      "epoch": 0.0688,
      "grad_norm": 19.789323806762695,
      "learning_rate": 9.772e-07,
      "logits/chosen": -2.1503982543945312,
      "logits/rejected": -2.3471133708953857,
      "logps/chosen": -146.87960815429688,
      "logps/rejected": -129.30630493164062,
      "loss": 0.509,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22852478921413422,
      "rewards/margins": 0.4104183316230774,
      "rewards/rejected": -0.18189354240894318,
      "step": 172
    },
    {
      "epoch": 0.0692,
      "grad_norm": 14.606046676635742,
      "learning_rate": 9.770666666666665e-07,
      "logits/chosen": -2.170980215072632,
      "logits/rejected": -1.9674601554870605,
      "logps/chosen": -205.819091796875,
      "logps/rejected": -96.16998291015625,
      "loss": 0.453,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4504402279853821,
      "rewards/margins": 0.5569747686386108,
      "rewards/rejected": -0.10653457790613174,
      "step": 173
    },
    {
      "epoch": 0.0696,
      "grad_norm": 15.157222747802734,
      "learning_rate": 9.769333333333333e-07,
      "logits/chosen": -2.074598550796509,
      "logits/rejected": -2.364358901977539,
      "logps/chosen": -222.5376739501953,
      "logps/rejected": -106.90171813964844,
      "loss": 0.4868,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4048721194267273,
      "rewards/margins": 0.4714488983154297,
      "rewards/rejected": -0.0665767639875412,
      "step": 174
    },
    {
      "epoch": 0.07,
      "grad_norm": 15.200950622558594,
      "learning_rate": 9.768e-07,
      "logits/chosen": -2.084573745727539,
      "logits/rejected": -1.6992114782333374,
      "logps/chosen": -138.96473693847656,
      "logps/rejected": -107.50279235839844,
      "loss": 0.5341,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3280777037143707,
      "rewards/margins": 0.3486618101596832,
      "rewards/rejected": -0.02058410830795765,
      "step": 175
    },
    {
      "epoch": 0.0704,
      "grad_norm": 16.123685836791992,
      "learning_rate": 9.766666666666667e-07,
      "logits/chosen": -1.7355825901031494,
      "logits/rejected": -2.3261115550994873,
      "logps/chosen": -120.07325744628906,
      "logps/rejected": -138.27145385742188,
      "loss": 0.5981,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12051849067211151,
      "rewards/margins": 0.2023494690656662,
      "rewards/rejected": -0.08183097839355469,
      "step": 176
    },
    {
      "epoch": 0.0708,
      "grad_norm": 15.511720657348633,
      "learning_rate": 9.765333333333333e-07,
      "logits/chosen": -2.244464159011841,
      "logits/rejected": -2.4061684608459473,
      "logps/chosen": -158.6040802001953,
      "logps/rejected": -134.68585205078125,
      "loss": 0.4694,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.315390020608902,
      "rewards/margins": 0.5143744945526123,
      "rewards/rejected": -0.1989845335483551,
      "step": 177
    },
    {
      "epoch": 0.0712,
      "grad_norm": 15.288220405578613,
      "learning_rate": 9.764e-07,
      "logits/chosen": -1.8441169261932373,
      "logits/rejected": -1.5067811012268066,
      "logps/chosen": -92.47331237792969,
      "logps/rejected": -82.22018432617188,
      "loss": 0.5645,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14815406501293182,
      "rewards/margins": 0.277688205242157,
      "rewards/rejected": -0.12953415513038635,
      "step": 178
    },
    {
      "epoch": 0.0716,
      "grad_norm": 14.865889549255371,
      "learning_rate": 9.762666666666667e-07,
      "logits/chosen": -1.8147497177124023,
      "logits/rejected": -2.1655097007751465,
      "logps/chosen": -120.60774993896484,
      "logps/rejected": -118.31983947753906,
      "loss": 0.5231,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32050856947898865,
      "rewards/margins": 0.3774387240409851,
      "rewards/rejected": -0.05693016201257706,
      "step": 179
    },
    {
      "epoch": 0.072,
      "grad_norm": 16.678058624267578,
      "learning_rate": 9.761333333333333e-07,
      "logits/chosen": -1.527198076248169,
      "logits/rejected": -2.0419836044311523,
      "logps/chosen": -150.2867431640625,
      "logps/rejected": -95.1392822265625,
      "loss": 0.5809,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17415352165699005,
      "rewards/margins": 0.243072509765625,
      "rewards/rejected": -0.06891899555921555,
      "step": 180
    },
    {
      "epoch": 0.0724,
      "grad_norm": 19.896114349365234,
      "learning_rate": 9.759999999999998e-07,
      "logits/chosen": -2.090074300765991,
      "logits/rejected": -2.952662467956543,
      "logps/chosen": -208.0070037841797,
      "logps/rejected": -179.32958984375,
      "loss": 0.4718,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.37166786193847656,
      "rewards/margins": 0.5062954425811768,
      "rewards/rejected": -0.1346275359392166,
      "step": 181
    },
    {
      "epoch": 0.0728,
      "grad_norm": 13.993875503540039,
      "learning_rate": 9.758666666666666e-07,
      "logits/chosen": -1.824662446975708,
      "logits/rejected": -1.7559947967529297,
      "logps/chosen": -125.5269775390625,
      "logps/rejected": -96.40750885009766,
      "loss": 0.541,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2263568937778473,
      "rewards/margins": 0.3320114016532898,
      "rewards/rejected": -0.1056545227766037,
      "step": 182
    },
    {
      "epoch": 0.0732,
      "grad_norm": 14.98769760131836,
      "learning_rate": 9.757333333333332e-07,
      "logits/chosen": -1.9969737529754639,
      "logits/rejected": -1.7142882347106934,
      "logps/chosen": -133.49554443359375,
      "logps/rejected": -96.38359069824219,
      "loss": 0.5051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.292227178812027,
      "rewards/margins": 0.42026978731155396,
      "rewards/rejected": -0.12804260849952698,
      "step": 183
    },
    {
      "epoch": 0.0736,
      "grad_norm": 15.131768226623535,
      "learning_rate": 9.756e-07,
      "logits/chosen": -2.0803496837615967,
      "logits/rejected": -2.287137985229492,
      "logps/chosen": -242.0331573486328,
      "logps/rejected": -98.29158020019531,
      "loss": 0.489,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4122089445590973,
      "rewards/margins": 0.4962169826030731,
      "rewards/rejected": -0.08400802314281464,
      "step": 184
    },
    {
      "epoch": 0.074,
      "grad_norm": 15.406317710876465,
      "learning_rate": 9.754666666666666e-07,
      "logits/chosen": -2.240523338317871,
      "logits/rejected": -1.7456936836242676,
      "logps/chosen": -185.1173553466797,
      "logps/rejected": -115.43141174316406,
      "loss": 0.4272,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4454086422920227,
      "rewards/margins": 0.6339473724365234,
      "rewards/rejected": -0.18853874504566193,
      "step": 185
    },
    {
      "epoch": 0.0744,
      "grad_norm": 13.471597671508789,
      "learning_rate": 9.753333333333334e-07,
      "logits/chosen": -2.3313302993774414,
      "logits/rejected": -1.7066056728363037,
      "logps/chosen": -158.2538604736328,
      "logps/rejected": -96.03717803955078,
      "loss": 0.4857,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3834671080112457,
      "rewards/margins": 0.47373849153518677,
      "rewards/rejected": -0.09027137607336044,
      "step": 186
    },
    {
      "epoch": 0.0748,
      "grad_norm": 15.715229034423828,
      "learning_rate": 9.752e-07,
      "logits/chosen": -1.854846477508545,
      "logits/rejected": -2.0235133171081543,
      "logps/chosen": -151.14126586914062,
      "logps/rejected": -105.80384063720703,
      "loss": 0.5049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2543777525424957,
      "rewards/margins": 0.42098045349121094,
      "rewards/rejected": -0.1666027009487152,
      "step": 187
    },
    {
      "epoch": 0.0752,
      "grad_norm": 15.894173622131348,
      "learning_rate": 9.750666666666666e-07,
      "logits/chosen": -1.9996623992919922,
      "logits/rejected": -1.3001651763916016,
      "logps/chosen": -119.51295471191406,
      "logps/rejected": -76.61112976074219,
      "loss": 0.5411,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.158488467335701,
      "rewards/margins": 0.33609312772750854,
      "rewards/rejected": -0.17760467529296875,
      "step": 188
    },
    {
      "epoch": 0.0756,
      "grad_norm": 14.249238967895508,
      "learning_rate": 9.749333333333332e-07,
      "logits/chosen": -2.0415666103363037,
      "logits/rejected": -2.5201871395111084,
      "logps/chosen": -168.14474487304688,
      "logps/rejected": -106.42434692382812,
      "loss": 0.469,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.44506949186325073,
      "rewards/margins": 0.5168560147285461,
      "rewards/rejected": -0.07178650051355362,
      "step": 189
    },
    {
      "epoch": 0.076,
      "grad_norm": 17.31495475769043,
      "learning_rate": 9.748e-07,
      "logits/chosen": -1.843214750289917,
      "logits/rejected": -1.8760234117507935,
      "logps/chosen": -125.88813781738281,
      "logps/rejected": -120.24752044677734,
      "loss": 0.5991,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17427712678909302,
      "rewards/margins": 0.20184290409088135,
      "rewards/rejected": -0.027565766125917435,
      "step": 190
    },
    {
      "epoch": 0.0764,
      "grad_norm": 17.70566749572754,
      "learning_rate": 9.746666666666666e-07,
      "logits/chosen": -2.205873966217041,
      "logits/rejected": -2.0358760356903076,
      "logps/chosen": -162.6166534423828,
      "logps/rejected": -99.768310546875,
      "loss": 0.478,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.28176918625831604,
      "rewards/margins": 0.4903907775878906,
      "rewards/rejected": -0.20862160623073578,
      "step": 191
    },
    {
      "epoch": 0.0768,
      "grad_norm": 12.92448616027832,
      "learning_rate": 9.745333333333334e-07,
      "logits/chosen": -1.5102382898330688,
      "logits/rejected": -1.3043839931488037,
      "logps/chosen": -117.97699737548828,
      "logps/rejected": -89.12928009033203,
      "loss": 0.6251,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11035384982824326,
      "rewards/margins": 0.14354248344898224,
      "rewards/rejected": -0.033188629895448685,
      "step": 192
    },
    {
      "epoch": 0.0772,
      "grad_norm": 16.93018341064453,
      "learning_rate": 9.744e-07,
      "logits/chosen": -2.0458381175994873,
      "logits/rejected": -1.1773983240127563,
      "logps/chosen": -206.13661193847656,
      "logps/rejected": -105.74281311035156,
      "loss": 0.4571,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4906959533691406,
      "rewards/margins": 0.5474452972412109,
      "rewards/rejected": -0.05674934387207031,
      "step": 193
    },
    {
      "epoch": 0.0776,
      "grad_norm": 19.97800064086914,
      "learning_rate": 9.742666666666665e-07,
      "logits/chosen": -1.6069295406341553,
      "logits/rejected": -1.716064453125,
      "logps/chosen": -96.5454330444336,
      "logps/rejected": -124.51791381835938,
      "loss": 0.5727,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24188080430030823,
      "rewards/margins": 0.2717094421386719,
      "rewards/rejected": -0.029828645288944244,
      "step": 194
    },
    {
      "epoch": 0.078,
      "grad_norm": 12.952960014343262,
      "learning_rate": 9.741333333333333e-07,
      "logits/chosen": -2.056898832321167,
      "logits/rejected": -1.7396833896636963,
      "logps/chosen": -159.60598754882812,
      "logps/rejected": -87.42559051513672,
      "loss": 0.4792,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35908928513526917,
      "rewards/margins": 0.4923160672187805,
      "rewards/rejected": -0.13322678208351135,
      "step": 195
    },
    {
      "epoch": 0.0784,
      "grad_norm": 14.311073303222656,
      "learning_rate": 9.74e-07,
      "logits/chosen": -1.9444609880447388,
      "logits/rejected": -2.2826600074768066,
      "logps/chosen": -135.68763732910156,
      "logps/rejected": -129.58062744140625,
      "loss": 0.5527,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17344476282596588,
      "rewards/margins": 0.3042759299278259,
      "rewards/rejected": -0.13083115220069885,
      "step": 196
    },
    {
      "epoch": 0.0788,
      "grad_norm": 16.00174331665039,
      "learning_rate": 9.738666666666667e-07,
      "logits/chosen": -1.9642858505249023,
      "logits/rejected": -1.9293482303619385,
      "logps/chosen": -150.9709930419922,
      "logps/rejected": -95.71429443359375,
      "loss": 0.445,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4788574278354645,
      "rewards/margins": 0.5793483853340149,
      "rewards/rejected": -0.10049095004796982,
      "step": 197
    },
    {
      "epoch": 0.0792,
      "grad_norm": 15.673871040344238,
      "learning_rate": 9.737333333333333e-07,
      "logits/chosen": -2.11210036277771,
      "logits/rejected": -2.029848337173462,
      "logps/chosen": -177.69149780273438,
      "logps/rejected": -94.47491455078125,
      "loss": 0.5444,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3459320068359375,
      "rewards/margins": 0.3243519067764282,
      "rewards/rejected": 0.021580124273896217,
      "step": 198
    },
    {
      "epoch": 0.0796,
      "grad_norm": 14.848771095275879,
      "learning_rate": 9.735999999999999e-07,
      "logits/chosen": -1.8076493740081787,
      "logits/rejected": -2.259716033935547,
      "logps/chosen": -152.45913696289062,
      "logps/rejected": -124.85626983642578,
      "loss": 0.4746,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.28693312406539917,
      "rewards/margins": 0.5019451379776001,
      "rewards/rejected": -0.21501198410987854,
      "step": 199
    },
    {
      "epoch": 0.08,
      "grad_norm": 14.82997989654541,
      "learning_rate": 9.734666666666667e-07,
      "logits/chosen": -1.857046365737915,
      "logits/rejected": -2.217176914215088,
      "logps/chosen": -162.9516143798828,
      "logps/rejected": -118.65200805664062,
      "loss": 0.4306,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.48549577593803406,
      "rewards/margins": 0.6249634027481079,
      "rewards/rejected": -0.13946762681007385,
      "step": 200
    },
    {
      "epoch": 0.0804,
      "grad_norm": 14.736102104187012,
      "learning_rate": 9.733333333333333e-07,
      "logits/chosen": -2.2667078971862793,
      "logits/rejected": -2.433317184448242,
      "logps/chosen": -177.34384155273438,
      "logps/rejected": -101.17034912109375,
      "loss": 0.4285,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.534613847732544,
      "rewards/margins": 0.6258449554443359,
      "rewards/rejected": -0.09123115241527557,
      "step": 201
    },
    {
      "epoch": 0.0808,
      "grad_norm": 12.882009506225586,
      "learning_rate": 9.731999999999998e-07,
      "logits/chosen": -2.2204251289367676,
      "logits/rejected": -1.6443371772766113,
      "logps/chosen": -168.23825073242188,
      "logps/rejected": -73.51646423339844,
      "loss": 0.4316,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4392665922641754,
      "rewards/margins": 0.6192005276679993,
      "rewards/rejected": -0.17993393540382385,
      "step": 202
    },
    {
      "epoch": 0.0812,
      "grad_norm": 14.241583824157715,
      "learning_rate": 9.730666666666666e-07,
      "logits/chosen": -1.9037933349609375,
      "logits/rejected": -1.9895234107971191,
      "logps/chosen": -101.24972534179688,
      "logps/rejected": -86.82413482666016,
      "loss": 0.5401,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22802506387233734,
      "rewards/margins": 0.3339744806289673,
      "rewards/rejected": -0.10594940185546875,
      "step": 203
    },
    {
      "epoch": 0.0816,
      "grad_norm": 16.731718063354492,
      "learning_rate": 9.729333333333332e-07,
      "logits/chosen": -2.3595635890960693,
      "logits/rejected": -1.6469991207122803,
      "logps/chosen": -121.2806167602539,
      "logps/rejected": -90.17388916015625,
      "loss": 0.4785,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14852866530418396,
      "rewards/margins": 0.48829346895217896,
      "rewards/rejected": -0.3397647738456726,
      "step": 204
    },
    {
      "epoch": 0.082,
      "grad_norm": 15.068917274475098,
      "learning_rate": 9.728e-07,
      "logits/chosen": -2.0658040046691895,
      "logits/rejected": -2.211104393005371,
      "logps/chosen": -153.06173706054688,
      "logps/rejected": -91.54537963867188,
      "loss": 0.5424,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19624672830104828,
      "rewards/margins": 0.3339042663574219,
      "rewards/rejected": -0.1376575529575348,
      "step": 205
    },
    {
      "epoch": 0.0824,
      "grad_norm": 11.88391399383545,
      "learning_rate": 9.726666666666666e-07,
      "logits/chosen": -2.4001708030700684,
      "logits/rejected": -2.201834201812744,
      "logps/chosen": -149.08433532714844,
      "logps/rejected": -89.62236022949219,
      "loss": 0.4921,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.354592889547348,
      "rewards/margins": 0.45856666564941406,
      "rewards/rejected": -0.10397377610206604,
      "step": 206
    },
    {
      "epoch": 0.0828,
      "grad_norm": 16.016521453857422,
      "learning_rate": 9.725333333333334e-07,
      "logits/chosen": -1.8883070945739746,
      "logits/rejected": -1.9385926723480225,
      "logps/chosen": -131.09130859375,
      "logps/rejected": -116.44227600097656,
      "loss": 0.4469,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33204424381256104,
      "rewards/margins": 0.5738884210586548,
      "rewards/rejected": -0.24184417724609375,
      "step": 207
    },
    {
      "epoch": 0.0832,
      "grad_norm": 12.821227073669434,
      "learning_rate": 9.724e-07,
      "logits/chosen": -1.6401491165161133,
      "logits/rejected": -1.812258243560791,
      "logps/chosen": -123.44853210449219,
      "logps/rejected": -89.39974975585938,
      "loss": 0.4968,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38880616426467896,
      "rewards/margins": 0.4450504183769226,
      "rewards/rejected": -0.05624427646398544,
      "step": 208
    },
    {
      "epoch": 0.0836,
      "grad_norm": 13.846927642822266,
      "learning_rate": 9.722666666666666e-07,
      "logits/chosen": -2.1907646656036377,
      "logits/rejected": -2.530543327331543,
      "logps/chosen": -157.84646606445312,
      "logps/rejected": -100.83956146240234,
      "loss": 0.4941,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.309347927570343,
      "rewards/margins": 0.4552879333496094,
      "rewards/rejected": -0.14594002068042755,
      "step": 209
    },
    {
      "epoch": 0.084,
      "grad_norm": 16.779155731201172,
      "learning_rate": 9.721333333333332e-07,
      "logits/chosen": -2.006211042404175,
      "logits/rejected": -1.9967141151428223,
      "logps/chosen": -143.937255859375,
      "logps/rejected": -128.22962951660156,
      "loss": 0.5251,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19099655747413635,
      "rewards/margins": 0.371829628944397,
      "rewards/rejected": -0.18083305656909943,
      "step": 210
    },
    {
      "epoch": 0.0844,
      "grad_norm": 16.147998809814453,
      "learning_rate": 9.72e-07,
      "logits/chosen": -2.2497398853302,
      "logits/rejected": -1.672083854675293,
      "logps/chosen": -176.862060546875,
      "logps/rejected": -110.10736846923828,
      "loss": 0.4752,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39635008573532104,
      "rewards/margins": 0.5049575567245483,
      "rewards/rejected": -0.10860748589038849,
      "step": 211
    },
    {
      "epoch": 0.0848,
      "grad_norm": 16.68891143798828,
      "learning_rate": 9.718666666666666e-07,
      "logits/chosen": -1.5778892040252686,
      "logits/rejected": -1.5080230236053467,
      "logps/chosen": -161.0042724609375,
      "logps/rejected": -94.73396301269531,
      "loss": 0.4299,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42661401629447937,
      "rewards/margins": 0.6246651411056519,
      "rewards/rejected": -0.1980510801076889,
      "step": 212
    },
    {
      "epoch": 0.0852,
      "grad_norm": 13.428424835205078,
      "learning_rate": 9.717333333333334e-07,
      "logits/chosen": -1.6321356296539307,
      "logits/rejected": -1.7972686290740967,
      "logps/chosen": -125.76956176757812,
      "logps/rejected": -112.60945892333984,
      "loss": 0.4655,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3437759578227997,
      "rewards/margins": 0.5366237759590149,
      "rewards/rejected": -0.1928478181362152,
      "step": 213
    },
    {
      "epoch": 0.0856,
      "grad_norm": 12.402342796325684,
      "learning_rate": 9.716e-07,
      "logits/chosen": -1.8785911798477173,
      "logits/rejected": -1.6035146713256836,
      "logps/chosen": -106.28009796142578,
      "logps/rejected": -86.62583923339844,
      "loss": 0.4859,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.331796258687973,
      "rewards/margins": 0.46982574462890625,
      "rewards/rejected": -0.13802948594093323,
      "step": 214
    },
    {
      "epoch": 0.086,
      "grad_norm": 18.293663024902344,
      "learning_rate": 9.714666666666667e-07,
      "logits/chosen": -2.300957679748535,
      "logits/rejected": -2.326000690460205,
      "logps/chosen": -195.41734313964844,
      "logps/rejected": -103.15274810791016,
      "loss": 0.5064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.28258171677589417,
      "rewards/margins": 0.41882896423339844,
      "rewards/rejected": -0.13624724745750427,
      "step": 215
    },
    {
      "epoch": 0.0864,
      "grad_norm": 18.159160614013672,
      "learning_rate": 9.713333333333333e-07,
      "logits/chosen": -2.253613233566284,
      "logits/rejected": -2.6576449871063232,
      "logps/chosen": -147.88206481933594,
      "logps/rejected": -166.6992950439453,
      "loss": 0.4277,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3695465326309204,
      "rewards/margins": 0.6470695734024048,
      "rewards/rejected": -0.2775230407714844,
      "step": 216
    },
    {
      "epoch": 0.0868,
      "grad_norm": 15.261011123657227,
      "learning_rate": 9.712e-07,
      "logits/chosen": -1.8707119226455688,
      "logits/rejected": -1.9900498390197754,
      "logps/chosen": -174.16351318359375,
      "logps/rejected": -166.2998046875,
      "loss": 0.4062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5838775634765625,
      "rewards/margins": 0.699601411819458,
      "rewards/rejected": -0.11572380363941193,
      "step": 217
    },
    {
      "epoch": 0.0872,
      "grad_norm": 17.32415771484375,
      "learning_rate": 9.710666666666665e-07,
      "logits/chosen": -1.9045389890670776,
      "logits/rejected": -2.2801499366760254,
      "logps/chosen": -150.41754150390625,
      "logps/rejected": -95.56461334228516,
      "loss": 0.4847,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3257896304130554,
      "rewards/margins": 0.4723087251186371,
      "rewards/rejected": -0.14651909470558167,
      "step": 218
    },
    {
      "epoch": 0.0876,
      "grad_norm": 13.010327339172363,
      "learning_rate": 9.709333333333333e-07,
      "logits/chosen": -2.253253936767578,
      "logits/rejected": -1.780455231666565,
      "logps/chosen": -144.5403289794922,
      "logps/rejected": -114.48267364501953,
      "loss": 0.4978,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4547683596611023,
      "rewards/margins": 0.4425193667411804,
      "rewards/rejected": 0.012248992919921875,
      "step": 219
    },
    {
      "epoch": 0.088,
      "grad_norm": 14.240906715393066,
      "learning_rate": 9.707999999999999e-07,
      "logits/chosen": -2.1533291339874268,
      "logits/rejected": -2.270066738128662,
      "logps/chosen": -156.06695556640625,
      "logps/rejected": -120.27235412597656,
      "loss": 0.4045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4091266691684723,
      "rewards/margins": 0.7161449193954468,
      "rewards/rejected": -0.3070182800292969,
      "step": 220
    },
    {
      "epoch": 0.0884,
      "grad_norm": 15.02370548248291,
      "learning_rate": 9.706666666666667e-07,
      "logits/chosen": -2.0176281929016113,
      "logits/rejected": -2.130157470703125,
      "logps/chosen": -113.82833862304688,
      "logps/rejected": -124.34172058105469,
      "loss": 0.5231,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27414438128471375,
      "rewards/margins": 0.38011208176612854,
      "rewards/rejected": -0.10596771538257599,
      "step": 221
    },
    {
      "epoch": 0.0888,
      "grad_norm": 14.024950981140137,
      "learning_rate": 9.705333333333333e-07,
      "logits/chosen": -1.941678762435913,
      "logits/rejected": -2.318819522857666,
      "logps/chosen": -178.1046600341797,
      "logps/rejected": -105.17333221435547,
      "loss": 0.5269,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25038450956344604,
      "rewards/margins": 0.38955458998680115,
      "rewards/rejected": -0.1391700804233551,
      "step": 222
    },
    {
      "epoch": 0.0892,
      "grad_norm": 13.387491226196289,
      "learning_rate": 9.704e-07,
      "logits/chosen": -1.5315625667572021,
      "logits/rejected": -2.238101005554199,
      "logps/chosen": -118.40945434570312,
      "logps/rejected": -101.35859680175781,
      "loss": 0.4773,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24906808137893677,
      "rewards/margins": 0.49147874116897583,
      "rewards/rejected": -0.24241065979003906,
      "step": 223
    },
    {
      "epoch": 0.0896,
      "grad_norm": 14.968443870544434,
      "learning_rate": 9.702666666666666e-07,
      "logits/chosen": -2.2186012268066406,
      "logits/rejected": -1.6234768629074097,
      "logps/chosen": -198.57061767578125,
      "logps/rejected": -95.89431762695312,
      "loss": 0.4588,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4812244474887848,
      "rewards/margins": 0.5567028522491455,
      "rewards/rejected": -0.07547836750745773,
      "step": 224
    },
    {
      "epoch": 0.09,
      "grad_norm": 15.982439041137695,
      "learning_rate": 9.701333333333332e-07,
      "logits/chosen": -2.2798233032226562,
      "logits/rejected": -1.962646245956421,
      "logps/chosen": -166.54209899902344,
      "logps/rejected": -96.27203369140625,
      "loss": 0.4498,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4393013119697571,
      "rewards/margins": 0.5656677484512329,
      "rewards/rejected": -0.12636642158031464,
      "step": 225
    },
    {
      "epoch": 0.0904,
      "grad_norm": 14.837868690490723,
      "learning_rate": 9.7e-07,
      "logits/chosen": -1.6572561264038086,
      "logits/rejected": -2.1773009300231934,
      "logps/chosen": -103.69522857666016,
      "logps/rejected": -102.8018798828125,
      "loss": 0.4991,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.30112725496292114,
      "rewards/margins": 0.4387268126010895,
      "rewards/rejected": -0.13759955763816833,
      "step": 226
    },
    {
      "epoch": 0.0908,
      "grad_norm": 14.208680152893066,
      "learning_rate": 9.698666666666666e-07,
      "logits/chosen": -1.4208736419677734,
      "logits/rejected": -1.3328171968460083,
      "logps/chosen": -106.84479522705078,
      "logps/rejected": -80.41463470458984,
      "loss": 0.4664,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3593311309814453,
      "rewards/margins": 0.5286544561386108,
      "rewards/rejected": -0.16932335495948792,
      "step": 227
    },
    {
      "epoch": 0.0912,
      "grad_norm": 17.428030014038086,
      "learning_rate": 9.697333333333332e-07,
      "logits/chosen": -1.9049392938613892,
      "logits/rejected": -2.4695568084716797,
      "logps/chosen": -182.75888061523438,
      "logps/rejected": -135.72079467773438,
      "loss": 0.3717,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.46642762422561646,
      "rewards/margins": 0.8024986982345581,
      "rewards/rejected": -0.3360710144042969,
      "step": 228
    },
    {
      "epoch": 0.0916,
      "grad_norm": 17.37397003173828,
      "learning_rate": 9.696e-07,
      "logits/chosen": -2.140303611755371,
      "logits/rejected": -2.914701223373413,
      "logps/chosen": -164.29571533203125,
      "logps/rejected": -123.92433166503906,
      "loss": 0.395,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.29230424761772156,
      "rewards/margins": 0.7290370464324951,
      "rewards/rejected": -0.43673285841941833,
      "step": 229
    },
    {
      "epoch": 0.092,
      "grad_norm": 13.955336570739746,
      "learning_rate": 9.694666666666666e-07,
      "logits/chosen": -2.015725612640381,
      "logits/rejected": -2.167724132537842,
      "logps/chosen": -134.08160400390625,
      "logps/rejected": -95.20018005371094,
      "loss": 0.5033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3542465269565582,
      "rewards/margins": 0.4244880676269531,
      "rewards/rejected": -0.0702415481209755,
      "step": 230
    },
    {
      "epoch": 0.0924,
      "grad_norm": 17.08428955078125,
      "learning_rate": 9.693333333333334e-07,
      "logits/chosen": -1.942035436630249,
      "logits/rejected": -2.088365316390991,
      "logps/chosen": -120.11309051513672,
      "logps/rejected": -80.60171508789062,
      "loss": 0.4092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4403885006904602,
      "rewards/margins": 0.6894012689590454,
      "rewards/rejected": -0.249012753367424,
      "step": 231
    },
    {
      "epoch": 0.0928,
      "grad_norm": 18.178504943847656,
      "learning_rate": 9.692e-07,
      "logits/chosen": -2.576084613800049,
      "logits/rejected": -2.490009307861328,
      "logps/chosen": -228.98785400390625,
      "logps/rejected": -92.71510314941406,
      "loss": 0.4958,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4200836420059204,
      "rewards/margins": 0.44351959228515625,
      "rewards/rejected": -0.02343597449362278,
      "step": 232
    },
    {
      "epoch": 0.0932,
      "grad_norm": 14.501802444458008,
      "learning_rate": 9.690666666666666e-07,
      "logits/chosen": -2.1531410217285156,
      "logits/rejected": -2.4351577758789062,
      "logps/chosen": -179.93899536132812,
      "logps/rejected": -106.36511993408203,
      "loss": 0.3891,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5112098455429077,
      "rewards/margins": 0.7435615658760071,
      "rewards/rejected": -0.23235169053077698,
      "step": 233
    },
    {
      "epoch": 0.0936,
      "grad_norm": 13.428903579711914,
      "learning_rate": 9.689333333333334e-07,
      "logits/chosen": -2.0008480548858643,
      "logits/rejected": -2.3601698875427246,
      "logps/chosen": -158.54116821289062,
      "logps/rejected": -130.5196990966797,
      "loss": 0.3503,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5931060910224915,
      "rewards/margins": 0.8748180866241455,
      "rewards/rejected": -0.28171196579933167,
      "step": 234
    },
    {
      "epoch": 0.094,
      "grad_norm": 14.82013988494873,
      "learning_rate": 9.688e-07,
      "logits/chosen": -1.5637784004211426,
      "logits/rejected": -2.013777494430542,
      "logps/chosen": -93.13448333740234,
      "logps/rejected": -99.59672546386719,
      "loss": 0.4681,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20000076293945312,
      "rewards/margins": 0.5234672427177429,
      "rewards/rejected": -0.3234664797782898,
      "step": 235
    },
    {
      "epoch": 0.0944,
      "grad_norm": 17.690406799316406,
      "learning_rate": 9.686666666666667e-07,
      "logits/chosen": -2.3357632160186768,
      "logits/rejected": -2.152374267578125,
      "logps/chosen": -192.16802978515625,
      "logps/rejected": -97.89231872558594,
      "loss": 0.42,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.515192449092865,
      "rewards/margins": 0.6607521176338196,
      "rewards/rejected": -0.14555969834327698,
      "step": 236
    },
    {
      "epoch": 0.0948,
      "grad_norm": 11.723567008972168,
      "learning_rate": 9.685333333333333e-07,
      "logits/chosen": -1.92128586769104,
      "logits/rejected": -2.067342519760132,
      "logps/chosen": -124.56971740722656,
      "logps/rejected": -85.61102294921875,
      "loss": 0.4537,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5045673847198486,
      "rewards/margins": 0.5575062036514282,
      "rewards/rejected": -0.05293884128332138,
      "step": 237
    },
    {
      "epoch": 0.0952,
      "grad_norm": 16.076438903808594,
      "learning_rate": 9.684e-07,
      "logits/chosen": -2.256013870239258,
      "logits/rejected": -1.724149465560913,
      "logps/chosen": -214.64968872070312,
      "logps/rejected": -93.27490997314453,
      "loss": 0.4643,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.49576568603515625,
      "rewards/margins": 0.5262737274169922,
      "rewards/rejected": -0.030508041381835938,
      "step": 238
    },
    {
      "epoch": 0.0956,
      "grad_norm": 12.952951431274414,
      "learning_rate": 9.682666666666667e-07,
      "logits/chosen": -2.1350767612457275,
      "logits/rejected": -1.2335193157196045,
      "logps/chosen": -161.3805694580078,
      "logps/rejected": -79.20146942138672,
      "loss": 0.4553,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3854309320449829,
      "rewards/margins": 0.5510826110839844,
      "rewards/rejected": -0.16565170884132385,
      "step": 239
    },
    {
      "epoch": 0.096,
      "grad_norm": 13.834997177124023,
      "learning_rate": 9.681333333333333e-07,
      "logits/chosen": -1.8890717029571533,
      "logits/rejected": -2.007157564163208,
      "logps/chosen": -105.3575439453125,
      "logps/rejected": -116.54779815673828,
      "loss": 0.4798,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39406928420066833,
      "rewards/margins": 0.49736785888671875,
      "rewards/rejected": -0.10329856723546982,
      "step": 240
    },
    {
      "epoch": 0.0964,
      "grad_norm": 14.985712051391602,
      "learning_rate": 9.679999999999999e-07,
      "logits/chosen": -1.860418438911438,
      "logits/rejected": -2.181546449661255,
      "logps/chosen": -177.0812530517578,
      "logps/rejected": -113.07230377197266,
      "loss": 0.3429,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5864593982696533,
      "rewards/margins": 0.8941993713378906,
      "rewards/rejected": -0.3077400326728821,
      "step": 241
    },
    {
      "epoch": 0.0968,
      "grad_norm": 13.226746559143066,
      "learning_rate": 9.678666666666667e-07,
      "logits/chosen": -2.0790252685546875,
      "logits/rejected": -1.7745285034179688,
      "logps/chosen": -146.37181091308594,
      "logps/rejected": -101.08578491210938,
      "loss": 0.4113,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5695144534111023,
      "rewards/margins": 0.6761447787284851,
      "rewards/rejected": -0.10663032531738281,
      "step": 242
    },
    {
      "epoch": 0.0972,
      "grad_norm": 14.157883644104004,
      "learning_rate": 9.677333333333333e-07,
      "logits/chosen": -2.2719197273254395,
      "logits/rejected": -1.691918134689331,
      "logps/chosen": -149.65744018554688,
      "logps/rejected": -101.78333282470703,
      "loss": 0.4437,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32227858901023865,
      "rewards/margins": 0.6018452048301697,
      "rewards/rejected": -0.27956658601760864,
      "step": 243
    },
    {
      "epoch": 0.0976,
      "grad_norm": 16.863330841064453,
      "learning_rate": 9.676e-07,
      "logits/chosen": -1.6504204273223877,
      "logits/rejected": -2.2937865257263184,
      "logps/chosen": -104.95082092285156,
      "logps/rejected": -95.10338592529297,
      "loss": 0.4742,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16331520676612854,
      "rewards/margins": 0.5195053219795227,
      "rewards/rejected": -0.35619011521339417,
      "step": 244
    },
    {
      "epoch": 0.098,
      "grad_norm": 13.270169258117676,
      "learning_rate": 9.674666666666666e-07,
      "logits/chosen": -2.4256162643432617,
      "logits/rejected": -2.2663378715515137,
      "logps/chosen": -182.0302734375,
      "logps/rejected": -115.6131591796875,
      "loss": 0.3288,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7172187566757202,
      "rewards/margins": 0.9459270238876343,
      "rewards/rejected": -0.22870826721191406,
      "step": 245
    },
    {
      "epoch": 0.0984,
      "grad_norm": 18.02309799194336,
      "learning_rate": 9.673333333333332e-07,
      "logits/chosen": -2.6302289962768555,
      "logits/rejected": -2.5427021980285645,
      "logps/chosen": -277.4732666015625,
      "logps/rejected": -148.17173767089844,
      "loss": 0.4067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5911407470703125,
      "rewards/margins": 0.7089531421661377,
      "rewards/rejected": -0.11781235039234161,
      "step": 246
    },
    {
      "epoch": 0.0988,
      "grad_norm": 13.121500015258789,
      "learning_rate": 9.671999999999998e-07,
      "logits/chosen": -1.8138922452926636,
      "logits/rejected": -1.3967217206954956,
      "logps/chosen": -103.49849700927734,
      "logps/rejected": -85.5018310546875,
      "loss": 0.4916,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5319942235946655,
      "rewards/margins": 0.45793455839157104,
      "rewards/rejected": 0.07405968010425568,
      "step": 247
    },
    {
      "epoch": 0.0992,
      "grad_norm": 12.717131614685059,
      "learning_rate": 9.670666666666666e-07,
      "logits/chosen": -1.9978442192077637,
      "logits/rejected": -1.7970010042190552,
      "logps/chosen": -122.52836608886719,
      "logps/rejected": -106.88394165039062,
      "loss": 0.3877,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5129833221435547,
      "rewards/margins": 0.7671844959259033,
      "rewards/rejected": -0.25420114398002625,
      "step": 248
    },
    {
      "epoch": 0.0996,
      "grad_norm": 14.945093154907227,
      "learning_rate": 9.669333333333332e-07,
      "logits/chosen": -1.780381441116333,
      "logits/rejected": -2.645908832550049,
      "logps/chosen": -116.75480651855469,
      "logps/rejected": -105.56498718261719,
      "loss": 0.3741,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.591862142086029,
      "rewards/margins": 0.7907257080078125,
      "rewards/rejected": -0.19886359572410583,
      "step": 249
    },
    {
      "epoch": 0.1,
      "grad_norm": 12.660970687866211,
      "learning_rate": 9.668e-07,
      "logits/chosen": -1.7348272800445557,
      "logits/rejected": -2.2098636627197266,
      "logps/chosen": -121.22599029541016,
      "logps/rejected": -112.13688659667969,
      "loss": 0.5008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41399574279785156,
      "rewards/margins": 0.4388920068740845,
      "rewards/rejected": -0.02489623986184597,
      "step": 250
    },
    {
      "epoch": 0.1004,
      "grad_norm": 14.017123222351074,
      "learning_rate": 9.666666666666666e-07,
      "logits/chosen": -1.7260699272155762,
      "logits/rejected": -1.8862907886505127,
      "logps/chosen": -129.4001922607422,
      "logps/rejected": -100.81625366210938,
      "loss": 0.5105,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3612464964389801,
      "rewards/margins": 0.4105995297431946,
      "rewards/rejected": -0.04935302957892418,
      "step": 251
    },
    {
      "epoch": 0.1008,
      "grad_norm": 12.803179740905762,
      "learning_rate": 9.665333333333334e-07,
      "logits/chosen": -1.6699068546295166,
      "logits/rejected": -1.7115110158920288,
      "logps/chosen": -124.13719177246094,
      "logps/rejected": -90.83358764648438,
      "loss": 0.554,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2832580804824829,
      "rewards/margins": 0.3011035919189453,
      "rewards/rejected": -0.01784553751349449,
      "step": 252
    },
    {
      "epoch": 0.1012,
      "grad_norm": 13.48849868774414,
      "learning_rate": 9.664e-07,
      "logits/chosen": -2.3457536697387695,
      "logits/rejected": -2.6351468563079834,
      "logps/chosen": -189.88150024414062,
      "logps/rejected": -90.67217254638672,
      "loss": 0.4449,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5346351861953735,
      "rewards/margins": 0.5837607979774475,
      "rewards/rejected": -0.04912567138671875,
      "step": 253
    },
    {
      "epoch": 0.1016,
      "grad_norm": 11.36355209350586,
      "learning_rate": 9.662666666666668e-07,
      "logits/chosen": -2.135857105255127,
      "logits/rejected": -1.5216760635375977,
      "logps/chosen": -131.07232666015625,
      "logps/rejected": -101.21012878417969,
      "loss": 0.4552,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4482731223106384,
      "rewards/margins": 0.5981605648994446,
      "rewards/rejected": -0.14988747239112854,
      "step": 254
    },
    {
      "epoch": 0.102,
      "grad_norm": 12.444218635559082,
      "learning_rate": 9.661333333333331e-07,
      "logits/chosen": -1.4147748947143555,
      "logits/rejected": -1.6266463994979858,
      "logps/chosen": -98.68913269042969,
      "logps/rejected": -97.20632934570312,
      "loss": 0.3903,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4710426330566406,
      "rewards/margins": 0.7411762475967407,
      "rewards/rejected": -0.2701336145401001,
      "step": 255
    },
    {
      "epoch": 0.1024,
      "grad_norm": 11.75374698638916,
      "learning_rate": 9.66e-07,
      "logits/chosen": -1.8503799438476562,
      "logits/rejected": -0.6449410319328308,
      "logps/chosen": -117.7560806274414,
      "logps/rejected": -101.7578125,
      "loss": 0.5354,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32694053649902344,
      "rewards/margins": 0.3536338806152344,
      "rewards/rejected": -0.026693344116210938,
      "step": 256
    },
    {
      "epoch": 0.1028,
      "grad_norm": 15.933476448059082,
      "learning_rate": 9.658666666666665e-07,
      "logits/chosen": -1.4785983562469482,
      "logits/rejected": -2.14064884185791,
      "logps/chosen": -82.36963653564453,
      "logps/rejected": -162.23117065429688,
      "loss": 0.4988,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22802849113941193,
      "rewards/margins": 0.4367450773715973,
      "rewards/rejected": -0.20871660113334656,
      "step": 257
    },
    {
      "epoch": 0.1032,
      "grad_norm": 13.58607006072998,
      "learning_rate": 9.657333333333333e-07,
      "logits/chosen": -1.6574561595916748,
      "logits/rejected": -1.944331169128418,
      "logps/chosen": -90.38685607910156,
      "logps/rejected": -123.44944763183594,
      "loss": 0.4064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4194103479385376,
      "rewards/margins": 0.7000744342803955,
      "rewards/rejected": -0.2806640565395355,
      "step": 258
    },
    {
      "epoch": 0.1036,
      "grad_norm": 16.40294647216797,
      "learning_rate": 9.656e-07,
      "logits/chosen": -1.8118057250976562,
      "logits/rejected": -2.393745183944702,
      "logps/chosen": -143.25665283203125,
      "logps/rejected": -163.5789337158203,
      "loss": 0.4307,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41404953598976135,
      "rewards/margins": 0.6424552798271179,
      "rewards/rejected": -0.22840577363967896,
      "step": 259
    },
    {
      "epoch": 0.104,
      "grad_norm": 12.925787925720215,
      "learning_rate": 9.654666666666667e-07,
      "logits/chosen": -1.6314772367477417,
      "logits/rejected": -2.849891185760498,
      "logps/chosen": -125.13861083984375,
      "logps/rejected": -114.05514526367188,
      "loss": 0.4717,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4843147397041321,
      "rewards/margins": 0.512169599533081,
      "rewards/rejected": -0.02785491943359375,
      "step": 260
    },
    {
      "epoch": 0.1044,
      "grad_norm": 14.709826469421387,
      "learning_rate": 9.653333333333333e-07,
      "logits/chosen": -1.9443655014038086,
      "logits/rejected": -2.177612781524658,
      "logps/chosen": -161.83827209472656,
      "logps/rejected": -124.79002380371094,
      "loss": 0.4022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5565750002861023,
      "rewards/margins": 0.7045966982841492,
      "rewards/rejected": -0.14802169799804688,
      "step": 261
    },
    {
      "epoch": 0.1048,
      "grad_norm": 11.923142433166504,
      "learning_rate": 9.651999999999999e-07,
      "logits/chosen": -1.5806279182434082,
      "logits/rejected": -1.8267011642456055,
      "logps/chosen": -109.14571380615234,
      "logps/rejected": -106.8717041015625,
      "loss": 0.4414,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4895431697368622,
      "rewards/margins": 0.6323383450508118,
      "rewards/rejected": -0.14279517531394958,
      "step": 262
    },
    {
      "epoch": 0.1052,
      "grad_norm": 12.957624435424805,
      "learning_rate": 9.650666666666667e-07,
      "logits/chosen": -1.6351819038391113,
      "logits/rejected": -2.181095600128174,
      "logps/chosen": -119.09001922607422,
      "logps/rejected": -115.56104278564453,
      "loss": 0.4543,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22364579141139984,
      "rewards/margins": 0.5571655035018921,
      "rewards/rejected": -0.33351975679397583,
      "step": 263
    },
    {
      "epoch": 0.1056,
      "grad_norm": 14.71950626373291,
      "learning_rate": 9.649333333333333e-07,
      "logits/chosen": -1.5031843185424805,
      "logits/rejected": -2.155705213546753,
      "logps/chosen": -92.73391723632812,
      "logps/rejected": -108.80449676513672,
      "loss": 0.4393,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16787758469581604,
      "rewards/margins": 0.5957512259483337,
      "rewards/rejected": -0.4278736114501953,
      "step": 264
    },
    {
      "epoch": 0.106,
      "grad_norm": 12.255167961120605,
      "learning_rate": 9.647999999999999e-07,
      "logits/chosen": -2.1706669330596924,
      "logits/rejected": -1.5778170824050903,
      "logps/chosen": -169.06385803222656,
      "logps/rejected": -89.34149169921875,
      "loss": 0.3383,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7389877438545227,
      "rewards/margins": 0.9313598871231079,
      "rewards/rejected": -0.1923721432685852,
      "step": 265
    },
    {
      "epoch": 0.1064,
      "grad_norm": 12.810718536376953,
      "learning_rate": 9.646666666666666e-07,
      "logits/chosen": -2.113994598388672,
      "logits/rejected": -2.246091842651367,
      "logps/chosen": -141.31121826171875,
      "logps/rejected": -94.7398681640625,
      "loss": 0.4456,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24442750215530396,
      "rewards/margins": 0.5775673389434814,
      "rewards/rejected": -0.3331398069858551,
      "step": 266
    },
    {
      "epoch": 0.1068,
      "grad_norm": 12.814823150634766,
      "learning_rate": 9.645333333333332e-07,
      "logits/chosen": -2.577113151550293,
      "logits/rejected": -1.9904897212982178,
      "logps/chosen": -154.8084716796875,
      "logps/rejected": -95.49163055419922,
      "loss": 0.3742,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5887168645858765,
      "rewards/margins": 0.7901100516319275,
      "rewards/rejected": -0.20139312744140625,
      "step": 267
    },
    {
      "epoch": 0.1072,
      "grad_norm": 12.490878105163574,
      "learning_rate": 9.644e-07,
      "logits/chosen": -1.4608542919158936,
      "logits/rejected": -2.34346079826355,
      "logps/chosen": -87.32855987548828,
      "logps/rejected": -93.2695541381836,
      "loss": 0.431,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4067363739013672,
      "rewards/margins": 0.6186774969100952,
      "rewards/rejected": -0.21194115281105042,
      "step": 268
    },
    {
      "epoch": 0.1076,
      "grad_norm": 13.632731437683105,
      "learning_rate": 9.642666666666666e-07,
      "logits/chosen": -1.5706424713134766,
      "logits/rejected": -1.5374231338500977,
      "logps/chosen": -89.33229064941406,
      "logps/rejected": -75.82127380371094,
      "loss": 0.4167,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6319893002510071,
      "rewards/margins": 0.6601657867431641,
      "rewards/rejected": -0.028176497668027878,
      "step": 269
    },
    {
      "epoch": 0.108,
      "grad_norm": 13.949299812316895,
      "learning_rate": 9.641333333333332e-07,
      "logits/chosen": -2.299685478210449,
      "logits/rejected": -2.457095146179199,
      "logps/chosen": -180.1892547607422,
      "logps/rejected": -129.17735290527344,
      "loss": 0.3484,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5437561273574829,
      "rewards/margins": 0.9170010089874268,
      "rewards/rejected": -0.37324488162994385,
      "step": 270
    },
    {
      "epoch": 0.1084,
      "grad_norm": 13.616464614868164,
      "learning_rate": 9.64e-07,
      "logits/chosen": -1.808245062828064,
      "logits/rejected": -2.702030658721924,
      "logps/chosen": -105.7900619506836,
      "logps/rejected": -91.72907257080078,
      "loss": 0.4375,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5208076238632202,
      "rewards/margins": 0.605634331703186,
      "rewards/rejected": -0.08482666313648224,
      "step": 271
    },
    {
      "epoch": 0.1088,
      "grad_norm": 14.529186248779297,
      "learning_rate": 9.638666666666666e-07,
      "logits/chosen": -1.9646403789520264,
      "logits/rejected": -2.3881032466888428,
      "logps/chosen": -157.9747314453125,
      "logps/rejected": -126.92338562011719,
      "loss": 0.4478,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.360015869140625,
      "rewards/margins": 0.573615312576294,
      "rewards/rejected": -0.21359939873218536,
      "step": 272
    },
    {
      "epoch": 0.1092,
      "grad_norm": 16.15298843383789,
      "learning_rate": 9.637333333333334e-07,
      "logits/chosen": -2.059417486190796,
      "logits/rejected": -2.5135841369628906,
      "logps/chosen": -159.54086303710938,
      "logps/rejected": -153.89810180664062,
      "loss": 0.4112,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5374259948730469,
      "rewards/margins": 0.6776069402694702,
      "rewards/rejected": -0.14018097519874573,
      "step": 273
    },
    {
      "epoch": 0.1096,
      "grad_norm": 14.441097259521484,
      "learning_rate": 9.636e-07,
      "logits/chosen": -1.60220468044281,
      "logits/rejected": -2.8087642192840576,
      "logps/chosen": -160.77578735351562,
      "logps/rejected": -187.2012481689453,
      "loss": 0.388,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6046172976493835,
      "rewards/margins": 0.746899425983429,
      "rewards/rejected": -0.14228211343288422,
      "step": 274
    },
    {
      "epoch": 0.11,
      "grad_norm": 14.174406051635742,
      "learning_rate": 9.634666666666666e-07,
      "logits/chosen": -1.6434221267700195,
      "logits/rejected": -2.659200668334961,
      "logps/chosen": -109.69621276855469,
      "logps/rejected": -116.26573181152344,
      "loss": 0.5175,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24618759751319885,
      "rewards/margins": 0.3949470520019531,
      "rewards/rejected": -0.14875945448875427,
      "step": 275
    },
    {
      "epoch": 0.1104,
      "grad_norm": 13.706230163574219,
      "learning_rate": 9.633333333333334e-07,
      "logits/chosen": -1.96561861038208,
      "logits/rejected": -1.7666106224060059,
      "logps/chosen": -135.7518768310547,
      "logps/rejected": -99.56953430175781,
      "loss": 0.5474,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.227131649851799,
      "rewards/margins": 0.3184940218925476,
      "rewards/rejected": -0.0913623794913292,
      "step": 276
    },
    {
      "epoch": 0.1108,
      "grad_norm": 14.198793411254883,
      "learning_rate": 9.632e-07,
      "logits/chosen": -2.131075382232666,
      "logits/rejected": -2.222280979156494,
      "logps/chosen": -166.10751342773438,
      "logps/rejected": -111.48271179199219,
      "loss": 0.4293,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39697265625,
      "rewards/margins": 0.6355884671211243,
      "rewards/rejected": -0.23861581087112427,
      "step": 277
    },
    {
      "epoch": 0.1112,
      "grad_norm": 10.941250801086426,
      "learning_rate": 9.630666666666665e-07,
      "logits/chosen": -2.07045578956604,
      "logits/rejected": -1.7385600805282593,
      "logps/chosen": -143.64100646972656,
      "logps/rejected": -104.48219299316406,
      "loss": 0.3398,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7541378140449524,
      "rewards/margins": 0.9048290252685547,
      "rewards/rejected": -0.1506912261247635,
      "step": 278
    },
    {
      "epoch": 0.1116,
      "grad_norm": 16.170984268188477,
      "learning_rate": 9.629333333333333e-07,
      "logits/chosen": -2.4641847610473633,
      "logits/rejected": -2.96100115776062,
      "logps/chosen": -155.5049591064453,
      "logps/rejected": -128.6614532470703,
      "loss": 0.3496,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6048153042793274,
      "rewards/margins": 0.8883018493652344,
      "rewards/rejected": -0.28348657488822937,
      "step": 279
    },
    {
      "epoch": 0.112,
      "grad_norm": 10.861207008361816,
      "learning_rate": 9.628e-07,
      "logits/chosen": -1.5554205179214478,
      "logits/rejected": -1.966877818107605,
      "logps/chosen": -103.84083557128906,
      "logps/rejected": -93.73564147949219,
      "loss": 0.4011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4433143734931946,
      "rewards/margins": 0.7564064264297485,
      "rewards/rejected": -0.31309205293655396,
      "step": 280
    },
    {
      "epoch": 0.1124,
      "grad_norm": 16.86087989807129,
      "learning_rate": 9.626666666666667e-07,
      "logits/chosen": -2.0318076610565186,
      "logits/rejected": -2.2931957244873047,
      "logps/chosen": -121.47476196289062,
      "logps/rejected": -113.82978820800781,
      "loss": 0.6005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03026122972369194,
      "rewards/margins": 0.19605103135108948,
      "rewards/rejected": -0.16578979790210724,
      "step": 281
    },
    {
      "epoch": 0.1128,
      "grad_norm": 10.541813850402832,
      "learning_rate": 9.625333333333333e-07,
      "logits/chosen": -2.0686566829681396,
      "logits/rejected": -1.7719664573669434,
      "logps/chosen": -111.71642303466797,
      "logps/rejected": -79.50823211669922,
      "loss": 0.4039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6062930822372437,
      "rewards/margins": 0.7064918279647827,
      "rewards/rejected": -0.10019874572753906,
      "step": 282
    },
    {
      "epoch": 0.1132,
      "grad_norm": 15.196579933166504,
      "learning_rate": 9.624e-07,
      "logits/chosen": -1.823004961013794,
      "logits/rejected": -2.2738234996795654,
      "logps/chosen": -130.42620849609375,
      "logps/rejected": -137.06317138671875,
      "loss": 0.4314,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4289790987968445,
      "rewards/margins": 0.6248573064804077,
      "rewards/rejected": -0.19587822258472443,
      "step": 283
    },
    {
      "epoch": 0.1136,
      "grad_norm": 13.254646301269531,
      "learning_rate": 9.622666666666667e-07,
      "logits/chosen": -1.6032708883285522,
      "logits/rejected": -1.796459674835205,
      "logps/chosen": -105.35039520263672,
      "logps/rejected": -100.4823226928711,
      "loss": 0.4508,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4079548120498657,
      "rewards/margins": 0.5641731023788452,
      "rewards/rejected": -0.15621833503246307,
      "step": 284
    },
    {
      "epoch": 0.114,
      "grad_norm": 12.205452919006348,
      "learning_rate": 9.621333333333333e-07,
      "logits/chosen": -1.9285612106323242,
      "logits/rejected": -2.0166232585906982,
      "logps/chosen": -134.33636474609375,
      "logps/rejected": -114.4319076538086,
      "loss": 0.3633,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5674408078193665,
      "rewards/margins": 0.8448017239570618,
      "rewards/rejected": -0.2773609161376953,
      "step": 285
    },
    {
      "epoch": 0.1144,
      "grad_norm": 13.710352897644043,
      "learning_rate": 9.619999999999999e-07,
      "logits/chosen": -2.447223663330078,
      "logits/rejected": -1.9562852382659912,
      "logps/chosen": -229.28265380859375,
      "logps/rejected": -103.91162872314453,
      "loss": 0.316,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7774956226348877,
      "rewards/margins": 1.0263240337371826,
      "rewards/rejected": -0.24882851541042328,
      "step": 286
    },
    {
      "epoch": 0.1148,
      "grad_norm": 11.021951675415039,
      "learning_rate": 9.618666666666667e-07,
      "logits/chosen": -1.9942350387573242,
      "logits/rejected": -1.22480309009552,
      "logps/chosen": -119.92402648925781,
      "logps/rejected": -80.40452575683594,
      "loss": 0.4877,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.43754690885543823,
      "rewards/margins": 0.4660850465297699,
      "rewards/rejected": -0.028538133949041367,
      "step": 287
    },
    {
      "epoch": 0.1152,
      "grad_norm": 11.910274505615234,
      "learning_rate": 9.617333333333332e-07,
      "logits/chosen": -1.96437406539917,
      "logits/rejected": -1.9358832836151123,
      "logps/chosen": -135.69320678710938,
      "logps/rejected": -94.74333190917969,
      "loss": 0.4475,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5837554931640625,
      "rewards/margins": 0.6064090728759766,
      "rewards/rejected": -0.022653579711914062,
      "step": 288
    },
    {
      "epoch": 0.1156,
      "grad_norm": 12.223573684692383,
      "learning_rate": 9.616e-07,
      "logits/chosen": -2.1841092109680176,
      "logits/rejected": -2.469616413116455,
      "logps/chosen": -141.5284423828125,
      "logps/rejected": -119.0548095703125,
      "loss": 0.3472,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6530395746231079,
      "rewards/margins": 0.8791583776473999,
      "rewards/rejected": -0.22611886262893677,
      "step": 289
    },
    {
      "epoch": 0.116,
      "grad_norm": 9.239107131958008,
      "learning_rate": 9.614666666666666e-07,
      "logits/chosen": -1.969975471496582,
      "logits/rejected": -1.9230351448059082,
      "logps/chosen": -110.49855041503906,
      "logps/rejected": -75.00497436523438,
      "loss": 0.3356,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6847175359725952,
      "rewards/margins": 0.9320671558380127,
      "rewards/rejected": -0.2473495602607727,
      "step": 290
    },
    {
      "epoch": 0.1164,
      "grad_norm": 12.382530212402344,
      "learning_rate": 9.613333333333334e-07,
      "logits/chosen": -2.270829677581787,
      "logits/rejected": -2.456331968307495,
      "logps/chosen": -118.67245483398438,
      "logps/rejected": -88.2711181640625,
      "loss": 0.5034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.39361533522605896,
      "rewards/margins": 0.44158250093460083,
      "rewards/rejected": -0.047967150807380676,
      "step": 291
    },
    {
      "epoch": 0.1168,
      "grad_norm": 17.528404235839844,
      "learning_rate": 9.612e-07,
      "logits/chosen": -2.2578470706939697,
      "logits/rejected": -1.6357388496398926,
      "logps/chosen": -219.80523681640625,
      "logps/rejected": -150.09262084960938,
      "loss": 0.3829,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5295112729072571,
      "rewards/margins": 0.7951278686523438,
      "rewards/rejected": -0.26561662554740906,
      "step": 292
    },
    {
      "epoch": 0.1172,
      "grad_norm": 11.938892364501953,
      "learning_rate": 9.610666666666666e-07,
      "logits/chosen": -1.9261858463287354,
      "logits/rejected": -2.4814350605010986,
      "logps/chosen": -155.42689514160156,
      "logps/rejected": -106.7828140258789,
      "loss": 0.374,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4703819453716278,
      "rewards/margins": 0.7906948328018188,
      "rewards/rejected": -0.32031288743019104,
      "step": 293
    },
    {
      "epoch": 0.1176,
      "grad_norm": 12.196470260620117,
      "learning_rate": 9.609333333333332e-07,
      "logits/chosen": -2.1155619621276855,
      "logits/rejected": -1.6123104095458984,
      "logps/chosen": -144.27293395996094,
      "logps/rejected": -110.16448211669922,
      "loss": 0.4257,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4105846583843231,
      "rewards/margins": 0.6906574964523315,
      "rewards/rejected": -0.28007280826568604,
      "step": 294
    },
    {
      "epoch": 0.118,
      "grad_norm": 14.276862144470215,
      "learning_rate": 9.608e-07,
      "logits/chosen": -1.6354470252990723,
      "logits/rejected": -2.095930576324463,
      "logps/chosen": -123.89559173583984,
      "logps/rejected": -106.47134399414062,
      "loss": 0.4381,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45509567856788635,
      "rewards/margins": 0.598432183265686,
      "rewards/rejected": -0.1433364897966385,
      "step": 295
    },
    {
      "epoch": 0.1184,
      "grad_norm": 14.819598197937012,
      "learning_rate": 9.606666666666666e-07,
      "logits/chosen": -1.9527920484542847,
      "logits/rejected": -2.4182543754577637,
      "logps/chosen": -115.63445281982422,
      "logps/rejected": -116.065673828125,
      "loss": 0.3461,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41061514616012573,
      "rewards/margins": 0.8945556282997131,
      "rewards/rejected": -0.4839405119419098,
      "step": 296
    },
    {
      "epoch": 0.1188,
      "grad_norm": 14.786139488220215,
      "learning_rate": 9.605333333333334e-07,
      "logits/chosen": -2.6746888160705566,
      "logits/rejected": -2.6630215644836426,
      "logps/chosen": -222.24911499023438,
      "logps/rejected": -87.84962463378906,
      "loss": 0.3554,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7071526050567627,
      "rewards/margins": 0.859463095664978,
      "rewards/rejected": -0.1523105651140213,
      "step": 297
    },
    {
      "epoch": 0.1192,
      "grad_norm": 16.786563873291016,
      "learning_rate": 9.604e-07,
      "logits/chosen": -2.3788492679595947,
      "logits/rejected": -2.739400625228882,
      "logps/chosen": -277.93994140625,
      "logps/rejected": -106.21590423583984,
      "loss": 0.3665,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.568804144859314,
      "rewards/margins": 0.8235050439834595,
      "rewards/rejected": -0.2547008693218231,
      "step": 298
    },
    {
      "epoch": 0.1196,
      "grad_norm": 14.5476713180542,
      "learning_rate": 9.602666666666667e-07,
      "logits/chosen": -2.568037509918213,
      "logits/rejected": -2.0788893699645996,
      "logps/chosen": -158.58004760742188,
      "logps/rejected": -107.69029235839844,
      "loss": 0.4625,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3375355005264282,
      "rewards/margins": 0.5526905059814453,
      "rewards/rejected": -0.21515503525733948,
      "step": 299
    },
    {
      "epoch": 0.12,
      "grad_norm": 12.40864372253418,
      "learning_rate": 9.601333333333333e-07,
      "logits/chosen": -2.3200607299804688,
      "logits/rejected": -2.2355618476867676,
      "logps/chosen": -164.9247283935547,
      "logps/rejected": -111.97676849365234,
      "loss": 0.3938,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5528885126113892,
      "rewards/margins": 0.8012443780899048,
      "rewards/rejected": -0.24835586547851562,
      "step": 300
    },
    {
      "epoch": 0.1204,
      "grad_norm": 10.663963317871094,
      "learning_rate": 9.6e-07,
      "logits/chosen": -2.020142078399658,
      "logits/rejected": -1.3340409994125366,
      "logps/chosen": -137.63560485839844,
      "logps/rejected": -73.5970687866211,
      "loss": 0.3668,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6810901761054993,
      "rewards/margins": 0.8139957189559937,
      "rewards/rejected": -0.13290557265281677,
      "step": 301
    },
    {
      "epoch": 0.1208,
      "grad_norm": 13.159858703613281,
      "learning_rate": 9.598666666666665e-07,
      "logits/chosen": -2.058608055114746,
      "logits/rejected": -1.8802704811096191,
      "logps/chosen": -167.01620483398438,
      "logps/rejected": -94.14705657958984,
      "loss": 0.35,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5670463442802429,
      "rewards/margins": 0.8715389370918274,
      "rewards/rejected": -0.3044925630092621,
      "step": 302
    },
    {
      "epoch": 0.1212,
      "grad_norm": 14.050731658935547,
      "learning_rate": 9.597333333333333e-07,
      "logits/chosen": -2.1952905654907227,
      "logits/rejected": -2.5662851333618164,
      "logps/chosen": -141.9801025390625,
      "logps/rejected": -181.38534545898438,
      "loss": 0.3053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7144893407821655,
      "rewards/margins": 1.0440860986709595,
      "rewards/rejected": -0.32959669828414917,
      "step": 303
    },
    {
      "epoch": 0.1216,
      "grad_norm": 12.985161781311035,
      "learning_rate": 9.595999999999999e-07,
      "logits/chosen": -2.288228750228882,
      "logits/rejected": -1.903712272644043,
      "logps/chosen": -198.84637451171875,
      "logps/rejected": -102.85623931884766,
      "loss": 0.3741,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7462104558944702,
      "rewards/margins": 0.7936439514160156,
      "rewards/rejected": -0.04743346944451332,
      "step": 304
    },
    {
      "epoch": 0.122,
      "grad_norm": 11.640898704528809,
      "learning_rate": 9.594666666666667e-07,
      "logits/chosen": -2.058647394180298,
      "logits/rejected": -2.224377155303955,
      "logps/chosen": -163.2994384765625,
      "logps/rejected": -105.71807098388672,
      "loss": 0.4207,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6801013946533203,
      "rewards/margins": 0.7357528209686279,
      "rewards/rejected": -0.055651478469371796,
      "step": 305
    },
    {
      "epoch": 0.1224,
      "grad_norm": 14.999980926513672,
      "learning_rate": 9.593333333333333e-07,
      "logits/chosen": -1.9643926620483398,
      "logits/rejected": -2.6374833583831787,
      "logps/chosen": -137.06289672851562,
      "logps/rejected": -122.50288391113281,
      "loss": 0.4377,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33203619718551636,
      "rewards/margins": 0.6025474667549133,
      "rewards/rejected": -0.270511269569397,
      "step": 306
    },
    {
      "epoch": 0.1228,
      "grad_norm": 14.916993141174316,
      "learning_rate": 9.592e-07,
      "logits/chosen": -1.9617637395858765,
      "logits/rejected": -2.258445978164673,
      "logps/chosen": -131.87094116210938,
      "logps/rejected": -93.09133911132812,
      "loss": 0.4291,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.492239385843277,
      "rewards/margins": 0.659641683101654,
      "rewards/rejected": -0.1674022674560547,
      "step": 307
    },
    {
      "epoch": 0.1232,
      "grad_norm": 11.987850189208984,
      "learning_rate": 9.590666666666667e-07,
      "logits/chosen": -2.1662557125091553,
      "logits/rejected": -2.093965530395508,
      "logps/chosen": -166.61483764648438,
      "logps/rejected": -157.8675537109375,
      "loss": 0.3608,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7445014715194702,
      "rewards/margins": 0.836090087890625,
      "rewards/rejected": -0.091588594019413,
      "step": 308
    },
    {
      "epoch": 0.1236,
      "grad_norm": 12.436102867126465,
      "learning_rate": 9.589333333333332e-07,
      "logits/chosen": -2.1055893898010254,
      "logits/rejected": -1.5288081169128418,
      "logps/chosen": -179.09536743164062,
      "logps/rejected": -99.20947265625,
      "loss": 0.2563,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9129433035850525,
      "rewards/margins": 1.2405757904052734,
      "rewards/rejected": -0.3276325464248657,
      "step": 309
    },
    {
      "epoch": 0.124,
      "grad_norm": 11.942190170288086,
      "learning_rate": 9.588e-07,
      "logits/chosen": -2.3960509300231934,
      "logits/rejected": -2.079711675643921,
      "logps/chosen": -187.5016326904297,
      "logps/rejected": -107.17412567138672,
      "loss": 0.2872,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8936004638671875,
      "rewards/margins": 1.2133773565292358,
      "rewards/rejected": -0.3197769224643707,
      "step": 310
    },
    {
      "epoch": 0.1244,
      "grad_norm": 11.078207969665527,
      "learning_rate": 9.586666666666666e-07,
      "logits/chosen": -1.915602684020996,
      "logits/rejected": -1.677961826324463,
      "logps/chosen": -115.867431640625,
      "logps/rejected": -93.24171447753906,
      "loss": 0.433,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6520645022392273,
      "rewards/margins": 0.6147556304931641,
      "rewards/rejected": 0.03730888292193413,
      "step": 311
    },
    {
      "epoch": 0.1248,
      "grad_norm": 10.957127571105957,
      "learning_rate": 9.585333333333332e-07,
      "logits/chosen": -2.038909912109375,
      "logits/rejected": -2.6339728832244873,
      "logps/chosen": -169.66282653808594,
      "logps/rejected": -127.91425323486328,
      "loss": 0.2622,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8870781064033508,
      "rewards/margins": 1.206984281539917,
      "rewards/rejected": -0.31990623474121094,
      "step": 312
    },
    {
      "epoch": 0.1252,
      "grad_norm": 9.657113075256348,
      "learning_rate": 9.584e-07,
      "logits/chosen": -2.0026679039001465,
      "logits/rejected": -1.0023781061172485,
      "logps/chosen": -130.56137084960938,
      "logps/rejected": -72.73910522460938,
      "loss": 0.4211,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6541957855224609,
      "rewards/margins": 0.6586955785751343,
      "rewards/rejected": -0.004499815404415131,
      "step": 313
    },
    {
      "epoch": 0.1256,
      "grad_norm": 10.376707077026367,
      "learning_rate": 9.582666666666666e-07,
      "logits/chosen": -2.3139424324035645,
      "logits/rejected": -2.542186737060547,
      "logps/chosen": -124.09696960449219,
      "logps/rejected": -119.01596069335938,
      "loss": 0.2727,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8785732388496399,
      "rewards/margins": 1.163343071937561,
      "rewards/rejected": -0.28476983308792114,
      "step": 314
    },
    {
      "epoch": 0.126,
      "grad_norm": 14.284221649169922,
      "learning_rate": 9.581333333333332e-07,
      "logits/chosen": -1.691880702972412,
      "logits/rejected": -1.9907406568527222,
      "logps/chosen": -140.1698455810547,
      "logps/rejected": -93.45320129394531,
      "loss": 0.5539,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3637496829032898,
      "rewards/margins": 0.3015918731689453,
      "rewards/rejected": 0.062157824635505676,
      "step": 315
    },
    {
      "epoch": 0.1264,
      "grad_norm": 12.131782531738281,
      "learning_rate": 9.58e-07,
      "logits/chosen": -2.175274610519409,
      "logits/rejected": -2.0548791885375977,
      "logps/chosen": -175.84104919433594,
      "logps/rejected": -151.5435333251953,
      "loss": 0.4274,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.684238851070404,
      "rewards/margins": 0.7764854431152344,
      "rewards/rejected": -0.09224662184715271,
      "step": 316
    },
    {
      "epoch": 0.1268,
      "grad_norm": 13.421792030334473,
      "learning_rate": 9.578666666666666e-07,
      "logits/chosen": -1.858530879020691,
      "logits/rejected": -2.8102331161499023,
      "logps/chosen": -146.52438354492188,
      "logps/rejected": -119.43385314941406,
      "loss": 0.3082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6565731167793274,
      "rewards/margins": 1.033708930015564,
      "rewards/rejected": -0.37713584303855896,
      "step": 317
    },
    {
      "epoch": 0.1272,
      "grad_norm": 13.030791282653809,
      "learning_rate": 9.577333333333334e-07,
      "logits/chosen": -1.7606556415557861,
      "logits/rejected": -2.333479642868042,
      "logps/chosen": -183.80255126953125,
      "logps/rejected": -167.63864135742188,
      "loss": 0.2515,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8599929809570312,
      "rewards/margins": 1.2517859935760498,
      "rewards/rejected": -0.39179307222366333,
      "step": 318
    },
    {
      "epoch": 0.1276,
      "grad_norm": 13.80737018585205,
      "learning_rate": 9.576e-07,
      "logits/chosen": -1.8543338775634766,
      "logits/rejected": -3.0451345443725586,
      "logps/chosen": -198.4344482421875,
      "logps/rejected": -172.7421112060547,
      "loss": 0.2964,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5486297607421875,
      "rewards/margins": 1.06842041015625,
      "rewards/rejected": -0.5197906494140625,
      "step": 319
    },
    {
      "epoch": 0.128,
      "grad_norm": 11.926711082458496,
      "learning_rate": 9.574666666666667e-07,
      "logits/chosen": -2.2329564094543457,
      "logits/rejected": -2.427905797958374,
      "logps/chosen": -195.26426696777344,
      "logps/rejected": -137.20236206054688,
      "loss": 0.3332,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7112144827842712,
      "rewards/margins": 0.9315564036369324,
      "rewards/rejected": -0.22034187614917755,
      "step": 320
    },
    {
      "epoch": 0.1284,
      "grad_norm": 11.058405876159668,
      "learning_rate": 9.573333333333333e-07,
      "logits/chosen": -2.170854091644287,
      "logits/rejected": -2.284374713897705,
      "logps/chosen": -193.06680297851562,
      "logps/rejected": -99.57476806640625,
      "loss": 0.2982,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9952560663223267,
      "rewards/margins": 1.0578136444091797,
      "rewards/rejected": -0.06255760788917542,
      "step": 321
    },
    {
      "epoch": 0.1288,
      "grad_norm": 11.332831382751465,
      "learning_rate": 9.572e-07,
      "logits/chosen": -2.208094358444214,
      "logits/rejected": -2.789024829864502,
      "logps/chosen": -159.32907104492188,
      "logps/rejected": -152.3526611328125,
      "loss": 0.3001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8543083667755127,
      "rewards/margins": 1.0501617193222046,
      "rewards/rejected": -0.19585342705249786,
      "step": 322
    },
    {
      "epoch": 0.1292,
      "grad_norm": 11.533520698547363,
      "learning_rate": 9.570666666666665e-07,
      "logits/chosen": -1.9344141483306885,
      "logits/rejected": -1.6428004503250122,
      "logps/chosen": -126.77522277832031,
      "logps/rejected": -104.25895690917969,
      "loss": 0.4609,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5018707513809204,
      "rewards/margins": 0.5582630038261414,
      "rewards/rejected": -0.05639229714870453,
      "step": 323
    },
    {
      "epoch": 0.1296,
      "grad_norm": 11.75419807434082,
      "learning_rate": 9.569333333333333e-07,
      "logits/chosen": -2.2427096366882324,
      "logits/rejected": -2.6767568588256836,
      "logps/chosen": -148.96722412109375,
      "logps/rejected": -121.97100830078125,
      "loss": 0.3111,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5852543115615845,
      "rewards/margins": 1.0097222328186035,
      "rewards/rejected": -0.42446786165237427,
      "step": 324
    },
    {
      "epoch": 0.13,
      "grad_norm": 9.735590934753418,
      "learning_rate": 9.567999999999999e-07,
      "logits/chosen": -2.254542350769043,
      "logits/rejected": -1.5541445016860962,
      "logps/chosen": -143.7095947265625,
      "logps/rejected": -86.95208740234375,
      "loss": 0.3342,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0367828607559204,
      "rewards/margins": 1.017345905303955,
      "rewards/rejected": 0.0194370299577713,
      "step": 325
    },
    {
      "epoch": 0.1304,
      "grad_norm": 12.297895431518555,
      "learning_rate": 9.566666666666667e-07,
      "logits/chosen": -2.00960111618042,
      "logits/rejected": -2.3351025581359863,
      "logps/chosen": -100.96467590332031,
      "logps/rejected": -118.62254333496094,
      "loss": 0.4289,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3766746520996094,
      "rewards/margins": 0.6250816583633423,
      "rewards/rejected": -0.24840699136257172,
      "step": 326
    },
    {
      "epoch": 0.1308,
      "grad_norm": 11.732319831848145,
      "learning_rate": 9.565333333333333e-07,
      "logits/chosen": -1.6790229082107544,
      "logits/rejected": -2.071122646331787,
      "logps/chosen": -86.78253936767578,
      "logps/rejected": -90.49698638916016,
      "loss": 0.5167,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33662301301956177,
      "rewards/margins": 0.41987189650535583,
      "rewards/rejected": -0.08324889838695526,
      "step": 327
    },
    {
      "epoch": 0.1312,
      "grad_norm": 7.506840229034424,
      "learning_rate": 9.564e-07,
      "logits/chosen": -2.361652135848999,
      "logits/rejected": -2.6782002449035645,
      "logps/chosen": -167.8133087158203,
      "logps/rejected": -130.01739501953125,
      "loss": 0.1581,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1103591918945312,
      "rewards/margins": 1.7668159008026123,
      "rewards/rejected": -0.6564567685127258,
      "step": 328
    },
    {
      "epoch": 0.1316,
      "grad_norm": 10.992173194885254,
      "learning_rate": 9.562666666666667e-07,
      "logits/chosen": -2.296079158782959,
      "logits/rejected": -2.2335174083709717,
      "logps/chosen": -200.86203002929688,
      "logps/rejected": -87.53048706054688,
      "loss": 0.2611,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9115607738494873,
      "rewards/margins": 1.2935978174209595,
      "rewards/rejected": -0.3820369839668274,
      "step": 329
    },
    {
      "epoch": 0.132,
      "grad_norm": 15.394968032836914,
      "learning_rate": 9.561333333333332e-07,
      "logits/chosen": -1.6588709354400635,
      "logits/rejected": -1.9331907033920288,
      "logps/chosen": -118.10418701171875,
      "logps/rejected": -90.86491394042969,
      "loss": 0.5889,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11032639443874359,
      "rewards/margins": 0.22175446152687073,
      "rewards/rejected": -0.11142807453870773,
      "step": 330
    },
    {
      "epoch": 0.1324,
      "grad_norm": 12.797173500061035,
      "learning_rate": 9.559999999999998e-07,
      "logits/chosen": -1.4791088104248047,
      "logits/rejected": -2.070399761199951,
      "logps/chosen": -117.97552490234375,
      "logps/rejected": -93.49156951904297,
      "loss": 0.4149,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7531921863555908,
      "rewards/margins": 0.6690124273300171,
      "rewards/rejected": 0.08417969197034836,
      "step": 331
    },
    {
      "epoch": 0.1328,
      "grad_norm": 11.30887508392334,
      "learning_rate": 9.558666666666666e-07,
      "logits/chosen": -1.8146429061889648,
      "logits/rejected": -1.4118348360061646,
      "logps/chosen": -86.69029235839844,
      "logps/rejected": -85.42684173583984,
      "loss": 0.3698,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5579643249511719,
      "rewards/margins": 0.8196926116943359,
      "rewards/rejected": -0.26172828674316406,
      "step": 332
    },
    {
      "epoch": 0.1332,
      "grad_norm": 10.904187202453613,
      "learning_rate": 9.557333333333332e-07,
      "logits/chosen": -1.649134874343872,
      "logits/rejected": -1.9934391975402832,
      "logps/chosen": -107.49665832519531,
      "logps/rejected": -94.91162109375,
      "loss": 0.3847,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5585654973983765,
      "rewards/margins": 0.7625980377197266,
      "rewards/rejected": -0.2040325254201889,
      "step": 333
    },
    {
      "epoch": 0.1336,
      "grad_norm": 10.141546249389648,
      "learning_rate": 9.556e-07,
      "logits/chosen": -2.1645326614379883,
      "logits/rejected": -2.094012975692749,
      "logps/chosen": -121.65289306640625,
      "logps/rejected": -108.60608673095703,
      "loss": 0.3963,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7382984161376953,
      "rewards/margins": 0.7695339322090149,
      "rewards/rejected": -0.031235501170158386,
      "step": 334
    },
    {
      "epoch": 0.134,
      "grad_norm": 10.338302612304688,
      "learning_rate": 9.554666666666666e-07,
      "logits/chosen": -1.9099140167236328,
      "logits/rejected": -1.711198091506958,
      "logps/chosen": -141.37588500976562,
      "logps/rejected": -83.49897766113281,
      "loss": 0.3438,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7056339383125305,
      "rewards/margins": 0.8964035511016846,
      "rewards/rejected": -0.19076958298683167,
      "step": 335
    },
    {
      "epoch": 0.1344,
      "grad_norm": 9.51525592803955,
      "learning_rate": 9.553333333333334e-07,
      "logits/chosen": -1.9487619400024414,
      "logits/rejected": -2.1649580001831055,
      "logps/chosen": -121.84542083740234,
      "logps/rejected": -101.561767578125,
      "loss": 0.2909,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9277992248535156,
      "rewards/margins": 1.1176254749298096,
      "rewards/rejected": -0.18982620537281036,
      "step": 336
    },
    {
      "epoch": 0.1348,
      "grad_norm": 10.147809028625488,
      "learning_rate": 9.552e-07,
      "logits/chosen": -2.257451057434082,
      "logits/rejected": -1.9222394227981567,
      "logps/chosen": -191.10719299316406,
      "logps/rejected": -85.64939880371094,
      "loss": 0.2309,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1129478216171265,
      "rewards/margins": 1.3723182678222656,
      "rewards/rejected": -0.25937044620513916,
      "step": 337
    },
    {
      "epoch": 0.1352,
      "grad_norm": 12.834878921508789,
      "learning_rate": 9.550666666666666e-07,
      "logits/chosen": -1.7756242752075195,
      "logits/rejected": -2.4170122146606445,
      "logps/chosen": -118.72027587890625,
      "logps/rejected": -107.18551635742188,
      "loss": 0.4657,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38856619596481323,
      "rewards/margins": 0.5436553955078125,
      "rewards/rejected": -0.15508919954299927,
      "step": 338
    },
    {
      "epoch": 0.1356,
      "grad_norm": 8.74482536315918,
      "learning_rate": 9.549333333333334e-07,
      "logits/chosen": -2.071829319000244,
      "logits/rejected": -2.2646644115448,
      "logps/chosen": -107.88862609863281,
      "logps/rejected": -101.2119140625,
      "loss": 0.2349,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8171809911727905,
      "rewards/margins": 1.3466548919677734,
      "rewards/rejected": -0.5294739007949829,
      "step": 339
    },
    {
      "epoch": 0.136,
      "grad_norm": 12.520222663879395,
      "learning_rate": 9.548e-07,
      "logits/chosen": -1.8740763664245605,
      "logits/rejected": -1.7102367877960205,
      "logps/chosen": -113.11312103271484,
      "logps/rejected": -92.58493041992188,
      "loss": 0.4299,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6516456604003906,
      "rewards/margins": 0.6301235556602478,
      "rewards/rejected": 0.02152213454246521,
      "step": 340
    },
    {
      "epoch": 0.1364,
      "grad_norm": 8.720784187316895,
      "learning_rate": 9.546666666666665e-07,
      "logits/chosen": -2.001288890838623,
      "logits/rejected": -2.1833841800689697,
      "logps/chosen": -159.24212646484375,
      "logps/rejected": -96.96380615234375,
      "loss": 0.2513,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.082759141921997,
      "rewards/margins": 1.3303020000457764,
      "rewards/rejected": -0.24754294753074646,
      "step": 341
    },
    {
      "epoch": 0.1368,
      "grad_norm": 13.765422821044922,
      "learning_rate": 9.545333333333333e-07,
      "logits/chosen": -2.085275173187256,
      "logits/rejected": -2.728032112121582,
      "logps/chosen": -157.38633728027344,
      "logps/rejected": -98.18443298339844,
      "loss": 0.3213,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8185989260673523,
      "rewards/margins": 1.0216732025146484,
      "rewards/rejected": -0.20307426154613495,
      "step": 342
    },
    {
      "epoch": 0.1372,
      "grad_norm": 9.867291450500488,
      "learning_rate": 9.544e-07,
      "logits/chosen": -2.5137381553649902,
      "logits/rejected": -2.128641366958618,
      "logps/chosen": -163.31146240234375,
      "logps/rejected": -113.5212173461914,
      "loss": 0.2539,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9958854913711548,
      "rewards/margins": 1.315298080444336,
      "rewards/rejected": -0.31941261887550354,
      "step": 343
    },
    {
      "epoch": 0.1376,
      "grad_norm": 10.123295783996582,
      "learning_rate": 9.542666666666667e-07,
      "logits/chosen": -2.068319082260132,
      "logits/rejected": -1.8827178478240967,
      "logps/chosen": -150.27740478515625,
      "logps/rejected": -102.6128158569336,
      "loss": 0.274,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9344837665557861,
      "rewards/margins": 1.1655871868133545,
      "rewards/rejected": -0.23110350966453552,
      "step": 344
    },
    {
      "epoch": 0.138,
      "grad_norm": 11.688067436218262,
      "learning_rate": 9.541333333333333e-07,
      "logits/chosen": -2.127321243286133,
      "logits/rejected": -2.603987216949463,
      "logps/chosen": -119.79167175292969,
      "logps/rejected": -122.39602661132812,
      "loss": 0.2632,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4507888853549957,
      "rewards/margins": 1.2014251947402954,
      "rewards/rejected": -0.7506363391876221,
      "step": 345
    },
    {
      "epoch": 0.1384,
      "grad_norm": 14.33978271484375,
      "learning_rate": 9.539999999999999e-07,
      "logits/chosen": -1.8845057487487793,
      "logits/rejected": -2.0055880546569824,
      "logps/chosen": -146.91270446777344,
      "logps/rejected": -113.65312957763672,
      "loss": 0.3626,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4611145257949829,
      "rewards/margins": 0.8436771631240845,
      "rewards/rejected": -0.38256263732910156,
      "step": 346
    },
    {
      "epoch": 0.1388,
      "grad_norm": 10.98196029663086,
      "learning_rate": 9.538666666666667e-07,
      "logits/chosen": -1.896848440170288,
      "logits/rejected": -2.1198980808258057,
      "logps/chosen": -131.83883666992188,
      "logps/rejected": -149.12075805664062,
      "loss": 0.2443,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8171112537384033,
      "rewards/margins": 1.2859902381896973,
      "rewards/rejected": -0.46887892484664917,
      "step": 347
    },
    {
      "epoch": 0.1392,
      "grad_norm": 15.018998146057129,
      "learning_rate": 9.537333333333333e-07,
      "logits/chosen": -1.6546475887298584,
      "logits/rejected": -2.3062362670898438,
      "logps/chosen": -88.27896118164062,
      "logps/rejected": -164.96200561523438,
      "loss": 0.4536,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5107277035713196,
      "rewards/margins": 0.5783588290214539,
      "rewards/rejected": -0.06763114780187607,
      "step": 348
    },
    {
      "epoch": 0.1396,
      "grad_norm": 11.12929916381836,
      "learning_rate": 9.536e-07,
      "logits/chosen": -2.2950496673583984,
      "logits/rejected": -2.369715690612793,
      "logps/chosen": -183.5143585205078,
      "logps/rejected": -110.28754425048828,
      "loss": 0.2431,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8320801258087158,
      "rewards/margins": 1.3070781230926514,
      "rewards/rejected": -0.4749981164932251,
      "step": 349
    },
    {
      "epoch": 0.14,
      "grad_norm": 9.235968589782715,
      "learning_rate": 9.534666666666667e-07,
      "logits/chosen": -1.8936326503753662,
      "logits/rejected": -2.929123878479004,
      "logps/chosen": -155.58470153808594,
      "logps/rejected": -104.74146270751953,
      "loss": 0.2588,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8917827606201172,
      "rewards/margins": 1.3213393688201904,
      "rewards/rejected": -0.429556667804718,
      "step": 350
    },
    {
      "epoch": 0.1404,
      "grad_norm": 13.856289863586426,
      "learning_rate": 9.533333333333333e-07,
      "logits/chosen": -1.919039011001587,
      "logits/rejected": -1.7163231372833252,
      "logps/chosen": -137.10513305664062,
      "logps/rejected": -97.58039093017578,
      "loss": 0.3802,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4284507930278778,
      "rewards/margins": 0.7732959985733032,
      "rewards/rejected": -0.3448452055454254,
      "step": 351
    },
    {
      "epoch": 0.1408,
      "grad_norm": 13.493905067443848,
      "learning_rate": 9.532e-07,
      "logits/chosen": -1.4531432390213013,
      "logits/rejected": -2.5324740409851074,
      "logps/chosen": -75.1290512084961,
      "logps/rejected": -120.27294921875,
      "loss": 0.4163,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4479801058769226,
      "rewards/margins": 0.6642040014266968,
      "rewards/rejected": -0.21622391045093536,
      "step": 352
    },
    {
      "epoch": 0.1412,
      "grad_norm": 12.82694149017334,
      "learning_rate": 9.530666666666666e-07,
      "logits/chosen": -1.7151232957839966,
      "logits/rejected": -2.196300506591797,
      "logps/chosen": -138.0375518798828,
      "logps/rejected": -101.56670379638672,
      "loss": 0.4329,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42985114455223083,
      "rewards/margins": 0.6267986297607422,
      "rewards/rejected": -0.19694748520851135,
      "step": 353
    },
    {
      "epoch": 0.1416,
      "grad_norm": 12.656393051147461,
      "learning_rate": 9.529333333333332e-07,
      "logits/chosen": -1.7616283893585205,
      "logits/rejected": -2.234405517578125,
      "logps/chosen": -125.9428482055664,
      "logps/rejected": -95.98524475097656,
      "loss": 0.3771,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3472389280796051,
      "rewards/margins": 0.8057087063789368,
      "rewards/rejected": -0.45846980810165405,
      "step": 354
    },
    {
      "epoch": 0.142,
      "grad_norm": 11.418084144592285,
      "learning_rate": 9.527999999999999e-07,
      "logits/chosen": -2.2805190086364746,
      "logits/rejected": -1.6600629091262817,
      "logps/chosen": -166.3076934814453,
      "logps/rejected": -100.41447448730469,
      "loss": 0.32,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8029266595840454,
      "rewards/margins": 0.9782726168632507,
      "rewards/rejected": -0.1753460019826889,
      "step": 355
    },
    {
      "epoch": 0.1424,
      "grad_norm": 14.274686813354492,
      "learning_rate": 9.526666666666666e-07,
      "logits/chosen": -2.160705327987671,
      "logits/rejected": -1.2577961683273315,
      "logps/chosen": -130.42681884765625,
      "logps/rejected": -107.40043640136719,
      "loss": 0.5507,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.37729111313819885,
      "rewards/margins": 0.46296578645706177,
      "rewards/rejected": -0.08567467331886292,
      "step": 356
    },
    {
      "epoch": 0.1428,
      "grad_norm": 11.299083709716797,
      "learning_rate": 9.525333333333333e-07,
      "logits/chosen": -1.8485956192016602,
      "logits/rejected": -2.3741636276245117,
      "logps/chosen": -167.78311157226562,
      "logps/rejected": -146.5095977783203,
      "loss": 0.2382,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.067840576171875,
      "rewards/margins": 1.313985824584961,
      "rewards/rejected": -0.24614524841308594,
      "step": 357
    },
    {
      "epoch": 0.1432,
      "grad_norm": 9.336177825927734,
      "learning_rate": 9.524e-07,
      "logits/chosen": -2.260824203491211,
      "logits/rejected": -2.607541561126709,
      "logps/chosen": -98.86637878417969,
      "logps/rejected": -103.50428009033203,
      "loss": 0.3252,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7557506561279297,
      "rewards/margins": 1.0795044898986816,
      "rewards/rejected": -0.3237537443637848,
      "step": 358
    },
    {
      "epoch": 0.1436,
      "grad_norm": 8.682798385620117,
      "learning_rate": 9.522666666666667e-07,
      "logits/chosen": -1.8525636196136475,
      "logits/rejected": -2.8452634811401367,
      "logps/chosen": -106.86477661132812,
      "logps/rejected": -112.48531341552734,
      "loss": 0.2278,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9767674207687378,
      "rewards/margins": 1.380671739578247,
      "rewards/rejected": -0.40390434861183167,
      "step": 359
    },
    {
      "epoch": 0.144,
      "grad_norm": 9.145380973815918,
      "learning_rate": 9.521333333333334e-07,
      "logits/chosen": -1.6418769359588623,
      "logits/rejected": -1.9786100387573242,
      "logps/chosen": -99.93850708007812,
      "logps/rejected": -80.95884704589844,
      "loss": 0.2996,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8148006796836853,
      "rewards/margins": 1.0917046070098877,
      "rewards/rejected": -0.2769039273262024,
      "step": 360
    },
    {
      "epoch": 0.1444,
      "grad_norm": 10.36797046661377,
      "learning_rate": 9.52e-07,
      "logits/chosen": -2.0813405513763428,
      "logits/rejected": -2.046511650085449,
      "logps/chosen": -140.75628662109375,
      "logps/rejected": -124.78031921386719,
      "loss": 0.3442,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7576786279678345,
      "rewards/margins": 1.0147217512130737,
      "rewards/rejected": -0.25704309344291687,
      "step": 361
    },
    {
      "epoch": 0.1448,
      "grad_norm": 13.570343971252441,
      "learning_rate": 9.518666666666666e-07,
      "logits/chosen": -2.005720615386963,
      "logits/rejected": -2.793525218963623,
      "logps/chosen": -175.9668731689453,
      "logps/rejected": -125.14128112792969,
      "loss": 0.3443,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6709270477294922,
      "rewards/margins": 0.9494178891181946,
      "rewards/rejected": -0.2784908413887024,
      "step": 362
    },
    {
      "epoch": 0.1452,
      "grad_norm": 6.987004280090332,
      "learning_rate": 9.517333333333332e-07,
      "logits/chosen": -1.8027461767196655,
      "logits/rejected": -1.8652089834213257,
      "logps/chosen": -94.84709167480469,
      "logps/rejected": -84.95722961425781,
      "loss": 0.244,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9833306074142456,
      "rewards/margins": 1.3669519424438477,
      "rewards/rejected": -0.3836214244365692,
      "step": 363
    },
    {
      "epoch": 0.1456,
      "grad_norm": 11.490894317626953,
      "learning_rate": 9.515999999999999e-07,
      "logits/chosen": -2.0487098693847656,
      "logits/rejected": -2.5485012531280518,
      "logps/chosen": -167.71572875976562,
      "logps/rejected": -115.78235626220703,
      "loss": 0.2918,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8333466053009033,
      "rewards/margins": 1.108116626739502,
      "rewards/rejected": -0.27476999163627625,
      "step": 364
    },
    {
      "epoch": 0.146,
      "grad_norm": 12.685693740844727,
      "learning_rate": 9.514666666666666e-07,
      "logits/chosen": -2.0365726947784424,
      "logits/rejected": -2.2284841537475586,
      "logps/chosen": -140.4332275390625,
      "logps/rejected": -97.76905059814453,
      "loss": 0.3872,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.37633323669433594,
      "rewards/margins": 0.7507511377334595,
      "rewards/rejected": -0.37441787123680115,
      "step": 365
    },
    {
      "epoch": 0.1464,
      "grad_norm": 7.3211565017700195,
      "learning_rate": 9.513333333333333e-07,
      "logits/chosen": -1.7710072994232178,
      "logits/rejected": -1.6665716171264648,
      "logps/chosen": -116.36080932617188,
      "logps/rejected": -82.16951751708984,
      "loss": 0.1877,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2544617652893066,
      "rewards/margins": 1.5898869037628174,
      "rewards/rejected": -0.3354251980781555,
      "step": 366
    },
    {
      "epoch": 0.1468,
      "grad_norm": 7.510016441345215,
      "learning_rate": 9.512e-07,
      "logits/chosen": -1.7499362230300903,
      "logits/rejected": -2.1663451194763184,
      "logps/chosen": -137.49813842773438,
      "logps/rejected": -110.95579528808594,
      "loss": 0.192,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.202662706375122,
      "rewards/margins": 1.6484477519989014,
      "rewards/rejected": -0.44578513503074646,
      "step": 367
    },
    {
      "epoch": 0.1472,
      "grad_norm": 7.877624034881592,
      "learning_rate": 9.510666666666666e-07,
      "logits/chosen": -1.9763375520706177,
      "logits/rejected": -2.513627052307129,
      "logps/chosen": -140.45654296875,
      "logps/rejected": -113.225830078125,
      "loss": 0.2448,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.202449083328247,
      "rewards/margins": 1.3416630029678345,
      "rewards/rejected": -0.1392139494419098,
      "step": 368
    },
    {
      "epoch": 0.1476,
      "grad_norm": 9.813507080078125,
      "learning_rate": 9.509333333333333e-07,
      "logits/chosen": -2.2253241539001465,
      "logits/rejected": -2.0527586936950684,
      "logps/chosen": -149.95877075195312,
      "logps/rejected": -98.8197021484375,
      "loss": 0.2069,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2354103326797485,
      "rewards/margins": 1.4861046075820923,
      "rewards/rejected": -0.25069427490234375,
      "step": 369
    },
    {
      "epoch": 0.148,
      "grad_norm": 9.5536470413208,
      "learning_rate": 9.508e-07,
      "logits/chosen": -1.9323830604553223,
      "logits/rejected": -2.1039233207702637,
      "logps/chosen": -156.32528686523438,
      "logps/rejected": -124.0758056640625,
      "loss": 0.2734,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1184509992599487,
      "rewards/margins": 1.2805111408233643,
      "rewards/rejected": -0.16206015646457672,
      "step": 370
    },
    {
      "epoch": 0.1484,
      "grad_norm": 7.910000801086426,
      "learning_rate": 9.506666666666667e-07,
      "logits/chosen": -1.8300211429595947,
      "logits/rejected": -1.297459602355957,
      "logps/chosen": -99.21824645996094,
      "logps/rejected": -124.9365005493164,
      "loss": 0.2975,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0642063617706299,
      "rewards/margins": 1.0616652965545654,
      "rewards/rejected": 0.0025409720838069916,
      "step": 371
    },
    {
      "epoch": 0.1488,
      "grad_norm": 10.368349075317383,
      "learning_rate": 9.505333333333333e-07,
      "logits/chosen": -2.067460060119629,
      "logits/rejected": -1.8475725650787354,
      "logps/chosen": -139.50064086914062,
      "logps/rejected": -80.68698120117188,
      "loss": 0.2913,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8239769339561462,
      "rewards/margins": 1.1013561487197876,
      "rewards/rejected": -0.27737924456596375,
      "step": 372
    },
    {
      "epoch": 0.1492,
      "grad_norm": 7.3329362869262695,
      "learning_rate": 9.503999999999999e-07,
      "logits/chosen": -1.9526185989379883,
      "logits/rejected": -2.2015793323516846,
      "logps/chosen": -127.7243881225586,
      "logps/rejected": -112.26014709472656,
      "loss": 0.1865,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2661080360412598,
      "rewards/margins": 1.588815689086914,
      "rewards/rejected": -0.32270774245262146,
      "step": 373
    },
    {
      "epoch": 0.1496,
      "grad_norm": 11.53016185760498,
      "learning_rate": 9.502666666666666e-07,
      "logits/chosen": -2.140340805053711,
      "logits/rejected": -2.8700661659240723,
      "logps/chosen": -164.28280639648438,
      "logps/rejected": -104.07437896728516,
      "loss": 0.3431,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5127601623535156,
      "rewards/margins": 0.8964020013809204,
      "rewards/rejected": -0.3836418092250824,
      "step": 374
    },
    {
      "epoch": 0.15,
      "grad_norm": 7.28753137588501,
      "learning_rate": 9.501333333333333e-07,
      "logits/chosen": -2.5547945499420166,
      "logits/rejected": -2.5946521759033203,
      "logps/chosen": -182.91717529296875,
      "logps/rejected": -133.85110473632812,
      "loss": 0.1466,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2150650024414062,
      "rewards/margins": 1.8501789569854736,
      "rewards/rejected": -0.6351138949394226,
      "step": 375
    },
    {
      "epoch": 0.1504,
      "grad_norm": 9.148015975952148,
      "learning_rate": 9.499999999999999e-07,
      "logits/chosen": -1.6617413759231567,
      "logits/rejected": -2.2854645252227783,
      "logps/chosen": -98.10789489746094,
      "logps/rejected": -81.83000183105469,
      "loss": 0.3176,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8450019955635071,
      "rewards/margins": 0.984173595905304,
      "rewards/rejected": -0.13917160034179688,
      "step": 376
    },
    {
      "epoch": 0.1508,
      "grad_norm": 10.297746658325195,
      "learning_rate": 9.498666666666666e-07,
      "logits/chosen": -2.529423713684082,
      "logits/rejected": -2.45241379737854,
      "logps/chosen": -256.02069091796875,
      "logps/rejected": -124.77095794677734,
      "loss": 0.2154,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9964935779571533,
      "rewards/margins": 1.4332561492919922,
      "rewards/rejected": -0.43676263093948364,
      "step": 377
    },
    {
      "epoch": 0.1512,
      "grad_norm": 12.253778457641602,
      "learning_rate": 9.497333333333333e-07,
      "logits/chosen": -2.2363340854644775,
      "logits/rejected": -2.313307762145996,
      "logps/chosen": -163.7865753173828,
      "logps/rejected": -105.56155395507812,
      "loss": 0.3235,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7563934922218323,
      "rewards/margins": 1.039902925491333,
      "rewards/rejected": -0.28350943326950073,
      "step": 378
    },
    {
      "epoch": 0.1516,
      "grad_norm": 9.639123916625977,
      "learning_rate": 9.496e-07,
      "logits/chosen": -1.6128370761871338,
      "logits/rejected": -2.859222412109375,
      "logps/chosen": -107.07048034667969,
      "logps/rejected": -103.79112243652344,
      "loss": 0.3328,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6085479855537415,
      "rewards/margins": 0.9559154510498047,
      "rewards/rejected": -0.3473674952983856,
      "step": 379
    },
    {
      "epoch": 0.152,
      "grad_norm": 13.886418342590332,
      "learning_rate": 9.494666666666667e-07,
      "logits/chosen": -2.138012409210205,
      "logits/rejected": -1.797116756439209,
      "logps/chosen": -120.83674621582031,
      "logps/rejected": -76.87982940673828,
      "loss": 0.3862,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6390007138252258,
      "rewards/margins": 0.7585057020187378,
      "rewards/rejected": -0.11950492858886719,
      "step": 380
    },
    {
      "epoch": 0.1524,
      "grad_norm": 9.497507095336914,
      "learning_rate": 9.493333333333334e-07,
      "logits/chosen": -1.9699599742889404,
      "logits/rejected": -2.350442409515381,
      "logps/chosen": -138.3687286376953,
      "logps/rejected": -130.41033935546875,
      "loss": 0.2235,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.042568564414978,
      "rewards/margins": 1.4287029504776,
      "rewards/rejected": -0.3861343264579773,
      "step": 381
    },
    {
      "epoch": 0.1528,
      "grad_norm": 9.270492553710938,
      "learning_rate": 9.492e-07,
      "logits/chosen": -1.741117238998413,
      "logits/rejected": -2.386035442352295,
      "logps/chosen": -123.07484436035156,
      "logps/rejected": -114.18351745605469,
      "loss": 0.2813,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9830993413925171,
      "rewards/margins": 1.1257762908935547,
      "rewards/rejected": -0.1426769196987152,
      "step": 382
    },
    {
      "epoch": 0.1532,
      "grad_norm": 10.245641708374023,
      "learning_rate": 9.490666666666665e-07,
      "logits/chosen": -1.928135871887207,
      "logits/rejected": -2.569612503051758,
      "logps/chosen": -120.55267333984375,
      "logps/rejected": -156.81797790527344,
      "loss": 0.2595,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.756029486656189,
      "rewards/margins": 1.293749213218689,
      "rewards/rejected": -0.5377197265625,
      "step": 383
    },
    {
      "epoch": 0.1536,
      "grad_norm": 12.067938804626465,
      "learning_rate": 9.489333333333332e-07,
      "logits/chosen": -2.441046714782715,
      "logits/rejected": -2.292257070541382,
      "logps/chosen": -180.46432495117188,
      "logps/rejected": -94.191650390625,
      "loss": 0.3546,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6873119473457336,
      "rewards/margins": 0.8563335537910461,
      "rewards/rejected": -0.1690216064453125,
      "step": 384
    },
    {
      "epoch": 0.154,
      "grad_norm": 8.169790267944336,
      "learning_rate": 9.487999999999999e-07,
      "logits/chosen": -2.1459455490112305,
      "logits/rejected": -1.6647861003875732,
      "logps/chosen": -155.9969940185547,
      "logps/rejected": -95.02266693115234,
      "loss": 0.2649,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2378612756729126,
      "rewards/margins": 1.255697250366211,
      "rewards/rejected": -0.017836004495620728,
      "step": 385
    },
    {
      "epoch": 0.1544,
      "grad_norm": 6.733552932739258,
      "learning_rate": 9.486666666666666e-07,
      "logits/chosen": -1.963012456893921,
      "logits/rejected": -2.6092190742492676,
      "logps/chosen": -152.21453857421875,
      "logps/rejected": -109.95803833007812,
      "loss": 0.1857,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3353309631347656,
      "rewards/margins": 1.5899609327316284,
      "rewards/rejected": -0.254629909992218,
      "step": 386
    },
    {
      "epoch": 0.1548,
      "grad_norm": 12.216314315795898,
      "learning_rate": 9.485333333333333e-07,
      "logits/chosen": -2.3652167320251465,
      "logits/rejected": -2.5351710319519043,
      "logps/chosen": -188.51052856445312,
      "logps/rejected": -122.753173828125,
      "loss": 0.2681,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0679374933242798,
      "rewards/margins": 1.3116893768310547,
      "rewards/rejected": -0.2437519133090973,
      "step": 387
    },
    {
      "epoch": 0.1552,
      "grad_norm": 13.942158699035645,
      "learning_rate": 9.484e-07,
      "logits/chosen": -1.9994442462921143,
      "logits/rejected": -2.442103385925293,
      "logps/chosen": -184.11099243164062,
      "logps/rejected": -116.03318786621094,
      "loss": 0.2599,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6710761785507202,
      "rewards/margins": 1.2169184684753418,
      "rewards/rejected": -0.5458423495292664,
      "step": 388
    },
    {
      "epoch": 0.1556,
      "grad_norm": 12.331748962402344,
      "learning_rate": 9.482666666666667e-07,
      "logits/chosen": -2.0864217281341553,
      "logits/rejected": -2.063352584838867,
      "logps/chosen": -146.79855346679688,
      "logps/rejected": -124.34456634521484,
      "loss": 0.3149,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4649433195590973,
      "rewards/margins": 1.0654239654541016,
      "rewards/rejected": -0.6004806756973267,
      "step": 389
    },
    {
      "epoch": 0.156,
      "grad_norm": 11.62092399597168,
      "learning_rate": 9.481333333333334e-07,
      "logits/chosen": -1.8897068500518799,
      "logits/rejected": -2.3556714057922363,
      "logps/chosen": -100.704833984375,
      "logps/rejected": -98.68241882324219,
      "loss": 0.4524,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9004650115966797,
      "rewards/margins": 0.5983417630195618,
      "rewards/rejected": 0.3021232485771179,
      "step": 390
    },
    {
      "epoch": 0.1564,
      "grad_norm": 11.608728408813477,
      "learning_rate": 9.479999999999999e-07,
      "logits/chosen": -2.3386034965515137,
      "logits/rejected": -2.7307748794555664,
      "logps/chosen": -173.66171264648438,
      "logps/rejected": -145.55361938476562,
      "loss": 0.28,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5952682495117188,
      "rewards/margins": 1.1594493389129639,
      "rewards/rejected": -0.5641811490058899,
      "step": 391
    },
    {
      "epoch": 0.1568,
      "grad_norm": 12.726834297180176,
      "learning_rate": 9.478666666666666e-07,
      "logits/chosen": -2.354743242263794,
      "logits/rejected": -2.717852830886841,
      "logps/chosen": -157.46881103515625,
      "logps/rejected": -139.5148162841797,
      "loss": 0.3507,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8644520044326782,
      "rewards/margins": 0.9663242697715759,
      "rewards/rejected": -0.10187225043773651,
      "step": 392
    },
    {
      "epoch": 0.1572,
      "grad_norm": 7.993042469024658,
      "learning_rate": 9.477333333333332e-07,
      "logits/chosen": -1.5804051160812378,
      "logits/rejected": -2.326617956161499,
      "logps/chosen": -117.14856719970703,
      "logps/rejected": -122.335205078125,
      "loss": 0.1875,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2884899377822876,
      "rewards/margins": 1.5827057361602783,
      "rewards/rejected": -0.29421576857566833,
      "step": 393
    },
    {
      "epoch": 0.1576,
      "grad_norm": 7.231118202209473,
      "learning_rate": 9.475999999999999e-07,
      "logits/chosen": -1.8528920412063599,
      "logits/rejected": -1.639711618423462,
      "logps/chosen": -92.0528564453125,
      "logps/rejected": -73.64485168457031,
      "loss": 0.2567,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1102015972137451,
      "rewards/margins": 1.2984516620635986,
      "rewards/rejected": -0.18824997544288635,
      "step": 394
    },
    {
      "epoch": 0.158,
      "grad_norm": 6.852899074554443,
      "learning_rate": 9.474666666666666e-07,
      "logits/chosen": -1.8281446695327759,
      "logits/rejected": -2.2063965797424316,
      "logps/chosen": -101.5073013305664,
      "logps/rejected": -106.08369445800781,
      "loss": 0.1602,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2424888610839844,
      "rewards/margins": 1.7554783821105957,
      "rewards/rejected": -0.5129894614219666,
      "step": 395
    },
    {
      "epoch": 0.1584,
      "grad_norm": 13.540509223937988,
      "learning_rate": 9.473333333333333e-07,
      "logits/chosen": -2.3715319633483887,
      "logits/rejected": -2.4869179725646973,
      "logps/chosen": -290.996826171875,
      "logps/rejected": -145.32095336914062,
      "loss": 0.2411,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0565086603164673,
      "rewards/margins": 1.38390052318573,
      "rewards/rejected": -0.3273918330669403,
      "step": 396
    },
    {
      "epoch": 0.1588,
      "grad_norm": 10.180379867553711,
      "learning_rate": 9.472e-07,
      "logits/chosen": -1.4122016429901123,
      "logits/rejected": -1.9342224597930908,
      "logps/chosen": -85.53691101074219,
      "logps/rejected": -87.52035522460938,
      "loss": 0.335,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6664243936538696,
      "rewards/margins": 0.9846780300140381,
      "rewards/rejected": -0.31825369596481323,
      "step": 397
    },
    {
      "epoch": 0.1592,
      "grad_norm": 11.034773826599121,
      "learning_rate": 9.470666666666666e-07,
      "logits/chosen": -2.0228371620178223,
      "logits/rejected": -2.3751461505889893,
      "logps/chosen": -117.36116790771484,
      "logps/rejected": -114.21444702148438,
      "loss": 0.3268,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2135917842388153,
      "rewards/margins": 0.9509170651435852,
      "rewards/rejected": -0.7373253107070923,
      "step": 398
    },
    {
      "epoch": 0.1596,
      "grad_norm": 8.054386138916016,
      "learning_rate": 9.469333333333333e-07,
      "logits/chosen": -1.5510790348052979,
      "logits/rejected": -1.9145108461380005,
      "logps/chosen": -99.90288543701172,
      "logps/rejected": -98.9764175415039,
      "loss": 0.2298,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5541046261787415,
      "rewards/margins": 1.3647063970565796,
      "rewards/rejected": -0.8106018304824829,
      "step": 399
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.975530624389648,
      "learning_rate": 9.468e-07,
      "logits/chosen": -2.4158143997192383,
      "logits/rejected": -2.0161213874816895,
      "logps/chosen": -190.5890655517578,
      "logps/rejected": -166.11181640625,
      "loss": 0.1725,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.205596923828125,
      "rewards/margins": 1.6697670221328735,
      "rewards/rejected": -0.46417009830474854,
      "step": 400
    },
    {
      "epoch": 0.1604,
      "grad_norm": 9.282535552978516,
      "learning_rate": 9.466666666666666e-07,
      "logits/chosen": -2.262916326522827,
      "logits/rejected": -2.5856990814208984,
      "logps/chosen": -134.20362854003906,
      "logps/rejected": -127.04547882080078,
      "loss": 0.2976,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9665489196777344,
      "rewards/margins": 1.1875946521759033,
      "rewards/rejected": -0.22104568779468536,
      "step": 401
    },
    {
      "epoch": 0.1608,
      "grad_norm": 7.493899345397949,
      "learning_rate": 9.465333333333333e-07,
      "logits/chosen": -2.134458541870117,
      "logits/rejected": -2.6458992958068848,
      "logps/chosen": -164.6883544921875,
      "logps/rejected": -153.93038940429688,
      "loss": 0.1373,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.569145917892456,
      "rewards/margins": 1.9639228582382202,
      "rewards/rejected": -0.3947769105434418,
      "step": 402
    },
    {
      "epoch": 0.1612,
      "grad_norm": 11.629280090332031,
      "learning_rate": 9.464e-07,
      "logits/chosen": -2.383512258529663,
      "logits/rejected": -2.286909580230713,
      "logps/chosen": -168.97279357910156,
      "logps/rejected": -99.29438781738281,
      "loss": 0.3008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9659870266914368,
      "rewards/margins": 1.123666763305664,
      "rewards/rejected": -0.1576797515153885,
      "step": 403
    },
    {
      "epoch": 0.1616,
      "grad_norm": 9.20734691619873,
      "learning_rate": 9.462666666666666e-07,
      "logits/chosen": -1.583045482635498,
      "logits/rejected": -2.120948314666748,
      "logps/chosen": -97.80064392089844,
      "logps/rejected": -89.93172454833984,
      "loss": 0.3815,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1660698652267456,
      "rewards/margins": 0.892707109451294,
      "rewards/rejected": 0.2733627259731293,
      "step": 404
    },
    {
      "epoch": 0.162,
      "grad_norm": 11.907289505004883,
      "learning_rate": 9.461333333333333e-07,
      "logits/chosen": -1.7811925411224365,
      "logits/rejected": -2.633497714996338,
      "logps/chosen": -99.49870300292969,
      "logps/rejected": -111.71630859375,
      "loss": 0.3545,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3083316683769226,
      "rewards/margins": 0.8653049468994141,
      "rewards/rejected": -0.5569732785224915,
      "step": 405
    },
    {
      "epoch": 0.1624,
      "grad_norm": 11.104279518127441,
      "learning_rate": 9.459999999999999e-07,
      "logits/chosen": -2.2487576007843018,
      "logits/rejected": -1.8973045349121094,
      "logps/chosen": -106.34475708007812,
      "logps/rejected": -84.4996337890625,
      "loss": 0.3515,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.848435640335083,
      "rewards/margins": 0.8995281457901001,
      "rewards/rejected": -0.05109252780675888,
      "step": 406
    },
    {
      "epoch": 0.1628,
      "grad_norm": 8.51587200164795,
      "learning_rate": 9.458666666666666e-07,
      "logits/chosen": -2.086266279220581,
      "logits/rejected": -2.070124387741089,
      "logps/chosen": -128.45416259765625,
      "logps/rejected": -100.02627563476562,
      "loss": 0.2431,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.821384072303772,
      "rewards/margins": 1.4821232557296753,
      "rewards/rejected": -0.6607391238212585,
      "step": 407
    },
    {
      "epoch": 0.1632,
      "grad_norm": 11.920384407043457,
      "learning_rate": 9.457333333333333e-07,
      "logits/chosen": -1.6838351488113403,
      "logits/rejected": -3.0173068046569824,
      "logps/chosen": -95.30009460449219,
      "logps/rejected": -109.85481262207031,
      "loss": 0.2781,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2770458459854126,
      "rewards/margins": 1.1428791284561157,
      "rewards/rejected": -0.8658332824707031,
      "step": 408
    },
    {
      "epoch": 0.1636,
      "grad_norm": 8.275662422180176,
      "learning_rate": 9.456e-07,
      "logits/chosen": -2.2192814350128174,
      "logits/rejected": -2.5773162841796875,
      "logps/chosen": -133.86627197265625,
      "logps/rejected": -132.1903076171875,
      "loss": 0.1958,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2782368659973145,
      "rewards/margins": 1.715040922164917,
      "rewards/rejected": -0.4368042051792145,
      "step": 409
    },
    {
      "epoch": 0.164,
      "grad_norm": 5.816837310791016,
      "learning_rate": 9.454666666666666e-07,
      "logits/chosen": -2.0674705505371094,
      "logits/rejected": -2.271671772003174,
      "logps/chosen": -130.803955078125,
      "logps/rejected": -122.76443481445312,
      "loss": 0.1261,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1916625499725342,
      "rewards/margins": 2.0421204566955566,
      "rewards/rejected": -0.8504577875137329,
      "step": 410
    },
    {
      "epoch": 0.1644,
      "grad_norm": 8.385333061218262,
      "learning_rate": 9.453333333333333e-07,
      "logits/chosen": -2.3192989826202393,
      "logits/rejected": -2.6337850093841553,
      "logps/chosen": -293.2218933105469,
      "logps/rejected": -119.7346420288086,
      "loss": 0.183,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2165474891662598,
      "rewards/margins": 1.7497090101242065,
      "rewards/rejected": -0.5331615209579468,
      "step": 411
    },
    {
      "epoch": 0.1648,
      "grad_norm": 8.10377311706543,
      "learning_rate": 9.452e-07,
      "logits/chosen": -1.922171950340271,
      "logits/rejected": -2.0256476402282715,
      "logps/chosen": -113.44041442871094,
      "logps/rejected": -108.41461181640625,
      "loss": 0.2458,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.319321870803833,
      "rewards/margins": 1.4050121307373047,
      "rewards/rejected": -0.08569031208753586,
      "step": 412
    },
    {
      "epoch": 0.1652,
      "grad_norm": 9.302472114562988,
      "learning_rate": 9.450666666666667e-07,
      "logits/chosen": -2.264190673828125,
      "logits/rejected": -1.2961950302124023,
      "logps/chosen": -134.43714904785156,
      "logps/rejected": -107.28605651855469,
      "loss": 0.2652,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.036341905593872,
      "rewards/margins": 1.2001854181289673,
      "rewards/rejected": -0.1638435423374176,
      "step": 413
    },
    {
      "epoch": 0.1656,
      "grad_norm": 4.8103227615356445,
      "learning_rate": 9.449333333333332e-07,
      "logits/chosen": -2.463682174682617,
      "logits/rejected": -2.4808731079101562,
      "logps/chosen": -156.03012084960938,
      "logps/rejected": -139.5924072265625,
      "loss": 0.0885,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4927231073379517,
      "rewards/margins": 2.3805863857269287,
      "rewards/rejected": -0.8878631591796875,
      "step": 414
    },
    {
      "epoch": 0.166,
      "grad_norm": 8.39031982421875,
      "learning_rate": 9.447999999999999e-07,
      "logits/chosen": -1.6984713077545166,
      "logits/rejected": -2.845871925354004,
      "logps/chosen": -123.16020202636719,
      "logps/rejected": -145.24798583984375,
      "loss": 0.1849,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2149349451065063,
      "rewards/margins": 1.603813648223877,
      "rewards/rejected": -0.38887864351272583,
      "step": 415
    },
    {
      "epoch": 0.1664,
      "grad_norm": 6.619210243225098,
      "learning_rate": 9.446666666666666e-07,
      "logits/chosen": -2.0965235233306885,
      "logits/rejected": -1.6821401119232178,
      "logps/chosen": -110.07695007324219,
      "logps/rejected": -92.12284088134766,
      "loss": 0.1776,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.373697280883789,
      "rewards/margins": 1.6381773948669434,
      "rewards/rejected": -0.26448002457618713,
      "step": 416
    },
    {
      "epoch": 0.1668,
      "grad_norm": 5.979409694671631,
      "learning_rate": 9.445333333333333e-07,
      "logits/chosen": -1.9234840869903564,
      "logits/rejected": -2.7448582649230957,
      "logps/chosen": -170.98329162597656,
      "logps/rejected": -119.53779602050781,
      "loss": 0.1444,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3956592082977295,
      "rewards/margins": 2.0119826793670654,
      "rewards/rejected": -0.6163234710693359,
      "step": 417
    },
    {
      "epoch": 0.1672,
      "grad_norm": 8.729636192321777,
      "learning_rate": 9.444e-07,
      "logits/chosen": -2.2540154457092285,
      "logits/rejected": -2.082726240158081,
      "logps/chosen": -124.50347900390625,
      "logps/rejected": -96.92491149902344,
      "loss": 0.361,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9766941666603088,
      "rewards/margins": 0.979261040687561,
      "rewards/rejected": -0.002566911280155182,
      "step": 418
    },
    {
      "epoch": 0.1676,
      "grad_norm": 8.098226547241211,
      "learning_rate": 9.442666666666667e-07,
      "logits/chosen": -2.249913215637207,
      "logits/rejected": -2.991631507873535,
      "logps/chosen": -176.66258239746094,
      "logps/rejected": -108.28280639648438,
      "loss": 0.1658,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4155998229980469,
      "rewards/margins": 1.7377254962921143,
      "rewards/rejected": -0.322125643491745,
      "step": 419
    },
    {
      "epoch": 0.168,
      "grad_norm": 8.106107711791992,
      "learning_rate": 9.441333333333333e-07,
      "logits/chosen": -1.9299628734588623,
      "logits/rejected": -2.544675350189209,
      "logps/chosen": -115.36860656738281,
      "logps/rejected": -108.35554504394531,
      "loss": 0.1979,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.047328233718872,
      "rewards/margins": 1.6106986999511719,
      "rewards/rejected": -0.5633705258369446,
      "step": 420
    },
    {
      "epoch": 0.1684,
      "grad_norm": 6.2054314613342285,
      "learning_rate": 9.439999999999999e-07,
      "logits/chosen": -2.303799629211426,
      "logits/rejected": -2.532221794128418,
      "logps/chosen": -115.06330108642578,
      "logps/rejected": -99.20648193359375,
      "loss": 0.1463,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2335362434387207,
      "rewards/margins": 1.903997778892517,
      "rewards/rejected": -0.6704616546630859,
      "step": 421
    },
    {
      "epoch": 0.1688,
      "grad_norm": 11.477980613708496,
      "learning_rate": 9.438666666666666e-07,
      "logits/chosen": -1.8046691417694092,
      "logits/rejected": -2.1795172691345215,
      "logps/chosen": -83.42847442626953,
      "logps/rejected": -91.38618469238281,
      "loss": 0.4085,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6901096105575562,
      "rewards/margins": 0.8716487884521484,
      "rewards/rejected": -0.1815391629934311,
      "step": 422
    },
    {
      "epoch": 0.1692,
      "grad_norm": 7.315863132476807,
      "learning_rate": 9.437333333333333e-07,
      "logits/chosen": -2.018951177597046,
      "logits/rejected": -2.1429224014282227,
      "logps/chosen": -128.6773681640625,
      "logps/rejected": -100.15084838867188,
      "loss": 0.1988,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9219543933868408,
      "rewards/margins": 1.5867302417755127,
      "rewards/rejected": -0.6647758483886719,
      "step": 423
    },
    {
      "epoch": 0.1696,
      "grad_norm": 6.397770404815674,
      "learning_rate": 9.436e-07,
      "logits/chosen": -1.9370198249816895,
      "logits/rejected": -2.3889541625976562,
      "logps/chosen": -154.3780517578125,
      "logps/rejected": -149.08726501464844,
      "loss": 0.1345,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3697669506072998,
      "rewards/margins": 1.9527592658996582,
      "rewards/rejected": -0.5829921960830688,
      "step": 424
    },
    {
      "epoch": 0.17,
      "grad_norm": 8.32265567779541,
      "learning_rate": 9.434666666666666e-07,
      "logits/chosen": -1.7096772193908691,
      "logits/rejected": -1.998321533203125,
      "logps/chosen": -124.79930114746094,
      "logps/rejected": -118.1744155883789,
      "loss": 0.2828,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9994838833808899,
      "rewards/margins": 1.2588279247283936,
      "rewards/rejected": -0.25934410095214844,
      "step": 425
    },
    {
      "epoch": 0.1704,
      "grad_norm": 6.179605484008789,
      "learning_rate": 9.433333333333333e-07,
      "logits/chosen": -2.3468103408813477,
      "logits/rejected": -0.9958484768867493,
      "logps/chosen": -125.40372467041016,
      "logps/rejected": -82.32990264892578,
      "loss": 0.1436,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3836288452148438,
      "rewards/margins": 1.8683381080627441,
      "rewards/rejected": -0.4847091734409332,
      "step": 426
    },
    {
      "epoch": 0.1708,
      "grad_norm": 6.535146236419678,
      "learning_rate": 9.432e-07,
      "logits/chosen": -2.2682557106018066,
      "logits/rejected": -2.063283920288086,
      "logps/chosen": -134.14938354492188,
      "logps/rejected": -100.34223937988281,
      "loss": 0.1435,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4050865173339844,
      "rewards/margins": 1.9089516401290894,
      "rewards/rejected": -0.5038650631904602,
      "step": 427
    },
    {
      "epoch": 0.1712,
      "grad_norm": 5.884174823760986,
      "learning_rate": 9.430666666666667e-07,
      "logits/chosen": -1.8248474597930908,
      "logits/rejected": -2.3534207344055176,
      "logps/chosen": -134.84408569335938,
      "logps/rejected": -97.16986846923828,
      "loss": 0.1436,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4124809503555298,
      "rewards/margins": 1.9432317018508911,
      "rewards/rejected": -0.5307506918907166,
      "step": 428
    },
    {
      "epoch": 0.1716,
      "grad_norm": 8.814674377441406,
      "learning_rate": 9.429333333333332e-07,
      "logits/chosen": -2.276615619659424,
      "logits/rejected": -2.6491267681121826,
      "logps/chosen": -113.9880599975586,
      "logps/rejected": -118.1513900756836,
      "loss": 0.2398,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8845447301864624,
      "rewards/margins": 1.316028118133545,
      "rewards/rejected": -0.4314834475517273,
      "step": 429
    },
    {
      "epoch": 0.172,
      "grad_norm": 6.068268299102783,
      "learning_rate": 9.427999999999999e-07,
      "logits/chosen": -2.0569188594818115,
      "logits/rejected": -2.561729907989502,
      "logps/chosen": -114.49224853515625,
      "logps/rejected": -103.50003051757812,
      "loss": 0.1569,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.107407808303833,
      "rewards/margins": 1.87101411819458,
      "rewards/rejected": -0.7636063098907471,
      "step": 430
    },
    {
      "epoch": 0.1724,
      "grad_norm": 7.818686008453369,
      "learning_rate": 9.426666666666666e-07,
      "logits/chosen": -2.3460164070129395,
      "logits/rejected": -2.8258485794067383,
      "logps/chosen": -143.8641357421875,
      "logps/rejected": -120.41709899902344,
      "loss": 0.2017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.561100721359253,
      "rewards/margins": 1.5937714576721191,
      "rewards/rejected": -0.03267059102654457,
      "step": 431
    },
    {
      "epoch": 0.1728,
      "grad_norm": 11.137125015258789,
      "learning_rate": 9.425333333333333e-07,
      "logits/chosen": -2.2966296672821045,
      "logits/rejected": -1.9364142417907715,
      "logps/chosen": -149.65728759765625,
      "logps/rejected": -105.409912109375,
      "loss": 0.2959,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0997109413146973,
      "rewards/margins": 1.076439380645752,
      "rewards/rejected": 0.023271560668945312,
      "step": 432
    },
    {
      "epoch": 0.1732,
      "grad_norm": 5.980758190155029,
      "learning_rate": 9.424e-07,
      "logits/chosen": -2.1824090480804443,
      "logits/rejected": -2.2439587116241455,
      "logps/chosen": -187.43394470214844,
      "logps/rejected": -115.23277282714844,
      "loss": 0.1324,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.54509699344635,
      "rewards/margins": 1.9552574157714844,
      "rewards/rejected": -0.4101604223251343,
      "step": 433
    },
    {
      "epoch": 0.1736,
      "grad_norm": 8.1349458694458,
      "learning_rate": 9.422666666666667e-07,
      "logits/chosen": -1.4908968210220337,
      "logits/rejected": -1.942918062210083,
      "logps/chosen": -103.36329650878906,
      "logps/rejected": -93.49767303466797,
      "loss": 0.2925,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5786159634590149,
      "rewards/margins": 1.2599185705184937,
      "rewards/rejected": -0.6813026666641235,
      "step": 434
    },
    {
      "epoch": 0.174,
      "grad_norm": 13.22981071472168,
      "learning_rate": 9.421333333333334e-07,
      "logits/chosen": -2.3302969932556152,
      "logits/rejected": -2.616847038269043,
      "logps/chosen": -179.09432983398438,
      "logps/rejected": -130.3411407470703,
      "loss": 0.3163,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6278091669082642,
      "rewards/margins": 0.991899847984314,
      "rewards/rejected": -0.3640907406806946,
      "step": 435
    },
    {
      "epoch": 0.1744,
      "grad_norm": 7.862563133239746,
      "learning_rate": 9.419999999999999e-07,
      "logits/chosen": -2.053072929382324,
      "logits/rejected": -1.8508379459381104,
      "logps/chosen": -126.90092468261719,
      "logps/rejected": -100.38697814941406,
      "loss": 0.2113,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9883193969726562,
      "rewards/margins": 1.656222939491272,
      "rewards/rejected": -0.6679035425186157,
      "step": 436
    },
    {
      "epoch": 0.1748,
      "grad_norm": 6.747744560241699,
      "learning_rate": 9.418666666666666e-07,
      "logits/chosen": -1.9168550968170166,
      "logits/rejected": -1.7541354894638062,
      "logps/chosen": -138.14523315429688,
      "logps/rejected": -115.1312255859375,
      "loss": 0.1521,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2456600666046143,
      "rewards/margins": 1.8072396516799927,
      "rewards/rejected": -0.5615795254707336,
      "step": 437
    },
    {
      "epoch": 0.1752,
      "grad_norm": 5.787333965301514,
      "learning_rate": 9.417333333333332e-07,
      "logits/chosen": -1.9010568857192993,
      "logits/rejected": -3.181495189666748,
      "logps/chosen": -164.4212646484375,
      "logps/rejected": -112.22901916503906,
      "loss": 0.1842,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2456135749816895,
      "rewards/margins": 1.814113736152649,
      "rewards/rejected": -0.5685001611709595,
      "step": 438
    },
    {
      "epoch": 0.1756,
      "grad_norm": 7.601593494415283,
      "learning_rate": 9.415999999999999e-07,
      "logits/chosen": -2.4204039573669434,
      "logits/rejected": -1.974669337272644,
      "logps/chosen": -187.41041564941406,
      "logps/rejected": -104.352294921875,
      "loss": 0.1447,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5117676258087158,
      "rewards/margins": 1.9046318531036377,
      "rewards/rejected": -0.3928642272949219,
      "step": 439
    },
    {
      "epoch": 0.176,
      "grad_norm": 7.6505937576293945,
      "learning_rate": 9.414666666666666e-07,
      "logits/chosen": -2.194939136505127,
      "logits/rejected": -2.2222583293914795,
      "logps/chosen": -147.02491760253906,
      "logps/rejected": -146.78890991210938,
      "loss": 0.1643,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2609658241271973,
      "rewards/margins": 2.0199334621429443,
      "rewards/rejected": -0.7589676380157471,
      "step": 440
    },
    {
      "epoch": 0.1764,
      "grad_norm": 12.316521644592285,
      "learning_rate": 9.413333333333333e-07,
      "logits/chosen": -1.9452686309814453,
      "logits/rejected": -2.38389253616333,
      "logps/chosen": -131.67819213867188,
      "logps/rejected": -108.72720336914062,
      "loss": 0.2448,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3599029779434204,
      "rewards/margins": 1.3122456073760986,
      "rewards/rejected": 0.04765739291906357,
      "step": 441
    },
    {
      "epoch": 0.1768,
      "grad_norm": 4.64815092086792,
      "learning_rate": 9.412e-07,
      "logits/chosen": -2.4159021377563477,
      "logits/rejected": -3.33536958694458,
      "logps/chosen": -216.40895080566406,
      "logps/rejected": -198.18710327148438,
      "loss": 0.0888,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9821555614471436,
      "rewards/margins": 2.3874523639678955,
      "rewards/rejected": -0.4052967131137848,
      "step": 442
    },
    {
      "epoch": 0.1772,
      "grad_norm": 7.3499932289123535,
      "learning_rate": 9.410666666666667e-07,
      "logits/chosen": -1.7514774799346924,
      "logits/rejected": -1.9795430898666382,
      "logps/chosen": -118.07240295410156,
      "logps/rejected": -152.90371704101562,
      "loss": 0.1691,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6114898920059204,
      "rewards/margins": 1.735388994216919,
      "rewards/rejected": -0.12389908730983734,
      "step": 443
    },
    {
      "epoch": 0.1776,
      "grad_norm": 7.234891414642334,
      "learning_rate": 9.409333333333333e-07,
      "logits/chosen": -2.02608585357666,
      "logits/rejected": -1.2404935359954834,
      "logps/chosen": -103.52883911132812,
      "logps/rejected": -82.70048522949219,
      "loss": 0.1866,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5756187438964844,
      "rewards/margins": 1.609704613685608,
      "rewards/rejected": -0.034085847437381744,
      "step": 444
    },
    {
      "epoch": 0.178,
      "grad_norm": 9.575199127197266,
      "learning_rate": 9.408e-07,
      "logits/chosen": -2.07270884513855,
      "logits/rejected": -1.8885571956634521,
      "logps/chosen": -138.49627685546875,
      "logps/rejected": -98.65254211425781,
      "loss": 0.4402,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.6128708124160767,
      "rewards/margins": 0.8972675204277039,
      "rewards/rejected": -0.284396767616272,
      "step": 445
    },
    {
      "epoch": 0.1784,
      "grad_norm": 6.634030818939209,
      "learning_rate": 9.406666666666666e-07,
      "logits/chosen": -1.5759129524230957,
      "logits/rejected": -2.458585262298584,
      "logps/chosen": -148.43994140625,
      "logps/rejected": -109.31562805175781,
      "loss": 0.1692,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4010944366455078,
      "rewards/margins": 1.720193862915039,
      "rewards/rejected": -0.31909945607185364,
      "step": 446
    },
    {
      "epoch": 0.1788,
      "grad_norm": 5.504769325256348,
      "learning_rate": 9.405333333333333e-07,
      "logits/chosen": -2.127640962600708,
      "logits/rejected": -1.6023845672607422,
      "logps/chosen": -106.97239685058594,
      "logps/rejected": -73.93147277832031,
      "loss": 0.1532,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3446674346923828,
      "rewards/margins": 1.8087456226348877,
      "rewards/rejected": -0.4640781283378601,
      "step": 447
    },
    {
      "epoch": 0.1792,
      "grad_norm": 6.930108547210693,
      "learning_rate": 9.403999999999999e-07,
      "logits/chosen": -2.1305220127105713,
      "logits/rejected": -1.2350587844848633,
      "logps/chosen": -145.03695678710938,
      "logps/rejected": -91.62367248535156,
      "loss": 0.1965,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4827752113342285,
      "rewards/margins": 1.5541744232177734,
      "rewards/rejected": -0.07139930874109268,
      "step": 448
    },
    {
      "epoch": 0.1796,
      "grad_norm": 9.250455856323242,
      "learning_rate": 9.402666666666666e-07,
      "logits/chosen": -2.6436195373535156,
      "logits/rejected": -1.6963984966278076,
      "logps/chosen": -203.39376831054688,
      "logps/rejected": -105.1161117553711,
      "loss": 0.2157,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2963128089904785,
      "rewards/margins": 1.4723851680755615,
      "rewards/rejected": -0.17607231438159943,
      "step": 449
    },
    {
      "epoch": 0.18,
      "grad_norm": 5.300508975982666,
      "learning_rate": 9.401333333333333e-07,
      "logits/chosen": -2.1291260719299316,
      "logits/rejected": -2.3204665184020996,
      "logps/chosen": -203.15408325195312,
      "logps/rejected": -100.4522933959961,
      "loss": 0.1209,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9568657875061035,
      "rewards/margins": 2.1259963512420654,
      "rewards/rejected": -0.16913071274757385,
      "step": 450
    },
    {
      "epoch": 0.1804,
      "grad_norm": 4.042469024658203,
      "learning_rate": 9.399999999999999e-07,
      "logits/chosen": -2.47550106048584,
      "logits/rejected": -2.9114866256713867,
      "logps/chosen": -161.17791748046875,
      "logps/rejected": -107.19690704345703,
      "loss": 0.0761,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5642235279083252,
      "rewards/margins": 2.5698370933532715,
      "rewards/rejected": -1.0056136846542358,
      "step": 451
    },
    {
      "epoch": 0.1808,
      "grad_norm": 10.688429832458496,
      "learning_rate": 9.398666666666666e-07,
      "logits/chosen": -2.0545477867126465,
      "logits/rejected": -2.1191048622131348,
      "logps/chosen": -133.54193115234375,
      "logps/rejected": -85.60525512695312,
      "loss": 0.23,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7820972800254822,
      "rewards/margins": 1.366734266281128,
      "rewards/rejected": -0.5846370458602905,
      "step": 452
    },
    {
      "epoch": 0.1812,
      "grad_norm": 3.32944393157959,
      "learning_rate": 9.397333333333333e-07,
      "logits/chosen": -2.142470359802246,
      "logits/rejected": -2.7580747604370117,
      "logps/chosen": -116.7171401977539,
      "logps/rejected": -111.27946472167969,
      "loss": 0.0633,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6816718578338623,
      "rewards/margins": 2.7443270683288574,
      "rewards/rejected": -1.0626552104949951,
      "step": 453
    },
    {
      "epoch": 0.1816,
      "grad_norm": 6.971113204956055,
      "learning_rate": 9.396e-07,
      "logits/chosen": -2.113433837890625,
      "logits/rejected": -2.282649517059326,
      "logps/chosen": -130.66732788085938,
      "logps/rejected": -135.16641235351562,
      "loss": 0.1176,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7894141674041748,
      "rewards/margins": 2.189654588699341,
      "rewards/rejected": -0.40024030208587646,
      "step": 454
    },
    {
      "epoch": 0.182,
      "grad_norm": 7.704702854156494,
      "learning_rate": 9.394666666666667e-07,
      "logits/chosen": -2.1240177154541016,
      "logits/rejected": -2.2992191314697266,
      "logps/chosen": -103.53217315673828,
      "logps/rejected": -106.92797088623047,
      "loss": 0.173,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.320868730545044,
      "rewards/margins": 1.6792826652526855,
      "rewards/rejected": -0.35841408371925354,
      "step": 455
    },
    {
      "epoch": 0.1824,
      "grad_norm": 10.083902359008789,
      "learning_rate": 9.393333333333334e-07,
      "logits/chosen": -1.9764409065246582,
      "logits/rejected": -1.1617236137390137,
      "logps/chosen": -134.4671173095703,
      "logps/rejected": -82.9744873046875,
      "loss": 0.3405,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9935131072998047,
      "rewards/margins": 1.0585845708847046,
      "rewards/rejected": -0.0650714859366417,
      "step": 456
    },
    {
      "epoch": 0.1828,
      "grad_norm": 6.4895148277282715,
      "learning_rate": 9.391999999999999e-07,
      "logits/chosen": -2.176215171813965,
      "logits/rejected": -2.926297903060913,
      "logps/chosen": -212.63372802734375,
      "logps/rejected": -159.96017456054688,
      "loss": 0.124,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5062682628631592,
      "rewards/margins": 2.0947251319885254,
      "rewards/rejected": -0.5884567499160767,
      "step": 457
    },
    {
      "epoch": 0.1832,
      "grad_norm": 5.975185394287109,
      "learning_rate": 9.390666666666666e-07,
      "logits/chosen": -2.3848628997802734,
      "logits/rejected": -2.3087618350982666,
      "logps/chosen": -157.17202758789062,
      "logps/rejected": -97.91046905517578,
      "loss": 0.1304,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2610931396484375,
      "rewards/margins": 2.0017876625061035,
      "rewards/rejected": -0.7406944632530212,
      "step": 458
    },
    {
      "epoch": 0.1836,
      "grad_norm": 18.055784225463867,
      "learning_rate": 9.389333333333332e-07,
      "logits/chosen": -1.391488790512085,
      "logits/rejected": -2.138089418411255,
      "logps/chosen": -107.22169494628906,
      "logps/rejected": -115.40748596191406,
      "loss": 0.478,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0745006799697876,
      "rewards/margins": 0.7484028339385986,
      "rewards/rejected": -0.673902153968811,
      "step": 459
    },
    {
      "epoch": 0.184,
      "grad_norm": 3.3201849460601807,
      "learning_rate": 9.387999999999999e-07,
      "logits/chosen": -2.0140299797058105,
      "logits/rejected": -2.1154141426086426,
      "logps/chosen": -131.0970458984375,
      "logps/rejected": -100.79759979248047,
      "loss": 0.0771,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8930022716522217,
      "rewards/margins": 2.523904800415039,
      "rewards/rejected": -0.6309025287628174,
      "step": 460
    },
    {
      "epoch": 0.1844,
      "grad_norm": 12.132363319396973,
      "learning_rate": 9.386666666666666e-07,
      "logits/chosen": -1.4297386407852173,
      "logits/rejected": -2.849109649658203,
      "logps/chosen": -77.12767028808594,
      "logps/rejected": -97.65412902832031,
      "loss": 0.3881,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5588917136192322,
      "rewards/margins": 0.7522026300430298,
      "rewards/rejected": -0.19331094622612,
      "step": 461
    },
    {
      "epoch": 0.1848,
      "grad_norm": 5.204902648925781,
      "learning_rate": 9.385333333333333e-07,
      "logits/chosen": -2.268874168395996,
      "logits/rejected": -2.6243464946746826,
      "logps/chosen": -130.04022216796875,
      "logps/rejected": -137.17710876464844,
      "loss": 0.0879,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8182837963104248,
      "rewards/margins": 2.3945412635803223,
      "rewards/rejected": -0.5762573480606079,
      "step": 462
    },
    {
      "epoch": 0.1852,
      "grad_norm": 9.027400016784668,
      "learning_rate": 9.384e-07,
      "logits/chosen": -1.9738661050796509,
      "logits/rejected": -1.3579847812652588,
      "logps/chosen": -151.41860961914062,
      "logps/rejected": -98.27037048339844,
      "loss": 0.3418,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1727256774902344,
      "rewards/margins": 1.5565627813339233,
      "rewards/rejected": -0.38383713364601135,
      "step": 463
    },
    {
      "epoch": 0.1856,
      "grad_norm": 6.04000186920166,
      "learning_rate": 9.382666666666667e-07,
      "logits/chosen": -1.8526535034179688,
      "logits/rejected": -2.176706075668335,
      "logps/chosen": -121.70663452148438,
      "logps/rejected": -100.78193664550781,
      "loss": 0.1241,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0633249282836914,
      "rewards/margins": 2.1793699264526367,
      "rewards/rejected": -0.11604499816894531,
      "step": 464
    },
    {
      "epoch": 0.186,
      "grad_norm": 6.481776714324951,
      "learning_rate": 9.381333333333334e-07,
      "logits/chosen": -2.1348252296447754,
      "logits/rejected": -2.245180606842041,
      "logps/chosen": -161.78897094726562,
      "logps/rejected": -104.4202880859375,
      "loss": 0.1568,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.434721827507019,
      "rewards/margins": 1.7838444709777832,
      "rewards/rejected": -0.34912264347076416,
      "step": 465
    },
    {
      "epoch": 0.1864,
      "grad_norm": 9.108842849731445,
      "learning_rate": 9.379999999999998e-07,
      "logits/chosen": -1.861648678779602,
      "logits/rejected": -2.655672550201416,
      "logps/chosen": -85.4677734375,
      "logps/rejected": -103.27925109863281,
      "loss": 0.2284,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1527760028839111,
      "rewards/margins": 1.6360622644424438,
      "rewards/rejected": -0.4832862615585327,
      "step": 466
    },
    {
      "epoch": 0.1868,
      "grad_norm": 4.975726127624512,
      "learning_rate": 9.378666666666665e-07,
      "logits/chosen": -1.9347612857818604,
      "logits/rejected": -2.7255496978759766,
      "logps/chosen": -155.42257690429688,
      "logps/rejected": -137.68121337890625,
      "loss": 0.0861,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.871163249015808,
      "rewards/margins": 2.4128637313842773,
      "rewards/rejected": -0.5417003631591797,
      "step": 467
    },
    {
      "epoch": 0.1872,
      "grad_norm": 7.5759596824646,
      "learning_rate": 9.377333333333332e-07,
      "logits/chosen": -2.5957915782928467,
      "logits/rejected": -2.233893394470215,
      "logps/chosen": -171.5383758544922,
      "logps/rejected": -115.33436584472656,
      "loss": 0.1749,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.463759183883667,
      "rewards/margins": 1.6928398609161377,
      "rewards/rejected": -0.22908057272434235,
      "step": 468
    },
    {
      "epoch": 0.1876,
      "grad_norm": 7.440673828125,
      "learning_rate": 9.375999999999999e-07,
      "logits/chosen": -1.7707229852676392,
      "logits/rejected": -2.1156740188598633,
      "logps/chosen": -135.9198455810547,
      "logps/rejected": -95.57026672363281,
      "loss": 0.2197,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3008906841278076,
      "rewards/margins": 1.5213226079940796,
      "rewards/rejected": -0.22043190896511078,
      "step": 469
    },
    {
      "epoch": 0.188,
      "grad_norm": 7.3313679695129395,
      "learning_rate": 9.374666666666666e-07,
      "logits/chosen": -2.0598385334014893,
      "logits/rejected": -2.0804684162139893,
      "logps/chosen": -159.87742614746094,
      "logps/rejected": -178.82406616210938,
      "loss": 0.167,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9132914543151855,
      "rewards/margins": 1.7949976921081543,
      "rewards/rejected": 0.11829376965761185,
      "step": 470
    },
    {
      "epoch": 0.1884,
      "grad_norm": 5.165286064147949,
      "learning_rate": 9.373333333333333e-07,
      "logits/chosen": -1.6266288757324219,
      "logits/rejected": -1.555564045906067,
      "logps/chosen": -80.11933898925781,
      "logps/rejected": -84.73303985595703,
      "loss": 0.116,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4195873737335205,
      "rewards/margins": 2.104351043701172,
      "rewards/rejected": -0.6847637295722961,
      "step": 471
    },
    {
      "epoch": 0.1888,
      "grad_norm": 6.676267623901367,
      "learning_rate": 9.372e-07,
      "logits/chosen": -1.274720311164856,
      "logits/rejected": -0.9806585311889648,
      "logps/chosen": -74.62461853027344,
      "logps/rejected": -70.06828308105469,
      "loss": 0.1839,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3631412982940674,
      "rewards/margins": 1.7829976081848145,
      "rewards/rejected": -0.4198562800884247,
      "step": 472
    },
    {
      "epoch": 0.1892,
      "grad_norm": 5.950916767120361,
      "learning_rate": 9.370666666666667e-07,
      "logits/chosen": -2.2108678817749023,
      "logits/rejected": -2.193936586380005,
      "logps/chosen": -177.296142578125,
      "logps/rejected": -107.01580810546875,
      "loss": 0.1448,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.676648736000061,
      "rewards/margins": 1.9884960651397705,
      "rewards/rejected": -0.3118473291397095,
      "step": 473
    },
    {
      "epoch": 0.1896,
      "grad_norm": 9.389249801635742,
      "learning_rate": 9.369333333333333e-07,
      "logits/chosen": -1.9428333044052124,
      "logits/rejected": -1.8118391036987305,
      "logps/chosen": -160.3140869140625,
      "logps/rejected": -89.69818115234375,
      "loss": 0.1643,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.320764183998108,
      "rewards/margins": 1.8144879341125488,
      "rewards/rejected": -0.49372369050979614,
      "step": 474
    },
    {
      "epoch": 0.19,
      "grad_norm": 3.5098044872283936,
      "learning_rate": 9.368e-07,
      "logits/chosen": -2.639662265777588,
      "logits/rejected": -2.2615902423858643,
      "logps/chosen": -224.0150146484375,
      "logps/rejected": -119.14244842529297,
      "loss": 0.0584,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.16938853263855,
      "rewards/margins": 2.824075698852539,
      "rewards/rejected": -0.6546871662139893,
      "step": 475
    },
    {
      "epoch": 0.1904,
      "grad_norm": 7.909759998321533,
      "learning_rate": 9.366666666666666e-07,
      "logits/chosen": -2.3286094665527344,
      "logits/rejected": -2.8753740787506104,
      "logps/chosen": -184.1855926513672,
      "logps/rejected": -125.60003662109375,
      "loss": 0.2286,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5114414691925049,
      "rewards/margins": 1.6209359169006348,
      "rewards/rejected": -0.1094944030046463,
      "step": 476
    },
    {
      "epoch": 0.1908,
      "grad_norm": 2.9873569011688232,
      "learning_rate": 9.365333333333332e-07,
      "logits/chosen": -2.0419881343841553,
      "logits/rejected": -2.9406967163085938,
      "logps/chosen": -190.1077880859375,
      "logps/rejected": -136.4575653076172,
      "loss": 0.0522,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6683974266052246,
      "rewards/margins": 2.9302597045898438,
      "rewards/rejected": -0.261862188577652,
      "step": 477
    },
    {
      "epoch": 0.1912,
      "grad_norm": 5.245849132537842,
      "learning_rate": 9.363999999999999e-07,
      "logits/chosen": -1.902796983718872,
      "logits/rejected": -2.4646544456481934,
      "logps/chosen": -103.12382507324219,
      "logps/rejected": -112.0045166015625,
      "loss": 0.1264,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7631611824035645,
      "rewards/margins": 2.2770779132843018,
      "rewards/rejected": -0.5139167904853821,
      "step": 478
    },
    {
      "epoch": 0.1916,
      "grad_norm": 8.573039054870605,
      "learning_rate": 9.362666666666666e-07,
      "logits/chosen": -2.6905782222747803,
      "logits/rejected": -1.7225764989852905,
      "logps/chosen": -168.5077362060547,
      "logps/rejected": -104.77801513671875,
      "loss": 0.1503,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2822175025939941,
      "rewards/margins": 1.8196285963058472,
      "rewards/rejected": -0.5374111533164978,
      "step": 479
    },
    {
      "epoch": 0.192,
      "grad_norm": 6.761692523956299,
      "learning_rate": 9.361333333333333e-07,
      "logits/chosen": -2.4644131660461426,
      "logits/rejected": -2.5562548637390137,
      "logps/chosen": -150.86978149414062,
      "logps/rejected": -101.41934967041016,
      "loss": 0.1804,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8817596435546875,
      "rewards/margins": 1.7961888313293457,
      "rewards/rejected": 0.08557091653347015,
      "step": 480
    },
    {
      "epoch": 0.1924,
      "grad_norm": 7.2054619789123535,
      "learning_rate": 9.36e-07,
      "logits/chosen": -1.875030279159546,
      "logits/rejected": -2.1668243408203125,
      "logps/chosen": -92.24864196777344,
      "logps/rejected": -107.23648071289062,
      "loss": 0.172,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0622665882110596,
      "rewards/margins": 1.6880345344543457,
      "rewards/rejected": -0.6257679462432861,
      "step": 481
    },
    {
      "epoch": 0.1928,
      "grad_norm": 3.2494962215423584,
      "learning_rate": 9.358666666666666e-07,
      "logits/chosen": -2.011373996734619,
      "logits/rejected": -1.9632880687713623,
      "logps/chosen": -118.10133361816406,
      "logps/rejected": -108.17488098144531,
      "loss": 0.0643,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.148768186569214,
      "rewards/margins": 2.7185707092285156,
      "rewards/rejected": -0.5698025226593018,
      "step": 482
    },
    {
      "epoch": 0.1932,
      "grad_norm": 6.263394832611084,
      "learning_rate": 9.357333333333333e-07,
      "logits/chosen": -1.5265491008758545,
      "logits/rejected": -1.8561413288116455,
      "logps/chosen": -113.87718200683594,
      "logps/rejected": -96.06974792480469,
      "loss": 0.1597,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2007758617401123,
      "rewards/margins": 1.777627944946289,
      "rewards/rejected": -0.5768520832061768,
      "step": 483
    },
    {
      "epoch": 0.1936,
      "grad_norm": 7.649388313293457,
      "learning_rate": 9.356e-07,
      "logits/chosen": -2.1203877925872803,
      "logits/rejected": -2.2890663146972656,
      "logps/chosen": -101.34011840820312,
      "logps/rejected": -107.54862976074219,
      "loss": 0.1852,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4202160835266113,
      "rewards/margins": 1.5923199653625488,
      "rewards/rejected": -0.1721038818359375,
      "step": 484
    },
    {
      "epoch": 0.194,
      "grad_norm": 8.296296119689941,
      "learning_rate": 9.354666666666667e-07,
      "logits/chosen": -2.304760217666626,
      "logits/rejected": -2.0613529682159424,
      "logps/chosen": -170.64195251464844,
      "logps/rejected": -107.89627838134766,
      "loss": 0.1747,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4068171977996826,
      "rewards/margins": 1.7733074426651,
      "rewards/rejected": -0.3664901852607727,
      "step": 485
    },
    {
      "epoch": 0.1944,
      "grad_norm": 7.827240467071533,
      "learning_rate": 9.353333333333333e-07,
      "logits/chosen": -1.635887861251831,
      "logits/rejected": -2.829770803451538,
      "logps/chosen": -105.89061737060547,
      "logps/rejected": -108.74900817871094,
      "loss": 0.1696,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7939281463623047,
      "rewards/margins": 1.7054401636123657,
      "rewards/rejected": -0.911512017250061,
      "step": 486
    },
    {
      "epoch": 0.1948,
      "grad_norm": 5.5571699142456055,
      "learning_rate": 9.352e-07,
      "logits/chosen": -1.6761243343353271,
      "logits/rejected": -2.4692819118499756,
      "logps/chosen": -92.88251495361328,
      "logps/rejected": -120.38194274902344,
      "loss": 0.1136,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.330418348312378,
      "rewards/margins": 2.1547462940216064,
      "rewards/rejected": -0.8243278861045837,
      "step": 487
    },
    {
      "epoch": 0.1952,
      "grad_norm": 4.8322930335998535,
      "learning_rate": 9.350666666666666e-07,
      "logits/chosen": -1.980518102645874,
      "logits/rejected": -1.4668534994125366,
      "logps/chosen": -101.28154754638672,
      "logps/rejected": -75.36158752441406,
      "loss": 0.1067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6772751808166504,
      "rewards/margins": 2.2135226726531982,
      "rewards/rejected": -0.5362476706504822,
      "step": 488
    },
    {
      "epoch": 0.1956,
      "grad_norm": 11.600099563598633,
      "learning_rate": 9.349333333333332e-07,
      "logits/chosen": -1.902313470840454,
      "logits/rejected": -2.3676528930664062,
      "logps/chosen": -141.4244384765625,
      "logps/rejected": -116.42291259765625,
      "loss": 0.2581,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0769004821777344,
      "rewards/margins": 1.6776984930038452,
      "rewards/rejected": -0.6007980704307556,
      "step": 489
    },
    {
      "epoch": 0.196,
      "grad_norm": 4.391833305358887,
      "learning_rate": 9.347999999999999e-07,
      "logits/chosen": -1.9164855480194092,
      "logits/rejected": -2.018462896347046,
      "logps/chosen": -86.02653503417969,
      "logps/rejected": -94.04102325439453,
      "loss": 0.1106,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4922528266906738,
      "rewards/margins": 2.1474504470825195,
      "rewards/rejected": -0.6551975607872009,
      "step": 490
    },
    {
      "epoch": 0.1964,
      "grad_norm": 4.494683265686035,
      "learning_rate": 9.346666666666666e-07,
      "logits/chosen": -2.0389132499694824,
      "logits/rejected": -2.354536294937134,
      "logps/chosen": -181.27871704101562,
      "logps/rejected": -123.42303466796875,
      "loss": 0.0951,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7625961303710938,
      "rewards/margins": 2.3136444091796875,
      "rewards/rejected": -0.5510482788085938,
      "step": 491
    },
    {
      "epoch": 0.1968,
      "grad_norm": 9.418853759765625,
      "learning_rate": 9.345333333333333e-07,
      "logits/chosen": -1.9829561710357666,
      "logits/rejected": -1.9130961894989014,
      "logps/chosen": -147.15000915527344,
      "logps/rejected": -92.23004150390625,
      "loss": 0.2478,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5768696069717407,
      "rewards/margins": 1.2890231609344482,
      "rewards/rejected": -0.7121536135673523,
      "step": 492
    },
    {
      "epoch": 0.1972,
      "grad_norm": 7.2088165283203125,
      "learning_rate": 9.344e-07,
      "logits/chosen": -1.5732342004776,
      "logits/rejected": -2.444749355316162,
      "logps/chosen": -93.45362854003906,
      "logps/rejected": -90.08836364746094,
      "loss": 0.2023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.806311845779419,
      "rewards/margins": 1.6226593255996704,
      "rewards/rejected": -0.8163474798202515,
      "step": 493
    },
    {
      "epoch": 0.1976,
      "grad_norm": 7.227087497711182,
      "learning_rate": 9.342666666666667e-07,
      "logits/chosen": -1.7847840785980225,
      "logits/rejected": -2.924168109893799,
      "logps/chosen": -104.07260131835938,
      "logps/rejected": -131.7213134765625,
      "loss": 0.1754,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4224357604980469,
      "rewards/margins": 1.7949786186218262,
      "rewards/rejected": -0.37254294753074646,
      "step": 494
    },
    {
      "epoch": 0.198,
      "grad_norm": 10.597424507141113,
      "learning_rate": 9.341333333333333e-07,
      "logits/chosen": -2.2907211780548096,
      "logits/rejected": -2.5026845932006836,
      "logps/chosen": -136.13319396972656,
      "logps/rejected": -157.5258026123047,
      "loss": 0.2759,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9583473205566406,
      "rewards/margins": 1.3819308280944824,
      "rewards/rejected": -0.42358362674713135,
      "step": 495
    },
    {
      "epoch": 0.1984,
      "grad_norm": 4.1756157875061035,
      "learning_rate": 9.34e-07,
      "logits/chosen": -2.379871368408203,
      "logits/rejected": -2.3513474464416504,
      "logps/chosen": -142.880615234375,
      "logps/rejected": -94.85346221923828,
      "loss": 0.0945,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8144347667694092,
      "rewards/margins": 2.311368465423584,
      "rewards/rejected": -0.4969337582588196,
      "step": 496
    },
    {
      "epoch": 0.1988,
      "grad_norm": 8.597823143005371,
      "learning_rate": 9.338666666666666e-07,
      "logits/chosen": -2.07090163230896,
      "logits/rejected": -2.977062225341797,
      "logps/chosen": -171.72543334960938,
      "logps/rejected": -114.67951965332031,
      "loss": 0.1669,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9353339672088623,
      "rewards/margins": 1.8114227056503296,
      "rewards/rejected": -0.8760887384414673,
      "step": 497
    },
    {
      "epoch": 0.1992,
      "grad_norm": 10.794647216796875,
      "learning_rate": 9.337333333333333e-07,
      "logits/chosen": -1.734929084777832,
      "logits/rejected": -2.386897087097168,
      "logps/chosen": -87.17213439941406,
      "logps/rejected": -113.28622436523438,
      "loss": 0.2866,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7945491671562195,
      "rewards/margins": 1.664189100265503,
      "rewards/rejected": -0.8696399927139282,
      "step": 498
    },
    {
      "epoch": 0.1996,
      "grad_norm": 6.347395896911621,
      "learning_rate": 9.335999999999999e-07,
      "logits/chosen": -2.1863510608673096,
      "logits/rejected": -2.6890039443969727,
      "logps/chosen": -198.66835021972656,
      "logps/rejected": -109.26004791259766,
      "loss": 0.1534,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2794113159179688,
      "rewards/margins": 2.150639533996582,
      "rewards/rejected": -0.8712280988693237,
      "step": 499
    },
    {
      "epoch": 0.2,
      "grad_norm": 13.940518379211426,
      "learning_rate": 9.334666666666666e-07,
      "logits/chosen": -1.9059054851531982,
      "logits/rejected": -2.036984920501709,
      "logps/chosen": -116.38938903808594,
      "logps/rejected": -171.67164611816406,
      "loss": 0.2798,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0613521337509155,
      "rewards/margins": 1.1343482732772827,
      "rewards/rejected": -0.07299615442752838,
      "step": 500
    },
    {
      "epoch": 0.2004,
      "grad_norm": 8.061468124389648,
      "learning_rate": 9.333333333333333e-07,
      "logits/chosen": -2.34066104888916,
      "logits/rejected": -3.34915828704834,
      "logps/chosen": -122.47455596923828,
      "logps/rejected": -101.56172180175781,
      "loss": 0.1885,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2572883367538452,
      "rewards/margins": 1.6253037452697754,
      "rewards/rejected": -0.3680152893066406,
      "step": 501
    },
    {
      "epoch": 0.2008,
      "grad_norm": 11.606132507324219,
      "learning_rate": 9.332e-07,
      "logits/chosen": -2.2449567317962646,
      "logits/rejected": -2.422640323638916,
      "logps/chosen": -128.5067138671875,
      "logps/rejected": -116.58114624023438,
      "loss": 0.3194,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5791565179824829,
      "rewards/margins": 0.9822303652763367,
      "rewards/rejected": -0.40307387709617615,
      "step": 502
    },
    {
      "epoch": 0.2012,
      "grad_norm": 6.091205596923828,
      "learning_rate": 9.330666666666667e-07,
      "logits/chosen": -2.3752846717834473,
      "logits/rejected": -2.8104844093322754,
      "logps/chosen": -160.57070922851562,
      "logps/rejected": -142.38006591796875,
      "loss": 0.0979,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7417564392089844,
      "rewards/margins": 2.424215078353882,
      "rewards/rejected": -0.6824585199356079,
      "step": 503
    },
    {
      "epoch": 0.2016,
      "grad_norm": 5.132981300354004,
      "learning_rate": 9.329333333333332e-07,
      "logits/chosen": -2.3334970474243164,
      "logits/rejected": -2.7119503021240234,
      "logps/chosen": -159.86447143554688,
      "logps/rejected": -112.59825134277344,
      "loss": 0.1331,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2504478693008423,
      "rewards/margins": 2.005718231201172,
      "rewards/rejected": -0.7552704215049744,
      "step": 504
    },
    {
      "epoch": 0.202,
      "grad_norm": 6.313882350921631,
      "learning_rate": 9.327999999999999e-07,
      "logits/chosen": -2.3980395793914795,
      "logits/rejected": -2.643448829650879,
      "logps/chosen": -165.32369995117188,
      "logps/rejected": -107.30244445800781,
      "loss": 0.1302,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8517022132873535,
      "rewards/margins": 2.188805103302002,
      "rewards/rejected": -0.3371029198169708,
      "step": 505
    },
    {
      "epoch": 0.2024,
      "grad_norm": 4.633833408355713,
      "learning_rate": 9.326666666666666e-07,
      "logits/chosen": -2.3942010402679443,
      "logits/rejected": -2.236712694168091,
      "logps/chosen": -127.91885375976562,
      "logps/rejected": -100.73226165771484,
      "loss": 0.1035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0233891010284424,
      "rewards/margins": 2.3731911182403564,
      "rewards/rejected": -0.34980201721191406,
      "step": 506
    },
    {
      "epoch": 0.2028,
      "grad_norm": 6.689391136169434,
      "learning_rate": 9.325333333333333e-07,
      "logits/chosen": -1.9617741107940674,
      "logits/rejected": -2.7298288345336914,
      "logps/chosen": -141.82858276367188,
      "logps/rejected": -106.39894104003906,
      "loss": 0.1687,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5395160913467407,
      "rewards/margins": 1.7802479267120361,
      "rewards/rejected": -0.24073180556297302,
      "step": 507
    },
    {
      "epoch": 0.2032,
      "grad_norm": 4.192946434020996,
      "learning_rate": 9.324e-07,
      "logits/chosen": -2.070082664489746,
      "logits/rejected": -2.6764841079711914,
      "logps/chosen": -215.19357299804688,
      "logps/rejected": -179.49163818359375,
      "loss": 0.0697,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.213052272796631,
      "rewards/margins": 2.8321189880371094,
      "rewards/rejected": -0.619066596031189,
      "step": 508
    },
    {
      "epoch": 0.2036,
      "grad_norm": 5.330076694488525,
      "learning_rate": 9.322666666666667e-07,
      "logits/chosen": -2.248229742050171,
      "logits/rejected": -2.1239218711853027,
      "logps/chosen": -165.724609375,
      "logps/rejected": -128.76390075683594,
      "loss": 0.1162,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.563328504562378,
      "rewards/margins": 2.286799669265747,
      "rewards/rejected": -0.7234710454940796,
      "step": 509
    },
    {
      "epoch": 0.204,
      "grad_norm": 10.955513954162598,
      "learning_rate": 9.321333333333333e-07,
      "logits/chosen": -2.1721315383911133,
      "logits/rejected": -2.471055507659912,
      "logps/chosen": -164.7738037109375,
      "logps/rejected": -118.41771697998047,
      "loss": 0.2697,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6077102422714233,
      "rewards/margins": 1.17875337600708,
      "rewards/rejected": -0.5710430145263672,
      "step": 510
    },
    {
      "epoch": 0.2044,
      "grad_norm": 10.442501068115234,
      "learning_rate": 9.32e-07,
      "logits/chosen": -2.0005998611450195,
      "logits/rejected": -2.6251673698425293,
      "logps/chosen": -154.5841522216797,
      "logps/rejected": -123.58727264404297,
      "loss": 0.2738,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7635536193847656,
      "rewards/margins": 1.158346176147461,
      "rewards/rejected": -0.3947925567626953,
      "step": 511
    },
    {
      "epoch": 0.2048,
      "grad_norm": 10.34024715423584,
      "learning_rate": 9.318666666666666e-07,
      "logits/chosen": -1.9066263437271118,
      "logits/rejected": -2.4763245582580566,
      "logps/chosen": -95.86939239501953,
      "logps/rejected": -144.7663116455078,
      "loss": 0.2742,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7839027643203735,
      "rewards/margins": 1.161989688873291,
      "rewards/rejected": -0.3780868649482727,
      "step": 512
    },
    {
      "epoch": 0.2052,
      "grad_norm": 3.960362195968628,
      "learning_rate": 9.317333333333333e-07,
      "logits/chosen": -1.9978461265563965,
      "logits/rejected": -2.012683391571045,
      "logps/chosen": -168.5716552734375,
      "logps/rejected": -134.04898071289062,
      "loss": 0.0897,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2705495357513428,
      "rewards/margins": 2.4645657539367676,
      "rewards/rejected": -0.19401627779006958,
      "step": 513
    },
    {
      "epoch": 0.2056,
      "grad_norm": 3.8010120391845703,
      "learning_rate": 9.315999999999999e-07,
      "logits/chosen": -2.1080710887908936,
      "logits/rejected": -2.9360415935516357,
      "logps/chosen": -137.08108520507812,
      "logps/rejected": -124.10154724121094,
      "loss": 0.0684,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1974217891693115,
      "rewards/margins": 2.8576011657714844,
      "rewards/rejected": -0.6601795554161072,
      "step": 514
    },
    {
      "epoch": 0.206,
      "grad_norm": 4.854564189910889,
      "learning_rate": 9.314666666666666e-07,
      "logits/chosen": -2.324739933013916,
      "logits/rejected": -2.597329616546631,
      "logps/chosen": -162.18719482421875,
      "logps/rejected": -171.10263061523438,
      "loss": 0.0807,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.900201439857483,
      "rewards/margins": 2.482192277908325,
      "rewards/rejected": -0.5819908380508423,
      "step": 515
    },
    {
      "epoch": 0.2064,
      "grad_norm": 3.2335822582244873,
      "learning_rate": 9.313333333333333e-07,
      "logits/chosen": -1.9362287521362305,
      "logits/rejected": -1.9500513076782227,
      "logps/chosen": -108.2002182006836,
      "logps/rejected": -94.03109741210938,
      "loss": 0.0731,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0196890830993652,
      "rewards/margins": 2.593721866607666,
      "rewards/rejected": -0.5740326046943665,
      "step": 516
    },
    {
      "epoch": 0.2068,
      "grad_norm": 1.7654461860656738,
      "learning_rate": 9.312e-07,
      "logits/chosen": -2.5060510635375977,
      "logits/rejected": -2.60414457321167,
      "logps/chosen": -186.52133178710938,
      "logps/rejected": -121.45533752441406,
      "loss": 0.0287,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3722052574157715,
      "rewards/margins": 3.5664894580841064,
      "rewards/rejected": -1.1942840814590454,
      "step": 517
    },
    {
      "epoch": 0.2072,
      "grad_norm": 1.9872816801071167,
      "learning_rate": 9.310666666666667e-07,
      "logits/chosen": -2.0246059894561768,
      "logits/rejected": -2.7776737213134766,
      "logps/chosen": -135.18260192871094,
      "logps/rejected": -128.4952850341797,
      "loss": 0.0339,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0687530040740967,
      "rewards/margins": 3.3787193298339844,
      "rewards/rejected": -1.3099663257598877,
      "step": 518
    },
    {
      "epoch": 0.2076,
      "grad_norm": 8.403228759765625,
      "learning_rate": 9.309333333333333e-07,
      "logits/chosen": -2.011042594909668,
      "logits/rejected": -1.6528054475784302,
      "logps/chosen": -191.68197631835938,
      "logps/rejected": -98.7454605102539,
      "loss": 0.1706,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4736428260803223,
      "rewards/margins": 1.6934845447540283,
      "rewards/rejected": -0.21984176337718964,
      "step": 519
    },
    {
      "epoch": 0.208,
      "grad_norm": 2.142554759979248,
      "learning_rate": 9.307999999999999e-07,
      "logits/chosen": -1.8042792081832886,
      "logits/rejected": -2.91148042678833,
      "logps/chosen": -94.10345458984375,
      "logps/rejected": -128.07647705078125,
      "loss": 0.0414,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9781670570373535,
      "rewards/margins": 3.2218968868255615,
      "rewards/rejected": -1.243729829788208,
      "step": 520
    },
    {
      "epoch": 0.2084,
      "grad_norm": 11.745914459228516,
      "learning_rate": 9.306666666666666e-07,
      "logits/chosen": -2.3091044425964355,
      "logits/rejected": -2.490844964981079,
      "logps/chosen": -137.16847229003906,
      "logps/rejected": -99.60391235351562,
      "loss": 0.1994,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9724781513214111,
      "rewards/margins": 1.5674580335617065,
      "rewards/rejected": -0.5949798822402954,
      "step": 521
    },
    {
      "epoch": 0.2088,
      "grad_norm": 3.8497989177703857,
      "learning_rate": 9.305333333333333e-07,
      "logits/chosen": -2.3329851627349854,
      "logits/rejected": -2.154874324798584,
      "logps/chosen": -140.24830627441406,
      "logps/rejected": -103.74093627929688,
      "loss": 0.0784,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8731849193572998,
      "rewards/margins": 2.511683940887451,
      "rewards/rejected": -0.6384990811347961,
      "step": 522
    },
    {
      "epoch": 0.2092,
      "grad_norm": 9.97929573059082,
      "learning_rate": 9.303999999999999e-07,
      "logits/chosen": -1.9388933181762695,
      "logits/rejected": -2.5194199085235596,
      "logps/chosen": -98.15507507324219,
      "logps/rejected": -103.97845458984375,
      "loss": 0.293,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.035801649093628,
      "rewards/margins": 1.1688064336776733,
      "rewards/rejected": -0.13300475478172302,
      "step": 523
    },
    {
      "epoch": 0.2096,
      "grad_norm": 9.46906566619873,
      "learning_rate": 9.302666666666666e-07,
      "logits/chosen": -2.164567470550537,
      "logits/rejected": -2.879485845565796,
      "logps/chosen": -181.82583618164062,
      "logps/rejected": -114.92262268066406,
      "loss": 0.1835,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3956940174102783,
      "rewards/margins": 1.6661076545715332,
      "rewards/rejected": -0.2704135775566101,
      "step": 524
    },
    {
      "epoch": 0.21,
      "grad_norm": 7.801684856414795,
      "learning_rate": 9.301333333333333e-07,
      "logits/chosen": -2.194638729095459,
      "logits/rejected": -1.8523585796356201,
      "logps/chosen": -99.1300048828125,
      "logps/rejected": -81.2927474975586,
      "loss": 0.1943,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.956578016281128,
      "rewards/margins": 1.8204548358917236,
      "rewards/rejected": 0.13612328469753265,
      "step": 525
    },
    {
      "epoch": 0.2104,
      "grad_norm": 5.766552448272705,
      "learning_rate": 9.3e-07,
      "logits/chosen": -2.2930564880371094,
      "logits/rejected": -1.4864250421524048,
      "logps/chosen": -106.78300476074219,
      "logps/rejected": -80.27959442138672,
      "loss": 0.1432,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2654004096984863,
      "rewards/margins": 1.8823307752609253,
      "rewards/rejected": -0.616930365562439,
      "step": 526
    },
    {
      "epoch": 0.2108,
      "grad_norm": 5.2296462059021,
      "learning_rate": 9.298666666666666e-07,
      "logits/chosen": -2.1747851371765137,
      "logits/rejected": -2.899171829223633,
      "logps/chosen": -139.06375122070312,
      "logps/rejected": -127.78770446777344,
      "loss": 0.098,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4703361988067627,
      "rewards/margins": 2.2854061126708984,
      "rewards/rejected": -0.8150699734687805,
      "step": 527
    },
    {
      "epoch": 0.2112,
      "grad_norm": 8.327896118164062,
      "learning_rate": 9.297333333333333e-07,
      "logits/chosen": -2.568650960922241,
      "logits/rejected": -2.846795082092285,
      "logps/chosen": -201.46524047851562,
      "logps/rejected": -153.58688354492188,
      "loss": 0.1325,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.709869384765625,
      "rewards/margins": 2.1291422843933105,
      "rewards/rejected": -0.4192729890346527,
      "step": 528
    },
    {
      "epoch": 0.2116,
      "grad_norm": 4.584876537322998,
      "learning_rate": 9.296e-07,
      "logits/chosen": -2.382266044616699,
      "logits/rejected": -2.3085780143737793,
      "logps/chosen": -120.27632904052734,
      "logps/rejected": -89.17654418945312,
      "loss": 0.0972,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.917510986328125,
      "rewards/margins": 2.3541531562805176,
      "rewards/rejected": -0.4366421103477478,
      "step": 529
    },
    {
      "epoch": 0.212,
      "grad_norm": 3.335068941116333,
      "learning_rate": 9.294666666666667e-07,
      "logits/chosen": -2.248896360397339,
      "logits/rejected": -3.2816991806030273,
      "logps/chosen": -182.5233154296875,
      "logps/rejected": -119.84210205078125,
      "loss": 0.0608,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9551904201507568,
      "rewards/margins": 2.780116319656372,
      "rewards/rejected": -0.8249260187149048,
      "step": 530
    },
    {
      "epoch": 0.2124,
      "grad_norm": 3.947721242904663,
      "learning_rate": 9.293333333333333e-07,
      "logits/chosen": -1.3544588088989258,
      "logits/rejected": -2.3086771965026855,
      "logps/chosen": -97.50584411621094,
      "logps/rejected": -108.17301177978516,
      "loss": 0.062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8721497058868408,
      "rewards/margins": 2.8495891094207764,
      "rewards/rejected": -0.9774395227432251,
      "step": 531
    },
    {
      "epoch": 0.2128,
      "grad_norm": 9.49806022644043,
      "learning_rate": 9.292e-07,
      "logits/chosen": -1.7887885570526123,
      "logits/rejected": -2.7117953300476074,
      "logps/chosen": -107.69741821289062,
      "logps/rejected": -136.1416015625,
      "loss": 0.1795,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2809380292892456,
      "rewards/margins": 2.1246020793914795,
      "rewards/rejected": -0.8436641693115234,
      "step": 532
    },
    {
      "epoch": 0.2132,
      "grad_norm": 3.193403482437134,
      "learning_rate": 9.290666666666666e-07,
      "logits/chosen": -2.267568588256836,
      "logits/rejected": -2.1862120628356934,
      "logps/chosen": -128.17739868164062,
      "logps/rejected": -81.00589752197266,
      "loss": 0.0745,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1424763202667236,
      "rewards/margins": 2.5594544410705566,
      "rewards/rejected": -0.41697806119918823,
      "step": 533
    },
    {
      "epoch": 0.2136,
      "grad_norm": 5.751621723175049,
      "learning_rate": 9.289333333333333e-07,
      "logits/chosen": -2.1338367462158203,
      "logits/rejected": -2.381269931793213,
      "logps/chosen": -181.854736328125,
      "logps/rejected": -129.5194854736328,
      "loss": 0.1244,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4010848999023438,
      "rewards/margins": 2.179605484008789,
      "rewards/rejected": -0.7785205841064453,
      "step": 534
    },
    {
      "epoch": 0.214,
      "grad_norm": 6.077519416809082,
      "learning_rate": 9.287999999999999e-07,
      "logits/chosen": -2.2039172649383545,
      "logits/rejected": -1.9957239627838135,
      "logps/chosen": -190.97586059570312,
      "logps/rejected": -114.42587280273438,
      "loss": 0.1535,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5787034034729004,
      "rewards/margins": 2.179396629333496,
      "rewards/rejected": -0.6006931066513062,
      "step": 535
    },
    {
      "epoch": 0.2144,
      "grad_norm": 14.790604591369629,
      "learning_rate": 9.286666666666666e-07,
      "logits/chosen": -2.2446517944335938,
      "logits/rejected": -2.4892234802246094,
      "logps/chosen": -165.88514709472656,
      "logps/rejected": -125.22573852539062,
      "loss": 0.3465,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3733131885528564,
      "rewards/margins": 1.7197871208190918,
      "rewards/rejected": -0.3464741110801697,
      "step": 536
    },
    {
      "epoch": 0.2148,
      "grad_norm": 5.488980770111084,
      "learning_rate": 9.285333333333333e-07,
      "logits/chosen": -2.212526798248291,
      "logits/rejected": -1.6551121473312378,
      "logps/chosen": -162.16534423828125,
      "logps/rejected": -133.26698303222656,
      "loss": 0.1314,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7671089172363281,
      "rewards/margins": 1.999193549156189,
      "rewards/rejected": -0.23208463191986084,
      "step": 537
    },
    {
      "epoch": 0.2152,
      "grad_norm": 3.652303695678711,
      "learning_rate": 9.284e-07,
      "logits/chosen": -2.2762832641601562,
      "logits/rejected": -2.5127334594726562,
      "logps/chosen": -190.56881713867188,
      "logps/rejected": -106.97624206542969,
      "loss": 0.084,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4333107471466064,
      "rewards/margins": 2.4367167949676514,
      "rewards/rejected": -1.0034061670303345,
      "step": 538
    },
    {
      "epoch": 0.2156,
      "grad_norm": 7.612290859222412,
      "learning_rate": 9.282666666666667e-07,
      "logits/chosen": -2.1288957595825195,
      "logits/rejected": -1.8794869184494019,
      "logps/chosen": -139.8837890625,
      "logps/rejected": -82.68946838378906,
      "loss": 0.1517,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6946022510528564,
      "rewards/margins": 1.8822021484375,
      "rewards/rejected": -0.18759994208812714,
      "step": 539
    },
    {
      "epoch": 0.216,
      "grad_norm": 6.8561787605285645,
      "learning_rate": 9.281333333333334e-07,
      "logits/chosen": -2.022470712661743,
      "logits/rejected": -2.4979071617126465,
      "logps/chosen": -167.8480224609375,
      "logps/rejected": -108.19313049316406,
      "loss": 0.1161,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9723526239395142,
      "rewards/margins": 2.094348430633545,
      "rewards/rejected": -0.1219959408044815,
      "step": 540
    },
    {
      "epoch": 0.2164,
      "grad_norm": 5.6509480476379395,
      "learning_rate": 9.28e-07,
      "logits/chosen": -2.2327651977539062,
      "logits/rejected": -2.1090238094329834,
      "logps/chosen": -145.49172973632812,
      "logps/rejected": -107.03411865234375,
      "loss": 0.1092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.40617835521698,
      "rewards/margins": 2.3346738815307617,
      "rewards/rejected": -0.928495466709137,
      "step": 541
    },
    {
      "epoch": 0.2168,
      "grad_norm": 5.225980281829834,
      "learning_rate": 9.278666666666665e-07,
      "logits/chosen": -1.9520273208618164,
      "logits/rejected": -1.9309102296829224,
      "logps/chosen": -118.64085388183594,
      "logps/rejected": -96.96512603759766,
      "loss": 0.1519,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7083179950714111,
      "rewards/margins": 1.9277527332305908,
      "rewards/rejected": -0.2194347381591797,
      "step": 542
    },
    {
      "epoch": 0.2172,
      "grad_norm": 5.784890651702881,
      "learning_rate": 9.277333333333332e-07,
      "logits/chosen": -1.6409220695495605,
      "logits/rejected": -2.227893829345703,
      "logps/chosen": -85.7620620727539,
      "logps/rejected": -99.86888122558594,
      "loss": 0.1518,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.693817138671875,
      "rewards/margins": 1.8092701435089111,
      "rewards/rejected": -0.11545296758413315,
      "step": 543
    },
    {
      "epoch": 0.2176,
      "grad_norm": 3.4736433029174805,
      "learning_rate": 9.275999999999999e-07,
      "logits/chosen": -2.35071063041687,
      "logits/rejected": -2.086319923400879,
      "logps/chosen": -167.17947387695312,
      "logps/rejected": -88.9920883178711,
      "loss": 0.0839,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.873517632484436,
      "rewards/margins": 2.4435176849365234,
      "rewards/rejected": -0.5700000524520874,
      "step": 544
    },
    {
      "epoch": 0.218,
      "grad_norm": 9.985095977783203,
      "learning_rate": 9.274666666666666e-07,
      "logits/chosen": -2.4703733921051025,
      "logits/rejected": -2.706338882446289,
      "logps/chosen": -170.5040740966797,
      "logps/rejected": -123.49715423583984,
      "loss": 0.1689,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7115601301193237,
      "rewards/margins": 1.9648830890655518,
      "rewards/rejected": -0.2533229887485504,
      "step": 545
    },
    {
      "epoch": 0.2184,
      "grad_norm": 6.831315040588379,
      "learning_rate": 9.273333333333333e-07,
      "logits/chosen": -2.012416362762451,
      "logits/rejected": -1.9262511730194092,
      "logps/chosen": -125.55955505371094,
      "logps/rejected": -117.21409606933594,
      "loss": 0.1415,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.922071933746338,
      "rewards/margins": 2.5539231300354004,
      "rewards/rejected": -0.6318511962890625,
      "step": 546
    },
    {
      "epoch": 0.2188,
      "grad_norm": 6.472436904907227,
      "learning_rate": 9.272e-07,
      "logits/chosen": -2.5583999156951904,
      "logits/rejected": -2.545283794403076,
      "logps/chosen": -161.5812225341797,
      "logps/rejected": -203.7899169921875,
      "loss": 0.1523,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.970386028289795,
      "rewards/margins": 2.1239612102508545,
      "rewards/rejected": -0.153575137257576,
      "step": 547
    },
    {
      "epoch": 0.2192,
      "grad_norm": 9.201415061950684,
      "learning_rate": 9.270666666666667e-07,
      "logits/chosen": -1.8144350051879883,
      "logits/rejected": -2.3927693367004395,
      "logps/chosen": -97.26458740234375,
      "logps/rejected": -112.35279846191406,
      "loss": 0.2245,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9553241729736328,
      "rewards/margins": 1.384965419769287,
      "rewards/rejected": -0.42964133620262146,
      "step": 548
    },
    {
      "epoch": 0.2196,
      "grad_norm": 6.676873207092285,
      "learning_rate": 9.269333333333334e-07,
      "logits/chosen": -2.3260927200317383,
      "logits/rejected": -2.691859722137451,
      "logps/chosen": -191.578857421875,
      "logps/rejected": -195.8448944091797,
      "loss": 0.0779,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3778939247131348,
      "rewards/margins": 2.868323564529419,
      "rewards/rejected": -0.49042969942092896,
      "step": 549
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.6931257247924805,
      "learning_rate": 9.268e-07,
      "logits/chosen": -2.247598886489868,
      "logits/rejected": -2.8830230236053467,
      "logps/chosen": -122.86264038085938,
      "logps/rejected": -117.52342224121094,
      "loss": 0.036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.577867269515991,
      "rewards/margins": 3.3304548263549805,
      "rewards/rejected": -0.7525874972343445,
      "step": 550
    },
    {
      "epoch": 0.2204,
      "grad_norm": 3.9729151725769043,
      "learning_rate": 9.266666666666665e-07,
      "logits/chosen": -2.2526190280914307,
      "logits/rejected": -1.09675133228302,
      "logps/chosen": -149.23028564453125,
      "logps/rejected": -89.18367004394531,
      "loss": 0.0856,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2528395652770996,
      "rewards/margins": 2.458261489868164,
      "rewards/rejected": -0.20542185008525848,
      "step": 551
    },
    {
      "epoch": 0.2208,
      "grad_norm": 7.275918483734131,
      "learning_rate": 9.265333333333332e-07,
      "logits/chosen": -1.6633868217468262,
      "logits/rejected": -2.2727580070495605,
      "logps/chosen": -78.98997497558594,
      "logps/rejected": -80.80867004394531,
      "loss": 0.1565,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8979556560516357,
      "rewards/margins": 2.1236889362335205,
      "rewards/rejected": -0.2257331907749176,
      "step": 552
    },
    {
      "epoch": 0.2212,
      "grad_norm": 8.737053871154785,
      "learning_rate": 9.263999999999999e-07,
      "logits/chosen": -1.9771852493286133,
      "logits/rejected": -1.7337861061096191,
      "logps/chosen": -141.6680908203125,
      "logps/rejected": -99.94248962402344,
      "loss": 0.2613,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4028122425079346,
      "rewards/margins": 1.3290514945983887,
      "rewards/rejected": 0.07376060634851456,
      "step": 553
    },
    {
      "epoch": 0.2216,
      "grad_norm": 12.1159029006958,
      "learning_rate": 9.262666666666666e-07,
      "logits/chosen": -1.3889268636703491,
      "logits/rejected": -2.3517754077911377,
      "logps/chosen": -72.01126098632812,
      "logps/rejected": -93.17059326171875,
      "loss": 0.3245,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0118225812911987,
      "rewards/margins": 1.1696629524230957,
      "rewards/rejected": -0.15784034132957458,
      "step": 554
    },
    {
      "epoch": 0.222,
      "grad_norm": 7.2783894538879395,
      "learning_rate": 9.261333333333333e-07,
      "logits/chosen": -1.8668746948242188,
      "logits/rejected": -2.288020610809326,
      "logps/chosen": -131.17205810546875,
      "logps/rejected": -87.94537353515625,
      "loss": 0.1431,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6719074249267578,
      "rewards/margins": 1.9134891033172607,
      "rewards/rejected": -0.2415817230939865,
      "step": 555
    },
    {
      "epoch": 0.2224,
      "grad_norm": 2.911193609237671,
      "learning_rate": 9.26e-07,
      "logits/chosen": -2.615859031677246,
      "logits/rejected": -2.7870874404907227,
      "logps/chosen": -203.58816528320312,
      "logps/rejected": -112.55313110351562,
      "loss": 0.0461,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4382071495056152,
      "rewards/margins": 3.062826633453369,
      "rewards/rejected": -0.6246193051338196,
      "step": 556
    },
    {
      "epoch": 0.2228,
      "grad_norm": 2.84824538230896,
      "learning_rate": 9.258666666666666e-07,
      "logits/chosen": -2.7778053283691406,
      "logits/rejected": -2.7426300048828125,
      "logps/chosen": -172.4766845703125,
      "logps/rejected": -110.80818939208984,
      "loss": 0.0604,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4453606605529785,
      "rewards/margins": 2.894925355911255,
      "rewards/rejected": -0.44956475496292114,
      "step": 557
    },
    {
      "epoch": 0.2232,
      "grad_norm": 4.1483001708984375,
      "learning_rate": 9.257333333333333e-07,
      "logits/chosen": -1.877084732055664,
      "logits/rejected": -2.7329397201538086,
      "logps/chosen": -76.476318359375,
      "logps/rejected": -113.31039428710938,
      "loss": 0.1037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8400115966796875,
      "rewards/margins": 2.223817825317383,
      "rewards/rejected": -0.3838062286376953,
      "step": 558
    },
    {
      "epoch": 0.2236,
      "grad_norm": 6.721107482910156,
      "learning_rate": 9.256e-07,
      "logits/chosen": -1.8684786558151245,
      "logits/rejected": -1.3766605854034424,
      "logps/chosen": -119.37174987792969,
      "logps/rejected": -84.96134948730469,
      "loss": 0.1347,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3858890533447266,
      "rewards/margins": 2.0157620906829834,
      "rewards/rejected": -0.6298729181289673,
      "step": 559
    },
    {
      "epoch": 0.224,
      "grad_norm": 14.068025588989258,
      "learning_rate": 9.254666666666667e-07,
      "logits/chosen": -1.8085551261901855,
      "logits/rejected": -2.581085205078125,
      "logps/chosen": -138.67770385742188,
      "logps/rejected": -75.34889221191406,
      "loss": 0.3266,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1929975748062134,
      "rewards/margins": 1.1489458084106445,
      "rewards/rejected": 0.04405173659324646,
      "step": 560
    },
    {
      "epoch": 0.2244,
      "grad_norm": 5.707910060882568,
      "learning_rate": 9.253333333333333e-07,
      "logits/chosen": -2.06376051902771,
      "logits/rejected": -2.452502727508545,
      "logps/chosen": -106.71575927734375,
      "logps/rejected": -110.91313934326172,
      "loss": 0.1515,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9648075103759766,
      "rewards/margins": 2.504641532897949,
      "rewards/rejected": -0.5398338437080383,
      "step": 561
    },
    {
      "epoch": 0.2248,
      "grad_norm": 2.6644763946533203,
      "learning_rate": 9.251999999999999e-07,
      "logits/chosen": -2.313443899154663,
      "logits/rejected": -2.06732177734375,
      "logps/chosen": -126.06765747070312,
      "logps/rejected": -116.53884887695312,
      "loss": 0.0601,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4872121810913086,
      "rewards/margins": 3.223539113998413,
      "rewards/rejected": -0.7363271713256836,
      "step": 562
    },
    {
      "epoch": 0.2252,
      "grad_norm": 3.793586254119873,
      "learning_rate": 9.250666666666666e-07,
      "logits/chosen": -1.9201891422271729,
      "logits/rejected": -1.975314736366272,
      "logps/chosen": -129.16915893554688,
      "logps/rejected": -163.87814331054688,
      "loss": 0.0589,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4163055419921875,
      "rewards/margins": 2.8054356575012207,
      "rewards/rejected": -0.38913002610206604,
      "step": 563
    },
    {
      "epoch": 0.2256,
      "grad_norm": 9.26096248626709,
      "learning_rate": 9.249333333333333e-07,
      "logits/chosen": -2.008767604827881,
      "logits/rejected": -1.9087507724761963,
      "logps/chosen": -88.34838104248047,
      "logps/rejected": -92.07745361328125,
      "loss": 0.2742,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1747231483459473,
      "rewards/margins": 1.2010676860809326,
      "rewards/rejected": -0.026344671845436096,
      "step": 564
    },
    {
      "epoch": 0.226,
      "grad_norm": 2.3584682941436768,
      "learning_rate": 9.247999999999999e-07,
      "logits/chosen": -2.4677979946136475,
      "logits/rejected": -2.0262768268585205,
      "logps/chosen": -230.76785278320312,
      "logps/rejected": -106.66011047363281,
      "loss": 0.0337,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.905118465423584,
      "rewards/margins": 3.504652976989746,
      "rewards/rejected": -0.599534273147583,
      "step": 565
    },
    {
      "epoch": 0.2264,
      "grad_norm": 3.5413615703582764,
      "learning_rate": 9.246666666666666e-07,
      "logits/chosen": -1.4039177894592285,
      "logits/rejected": -1.7595361471176147,
      "logps/chosen": -72.85565185546875,
      "logps/rejected": -99.61497497558594,
      "loss": 0.083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9809813499450684,
      "rewards/margins": 2.507230043411255,
      "rewards/rejected": -0.526248574256897,
      "step": 566
    },
    {
      "epoch": 0.2268,
      "grad_norm": 5.150127410888672,
      "learning_rate": 9.245333333333333e-07,
      "logits/chosen": -2.2812533378601074,
      "logits/rejected": -1.720871925354004,
      "logps/chosen": -115.15081787109375,
      "logps/rejected": -86.54025268554688,
      "loss": 0.1476,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5362969636917114,
      "rewards/margins": 1.8803516626358032,
      "rewards/rejected": -0.34405481815338135,
      "step": 567
    },
    {
      "epoch": 0.2272,
      "grad_norm": 11.58620834350586,
      "learning_rate": 9.244e-07,
      "logits/chosen": -1.947754144668579,
      "logits/rejected": -2.1800503730773926,
      "logps/chosen": -96.94453430175781,
      "logps/rejected": -114.76966857910156,
      "loss": 0.2551,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8202621936798096,
      "rewards/margins": 1.4956014156341553,
      "rewards/rejected": -0.6753391027450562,
      "step": 568
    },
    {
      "epoch": 0.2276,
      "grad_norm": 8.476699829101562,
      "learning_rate": 9.242666666666667e-07,
      "logits/chosen": -2.445157527923584,
      "logits/rejected": -3.088357925415039,
      "logps/chosen": -137.68206787109375,
      "logps/rejected": -147.3998260498047,
      "loss": 0.1689,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8436832427978516,
      "rewards/margins": 1.6967731714248657,
      "rewards/rejected": -0.8530899286270142,
      "step": 569
    },
    {
      "epoch": 0.228,
      "grad_norm": 3.1538174152374268,
      "learning_rate": 9.241333333333333e-07,
      "logits/chosen": -1.9219484329223633,
      "logits/rejected": -2.291541337966919,
      "logps/chosen": -152.57351684570312,
      "logps/rejected": -104.71359252929688,
      "loss": 0.0577,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1773910522460938,
      "rewards/margins": 2.8646116256713867,
      "rewards/rejected": -0.6872207522392273,
      "step": 570
    },
    {
      "epoch": 0.2284,
      "grad_norm": 4.460324287414551,
      "learning_rate": 9.24e-07,
      "logits/chosen": -2.426373243331909,
      "logits/rejected": -2.2482120990753174,
      "logps/chosen": -122.36277770996094,
      "logps/rejected": -119.12437438964844,
      "loss": 0.0863,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.170900344848633,
      "rewards/margins": 2.4059133529663086,
      "rewards/rejected": -0.23501282930374146,
      "step": 571
    },
    {
      "epoch": 0.2288,
      "grad_norm": 16.09914207458496,
      "learning_rate": 9.238666666666665e-07,
      "logits/chosen": -1.9340250492095947,
      "logits/rejected": -1.9430322647094727,
      "logps/chosen": -85.14479064941406,
      "logps/rejected": -94.7332992553711,
      "loss": 0.4243,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1484276056289673,
      "rewards/margins": 0.6850197315216064,
      "rewards/rejected": 0.4634079039096832,
      "step": 572
    },
    {
      "epoch": 0.2292,
      "grad_norm": 6.198967456817627,
      "learning_rate": 9.237333333333332e-07,
      "logits/chosen": -1.8831725120544434,
      "logits/rejected": -2.4512951374053955,
      "logps/chosen": -126.92953491210938,
      "logps/rejected": -91.201171875,
      "loss": 0.1249,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.104355812072754,
      "rewards/margins": 2.177952527999878,
      "rewards/rejected": -0.07359695434570312,
      "step": 573
    },
    {
      "epoch": 0.2296,
      "grad_norm": 8.941195487976074,
      "learning_rate": 9.235999999999999e-07,
      "logits/chosen": -2.057032585144043,
      "logits/rejected": -1.5232040882110596,
      "logps/chosen": -147.32150268554688,
      "logps/rejected": -83.08203887939453,
      "loss": 0.1764,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2663238048553467,
      "rewards/margins": 1.7332710027694702,
      "rewards/rejected": -0.46694719791412354,
      "step": 574
    },
    {
      "epoch": 0.23,
      "grad_norm": 11.443182945251465,
      "learning_rate": 9.234666666666666e-07,
      "logits/chosen": -2.175344944000244,
      "logits/rejected": -1.6657061576843262,
      "logps/chosen": -183.8204345703125,
      "logps/rejected": -103.93013763427734,
      "loss": 0.2174,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6701736450195312,
      "rewards/margins": 1.7148667573928833,
      "rewards/rejected": -0.0446930006146431,
      "step": 575
    },
    {
      "epoch": 0.2304,
      "grad_norm": 3.4408156871795654,
      "learning_rate": 9.233333333333333e-07,
      "logits/chosen": -2.0061593055725098,
      "logits/rejected": -2.1777520179748535,
      "logps/chosen": -94.15010070800781,
      "logps/rejected": -96.13677978515625,
      "loss": 0.0752,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2707786560058594,
      "rewards/margins": 2.6477060317993164,
      "rewards/rejected": -0.3769271969795227,
      "step": 576
    },
    {
      "epoch": 0.2308,
      "grad_norm": 5.864231109619141,
      "learning_rate": 9.232e-07,
      "logits/chosen": -2.5547213554382324,
      "logits/rejected": -2.394847869873047,
      "logps/chosen": -140.03366088867188,
      "logps/rejected": -112.99923706054688,
      "loss": 0.0998,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.636209487915039,
      "rewards/margins": 2.2655396461486816,
      "rewards/rejected": -0.629330039024353,
      "step": 577
    },
    {
      "epoch": 0.2312,
      "grad_norm": 2.269970417022705,
      "learning_rate": 9.230666666666667e-07,
      "logits/chosen": -2.07314133644104,
      "logits/rejected": -2.1813621520996094,
      "logps/chosen": -83.76766967773438,
      "logps/rejected": -79.97016906738281,
      "loss": 0.0533,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1296730041503906,
      "rewards/margins": 2.911652088165283,
      "rewards/rejected": -0.7819790244102478,
      "step": 578
    },
    {
      "epoch": 0.2316,
      "grad_norm": 2.2934765815734863,
      "learning_rate": 9.229333333333334e-07,
      "logits/chosen": -1.9840595722198486,
      "logits/rejected": -2.0849814414978027,
      "logps/chosen": -137.22811889648438,
      "logps/rejected": -107.272705078125,
      "loss": 0.0392,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.621138572692871,
      "rewards/margins": 3.2257251739501953,
      "rewards/rejected": -0.6045867800712585,
      "step": 579
    },
    {
      "epoch": 0.232,
      "grad_norm": 3.560678482055664,
      "learning_rate": 9.227999999999999e-07,
      "logits/chosen": -2.607558250427246,
      "logits/rejected": -2.966257095336914,
      "logps/chosen": -146.4925994873047,
      "logps/rejected": -185.451904296875,
      "loss": 0.0546,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9671261310577393,
      "rewards/margins": 3.057671070098877,
      "rewards/rejected": -1.0905449390411377,
      "step": 580
    },
    {
      "epoch": 0.2324,
      "grad_norm": 13.073211669921875,
      "learning_rate": 9.226666666666666e-07,
      "logits/chosen": -2.135881185531616,
      "logits/rejected": -2.117236614227295,
      "logps/chosen": -93.72666931152344,
      "logps/rejected": -76.86854553222656,
      "loss": 0.2803,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.59397554397583,
      "rewards/margins": 1.5513912439346313,
      "rewards/rejected": 0.04258422553539276,
      "step": 581
    },
    {
      "epoch": 0.2328,
      "grad_norm": 12.24453067779541,
      "learning_rate": 9.225333333333333e-07,
      "logits/chosen": -1.6558988094329834,
      "logits/rejected": -2.116823673248291,
      "logps/chosen": -83.32247161865234,
      "logps/rejected": -111.07148742675781,
      "loss": 0.3043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1430546045303345,
      "rewards/margins": 1.118778944015503,
      "rewards/rejected": 0.024275589734315872,
      "step": 582
    },
    {
      "epoch": 0.2332,
      "grad_norm": 1.9165395498275757,
      "learning_rate": 9.224e-07,
      "logits/chosen": -2.288022756576538,
      "logits/rejected": -2.2787857055664062,
      "logps/chosen": -109.76866149902344,
      "logps/rejected": -111.55516815185547,
      "loss": 0.0483,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.45866060256958,
      "rewards/margins": 3.0070643424987793,
      "rewards/rejected": -0.5484035611152649,
      "step": 583
    },
    {
      "epoch": 0.2336,
      "grad_norm": 4.992643356323242,
      "learning_rate": 9.222666666666666e-07,
      "logits/chosen": -2.35801100730896,
      "logits/rejected": -2.312654972076416,
      "logps/chosen": -135.92361450195312,
      "logps/rejected": -127.72065734863281,
      "loss": 0.0798,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.137688636779785,
      "rewards/margins": 2.847416877746582,
      "rewards/rejected": -0.7097282409667969,
      "step": 584
    },
    {
      "epoch": 0.234,
      "grad_norm": 2.4812498092651367,
      "learning_rate": 9.221333333333333e-07,
      "logits/chosen": -2.1561849117279053,
      "logits/rejected": -2.6343307495117188,
      "logps/chosen": -126.67349243164062,
      "logps/rejected": -95.99671936035156,
      "loss": 0.0555,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7158427238464355,
      "rewards/margins": 2.9985780715942383,
      "rewards/rejected": -0.2827354371547699,
      "step": 585
    },
    {
      "epoch": 0.2344,
      "grad_norm": 7.52426290512085,
      "learning_rate": 9.22e-07,
      "logits/chosen": -2.371603012084961,
      "logits/rejected": -1.8571598529815674,
      "logps/chosen": -204.82809448242188,
      "logps/rejected": -102.08214569091797,
      "loss": 0.1091,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0733611583709717,
      "rewards/margins": 2.4365429878234863,
      "rewards/rejected": -0.3631816804409027,
      "step": 586
    },
    {
      "epoch": 0.2348,
      "grad_norm": 8.2027006149292,
      "learning_rate": 9.218666666666666e-07,
      "logits/chosen": -2.355703353881836,
      "logits/rejected": -2.598933696746826,
      "logps/chosen": -159.668212890625,
      "logps/rejected": -108.14897155761719,
      "loss": 0.1462,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.373582363128662,
      "rewards/margins": 2.1779251098632812,
      "rewards/rejected": 0.19565734267234802,
      "step": 587
    },
    {
      "epoch": 0.2352,
      "grad_norm": 2.270596981048584,
      "learning_rate": 9.217333333333333e-07,
      "logits/chosen": -2.079501152038574,
      "logits/rejected": -2.669987440109253,
      "logps/chosen": -123.7654037475586,
      "logps/rejected": -108.2442626953125,
      "loss": 0.0439,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.817138671875,
      "rewards/margins": 3.304234504699707,
      "rewards/rejected": -0.4870956838130951,
      "step": 588
    },
    {
      "epoch": 0.2356,
      "grad_norm": 1.822716474533081,
      "learning_rate": 9.215999999999999e-07,
      "logits/chosen": -2.431321620941162,
      "logits/rejected": -3.006063222885132,
      "logps/chosen": -181.23281860351562,
      "logps/rejected": -108.57621765136719,
      "loss": 0.0292,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5486671924591064,
      "rewards/margins": 3.521383285522461,
      "rewards/rejected": -0.9727161526679993,
      "step": 589
    },
    {
      "epoch": 0.236,
      "grad_norm": 3.6992082595825195,
      "learning_rate": 9.214666666666666e-07,
      "logits/chosen": -2.0377626419067383,
      "logits/rejected": -1.9542253017425537,
      "logps/chosen": -92.93869018554688,
      "logps/rejected": -80.43787384033203,
      "loss": 0.1011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6279139518737793,
      "rewards/margins": 2.240509033203125,
      "rewards/rejected": -0.6125950217247009,
      "step": 590
    },
    {
      "epoch": 0.2364,
      "grad_norm": 3.731442451477051,
      "learning_rate": 9.213333333333333e-07,
      "logits/chosen": -2.091855525970459,
      "logits/rejected": -2.18501353263855,
      "logps/chosen": -123.89698791503906,
      "logps/rejected": -104.71955871582031,
      "loss": 0.0699,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2076733112335205,
      "rewards/margins": 3.1222352981567383,
      "rewards/rejected": -0.9145618677139282,
      "step": 591
    },
    {
      "epoch": 0.2368,
      "grad_norm": 6.133926868438721,
      "learning_rate": 9.212e-07,
      "logits/chosen": -2.525125503540039,
      "logits/rejected": -2.6639397144317627,
      "logps/chosen": -122.28089904785156,
      "logps/rejected": -91.8167724609375,
      "loss": 0.147,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.788764238357544,
      "rewards/margins": 1.889958143234253,
      "rewards/rejected": -0.10119400918483734,
      "step": 592
    },
    {
      "epoch": 0.2372,
      "grad_norm": 1.2387627363204956,
      "learning_rate": 9.210666666666667e-07,
      "logits/chosen": -2.549286127090454,
      "logits/rejected": -2.660712718963623,
      "logps/chosen": -139.23745727539062,
      "logps/rejected": -127.6725845336914,
      "loss": 0.0236,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5606510639190674,
      "rewards/margins": 4.113010406494141,
      "rewards/rejected": -1.5523591041564941,
      "step": 593
    },
    {
      "epoch": 0.2376,
      "grad_norm": 4.921478748321533,
      "learning_rate": 9.209333333333333e-07,
      "logits/chosen": -2.533721446990967,
      "logits/rejected": -2.5240461826324463,
      "logps/chosen": -154.33767700195312,
      "logps/rejected": -147.677734375,
      "loss": 0.099,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.060211181640625,
      "rewards/margins": 2.3983986377716064,
      "rewards/rejected": -0.33818739652633667,
      "step": 594
    },
    {
      "epoch": 0.238,
      "grad_norm": 8.155335426330566,
      "learning_rate": 9.207999999999999e-07,
      "logits/chosen": -2.2015774250030518,
      "logits/rejected": -2.496580123901367,
      "logps/chosen": -86.99923706054688,
      "logps/rejected": -107.70211791992188,
      "loss": 0.2151,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5887291431427002,
      "rewards/margins": 1.954121470451355,
      "rewards/rejected": -0.3653923273086548,
      "step": 595
    },
    {
      "epoch": 0.2384,
      "grad_norm": 4.275660514831543,
      "learning_rate": 9.206666666666666e-07,
      "logits/chosen": -2.1645426750183105,
      "logits/rejected": -2.1494979858398438,
      "logps/chosen": -115.29388427734375,
      "logps/rejected": -97.72644805908203,
      "loss": 0.101,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9049309492111206,
      "rewards/margins": 2.2581734657287598,
      "rewards/rejected": -0.3532424867153168,
      "step": 596
    },
    {
      "epoch": 0.2388,
      "grad_norm": 2.9136528968811035,
      "learning_rate": 9.205333333333333e-07,
      "logits/chosen": -2.661978244781494,
      "logits/rejected": -3.2127506732940674,
      "logps/chosen": -167.0438232421875,
      "logps/rejected": -119.70510864257812,
      "loss": 0.0446,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.254100799560547,
      "rewards/margins": 3.209984540939331,
      "rewards/rejected": -0.955883800983429,
      "step": 597
    },
    {
      "epoch": 0.2392,
      "grad_norm": 7.498394966125488,
      "learning_rate": 9.203999999999999e-07,
      "logits/chosen": -2.0011396408081055,
      "logits/rejected": -2.2106826305389404,
      "logps/chosen": -94.99571228027344,
      "logps/rejected": -85.79864501953125,
      "loss": 0.181,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.00275456905365,
      "rewards/margins": 1.7371490001678467,
      "rewards/rejected": -0.7343944311141968,
      "step": 598
    },
    {
      "epoch": 0.2396,
      "grad_norm": 1.8346984386444092,
      "learning_rate": 9.202666666666666e-07,
      "logits/chosen": -2.3456835746765137,
      "logits/rejected": -2.4709577560424805,
      "logps/chosen": -123.18428039550781,
      "logps/rejected": -134.09866333007812,
      "loss": 0.0269,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5835509300231934,
      "rewards/margins": 3.60667085647583,
      "rewards/rejected": -1.0231198072433472,
      "step": 599
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.5443551540374756,
      "learning_rate": 9.201333333333333e-07,
      "logits/chosen": -2.646080493927002,
      "logits/rejected": -3.141538381576538,
      "logps/chosen": -222.87399291992188,
      "logps/rejected": -128.4886016845703,
      "loss": 0.0445,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.173970937728882,
      "rewards/margins": 3.419400691986084,
      "rewards/rejected": -1.2454299926757812,
      "step": 600
    },
    {
      "epoch": 0.2404,
      "grad_norm": 1.7674599885940552,
      "learning_rate": 9.2e-07,
      "logits/chosen": -2.0882856845855713,
      "logits/rejected": -2.8447682857513428,
      "logps/chosen": -115.40510559082031,
      "logps/rejected": -121.89952850341797,
      "loss": 0.0336,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7328076362609863,
      "rewards/margins": 3.4546332359313965,
      "rewards/rejected": -0.7218254208564758,
      "step": 601
    },
    {
      "epoch": 0.2408,
      "grad_norm": 2.687648296356201,
      "learning_rate": 9.198666666666667e-07,
      "logits/chosen": -2.1581485271453857,
      "logits/rejected": -2.4255685806274414,
      "logps/chosen": -190.29580688476562,
      "logps/rejected": -93.99517822265625,
      "loss": 0.0694,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5336410999298096,
      "rewards/margins": 2.953861713409424,
      "rewards/rejected": -0.4202207624912262,
      "step": 602
    },
    {
      "epoch": 0.2412,
      "grad_norm": 4.428715229034424,
      "learning_rate": 9.197333333333333e-07,
      "logits/chosen": -1.7661645412445068,
      "logits/rejected": -2.6880130767822266,
      "logps/chosen": -121.15853881835938,
      "logps/rejected": -137.2882080078125,
      "loss": 0.0804,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0260536670684814,
      "rewards/margins": 2.4805078506469727,
      "rewards/rejected": -0.45445406436920166,
      "step": 603
    },
    {
      "epoch": 0.2416,
      "grad_norm": 6.288358688354492,
      "learning_rate": 9.196e-07,
      "logits/chosen": -2.091054677963257,
      "logits/rejected": -2.391326904296875,
      "logps/chosen": -123.60911560058594,
      "logps/rejected": -123.90898132324219,
      "loss": 0.1282,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.678629755973816,
      "rewards/margins": 2.043154239654541,
      "rewards/rejected": -0.3645244538784027,
      "step": 604
    },
    {
      "epoch": 0.242,
      "grad_norm": 3.9890217781066895,
      "learning_rate": 9.194666666666666e-07,
      "logits/chosen": -2.2490429878234863,
      "logits/rejected": -3.1022450923919678,
      "logps/chosen": -130.23219299316406,
      "logps/rejected": -127.15831756591797,
      "loss": 0.0821,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.594042181968689,
      "rewards/margins": 2.4590492248535156,
      "rewards/rejected": -0.8650070428848267,
      "step": 605
    },
    {
      "epoch": 0.2424,
      "grad_norm": 4.15163516998291,
      "learning_rate": 9.193333333333333e-07,
      "logits/chosen": -1.9424594640731812,
      "logits/rejected": -2.5894763469696045,
      "logps/chosen": -107.03257751464844,
      "logps/rejected": -139.507080078125,
      "loss": 0.0769,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2107162475585938,
      "rewards/margins": 3.0438895225524902,
      "rewards/rejected": -0.833173394203186,
      "step": 606
    },
    {
      "epoch": 0.2428,
      "grad_norm": 6.592341899871826,
      "learning_rate": 9.192e-07,
      "logits/chosen": -2.288283348083496,
      "logits/rejected": -2.283653736114502,
      "logps/chosen": -91.71868133544922,
      "logps/rejected": -109.86637115478516,
      "loss": 0.1527,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0075607299804688,
      "rewards/margins": 2.0300490856170654,
      "rewards/rejected": -1.0224883556365967,
      "step": 607
    },
    {
      "epoch": 0.2432,
      "grad_norm": 1.3478922843933105,
      "learning_rate": 9.190666666666666e-07,
      "logits/chosen": -2.076326847076416,
      "logits/rejected": -2.2959961891174316,
      "logps/chosen": -100.6220703125,
      "logps/rejected": -105.02949523925781,
      "loss": 0.0336,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.356198310852051,
      "rewards/margins": 3.4033596515655518,
      "rewards/rejected": -1.0471614599227905,
      "step": 608
    },
    {
      "epoch": 0.2436,
      "grad_norm": 8.744962692260742,
      "learning_rate": 9.189333333333333e-07,
      "logits/chosen": -1.9705755710601807,
      "logits/rejected": -1.7805335521697998,
      "logps/chosen": -106.59883117675781,
      "logps/rejected": -98.12866973876953,
      "loss": 0.15,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8856182098388672,
      "rewards/margins": 2.2105236053466797,
      "rewards/rejected": -0.3249053955078125,
      "step": 609
    },
    {
      "epoch": 0.244,
      "grad_norm": 4.192782402038574,
      "learning_rate": 9.187999999999999e-07,
      "logits/chosen": -1.9193332195281982,
      "logits/rejected": -2.441084384918213,
      "logps/chosen": -118.85003662109375,
      "logps/rejected": -145.639404296875,
      "loss": 0.0512,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2334342002868652,
      "rewards/margins": 3.1838035583496094,
      "rewards/rejected": -0.9503692388534546,
      "step": 610
    },
    {
      "epoch": 0.2444,
      "grad_norm": 4.817984104156494,
      "learning_rate": 9.186666666666666e-07,
      "logits/chosen": -2.0918993949890137,
      "logits/rejected": -1.8604998588562012,
      "logps/chosen": -140.11582946777344,
      "logps/rejected": -89.33271789550781,
      "loss": 0.0829,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.728837490081787,
      "rewards/margins": 2.7159247398376465,
      "rewards/rejected": 0.012912750244140625,
      "step": 611
    },
    {
      "epoch": 0.2448,
      "grad_norm": 6.1236572265625,
      "learning_rate": 9.185333333333333e-07,
      "logits/chosen": -1.8853590488433838,
      "logits/rejected": -2.4752180576324463,
      "logps/chosen": -126.18761444091797,
      "logps/rejected": -105.61322021484375,
      "loss": 0.1017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4849371910095215,
      "rewards/margins": 2.7678403854370117,
      "rewards/rejected": -0.2829033136367798,
      "step": 612
    },
    {
      "epoch": 0.2452,
      "grad_norm": 4.791440486907959,
      "learning_rate": 9.184e-07,
      "logits/chosen": -2.093857526779175,
      "logits/rejected": -2.9014904499053955,
      "logps/chosen": -160.82887268066406,
      "logps/rejected": -127.09999084472656,
      "loss": 0.0772,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1247611045837402,
      "rewards/margins": 2.6821913719177246,
      "rewards/rejected": -0.5574302673339844,
      "step": 613
    },
    {
      "epoch": 0.2456,
      "grad_norm": 3.762228012084961,
      "learning_rate": 9.182666666666667e-07,
      "logits/chosen": -1.8682012557983398,
      "logits/rejected": -2.8035030364990234,
      "logps/chosen": -99.35635375976562,
      "logps/rejected": -113.27562713623047,
      "loss": 0.0863,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.843681812286377,
      "rewards/margins": 2.602992057800293,
      "rewards/rejected": -0.7593101263046265,
      "step": 614
    },
    {
      "epoch": 0.246,
      "grad_norm": 2.464498996734619,
      "learning_rate": 9.181333333333333e-07,
      "logits/chosen": -2.372800827026367,
      "logits/rejected": -2.2947182655334473,
      "logps/chosen": -126.82908630371094,
      "logps/rejected": -86.53638458251953,
      "loss": 0.0547,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3480963706970215,
      "rewards/margins": 2.882110118865967,
      "rewards/rejected": -0.5340137481689453,
      "step": 615
    },
    {
      "epoch": 0.2464,
      "grad_norm": 18.60863494873047,
      "learning_rate": 9.18e-07,
      "logits/chosen": -1.9920580387115479,
      "logits/rejected": -3.5917739868164062,
      "logps/chosen": -107.25332641601562,
      "logps/rejected": -139.3303680419922,
      "loss": 0.2926,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1247131824493408,
      "rewards/margins": 1.6774479150772095,
      "rewards/rejected": -0.5527347922325134,
      "step": 616
    },
    {
      "epoch": 0.2468,
      "grad_norm": 5.975152492523193,
      "learning_rate": 9.178666666666666e-07,
      "logits/chosen": -2.137723445892334,
      "logits/rejected": -3.0126357078552246,
      "logps/chosen": -147.91952514648438,
      "logps/rejected": -123.01336669921875,
      "loss": 0.116,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2880730628967285,
      "rewards/margins": 2.100728988647461,
      "rewards/rejected": -0.812656044960022,
      "step": 617
    },
    {
      "epoch": 0.2472,
      "grad_norm": 4.805010795593262,
      "learning_rate": 9.177333333333332e-07,
      "logits/chosen": -1.5574352741241455,
      "logits/rejected": -2.4105944633483887,
      "logps/chosen": -96.75300598144531,
      "logps/rejected": -97.66769409179688,
      "loss": 0.0906,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8259937763214111,
      "rewards/margins": 2.554739475250244,
      "rewards/rejected": -0.728745698928833,
      "step": 618
    },
    {
      "epoch": 0.2476,
      "grad_norm": 2.5749592781066895,
      "learning_rate": 9.175999999999999e-07,
      "logits/chosen": -2.3138394355773926,
      "logits/rejected": -1.9986528158187866,
      "logps/chosen": -159.53414916992188,
      "logps/rejected": -111.28475952148438,
      "loss": 0.0469,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.604696750640869,
      "rewards/margins": 3.2527005672454834,
      "rewards/rejected": -0.6480037569999695,
      "step": 619
    },
    {
      "epoch": 0.248,
      "grad_norm": 1.4511947631835938,
      "learning_rate": 9.174666666666666e-07,
      "logits/chosen": -2.2789502143859863,
      "logits/rejected": -2.358292579650879,
      "logps/chosen": -114.35531616210938,
      "logps/rejected": -110.7822036743164,
      "loss": 0.0262,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.997640609741211,
      "rewards/margins": 3.634840488433838,
      "rewards/rejected": -0.6371997594833374,
      "step": 620
    },
    {
      "epoch": 0.2484,
      "grad_norm": 6.095137596130371,
      "learning_rate": 9.173333333333333e-07,
      "logits/chosen": -1.8216123580932617,
      "logits/rejected": -2.70164155960083,
      "logps/chosen": -82.97135925292969,
      "logps/rejected": -121.21495056152344,
      "loss": 0.0983,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.420744776725769,
      "rewards/margins": 2.2869629859924316,
      "rewards/rejected": -0.8662182092666626,
      "step": 621
    },
    {
      "epoch": 0.2488,
      "grad_norm": 5.185318946838379,
      "learning_rate": 9.172e-07,
      "logits/chosen": -2.307450771331787,
      "logits/rejected": -2.9182114601135254,
      "logps/chosen": -92.93429565429688,
      "logps/rejected": -120.03754425048828,
      "loss": 0.1043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.346314549446106,
      "rewards/margins": 2.230534076690674,
      "rewards/rejected": -0.884219765663147,
      "step": 622
    },
    {
      "epoch": 0.2492,
      "grad_norm": 14.825998306274414,
      "learning_rate": 9.170666666666667e-07,
      "logits/chosen": -2.3967771530151367,
      "logits/rejected": -2.0506834983825684,
      "logps/chosen": -139.56143188476562,
      "logps/rejected": -85.3072280883789,
      "loss": 0.2916,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.541904091835022,
      "rewards/margins": 1.7504818439483643,
      "rewards/rejected": -0.2085777223110199,
      "step": 623
    },
    {
      "epoch": 0.2496,
      "grad_norm": 10.156535148620605,
      "learning_rate": 9.169333333333334e-07,
      "logits/chosen": -2.3175601959228516,
      "logits/rejected": -2.496799945831299,
      "logps/chosen": -100.32350158691406,
      "logps/rejected": -86.17234802246094,
      "loss": 0.2602,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5848820209503174,
      "rewards/margins": 1.215055227279663,
      "rewards/rejected": 0.36982688307762146,
      "step": 624
    },
    {
      "epoch": 0.25,
      "grad_norm": 13.01721477508545,
      "learning_rate": 9.168e-07,
      "logits/chosen": -2.130720615386963,
      "logits/rejected": -2.0666606426239014,
      "logps/chosen": -146.96890258789062,
      "logps/rejected": -90.62645721435547,
      "loss": 0.2617,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7306369543075562,
      "rewards/margins": 2.1104159355163574,
      "rewards/rejected": -0.37977904081344604,
      "step": 625
    },
    {
      "epoch": 0.2504,
      "grad_norm": 1.4628798961639404,
      "learning_rate": 9.166666666666665e-07,
      "logits/chosen": -2.2636475563049316,
      "logits/rejected": -2.4741523265838623,
      "logps/chosen": -134.47119140625,
      "logps/rejected": -113.16146850585938,
      "loss": 0.0321,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.416177272796631,
      "rewards/margins": 3.481356620788574,
      "rewards/rejected": -1.0651791095733643,
      "step": 626
    },
    {
      "epoch": 0.2508,
      "grad_norm": 2.687530040740967,
      "learning_rate": 9.165333333333332e-07,
      "logits/chosen": -2.5677576065063477,
      "logits/rejected": -2.62863826751709,
      "logps/chosen": -208.03515625,
      "logps/rejected": -103.0213851928711,
      "loss": 0.0422,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.368025302886963,
      "rewards/margins": 3.166776180267334,
      "rewards/rejected": -0.7987511157989502,
      "step": 627
    },
    {
      "epoch": 0.2512,
      "grad_norm": 9.929285049438477,
      "learning_rate": 9.163999999999999e-07,
      "logits/chosen": -1.9500765800476074,
      "logits/rejected": -2.1025426387786865,
      "logps/chosen": -100.94731140136719,
      "logps/rejected": -84.50849914550781,
      "loss": 0.2194,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5922088623046875,
      "rewards/margins": 1.4358493089675903,
      "rewards/rejected": 0.1563594788312912,
      "step": 628
    },
    {
      "epoch": 0.2516,
      "grad_norm": 3.9538214206695557,
      "learning_rate": 9.162666666666666e-07,
      "logits/chosen": -1.892045259475708,
      "logits/rejected": -3.1342644691467285,
      "logps/chosen": -221.69845581054688,
      "logps/rejected": -137.94296264648438,
      "loss": 0.0689,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8828376531600952,
      "rewards/margins": 2.996607780456543,
      "rewards/rejected": -1.1137700080871582,
      "step": 629
    },
    {
      "epoch": 0.252,
      "grad_norm": 5.027427673339844,
      "learning_rate": 9.161333333333333e-07,
      "logits/chosen": -1.8619444370269775,
      "logits/rejected": -2.4819986820220947,
      "logps/chosen": -98.96493530273438,
      "logps/rejected": -100.77584838867188,
      "loss": 0.1243,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9430019855499268,
      "rewards/margins": 2.2630958557128906,
      "rewards/rejected": -0.32009392976760864,
      "step": 630
    },
    {
      "epoch": 0.2524,
      "grad_norm": 6.846052169799805,
      "learning_rate": 9.16e-07,
      "logits/chosen": -1.9328484535217285,
      "logits/rejected": -2.109179973602295,
      "logps/chosen": -92.80586242675781,
      "logps/rejected": -84.44673919677734,
      "loss": 0.24,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3498684167861938,
      "rewards/margins": 1.6951401233673096,
      "rewards/rejected": -0.3452717065811157,
      "step": 631
    },
    {
      "epoch": 0.2528,
      "grad_norm": 3.758017063140869,
      "learning_rate": 9.158666666666667e-07,
      "logits/chosen": -1.9829437732696533,
      "logits/rejected": -1.8337843418121338,
      "logps/chosen": -103.67214965820312,
      "logps/rejected": -96.71917724609375,
      "loss": 0.0816,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.842125415802002,
      "rewards/margins": 2.4820141792297363,
      "rewards/rejected": -0.6398887634277344,
      "step": 632
    },
    {
      "epoch": 0.2532,
      "grad_norm": 2.618180274963379,
      "learning_rate": 9.157333333333333e-07,
      "logits/chosen": -2.147724151611328,
      "logits/rejected": -2.5247979164123535,
      "logps/chosen": -98.50144958496094,
      "logps/rejected": -116.24337768554688,
      "loss": 0.0529,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.432115077972412,
      "rewards/margins": 3.1032509803771973,
      "rewards/rejected": -0.6711357235908508,
      "step": 633
    },
    {
      "epoch": 0.2536,
      "grad_norm": 9.856761932373047,
      "learning_rate": 9.156e-07,
      "logits/chosen": -1.7190887928009033,
      "logits/rejected": -2.466355800628662,
      "logps/chosen": -83.59065246582031,
      "logps/rejected": -126.86363220214844,
      "loss": 0.2244,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0320518016815186,
      "rewards/margins": 1.7948377132415771,
      "rewards/rejected": -0.7627857327461243,
      "step": 634
    },
    {
      "epoch": 0.254,
      "grad_norm": 3.278820753097534,
      "learning_rate": 9.154666666666667e-07,
      "logits/chosen": -1.9428156614303589,
      "logits/rejected": -2.3831334114074707,
      "logps/chosen": -85.6966552734375,
      "logps/rejected": -91.93339538574219,
      "loss": 0.0562,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1490349769592285,
      "rewards/margins": 3.0333542823791504,
      "rewards/rejected": -0.8843193054199219,
      "step": 635
    },
    {
      "epoch": 0.2544,
      "grad_norm": 4.9757819175720215,
      "learning_rate": 9.153333333333332e-07,
      "logits/chosen": -2.593398332595825,
      "logits/rejected": -2.4093992710113525,
      "logps/chosen": -182.8833770751953,
      "logps/rejected": -188.8056640625,
      "loss": 0.0665,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.34392249584198,
      "rewards/margins": 2.978208065032959,
      "rewards/rejected": -1.6342856884002686,
      "step": 636
    },
    {
      "epoch": 0.2548,
      "grad_norm": 5.479861259460449,
      "learning_rate": 9.151999999999999e-07,
      "logits/chosen": -2.029139757156372,
      "logits/rejected": -2.738028049468994,
      "logps/chosen": -122.44214630126953,
      "logps/rejected": -121.04122924804688,
      "loss": 0.1765,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2165435552597046,
      "rewards/margins": 1.7535511255264282,
      "rewards/rejected": -0.5370075106620789,
      "step": 637
    },
    {
      "epoch": 0.2552,
      "grad_norm": 2.6797831058502197,
      "learning_rate": 9.150666666666666e-07,
      "logits/chosen": -2.4800291061401367,
      "logits/rejected": -2.6440541744232178,
      "logps/chosen": -120.71875,
      "logps/rejected": -93.04219055175781,
      "loss": 0.0572,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6608989238739014,
      "rewards/margins": 2.9030425548553467,
      "rewards/rejected": -0.2421436309814453,
      "step": 638
    },
    {
      "epoch": 0.2556,
      "grad_norm": 5.948469638824463,
      "learning_rate": 9.149333333333333e-07,
      "logits/chosen": -1.9257464408874512,
      "logits/rejected": -2.301483154296875,
      "logps/chosen": -98.64579010009766,
      "logps/rejected": -100.60517883300781,
      "loss": 0.1576,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2904279232025146,
      "rewards/margins": 2.2689123153686523,
      "rewards/rejected": 0.021515652537345886,
      "step": 639
    },
    {
      "epoch": 0.256,
      "grad_norm": 2.951962947845459,
      "learning_rate": 9.147999999999999e-07,
      "logits/chosen": -2.1346874237060547,
      "logits/rejected": -1.9719233512878418,
      "logps/chosen": -111.85379028320312,
      "logps/rejected": -111.41073608398438,
      "loss": 0.052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.183615207672119,
      "rewards/margins": 3.127419948577881,
      "rewards/rejected": -0.9438049793243408,
      "step": 640
    },
    {
      "epoch": 0.2564,
      "grad_norm": 1.4520378112792969,
      "learning_rate": 9.146666666666666e-07,
      "logits/chosen": -2.6491494178771973,
      "logits/rejected": -2.951993942260742,
      "logps/chosen": -165.86827087402344,
      "logps/rejected": -145.5135498046875,
      "loss": 0.0212,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.951367139816284,
      "rewards/margins": 3.849713087081909,
      "rewards/rejected": -0.898345947265625,
      "step": 641
    },
    {
      "epoch": 0.2568,
      "grad_norm": 4.344520568847656,
      "learning_rate": 9.145333333333333e-07,
      "logits/chosen": -1.6574347019195557,
      "logits/rejected": -2.563598155975342,
      "logps/chosen": -91.97959899902344,
      "logps/rejected": -106.73517608642578,
      "loss": 0.1117,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4052006006240845,
      "rewards/margins": 2.289746046066284,
      "rewards/rejected": -0.8845455646514893,
      "step": 642
    },
    {
      "epoch": 0.2572,
      "grad_norm": 7.065405368804932,
      "learning_rate": 9.144e-07,
      "logits/chosen": -2.333543539047241,
      "logits/rejected": -2.1804773807525635,
      "logps/chosen": -100.03074645996094,
      "logps/rejected": -106.16514587402344,
      "loss": 0.1151,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6831119060516357,
      "rewards/margins": 2.269943952560425,
      "rewards/rejected": -0.5868320465087891,
      "step": 643
    },
    {
      "epoch": 0.2576,
      "grad_norm": 6.603237628936768,
      "learning_rate": 9.142666666666667e-07,
      "logits/chosen": -2.005920171737671,
      "logits/rejected": -2.1309168338775635,
      "logps/chosen": -94.166748046875,
      "logps/rejected": -89.30760955810547,
      "loss": 0.1028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9826807975769043,
      "rewards/margins": 2.6064693927764893,
      "rewards/rejected": -0.6237884759902954,
      "step": 644
    },
    {
      "epoch": 0.258,
      "grad_norm": 2.7952585220336914,
      "learning_rate": 9.141333333333333e-07,
      "logits/chosen": -1.5953776836395264,
      "logits/rejected": -2.9921679496765137,
      "logps/chosen": -120.91213989257812,
      "logps/rejected": -128.52857971191406,
      "loss": 0.0524,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.568727970123291,
      "rewards/margins": 3.2037854194641113,
      "rewards/rejected": -0.6350574493408203,
      "step": 645
    },
    {
      "epoch": 0.2584,
      "grad_norm": 4.501978874206543,
      "learning_rate": 9.14e-07,
      "logits/chosen": -1.9920580387115479,
      "logits/rejected": -3.1762685775756836,
      "logps/chosen": -172.05557250976562,
      "logps/rejected": -178.21726989746094,
      "loss": 0.065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9548240900039673,
      "rewards/margins": 2.843935489654541,
      "rewards/rejected": -0.8891113996505737,
      "step": 646
    },
    {
      "epoch": 0.2588,
      "grad_norm": 6.055637359619141,
      "learning_rate": 9.138666666666666e-07,
      "logits/chosen": -2.128467321395874,
      "logits/rejected": -2.7891697883605957,
      "logps/chosen": -97.78475952148438,
      "logps/rejected": -79.19200134277344,
      "loss": 0.1017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4462718963623047,
      "rewards/margins": 2.2535452842712402,
      "rewards/rejected": 0.1927265226840973,
      "step": 647
    },
    {
      "epoch": 0.2592,
      "grad_norm": 2.61346435546875,
      "learning_rate": 9.137333333333332e-07,
      "logits/chosen": -2.1622917652130127,
      "logits/rejected": -1.5987831354141235,
      "logps/chosen": -158.40487670898438,
      "logps/rejected": -86.8759536743164,
      "loss": 0.0423,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.727529287338257,
      "rewards/margins": 3.3359060287475586,
      "rewards/rejected": -0.6083767414093018,
      "step": 648
    },
    {
      "epoch": 0.2596,
      "grad_norm": 4.251710414886475,
      "learning_rate": 9.135999999999999e-07,
      "logits/chosen": -2.3999063968658447,
      "logits/rejected": -2.793610095977783,
      "logps/chosen": -118.791259765625,
      "logps/rejected": -112.33242797851562,
      "loss": 0.067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.338296413421631,
      "rewards/margins": 3.040872097015381,
      "rewards/rejected": -0.70257568359375,
      "step": 649
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.4628846645355225,
      "learning_rate": 9.134666666666666e-07,
      "logits/chosen": -2.1673269271850586,
      "logits/rejected": -1.9629733562469482,
      "logps/chosen": -144.6033477783203,
      "logps/rejected": -84.50051879882812,
      "loss": 0.0404,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.625413656234741,
      "rewards/margins": 3.2004313468933105,
      "rewards/rejected": -0.5750175714492798,
      "step": 650
    },
    {
      "epoch": 0.2604,
      "grad_norm": 2.813429355621338,
      "learning_rate": 9.133333333333333e-07,
      "logits/chosen": -1.9240422248840332,
      "logits/rejected": -2.7454988956451416,
      "logps/chosen": -129.96932983398438,
      "logps/rejected": -120.92296600341797,
      "loss": 0.0551,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2601916790008545,
      "rewards/margins": 2.93778657913208,
      "rewards/rejected": -0.677594780921936,
      "step": 651
    },
    {
      "epoch": 0.2608,
      "grad_norm": 2.035322427749634,
      "learning_rate": 9.132e-07,
      "logits/chosen": -2.1208510398864746,
      "logits/rejected": -2.2722296714782715,
      "logps/chosen": -111.75753021240234,
      "logps/rejected": -116.72166442871094,
      "loss": 0.0334,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.467906951904297,
      "rewards/margins": 3.3830649852752686,
      "rewards/rejected": -0.9151580333709717,
      "step": 652
    },
    {
      "epoch": 0.2612,
      "grad_norm": 4.571382999420166,
      "learning_rate": 9.130666666666667e-07,
      "logits/chosen": -2.476959228515625,
      "logits/rejected": -1.9766845703125,
      "logps/chosen": -109.01823425292969,
      "logps/rejected": -91.74859619140625,
      "loss": 0.1031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.037296772003174,
      "rewards/margins": 2.304036855697632,
      "rewards/rejected": -0.2667400538921356,
      "step": 653
    },
    {
      "epoch": 0.2616,
      "grad_norm": 4.659188747406006,
      "learning_rate": 9.129333333333334e-07,
      "logits/chosen": -2.4615092277526855,
      "logits/rejected": -2.5207395553588867,
      "logps/chosen": -126.23793029785156,
      "logps/rejected": -93.65419006347656,
      "loss": 0.0893,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.512636661529541,
      "rewards/margins": 3.0339417457580566,
      "rewards/rejected": -0.5213050842285156,
      "step": 654
    },
    {
      "epoch": 0.262,
      "grad_norm": 3.9765820503234863,
      "learning_rate": 9.127999999999999e-07,
      "logits/chosen": -1.9224023818969727,
      "logits/rejected": -2.5693345069885254,
      "logps/chosen": -155.72650146484375,
      "logps/rejected": -179.90684509277344,
      "loss": 0.0623,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1692519187927246,
      "rewards/margins": 2.796952724456787,
      "rewards/rejected": -0.6277008056640625,
      "step": 655
    },
    {
      "epoch": 0.2624,
      "grad_norm": 2.6814534664154053,
      "learning_rate": 9.126666666666666e-07,
      "logits/chosen": -2.1433987617492676,
      "logits/rejected": -2.441004753112793,
      "logps/chosen": -138.41949462890625,
      "logps/rejected": -118.01567077636719,
      "loss": 0.0466,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8745094537734985,
      "rewards/margins": 3.0494816303253174,
      "rewards/rejected": -1.1749721765518188,
      "step": 656
    },
    {
      "epoch": 0.2628,
      "grad_norm": 1.227753758430481,
      "learning_rate": 9.125333333333332e-07,
      "logits/chosen": -2.5131564140319824,
      "logits/rejected": -2.200596809387207,
      "logps/chosen": -142.93563842773438,
      "logps/rejected": -122.82645416259766,
      "loss": 0.0222,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.949624538421631,
      "rewards/margins": 3.8632583618164062,
      "rewards/rejected": -0.9136337041854858,
      "step": 657
    },
    {
      "epoch": 0.2632,
      "grad_norm": 2.2534425258636475,
      "learning_rate": 9.123999999999999e-07,
      "logits/chosen": -1.6866905689239502,
      "logits/rejected": -2.1100845336914062,
      "logps/chosen": -76.25530242919922,
      "logps/rejected": -104.33982849121094,
      "loss": 0.0475,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5470433235168457,
      "rewards/margins": 3.0292482376098633,
      "rewards/rejected": -0.4822048544883728,
      "step": 658
    },
    {
      "epoch": 0.2636,
      "grad_norm": 1.2392001152038574,
      "learning_rate": 9.122666666666666e-07,
      "logits/chosen": -2.2874796390533447,
      "logits/rejected": -2.3900489807128906,
      "logps/chosen": -180.99984741210938,
      "logps/rejected": -194.3689727783203,
      "loss": 0.0179,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.330059051513672,
      "rewards/margins": 4.1386308670043945,
      "rewards/rejected": -0.8085718154907227,
      "step": 659
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.625062108039856,
      "learning_rate": 9.121333333333333e-07,
      "logits/chosen": -2.3233389854431152,
      "logits/rejected": -3.061715602874756,
      "logps/chosen": -191.6136016845703,
      "logps/rejected": -125.26553344726562,
      "loss": 0.0096,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.39815616607666,
      "rewards/margins": 4.773125648498535,
      "rewards/rejected": -1.3749698400497437,
      "step": 660
    },
    {
      "epoch": 0.2644,
      "grad_norm": 6.260097503662109,
      "learning_rate": 9.12e-07,
      "logits/chosen": -1.840411901473999,
      "logits/rejected": -2.495509147644043,
      "logps/chosen": -89.62991333007812,
      "logps/rejected": -126.14179229736328,
      "loss": 0.1073,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2781877517700195,
      "rewards/margins": 2.3562660217285156,
      "rewards/rejected": -0.07807847857475281,
      "step": 661
    },
    {
      "epoch": 0.2648,
      "grad_norm": 4.737067222595215,
      "learning_rate": 9.118666666666667e-07,
      "logits/chosen": -1.9632641077041626,
      "logits/rejected": -2.082942008972168,
      "logps/chosen": -149.10818481445312,
      "logps/rejected": -93.7806167602539,
      "loss": 0.0612,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.039891242980957,
      "rewards/margins": 3.7278213500976562,
      "rewards/rejected": -0.6879302859306335,
      "step": 662
    },
    {
      "epoch": 0.2652,
      "grad_norm": 4.154921531677246,
      "learning_rate": 9.117333333333333e-07,
      "logits/chosen": -2.5149223804473877,
      "logits/rejected": -2.2163515090942383,
      "logps/chosen": -115.46180725097656,
      "logps/rejected": -91.33511352539062,
      "loss": 0.0875,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.675013542175293,
      "rewards/margins": 2.4699411392211914,
      "rewards/rejected": 0.20507241785526276,
      "step": 663
    },
    {
      "epoch": 0.2656,
      "grad_norm": 4.725563049316406,
      "learning_rate": 9.115999999999999e-07,
      "logits/chosen": -1.8103420734405518,
      "logits/rejected": -2.505194664001465,
      "logps/chosen": -79.84246826171875,
      "logps/rejected": -81.76876831054688,
      "loss": 0.0928,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.932121992111206,
      "rewards/margins": 2.3693878650665283,
      "rewards/rejected": -0.4372657835483551,
      "step": 664
    },
    {
      "epoch": 0.266,
      "grad_norm": 1.0180751085281372,
      "learning_rate": 9.114666666666666e-07,
      "logits/chosen": -1.9909167289733887,
      "logits/rejected": -2.098916530609131,
      "logps/chosen": -114.28233337402344,
      "logps/rejected": -119.86067199707031,
      "loss": 0.0171,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0563483238220215,
      "rewards/margins": 4.097560405731201,
      "rewards/rejected": -1.0412120819091797,
      "step": 665
    },
    {
      "epoch": 0.2664,
      "grad_norm": 1.611797571182251,
      "learning_rate": 9.113333333333333e-07,
      "logits/chosen": -2.1398606300354004,
      "logits/rejected": -2.4473540782928467,
      "logps/chosen": -190.47613525390625,
      "logps/rejected": -99.43647003173828,
      "loss": 0.0248,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7068839073181152,
      "rewards/margins": 3.8100461959838867,
      "rewards/rejected": -1.1031620502471924,
      "step": 666
    },
    {
      "epoch": 0.2668,
      "grad_norm": 4.74930477142334,
      "learning_rate": 9.112e-07,
      "logits/chosen": -2.239687442779541,
      "logits/rejected": -2.532036781311035,
      "logps/chosen": -108.57333374023438,
      "logps/rejected": -100.15486145019531,
      "loss": 0.1054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8207318782806396,
      "rewards/margins": 2.1964008808135986,
      "rewards/rejected": -0.37566912174224854,
      "step": 667
    },
    {
      "epoch": 0.2672,
      "grad_norm": 3.7634103298187256,
      "learning_rate": 9.110666666666666e-07,
      "logits/chosen": -2.000108242034912,
      "logits/rejected": -2.2977075576782227,
      "logps/chosen": -101.85896301269531,
      "logps/rejected": -123.23554992675781,
      "loss": 0.0528,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2741751670837402,
      "rewards/margins": 3.081704616546631,
      "rewards/rejected": -0.8075294494628906,
      "step": 668
    },
    {
      "epoch": 0.2676,
      "grad_norm": 1.801719307899475,
      "learning_rate": 9.109333333333333e-07,
      "logits/chosen": -2.5175607204437256,
      "logits/rejected": -2.79771089553833,
      "logps/chosen": -119.07755279541016,
      "logps/rejected": -178.95782470703125,
      "loss": 0.0233,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9845192432403564,
      "rewards/margins": 3.8760979175567627,
      "rewards/rejected": -0.8915786743164062,
      "step": 669
    },
    {
      "epoch": 0.268,
      "grad_norm": 4.0733137130737305,
      "learning_rate": 9.108e-07,
      "logits/chosen": -2.2461166381835938,
      "logits/rejected": -3.030999183654785,
      "logps/chosen": -151.25814819335938,
      "logps/rejected": -107.90272521972656,
      "loss": 0.0752,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.79917049407959,
      "rewards/margins": 2.9858810901641846,
      "rewards/rejected": -0.18671073019504547,
      "step": 670
    },
    {
      "epoch": 0.2684,
      "grad_norm": 0.9375492334365845,
      "learning_rate": 9.106666666666666e-07,
      "logits/chosen": -2.136272668838501,
      "logits/rejected": -2.239959239959717,
      "logps/chosen": -126.152099609375,
      "logps/rejected": -115.1767578125,
      "loss": 0.0204,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.702495574951172,
      "rewards/margins": 3.9432570934295654,
      "rewards/rejected": -1.2407615184783936,
      "step": 671
    },
    {
      "epoch": 0.2688,
      "grad_norm": 2.8299942016601562,
      "learning_rate": 9.105333333333333e-07,
      "logits/chosen": -1.8512637615203857,
      "logits/rejected": -1.8943030834197998,
      "logps/chosen": -105.47193908691406,
      "logps/rejected": -91.88406372070312,
      "loss": 0.035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5725646018981934,
      "rewards/margins": 4.007025241851807,
      "rewards/rejected": -1.4344605207443237,
      "step": 672
    },
    {
      "epoch": 0.2692,
      "grad_norm": 2.253965139389038,
      "learning_rate": 9.103999999999999e-07,
      "logits/chosen": -2.1878104209899902,
      "logits/rejected": -2.6938562393188477,
      "logps/chosen": -121.34249877929688,
      "logps/rejected": -114.95521545410156,
      "loss": 0.0418,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.316411256790161,
      "rewards/margins": 3.1791863441467285,
      "rewards/rejected": -0.8627750873565674,
      "step": 673
    },
    {
      "epoch": 0.2696,
      "grad_norm": 1.8182103633880615,
      "learning_rate": 9.102666666666666e-07,
      "logits/chosen": -2.154306411743164,
      "logits/rejected": -2.487062692642212,
      "logps/chosen": -118.20606994628906,
      "logps/rejected": -114.1349868774414,
      "loss": 0.0335,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.689612865447998,
      "rewards/margins": 3.710282802581787,
      "rewards/rejected": -1.020669937133789,
      "step": 674
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.447295665740967,
      "learning_rate": 9.101333333333333e-07,
      "logits/chosen": -1.9368700981140137,
      "logits/rejected": -1.800550937652588,
      "logps/chosen": -62.08528518676758,
      "logps/rejected": -86.57322692871094,
      "loss": 0.0766,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7975716590881348,
      "rewards/margins": 2.842895030975342,
      "rewards/rejected": -1.0453236103057861,
      "step": 675
    },
    {
      "epoch": 0.2704,
      "grad_norm": 3.9969985485076904,
      "learning_rate": 9.1e-07,
      "logits/chosen": -2.675591468811035,
      "logits/rejected": -2.964029550552368,
      "logps/chosen": -102.57295227050781,
      "logps/rejected": -113.34738159179688,
      "loss": 0.0667,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4312143325805664,
      "rewards/margins": 3.49800968170166,
      "rewards/rejected": -1.0667953491210938,
      "step": 676
    },
    {
      "epoch": 0.2708,
      "grad_norm": 8.511209487915039,
      "learning_rate": 9.098666666666667e-07,
      "logits/chosen": -2.3348324298858643,
      "logits/rejected": -2.8126614093780518,
      "logps/chosen": -150.8041534423828,
      "logps/rejected": -145.87220764160156,
      "loss": 0.1335,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.228490114212036,
      "rewards/margins": 2.7405972480773926,
      "rewards/rejected": -0.5121070742607117,
      "step": 677
    },
    {
      "epoch": 0.2712,
      "grad_norm": 3.5089333057403564,
      "learning_rate": 9.097333333333332e-07,
      "logits/chosen": -2.091057538986206,
      "logits/rejected": -2.476940631866455,
      "logps/chosen": -115.14058685302734,
      "logps/rejected": -128.09002685546875,
      "loss": 0.0603,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3708252906799316,
      "rewards/margins": 2.8318190574645996,
      "rewards/rejected": -1.460994005203247,
      "step": 678
    },
    {
      "epoch": 0.2716,
      "grad_norm": 3.380591630935669,
      "learning_rate": 9.095999999999999e-07,
      "logits/chosen": -2.1161789894104004,
      "logits/rejected": -2.219529151916504,
      "logps/chosen": -172.34298706054688,
      "logps/rejected": -105.7918701171875,
      "loss": 0.0562,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3710079193115234,
      "rewards/margins": 3.7196168899536133,
      "rewards/rejected": -1.3486088514328003,
      "step": 679
    },
    {
      "epoch": 0.272,
      "grad_norm": 3.961294412612915,
      "learning_rate": 9.094666666666666e-07,
      "logits/chosen": -1.8428101539611816,
      "logits/rejected": -2.0523838996887207,
      "logps/chosen": -140.20343017578125,
      "logps/rejected": -96.31861877441406,
      "loss": 0.0754,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.312382459640503,
      "rewards/margins": 2.9640450477600098,
      "rewards/rejected": -0.6516624689102173,
      "step": 680
    },
    {
      "epoch": 0.2724,
      "grad_norm": 2.8804285526275635,
      "learning_rate": 9.093333333333333e-07,
      "logits/chosen": -2.5130484104156494,
      "logits/rejected": -2.5615038871765137,
      "logps/chosen": -146.12490844726562,
      "logps/rejected": -101.67068481445312,
      "loss": 0.0479,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4819436073303223,
      "rewards/margins": 3.066345691680908,
      "rewards/rejected": -0.5844020843505859,
      "step": 681
    },
    {
      "epoch": 0.2728,
      "grad_norm": 0.9237185120582581,
      "learning_rate": 9.092e-07,
      "logits/chosen": -2.3986005783081055,
      "logits/rejected": -3.9616618156433105,
      "logps/chosen": -120.57514953613281,
      "logps/rejected": -151.72943115234375,
      "loss": 0.0152,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7460358142852783,
      "rewards/margins": 4.3620100021362305,
      "rewards/rejected": -1.6159744262695312,
      "step": 682
    },
    {
      "epoch": 0.2732,
      "grad_norm": 2.61718487739563,
      "learning_rate": 9.090666666666666e-07,
      "logits/chosen": -2.5265989303588867,
      "logits/rejected": -2.185500383377075,
      "logps/chosen": -106.39381408691406,
      "logps/rejected": -91.10379028320312,
      "loss": 0.0537,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7782669067382812,
      "rewards/margins": 2.973410129547119,
      "rewards/rejected": -0.19514313340187073,
      "step": 683
    },
    {
      "epoch": 0.2736,
      "grad_norm": 5.393703460693359,
      "learning_rate": 9.089333333333333e-07,
      "logits/chosen": -2.0729644298553467,
      "logits/rejected": -2.710751533508301,
      "logps/chosen": -115.59335327148438,
      "logps/rejected": -108.46546936035156,
      "loss": 0.0968,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4310723543167114,
      "rewards/margins": 2.58748722076416,
      "rewards/rejected": -1.1564147472381592,
      "step": 684
    },
    {
      "epoch": 0.274,
      "grad_norm": 7.280807018280029,
      "learning_rate": 9.088e-07,
      "logits/chosen": -1.7855565547943115,
      "logits/rejected": -2.466660976409912,
      "logps/chosen": -111.51449584960938,
      "logps/rejected": -186.94000244140625,
      "loss": 0.0954,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4782581329345703,
      "rewards/margins": 2.545175075531006,
      "rewards/rejected": -1.0669167041778564,
      "step": 685
    },
    {
      "epoch": 0.2744,
      "grad_norm": 2.6546971797943115,
      "learning_rate": 9.086666666666666e-07,
      "logits/chosen": -2.1623363494873047,
      "logits/rejected": -2.6208534240722656,
      "logps/chosen": -142.87228393554688,
      "logps/rejected": -117.123779296875,
      "loss": 0.0456,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.120494842529297,
      "rewards/margins": 3.1782963275909424,
      "rewards/rejected": -1.0578014850616455,
      "step": 686
    },
    {
      "epoch": 0.2748,
      "grad_norm": 1.7562819719314575,
      "learning_rate": 9.085333333333333e-07,
      "logits/chosen": -2.216831922531128,
      "logits/rejected": -2.3343491554260254,
      "logps/chosen": -154.68994140625,
      "logps/rejected": -107.7681884765625,
      "loss": 0.0282,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0589394569396973,
      "rewards/margins": 3.562202215194702,
      "rewards/rejected": -0.5032626986503601,
      "step": 687
    },
    {
      "epoch": 0.2752,
      "grad_norm": 1.0018490552902222,
      "learning_rate": 9.084e-07,
      "logits/chosen": -2.7288005352020264,
      "logits/rejected": -2.9146595001220703,
      "logps/chosen": -188.252685546875,
      "logps/rejected": -140.36557006835938,
      "loss": 0.0143,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1311559677124023,
      "rewards/margins": 4.3426055908203125,
      "rewards/rejected": -1.2114498615264893,
      "step": 688
    },
    {
      "epoch": 0.2756,
      "grad_norm": 4.997928619384766,
      "learning_rate": 9.082666666666666e-07,
      "logits/chosen": -2.357656717300415,
      "logits/rejected": -2.511890411376953,
      "logps/chosen": -160.33779907226562,
      "logps/rejected": -119.73135375976562,
      "loss": 0.0978,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0221991539001465,
      "rewards/margins": 2.7109973430633545,
      "rewards/rejected": -0.6887981295585632,
      "step": 689
    },
    {
      "epoch": 0.276,
      "grad_norm": 3.638631582260132,
      "learning_rate": 9.081333333333333e-07,
      "logits/chosen": -2.29526424407959,
      "logits/rejected": -2.9870150089263916,
      "logps/chosen": -124.8494873046875,
      "logps/rejected": -237.424560546875,
      "loss": 0.0461,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.289111614227295,
      "rewards/margins": 3.097496509552002,
      "rewards/rejected": -0.8083847165107727,
      "step": 690
    },
    {
      "epoch": 0.2764,
      "grad_norm": 1.5483884811401367,
      "learning_rate": 9.08e-07,
      "logits/chosen": -2.410339832305908,
      "logits/rejected": -2.8980937004089355,
      "logps/chosen": -167.6585693359375,
      "logps/rejected": -148.31134033203125,
      "loss": 0.027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.243488311767578,
      "rewards/margins": 3.662797212600708,
      "rewards/rejected": -0.4193088710308075,
      "step": 691
    },
    {
      "epoch": 0.2768,
      "grad_norm": 1.7064744234085083,
      "learning_rate": 9.078666666666666e-07,
      "logits/chosen": -1.6731996536254883,
      "logits/rejected": -2.550992250442505,
      "logps/chosen": -107.39697265625,
      "logps/rejected": -149.00025939941406,
      "loss": 0.0331,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8988349437713623,
      "rewards/margins": 3.400763988494873,
      "rewards/rejected": -1.5019290447235107,
      "step": 692
    },
    {
      "epoch": 0.2772,
      "grad_norm": 4.3314056396484375,
      "learning_rate": 9.077333333333332e-07,
      "logits/chosen": -2.518362283706665,
      "logits/rejected": -3.113176107406616,
      "logps/chosen": -165.25778198242188,
      "logps/rejected": -113.6509780883789,
      "loss": 0.0683,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8737298250198364,
      "rewards/margins": 3.2939281463623047,
      "rewards/rejected": -1.4201980829238892,
      "step": 693
    },
    {
      "epoch": 0.2776,
      "grad_norm": 0.8846026659011841,
      "learning_rate": 9.075999999999999e-07,
      "logits/chosen": -2.255570411682129,
      "logits/rejected": -2.4367737770080566,
      "logps/chosen": -98.72421264648438,
      "logps/rejected": -116.69699096679688,
      "loss": 0.0199,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.855330467224121,
      "rewards/margins": 3.9915919303894043,
      "rewards/rejected": -1.1362613439559937,
      "step": 694
    },
    {
      "epoch": 0.278,
      "grad_norm": 1.142778754234314,
      "learning_rate": 9.074666666666666e-07,
      "logits/chosen": -2.3776843547821045,
      "logits/rejected": -2.0968170166015625,
      "logps/chosen": -169.224609375,
      "logps/rejected": -93.4073486328125,
      "loss": 0.0246,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.571791648864746,
      "rewards/margins": 3.831056833267212,
      "rewards/rejected": -1.2592653036117554,
      "step": 695
    },
    {
      "epoch": 0.2784,
      "grad_norm": 2.472511053085327,
      "learning_rate": 9.073333333333333e-07,
      "logits/chosen": -2.067255973815918,
      "logits/rejected": -2.8361668586730957,
      "logps/chosen": -110.52415466308594,
      "logps/rejected": -123.69294738769531,
      "loss": 0.0311,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.580460786819458,
      "rewards/margins": 3.638373613357544,
      "rewards/rejected": -1.057912826538086,
      "step": 696
    },
    {
      "epoch": 0.2788,
      "grad_norm": 0.5030413269996643,
      "learning_rate": 9.072e-07,
      "logits/chosen": -2.061736583709717,
      "logits/rejected": -1.959744930267334,
      "logps/chosen": -133.75787353515625,
      "logps/rejected": -109.75362396240234,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4479877948760986,
      "rewards/margins": 5.244077682495117,
      "rewards/rejected": -1.79608952999115,
      "step": 697
    },
    {
      "epoch": 0.2792,
      "grad_norm": 5.440914154052734,
      "learning_rate": 9.070666666666667e-07,
      "logits/chosen": -2.217369794845581,
      "logits/rejected": -2.7645978927612305,
      "logps/chosen": -133.2884063720703,
      "logps/rejected": -159.9510040283203,
      "loss": 0.1031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1852924823760986,
      "rewards/margins": 3.2569878101348877,
      "rewards/rejected": -1.071695327758789,
      "step": 698
    },
    {
      "epoch": 0.2796,
      "grad_norm": 9.989261627197266,
      "learning_rate": 9.069333333333334e-07,
      "logits/chosen": -2.186359405517578,
      "logits/rejected": -2.7622969150543213,
      "logps/chosen": -125.54292297363281,
      "logps/rejected": -91.32066345214844,
      "loss": 0.1455,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0437259674072266,
      "rewards/margins": 2.395174026489258,
      "rewards/rejected": -0.35144808888435364,
      "step": 699
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.4463865756988525,
      "learning_rate": 9.068e-07,
      "logits/chosen": -2.416017770767212,
      "logits/rejected": -2.8063249588012695,
      "logps/chosen": -203.16925048828125,
      "logps/rejected": -142.60281372070312,
      "loss": 0.0265,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8033199310302734,
      "rewards/margins": 3.7575111389160156,
      "rewards/rejected": -0.9541912078857422,
      "step": 700
    },
    {
      "epoch": 0.2804,
      "grad_norm": 1.0359190702438354,
      "learning_rate": 9.066666666666665e-07,
      "logits/chosen": -2.169443130493164,
      "logits/rejected": -2.739349365234375,
      "logps/chosen": -133.46334838867188,
      "logps/rejected": -175.77127075195312,
      "loss": 0.0155,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.947505235671997,
      "rewards/margins": 4.162461280822754,
      "rewards/rejected": -1.2149559259414673,
      "step": 701
    },
    {
      "epoch": 0.2808,
      "grad_norm": 5.130861759185791,
      "learning_rate": 9.065333333333332e-07,
      "logits/chosen": -1.7484537363052368,
      "logits/rejected": -2.090744733810425,
      "logps/chosen": -139.30291748046875,
      "logps/rejected": -85.24402618408203,
      "loss": 0.1175,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5690354108810425,
      "rewards/margins": 2.2631492614746094,
      "rewards/rejected": -0.6941137909889221,
      "step": 702
    },
    {
      "epoch": 0.2812,
      "grad_norm": 17.288455963134766,
      "learning_rate": 9.063999999999999e-07,
      "logits/chosen": -1.7741893529891968,
      "logits/rejected": -2.638237476348877,
      "logps/chosen": -93.26078796386719,
      "logps/rejected": -110.4891357421875,
      "loss": 0.3359,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7890422940254211,
      "rewards/margins": 1.1135822534561157,
      "rewards/rejected": -0.3245399594306946,
      "step": 703
    },
    {
      "epoch": 0.2816,
      "grad_norm": 1.1075966358184814,
      "learning_rate": 9.062666666666666e-07,
      "logits/chosen": -2.5189599990844727,
      "logits/rejected": -2.5780982971191406,
      "logps/chosen": -141.595458984375,
      "logps/rejected": -137.22235107421875,
      "loss": 0.0158,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2632498741149902,
      "rewards/margins": 4.139703750610352,
      "rewards/rejected": -0.8764537572860718,
      "step": 704
    },
    {
      "epoch": 0.282,
      "grad_norm": 2.4032938480377197,
      "learning_rate": 9.061333333333333e-07,
      "logits/chosen": -2.114861249923706,
      "logits/rejected": -2.4898624420166016,
      "logps/chosen": -111.38890075683594,
      "logps/rejected": -101.10686492919922,
      "loss": 0.0594,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.689931869506836,
      "rewards/margins": 2.815877914428711,
      "rewards/rejected": -1.125946044921875,
      "step": 705
    },
    {
      "epoch": 0.2824,
      "grad_norm": 5.115031719207764,
      "learning_rate": 9.06e-07,
      "logits/chosen": -2.285315752029419,
      "logits/rejected": -3.04237699508667,
      "logps/chosen": -128.91091918945312,
      "logps/rejected": -111.41766357421875,
      "loss": 0.0656,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9194157123565674,
      "rewards/margins": 2.9103543758392334,
      "rewards/rejected": -0.9909386038780212,
      "step": 706
    },
    {
      "epoch": 0.2828,
      "grad_norm": 2.706799268722534,
      "learning_rate": 9.058666666666667e-07,
      "logits/chosen": -2.126347541809082,
      "logits/rejected": -2.2493839263916016,
      "logps/chosen": -106.01085662841797,
      "logps/rejected": -131.20828247070312,
      "loss": 0.036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4623019695281982,
      "rewards/margins": 4.053959846496582,
      "rewards/rejected": -1.591658115386963,
      "step": 707
    },
    {
      "epoch": 0.2832,
      "grad_norm": 2.459059953689575,
      "learning_rate": 9.057333333333333e-07,
      "logits/chosen": -2.168837785720825,
      "logits/rejected": -2.3620994091033936,
      "logps/chosen": -122.36197662353516,
      "logps/rejected": -99.30758666992188,
      "loss": 0.0319,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0177712440490723,
      "rewards/margins": 3.8519043922424316,
      "rewards/rejected": -0.8341332077980042,
      "step": 708
    },
    {
      "epoch": 0.2836,
      "grad_norm": 3.9389822483062744,
      "learning_rate": 9.056e-07,
      "logits/chosen": -2.638233184814453,
      "logits/rejected": -2.368373394012451,
      "logps/chosen": -184.72738647460938,
      "logps/rejected": -121.1895751953125,
      "loss": 0.0666,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.024510145187378,
      "rewards/margins": 2.769768714904785,
      "rewards/rejected": -0.7452583312988281,
      "step": 709
    },
    {
      "epoch": 0.284,
      "grad_norm": 7.482361316680908,
      "learning_rate": 9.054666666666666e-07,
      "logits/chosen": -2.127319812774658,
      "logits/rejected": -2.2688112258911133,
      "logps/chosen": -124.47003936767578,
      "logps/rejected": -103.56033325195312,
      "loss": 0.1267,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2552640438079834,
      "rewards/margins": 2.6129980087280273,
      "rewards/rejected": -0.35773393511772156,
      "step": 710
    },
    {
      "epoch": 0.2844,
      "grad_norm": 1.8704215288162231,
      "learning_rate": 9.053333333333332e-07,
      "logits/chosen": -1.59938645362854,
      "logits/rejected": -1.9502882957458496,
      "logps/chosen": -86.23334503173828,
      "logps/rejected": -99.48023223876953,
      "loss": 0.0375,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.912318229675293,
      "rewards/margins": 3.78920578956604,
      "rewards/rejected": -0.8768875598907471,
      "step": 711
    },
    {
      "epoch": 0.2848,
      "grad_norm": 5.774497985839844,
      "learning_rate": 9.051999999999999e-07,
      "logits/chosen": -2.161914587020874,
      "logits/rejected": -2.7039270401000977,
      "logps/chosen": -131.48712158203125,
      "logps/rejected": -122.67481994628906,
      "loss": 0.0895,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7677910327911377,
      "rewards/margins": 2.8226373195648193,
      "rewards/rejected": -1.0548462867736816,
      "step": 712
    },
    {
      "epoch": 0.2852,
      "grad_norm": 2.2346787452697754,
      "learning_rate": 9.050666666666666e-07,
      "logits/chosen": -2.525317668914795,
      "logits/rejected": -1.5654237270355225,
      "logps/chosen": -171.7447967529297,
      "logps/rejected": -115.47383117675781,
      "loss": 0.0394,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5832629203796387,
      "rewards/margins": 3.5661139488220215,
      "rewards/rejected": 0.017148971557617188,
      "step": 713
    },
    {
      "epoch": 0.2856,
      "grad_norm": 4.082427024841309,
      "learning_rate": 9.049333333333333e-07,
      "logits/chosen": -1.9944519996643066,
      "logits/rejected": -2.8272178173065186,
      "logps/chosen": -121.58467864990234,
      "logps/rejected": -107.32672119140625,
      "loss": 0.0736,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.137239933013916,
      "rewards/margins": 2.641786575317383,
      "rewards/rejected": -0.5045467615127563,
      "step": 714
    },
    {
      "epoch": 0.286,
      "grad_norm": 0.723056435585022,
      "learning_rate": 9.048e-07,
      "logits/chosen": -2.503063201904297,
      "logits/rejected": -3.1876220703125,
      "logps/chosen": -143.3983154296875,
      "logps/rejected": -128.57920837402344,
      "loss": 0.0104,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.243669033050537,
      "rewards/margins": 4.605350494384766,
      "rewards/rejected": -1.3616809844970703,
      "step": 715
    },
    {
      "epoch": 0.2864,
      "grad_norm": 0.8177483081817627,
      "learning_rate": 9.046666666666666e-07,
      "logits/chosen": -2.110382556915283,
      "logits/rejected": -2.275439977645874,
      "logps/chosen": -125.21782684326172,
      "logps/rejected": -121.87430572509766,
      "loss": 0.0142,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.089587450027466,
      "rewards/margins": 4.274784564971924,
      "rewards/rejected": -1.185197114944458,
      "step": 716
    },
    {
      "epoch": 0.2868,
      "grad_norm": 1.6958924531936646,
      "learning_rate": 9.045333333333333e-07,
      "logits/chosen": -1.949837565422058,
      "logits/rejected": -2.5709266662597656,
      "logps/chosen": -73.17947387695312,
      "logps/rejected": -130.2543182373047,
      "loss": 0.0294,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.709179401397705,
      "rewards/margins": 3.540188789367676,
      "rewards/rejected": -0.8310093283653259,
      "step": 717
    },
    {
      "epoch": 0.2872,
      "grad_norm": 4.653999328613281,
      "learning_rate": 9.044e-07,
      "logits/chosen": -2.126430034637451,
      "logits/rejected": -2.507523536682129,
      "logps/chosen": -136.89865112304688,
      "logps/rejected": -90.82069396972656,
      "loss": 0.078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.578759789466858,
      "rewards/margins": 2.5154716968536377,
      "rewards/rejected": -0.9367119073867798,
      "step": 718
    },
    {
      "epoch": 0.2876,
      "grad_norm": 0.9006991386413574,
      "learning_rate": 9.042666666666667e-07,
      "logits/chosen": -2.4581491947174072,
      "logits/rejected": -3.022947311401367,
      "logps/chosen": -115.98406982421875,
      "logps/rejected": -126.71258544921875,
      "loss": 0.0159,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.912796974182129,
      "rewards/margins": 4.256859302520752,
      "rewards/rejected": -1.3440624475479126,
      "step": 719
    },
    {
      "epoch": 0.288,
      "grad_norm": 2.081514596939087,
      "learning_rate": 9.041333333333334e-07,
      "logits/chosen": -2.17229962348938,
      "logits/rejected": -2.412550449371338,
      "logps/chosen": -160.4269256591797,
      "logps/rejected": -114.46723937988281,
      "loss": 0.0337,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6066031455993652,
      "rewards/margins": 3.5370032787323,
      "rewards/rejected": -0.9304001331329346,
      "step": 720
    },
    {
      "epoch": 0.2884,
      "grad_norm": 1.8438290357589722,
      "learning_rate": 9.039999999999999e-07,
      "logits/chosen": -2.2387900352478027,
      "logits/rejected": -2.6363892555236816,
      "logps/chosen": -179.48861694335938,
      "logps/rejected": -116.30148315429688,
      "loss": 0.0245,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.369387149810791,
      "rewards/margins": 3.7642900943756104,
      "rewards/rejected": -1.3949028253555298,
      "step": 721
    },
    {
      "epoch": 0.2888,
      "grad_norm": 2.9005794525146484,
      "learning_rate": 9.038666666666666e-07,
      "logits/chosen": -2.3339664936065674,
      "logits/rejected": -2.1413326263427734,
      "logps/chosen": -119.53900146484375,
      "logps/rejected": -120.08074951171875,
      "loss": 0.0612,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6890385150909424,
      "rewards/margins": 3.2698116302490234,
      "rewards/rejected": -0.5807732343673706,
      "step": 722
    },
    {
      "epoch": 0.2892,
      "grad_norm": 1.4367810487747192,
      "learning_rate": 9.037333333333333e-07,
      "logits/chosen": -2.3146250247955322,
      "logits/rejected": -2.225048065185547,
      "logps/chosen": -108.14129638671875,
      "logps/rejected": -113.10029602050781,
      "loss": 0.0266,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5839996337890625,
      "rewards/margins": 3.6192848682403564,
      "rewards/rejected": -1.035285234451294,
      "step": 723
    },
    {
      "epoch": 0.2896,
      "grad_norm": 3.4309446811676025,
      "learning_rate": 9.035999999999999e-07,
      "logits/chosen": -2.2663955688476562,
      "logits/rejected": -2.420382261276245,
      "logps/chosen": -95.32463836669922,
      "logps/rejected": -116.83100891113281,
      "loss": 0.0532,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5904436111450195,
      "rewards/margins": 3.6232099533081055,
      "rewards/rejected": -1.032766342163086,
      "step": 724
    },
    {
      "epoch": 0.29,
      "grad_norm": 5.8699493408203125,
      "learning_rate": 9.034666666666666e-07,
      "logits/chosen": -2.030355453491211,
      "logits/rejected": -2.565328598022461,
      "logps/chosen": -80.6592788696289,
      "logps/rejected": -96.35013580322266,
      "loss": 0.0872,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.320810317993164,
      "rewards/margins": 2.994145154953003,
      "rewards/rejected": -0.6733348965644836,
      "step": 725
    },
    {
      "epoch": 0.2904,
      "grad_norm": 1.300604224205017,
      "learning_rate": 9.033333333333333e-07,
      "logits/chosen": -2.0951614379882812,
      "logits/rejected": -2.255030393600464,
      "logps/chosen": -108.65072631835938,
      "logps/rejected": -114.17637634277344,
      "loss": 0.0262,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.00056791305542,
      "rewards/margins": 3.6303744316101074,
      "rewards/rejected": -0.6298065185546875,
      "step": 726
    },
    {
      "epoch": 0.2908,
      "grad_norm": 2.538127899169922,
      "learning_rate": 9.032e-07,
      "logits/chosen": -2.6278159618377686,
      "logits/rejected": -2.3845415115356445,
      "logps/chosen": -218.7396240234375,
      "logps/rejected": -178.45338439941406,
      "loss": 0.0317,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6467409133911133,
      "rewards/margins": 3.488496780395508,
      "rewards/rejected": -0.8417561054229736,
      "step": 727
    },
    {
      "epoch": 0.2912,
      "grad_norm": 9.458392143249512,
      "learning_rate": 9.030666666666667e-07,
      "logits/chosen": -2.4893436431884766,
      "logits/rejected": -2.541158437728882,
      "logps/chosen": -197.35508728027344,
      "logps/rejected": -91.67109680175781,
      "loss": 0.1791,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1917061805725098,
      "rewards/margins": 2.3555564880371094,
      "rewards/rejected": -0.16385042667388916,
      "step": 728
    },
    {
      "epoch": 0.2916,
      "grad_norm": 6.341865539550781,
      "learning_rate": 9.029333333333334e-07,
      "logits/chosen": -2.3981335163116455,
      "logits/rejected": -1.4406447410583496,
      "logps/chosen": -94.79808044433594,
      "logps/rejected": -139.24778747558594,
      "loss": 0.0847,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0449728965759277,
      "rewards/margins": 2.4567480087280273,
      "rewards/rejected": -0.41177481412887573,
      "step": 729
    },
    {
      "epoch": 0.292,
      "grad_norm": 2.6327059268951416,
      "learning_rate": 9.028e-07,
      "logits/chosen": -2.207946300506592,
      "logits/rejected": -2.8325352668762207,
      "logps/chosen": -122.00862121582031,
      "logps/rejected": -88.17446899414062,
      "loss": 0.0549,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4676856994628906,
      "rewards/margins": 2.878955125808716,
      "rewards/rejected": -0.4112693667411804,
      "step": 730
    },
    {
      "epoch": 0.2924,
      "grad_norm": 3.9424993991851807,
      "learning_rate": 9.026666666666665e-07,
      "logits/chosen": -2.0962772369384766,
      "logits/rejected": -2.3903732299804688,
      "logps/chosen": -109.74455261230469,
      "logps/rejected": -99.18121337890625,
      "loss": 0.0714,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.408454418182373,
      "rewards/margins": 3.685676097869873,
      "rewards/rejected": -1.2772216796875,
      "step": 731
    },
    {
      "epoch": 0.2928,
      "grad_norm": 2.9431469440460205,
      "learning_rate": 9.025333333333332e-07,
      "logits/chosen": -2.0941412448883057,
      "logits/rejected": -3.117659091949463,
      "logps/chosen": -73.95130157470703,
      "logps/rejected": -96.18179321289062,
      "loss": 0.0631,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.243609666824341,
      "rewards/margins": 2.732860565185547,
      "rewards/rejected": -0.48925095796585083,
      "step": 732
    },
    {
      "epoch": 0.2932,
      "grad_norm": 2.267510414123535,
      "learning_rate": 9.023999999999999e-07,
      "logits/chosen": -2.5484423637390137,
      "logits/rejected": -2.651308536529541,
      "logps/chosen": -148.60751342773438,
      "logps/rejected": -89.69355773925781,
      "loss": 0.0364,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.960160493850708,
      "rewards/margins": 3.4691805839538574,
      "rewards/rejected": -0.5090199112892151,
      "step": 733
    },
    {
      "epoch": 0.2936,
      "grad_norm": 5.489495754241943,
      "learning_rate": 9.022666666666666e-07,
      "logits/chosen": -2.0923991203308105,
      "logits/rejected": -3.5363221168518066,
      "logps/chosen": -141.00257873535156,
      "logps/rejected": -131.50112915039062,
      "loss": 0.0765,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.758420944213867,
      "rewards/margins": 3.2720863819122314,
      "rewards/rejected": -0.5136653780937195,
      "step": 734
    },
    {
      "epoch": 0.294,
      "grad_norm": 14.111071586608887,
      "learning_rate": 9.021333333333333e-07,
      "logits/chosen": -2.058048725128174,
      "logits/rejected": -2.674834728240967,
      "logps/chosen": -111.19705200195312,
      "logps/rejected": -91.43190002441406,
      "loss": 0.3233,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4733664989471436,
      "rewards/margins": 1.6079524755477905,
      "rewards/rejected": -0.13458596169948578,
      "step": 735
    },
    {
      "epoch": 0.2944,
      "grad_norm": 1.464805245399475,
      "learning_rate": 9.02e-07,
      "logits/chosen": -2.164936065673828,
      "logits/rejected": -2.3672561645507812,
      "logps/chosen": -156.35430908203125,
      "logps/rejected": -115.66307067871094,
      "loss": 0.0291,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5030479431152344,
      "rewards/margins": 3.6380550861358643,
      "rewards/rejected": -1.1350071430206299,
      "step": 736
    },
    {
      "epoch": 0.2948,
      "grad_norm": 1.1279784440994263,
      "learning_rate": 9.018666666666667e-07,
      "logits/chosen": -2.409402370452881,
      "logits/rejected": -2.253572940826416,
      "logps/chosen": -128.97740173339844,
      "logps/rejected": -77.82020568847656,
      "loss": 0.0235,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9054603576660156,
      "rewards/margins": 3.747767448425293,
      "rewards/rejected": -0.8423069715499878,
      "step": 737
    },
    {
      "epoch": 0.2952,
      "grad_norm": 1.7111448049545288,
      "learning_rate": 9.017333333333334e-07,
      "logits/chosen": -1.851823091506958,
      "logits/rejected": -2.610039234161377,
      "logps/chosen": -79.3306655883789,
      "logps/rejected": -102.29829406738281,
      "loss": 0.0276,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.026906967163086,
      "rewards/margins": 3.5815348625183105,
      "rewards/rejected": -0.5546280145645142,
      "step": 738
    },
    {
      "epoch": 0.2956,
      "grad_norm": 1.5197844505310059,
      "learning_rate": 9.015999999999999e-07,
      "logits/chosen": -2.1800851821899414,
      "logits/rejected": -2.7711076736450195,
      "logps/chosen": -126.76219177246094,
      "logps/rejected": -147.8239288330078,
      "loss": 0.0276,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6638569831848145,
      "rewards/margins": 4.098533630371094,
      "rewards/rejected": -0.4346763491630554,
      "step": 739
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.36461684107780457,
      "learning_rate": 9.014666666666666e-07,
      "logits/chosen": -2.4132637977600098,
      "logits/rejected": -2.989797830581665,
      "logps/chosen": -163.66494750976562,
      "logps/rejected": -146.10064697265625,
      "loss": 0.0057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.625277042388916,
      "rewards/margins": 5.369462490081787,
      "rewards/rejected": -1.7441856861114502,
      "step": 740
    },
    {
      "epoch": 0.2964,
      "grad_norm": 2.9841723442077637,
      "learning_rate": 9.013333333333333e-07,
      "logits/chosen": -2.625972270965576,
      "logits/rejected": -3.0662927627563477,
      "logps/chosen": -169.06796264648438,
      "logps/rejected": -139.23617553710938,
      "loss": 0.0419,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.267624616622925,
      "rewards/margins": 3.8400137424468994,
      "rewards/rejected": -1.5723892450332642,
      "step": 741
    },
    {
      "epoch": 0.2968,
      "grad_norm": 1.2449610233306885,
      "learning_rate": 9.011999999999999e-07,
      "logits/chosen": -2.386064052581787,
      "logits/rejected": -2.1300430297851562,
      "logps/chosen": -175.6629180908203,
      "logps/rejected": -124.53763580322266,
      "loss": 0.0225,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0681869983673096,
      "rewards/margins": 4.329463958740234,
      "rewards/rejected": -1.2612769603729248,
      "step": 742
    },
    {
      "epoch": 0.2972,
      "grad_norm": 1.7274221181869507,
      "learning_rate": 9.010666666666666e-07,
      "logits/chosen": -2.692204475402832,
      "logits/rejected": -2.44508957862854,
      "logps/chosen": -192.81796264648438,
      "logps/rejected": -144.3341064453125,
      "loss": 0.0209,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.944934129714966,
      "rewards/margins": 3.93615460395813,
      "rewards/rejected": -0.9912204742431641,
      "step": 743
    },
    {
      "epoch": 0.2976,
      "grad_norm": 4.792261123657227,
      "learning_rate": 9.009333333333333e-07,
      "logits/chosen": -2.4652507305145264,
      "logits/rejected": -1.8573670387268066,
      "logps/chosen": -83.6668472290039,
      "logps/rejected": -75.30508422851562,
      "loss": 0.1021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8757224082946777,
      "rewards/margins": 2.9180362224578857,
      "rewards/rejected": -0.042313769459724426,
      "step": 744
    },
    {
      "epoch": 0.298,
      "grad_norm": 6.544372081756592,
      "learning_rate": 9.008e-07,
      "logits/chosen": -2.2554497718811035,
      "logits/rejected": -2.1043338775634766,
      "logps/chosen": -141.97312927246094,
      "logps/rejected": -80.85575866699219,
      "loss": 0.12,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8876789808273315,
      "rewards/margins": 2.251924514770508,
      "rewards/rejected": -0.36424559354782104,
      "step": 745
    },
    {
      "epoch": 0.2984,
      "grad_norm": 13.212539672851562,
      "learning_rate": 9.006666666666666e-07,
      "logits/chosen": -2.253730535507202,
      "logits/rejected": -2.5087385177612305,
      "logps/chosen": -96.00276184082031,
      "logps/rejected": -90.8216552734375,
      "loss": 0.2281,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3726966381072998,
      "rewards/margins": 1.724108099937439,
      "rewards/rejected": -0.35141146183013916,
      "step": 746
    },
    {
      "epoch": 0.2988,
      "grad_norm": 3.332308292388916,
      "learning_rate": 9.005333333333333e-07,
      "logits/chosen": -1.9225456714630127,
      "logits/rejected": -2.49967360496521,
      "logps/chosen": -98.956787109375,
      "logps/rejected": -122.79792785644531,
      "loss": 0.0546,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2998533248901367,
      "rewards/margins": 3.4828295707702637,
      "rewards/rejected": -1.182976484298706,
      "step": 747
    },
    {
      "epoch": 0.2992,
      "grad_norm": 1.5349642038345337,
      "learning_rate": 9.004e-07,
      "logits/chosen": -2.740598678588867,
      "logits/rejected": -2.694929599761963,
      "logps/chosen": -132.7092742919922,
      "logps/rejected": -95.14521026611328,
      "loss": 0.0261,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.100234031677246,
      "rewards/margins": 3.7445733547210693,
      "rewards/rejected": -0.644339382648468,
      "step": 748
    },
    {
      "epoch": 0.2996,
      "grad_norm": 1.5849775075912476,
      "learning_rate": 9.002666666666666e-07,
      "logits/chosen": -2.213322162628174,
      "logits/rejected": -2.7420239448547363,
      "logps/chosen": -161.78067016601562,
      "logps/rejected": -95.01495361328125,
      "loss": 0.0195,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.533281087875366,
      "rewards/margins": 4.083387851715088,
      "rewards/rejected": -0.5501068234443665,
      "step": 749
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.7914042472839355,
      "learning_rate": 9.001333333333333e-07,
      "logits/chosen": -2.293971538543701,
      "logits/rejected": -2.3802552223205566,
      "logps/chosen": -106.54293823242188,
      "logps/rejected": -87.96089172363281,
      "loss": 0.0528,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.641663074493408,
      "rewards/margins": 2.925349235534668,
      "rewards/rejected": -0.2836860716342926,
      "step": 750
    },
    {
      "epoch": 0.3004,
      "grad_norm": 7.010635852813721,
      "learning_rate": 9e-07,
      "logits/chosen": -1.8418651819229126,
      "logits/rejected": -3.0491185188293457,
      "logps/chosen": -118.12368774414062,
      "logps/rejected": -120.17146301269531,
      "loss": 0.1375,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.058911919593811,
      "rewards/margins": 2.003293991088867,
      "rewards/rejected": -0.9443821310997009,
      "step": 751
    },
    {
      "epoch": 0.3008,
      "grad_norm": 2.524777889251709,
      "learning_rate": 8.998666666666667e-07,
      "logits/chosen": -2.453357219696045,
      "logits/rejected": -1.7770874500274658,
      "logps/chosen": -146.688232421875,
      "logps/rejected": -117.24864196777344,
      "loss": 0.0282,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.400257110595703,
      "rewards/margins": 4.19193172454834,
      "rewards/rejected": -0.7916748523712158,
      "step": 752
    },
    {
      "epoch": 0.3012,
      "grad_norm": 0.47316116094589233,
      "learning_rate": 8.997333333333333e-07,
      "logits/chosen": -2.4130859375,
      "logits/rejected": -2.952833414077759,
      "logps/chosen": -128.2381591796875,
      "logps/rejected": -146.25082397460938,
      "loss": 0.0067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4075164794921875,
      "rewards/margins": 5.007711410522461,
      "rewards/rejected": -1.6001945734024048,
      "step": 753
    },
    {
      "epoch": 0.3016,
      "grad_norm": 1.247700572013855,
      "learning_rate": 8.995999999999999e-07,
      "logits/chosen": -2.5096969604492188,
      "logits/rejected": -2.910552501678467,
      "logps/chosen": -208.79978942871094,
      "logps/rejected": -146.68115234375,
      "loss": 0.0187,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.026628017425537,
      "rewards/margins": 4.283781051635742,
      "rewards/rejected": -1.257153034210205,
      "step": 754
    },
    {
      "epoch": 0.302,
      "grad_norm": 3.0421462059020996,
      "learning_rate": 8.994666666666666e-07,
      "logits/chosen": -2.746831178665161,
      "logits/rejected": -2.2243034839630127,
      "logps/chosen": -213.02572631835938,
      "logps/rejected": -136.348388671875,
      "loss": 0.0322,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2904725074768066,
      "rewards/margins": 3.992344617843628,
      "rewards/rejected": -1.7018723487854004,
      "step": 755
    },
    {
      "epoch": 0.3024,
      "grad_norm": 0.9353224635124207,
      "learning_rate": 8.993333333333333e-07,
      "logits/chosen": -2.179460287094116,
      "logits/rejected": -1.981523036956787,
      "logps/chosen": -135.25230407714844,
      "logps/rejected": -89.50272369384766,
      "loss": 0.015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7951102256774902,
      "rewards/margins": 4.437460899353027,
      "rewards/rejected": -1.642350435256958,
      "step": 756
    },
    {
      "epoch": 0.3028,
      "grad_norm": 0.6461456418037415,
      "learning_rate": 8.992e-07,
      "logits/chosen": -2.0039145946502686,
      "logits/rejected": -2.8236236572265625,
      "logps/chosen": -96.29644012451172,
      "logps/rejected": -148.1389617919922,
      "loss": 0.0093,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4814348220825195,
      "rewards/margins": 4.755762577056885,
      "rewards/rejected": -1.2743278741836548,
      "step": 757
    },
    {
      "epoch": 0.3032,
      "grad_norm": 0.4849247932434082,
      "learning_rate": 8.990666666666666e-07,
      "logits/chosen": -2.6036581993103027,
      "logits/rejected": -2.362868309020996,
      "logps/chosen": -164.10174560546875,
      "logps/rejected": -170.78469848632812,
      "loss": 0.0065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.137814998626709,
      "rewards/margins": 5.09195613861084,
      "rewards/rejected": -1.9541412591934204,
      "step": 758
    },
    {
      "epoch": 0.3036,
      "grad_norm": 1.9696834087371826,
      "learning_rate": 8.989333333333333e-07,
      "logits/chosen": -2.245577096939087,
      "logits/rejected": -2.8822450637817383,
      "logps/chosen": -175.5797119140625,
      "logps/rejected": -118.18766784667969,
      "loss": 0.0298,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5521364212036133,
      "rewards/margins": 3.597564220428467,
      "rewards/rejected": -1.045427680015564,
      "step": 759
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.6146087050437927,
      "learning_rate": 8.988e-07,
      "logits/chosen": -2.0122971534729004,
      "logits/rejected": -2.8989460468292236,
      "logps/chosen": -123.33549499511719,
      "logps/rejected": -148.4015655517578,
      "loss": 0.0085,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7617955207824707,
      "rewards/margins": 5.097466468811035,
      "rewards/rejected": -1.335670828819275,
      "step": 760
    },
    {
      "epoch": 0.3044,
      "grad_norm": 0.32467588782310486,
      "learning_rate": 8.986666666666666e-07,
      "logits/chosen": -2.4913763999938965,
      "logits/rejected": -2.301738739013672,
      "logps/chosen": -159.03762817382812,
      "logps/rejected": -221.5517578125,
      "loss": 0.0045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.2349443435668945,
      "rewards/margins": 5.405002593994141,
      "rewards/rejected": -1.1700584888458252,
      "step": 761
    },
    {
      "epoch": 0.3048,
      "grad_norm": 1.1502612829208374,
      "learning_rate": 8.985333333333333e-07,
      "logits/chosen": -2.2945797443389893,
      "logits/rejected": -2.315669059753418,
      "logps/chosen": -119.5354232788086,
      "logps/rejected": -136.07919311523438,
      "loss": 0.0173,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.227510929107666,
      "rewards/margins": 4.430871963500977,
      "rewards/rejected": -1.2033611536026,
      "step": 762
    },
    {
      "epoch": 0.3052,
      "grad_norm": 11.027819633483887,
      "learning_rate": 8.983999999999999e-07,
      "logits/chosen": -2.4695277214050293,
      "logits/rejected": -3.15946364402771,
      "logps/chosen": -126.40845489501953,
      "logps/rejected": -96.06217956542969,
      "loss": 0.2502,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2657066583633423,
      "rewards/margins": 1.5003483295440674,
      "rewards/rejected": -0.2346416562795639,
      "step": 763
    },
    {
      "epoch": 0.3056,
      "grad_norm": 0.4583013653755188,
      "learning_rate": 8.982666666666666e-07,
      "logits/chosen": -2.3427574634552,
      "logits/rejected": -3.0091259479522705,
      "logps/chosen": -202.0019989013672,
      "logps/rejected": -134.4701690673828,
      "loss": 0.0078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8469269275665283,
      "rewards/margins": 4.88568115234375,
      "rewards/rejected": -1.0387539863586426,
      "step": 764
    },
    {
      "epoch": 0.306,
      "grad_norm": 0.9329016208648682,
      "learning_rate": 8.981333333333333e-07,
      "logits/chosen": -2.3483734130859375,
      "logits/rejected": -2.5499143600463867,
      "logps/chosen": -129.04852294921875,
      "logps/rejected": -107.47587585449219,
      "loss": 0.0133,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6254451274871826,
      "rewards/margins": 4.4168219566345215,
      "rewards/rejected": -0.7913768887519836,
      "step": 765
    },
    {
      "epoch": 0.3064,
      "grad_norm": 5.387580394744873,
      "learning_rate": 8.98e-07,
      "logits/chosen": -2.1371099948883057,
      "logits/rejected": -2.618004560470581,
      "logps/chosen": -89.83863830566406,
      "logps/rejected": -117.11740112304688,
      "loss": 0.0818,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9604389667510986,
      "rewards/margins": 3.0887691974639893,
      "rewards/rejected": -1.1283302307128906,
      "step": 766
    },
    {
      "epoch": 0.3068,
      "grad_norm": 10.762910842895508,
      "learning_rate": 8.978666666666667e-07,
      "logits/chosen": -2.439697265625,
      "logits/rejected": -2.6753106117248535,
      "logps/chosen": -141.6194610595703,
      "logps/rejected": -130.701171875,
      "loss": 0.1846,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8703937530517578,
      "rewards/margins": 1.616841197013855,
      "rewards/rejected": -0.7464473843574524,
      "step": 767
    },
    {
      "epoch": 0.3072,
      "grad_norm": 1.070212483406067,
      "learning_rate": 8.977333333333333e-07,
      "logits/chosen": -2.2248432636260986,
      "logits/rejected": -1.6553691625595093,
      "logps/chosen": -90.31580352783203,
      "logps/rejected": -87.07117462158203,
      "loss": 0.0185,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.203350067138672,
      "rewards/margins": 4.124791145324707,
      "rewards/rejected": -0.9214408993721008,
      "step": 768
    },
    {
      "epoch": 0.3076,
      "grad_norm": 1.4016839265823364,
      "learning_rate": 8.975999999999999e-07,
      "logits/chosen": -2.176999092102051,
      "logits/rejected": -2.0974903106689453,
      "logps/chosen": -170.3798828125,
      "logps/rejected": -103.99959564208984,
      "loss": 0.021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.997016191482544,
      "rewards/margins": 3.857581377029419,
      "rewards/rejected": -0.860565185546875,
      "step": 769
    },
    {
      "epoch": 0.308,
      "grad_norm": 0.8604116439819336,
      "learning_rate": 8.974666666666666e-07,
      "logits/chosen": -2.202345132827759,
      "logits/rejected": -3.255316972732544,
      "logps/chosen": -107.87577819824219,
      "logps/rejected": -111.58007049560547,
      "loss": 0.0148,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6552929878234863,
      "rewards/margins": 4.302216053009033,
      "rewards/rejected": -0.6469230651855469,
      "step": 770
    },
    {
      "epoch": 0.3084,
      "grad_norm": 2.8755245208740234,
      "learning_rate": 8.973333333333333e-07,
      "logits/chosen": -1.8289899826049805,
      "logits/rejected": -2.795013666152954,
      "logps/chosen": -65.3798828125,
      "logps/rejected": -97.68152618408203,
      "loss": 0.0531,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.417426109313965,
      "rewards/margins": 3.058537721633911,
      "rewards/rejected": -0.6411117315292358,
      "step": 771
    },
    {
      "epoch": 0.3088,
      "grad_norm": 2.150043487548828,
      "learning_rate": 8.972e-07,
      "logits/chosen": -2.218122720718384,
      "logits/rejected": -2.407042980194092,
      "logps/chosen": -115.09114074707031,
      "logps/rejected": -121.50028991699219,
      "loss": 0.027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9148495197296143,
      "rewards/margins": 3.962176561355591,
      "rewards/rejected": -1.0473270416259766,
      "step": 772
    },
    {
      "epoch": 0.3092,
      "grad_norm": 3.774305820465088,
      "learning_rate": 8.970666666666667e-07,
      "logits/chosen": -2.073270320892334,
      "logits/rejected": -2.754878044128418,
      "logps/chosen": -86.31742858886719,
      "logps/rejected": -92.88706970214844,
      "loss": 0.0531,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.517519950866699,
      "rewards/margins": 3.285672664642334,
      "rewards/rejected": -0.7681525945663452,
      "step": 773
    },
    {
      "epoch": 0.3096,
      "grad_norm": 8.24389934539795,
      "learning_rate": 8.969333333333333e-07,
      "logits/chosen": -3.1189517974853516,
      "logits/rejected": -2.76361346244812,
      "logps/chosen": -139.96913146972656,
      "logps/rejected": -97.73430633544922,
      "loss": 0.1385,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.086879014968872,
      "rewards/margins": 1.9081478118896484,
      "rewards/rejected": 0.17873115837574005,
      "step": 774
    },
    {
      "epoch": 0.31,
      "grad_norm": 3.3499388694763184,
      "learning_rate": 8.968e-07,
      "logits/chosen": -2.198568820953369,
      "logits/rejected": -2.3885207176208496,
      "logps/chosen": -134.81153869628906,
      "logps/rejected": -122.0280990600586,
      "loss": 0.0497,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4380111694335938,
      "rewards/margins": 3.662269115447998,
      "rewards/rejected": -1.2242580652236938,
      "step": 775
    },
    {
      "epoch": 0.3104,
      "grad_norm": 1.8148291110992432,
      "learning_rate": 8.966666666666666e-07,
      "logits/chosen": -2.5462183952331543,
      "logits/rejected": -2.2380454540252686,
      "logps/chosen": -106.682861328125,
      "logps/rejected": -90.800537109375,
      "loss": 0.0227,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.242611885070801,
      "rewards/margins": 3.9034171104431152,
      "rewards/rejected": -0.6608055233955383,
      "step": 776
    },
    {
      "epoch": 0.3108,
      "grad_norm": 0.8915332555770874,
      "learning_rate": 8.965333333333332e-07,
      "logits/chosen": -2.276937484741211,
      "logits/rejected": -3.0411739349365234,
      "logps/chosen": -118.32014465332031,
      "logps/rejected": -139.54940795898438,
      "loss": 0.0131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.858062744140625,
      "rewards/margins": 4.539011001586914,
      "rewards/rejected": -1.6809478998184204,
      "step": 777
    },
    {
      "epoch": 0.3112,
      "grad_norm": 1.623048186302185,
      "learning_rate": 8.963999999999999e-07,
      "logits/chosen": -2.8049283027648926,
      "logits/rejected": -2.565147876739502,
      "logps/chosen": -128.2263641357422,
      "logps/rejected": -107.15559387207031,
      "loss": 0.0293,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5063843727111816,
      "rewards/margins": 3.559460163116455,
      "rewards/rejected": -1.0530757904052734,
      "step": 778
    },
    {
      "epoch": 0.3116,
      "grad_norm": 3.6667633056640625,
      "learning_rate": 8.962666666666666e-07,
      "logits/chosen": -2.460651397705078,
      "logits/rejected": -2.5908432006835938,
      "logps/chosen": -141.62916564941406,
      "logps/rejected": -103.74864196777344,
      "loss": 0.0498,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.588855266571045,
      "rewards/margins": 3.5969715118408203,
      "rewards/rejected": -1.0081161260604858,
      "step": 779
    },
    {
      "epoch": 0.312,
      "grad_norm": 1.384175419807434,
      "learning_rate": 8.961333333333333e-07,
      "logits/chosen": -2.065964937210083,
      "logits/rejected": -1.51295804977417,
      "logps/chosen": -96.91458892822266,
      "logps/rejected": -76.26074981689453,
      "loss": 0.0235,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.119208812713623,
      "rewards/margins": 3.7521233558654785,
      "rewards/rejected": -0.6329145431518555,
      "step": 780
    },
    {
      "epoch": 0.3124,
      "grad_norm": 1.203910231590271,
      "learning_rate": 8.96e-07,
      "logits/chosen": -2.130234718322754,
      "logits/rejected": -2.0894761085510254,
      "logps/chosen": -139.58204650878906,
      "logps/rejected": -103.94606018066406,
      "loss": 0.0214,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6158699989318848,
      "rewards/margins": 3.8671603202819824,
      "rewards/rejected": -1.2512900829315186,
      "step": 781
    },
    {
      "epoch": 0.3128,
      "grad_norm": 2.0236785411834717,
      "learning_rate": 8.958666666666667e-07,
      "logits/chosen": -2.056626319885254,
      "logits/rejected": -2.7698557376861572,
      "logps/chosen": -103.11468505859375,
      "logps/rejected": -115.16119384765625,
      "loss": 0.0248,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4660725593566895,
      "rewards/margins": 4.056765556335449,
      "rewards/rejected": -0.590692937374115,
      "step": 782
    },
    {
      "epoch": 0.3132,
      "grad_norm": 20.951173782348633,
      "learning_rate": 8.957333333333334e-07,
      "logits/chosen": -1.7704534530639648,
      "logits/rejected": -2.2317891120910645,
      "logps/chosen": -119.42454528808594,
      "logps/rejected": -89.52031707763672,
      "loss": 0.312,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5218902230262756,
      "rewards/margins": 1.1800575256347656,
      "rewards/rejected": -0.6581672430038452,
      "step": 783
    },
    {
      "epoch": 0.3136,
      "grad_norm": 1.266780138015747,
      "learning_rate": 8.955999999999999e-07,
      "logits/chosen": -2.569981575012207,
      "logits/rejected": -2.700136661529541,
      "logps/chosen": -155.70164489746094,
      "logps/rejected": -109.40281677246094,
      "loss": 0.0212,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.846662998199463,
      "rewards/margins": 4.092294216156006,
      "rewards/rejected": -1.2456309795379639,
      "step": 784
    },
    {
      "epoch": 0.314,
      "grad_norm": 2.433847665786743,
      "learning_rate": 8.954666666666666e-07,
      "logits/chosen": -2.2616562843322754,
      "logits/rejected": -2.6472089290618896,
      "logps/chosen": -79.11831665039062,
      "logps/rejected": -89.29237365722656,
      "loss": 0.0513,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0189361572265625,
      "rewards/margins": 3.050157070159912,
      "rewards/rejected": -1.0312206745147705,
      "step": 785
    },
    {
      "epoch": 0.3144,
      "grad_norm": 4.962613105773926,
      "learning_rate": 8.953333333333332e-07,
      "logits/chosen": -2.5943944454193115,
      "logits/rejected": -3.4688291549682617,
      "logps/chosen": -112.29634857177734,
      "logps/rejected": -190.42581176757812,
      "loss": 0.0442,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0733489990234375,
      "rewards/margins": 4.203968524932861,
      "rewards/rejected": -2.130619525909424,
      "step": 786
    },
    {
      "epoch": 0.3148,
      "grad_norm": 1.8777269124984741,
      "learning_rate": 8.951999999999999e-07,
      "logits/chosen": -2.358613967895508,
      "logits/rejected": -2.916337251663208,
      "logps/chosen": -176.43719482421875,
      "logps/rejected": -124.7771224975586,
      "loss": 0.0252,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.981060028076172,
      "rewards/margins": 4.02894401550293,
      "rewards/rejected": -1.0478839874267578,
      "step": 787
    },
    {
      "epoch": 0.3152,
      "grad_norm": 1.071423888206482,
      "learning_rate": 8.950666666666666e-07,
      "logits/chosen": -2.3596749305725098,
      "logits/rejected": -2.6312308311462402,
      "logps/chosen": -93.57471466064453,
      "logps/rejected": -197.58154296875,
      "loss": 0.0192,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0071113109588623,
      "rewards/margins": 4.316878318786621,
      "rewards/rejected": -1.3097668886184692,
      "step": 788
    },
    {
      "epoch": 0.3156,
      "grad_norm": 7.989108562469482,
      "learning_rate": 8.949333333333333e-07,
      "logits/chosen": -2.6538925170898438,
      "logits/rejected": -2.903766632080078,
      "logps/chosen": -236.46348571777344,
      "logps/rejected": -120.4380111694336,
      "loss": 0.0954,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.283616542816162,
      "rewards/margins": 3.234147787094116,
      "rewards/rejected": -0.950531005859375,
      "step": 789
    },
    {
      "epoch": 0.316,
      "grad_norm": 3.8513331413269043,
      "learning_rate": 8.948e-07,
      "logits/chosen": -1.8223698139190674,
      "logits/rejected": -2.488344192504883,
      "logps/chosen": -94.1585922241211,
      "logps/rejected": -183.72604370117188,
      "loss": 0.0389,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.116349935531616,
      "rewards/margins": 3.9152450561523438,
      "rewards/rejected": -1.7988953590393066,
      "step": 790
    },
    {
      "epoch": 0.3164,
      "grad_norm": 12.640743255615234,
      "learning_rate": 8.946666666666667e-07,
      "logits/chosen": -2.1420345306396484,
      "logits/rejected": -2.28462553024292,
      "logps/chosen": -98.6251220703125,
      "logps/rejected": -91.61013793945312,
      "loss": 0.2676,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.218601942062378,
      "rewards/margins": 2.6125948429107666,
      "rewards/rejected": -0.3939930200576782,
      "step": 791
    },
    {
      "epoch": 0.3168,
      "grad_norm": 3.378438949584961,
      "learning_rate": 8.945333333333333e-07,
      "logits/chosen": -2.0873618125915527,
      "logits/rejected": -2.5999512672424316,
      "logps/chosen": -150.55142211914062,
      "logps/rejected": -129.91529846191406,
      "loss": 0.0364,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2375876903533936,
      "rewards/margins": 3.7210769653320312,
      "rewards/rejected": -1.4834892749786377,
      "step": 792
    },
    {
      "epoch": 0.3172,
      "grad_norm": 1.0676642656326294,
      "learning_rate": 8.944e-07,
      "logits/chosen": -2.458928108215332,
      "logits/rejected": -3.6109907627105713,
      "logps/chosen": -139.55532836914062,
      "logps/rejected": -106.81173706054688,
      "loss": 0.014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.529690742492676,
      "rewards/margins": 4.481165885925293,
      "rewards/rejected": -0.951475203037262,
      "step": 793
    },
    {
      "epoch": 0.3176,
      "grad_norm": 0.7012012600898743,
      "learning_rate": 8.942666666666667e-07,
      "logits/chosen": -2.299588203430176,
      "logits/rejected": -2.5012714862823486,
      "logps/chosen": -143.48715209960938,
      "logps/rejected": -149.4267578125,
      "loss": 0.0089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.881040573120117,
      "rewards/margins": 4.947179794311523,
      "rewards/rejected": -1.0661388635635376,
      "step": 794
    },
    {
      "epoch": 0.318,
      "grad_norm": 10.060739517211914,
      "learning_rate": 8.941333333333333e-07,
      "logits/chosen": -2.769075393676758,
      "logits/rejected": -2.3331735134124756,
      "logps/chosen": -130.14205932617188,
      "logps/rejected": -82.25627136230469,
      "loss": 0.1433,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6993106603622437,
      "rewards/margins": 2.6302859783172607,
      "rewards/rejected": -0.9309753179550171,
      "step": 795
    },
    {
      "epoch": 0.3184,
      "grad_norm": 2.1081008911132812,
      "learning_rate": 8.939999999999999e-07,
      "logits/chosen": -2.2366456985473633,
      "logits/rejected": -2.1610710620880127,
      "logps/chosen": -146.458740234375,
      "logps/rejected": -114.4478759765625,
      "loss": 0.0394,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0528228282928467,
      "rewards/margins": 3.297722339630127,
      "rewards/rejected": -1.2448993921279907,
      "step": 796
    },
    {
      "epoch": 0.3188,
      "grad_norm": 8.540313720703125,
      "learning_rate": 8.938666666666666e-07,
      "logits/chosen": -1.9949531555175781,
      "logits/rejected": -2.6433615684509277,
      "logps/chosen": -83.91197204589844,
      "logps/rejected": -86.8432388305664,
      "loss": 0.2461,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6137924194335938,
      "rewards/margins": 1.3348416090011597,
      "rewards/rejected": -0.7210491299629211,
      "step": 797
    },
    {
      "epoch": 0.3192,
      "grad_norm": 2.029665470123291,
      "learning_rate": 8.937333333333333e-07,
      "logits/chosen": -2.098334312438965,
      "logits/rejected": -2.5081448554992676,
      "logps/chosen": -97.47026824951172,
      "logps/rejected": -100.45570373535156,
      "loss": 0.0282,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.133910894393921,
      "rewards/margins": 3.616145610809326,
      "rewards/rejected": -0.4822345972061157,
      "step": 798
    },
    {
      "epoch": 0.3196,
      "grad_norm": 4.12944221496582,
      "learning_rate": 8.935999999999999e-07,
      "logits/chosen": -2.204253911972046,
      "logits/rejected": -2.2451868057250977,
      "logps/chosen": -110.4699935913086,
      "logps/rejected": -122.26057434082031,
      "loss": 0.0707,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0360822677612305,
      "rewards/margins": 2.804030179977417,
      "rewards/rejected": -0.767947793006897,
      "step": 799
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6872997879981995,
      "learning_rate": 8.934666666666666e-07,
      "logits/chosen": -2.2026891708374023,
      "logits/rejected": -2.9530887603759766,
      "logps/chosen": -78.65464782714844,
      "logps/rejected": -104.75997924804688,
      "loss": 0.0094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.937812089920044,
      "rewards/margins": 5.1615824699401855,
      "rewards/rejected": -2.2237701416015625,
      "step": 800
    },
    {
      "epoch": 0.3204,
      "grad_norm": 4.517988204956055,
      "learning_rate": 8.933333333333333e-07,
      "logits/chosen": -2.1748127937316895,
      "logits/rejected": -3.047051429748535,
      "logps/chosen": -100.82695007324219,
      "logps/rejected": -106.10684204101562,
      "loss": 0.0519,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.05753755569458,
      "rewards/margins": 3.6844162940979004,
      "rewards/rejected": -0.6268787384033203,
      "step": 801
    },
    {
      "epoch": 0.3208,
      "grad_norm": 10.753323554992676,
      "learning_rate": 8.932e-07,
      "logits/chosen": -1.9807549715042114,
      "logits/rejected": -1.685462474822998,
      "logps/chosen": -85.24569702148438,
      "logps/rejected": -70.3848876953125,
      "loss": 0.1726,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1963610649108887,
      "rewards/margins": 2.0079143047332764,
      "rewards/rejected": 0.18844681978225708,
      "step": 802
    },
    {
      "epoch": 0.3212,
      "grad_norm": 0.425980806350708,
      "learning_rate": 8.930666666666667e-07,
      "logits/chosen": -2.3401477336883545,
      "logits/rejected": -2.9292545318603516,
      "logps/chosen": -114.03564453125,
      "logps/rejected": -105.29086303710938,
      "loss": 0.0078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.905242443084717,
      "rewards/margins": 4.912909507751465,
      "rewards/rejected": -1.0076671838760376,
      "step": 803
    },
    {
      "epoch": 0.3216,
      "grad_norm": 2.3754000663757324,
      "learning_rate": 8.929333333333334e-07,
      "logits/chosen": -2.4478492736816406,
      "logits/rejected": -2.3317112922668457,
      "logps/chosen": -166.0182647705078,
      "logps/rejected": -107.93126678466797,
      "loss": 0.0375,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6887569427490234,
      "rewards/margins": 3.548722505569458,
      "rewards/rejected": -0.8599655628204346,
      "step": 804
    },
    {
      "epoch": 0.322,
      "grad_norm": 2.870220422744751,
      "learning_rate": 8.928e-07,
      "logits/chosen": -2.0157785415649414,
      "logits/rejected": -1.6724956035614014,
      "logps/chosen": -96.07544708251953,
      "logps/rejected": -90.28720092773438,
      "loss": 0.0507,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5981345176696777,
      "rewards/margins": 3.182237148284912,
      "rewards/rejected": -0.5841026306152344,
      "step": 805
    },
    {
      "epoch": 0.3224,
      "grad_norm": 0.5676467418670654,
      "learning_rate": 8.926666666666666e-07,
      "logits/chosen": -2.1507906913757324,
      "logits/rejected": -2.703646659851074,
      "logps/chosen": -146.82691955566406,
      "logps/rejected": -121.77112579345703,
      "loss": 0.0083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4247565269470215,
      "rewards/margins": 4.801511764526367,
      "rewards/rejected": -1.3767552375793457,
      "step": 806
    },
    {
      "epoch": 0.3228,
      "grad_norm": 2.4314332008361816,
      "learning_rate": 8.925333333333332e-07,
      "logits/chosen": -2.047804355621338,
      "logits/rejected": -2.6963014602661133,
      "logps/chosen": -159.6792449951172,
      "logps/rejected": -111.93836975097656,
      "loss": 0.052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5022635459899902,
      "rewards/margins": 3.05499267578125,
      "rewards/rejected": -0.552729070186615,
      "step": 807
    },
    {
      "epoch": 0.3232,
      "grad_norm": 2.6704609394073486,
      "learning_rate": 8.923999999999999e-07,
      "logits/chosen": -1.9387717247009277,
      "logits/rejected": -1.5617411136627197,
      "logps/chosen": -116.40144348144531,
      "logps/rejected": -77.0108413696289,
      "loss": 0.0495,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1731042861938477,
      "rewards/margins": 3.0447678565979004,
      "rewards/rejected": -0.8716638684272766,
      "step": 808
    },
    {
      "epoch": 0.3236,
      "grad_norm": 1.984242558479309,
      "learning_rate": 8.922666666666666e-07,
      "logits/chosen": -2.71366810798645,
      "logits/rejected": -2.4580960273742676,
      "logps/chosen": -191.4305419921875,
      "logps/rejected": -138.6422576904297,
      "loss": 0.0262,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7609100341796875,
      "rewards/margins": 4.047698497772217,
      "rewards/rejected": -1.2867885828018188,
      "step": 809
    },
    {
      "epoch": 0.324,
      "grad_norm": 2.1393535137176514,
      "learning_rate": 8.921333333333333e-07,
      "logits/chosen": -2.0826926231384277,
      "logits/rejected": -3.4439697265625,
      "logps/chosen": -156.74078369140625,
      "logps/rejected": -144.24331665039062,
      "loss": 0.0303,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.783551812171936,
      "rewards/margins": 3.669999122619629,
      "rewards/rejected": -1.8864471912384033,
      "step": 810
    },
    {
      "epoch": 0.3244,
      "grad_norm": 1.1767504215240479,
      "learning_rate": 8.92e-07,
      "logits/chosen": -2.0991053581237793,
      "logits/rejected": -2.4393820762634277,
      "logps/chosen": -66.5164794921875,
      "logps/rejected": -103.59549713134766,
      "loss": 0.0212,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7729767560958862,
      "rewards/margins": 3.866176128387451,
      "rewards/rejected": -2.0931992530822754,
      "step": 811
    },
    {
      "epoch": 0.3248,
      "grad_norm": 0.8609403371810913,
      "learning_rate": 8.918666666666667e-07,
      "logits/chosen": -2.1425528526306152,
      "logits/rejected": -2.564800262451172,
      "logps/chosen": -88.95923614501953,
      "logps/rejected": -110.54081726074219,
      "loss": 0.0149,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.158205509185791,
      "rewards/margins": 4.327341079711914,
      "rewards/rejected": -1.1691356897354126,
      "step": 812
    },
    {
      "epoch": 0.3252,
      "grad_norm": 0.17998626828193665,
      "learning_rate": 8.917333333333334e-07,
      "logits/chosen": -2.2806015014648438,
      "logits/rejected": -2.391666889190674,
      "logps/chosen": -155.27577209472656,
      "logps/rejected": -137.16473388671875,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.114643573760986,
      "rewards/margins": 5.883709907531738,
      "rewards/rejected": -1.769066333770752,
      "step": 813
    },
    {
      "epoch": 0.3256,
      "grad_norm": 1.3810558319091797,
      "learning_rate": 8.915999999999999e-07,
      "logits/chosen": -2.039872407913208,
      "logits/rejected": -2.997816801071167,
      "logps/chosen": -138.361572265625,
      "logps/rejected": -193.64810180664062,
      "loss": 0.02,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.799039602279663,
      "rewards/margins": 3.9463469982147217,
      "rewards/rejected": -1.1473071575164795,
      "step": 814
    },
    {
      "epoch": 0.326,
      "grad_norm": 5.043862819671631,
      "learning_rate": 8.914666666666665e-07,
      "logits/chosen": -2.081573724746704,
      "logits/rejected": -2.921724796295166,
      "logps/chosen": -77.16655731201172,
      "logps/rejected": -102.86692810058594,
      "loss": 0.0837,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.113478183746338,
      "rewards/margins": 2.5927059650421143,
      "rewards/rejected": 0.5207721590995789,
      "step": 815
    },
    {
      "epoch": 0.3264,
      "grad_norm": 10.377603530883789,
      "learning_rate": 8.913333333333332e-07,
      "logits/chosen": -2.3603315353393555,
      "logits/rejected": -1.795809030532837,
      "logps/chosen": -107.91226196289062,
      "logps/rejected": -96.75129699707031,
      "loss": 0.2008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7955710887908936,
      "rewards/margins": 2.669872999191284,
      "rewards/rejected": -0.8743019104003906,
      "step": 816
    },
    {
      "epoch": 0.3268,
      "grad_norm": 2.2068803310394287,
      "learning_rate": 8.911999999999999e-07,
      "logits/chosen": -2.1881051063537598,
      "logits/rejected": -2.6564688682556152,
      "logps/chosen": -110.70321655273438,
      "logps/rejected": -124.21011352539062,
      "loss": 0.0396,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7030476331710815,
      "rewards/margins": 3.211836814880371,
      "rewards/rejected": -1.5087890625,
      "step": 817
    },
    {
      "epoch": 0.3272,
      "grad_norm": 1.9314175844192505,
      "learning_rate": 8.910666666666666e-07,
      "logits/chosen": -1.9081323146820068,
      "logits/rejected": -2.956308603286743,
      "logps/chosen": -79.89747619628906,
      "logps/rejected": -119.73229217529297,
      "loss": 0.0283,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9281814098358154,
      "rewards/margins": 4.15826416015625,
      "rewards/rejected": -1.2300827503204346,
      "step": 818
    },
    {
      "epoch": 0.3276,
      "grad_norm": 1.9245866537094116,
      "learning_rate": 8.909333333333333e-07,
      "logits/chosen": -2.4317140579223633,
      "logits/rejected": -2.5172290802001953,
      "logps/chosen": -115.2402572631836,
      "logps/rejected": -116.59526824951172,
      "loss": 0.0333,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6638758182525635,
      "rewards/margins": 3.9020066261291504,
      "rewards/rejected": -1.2381305694580078,
      "step": 819
    },
    {
      "epoch": 0.328,
      "grad_norm": 2.114412546157837,
      "learning_rate": 8.908e-07,
      "logits/chosen": -2.1739611625671387,
      "logits/rejected": -2.7165980339050293,
      "logps/chosen": -154.8603973388672,
      "logps/rejected": -127.94245910644531,
      "loss": 0.0368,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.120532274246216,
      "rewards/margins": 3.4652369022369385,
      "rewards/rejected": -1.3447043895721436,
      "step": 820
    },
    {
      "epoch": 0.3284,
      "grad_norm": 0.6676588654518127,
      "learning_rate": 8.906666666666667e-07,
      "logits/chosen": -2.479166030883789,
      "logits/rejected": -2.190455913543701,
      "logps/chosen": -91.43891906738281,
      "logps/rejected": -118.60624694824219,
      "loss": 0.0104,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.728607177734375,
      "rewards/margins": 5.0622711181640625,
      "rewards/rejected": -1.3336635828018188,
      "step": 821
    },
    {
      "epoch": 0.3288,
      "grad_norm": 1.743912696838379,
      "learning_rate": 8.905333333333333e-07,
      "logits/chosen": -2.3176417350769043,
      "logits/rejected": -2.7252461910247803,
      "logps/chosen": -102.71382904052734,
      "logps/rejected": -135.2818603515625,
      "loss": 0.0156,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.954738140106201,
      "rewards/margins": 4.563777923583984,
      "rewards/rejected": -1.609039306640625,
      "step": 822
    },
    {
      "epoch": 0.3292,
      "grad_norm": 0.5026206374168396,
      "learning_rate": 8.904e-07,
      "logits/chosen": -2.2321741580963135,
      "logits/rejected": -3.007467269897461,
      "logps/chosen": -102.57070922851562,
      "logps/rejected": -151.8827667236328,
      "loss": 0.0088,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7847228050231934,
      "rewards/margins": 5.020562171936035,
      "rewards/rejected": -1.2358391284942627,
      "step": 823
    },
    {
      "epoch": 0.3296,
      "grad_norm": 7.122845649719238,
      "learning_rate": 8.902666666666666e-07,
      "logits/chosen": -2.0521397590637207,
      "logits/rejected": -2.343379497528076,
      "logps/chosen": -95.44326782226562,
      "logps/rejected": -126.28777313232422,
      "loss": 0.1639,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1786086559295654,
      "rewards/margins": 1.7263282537460327,
      "rewards/rejected": -0.5477195978164673,
      "step": 824
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.767931580543518,
      "learning_rate": 8.901333333333333e-07,
      "logits/chosen": -2.297421455383301,
      "logits/rejected": -2.191300868988037,
      "logps/chosen": -92.88983154296875,
      "logps/rejected": -86.72848510742188,
      "loss": 0.0311,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7654805183410645,
      "rewards/margins": 3.4777109622955322,
      "rewards/rejected": -0.7122303247451782,
      "step": 825
    },
    {
      "epoch": 0.3304,
      "grad_norm": 2.9281606674194336,
      "learning_rate": 8.9e-07,
      "logits/chosen": -2.389708995819092,
      "logits/rejected": -1.8518917560577393,
      "logps/chosen": -110.49971008300781,
      "logps/rejected": -123.04203033447266,
      "loss": 0.0326,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.015735149383545,
      "rewards/margins": 4.062949180603027,
      "rewards/rejected": -1.0472137928009033,
      "step": 826
    },
    {
      "epoch": 0.3308,
      "grad_norm": 4.613772869110107,
      "learning_rate": 8.898666666666666e-07,
      "logits/chosen": -1.8721821308135986,
      "logits/rejected": -1.835613489151001,
      "logps/chosen": -138.39059448242188,
      "logps/rejected": -83.87528228759766,
      "loss": 0.0556,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.120154857635498,
      "rewards/margins": 3.814680576324463,
      "rewards/rejected": -0.6945257186889648,
      "step": 827
    },
    {
      "epoch": 0.3312,
      "grad_norm": 0.1921926587820053,
      "learning_rate": 8.897333333333333e-07,
      "logits/chosen": -1.9919633865356445,
      "logits/rejected": -3.056222438812256,
      "logps/chosen": -112.30611419677734,
      "logps/rejected": -184.66700744628906,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.285749912261963,
      "rewards/margins": 6.179891586303711,
      "rewards/rejected": -1.894141435623169,
      "step": 828
    },
    {
      "epoch": 0.3316,
      "grad_norm": 7.4077301025390625,
      "learning_rate": 8.895999999999999e-07,
      "logits/chosen": -1.7259577512741089,
      "logits/rejected": -2.2624902725219727,
      "logps/chosen": -67.17411041259766,
      "logps/rejected": -82.67288208007812,
      "loss": 0.1879,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.41274094581604,
      "rewards/margins": 2.1946218013763428,
      "rewards/rejected": 0.21811902523040771,
      "step": 829
    },
    {
      "epoch": 0.332,
      "grad_norm": 0.777452826499939,
      "learning_rate": 8.894666666666666e-07,
      "logits/chosen": -2.6819000244140625,
      "logits/rejected": -2.088336944580078,
      "logps/chosen": -258.20123291015625,
      "logps/rejected": -92.70182037353516,
      "loss": 0.0108,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8780322074890137,
      "rewards/margins": 4.858956336975098,
      "rewards/rejected": -0.9809242486953735,
      "step": 830
    },
    {
      "epoch": 0.3324,
      "grad_norm": 2.2969353199005127,
      "learning_rate": 8.893333333333333e-07,
      "logits/chosen": -2.608407974243164,
      "logits/rejected": -2.937574863433838,
      "logps/chosen": -125.88926696777344,
      "logps/rejected": -121.51696014404297,
      "loss": 0.0356,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.196072816848755,
      "rewards/margins": 3.936098575592041,
      "rewards/rejected": -1.7400257587432861,
      "step": 831
    },
    {
      "epoch": 0.3328,
      "grad_norm": 0.5416452884674072,
      "learning_rate": 8.892e-07,
      "logits/chosen": -2.161639928817749,
      "logits/rejected": -2.0754857063293457,
      "logps/chosen": -91.46189880371094,
      "logps/rejected": -99.40431213378906,
      "loss": 0.0087,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0704402923583984,
      "rewards/margins": 4.74195671081543,
      "rewards/rejected": -1.6715164184570312,
      "step": 832
    },
    {
      "epoch": 0.3332,
      "grad_norm": 3.5193135738372803,
      "learning_rate": 8.890666666666666e-07,
      "logits/chosen": -2.0504817962646484,
      "logits/rejected": -2.567875385284424,
      "logps/chosen": -90.51715087890625,
      "logps/rejected": -198.4585418701172,
      "loss": 0.0671,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7434794902801514,
      "rewards/margins": 4.0074381828308105,
      "rewards/rejected": -1.2639588117599487,
      "step": 833
    },
    {
      "epoch": 0.3336,
      "grad_norm": 0.9003880620002747,
      "learning_rate": 8.889333333333333e-07,
      "logits/chosen": -2.844499349594116,
      "logits/rejected": -1.6914443969726562,
      "logps/chosen": -152.29518127441406,
      "logps/rejected": -97.06120300292969,
      "loss": 0.0129,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6283202171325684,
      "rewards/margins": 4.346653461456299,
      "rewards/rejected": -0.7183330655097961,
      "step": 834
    },
    {
      "epoch": 0.334,
      "grad_norm": 1.3981313705444336,
      "learning_rate": 8.888e-07,
      "logits/chosen": -2.3355138301849365,
      "logits/rejected": -1.6559686660766602,
      "logps/chosen": -116.99127197265625,
      "logps/rejected": -112.30949401855469,
      "loss": 0.0255,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5547935962677,
      "rewards/margins": 3.947514057159424,
      "rewards/rejected": -0.39272040128707886,
      "step": 835
    },
    {
      "epoch": 0.3344,
      "grad_norm": 0.19672891497612,
      "learning_rate": 8.886666666666667e-07,
      "logits/chosen": -2.2957611083984375,
      "logits/rejected": -2.6988086700439453,
      "logps/chosen": -105.29034423828125,
      "logps/rejected": -136.52325439453125,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.894942283630371,
      "rewards/margins": 5.8761186599731445,
      "rewards/rejected": -1.9811763763427734,
      "step": 836
    },
    {
      "epoch": 0.3348,
      "grad_norm": 0.2789686620235443,
      "learning_rate": 8.885333333333332e-07,
      "logits/chosen": -2.1932945251464844,
      "logits/rejected": -2.9832167625427246,
      "logps/chosen": -115.87138366699219,
      "logps/rejected": -155.90640258789062,
      "loss": 0.0045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.78201961517334,
      "rewards/margins": 5.462213516235352,
      "rewards/rejected": -1.6801934242248535,
      "step": 837
    },
    {
      "epoch": 0.3352,
      "grad_norm": 0.758003294467926,
      "learning_rate": 8.883999999999999e-07,
      "logits/chosen": -2.460911273956299,
      "logits/rejected": -2.8378679752349854,
      "logps/chosen": -146.67007446289062,
      "logps/rejected": -98.50162506103516,
      "loss": 0.0109,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9335973262786865,
      "rewards/margins": 5.048765659332275,
      "rewards/rejected": -1.1151683330535889,
      "step": 838
    },
    {
      "epoch": 0.3356,
      "grad_norm": 5.777073383331299,
      "learning_rate": 8.882666666666666e-07,
      "logits/chosen": -2.398968458175659,
      "logits/rejected": -2.4592530727386475,
      "logps/chosen": -140.13465881347656,
      "logps/rejected": -79.05241394042969,
      "loss": 0.0958,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7077522277832031,
      "rewards/margins": 2.656909942626953,
      "rewards/rejected": -0.94915771484375,
      "step": 839
    },
    {
      "epoch": 0.336,
      "grad_norm": 1.5385912656784058,
      "learning_rate": 8.881333333333333e-07,
      "logits/chosen": -2.099606513977051,
      "logits/rejected": -2.755464553833008,
      "logps/chosen": -92.36392974853516,
      "logps/rejected": -104.26797485351562,
      "loss": 0.0224,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6163077354431152,
      "rewards/margins": 4.22487735748291,
      "rewards/rejected": -1.6085693836212158,
      "step": 840
    },
    {
      "epoch": 0.3364,
      "grad_norm": 2.392536163330078,
      "learning_rate": 8.88e-07,
      "logits/chosen": -2.231024742126465,
      "logits/rejected": -2.629868984222412,
      "logps/chosen": -97.71873474121094,
      "logps/rejected": -98.83311462402344,
      "loss": 0.0314,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5947964191436768,
      "rewards/margins": 3.8803014755249023,
      "rewards/rejected": -1.285504937171936,
      "step": 841
    },
    {
      "epoch": 0.3368,
      "grad_norm": 0.7736183404922485,
      "learning_rate": 8.878666666666667e-07,
      "logits/chosen": -2.7321863174438477,
      "logits/rejected": -2.6007957458496094,
      "logps/chosen": -149.83737182617188,
      "logps/rejected": -109.81175994873047,
      "loss": 0.0116,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4639945030212402,
      "rewards/margins": 4.895782470703125,
      "rewards/rejected": -1.4317874908447266,
      "step": 842
    },
    {
      "epoch": 0.3372,
      "grad_norm": 5.095176696777344,
      "learning_rate": 8.877333333333333e-07,
      "logits/chosen": -2.419353485107422,
      "logits/rejected": -3.0176682472229004,
      "logps/chosen": -106.70379638671875,
      "logps/rejected": -109.1944351196289,
      "loss": 0.0684,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8280510902404785,
      "rewards/margins": 3.8860321044921875,
      "rewards/rejected": -1.0579811334609985,
      "step": 843
    },
    {
      "epoch": 0.3376,
      "grad_norm": 15.218343734741211,
      "learning_rate": 8.875999999999999e-07,
      "logits/chosen": -1.7683169841766357,
      "logits/rejected": -2.3318309783935547,
      "logps/chosen": -78.357421875,
      "logps/rejected": -81.43385314941406,
      "loss": 0.191,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4673607349395752,
      "rewards/margins": 2.2970967292785645,
      "rewards/rejected": -0.8297359943389893,
      "step": 844
    },
    {
      "epoch": 0.338,
      "grad_norm": 0.5556968450546265,
      "learning_rate": 8.874666666666666e-07,
      "logits/chosen": -2.421030044555664,
      "logits/rejected": -2.857093334197998,
      "logps/chosen": -95.26863861083984,
      "logps/rejected": -120.22237396240234,
      "loss": 0.0091,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4985504150390625,
      "rewards/margins": 4.9412078857421875,
      "rewards/rejected": -1.442657470703125,
      "step": 845
    },
    {
      "epoch": 0.3384,
      "grad_norm": 3.8007121086120605,
      "learning_rate": 8.873333333333333e-07,
      "logits/chosen": -2.279721736907959,
      "logits/rejected": -2.4521090984344482,
      "logps/chosen": -84.45494079589844,
      "logps/rejected": -99.33006286621094,
      "loss": 0.0713,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6922597885131836,
      "rewards/margins": 2.9255785942077637,
      "rewards/rejected": -0.23331871628761292,
      "step": 846
    },
    {
      "epoch": 0.3388,
      "grad_norm": 4.216347694396973,
      "learning_rate": 8.872e-07,
      "logits/chosen": -2.06081485748291,
      "logits/rejected": -2.3576340675354004,
      "logps/chosen": -137.59048461914062,
      "logps/rejected": -100.10685729980469,
      "loss": 0.0611,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6669321060180664,
      "rewards/margins": 4.107517242431641,
      "rewards/rejected": -1.4405851364135742,
      "step": 847
    },
    {
      "epoch": 0.3392,
      "grad_norm": 2.992288112640381,
      "learning_rate": 8.870666666666666e-07,
      "logits/chosen": -2.534557580947876,
      "logits/rejected": -2.9391322135925293,
      "logps/chosen": -178.37405395507812,
      "logps/rejected": -145.50559997558594,
      "loss": 0.0486,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9140288829803467,
      "rewards/margins": 3.0201351642608643,
      "rewards/rejected": -1.1061062812805176,
      "step": 848
    },
    {
      "epoch": 0.3396,
      "grad_norm": 3.561558723449707,
      "learning_rate": 8.869333333333333e-07,
      "logits/chosen": -1.9580166339874268,
      "logits/rejected": -1.9905898571014404,
      "logps/chosen": -70.35733032226562,
      "logps/rejected": -89.26181030273438,
      "loss": 0.0533,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6955070495605469,
      "rewards/margins": 2.9564085006713867,
      "rewards/rejected": -1.2609012126922607,
      "step": 849
    },
    {
      "epoch": 0.34,
      "grad_norm": 25.44463539123535,
      "learning_rate": 8.868e-07,
      "logits/chosen": -2.145777702331543,
      "logits/rejected": -2.222597599029541,
      "logps/chosen": -83.45771789550781,
      "logps/rejected": -79.42788696289062,
      "loss": 0.5061,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 1.341888666152954,
      "rewards/margins": 1.493883728981018,
      "rewards/rejected": -0.15199506282806396,
      "step": 850
    },
    {
      "epoch": 0.3404,
      "grad_norm": 6.083514213562012,
      "learning_rate": 8.866666666666667e-07,
      "logits/chosen": -2.7904624938964844,
      "logits/rejected": -3.2834229469299316,
      "logps/chosen": -178.4914093017578,
      "logps/rejected": -133.19308471679688,
      "loss": 0.0599,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.442652702331543,
      "rewards/margins": 3.417977809906006,
      "rewards/rejected": -0.9753250479698181,
      "step": 851
    },
    {
      "epoch": 0.3408,
      "grad_norm": 0.512304425239563,
      "learning_rate": 8.865333333333332e-07,
      "logits/chosen": -2.5440168380737305,
      "logits/rejected": -2.985495090484619,
      "logps/chosen": -198.25991821289062,
      "logps/rejected": -153.76438903808594,
      "loss": 0.0057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.046684265136719,
      "rewards/margins": 5.231103897094727,
      "rewards/rejected": -1.1844192743301392,
      "step": 852
    },
    {
      "epoch": 0.3412,
      "grad_norm": 1.3507477045059204,
      "learning_rate": 8.863999999999999e-07,
      "logits/chosen": -2.1753828525543213,
      "logits/rejected": -2.5000786781311035,
      "logps/chosen": -115.08191680908203,
      "logps/rejected": -107.48090362548828,
      "loss": 0.0207,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1361169815063477,
      "rewards/margins": 3.866753101348877,
      "rewards/rejected": -0.7306362390518188,
      "step": 853
    },
    {
      "epoch": 0.3416,
      "grad_norm": 1.4234484434127808,
      "learning_rate": 8.862666666666666e-07,
      "logits/chosen": -2.3079004287719727,
      "logits/rejected": -2.765338897705078,
      "logps/chosen": -75.39707946777344,
      "logps/rejected": -91.97970581054688,
      "loss": 0.0237,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5789990425109863,
      "rewards/margins": 3.7809276580810547,
      "rewards/rejected": -1.201928734779358,
      "step": 854
    },
    {
      "epoch": 0.342,
      "grad_norm": 0.7049193382263184,
      "learning_rate": 8.861333333333333e-07,
      "logits/chosen": -2.3416748046875,
      "logits/rejected": -2.3254454135894775,
      "logps/chosen": -91.78579711914062,
      "logps/rejected": -114.45436096191406,
      "loss": 0.0094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7633891105651855,
      "rewards/margins": 4.9308061599731445,
      "rewards/rejected": -1.1674175262451172,
      "step": 855
    },
    {
      "epoch": 0.3424,
      "grad_norm": 1.103904366493225,
      "learning_rate": 8.86e-07,
      "logits/chosen": -2.199080467224121,
      "logits/rejected": -3.053528070449829,
      "logps/chosen": -115.43734741210938,
      "logps/rejected": -120.31016540527344,
      "loss": 0.0124,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6580474376678467,
      "rewards/margins": 5.062779426574707,
      "rewards/rejected": -1.40473210811615,
      "step": 856
    },
    {
      "epoch": 0.3428,
      "grad_norm": 0.6364588141441345,
      "learning_rate": 8.858666666666667e-07,
      "logits/chosen": -2.168372392654419,
      "logits/rejected": -2.669931411743164,
      "logps/chosen": -97.4451904296875,
      "logps/rejected": -128.6907196044922,
      "loss": 0.0114,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.118623733520508,
      "rewards/margins": 4.469459533691406,
      "rewards/rejected": -1.3508358001708984,
      "step": 857
    },
    {
      "epoch": 0.3432,
      "grad_norm": 1.2302404642105103,
      "learning_rate": 8.857333333333334e-07,
      "logits/chosen": -2.4763612747192383,
      "logits/rejected": -3.116987466812134,
      "logps/chosen": -200.47735595703125,
      "logps/rejected": -159.33071899414062,
      "loss": 0.0131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8222808837890625,
      "rewards/margins": 4.406981468200684,
      "rewards/rejected": -1.584700345993042,
      "step": 858
    },
    {
      "epoch": 0.3436,
      "grad_norm": 0.5875187516212463,
      "learning_rate": 8.856e-07,
      "logits/chosen": -2.184408187866211,
      "logits/rejected": -3.2400293350219727,
      "logps/chosen": -163.20770263671875,
      "logps/rejected": -106.66328430175781,
      "loss": 0.0084,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.3241801261901855,
      "rewards/margins": 4.782444953918457,
      "rewards/rejected": -0.4582653343677521,
      "step": 859
    },
    {
      "epoch": 0.344,
      "grad_norm": 2.824472188949585,
      "learning_rate": 8.854666666666666e-07,
      "logits/chosen": -2.4408607482910156,
      "logits/rejected": -2.0185317993164062,
      "logps/chosen": -114.72798919677734,
      "logps/rejected": -100.51312255859375,
      "loss": 0.0455,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8285317420959473,
      "rewards/margins": 3.1632137298583984,
      "rewards/rejected": -0.3346821069717407,
      "step": 860
    },
    {
      "epoch": 0.3444,
      "grad_norm": 1.6561843156814575,
      "learning_rate": 8.853333333333332e-07,
      "logits/chosen": -2.395325183868408,
      "logits/rejected": -2.9110279083251953,
      "logps/chosen": -98.91046142578125,
      "logps/rejected": -151.85385131835938,
      "loss": 0.0216,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.137296676635742,
      "rewards/margins": 4.072588920593262,
      "rewards/rejected": -0.93529212474823,
      "step": 861
    },
    {
      "epoch": 0.3448,
      "grad_norm": 0.9106718897819519,
      "learning_rate": 8.851999999999999e-07,
      "logits/chosen": -1.9229803085327148,
      "logits/rejected": -2.958369016647339,
      "logps/chosen": -70.09628295898438,
      "logps/rejected": -103.88026428222656,
      "loss": 0.0153,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3935041427612305,
      "rewards/margins": 4.503819942474365,
      "rewards/rejected": -1.1103157997131348,
      "step": 862
    },
    {
      "epoch": 0.3452,
      "grad_norm": 4.759724140167236,
      "learning_rate": 8.850666666666666e-07,
      "logits/chosen": -2.7100749015808105,
      "logits/rejected": -3.065910577774048,
      "logps/chosen": -171.2465362548828,
      "logps/rejected": -125.11653137207031,
      "loss": 0.0674,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9960968494415283,
      "rewards/margins": 3.529022216796875,
      "rewards/rejected": -1.5329253673553467,
      "step": 863
    },
    {
      "epoch": 0.3456,
      "grad_norm": 1.1635247468948364,
      "learning_rate": 8.849333333333333e-07,
      "logits/chosen": -2.166440010070801,
      "logits/rejected": -2.65462589263916,
      "logps/chosen": -145.34927368164062,
      "logps/rejected": -170.6249237060547,
      "loss": 0.0126,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0361413955688477,
      "rewards/margins": 5.086309432983398,
      "rewards/rejected": -2.0501677989959717,
      "step": 864
    },
    {
      "epoch": 0.346,
      "grad_norm": 0.42896825075149536,
      "learning_rate": 8.848e-07,
      "logits/chosen": -1.864673376083374,
      "logits/rejected": -2.519920825958252,
      "logps/chosen": -67.66694641113281,
      "logps/rejected": -97.79374694824219,
      "loss": 0.0069,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3970131874084473,
      "rewards/margins": 5.001409530639648,
      "rewards/rejected": -1.604396104812622,
      "step": 865
    },
    {
      "epoch": 0.3464,
      "grad_norm": 0.5232754349708557,
      "learning_rate": 8.846666666666667e-07,
      "logits/chosen": -2.185178518295288,
      "logits/rejected": -2.6338019371032715,
      "logps/chosen": -79.63853454589844,
      "logps/rejected": -115.90737915039062,
      "loss": 0.0072,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.479515552520752,
      "rewards/margins": 4.976128578186035,
      "rewards/rejected": -1.4966129064559937,
      "step": 866
    },
    {
      "epoch": 0.3468,
      "grad_norm": 0.8470064401626587,
      "learning_rate": 8.845333333333333e-07,
      "logits/chosen": -2.102217435836792,
      "logits/rejected": -1.9876564741134644,
      "logps/chosen": -94.93409729003906,
      "logps/rejected": -104.16300964355469,
      "loss": 0.012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3304104804992676,
      "rewards/margins": 4.418717384338379,
      "rewards/rejected": -2.0883071422576904,
      "step": 867
    },
    {
      "epoch": 0.3472,
      "grad_norm": 0.9724330306053162,
      "learning_rate": 8.844e-07,
      "logits/chosen": -2.2165794372558594,
      "logits/rejected": -2.4058902263641357,
      "logps/chosen": -113.5841064453125,
      "logps/rejected": -163.91018676757812,
      "loss": 0.0141,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.538698196411133,
      "rewards/margins": 4.932177543640137,
      "rewards/rejected": -1.393479585647583,
      "step": 868
    },
    {
      "epoch": 0.3476,
      "grad_norm": 6.082474231719971,
      "learning_rate": 8.842666666666666e-07,
      "logits/chosen": -1.4908487796783447,
      "logits/rejected": -2.3796963691711426,
      "logps/chosen": -116.43740844726562,
      "logps/rejected": -134.56393432617188,
      "loss": 0.0852,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4052035808563232,
      "rewards/margins": 3.6421597003936768,
      "rewards/rejected": -1.236956000328064,
      "step": 869
    },
    {
      "epoch": 0.348,
      "grad_norm": 1.1151636838912964,
      "learning_rate": 8.841333333333333e-07,
      "logits/chosen": -2.3375914096832275,
      "logits/rejected": -3.4069390296936035,
      "logps/chosen": -153.53387451171875,
      "logps/rejected": -165.39486694335938,
      "loss": 0.0181,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7180085182189941,
      "rewards/margins": 4.10216760635376,
      "rewards/rejected": -2.3841590881347656,
      "step": 870
    },
    {
      "epoch": 0.3484,
      "grad_norm": 0.49653905630111694,
      "learning_rate": 8.839999999999999e-07,
      "logits/chosen": -2.2950596809387207,
      "logits/rejected": -2.5230369567871094,
      "logps/chosen": -144.53262329101562,
      "logps/rejected": -121.90235900878906,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8074307441711426,
      "rewards/margins": 5.06284236907959,
      "rewards/rejected": -1.2554118633270264,
      "step": 871
    },
    {
      "epoch": 0.3488,
      "grad_norm": 0.51955646276474,
      "learning_rate": 8.838666666666666e-07,
      "logits/chosen": -2.41019344329834,
      "logits/rejected": -2.5512771606445312,
      "logps/chosen": -94.357421875,
      "logps/rejected": -98.88490295410156,
      "loss": 0.0099,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0930988788604736,
      "rewards/margins": 4.6302900314331055,
      "rewards/rejected": -1.537191390991211,
      "step": 872
    },
    {
      "epoch": 0.3492,
      "grad_norm": 2.2918264865875244,
      "learning_rate": 8.837333333333333e-07,
      "logits/chosen": -2.2886595726013184,
      "logits/rejected": -2.9691193103790283,
      "logps/chosen": -104.18736267089844,
      "logps/rejected": -110.66567993164062,
      "loss": 0.0369,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7842319011688232,
      "rewards/margins": 3.8768482208251953,
      "rewards/rejected": -1.092616319656372,
      "step": 873
    },
    {
      "epoch": 0.3496,
      "grad_norm": 7.432302474975586,
      "learning_rate": 8.836e-07,
      "logits/chosen": -2.050313949584961,
      "logits/rejected": -2.7624666690826416,
      "logps/chosen": -94.78654479980469,
      "logps/rejected": -128.82118225097656,
      "loss": 0.1098,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2826194763183594,
      "rewards/margins": 2.4228851795196533,
      "rewards/rejected": -1.1402655839920044,
      "step": 874
    },
    {
      "epoch": 0.35,
      "grad_norm": 12.013673782348633,
      "learning_rate": 8.834666666666666e-07,
      "logits/chosen": -2.6092376708984375,
      "logits/rejected": -3.005934238433838,
      "logps/chosen": -153.82943725585938,
      "logps/rejected": -147.46041870117188,
      "loss": 0.1994,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0723838806152344,
      "rewards/margins": 3.132290840148926,
      "rewards/rejected": -1.0599068403244019,
      "step": 875
    },
    {
      "epoch": 0.3504,
      "grad_norm": 1.3279967308044434,
      "learning_rate": 8.833333333333333e-07,
      "logits/chosen": -2.309670925140381,
      "logits/rejected": -2.554323196411133,
      "logps/chosen": -85.7931900024414,
      "logps/rejected": -78.12262725830078,
      "loss": 0.0215,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.069638729095459,
      "rewards/margins": 3.8883776664733887,
      "rewards/rejected": -0.8187389373779297,
      "step": 876
    },
    {
      "epoch": 0.3508,
      "grad_norm": 0.9132638573646545,
      "learning_rate": 8.832e-07,
      "logits/chosen": -2.035719871520996,
      "logits/rejected": -2.867403030395508,
      "logps/chosen": -66.60893249511719,
      "logps/rejected": -124.575439453125,
      "loss": 0.013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.647702932357788,
      "rewards/margins": 4.345724105834961,
      "rewards/rejected": -1.6980209350585938,
      "step": 877
    },
    {
      "epoch": 0.3512,
      "grad_norm": 0.6568717956542969,
      "learning_rate": 8.830666666666667e-07,
      "logits/chosen": -2.156785011291504,
      "logits/rejected": -1.8389700651168823,
      "logps/chosen": -90.63113403320312,
      "logps/rejected": -87.6791000366211,
      "loss": 0.0114,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3012959957122803,
      "rewards/margins": 4.55023193359375,
      "rewards/rejected": -1.2489360570907593,
      "step": 878
    },
    {
      "epoch": 0.3516,
      "grad_norm": 0.2165733128786087,
      "learning_rate": 8.829333333333334e-07,
      "logits/chosen": -2.1443028450012207,
      "logits/rejected": -2.7998714447021484,
      "logps/chosen": -152.88970947265625,
      "logps/rejected": -167.30859375,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.198339462280273,
      "rewards/margins": 6.048340797424316,
      "rewards/rejected": -1.850001573562622,
      "step": 879
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.36015331745147705,
      "learning_rate": 8.827999999999999e-07,
      "logits/chosen": -2.619823932647705,
      "logits/rejected": -2.6963953971862793,
      "logps/chosen": -188.76248168945312,
      "logps/rejected": -176.10357666015625,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.515622138977051,
      "rewards/margins": 5.781351089477539,
      "rewards/rejected": -2.2657291889190674,
      "step": 880
    },
    {
      "epoch": 0.3524,
      "grad_norm": 15.39952278137207,
      "learning_rate": 8.826666666666666e-07,
      "logits/chosen": -2.2639145851135254,
      "logits/rejected": -2.365785837173462,
      "logps/chosen": -147.4745330810547,
      "logps/rejected": -100.21082305908203,
      "loss": 0.2756,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.398685485124588,
      "rewards/margins": 1.1621837615966797,
      "rewards/rejected": -0.7634983062744141,
      "step": 881
    },
    {
      "epoch": 0.3528,
      "grad_norm": 0.8220419883728027,
      "learning_rate": 8.825333333333332e-07,
      "logits/chosen": -2.221325397491455,
      "logits/rejected": -3.34364652633667,
      "logps/chosen": -117.7776870727539,
      "logps/rejected": -135.71878051757812,
      "loss": 0.0117,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5357742309570312,
      "rewards/margins": 4.700972080230713,
      "rewards/rejected": -2.1651978492736816,
      "step": 882
    },
    {
      "epoch": 0.3532,
      "grad_norm": 3.9799816608428955,
      "learning_rate": 8.823999999999999e-07,
      "logits/chosen": -2.1073148250579834,
      "logits/rejected": -2.3850746154785156,
      "logps/chosen": -114.50975036621094,
      "logps/rejected": -103.12480926513672,
      "loss": 0.0652,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.727975606918335,
      "rewards/margins": 3.351803779602051,
      "rewards/rejected": -0.6238281726837158,
      "step": 883
    },
    {
      "epoch": 0.3536,
      "grad_norm": 1.267508625984192,
      "learning_rate": 8.822666666666666e-07,
      "logits/chosen": -2.122365951538086,
      "logits/rejected": -2.722792148590088,
      "logps/chosen": -108.13386535644531,
      "logps/rejected": -121.44935607910156,
      "loss": 0.0144,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.347060203552246,
      "rewards/margins": 4.64450740814209,
      "rewards/rejected": -1.2974472045898438,
      "step": 884
    },
    {
      "epoch": 0.354,
      "grad_norm": 0.15673035383224487,
      "learning_rate": 8.821333333333333e-07,
      "logits/chosen": -2.586277723312378,
      "logits/rejected": -2.708143472671509,
      "logps/chosen": -284.2630310058594,
      "logps/rejected": -149.38595581054688,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.947699069976807,
      "rewards/margins": 6.960450172424316,
      "rewards/rejected": -2.0127511024475098,
      "step": 885
    },
    {
      "epoch": 0.3544,
      "grad_norm": 0.10520278662443161,
      "learning_rate": 8.82e-07,
      "logits/chosen": -2.2914724349975586,
      "logits/rejected": -2.654284954071045,
      "logps/chosen": -157.473876953125,
      "logps/rejected": -139.12596130371094,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 5.013869285583496,
      "rewards/margins": 6.680793762207031,
      "rewards/rejected": -1.6669243574142456,
      "step": 886
    },
    {
      "epoch": 0.3548,
      "grad_norm": 0.9169249534606934,
      "learning_rate": 8.818666666666667e-07,
      "logits/chosen": -1.9253827333450317,
      "logits/rejected": -3.0617008209228516,
      "logps/chosen": -127.30502319335938,
      "logps/rejected": -125.77937316894531,
      "loss": 0.0124,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.050660610198975,
      "rewards/margins": 5.234200477600098,
      "rewards/rejected": -1.183539628982544,
      "step": 887
    },
    {
      "epoch": 0.3552,
      "grad_norm": 3.5739970207214355,
      "learning_rate": 8.817333333333334e-07,
      "logits/chosen": -2.007051944732666,
      "logits/rejected": -2.7731432914733887,
      "logps/chosen": -168.03176879882812,
      "logps/rejected": -104.1241455078125,
      "loss": 0.0487,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3066298961639404,
      "rewards/margins": 2.9984402656555176,
      "rewards/rejected": -1.6918103694915771,
      "step": 888
    },
    {
      "epoch": 0.3556,
      "grad_norm": 2.6579959392547607,
      "learning_rate": 8.816000000000001e-07,
      "logits/chosen": -2.1757283210754395,
      "logits/rejected": -2.8026511669158936,
      "logps/chosen": -141.8468475341797,
      "logps/rejected": -117.11779022216797,
      "loss": 0.0305,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.206937313079834,
      "rewards/margins": 4.779445648193359,
      "rewards/rejected": -1.5725082159042358,
      "step": 889
    },
    {
      "epoch": 0.356,
      "grad_norm": 3.939337730407715,
      "learning_rate": 8.814666666666665e-07,
      "logits/chosen": -2.3439788818359375,
      "logits/rejected": -2.304750442504883,
      "logps/chosen": -118.08889770507812,
      "logps/rejected": -95.19756317138672,
      "loss": 0.0763,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2186617851257324,
      "rewards/margins": 2.6627330780029297,
      "rewards/rejected": -0.4440712034702301,
      "step": 890
    },
    {
      "epoch": 0.3564,
      "grad_norm": 1.148431658744812,
      "learning_rate": 8.813333333333332e-07,
      "logits/chosen": -2.0069639682769775,
      "logits/rejected": -2.2123022079467773,
      "logps/chosen": -76.90491485595703,
      "logps/rejected": -105.94549560546875,
      "loss": 0.0163,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.10101318359375,
      "rewards/margins": 4.2972002029418945,
      "rewards/rejected": -2.1961872577667236,
      "step": 891
    },
    {
      "epoch": 0.3568,
      "grad_norm": 0.11259125173091888,
      "learning_rate": 8.811999999999999e-07,
      "logits/chosen": -2.5054500102996826,
      "logits/rejected": -2.7357935905456543,
      "logps/chosen": -106.74726104736328,
      "logps/rejected": -121.3192138671875,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4550156593322754,
      "rewards/margins": 6.316105365753174,
      "rewards/rejected": -2.8610897064208984,
      "step": 892
    },
    {
      "epoch": 0.3572,
      "grad_norm": 4.069399833679199,
      "learning_rate": 8.810666666666666e-07,
      "logits/chosen": -2.3295538425445557,
      "logits/rejected": -1.9579212665557861,
      "logps/chosen": -136.60269165039062,
      "logps/rejected": -164.30789184570312,
      "loss": 0.0706,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6884593963623047,
      "rewards/margins": 2.7965431213378906,
      "rewards/rejected": -1.108083724975586,
      "step": 893
    },
    {
      "epoch": 0.3576,
      "grad_norm": 0.4342983663082123,
      "learning_rate": 8.809333333333333e-07,
      "logits/chosen": -2.477869749069214,
      "logits/rejected": -2.5138745307922363,
      "logps/chosen": -129.8585205078125,
      "logps/rejected": -163.15679931640625,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.643235445022583,
      "rewards/margins": 5.340372085571289,
      "rewards/rejected": -1.6971367597579956,
      "step": 894
    },
    {
      "epoch": 0.358,
      "grad_norm": 0.07338424026966095,
      "learning_rate": 8.808e-07,
      "logits/chosen": -2.4253220558166504,
      "logits/rejected": -2.475712537765503,
      "logps/chosen": -139.29824829101562,
      "logps/rejected": -117.582275390625,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.9017014503479,
      "rewards/margins": 6.753366470336914,
      "rewards/rejected": -1.8516647815704346,
      "step": 895
    },
    {
      "epoch": 0.3584,
      "grad_norm": 0.2257143259048462,
      "learning_rate": 8.806666666666667e-07,
      "logits/chosen": -2.5352439880371094,
      "logits/rejected": -2.5803582668304443,
      "logps/chosen": -137.37191772460938,
      "logps/rejected": -132.83560180664062,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.071933746337891,
      "rewards/margins": 5.970492362976074,
      "rewards/rejected": -1.8985588550567627,
      "step": 896
    },
    {
      "epoch": 0.3588,
      "grad_norm": 1.6319419145584106,
      "learning_rate": 8.805333333333333e-07,
      "logits/chosen": -2.1593267917633057,
      "logits/rejected": -2.9646811485290527,
      "logps/chosen": -124.55751037597656,
      "logps/rejected": -123.99508666992188,
      "loss": 0.028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.657118558883667,
      "rewards/margins": 4.192355155944824,
      "rewards/rejected": -1.5352368354797363,
      "step": 897
    },
    {
      "epoch": 0.3592,
      "grad_norm": 1.784935712814331,
      "learning_rate": 8.804e-07,
      "logits/chosen": -2.247615337371826,
      "logits/rejected": -2.439605712890625,
      "logps/chosen": -195.52584838867188,
      "logps/rejected": -112.63807678222656,
      "loss": 0.0234,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1605920791625977,
      "rewards/margins": 4.494100570678711,
      "rewards/rejected": -1.3335083723068237,
      "step": 898
    },
    {
      "epoch": 0.3596,
      "grad_norm": 3.982699394226074,
      "learning_rate": 8.802666666666666e-07,
      "logits/chosen": -2.700985908508301,
      "logits/rejected": -2.685645818710327,
      "logps/chosen": -116.87405395507812,
      "logps/rejected": -115.51541137695312,
      "loss": 0.0521,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0621390342712402,
      "rewards/margins": 3.3258166313171387,
      "rewards/rejected": -1.2636775970458984,
      "step": 899
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.22945678234100342,
      "learning_rate": 8.801333333333332e-07,
      "logits/chosen": -2.5137484073638916,
      "logits/rejected": -3.411806106567383,
      "logps/chosen": -186.37197875976562,
      "logps/rejected": -116.92700958251953,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.611638069152832,
      "rewards/margins": 5.759393215179443,
      "rewards/rejected": -1.1477553844451904,
      "step": 900
    },
    {
      "epoch": 0.3604,
      "grad_norm": 0.935498058795929,
      "learning_rate": 8.799999999999999e-07,
      "logits/chosen": -2.3589138984680176,
      "logits/rejected": -2.9366087913513184,
      "logps/chosen": -127.11821746826172,
      "logps/rejected": -137.95382690429688,
      "loss": 0.0159,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9527900218963623,
      "rewards/margins": 4.350186347961426,
      "rewards/rejected": -1.3973965644836426,
      "step": 901
    },
    {
      "epoch": 0.3608,
      "grad_norm": 0.7515887022018433,
      "learning_rate": 8.798666666666666e-07,
      "logits/chosen": -2.0721054077148438,
      "logits/rejected": -2.796375274658203,
      "logps/chosen": -87.93319702148438,
      "logps/rejected": -120.72045135498047,
      "loss": 0.0101,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0524210929870605,
      "rewards/margins": 4.660200119018555,
      "rewards/rejected": -2.607779026031494,
      "step": 902
    },
    {
      "epoch": 0.3612,
      "grad_norm": 0.9702097773551941,
      "learning_rate": 8.797333333333333e-07,
      "logits/chosen": -2.4127087593078613,
      "logits/rejected": -2.904628276824951,
      "logps/chosen": -198.80990600585938,
      "logps/rejected": -133.9188232421875,
      "loss": 0.0079,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8812766075134277,
      "rewards/margins": 5.424795150756836,
      "rewards/rejected": -2.54351806640625,
      "step": 903
    },
    {
      "epoch": 0.3616,
      "grad_norm": 3.113576650619507,
      "learning_rate": 8.796e-07,
      "logits/chosen": -2.0203518867492676,
      "logits/rejected": -2.863724708557129,
      "logps/chosen": -107.77665710449219,
      "logps/rejected": -110.29999542236328,
      "loss": 0.0438,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4964637756347656,
      "rewards/margins": 3.3737680912017822,
      "rewards/rejected": -1.8773040771484375,
      "step": 904
    },
    {
      "epoch": 0.362,
      "grad_norm": 0.6972790956497192,
      "learning_rate": 8.794666666666666e-07,
      "logits/chosen": -2.7922723293304443,
      "logits/rejected": -2.9313182830810547,
      "logps/chosen": -195.00502014160156,
      "logps/rejected": -141.7165069580078,
      "loss": 0.0079,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.078359365463257,
      "rewards/margins": 5.25956916809082,
      "rewards/rejected": -2.1812095642089844,
      "step": 905
    },
    {
      "epoch": 0.3624,
      "grad_norm": 1.4919838905334473,
      "learning_rate": 8.793333333333333e-07,
      "logits/chosen": -2.253086566925049,
      "logits/rejected": -2.4002459049224854,
      "logps/chosen": -85.276123046875,
      "logps/rejected": -131.39117431640625,
      "loss": 0.0261,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2088942527770996,
      "rewards/margins": 3.635317802429199,
      "rewards/rejected": -1.4264233112335205,
      "step": 906
    },
    {
      "epoch": 0.3628,
      "grad_norm": 1.1419857740402222,
      "learning_rate": 8.792e-07,
      "logits/chosen": -2.267204761505127,
      "logits/rejected": -2.754969596862793,
      "logps/chosen": -170.79913330078125,
      "logps/rejected": -130.84521484375,
      "loss": 0.0192,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.325202226638794,
      "rewards/margins": 4.006586074829102,
      "rewards/rejected": -2.6813840866088867,
      "step": 907
    },
    {
      "epoch": 0.3632,
      "grad_norm": 9.029319763183594,
      "learning_rate": 8.790666666666666e-07,
      "logits/chosen": -1.9519243240356445,
      "logits/rejected": -2.7460989952087402,
      "logps/chosen": -66.86267852783203,
      "logps/rejected": -101.789306640625,
      "loss": 0.1389,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8573285341262817,
      "rewards/margins": 3.5138609409332275,
      "rewards/rejected": -1.6565322875976562,
      "step": 908
    },
    {
      "epoch": 0.3636,
      "grad_norm": 2.6672120094299316,
      "learning_rate": 8.789333333333333e-07,
      "logits/chosen": -2.7200684547424316,
      "logits/rejected": -3.2676639556884766,
      "logps/chosen": -153.9306640625,
      "logps/rejected": -136.94284057617188,
      "loss": 0.0303,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7191483974456787,
      "rewards/margins": 5.105963230133057,
      "rewards/rejected": -2.386814594268799,
      "step": 909
    },
    {
      "epoch": 0.364,
      "grad_norm": 3.944885492324829,
      "learning_rate": 8.788e-07,
      "logits/chosen": -2.2033636569976807,
      "logits/rejected": -2.761070728302002,
      "logps/chosen": -164.4838104248047,
      "logps/rejected": -109.11847686767578,
      "loss": 0.0418,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.585780382156372,
      "rewards/margins": 3.97127628326416,
      "rewards/rejected": -0.38549575209617615,
      "step": 910
    },
    {
      "epoch": 0.3644,
      "grad_norm": 0.1461348980665207,
      "learning_rate": 8.786666666666666e-07,
      "logits/chosen": -2.403510093688965,
      "logits/rejected": -3.040091037750244,
      "logps/chosen": -212.54322814941406,
      "logps/rejected": -138.00204467773438,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.087667942047119,
      "rewards/margins": 6.170294761657715,
      "rewards/rejected": -2.0826268196105957,
      "step": 911
    },
    {
      "epoch": 0.3648,
      "grad_norm": 0.7785078883171082,
      "learning_rate": 8.785333333333333e-07,
      "logits/chosen": -2.5697028636932373,
      "logits/rejected": -2.7624669075012207,
      "logps/chosen": -142.82066345214844,
      "logps/rejected": -238.0677490234375,
      "loss": 0.0072,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.2685956954956055,
      "rewards/margins": 5.582239151000977,
      "rewards/rejected": -1.3136433362960815,
      "step": 912
    },
    {
      "epoch": 0.3652,
      "grad_norm": 5.239083290100098,
      "learning_rate": 8.783999999999999e-07,
      "logits/chosen": -2.1477317810058594,
      "logits/rejected": -2.6741347312927246,
      "logps/chosen": -84.64513397216797,
      "logps/rejected": -99.28131866455078,
      "loss": 0.0656,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1485800743103027,
      "rewards/margins": 3.2265262603759766,
      "rewards/rejected": -1.0779460668563843,
      "step": 913
    },
    {
      "epoch": 0.3656,
      "grad_norm": 0.28821200132369995,
      "learning_rate": 8.782666666666666e-07,
      "logits/chosen": -2.2156262397766113,
      "logits/rejected": -2.749918222427368,
      "logps/chosen": -73.89797973632812,
      "logps/rejected": -133.52557373046875,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2710461616516113,
      "rewards/margins": 5.49123477935791,
      "rewards/rejected": -2.220188856124878,
      "step": 914
    },
    {
      "epoch": 0.366,
      "grad_norm": 0.9265820384025574,
      "learning_rate": 8.781333333333333e-07,
      "logits/chosen": -1.990908145904541,
      "logits/rejected": -2.1638026237487793,
      "logps/chosen": -67.50108337402344,
      "logps/rejected": -82.89474487304688,
      "loss": 0.0157,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.756049156188965,
      "rewards/margins": 4.416865348815918,
      "rewards/rejected": -0.6608161926269531,
      "step": 915
    },
    {
      "epoch": 0.3664,
      "grad_norm": 0.8596131801605225,
      "learning_rate": 8.78e-07,
      "logits/chosen": -2.088934898376465,
      "logits/rejected": -2.6664750576019287,
      "logps/chosen": -92.65727233886719,
      "logps/rejected": -144.2718505859375,
      "loss": 0.0113,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3570504188537598,
      "rewards/margins": 4.860579967498779,
      "rewards/rejected": -1.5035293102264404,
      "step": 916
    },
    {
      "epoch": 0.3668,
      "grad_norm": 1.1314600706100464,
      "learning_rate": 8.778666666666667e-07,
      "logits/chosen": -2.6154212951660156,
      "logits/rejected": -3.03096866607666,
      "logps/chosen": -211.6890411376953,
      "logps/rejected": -114.10147094726562,
      "loss": 0.0123,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3063366413116455,
      "rewards/margins": 5.787847518920898,
      "rewards/rejected": -2.481511116027832,
      "step": 917
    },
    {
      "epoch": 0.3672,
      "grad_norm": 2.6710846424102783,
      "learning_rate": 8.777333333333333e-07,
      "logits/chosen": -1.7407257556915283,
      "logits/rejected": -2.40986967086792,
      "logps/chosen": -97.62662506103516,
      "logps/rejected": -162.34298706054688,
      "loss": 0.0351,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3051040172576904,
      "rewards/margins": 3.967667579650879,
      "rewards/rejected": -1.6625633239746094,
      "step": 918
    },
    {
      "epoch": 0.3676,
      "grad_norm": 1.587469220161438,
      "learning_rate": 8.776e-07,
      "logits/chosen": -3.037346363067627,
      "logits/rejected": -2.785252094268799,
      "logps/chosen": -242.93130493164062,
      "logps/rejected": -143.9259796142578,
      "loss": 0.0184,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.049297332763672,
      "rewards/margins": 3.988391637802124,
      "rewards/rejected": -1.9390943050384521,
      "step": 919
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.6171916723251343,
      "learning_rate": 8.774666666666666e-07,
      "logits/chosen": -2.3785269260406494,
      "logits/rejected": -2.879246473312378,
      "logps/chosen": -119.95054626464844,
      "logps/rejected": -126.27638244628906,
      "loss": 0.0077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8790078163146973,
      "rewards/margins": 5.8735270500183105,
      "rewards/rejected": -1.9945194721221924,
      "step": 920
    },
    {
      "epoch": 0.3684,
      "grad_norm": 4.2291789054870605,
      "learning_rate": 8.773333333333332e-07,
      "logits/chosen": -2.0066232681274414,
      "logits/rejected": -2.6366636753082275,
      "logps/chosen": -78.04205322265625,
      "logps/rejected": -111.42103576660156,
      "loss": 0.059,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.559264063835144,
      "rewards/margins": 2.8813695907592773,
      "rewards/rejected": -1.3221054077148438,
      "step": 921
    },
    {
      "epoch": 0.3688,
      "grad_norm": 2.249873638153076,
      "learning_rate": 8.771999999999999e-07,
      "logits/chosen": -2.756678581237793,
      "logits/rejected": -2.8355283737182617,
      "logps/chosen": -310.49267578125,
      "logps/rejected": -168.1672821044922,
      "loss": 0.0241,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.438441514968872,
      "rewards/margins": 4.3569655418396,
      "rewards/rejected": -1.9185237884521484,
      "step": 922
    },
    {
      "epoch": 0.3692,
      "grad_norm": 0.8335833549499512,
      "learning_rate": 8.770666666666666e-07,
      "logits/chosen": -2.035412073135376,
      "logits/rejected": -2.720742702484131,
      "logps/chosen": -90.12281799316406,
      "logps/rejected": -104.66405487060547,
      "loss": 0.016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9729981422424316,
      "rewards/margins": 4.14409065246582,
      "rewards/rejected": -2.1710927486419678,
      "step": 923
    },
    {
      "epoch": 0.3696,
      "grad_norm": 8.476115226745605,
      "learning_rate": 8.769333333333333e-07,
      "logits/chosen": -2.9475607872009277,
      "logits/rejected": -2.924838066101074,
      "logps/chosen": -291.4437255859375,
      "logps/rejected": -136.28231811523438,
      "loss": 0.0975,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.310176134109497,
      "rewards/margins": 2.921942949295044,
      "rewards/rejected": -1.6117668151855469,
      "step": 924
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.446690082550049,
      "learning_rate": 8.768e-07,
      "logits/chosen": -2.630631446838379,
      "logits/rejected": -2.695394992828369,
      "logps/chosen": -109.2536392211914,
      "logps/rejected": -127.04269409179688,
      "loss": 0.0325,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.375211715698242,
      "rewards/margins": 4.248255729675293,
      "rewards/rejected": -1.8730437755584717,
      "step": 925
    },
    {
      "epoch": 0.3704,
      "grad_norm": 3.0159308910369873,
      "learning_rate": 8.766666666666667e-07,
      "logits/chosen": -2.341381072998047,
      "logits/rejected": -2.931980609893799,
      "logps/chosen": -171.73287963867188,
      "logps/rejected": -152.3045654296875,
      "loss": 0.0325,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.002239227294922,
      "rewards/margins": 3.66500186920166,
      "rewards/rejected": -1.6627625226974487,
      "step": 926
    },
    {
      "epoch": 0.3708,
      "grad_norm": 1.237661361694336,
      "learning_rate": 8.765333333333333e-07,
      "logits/chosen": -2.069611072540283,
      "logits/rejected": -2.4156529903411865,
      "logps/chosen": -64.79780578613281,
      "logps/rejected": -98.262451171875,
      "loss": 0.0163,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.944182872772217,
      "rewards/margins": 4.772252082824707,
      "rewards/rejected": -1.8280693292617798,
      "step": 927
    },
    {
      "epoch": 0.3712,
      "grad_norm": 1.4492697715759277,
      "learning_rate": 8.763999999999999e-07,
      "logits/chosen": -2.0623745918273926,
      "logits/rejected": -2.5018887519836426,
      "logps/chosen": -105.72285461425781,
      "logps/rejected": -146.84201049804688,
      "loss": 0.02,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0180420875549316,
      "rewards/margins": 4.037836074829102,
      "rewards/rejected": -2.019793748855591,
      "step": 928
    },
    {
      "epoch": 0.3716,
      "grad_norm": 2.4171085357666016,
      "learning_rate": 8.762666666666666e-07,
      "logits/chosen": -2.3338823318481445,
      "logits/rejected": -1.8990399837493896,
      "logps/chosen": -93.39051818847656,
      "logps/rejected": -100.71107482910156,
      "loss": 0.0343,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0294976234436035,
      "rewards/margins": 3.5542490482330322,
      "rewards/rejected": -0.5247513055801392,
      "step": 929
    },
    {
      "epoch": 0.372,
      "grad_norm": 0.07276073098182678,
      "learning_rate": 8.761333333333333e-07,
      "logits/chosen": -2.511284351348877,
      "logits/rejected": -3.428342342376709,
      "logps/chosen": -163.94137573242188,
      "logps/rejected": -151.0337677001953,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.423464298248291,
      "rewards/margins": 7.041274070739746,
      "rewards/rejected": -2.617809772491455,
      "step": 930
    },
    {
      "epoch": 0.3724,
      "grad_norm": 2.6238555908203125,
      "learning_rate": 8.76e-07,
      "logits/chosen": -1.9989675283432007,
      "logits/rejected": -2.2188515663146973,
      "logps/chosen": -64.919921875,
      "logps/rejected": -92.72505950927734,
      "loss": 0.0271,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8761134147644043,
      "rewards/margins": 4.164148330688477,
      "rewards/rejected": -1.2880349159240723,
      "step": 931
    },
    {
      "epoch": 0.3728,
      "grad_norm": 1.5379114151000977,
      "learning_rate": 8.758666666666666e-07,
      "logits/chosen": -2.229048252105713,
      "logits/rejected": -2.5269460678100586,
      "logps/chosen": -99.92932891845703,
      "logps/rejected": -168.4128875732422,
      "loss": 0.019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.122351884841919,
      "rewards/margins": 4.751825332641602,
      "rewards/rejected": -1.6294732093811035,
      "step": 932
    },
    {
      "epoch": 0.3732,
      "grad_norm": 0.7900665998458862,
      "learning_rate": 8.757333333333333e-07,
      "logits/chosen": -2.6363959312438965,
      "logits/rejected": -2.7033722400665283,
      "logps/chosen": -168.21188354492188,
      "logps/rejected": -191.33538818359375,
      "loss": 0.0119,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7696471214294434,
      "rewards/margins": 4.672415256500244,
      "rewards/rejected": -1.9027678966522217,
      "step": 933
    },
    {
      "epoch": 0.3736,
      "grad_norm": 0.8384228944778442,
      "learning_rate": 8.756e-07,
      "logits/chosen": -2.419572114944458,
      "logits/rejected": -2.5776290893554688,
      "logps/chosen": -141.12136840820312,
      "logps/rejected": -121.87490844726562,
      "loss": 0.0119,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5105679035186768,
      "rewards/margins": 5.164333343505859,
      "rewards/rejected": -1.6537652015686035,
      "step": 934
    },
    {
      "epoch": 0.374,
      "grad_norm": 0.9747537970542908,
      "learning_rate": 8.754666666666666e-07,
      "logits/chosen": -2.080491065979004,
      "logits/rejected": -2.6582484245300293,
      "logps/chosen": -184.55685424804688,
      "logps/rejected": -101.40476989746094,
      "loss": 0.0128,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9451904296875,
      "rewards/margins": 4.428072452545166,
      "rewards/rejected": -1.4828819036483765,
      "step": 935
    },
    {
      "epoch": 0.3744,
      "grad_norm": 2.3438408374786377,
      "learning_rate": 8.753333333333332e-07,
      "logits/chosen": -1.8803205490112305,
      "logits/rejected": -2.909499168395996,
      "logps/chosen": -67.12751770019531,
      "logps/rejected": -118.7498779296875,
      "loss": 0.0367,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8943085670471191,
      "rewards/margins": 3.324254035949707,
      "rewards/rejected": -1.4299453496932983,
      "step": 936
    },
    {
      "epoch": 0.3748,
      "grad_norm": 20.869163513183594,
      "learning_rate": 8.751999999999999e-07,
      "logits/chosen": -2.5574965476989746,
      "logits/rejected": -2.0812618732452393,
      "logps/chosen": -115.27861022949219,
      "logps/rejected": -113.478759765625,
      "loss": 0.3289,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8702725172042847,
      "rewards/margins": 1.5425081253051758,
      "rewards/rejected": -0.6722354888916016,
      "step": 937
    },
    {
      "epoch": 0.3752,
      "grad_norm": 0.5522946119308472,
      "learning_rate": 8.750666666666666e-07,
      "logits/chosen": -2.162093162536621,
      "logits/rejected": -2.624527931213379,
      "logps/chosen": -84.05149841308594,
      "logps/rejected": -122.66533660888672,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.998126983642578,
      "rewards/margins": 4.957696914672852,
      "rewards/rejected": -1.9595695734024048,
      "step": 938
    },
    {
      "epoch": 0.3756,
      "grad_norm": 4.546990394592285,
      "learning_rate": 8.749333333333333e-07,
      "logits/chosen": -2.458098888397217,
      "logits/rejected": -2.68223237991333,
      "logps/chosen": -114.61566162109375,
      "logps/rejected": -98.18072509765625,
      "loss": 0.0864,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.022247791290283,
      "rewards/margins": 3.138993263244629,
      "rewards/rejected": -0.11674537509679794,
      "step": 939
    },
    {
      "epoch": 0.376,
      "grad_norm": 1.999180555343628,
      "learning_rate": 8.748e-07,
      "logits/chosen": -2.136150598526001,
      "logits/rejected": -2.9759912490844727,
      "logps/chosen": -100.27769470214844,
      "logps/rejected": -128.2489013671875,
      "loss": 0.0243,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1559224128723145,
      "rewards/margins": 3.8278067111968994,
      "rewards/rejected": -1.6718841791152954,
      "step": 940
    },
    {
      "epoch": 0.3764,
      "grad_norm": 0.814444363117218,
      "learning_rate": 8.746666666666667e-07,
      "logits/chosen": -2.020580768585205,
      "logits/rejected": -3.047119140625,
      "logps/chosen": -131.12469482421875,
      "logps/rejected": -123.90474700927734,
      "loss": 0.0095,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.275148868560791,
      "rewards/margins": 4.656469345092773,
      "rewards/rejected": -2.3813202381134033,
      "step": 941
    },
    {
      "epoch": 0.3768,
      "grad_norm": 0.9333492517471313,
      "learning_rate": 8.745333333333334e-07,
      "logits/chosen": -2.2785067558288574,
      "logits/rejected": -2.7497048377990723,
      "logps/chosen": -113.82793426513672,
      "logps/rejected": -133.36488342285156,
      "loss": 0.0153,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.221661329269409,
      "rewards/margins": 4.183958053588867,
      "rewards/rejected": -1.962296724319458,
      "step": 942
    },
    {
      "epoch": 0.3772,
      "grad_norm": 0.4968250095844269,
      "learning_rate": 8.743999999999999e-07,
      "logits/chosen": -2.3946094512939453,
      "logits/rejected": -2.8601932525634766,
      "logps/chosen": -183.89735412597656,
      "logps/rejected": -157.21859741210938,
      "loss": 0.0048,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4398276805877686,
      "rewards/margins": 5.793123245239258,
      "rewards/rejected": -3.3532958030700684,
      "step": 943
    },
    {
      "epoch": 0.3776,
      "grad_norm": 0.31755536794662476,
      "learning_rate": 8.742666666666666e-07,
      "logits/chosen": -2.0307366847991943,
      "logits/rejected": -2.9735655784606934,
      "logps/chosen": -92.76373291015625,
      "logps/rejected": -127.58920288085938,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.020242691040039,
      "rewards/margins": 5.915635585784912,
      "rewards/rejected": -2.895392656326294,
      "step": 944
    },
    {
      "epoch": 0.378,
      "grad_norm": 2.2374789714813232,
      "learning_rate": 8.741333333333333e-07,
      "logits/chosen": -2.3474066257476807,
      "logits/rejected": -2.955836772918701,
      "logps/chosen": -138.79966735839844,
      "logps/rejected": -130.4871826171875,
      "loss": 0.0294,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4792027473449707,
      "rewards/margins": 4.356569290161133,
      "rewards/rejected": -2.877366781234741,
      "step": 945
    },
    {
      "epoch": 0.3784,
      "grad_norm": 1.34378981590271,
      "learning_rate": 8.739999999999999e-07,
      "logits/chosen": -2.4009032249450684,
      "logits/rejected": -2.51328706741333,
      "logps/chosen": -101.94027709960938,
      "logps/rejected": -195.03627014160156,
      "loss": 0.0136,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.550647258758545,
      "rewards/margins": 4.354678153991699,
      "rewards/rejected": -1.8040306568145752,
      "step": 946
    },
    {
      "epoch": 0.3788,
      "grad_norm": 1.8363722562789917,
      "learning_rate": 8.738666666666666e-07,
      "logits/chosen": -1.9883356094360352,
      "logits/rejected": -2.7993154525756836,
      "logps/chosen": -74.81178283691406,
      "logps/rejected": -101.70379638671875,
      "loss": 0.0301,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.17464542388916,
      "rewards/margins": 3.5164403915405273,
      "rewards/rejected": -1.3417949676513672,
      "step": 947
    },
    {
      "epoch": 0.3792,
      "grad_norm": 1.2563523054122925,
      "learning_rate": 8.737333333333333e-07,
      "logits/chosen": -2.4402761459350586,
      "logits/rejected": -3.3309850692749023,
      "logps/chosen": -153.65562438964844,
      "logps/rejected": -177.85922241210938,
      "loss": 0.0184,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.24306058883667,
      "rewards/margins": 4.086817741394043,
      "rewards/rejected": -1.8437573909759521,
      "step": 948
    },
    {
      "epoch": 0.3796,
      "grad_norm": 0.39228355884552,
      "learning_rate": 8.736e-07,
      "logits/chosen": -2.70979642868042,
      "logits/rejected": -3.1815192699432373,
      "logps/chosen": -131.9307403564453,
      "logps/rejected": -112.6888198852539,
      "loss": 0.0059,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9207425117492676,
      "rewards/margins": 5.129413604736328,
      "rewards/rejected": -2.2086710929870605,
      "step": 949
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3800564110279083,
      "learning_rate": 8.734666666666666e-07,
      "logits/chosen": -2.0499095916748047,
      "logits/rejected": -2.3441972732543945,
      "logps/chosen": -101.8538818359375,
      "logps/rejected": -99.42021179199219,
      "loss": 0.0065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.107797622680664,
      "rewards/margins": 5.238996505737305,
      "rewards/rejected": -1.1311988830566406,
      "step": 950
    },
    {
      "epoch": 0.3804,
      "grad_norm": 0.13035830855369568,
      "learning_rate": 8.733333333333333e-07,
      "logits/chosen": -2.4789810180664062,
      "logits/rejected": -3.1737890243530273,
      "logps/chosen": -178.1898956298828,
      "logps/rejected": -153.14654541015625,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.48189640045166,
      "rewards/margins": 6.504168510437012,
      "rewards/rejected": -3.0222725868225098,
      "step": 951
    },
    {
      "epoch": 0.3808,
      "grad_norm": 9.687320709228516,
      "learning_rate": 8.732e-07,
      "logits/chosen": -2.3038558959960938,
      "logits/rejected": -2.6573784351348877,
      "logps/chosen": -149.07199096679688,
      "logps/rejected": -103.52711486816406,
      "loss": 0.1442,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9826152920722961,
      "rewards/margins": 1.9323444366455078,
      "rewards/rejected": -0.9497291445732117,
      "step": 952
    },
    {
      "epoch": 0.3812,
      "grad_norm": 2.073533296585083,
      "learning_rate": 8.730666666666666e-07,
      "logits/chosen": -2.2249414920806885,
      "logits/rejected": -2.7114405632019043,
      "logps/chosen": -102.42149353027344,
      "logps/rejected": -128.9277801513672,
      "loss": 0.0267,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4195778369903564,
      "rewards/margins": 4.494503974914551,
      "rewards/rejected": -2.0749258995056152,
      "step": 953
    },
    {
      "epoch": 0.3816,
      "grad_norm": 0.7726842761039734,
      "learning_rate": 8.729333333333333e-07,
      "logits/chosen": -2.147294044494629,
      "logits/rejected": -2.802711009979248,
      "logps/chosen": -89.73674011230469,
      "logps/rejected": -116.78440856933594,
      "loss": 0.0135,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.417011022567749,
      "rewards/margins": 4.745630264282227,
      "rewards/rejected": -2.3286190032958984,
      "step": 954
    },
    {
      "epoch": 0.382,
      "grad_norm": 0.8981248140335083,
      "learning_rate": 8.728e-07,
      "logits/chosen": -2.3929238319396973,
      "logits/rejected": -2.523280143737793,
      "logps/chosen": -112.81680297851562,
      "logps/rejected": -105.49330139160156,
      "loss": 0.0111,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.173863410949707,
      "rewards/margins": 4.884181022644043,
      "rewards/rejected": -1.7103179693222046,
      "step": 955
    },
    {
      "epoch": 0.3824,
      "grad_norm": 1.061928391456604,
      "learning_rate": 8.726666666666666e-07,
      "logits/chosen": -1.8116729259490967,
      "logits/rejected": -2.910733222961426,
      "logps/chosen": -143.8711395263672,
      "logps/rejected": -139.57749938964844,
      "loss": 0.0128,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8304367065429688,
      "rewards/margins": 4.472309589385986,
      "rewards/rejected": -1.6418728828430176,
      "step": 956
    },
    {
      "epoch": 0.3828,
      "grad_norm": 7.781209468841553,
      "learning_rate": 8.725333333333333e-07,
      "logits/chosen": -2.322652816772461,
      "logits/rejected": -2.9421300888061523,
      "logps/chosen": -190.93154907226562,
      "logps/rejected": -141.89675903320312,
      "loss": 0.0783,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5701778531074524,
      "rewards/margins": 2.8031861782073975,
      "rewards/rejected": -2.2330081462860107,
      "step": 957
    },
    {
      "epoch": 0.3832,
      "grad_norm": 3.8858683109283447,
      "learning_rate": 8.723999999999999e-07,
      "logits/chosen": -1.9311003684997559,
      "logits/rejected": -2.322194814682007,
      "logps/chosen": -82.18095397949219,
      "logps/rejected": -103.64324188232422,
      "loss": 0.0585,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0289528369903564,
      "rewards/margins": 3.4749412536621094,
      "rewards/rejected": -1.445988416671753,
      "step": 958
    },
    {
      "epoch": 0.3836,
      "grad_norm": 0.5565708875656128,
      "learning_rate": 8.722666666666666e-07,
      "logits/chosen": -2.0031025409698486,
      "logits/rejected": -2.8466038703918457,
      "logps/chosen": -88.86783599853516,
      "logps/rejected": -152.16522216796875,
      "loss": 0.0063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.852806568145752,
      "rewards/margins": 5.878992557525635,
      "rewards/rejected": -2.026185989379883,
      "step": 959
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.5571703910827637,
      "learning_rate": 8.721333333333333e-07,
      "logits/chosen": -1.7840299606323242,
      "logits/rejected": -1.8926784992218018,
      "logps/chosen": -92.00601196289062,
      "logps/rejected": -106.33052825927734,
      "loss": 0.0077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.116795539855957,
      "rewards/margins": 4.876301288604736,
      "rewards/rejected": -1.7595058679580688,
      "step": 960
    },
    {
      "epoch": 0.3844,
      "grad_norm": 0.2815055847167969,
      "learning_rate": 8.72e-07,
      "logits/chosen": -1.948317050933838,
      "logits/rejected": -2.2849645614624023,
      "logps/chosen": -128.10308837890625,
      "logps/rejected": -100.96966552734375,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.724259376525879,
      "rewards/margins": 5.785791873931885,
      "rewards/rejected": -2.061532735824585,
      "step": 961
    },
    {
      "epoch": 0.3848,
      "grad_norm": 0.5266254544258118,
      "learning_rate": 8.718666666666667e-07,
      "logits/chosen": -2.385274887084961,
      "logits/rejected": -2.642113447189331,
      "logps/chosen": -123.26069641113281,
      "logps/rejected": -112.84477233886719,
      "loss": 0.0098,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.712599992752075,
      "rewards/margins": 4.64140510559082,
      "rewards/rejected": -1.9288051128387451,
      "step": 962
    },
    {
      "epoch": 0.3852,
      "grad_norm": 0.7816439867019653,
      "learning_rate": 8.717333333333334e-07,
      "logits/chosen": -2.3728737831115723,
      "logits/rejected": -1.9810783863067627,
      "logps/chosen": -106.51002502441406,
      "logps/rejected": -105.84587097167969,
      "loss": 0.0141,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.008235216140747,
      "rewards/margins": 4.588223457336426,
      "rewards/rejected": -1.5799881219863892,
      "step": 963
    },
    {
      "epoch": 0.3856,
      "grad_norm": 0.14558760821819305,
      "learning_rate": 8.716e-07,
      "logits/chosen": -2.4225692749023438,
      "logits/rejected": -2.4140875339508057,
      "logps/chosen": -127.2867202758789,
      "logps/rejected": -189.86224365234375,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3301901817321777,
      "rewards/margins": 6.422596454620361,
      "rewards/rejected": -3.0924062728881836,
      "step": 964
    },
    {
      "epoch": 0.386,
      "grad_norm": 0.5384384989738464,
      "learning_rate": 8.714666666666665e-07,
      "logits/chosen": -2.426486015319824,
      "logits/rejected": -3.3370044231414795,
      "logps/chosen": -92.09378051757812,
      "logps/rejected": -114.6192626953125,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.845000743865967,
      "rewards/margins": 5.0878777503967285,
      "rewards/rejected": -2.2428767681121826,
      "step": 965
    },
    {
      "epoch": 0.3864,
      "grad_norm": 1.5761382579803467,
      "learning_rate": 8.713333333333332e-07,
      "logits/chosen": -2.6234991550445557,
      "logits/rejected": -2.622318744659424,
      "logps/chosen": -101.04557037353516,
      "logps/rejected": -99.07182312011719,
      "loss": 0.0238,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6920886039733887,
      "rewards/margins": 4.352419376373291,
      "rewards/rejected": -1.6603306531906128,
      "step": 966
    },
    {
      "epoch": 0.3868,
      "grad_norm": 5.318860054016113,
      "learning_rate": 8.711999999999999e-07,
      "logits/chosen": -2.1525142192840576,
      "logits/rejected": -3.182133674621582,
      "logps/chosen": -146.8383026123047,
      "logps/rejected": -146.77593994140625,
      "loss": 0.0517,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.79842609167099,
      "rewards/margins": 3.922410726547241,
      "rewards/rejected": -3.1239845752716064,
      "step": 967
    },
    {
      "epoch": 0.3872,
      "grad_norm": 2.5346715450286865,
      "learning_rate": 8.710666666666666e-07,
      "logits/chosen": -1.9345033168792725,
      "logits/rejected": -2.456012487411499,
      "logps/chosen": -69.62310791015625,
      "logps/rejected": -94.54325103759766,
      "loss": 0.0475,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9178733825683594,
      "rewards/margins": 3.1003899574279785,
      "rewards/rejected": -1.1825164556503296,
      "step": 968
    },
    {
      "epoch": 0.3876,
      "grad_norm": 2.2149884700775146,
      "learning_rate": 8.709333333333333e-07,
      "logits/chosen": -2.2348363399505615,
      "logits/rejected": -2.8120007514953613,
      "logps/chosen": -140.53131103515625,
      "logps/rejected": -135.97427368164062,
      "loss": 0.0323,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2835137844085693,
      "rewards/margins": 4.627459526062012,
      "rewards/rejected": -2.3439457416534424,
      "step": 969
    },
    {
      "epoch": 0.388,
      "grad_norm": 10.010852813720703,
      "learning_rate": 8.708e-07,
      "logits/chosen": -2.4934706687927246,
      "logits/rejected": -3.070765495300293,
      "logps/chosen": -102.93695831298828,
      "logps/rejected": -108.57707977294922,
      "loss": 0.1869,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.258489966392517,
      "rewards/margins": 2.9979515075683594,
      "rewards/rejected": -1.7394615411758423,
      "step": 970
    },
    {
      "epoch": 0.3884,
      "grad_norm": 2.150981903076172,
      "learning_rate": 8.706666666666667e-07,
      "logits/chosen": -2.0627388954162598,
      "logits/rejected": -2.668959617614746,
      "logps/chosen": -128.1241912841797,
      "logps/rejected": -124.28498840332031,
      "loss": 0.0222,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5829172134399414,
      "rewards/margins": 4.661722183227539,
      "rewards/rejected": -2.0788047313690186,
      "step": 971
    },
    {
      "epoch": 0.3888,
      "grad_norm": 0.2588587999343872,
      "learning_rate": 8.705333333333334e-07,
      "logits/chosen": -2.339219093322754,
      "logits/rejected": -2.2001562118530273,
      "logps/chosen": -76.60599517822266,
      "logps/rejected": -105.0540771484375,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9877469539642334,
      "rewards/margins": 6.252224445343018,
      "rewards/rejected": -2.264477491378784,
      "step": 972
    },
    {
      "epoch": 0.3892,
      "grad_norm": 2.882620096206665,
      "learning_rate": 8.704e-07,
      "logits/chosen": -2.14888596534729,
      "logits/rejected": -2.786162853240967,
      "logps/chosen": -131.48101806640625,
      "logps/rejected": -157.780517578125,
      "loss": 0.0452,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2497503757476807,
      "rewards/margins": 3.7646496295928955,
      "rewards/rejected": -1.5148991346359253,
      "step": 973
    },
    {
      "epoch": 0.3896,
      "grad_norm": 0.6674132943153381,
      "learning_rate": 8.702666666666665e-07,
      "logits/chosen": -1.9475486278533936,
      "logits/rejected": -2.422900915145874,
      "logps/chosen": -75.44023895263672,
      "logps/rejected": -105.33550262451172,
      "loss": 0.0117,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2353761196136475,
      "rewards/margins": 4.457703590393066,
      "rewards/rejected": -2.222327709197998,
      "step": 974
    },
    {
      "epoch": 0.39,
      "grad_norm": 4.148820400238037,
      "learning_rate": 8.701333333333332e-07,
      "logits/chosen": -2.154099941253662,
      "logits/rejected": -2.8886373043060303,
      "logps/chosen": -100.24600219726562,
      "logps/rejected": -125.97048950195312,
      "loss": 0.0652,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7749683856964111,
      "rewards/margins": 3.936743974685669,
      "rewards/rejected": -2.161775588989258,
      "step": 975
    },
    {
      "epoch": 0.3904,
      "grad_norm": 0.31848230957984924,
      "learning_rate": 8.699999999999999e-07,
      "logits/chosen": -2.5082855224609375,
      "logits/rejected": -2.8296773433685303,
      "logps/chosen": -151.16587829589844,
      "logps/rejected": -105.66024780273438,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8130011558532715,
      "rewards/margins": 5.556972026824951,
      "rewards/rejected": -1.743970513343811,
      "step": 976
    },
    {
      "epoch": 0.3908,
      "grad_norm": 1.3037409782409668,
      "learning_rate": 8.698666666666666e-07,
      "logits/chosen": -1.8717299699783325,
      "logits/rejected": -2.6950221061706543,
      "logps/chosen": -84.71793365478516,
      "logps/rejected": -111.7591552734375,
      "loss": 0.0236,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6842819452285767,
      "rewards/margins": 3.7333805561065674,
      "rewards/rejected": -2.0490987300872803,
      "step": 977
    },
    {
      "epoch": 0.3912,
      "grad_norm": 0.23316791653633118,
      "learning_rate": 8.697333333333333e-07,
      "logits/chosen": -2.3468708992004395,
      "logits/rejected": -3.0426478385925293,
      "logps/chosen": -171.21560668945312,
      "logps/rejected": -165.32374572753906,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.336270809173584,
      "rewards/margins": 6.479382038116455,
      "rewards/rejected": -3.143111228942871,
      "step": 978
    },
    {
      "epoch": 0.3916,
      "grad_norm": 1.263386607170105,
      "learning_rate": 8.696e-07,
      "logits/chosen": -2.398583173751831,
      "logits/rejected": -2.8916547298431396,
      "logps/chosen": -108.14722442626953,
      "logps/rejected": -121.09867858886719,
      "loss": 0.0198,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3948302268981934,
      "rewards/margins": 5.2931132316589355,
      "rewards/rejected": -1.8982826471328735,
      "step": 979
    },
    {
      "epoch": 0.392,
      "grad_norm": 4.518253326416016,
      "learning_rate": 8.694666666666667e-07,
      "logits/chosen": -2.3916358947753906,
      "logits/rejected": -3.0782523155212402,
      "logps/chosen": -96.27892303466797,
      "logps/rejected": -117.26631164550781,
      "loss": 0.038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.521674394607544,
      "rewards/margins": 3.909822940826416,
      "rewards/rejected": -1.388148546218872,
      "step": 980
    },
    {
      "epoch": 0.3924,
      "grad_norm": 2.5991578102111816,
      "learning_rate": 8.693333333333333e-07,
      "logits/chosen": -2.221172571182251,
      "logits/rejected": -2.854746103286743,
      "logps/chosen": -109.83366394042969,
      "logps/rejected": -100.08705139160156,
      "loss": 0.0373,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8369007110595703,
      "rewards/margins": 3.272209882736206,
      "rewards/rejected": -1.4353091716766357,
      "step": 981
    },
    {
      "epoch": 0.3928,
      "grad_norm": 0.22498399019241333,
      "learning_rate": 8.692e-07,
      "logits/chosen": -1.9467889070510864,
      "logits/rejected": -3.0823442935943604,
      "logps/chosen": -62.05353546142578,
      "logps/rejected": -126.34654235839844,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.56634521484375,
      "rewards/margins": 6.074289321899414,
      "rewards/rejected": -2.5079445838928223,
      "step": 982
    },
    {
      "epoch": 0.3932,
      "grad_norm": 0.9438521862030029,
      "learning_rate": 8.690666666666667e-07,
      "logits/chosen": -1.9658613204956055,
      "logits/rejected": -2.6708574295043945,
      "logps/chosen": -97.75456237792969,
      "logps/rejected": -118.41079711914062,
      "loss": 0.0104,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6996490955352783,
      "rewards/margins": 4.967637062072754,
      "rewards/rejected": -2.2679877281188965,
      "step": 983
    },
    {
      "epoch": 0.3936,
      "grad_norm": 0.34886953234672546,
      "learning_rate": 8.689333333333333e-07,
      "logits/chosen": -1.918076753616333,
      "logits/rejected": -2.714293956756592,
      "logps/chosen": -77.1041259765625,
      "logps/rejected": -155.03817749023438,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1745457649230957,
      "rewards/margins": 5.427417755126953,
      "rewards/rejected": -2.2528717517852783,
      "step": 984
    },
    {
      "epoch": 0.394,
      "grad_norm": 4.965587615966797,
      "learning_rate": 8.687999999999999e-07,
      "logits/chosen": -2.126830577850342,
      "logits/rejected": -2.6070287227630615,
      "logps/chosen": -88.97698974609375,
      "logps/rejected": -119.51496124267578,
      "loss": 0.0821,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5545315146446228,
      "rewards/margins": 2.6952571868896484,
      "rewards/rejected": -2.140725612640381,
      "step": 985
    },
    {
      "epoch": 0.3944,
      "grad_norm": 0.4126344621181488,
      "learning_rate": 8.686666666666666e-07,
      "logits/chosen": -2.2384867668151855,
      "logits/rejected": -1.8828325271606445,
      "logps/chosen": -125.24364471435547,
      "logps/rejected": -170.60845947265625,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.4773850440979,
      "rewards/margins": 6.001396179199219,
      "rewards/rejected": -1.524011254310608,
      "step": 986
    },
    {
      "epoch": 0.3948,
      "grad_norm": 0.8499763607978821,
      "learning_rate": 8.685333333333333e-07,
      "logits/chosen": -2.4155373573303223,
      "logits/rejected": -2.3886454105377197,
      "logps/chosen": -77.94047546386719,
      "logps/rejected": -121.02239227294922,
      "loss": 0.0089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4227311611175537,
      "rewards/margins": 5.634485244750977,
      "rewards/rejected": -2.2117538452148438,
      "step": 987
    },
    {
      "epoch": 0.3952,
      "grad_norm": 12.908856391906738,
      "learning_rate": 8.683999999999999e-07,
      "logits/chosen": -2.122032403945923,
      "logits/rejected": -1.578774094581604,
      "logps/chosen": -88.35523223876953,
      "logps/rejected": -89.39095306396484,
      "loss": 0.1426,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.264065146446228,
      "rewards/margins": 2.5337777137756348,
      "rewards/rejected": -1.2697124481201172,
      "step": 988
    },
    {
      "epoch": 0.3956,
      "grad_norm": 0.2227674424648285,
      "learning_rate": 8.682666666666666e-07,
      "logits/chosen": -2.443783760070801,
      "logits/rejected": -3.3606514930725098,
      "logps/chosen": -209.03738403320312,
      "logps/rejected": -132.99417114257812,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.120485782623291,
      "rewards/margins": 6.412284851074219,
      "rewards/rejected": -2.2917990684509277,
      "step": 989
    },
    {
      "epoch": 0.396,
      "grad_norm": 3.5913453102111816,
      "learning_rate": 8.681333333333333e-07,
      "logits/chosen": -2.1934432983398438,
      "logits/rejected": -2.1949217319488525,
      "logps/chosen": -165.62249755859375,
      "logps/rejected": -165.56649780273438,
      "loss": 0.0392,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9380340576171875,
      "rewards/margins": 3.3305954933166504,
      "rewards/rejected": -1.3925613164901733,
      "step": 990
    },
    {
      "epoch": 0.3964,
      "grad_norm": 4.900576591491699,
      "learning_rate": 8.68e-07,
      "logits/chosen": -2.316140651702881,
      "logits/rejected": -2.8412537574768066,
      "logps/chosen": -99.42245483398438,
      "logps/rejected": -132.89813232421875,
      "loss": 0.0635,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6015434265136719,
      "rewards/margins": 2.9463143348693848,
      "rewards/rejected": -2.344770908355713,
      "step": 991
    },
    {
      "epoch": 0.3968,
      "grad_norm": 0.1827591210603714,
      "learning_rate": 8.678666666666667e-07,
      "logits/chosen": -2.539137363433838,
      "logits/rejected": -2.820176601409912,
      "logps/chosen": -207.3953857421875,
      "logps/rejected": -137.52723693847656,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.102987766265869,
      "rewards/margins": 6.698374271392822,
      "rewards/rejected": -2.595386505126953,
      "step": 992
    },
    {
      "epoch": 0.3972,
      "grad_norm": 0.7646521925926208,
      "learning_rate": 8.677333333333333e-07,
      "logits/chosen": -2.525925636291504,
      "logits/rejected": -3.244908094406128,
      "logps/chosen": -101.11213684082031,
      "logps/rejected": -119.61351013183594,
      "loss": 0.0102,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.058215856552124,
      "rewards/margins": 4.851947784423828,
      "rewards/rejected": -2.793732166290283,
      "step": 993
    },
    {
      "epoch": 0.3976,
      "grad_norm": 0.28200629353523254,
      "learning_rate": 8.676e-07,
      "logits/chosen": -2.50722074508667,
      "logits/rejected": -3.163666248321533,
      "logps/chosen": -114.4616470336914,
      "logps/rejected": -154.06211853027344,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4732255935668945,
      "rewards/margins": 6.492610454559326,
      "rewards/rejected": -3.0193848609924316,
      "step": 994
    },
    {
      "epoch": 0.398,
      "grad_norm": 8.720596313476562,
      "learning_rate": 8.674666666666667e-07,
      "logits/chosen": -2.08919620513916,
      "logits/rejected": -2.6588215827941895,
      "logps/chosen": -130.1461181640625,
      "logps/rejected": -191.20523071289062,
      "loss": 0.0928,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.275472640991211,
      "rewards/margins": 4.303889274597168,
      "rewards/rejected": -2.028416633605957,
      "step": 995
    },
    {
      "epoch": 0.3984,
      "grad_norm": 1.2231314182281494,
      "learning_rate": 8.673333333333332e-07,
      "logits/chosen": -2.2350480556488037,
      "logits/rejected": -1.8129289150238037,
      "logps/chosen": -81.36097717285156,
      "logps/rejected": -101.40266418457031,
      "loss": 0.0152,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.562382698059082,
      "rewards/margins": 4.206614017486572,
      "rewards/rejected": -0.6442314386367798,
      "step": 996
    },
    {
      "epoch": 0.3988,
      "grad_norm": 1.7127320766448975,
      "learning_rate": 8.671999999999999e-07,
      "logits/chosen": -2.0456881523132324,
      "logits/rejected": -2.589691638946533,
      "logps/chosen": -94.13610076904297,
      "logps/rejected": -133.49549865722656,
      "loss": 0.0243,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.357395648956299,
      "rewards/margins": 4.930874824523926,
      "rewards/rejected": -2.573479652404785,
      "step": 997
    },
    {
      "epoch": 0.3992,
      "grad_norm": 5.4353556632995605,
      "learning_rate": 8.670666666666666e-07,
      "logits/chosen": -2.219006061553955,
      "logits/rejected": -3.0967888832092285,
      "logps/chosen": -120.484130859375,
      "logps/rejected": -114.50829315185547,
      "loss": 0.0709,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2997708320617676,
      "rewards/margins": 3.794790029525757,
      "rewards/rejected": -1.4950191974639893,
      "step": 998
    },
    {
      "epoch": 0.3996,
      "grad_norm": 0.31021931767463684,
      "learning_rate": 8.669333333333333e-07,
      "logits/chosen": -2.209664821624756,
      "logits/rejected": -3.0207414627075195,
      "logps/chosen": -83.3301773071289,
      "logps/rejected": -152.84304809570312,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.262195587158203,
      "rewards/margins": 5.868431091308594,
      "rewards/rejected": -2.6062350273132324,
      "step": 999
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.240072101354599,
      "learning_rate": 8.668e-07,
      "logits/chosen": -2.2730631828308105,
      "logits/rejected": -3.060350179672241,
      "logps/chosen": -85.61474609375,
      "logps/rejected": -99.42426300048828,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4278955459594727,
      "rewards/margins": 5.702214241027832,
      "rewards/rejected": -2.2743186950683594,
      "step": 1000
    },
    {
      "epoch": 0.4004,
      "grad_norm": 0.8842854499816895,
      "learning_rate": 8.666666666666667e-07,
      "logits/chosen": -2.1260600090026855,
      "logits/rejected": -2.963569164276123,
      "logps/chosen": -103.3843765258789,
      "logps/rejected": -124.31617736816406,
      "loss": 0.0086,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0288541316986084,
      "rewards/margins": 4.75399923324585,
      "rewards/rejected": -2.725144863128662,
      "step": 1001
    },
    {
      "epoch": 0.4008,
      "grad_norm": 0.7786399722099304,
      "learning_rate": 8.665333333333334e-07,
      "logits/chosen": -1.77853524684906,
      "logits/rejected": -2.6751251220703125,
      "logps/chosen": -116.05855560302734,
      "logps/rejected": -122.10691833496094,
      "loss": 0.0128,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4968674182891846,
      "rewards/margins": 4.708100318908691,
      "rewards/rejected": -2.211233139038086,
      "step": 1002
    },
    {
      "epoch": 0.4012,
      "grad_norm": 3.005661964416504,
      "learning_rate": 8.663999999999999e-07,
      "logits/chosen": -1.893611192703247,
      "logits/rejected": -2.59089994430542,
      "logps/chosen": -123.05966186523438,
      "logps/rejected": -105.80560302734375,
      "loss": 0.0377,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.413954496383667,
      "rewards/margins": 3.260542869567871,
      "rewards/rejected": -1.846588134765625,
      "step": 1003
    },
    {
      "epoch": 0.4016,
      "grad_norm": 2.661505937576294,
      "learning_rate": 8.662666666666666e-07,
      "logits/chosen": -2.5958712100982666,
      "logits/rejected": -2.5922932624816895,
      "logps/chosen": -132.14389038085938,
      "logps/rejected": -104.84564208984375,
      "loss": 0.0395,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8957526683807373,
      "rewards/margins": 3.223254919052124,
      "rewards/rejected": -1.3275020122528076,
      "step": 1004
    },
    {
      "epoch": 0.402,
      "grad_norm": 1.6224191188812256,
      "learning_rate": 8.661333333333333e-07,
      "logits/chosen": -2.700407028198242,
      "logits/rejected": -2.4945590496063232,
      "logps/chosen": -141.54046630859375,
      "logps/rejected": -166.33860778808594,
      "loss": 0.0304,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4232211112976074,
      "rewards/margins": 4.528425693511963,
      "rewards/rejected": -1.1052043437957764,
      "step": 1005
    },
    {
      "epoch": 0.4024,
      "grad_norm": 0.5156925916671753,
      "learning_rate": 8.659999999999999e-07,
      "logits/chosen": -2.2669425010681152,
      "logits/rejected": -2.5350558757781982,
      "logps/chosen": -136.27816772460938,
      "logps/rejected": -157.43026733398438,
      "loss": 0.0067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4760255813598633,
      "rewards/margins": 5.587734699249268,
      "rewards/rejected": -2.1117091178894043,
      "step": 1006
    },
    {
      "epoch": 0.4028,
      "grad_norm": 0.5366275906562805,
      "learning_rate": 8.658666666666666e-07,
      "logits/chosen": -1.9516263008117676,
      "logits/rejected": -2.8757619857788086,
      "logps/chosen": -93.51016235351562,
      "logps/rejected": -115.2319107055664,
      "loss": 0.0063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2639191150665283,
      "rewards/margins": 5.148748874664307,
      "rewards/rejected": -1.8848297595977783,
      "step": 1007
    },
    {
      "epoch": 0.4032,
      "grad_norm": 0.31687793135643005,
      "learning_rate": 8.657333333333333e-07,
      "logits/chosen": -2.203947067260742,
      "logits/rejected": -2.671215057373047,
      "logps/chosen": -106.01278686523438,
      "logps/rejected": -278.59234619140625,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4457478523254395,
      "rewards/margins": 6.279669761657715,
      "rewards/rejected": -3.8339219093322754,
      "step": 1008
    },
    {
      "epoch": 0.4036,
      "grad_norm": 1.8821942806243896,
      "learning_rate": 8.656e-07,
      "logits/chosen": -2.091679573059082,
      "logits/rejected": -2.693296432495117,
      "logps/chosen": -100.66360473632812,
      "logps/rejected": -130.9735107421875,
      "loss": 0.0222,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3810226917266846,
      "rewards/margins": 4.178233623504639,
      "rewards/rejected": -1.797210693359375,
      "step": 1009
    },
    {
      "epoch": 0.404,
      "grad_norm": 1.323736548423767,
      "learning_rate": 8.654666666666667e-07,
      "logits/chosen": -2.2290592193603516,
      "logits/rejected": -2.306286096572876,
      "logps/chosen": -112.03424835205078,
      "logps/rejected": -109.89237213134766,
      "loss": 0.0194,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6030240058898926,
      "rewards/margins": 4.159843444824219,
      "rewards/rejected": -1.556819200515747,
      "step": 1010
    },
    {
      "epoch": 0.4044,
      "grad_norm": 1.5848212242126465,
      "learning_rate": 8.653333333333333e-07,
      "logits/chosen": -2.308234691619873,
      "logits/rejected": -2.670865535736084,
      "logps/chosen": -145.9526824951172,
      "logps/rejected": -125.33152770996094,
      "loss": 0.0185,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1416192054748535,
      "rewards/margins": 4.392412185668945,
      "rewards/rejected": -2.2507927417755127,
      "step": 1011
    },
    {
      "epoch": 0.4048,
      "grad_norm": 1.4510515928268433,
      "learning_rate": 8.651999999999999e-07,
      "logits/chosen": -2.3240785598754883,
      "logits/rejected": -2.7202141284942627,
      "logps/chosen": -87.87008666992188,
      "logps/rejected": -92.2452621459961,
      "loss": 0.0202,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4659996032714844,
      "rewards/margins": 3.891916513442993,
      "rewards/rejected": -1.4259166717529297,
      "step": 1012
    },
    {
      "epoch": 0.4052,
      "grad_norm": 1.4830573797225952,
      "learning_rate": 8.650666666666666e-07,
      "logits/chosen": -2.1654205322265625,
      "logits/rejected": -2.871220827102661,
      "logps/chosen": -113.05693054199219,
      "logps/rejected": -136.41604614257812,
      "loss": 0.0213,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4817192554473877,
      "rewards/margins": 4.114472389221191,
      "rewards/rejected": -1.6327533721923828,
      "step": 1013
    },
    {
      "epoch": 0.4056,
      "grad_norm": 0.3080388307571411,
      "learning_rate": 8.649333333333333e-07,
      "logits/chosen": -2.1435203552246094,
      "logits/rejected": -3.2566022872924805,
      "logps/chosen": -155.7700653076172,
      "logps/rejected": -141.91473388671875,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3439064025878906,
      "rewards/margins": 6.067607879638672,
      "rewards/rejected": -2.723701000213623,
      "step": 1014
    },
    {
      "epoch": 0.406,
      "grad_norm": 0.8067086935043335,
      "learning_rate": 8.648e-07,
      "logits/chosen": -2.562741279602051,
      "logits/rejected": -3.0902252197265625,
      "logps/chosen": -107.4393310546875,
      "logps/rejected": -104.75418090820312,
      "loss": 0.0094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.057420253753662,
      "rewards/margins": 4.691473960876465,
      "rewards/rejected": -1.6340539455413818,
      "step": 1015
    },
    {
      "epoch": 0.4064,
      "grad_norm": 2.7113394737243652,
      "learning_rate": 8.646666666666667e-07,
      "logits/chosen": -2.8126187324523926,
      "logits/rejected": -3.259218215942383,
      "logps/chosen": -151.8725128173828,
      "logps/rejected": -116.81107330322266,
      "loss": 0.0363,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.690305471420288,
      "rewards/margins": 3.68057918548584,
      "rewards/rejected": -1.9902737140655518,
      "step": 1016
    },
    {
      "epoch": 0.4068,
      "grad_norm": 0.13156019151210785,
      "learning_rate": 8.645333333333333e-07,
      "logits/chosen": -1.831816554069519,
      "logits/rejected": -2.4152631759643555,
      "logps/chosen": -103.55911254882812,
      "logps/rejected": -98.13970947265625,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.0894999504089355,
      "rewards/margins": 6.273180961608887,
      "rewards/rejected": -2.183680772781372,
      "step": 1017
    },
    {
      "epoch": 0.4072,
      "grad_norm": 0.858697772026062,
      "learning_rate": 8.643999999999999e-07,
      "logits/chosen": -2.196185350418091,
      "logits/rejected": -2.7959015369415283,
      "logps/chosen": -108.20857238769531,
      "logps/rejected": -113.61579895019531,
      "loss": 0.0089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0672767162323,
      "rewards/margins": 4.886825084686279,
      "rewards/rejected": -1.819548487663269,
      "step": 1018
    },
    {
      "epoch": 0.4076,
      "grad_norm": 1.0580192804336548,
      "learning_rate": 8.642666666666666e-07,
      "logits/chosen": -2.7912535667419434,
      "logits/rejected": -2.7041726112365723,
      "logps/chosen": -84.96633911132812,
      "logps/rejected": -121.49783325195312,
      "loss": 0.0183,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.698296308517456,
      "rewards/margins": 4.762690544128418,
      "rewards/rejected": -2.064394474029541,
      "step": 1019
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.46630340814590454,
      "learning_rate": 8.641333333333333e-07,
      "logits/chosen": -2.2624547481536865,
      "logits/rejected": -2.3177199363708496,
      "logps/chosen": -126.02127838134766,
      "logps/rejected": -111.806396484375,
      "loss": 0.0077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.185675859451294,
      "rewards/margins": 5.0597991943359375,
      "rewards/rejected": -1.8741233348846436,
      "step": 1020
    },
    {
      "epoch": 0.4084,
      "grad_norm": 0.8539828062057495,
      "learning_rate": 8.639999999999999e-07,
      "logits/chosen": -2.476044178009033,
      "logits/rejected": -2.948939800262451,
      "logps/chosen": -97.392578125,
      "logps/rejected": -153.11318969726562,
      "loss": 0.0107,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7673091888427734,
      "rewards/margins": 5.358187675476074,
      "rewards/rejected": -1.5908787250518799,
      "step": 1021
    },
    {
      "epoch": 0.4088,
      "grad_norm": 2.5036208629608154,
      "learning_rate": 8.638666666666666e-07,
      "logits/chosen": -1.9195904731750488,
      "logits/rejected": -2.2661824226379395,
      "logps/chosen": -125.5784683227539,
      "logps/rejected": -117.36776733398438,
      "loss": 0.0433,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2415955066680908,
      "rewards/margins": 3.131709575653076,
      "rewards/rejected": -1.8901143074035645,
      "step": 1022
    },
    {
      "epoch": 0.4092,
      "grad_norm": 1.2820932865142822,
      "learning_rate": 8.637333333333333e-07,
      "logits/chosen": -2.6274642944335938,
      "logits/rejected": -2.487095832824707,
      "logps/chosen": -109.51383972167969,
      "logps/rejected": -122.52584838867188,
      "loss": 0.0194,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4617791175842285,
      "rewards/margins": 4.271624565124512,
      "rewards/rejected": -1.8098456859588623,
      "step": 1023
    },
    {
      "epoch": 0.4096,
      "grad_norm": 5.042874336242676,
      "learning_rate": 8.636e-07,
      "logits/chosen": -2.083019733428955,
      "logits/rejected": -2.6830544471740723,
      "logps/chosen": -102.95611572265625,
      "logps/rejected": -132.67623901367188,
      "loss": 0.0639,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9346096515655518,
      "rewards/margins": 3.633317470550537,
      "rewards/rejected": -1.6987075805664062,
      "step": 1024
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.4822593927383423,
      "learning_rate": 8.634666666666667e-07,
      "logits/chosen": -2.20365309715271,
      "logits/rejected": -2.460941791534424,
      "logps/chosen": -138.73577880859375,
      "logps/rejected": -133.0948486328125,
      "loss": 0.0237,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.503134250640869,
      "rewards/margins": 4.081134796142578,
      "rewards/rejected": -1.5780003070831299,
      "step": 1025
    },
    {
      "epoch": 0.4104,
      "grad_norm": 0.24410219490528107,
      "learning_rate": 8.633333333333333e-07,
      "logits/chosen": -2.2589430809020996,
      "logits/rejected": -3.0077738761901855,
      "logps/chosen": -80.95280456542969,
      "logps/rejected": -117.94821166992188,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.329883098602295,
      "rewards/margins": 5.8088765144348145,
      "rewards/rejected": -2.4789934158325195,
      "step": 1026
    },
    {
      "epoch": 0.4108,
      "grad_norm": 0.29623091220855713,
      "learning_rate": 8.632e-07,
      "logits/chosen": -2.5409553050994873,
      "logits/rejected": -3.0371737480163574,
      "logps/chosen": -174.13494873046875,
      "logps/rejected": -121.84896850585938,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0474979877471924,
      "rewards/margins": 5.497432708740234,
      "rewards/rejected": -2.449934482574463,
      "step": 1027
    },
    {
      "epoch": 0.4112,
      "grad_norm": 0.9214242696762085,
      "learning_rate": 8.630666666666666e-07,
      "logits/chosen": -2.1434197425842285,
      "logits/rejected": -2.8684465885162354,
      "logps/chosen": -104.47509765625,
      "logps/rejected": -121.62916564941406,
      "loss": 0.0106,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.786569595336914,
      "rewards/margins": 4.75885534286499,
      "rewards/rejected": -1.9722858667373657,
      "step": 1028
    },
    {
      "epoch": 0.4116,
      "grad_norm": 0.963379979133606,
      "learning_rate": 8.629333333333333e-07,
      "logits/chosen": -2.024423837661743,
      "logits/rejected": -2.6412577629089355,
      "logps/chosen": -110.35528564453125,
      "logps/rejected": -179.41725158691406,
      "loss": 0.0146,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.428074598312378,
      "rewards/margins": 4.869866847991943,
      "rewards/rejected": -2.4417924880981445,
      "step": 1029
    },
    {
      "epoch": 0.412,
      "grad_norm": 0.07977204024791718,
      "learning_rate": 8.628e-07,
      "logits/chosen": -2.482992172241211,
      "logits/rejected": -2.691218376159668,
      "logps/chosen": -123.98773193359375,
      "logps/rejected": -120.18228149414062,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8915977478027344,
      "rewards/margins": 7.110053062438965,
      "rewards/rejected": -3.2184555530548096,
      "step": 1030
    },
    {
      "epoch": 0.4124,
      "grad_norm": 0.6464134454727173,
      "learning_rate": 8.626666666666666e-07,
      "logits/chosen": -2.2727155685424805,
      "logits/rejected": -2.681823492050171,
      "logps/chosen": -86.91963195800781,
      "logps/rejected": -115.55209350585938,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.419027805328369,
      "rewards/margins": 5.115616798400879,
      "rewards/rejected": -2.6965889930725098,
      "step": 1031
    },
    {
      "epoch": 0.4128,
      "grad_norm": 3.2408149242401123,
      "learning_rate": 8.625333333333333e-07,
      "logits/chosen": -2.4100136756896973,
      "logits/rejected": -2.6839160919189453,
      "logps/chosen": -72.87367248535156,
      "logps/rejected": -108.00997924804688,
      "loss": 0.0391,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.823197841644287,
      "rewards/margins": 3.9349753856658936,
      "rewards/rejected": -1.1117775440216064,
      "step": 1032
    },
    {
      "epoch": 0.4132,
      "grad_norm": 0.26561135053634644,
      "learning_rate": 8.624e-07,
      "logits/chosen": -2.430849075317383,
      "logits/rejected": -2.4531335830688477,
      "logps/chosen": -101.2646713256836,
      "logps/rejected": -99.99308013916016,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.522672176361084,
      "rewards/margins": 5.602697372436523,
      "rewards/rejected": -2.0800251960754395,
      "step": 1033
    },
    {
      "epoch": 0.4136,
      "grad_norm": 2.0908422470092773,
      "learning_rate": 8.622666666666666e-07,
      "logits/chosen": -2.197902202606201,
      "logits/rejected": -2.923936128616333,
      "logps/chosen": -156.6182861328125,
      "logps/rejected": -99.35963439941406,
      "loss": 0.0296,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.358208417892456,
      "rewards/margins": 3.7731552124023438,
      "rewards/rejected": -1.4149467945098877,
      "step": 1034
    },
    {
      "epoch": 0.414,
      "grad_norm": 1.2345536947250366,
      "learning_rate": 8.621333333333333e-07,
      "logits/chosen": -2.355591297149658,
      "logits/rejected": -2.827087879180908,
      "logps/chosen": -103.56782531738281,
      "logps/rejected": -125.1845703125,
      "loss": 0.0158,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9792797565460205,
      "rewards/margins": 4.630592346191406,
      "rewards/rejected": -2.6513123512268066,
      "step": 1035
    },
    {
      "epoch": 0.4144,
      "grad_norm": 0.28635233640670776,
      "learning_rate": 8.62e-07,
      "logits/chosen": -2.4418954849243164,
      "logits/rejected": -3.4668357372283936,
      "logps/chosen": -93.41773223876953,
      "logps/rejected": -151.166748046875,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9199531078338623,
      "rewards/margins": 5.688897132873535,
      "rewards/rejected": -2.7689437866210938,
      "step": 1036
    },
    {
      "epoch": 0.4148,
      "grad_norm": 0.44974255561828613,
      "learning_rate": 8.618666666666667e-07,
      "logits/chosen": -2.6144933700561523,
      "logits/rejected": -2.9906058311462402,
      "logps/chosen": -127.30211639404297,
      "logps/rejected": -127.6230239868164,
      "loss": 0.0045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1713690757751465,
      "rewards/margins": 6.110116958618164,
      "rewards/rejected": -2.9387478828430176,
      "step": 1037
    },
    {
      "epoch": 0.4152,
      "grad_norm": 1.1378974914550781,
      "learning_rate": 8.617333333333333e-07,
      "logits/chosen": -2.501605987548828,
      "logits/rejected": -2.9818100929260254,
      "logps/chosen": -170.39913940429688,
      "logps/rejected": -146.1743927001953,
      "loss": 0.0117,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.129732608795166,
      "rewards/margins": 4.683331489562988,
      "rewards/rejected": -2.5535988807678223,
      "step": 1038
    },
    {
      "epoch": 0.4156,
      "grad_norm": 6.268846035003662,
      "learning_rate": 8.616e-07,
      "logits/chosen": -2.4231605529785156,
      "logits/rejected": -2.800825834274292,
      "logps/chosen": -139.40061950683594,
      "logps/rejected": -113.44874572753906,
      "loss": 0.0527,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.753802537918091,
      "rewards/margins": 4.087385177612305,
      "rewards/rejected": -1.3335827589035034,
      "step": 1039
    },
    {
      "epoch": 0.416,
      "grad_norm": 3.2968082427978516,
      "learning_rate": 8.614666666666666e-07,
      "logits/chosen": -1.8115615844726562,
      "logits/rejected": -2.4503750801086426,
      "logps/chosen": -68.15545654296875,
      "logps/rejected": -97.32923889160156,
      "loss": 0.0586,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8193867206573486,
      "rewards/margins": 3.689134359359741,
      "rewards/rejected": -1.8697476387023926,
      "step": 1040
    },
    {
      "epoch": 0.4164,
      "grad_norm": 4.599780082702637,
      "learning_rate": 8.613333333333332e-07,
      "logits/chosen": -2.2474117279052734,
      "logits/rejected": -2.8834025859832764,
      "logps/chosen": -134.96267700195312,
      "logps/rejected": -122.98176574707031,
      "loss": 0.0529,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9016728401184082,
      "rewards/margins": 4.094318389892578,
      "rewards/rejected": -2.192645311355591,
      "step": 1041
    },
    {
      "epoch": 0.4168,
      "grad_norm": 1.6181727647781372,
      "learning_rate": 8.611999999999999e-07,
      "logits/chosen": -2.8591227531433105,
      "logits/rejected": -3.2320353984832764,
      "logps/chosen": -219.84918212890625,
      "logps/rejected": -263.54443359375,
      "loss": 0.0109,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5962324142456055,
      "rewards/margins": 5.441538333892822,
      "rewards/rejected": -1.8453056812286377,
      "step": 1042
    },
    {
      "epoch": 0.4172,
      "grad_norm": 1.4584323167800903,
      "learning_rate": 8.610666666666666e-07,
      "logits/chosen": -2.4723310470581055,
      "logits/rejected": -2.554797649383545,
      "logps/chosen": -146.60658264160156,
      "logps/rejected": -105.61026000976562,
      "loss": 0.0109,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.697341203689575,
      "rewards/margins": 4.722533226013184,
      "rewards/rejected": -2.0251922607421875,
      "step": 1043
    },
    {
      "epoch": 0.4176,
      "grad_norm": 0.14904175698757172,
      "learning_rate": 8.609333333333333e-07,
      "logits/chosen": -2.206291675567627,
      "logits/rejected": -2.567666530609131,
      "logps/chosen": -83.49813842773438,
      "logps/rejected": -102.76806640625,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.396444797515869,
      "rewards/margins": 6.144919395446777,
      "rewards/rejected": -1.74847412109375,
      "step": 1044
    },
    {
      "epoch": 0.418,
      "grad_norm": 0.34416231513023376,
      "learning_rate": 8.608e-07,
      "logits/chosen": -2.2372183799743652,
      "logits/rejected": -3.161571502685547,
      "logps/chosen": -98.79987335205078,
      "logps/rejected": -131.4824981689453,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.182989597320557,
      "rewards/margins": 5.468165874481201,
      "rewards/rejected": -1.2851765155792236,
      "step": 1045
    },
    {
      "epoch": 0.4184,
      "grad_norm": 6.363046646118164,
      "learning_rate": 8.606666666666667e-07,
      "logits/chosen": -2.6905517578125,
      "logits/rejected": -3.015843391418457,
      "logps/chosen": -197.23007202148438,
      "logps/rejected": -122.83070373535156,
      "loss": 0.0583,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.567833185195923,
      "rewards/margins": 4.4233808517456055,
      "rewards/rejected": -1.8555474281311035,
      "step": 1046
    },
    {
      "epoch": 0.4188,
      "grad_norm": 0.2848553955554962,
      "learning_rate": 8.605333333333334e-07,
      "logits/chosen": -2.3473339080810547,
      "logits/rejected": -2.996053695678711,
      "logps/chosen": -83.6697998046875,
      "logps/rejected": -162.19692993164062,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.40097713470459,
      "rewards/margins": 6.21665096282959,
      "rewards/rejected": -1.8156743049621582,
      "step": 1047
    },
    {
      "epoch": 0.4192,
      "grad_norm": 0.44545018672943115,
      "learning_rate": 8.604000000000001e-07,
      "logits/chosen": -2.316549062728882,
      "logits/rejected": -3.0319347381591797,
      "logps/chosen": -109.11323547363281,
      "logps/rejected": -145.17771911621094,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.523270845413208,
      "rewards/margins": 5.32705020904541,
      "rewards/rejected": -2.8037796020507812,
      "step": 1048
    },
    {
      "epoch": 0.4196,
      "grad_norm": 1.2946218252182007,
      "learning_rate": 8.602666666666665e-07,
      "logits/chosen": -2.304276466369629,
      "logits/rejected": -3.3554794788360596,
      "logps/chosen": -115.79572296142578,
      "logps/rejected": -123.75453186035156,
      "loss": 0.016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2892982959747314,
      "rewards/margins": 4.90504789352417,
      "rewards/rejected": -2.6157498359680176,
      "step": 1049
    },
    {
      "epoch": 0.42,
      "grad_norm": 9.811087608337402,
      "learning_rate": 8.601333333333332e-07,
      "logits/chosen": -1.4620884656906128,
      "logits/rejected": -2.705785036087036,
      "logps/chosen": -60.022117614746094,
      "logps/rejected": -110.9886474609375,
      "loss": 0.1144,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2701069116592407,
      "rewards/margins": 3.5314269065856934,
      "rewards/rejected": -2.261319875717163,
      "step": 1050
    },
    {
      "epoch": 0.4204,
      "grad_norm": 0.2613171935081482,
      "learning_rate": 8.599999999999999e-07,
      "logits/chosen": -2.225828170776367,
      "logits/rejected": -2.880286693572998,
      "logps/chosen": -88.60049438476562,
      "logps/rejected": -127.21794891357422,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9481887817382812,
      "rewards/margins": 6.098037242889404,
      "rewards/rejected": -2.149848222732544,
      "step": 1051
    },
    {
      "epoch": 0.4208,
      "grad_norm": 0.07561682909727097,
      "learning_rate": 8.598666666666666e-07,
      "logits/chosen": -2.0434513092041016,
      "logits/rejected": -2.759097099304199,
      "logps/chosen": -84.84440612792969,
      "logps/rejected": -128.14462280273438,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.884202003479004,
      "rewards/margins": 6.973846435546875,
      "rewards/rejected": -3.089644432067871,
      "step": 1052
    },
    {
      "epoch": 0.4212,
      "grad_norm": 0.8563008904457092,
      "learning_rate": 8.597333333333333e-07,
      "logits/chosen": -2.119539976119995,
      "logits/rejected": -2.904482841491699,
      "logps/chosen": -87.64542388916016,
      "logps/rejected": -107.6888427734375,
      "loss": 0.0077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5909667015075684,
      "rewards/margins": 5.16652774810791,
      "rewards/rejected": -1.5755611658096313,
      "step": 1053
    },
    {
      "epoch": 0.4216,
      "grad_norm": 0.7082684636116028,
      "learning_rate": 8.596e-07,
      "logits/chosen": -2.3925061225891113,
      "logits/rejected": -3.051478624343872,
      "logps/chosen": -129.24313354492188,
      "logps/rejected": -136.1741943359375,
      "loss": 0.0086,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0928659439086914,
      "rewards/margins": 5.686013221740723,
      "rewards/rejected": -3.5931472778320312,
      "step": 1054
    },
    {
      "epoch": 0.422,
      "grad_norm": 2.2868165969848633,
      "learning_rate": 8.594666666666667e-07,
      "logits/chosen": -1.830251932144165,
      "logits/rejected": -2.579132556915283,
      "logps/chosen": -73.2260971069336,
      "logps/rejected": -98.60513305664062,
      "loss": 0.0421,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2878963947296143,
      "rewards/margins": 3.1556601524353027,
      "rewards/rejected": -1.8677635192871094,
      "step": 1055
    },
    {
      "epoch": 0.4224,
      "grad_norm": 0.5721176266670227,
      "learning_rate": 8.593333333333333e-07,
      "logits/chosen": -2.176431894302368,
      "logits/rejected": -2.892824172973633,
      "logps/chosen": -68.6796875,
      "logps/rejected": -139.64630126953125,
      "loss": 0.0082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3587801456451416,
      "rewards/margins": 5.667481899261475,
      "rewards/rejected": -2.308701753616333,
      "step": 1056
    },
    {
      "epoch": 0.4228,
      "grad_norm": 0.7164557576179504,
      "learning_rate": 8.592e-07,
      "logits/chosen": -2.4639029502868652,
      "logits/rejected": -2.7360830307006836,
      "logps/chosen": -137.86322021484375,
      "logps/rejected": -135.9775390625,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7829689979553223,
      "rewards/margins": 5.340607166290283,
      "rewards/rejected": -1.557638168334961,
      "step": 1057
    },
    {
      "epoch": 0.4232,
      "grad_norm": 0.35354557633399963,
      "learning_rate": 8.590666666666667e-07,
      "logits/chosen": -2.5472733974456787,
      "logits/rejected": -2.4406332969665527,
      "logps/chosen": -111.0505599975586,
      "logps/rejected": -138.44815063476562,
      "loss": 0.0051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2219388484954834,
      "rewards/margins": 5.462066173553467,
      "rewards/rejected": -2.2401270866394043,
      "step": 1058
    },
    {
      "epoch": 0.4236,
      "grad_norm": 15.123385429382324,
      "learning_rate": 8.589333333333332e-07,
      "logits/chosen": -2.407724380493164,
      "logits/rejected": -2.676083564758301,
      "logps/chosen": -127.70516967773438,
      "logps/rejected": -105.83023834228516,
      "loss": 0.2012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7909278869628906,
      "rewards/margins": 3.66593861579895,
      "rewards/rejected": -0.8750106692314148,
      "step": 1059
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.2358095496892929,
      "learning_rate": 8.587999999999999e-07,
      "logits/chosen": -2.317336320877075,
      "logits/rejected": -3.111237049102783,
      "logps/chosen": -146.7809295654297,
      "logps/rejected": -115.3979721069336,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.655294418334961,
      "rewards/margins": 6.485620498657227,
      "rewards/rejected": -2.8303260803222656,
      "step": 1060
    },
    {
      "epoch": 0.4244,
      "grad_norm": 0.7439464330673218,
      "learning_rate": 8.586666666666666e-07,
      "logits/chosen": -1.807145357131958,
      "logits/rejected": -2.9189205169677734,
      "logps/chosen": -90.33810424804688,
      "logps/rejected": -114.26892852783203,
      "loss": 0.0078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.851022243499756,
      "rewards/margins": 4.9897003173828125,
      "rewards/rejected": -2.1386780738830566,
      "step": 1061
    },
    {
      "epoch": 0.4248,
      "grad_norm": 0.22232294082641602,
      "learning_rate": 8.585333333333333e-07,
      "logits/chosen": -2.246076822280884,
      "logits/rejected": -2.7811970710754395,
      "logps/chosen": -91.38372802734375,
      "logps/rejected": -123.48939514160156,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1287643909454346,
      "rewards/margins": 6.072168350219727,
      "rewards/rejected": -2.943404197692871,
      "step": 1062
    },
    {
      "epoch": 0.4252,
      "grad_norm": 1.1401629447937012,
      "learning_rate": 8.584e-07,
      "logits/chosen": -2.5668554306030273,
      "logits/rejected": -2.5241141319274902,
      "logps/chosen": -107.41609191894531,
      "logps/rejected": -86.72920227050781,
      "loss": 0.0169,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2637851238250732,
      "rewards/margins": 4.230061054229736,
      "rewards/rejected": -0.9662758111953735,
      "step": 1063
    },
    {
      "epoch": 0.4256,
      "grad_norm": 0.5076568722724915,
      "learning_rate": 8.582666666666666e-07,
      "logits/chosen": -2.091930866241455,
      "logits/rejected": -3.0478124618530273,
      "logps/chosen": -96.4588851928711,
      "logps/rejected": -152.227783203125,
      "loss": 0.006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5498130321502686,
      "rewards/margins": 6.2449798583984375,
      "rewards/rejected": -2.695166826248169,
      "step": 1064
    },
    {
      "epoch": 0.426,
      "grad_norm": 0.21163614094257355,
      "learning_rate": 8.581333333333333e-07,
      "logits/chosen": -2.221522808074951,
      "logits/rejected": -2.8089733123779297,
      "logps/chosen": -212.7317657470703,
      "logps/rejected": -155.13433837890625,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.847470283508301,
      "rewards/margins": 6.443218231201172,
      "rewards/rejected": -2.595747709274292,
      "step": 1065
    },
    {
      "epoch": 0.4264,
      "grad_norm": 7.334747791290283,
      "learning_rate": 8.58e-07,
      "logits/chosen": -2.649110794067383,
      "logits/rejected": -2.462256669998169,
      "logps/chosen": -127.20831298828125,
      "logps/rejected": -103.55496978759766,
      "loss": 0.037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.266122817993164,
      "rewards/margins": 4.229646682739258,
      "rewards/rejected": -1.9635238647460938,
      "step": 1066
    },
    {
      "epoch": 0.4268,
      "grad_norm": 0.24451041221618652,
      "learning_rate": 8.578666666666667e-07,
      "logits/chosen": -1.8257848024368286,
      "logits/rejected": -3.3001034259796143,
      "logps/chosen": -95.2626724243164,
      "logps/rejected": -164.20579528808594,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.633324146270752,
      "rewards/margins": 6.856321334838867,
      "rewards/rejected": -3.2229971885681152,
      "step": 1067
    },
    {
      "epoch": 0.4272,
      "grad_norm": 0.321053683757782,
      "learning_rate": 8.577333333333333e-07,
      "logits/chosen": -2.217118740081787,
      "logits/rejected": -2.795926332473755,
      "logps/chosen": -95.13259887695312,
      "logps/rejected": -115.03752899169922,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.355823040008545,
      "rewards/margins": 5.602191925048828,
      "rewards/rejected": -2.246368885040283,
      "step": 1068
    },
    {
      "epoch": 0.4276,
      "grad_norm": 3.294461488723755,
      "learning_rate": 8.576e-07,
      "logits/chosen": -2.2409844398498535,
      "logits/rejected": -3.07949161529541,
      "logps/chosen": -99.84115600585938,
      "logps/rejected": -101.86144256591797,
      "loss": 0.0423,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6456298828125,
      "rewards/margins": 3.353598117828369,
      "rewards/rejected": -1.7079682350158691,
      "step": 1069
    },
    {
      "epoch": 0.428,
      "grad_norm": 0.6929410099983215,
      "learning_rate": 8.574666666666666e-07,
      "logits/chosen": -2.345341682434082,
      "logits/rejected": -2.798013210296631,
      "logps/chosen": -184.4403076171875,
      "logps/rejected": -137.30259704589844,
      "loss": 0.0092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5969629287719727,
      "rewards/margins": 4.709571838378906,
      "rewards/rejected": -2.1126086711883545,
      "step": 1070
    },
    {
      "epoch": 0.4284,
      "grad_norm": 1.8489277362823486,
      "learning_rate": 8.573333333333332e-07,
      "logits/chosen": -2.6333236694335938,
      "logits/rejected": -2.359539031982422,
      "logps/chosen": -89.16944885253906,
      "logps/rejected": -92.06483459472656,
      "loss": 0.0232,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.69942045211792,
      "rewards/margins": 4.575656890869141,
      "rewards/rejected": -1.8762359619140625,
      "step": 1071
    },
    {
      "epoch": 0.4288,
      "grad_norm": 2.5370335578918457,
      "learning_rate": 8.571999999999999e-07,
      "logits/chosen": -2.115504264831543,
      "logits/rejected": -2.4362316131591797,
      "logps/chosen": -89.5761489868164,
      "logps/rejected": -131.19595336914062,
      "loss": 0.0226,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.249962091445923,
      "rewards/margins": 4.5640339851379395,
      "rewards/rejected": -2.3140716552734375,
      "step": 1072
    },
    {
      "epoch": 0.4292,
      "grad_norm": 0.918662428855896,
      "learning_rate": 8.570666666666666e-07,
      "logits/chosen": -2.520446538925171,
      "logits/rejected": -3.007762908935547,
      "logps/chosen": -182.38339233398438,
      "logps/rejected": -117.82496643066406,
      "loss": 0.0097,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9232261180877686,
      "rewards/margins": 5.5662312507629395,
      "rewards/rejected": -2.643004894256592,
      "step": 1073
    },
    {
      "epoch": 0.4296,
      "grad_norm": 0.8827731609344482,
      "learning_rate": 8.569333333333333e-07,
      "logits/chosen": -2.6688125133514404,
      "logits/rejected": -2.8011248111724854,
      "logps/chosen": -120.71054077148438,
      "logps/rejected": -136.00653076171875,
      "loss": 0.0116,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8360841274261475,
      "rewards/margins": 5.1663970947265625,
      "rewards/rejected": -1.3303132057189941,
      "step": 1074
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7582102417945862,
      "learning_rate": 8.568e-07,
      "logits/chosen": -2.1982288360595703,
      "logits/rejected": -2.2585926055908203,
      "logps/chosen": -109.75997161865234,
      "logps/rejected": -84.56463623046875,
      "loss": 0.0102,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0379478931427,
      "rewards/margins": 4.749809265136719,
      "rewards/rejected": -1.7118618488311768,
      "step": 1075
    },
    {
      "epoch": 0.4304,
      "grad_norm": 3.131563186645508,
      "learning_rate": 8.566666666666667e-07,
      "logits/chosen": -2.8532533645629883,
      "logits/rejected": -3.1531333923339844,
      "logps/chosen": -123.83399200439453,
      "logps/rejected": -136.8805389404297,
      "loss": 0.0274,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2941367626190186,
      "rewards/margins": 3.800529956817627,
      "rewards/rejected": -2.5063929557800293,
      "step": 1076
    },
    {
      "epoch": 0.4308,
      "grad_norm": 1.548867106437683,
      "learning_rate": 8.565333333333334e-07,
      "logits/chosen": -2.078381299972534,
      "logits/rejected": -2.774571180343628,
      "logps/chosen": -192.83514404296875,
      "logps/rejected": -149.2393798828125,
      "loss": 0.023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7363853454589844,
      "rewards/margins": 4.303017616271973,
      "rewards/rejected": -2.5666325092315674,
      "step": 1077
    },
    {
      "epoch": 0.4312,
      "grad_norm": 1.6052085161209106,
      "learning_rate": 8.564e-07,
      "logits/chosen": -2.205402135848999,
      "logits/rejected": -1.8970744609832764,
      "logps/chosen": -81.19064331054688,
      "logps/rejected": -153.73956298828125,
      "loss": 0.0129,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.70025634765625,
      "rewards/margins": 5.469536781311035,
      "rewards/rejected": -1.769280195236206,
      "step": 1078
    },
    {
      "epoch": 0.4316,
      "grad_norm": 0.24007152020931244,
      "learning_rate": 8.562666666666666e-07,
      "logits/chosen": -2.847217082977295,
      "logits/rejected": -3.1416616439819336,
      "logps/chosen": -152.9589385986328,
      "logps/rejected": -147.30856323242188,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.579561233520508,
      "rewards/margins": 5.813570022583008,
      "rewards/rejected": -3.234008550643921,
      "step": 1079
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.6255232095718384,
      "learning_rate": 8.561333333333332e-07,
      "logits/chosen": -2.0753679275512695,
      "logits/rejected": -2.571625232696533,
      "logps/chosen": -105.03964233398438,
      "logps/rejected": -114.88285827636719,
      "loss": 0.0114,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.682335376739502,
      "rewards/margins": 4.954667091369629,
      "rewards/rejected": -3.272332191467285,
      "step": 1080
    },
    {
      "epoch": 0.4324,
      "grad_norm": 0.22378917038440704,
      "learning_rate": 8.559999999999999e-07,
      "logits/chosen": -2.327416181564331,
      "logits/rejected": -2.749472141265869,
      "logps/chosen": -97.3907470703125,
      "logps/rejected": -104.8634033203125,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.383981466293335,
      "rewards/margins": 5.962656021118164,
      "rewards/rejected": -2.578674793243408,
      "step": 1081
    },
    {
      "epoch": 0.4328,
      "grad_norm": 0.7756544947624207,
      "learning_rate": 8.558666666666666e-07,
      "logits/chosen": -1.921020269393921,
      "logits/rejected": -3.142939567565918,
      "logps/chosen": -100.47828674316406,
      "logps/rejected": -155.9392852783203,
      "loss": 0.0085,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.751030683517456,
      "rewards/margins": 5.063791275024414,
      "rewards/rejected": -3.312760591506958,
      "step": 1082
    },
    {
      "epoch": 0.4332,
      "grad_norm": 1.3847041130065918,
      "learning_rate": 8.557333333333333e-07,
      "logits/chosen": -2.2158634662628174,
      "logits/rejected": -2.9073500633239746,
      "logps/chosen": -101.46617126464844,
      "logps/rejected": -117.80259704589844,
      "loss": 0.0218,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2776870727539062,
      "rewards/margins": 4.215941429138184,
      "rewards/rejected": -2.9382545948028564,
      "step": 1083
    },
    {
      "epoch": 0.4336,
      "grad_norm": 0.09263624995946884,
      "learning_rate": 8.556e-07,
      "logits/chosen": -2.78389835357666,
      "logits/rejected": -2.7325186729431152,
      "logps/chosen": -160.85658264160156,
      "logps/rejected": -134.88101196289062,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6434340476989746,
      "rewards/margins": 6.688164710998535,
      "rewards/rejected": -3.0447304248809814,
      "step": 1084
    },
    {
      "epoch": 0.434,
      "grad_norm": 0.17434634268283844,
      "learning_rate": 8.554666666666667e-07,
      "logits/chosen": -2.107311248779297,
      "logits/rejected": -2.6622707843780518,
      "logps/chosen": -52.923240661621094,
      "logps/rejected": -146.10894775390625,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.036219596862793,
      "rewards/margins": 6.430748462677002,
      "rewards/rejected": -3.394528865814209,
      "step": 1085
    },
    {
      "epoch": 0.4344,
      "grad_norm": 0.05645950883626938,
      "learning_rate": 8.553333333333333e-07,
      "logits/chosen": -2.3404035568237305,
      "logits/rejected": -3.1907081604003906,
      "logps/chosen": -117.41790008544922,
      "logps/rejected": -152.98809814453125,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.638932228088379,
      "rewards/margins": 7.124977111816406,
      "rewards/rejected": -3.4860448837280273,
      "step": 1086
    },
    {
      "epoch": 0.4348,
      "grad_norm": 0.10671361535787582,
      "learning_rate": 8.551999999999999e-07,
      "logits/chosen": -2.464721918106079,
      "logits/rejected": -2.8000361919403076,
      "logps/chosen": -97.01878356933594,
      "logps/rejected": -124.21553039550781,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.108425140380859,
      "rewards/margins": 6.3963727951049805,
      "rewards/rejected": -2.2879478931427,
      "step": 1087
    },
    {
      "epoch": 0.4352,
      "grad_norm": 6.737219333648682,
      "learning_rate": 8.550666666666666e-07,
      "logits/chosen": -2.2321369647979736,
      "logits/rejected": -2.340667247772217,
      "logps/chosen": -123.99313354492188,
      "logps/rejected": -96.72377014160156,
      "loss": 0.0786,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7108844518661499,
      "rewards/margins": 2.583162307739258,
      "rewards/rejected": -1.8722779750823975,
      "step": 1088
    },
    {
      "epoch": 0.4356,
      "grad_norm": 1.851807951927185,
      "learning_rate": 8.549333333333333e-07,
      "logits/chosen": -2.5419938564300537,
      "logits/rejected": -3.0396385192871094,
      "logps/chosen": -110.41107940673828,
      "logps/rejected": -104.66039276123047,
      "loss": 0.0281,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7775185108184814,
      "rewards/margins": 4.837185859680176,
      "rewards/rejected": -2.0596671104431152,
      "step": 1089
    },
    {
      "epoch": 0.436,
      "grad_norm": 1.737781047821045,
      "learning_rate": 8.548e-07,
      "logits/chosen": -2.7248921394348145,
      "logits/rejected": -2.825446605682373,
      "logps/chosen": -179.17153930664062,
      "logps/rejected": -110.37579345703125,
      "loss": 0.0253,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4922752380371094,
      "rewards/margins": 3.6640920639038086,
      "rewards/rejected": -2.17181658744812,
      "step": 1090
    },
    {
      "epoch": 0.4364,
      "grad_norm": 0.10069919377565384,
      "learning_rate": 8.546666666666666e-07,
      "logits/chosen": -2.042755126953125,
      "logits/rejected": -2.8159024715423584,
      "logps/chosen": -109.11576843261719,
      "logps/rejected": -127.59162902832031,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.234628677368164,
      "rewards/margins": 6.583517074584961,
      "rewards/rejected": -3.348888397216797,
      "step": 1091
    },
    {
      "epoch": 0.4368,
      "grad_norm": 0.4729370176792145,
      "learning_rate": 8.545333333333333e-07,
      "logits/chosen": -2.171630382537842,
      "logits/rejected": -3.3117260932922363,
      "logps/chosen": -139.21099853515625,
      "logps/rejected": -160.48358154296875,
      "loss": 0.0051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.379842519760132,
      "rewards/margins": 5.890273094177246,
      "rewards/rejected": -2.5104308128356934,
      "step": 1092
    },
    {
      "epoch": 0.4372,
      "grad_norm": 0.5133698582649231,
      "learning_rate": 8.544e-07,
      "logits/chosen": -2.674499273300171,
      "logits/rejected": -3.131991147994995,
      "logps/chosen": -226.53622436523438,
      "logps/rejected": -139.2229766845703,
      "loss": 0.0063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0981571674346924,
      "rewards/margins": 5.072744846343994,
      "rewards/rejected": -2.9745876789093018,
      "step": 1093
    },
    {
      "epoch": 0.4376,
      "grad_norm": 0.3839462995529175,
      "learning_rate": 8.542666666666666e-07,
      "logits/chosen": -2.3872885704040527,
      "logits/rejected": -2.7828476428985596,
      "logps/chosen": -108.00474548339844,
      "logps/rejected": -111.68836975097656,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.453246831893921,
      "rewards/margins": 6.160912990570068,
      "rewards/rejected": -2.7076663970947266,
      "step": 1094
    },
    {
      "epoch": 0.438,
      "grad_norm": 0.4042467474937439,
      "learning_rate": 8.541333333333333e-07,
      "logits/chosen": -2.0947365760803223,
      "logits/rejected": -3.229039192199707,
      "logps/chosen": -107.07288360595703,
      "logps/rejected": -137.9056396484375,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8818717002868652,
      "rewards/margins": 5.23902702331543,
      "rewards/rejected": -3.3571553230285645,
      "step": 1095
    },
    {
      "epoch": 0.4384,
      "grad_norm": 1.0287777185440063,
      "learning_rate": 8.539999999999999e-07,
      "logits/chosen": -2.3782358169555664,
      "logits/rejected": -2.8344573974609375,
      "logps/chosen": -174.2888641357422,
      "logps/rejected": -195.4410400390625,
      "loss": 0.0077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.693862199783325,
      "rewards/margins": 5.702510833740234,
      "rewards/rejected": -3.0086488723754883,
      "step": 1096
    },
    {
      "epoch": 0.4388,
      "grad_norm": 1.636803388595581,
      "learning_rate": 8.538666666666666e-07,
      "logits/chosen": -2.3744983673095703,
      "logits/rejected": -3.39389705657959,
      "logps/chosen": -94.65951538085938,
      "logps/rejected": -138.37203979492188,
      "loss": 0.0166,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.911214828491211,
      "rewards/margins": 6.001796245574951,
      "rewards/rejected": -4.09058141708374,
      "step": 1097
    },
    {
      "epoch": 0.4392,
      "grad_norm": 0.1798582822084427,
      "learning_rate": 8.537333333333333e-07,
      "logits/chosen": -2.544304370880127,
      "logits/rejected": -2.4381203651428223,
      "logps/chosen": -114.19638061523438,
      "logps/rejected": -110.1236343383789,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5823755264282227,
      "rewards/margins": 6.073442459106445,
      "rewards/rejected": -2.4910666942596436,
      "step": 1098
    },
    {
      "epoch": 0.4396,
      "grad_norm": 0.5353990197181702,
      "learning_rate": 8.536e-07,
      "logits/chosen": -2.3258790969848633,
      "logits/rejected": -3.2343573570251465,
      "logps/chosen": -120.94692993164062,
      "logps/rejected": -96.25936889648438,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.251126766204834,
      "rewards/margins": 5.1817851066589355,
      "rewards/rejected": -1.9306581020355225,
      "step": 1099
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.976406455039978,
      "learning_rate": 8.534666666666667e-07,
      "logits/chosen": -1.996948480606079,
      "logits/rejected": -2.8538618087768555,
      "logps/chosen": -92.79177856445312,
      "logps/rejected": -105.4939956665039,
      "loss": 0.0209,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9403433799743652,
      "rewards/margins": 4.945117950439453,
      "rewards/rejected": -2.004774570465088,
      "step": 1100
    },
    {
      "epoch": 0.4404,
      "grad_norm": 2.648000478744507,
      "learning_rate": 8.533333333333334e-07,
      "logits/chosen": -2.3108439445495605,
      "logits/rejected": -2.4994449615478516,
      "logps/chosen": -91.17076110839844,
      "logps/rejected": -140.24029541015625,
      "loss": 0.0267,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.984971761703491,
      "rewards/margins": 5.16025447845459,
      "rewards/rejected": -2.1752827167510986,
      "step": 1101
    },
    {
      "epoch": 0.4408,
      "grad_norm": 1.0820717811584473,
      "learning_rate": 8.531999999999999e-07,
      "logits/chosen": -1.883169412612915,
      "logits/rejected": -3.37162184715271,
      "logps/chosen": -94.78004455566406,
      "logps/rejected": -121.77140045166016,
      "loss": 0.011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.796849489212036,
      "rewards/margins": 4.962671279907227,
      "rewards/rejected": -2.1658217906951904,
      "step": 1102
    },
    {
      "epoch": 0.4412,
      "grad_norm": 2.7143335342407227,
      "learning_rate": 8.530666666666666e-07,
      "logits/chosen": -2.635200023651123,
      "logits/rejected": -2.820204257965088,
      "logps/chosen": -174.4458770751953,
      "logps/rejected": -122.45642852783203,
      "loss": 0.0399,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.166740894317627,
      "rewards/margins": 4.382011890411377,
      "rewards/rejected": -2.21527099609375,
      "step": 1103
    },
    {
      "epoch": 0.4416,
      "grad_norm": 0.7189952731132507,
      "learning_rate": 8.529333333333333e-07,
      "logits/chosen": -2.643861770629883,
      "logits/rejected": -3.250283718109131,
      "logps/chosen": -132.66720581054688,
      "logps/rejected": -121.514404296875,
      "loss": 0.0065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.751082420349121,
      "rewards/margins": 6.2091064453125,
      "rewards/rejected": -3.458024024963379,
      "step": 1104
    },
    {
      "epoch": 0.442,
      "grad_norm": 0.2800554633140564,
      "learning_rate": 8.528e-07,
      "logits/chosen": -1.7274930477142334,
      "logits/rejected": -3.2399425506591797,
      "logps/chosen": -103.69326782226562,
      "logps/rejected": -140.18551635742188,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.895744800567627,
      "rewards/margins": 6.605001449584961,
      "rewards/rejected": -3.709256649017334,
      "step": 1105
    },
    {
      "epoch": 0.4424,
      "grad_norm": 0.45133259892463684,
      "learning_rate": 8.526666666666666e-07,
      "logits/chosen": -1.7827670574188232,
      "logits/rejected": -2.990953207015991,
      "logps/chosen": -73.2272720336914,
      "logps/rejected": -129.8207244873047,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1407604217529297,
      "rewards/margins": 5.371891975402832,
      "rewards/rejected": -3.2311315536499023,
      "step": 1106
    },
    {
      "epoch": 0.4428,
      "grad_norm": 0.14609961211681366,
      "learning_rate": 8.525333333333333e-07,
      "logits/chosen": -2.8888497352600098,
      "logits/rejected": -3.0184144973754883,
      "logps/chosen": -163.11651611328125,
      "logps/rejected": -154.51214599609375,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.759899139404297,
      "rewards/margins": 6.797417640686035,
      "rewards/rejected": -3.0375187397003174,
      "step": 1107
    },
    {
      "epoch": 0.4432,
      "grad_norm": 0.6506882309913635,
      "learning_rate": 8.524e-07,
      "logits/chosen": -2.5612003803253174,
      "logits/rejected": -2.734370231628418,
      "logps/chosen": -173.68386840820312,
      "logps/rejected": -124.51103973388672,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4555230140686035,
      "rewards/margins": 5.259701251983643,
      "rewards/rejected": -2.804178237915039,
      "step": 1108
    },
    {
      "epoch": 0.4436,
      "grad_norm": 0.6661438345909119,
      "learning_rate": 8.522666666666666e-07,
      "logits/chosen": -2.3844640254974365,
      "logits/rejected": -3.2522318363189697,
      "logps/chosen": -110.58511352539062,
      "logps/rejected": -127.77584838867188,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4325673580169678,
      "rewards/margins": 4.885494232177734,
      "rewards/rejected": -2.4529266357421875,
      "step": 1109
    },
    {
      "epoch": 0.444,
      "grad_norm": 0.5448317527770996,
      "learning_rate": 8.521333333333333e-07,
      "logits/chosen": -2.8329923152923584,
      "logits/rejected": -2.508375644683838,
      "logps/chosen": -210.68807983398438,
      "logps/rejected": -100.57522583007812,
      "loss": 0.0057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.413886308670044,
      "rewards/margins": 5.287845611572266,
      "rewards/rejected": -1.873958945274353,
      "step": 1110
    },
    {
      "epoch": 0.4444,
      "grad_norm": 0.06556960940361023,
      "learning_rate": 8.52e-07,
      "logits/chosen": -2.4599838256835938,
      "logits/rejected": -2.989429473876953,
      "logps/chosen": -162.54379272460938,
      "logps/rejected": -173.1974334716797,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9015893936157227,
      "rewards/margins": 7.2174882888793945,
      "rewards/rejected": -3.31589937210083,
      "step": 1111
    },
    {
      "epoch": 0.4448,
      "grad_norm": 1.3887356519699097,
      "learning_rate": 8.518666666666666e-07,
      "logits/chosen": -2.0164623260498047,
      "logits/rejected": -2.9316389560699463,
      "logps/chosen": -79.13898468017578,
      "logps/rejected": -129.23793029785156,
      "loss": 0.013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.368931531906128,
      "rewards/margins": 4.61474609375,
      "rewards/rejected": -2.245814085006714,
      "step": 1112
    },
    {
      "epoch": 0.4452,
      "grad_norm": 0.5753272771835327,
      "learning_rate": 8.517333333333333e-07,
      "logits/chosen": -2.343658924102783,
      "logits/rejected": -3.0720105171203613,
      "logps/chosen": -141.05923461914062,
      "logps/rejected": -132.08148193359375,
      "loss": 0.0072,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7626142501831055,
      "rewards/margins": 5.527157783508301,
      "rewards/rejected": -2.764543294906616,
      "step": 1113
    },
    {
      "epoch": 0.4456,
      "grad_norm": 1.4188882112503052,
      "learning_rate": 8.516e-07,
      "logits/chosen": -2.699547290802002,
      "logits/rejected": -3.067544937133789,
      "logps/chosen": -141.87942504882812,
      "logps/rejected": -184.014404296875,
      "loss": 0.0115,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5237298011779785,
      "rewards/margins": 5.5197882652282715,
      "rewards/rejected": -2.996058464050293,
      "step": 1114
    },
    {
      "epoch": 0.446,
      "grad_norm": 0.20880360901355743,
      "learning_rate": 8.514666666666666e-07,
      "logits/chosen": -2.182849645614624,
      "logits/rejected": -2.031435489654541,
      "logps/chosen": -105.260986328125,
      "logps/rejected": -92.39543151855469,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.080613136291504,
      "rewards/margins": 5.845173358917236,
      "rewards/rejected": -1.7645602226257324,
      "step": 1115
    },
    {
      "epoch": 0.4464,
      "grad_norm": 0.7836132049560547,
      "learning_rate": 8.513333333333333e-07,
      "logits/chosen": -2.089369773864746,
      "logits/rejected": -2.583808422088623,
      "logps/chosen": -127.85711669921875,
      "logps/rejected": -190.9218292236328,
      "loss": 0.0073,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7433395385742188,
      "rewards/margins": 4.9358367919921875,
      "rewards/rejected": -2.1924972534179688,
      "step": 1116
    },
    {
      "epoch": 0.4468,
      "grad_norm": 1.9923053979873657,
      "learning_rate": 8.511999999999999e-07,
      "logits/chosen": -2.243405342102051,
      "logits/rejected": -2.522756576538086,
      "logps/chosen": -69.70514678955078,
      "logps/rejected": -92.20932006835938,
      "loss": 0.0306,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.711275100708008,
      "rewards/margins": 4.17728328704834,
      "rewards/rejected": -1.4660084247589111,
      "step": 1117
    },
    {
      "epoch": 0.4472,
      "grad_norm": 0.13489964604377747,
      "learning_rate": 8.510666666666666e-07,
      "logits/chosen": -2.339569091796875,
      "logits/rejected": -3.143958806991577,
      "logps/chosen": -88.61891174316406,
      "logps/rejected": -145.00198364257812,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0530223846435547,
      "rewards/margins": 6.146371841430664,
      "rewards/rejected": -3.093348979949951,
      "step": 1118
    },
    {
      "epoch": 0.4476,
      "grad_norm": 1.0169668197631836,
      "learning_rate": 8.509333333333333e-07,
      "logits/chosen": -2.3133063316345215,
      "logits/rejected": -3.344860553741455,
      "logps/chosen": -148.3380126953125,
      "logps/rejected": -135.4773406982422,
      "loss": 0.0083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.581678867340088,
      "rewards/margins": 4.796196937561035,
      "rewards/rejected": -2.2145180702209473,
      "step": 1119
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.38500455021858215,
      "learning_rate": 8.508e-07,
      "logits/chosen": -2.259507656097412,
      "logits/rejected": -3.3558099269866943,
      "logps/chosen": -133.5844268798828,
      "logps/rejected": -142.02267456054688,
      "loss": 0.0056,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8005175590515137,
      "rewards/margins": 5.219730377197266,
      "rewards/rejected": -2.4192123413085938,
      "step": 1120
    },
    {
      "epoch": 0.4484,
      "grad_norm": 0.8922356367111206,
      "learning_rate": 8.506666666666667e-07,
      "logits/chosen": -2.215946674346924,
      "logits/rejected": -2.307117462158203,
      "logps/chosen": -98.13612365722656,
      "logps/rejected": -86.67184448242188,
      "loss": 0.0094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.878783702850342,
      "rewards/margins": 4.758363246917725,
      "rewards/rejected": -1.8795793056488037,
      "step": 1121
    },
    {
      "epoch": 0.4488,
      "grad_norm": 0.5108032822608948,
      "learning_rate": 8.505333333333334e-07,
      "logits/chosen": -2.5217185020446777,
      "logits/rejected": -3.0599966049194336,
      "logps/chosen": -147.31884765625,
      "logps/rejected": -129.9339599609375,
      "loss": 0.0056,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6818318367004395,
      "rewards/margins": 5.787929058074951,
      "rewards/rejected": -3.1060972213745117,
      "step": 1122
    },
    {
      "epoch": 0.4492,
      "grad_norm": 0.04669588804244995,
      "learning_rate": 8.504e-07,
      "logits/chosen": -2.0893375873565674,
      "logits/rejected": -2.7000465393066406,
      "logps/chosen": -95.3854751586914,
      "logps/rejected": -135.68026733398438,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.577230453491211,
      "rewards/margins": 7.7247161865234375,
      "rewards/rejected": -3.1474857330322266,
      "step": 1123
    },
    {
      "epoch": 0.4496,
      "grad_norm": 1.139458179473877,
      "learning_rate": 8.502666666666665e-07,
      "logits/chosen": -2.135226249694824,
      "logits/rejected": -2.2914962768554688,
      "logps/chosen": -109.92355346679688,
      "logps/rejected": -127.00242614746094,
      "loss": 0.014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9413387775421143,
      "rewards/margins": 4.901872634887695,
      "rewards/rejected": -1.960533618927002,
      "step": 1124
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.199811577796936,
      "learning_rate": 8.501333333333332e-07,
      "logits/chosen": -2.196195125579834,
      "logits/rejected": -2.6085357666015625,
      "logps/chosen": -118.02581787109375,
      "logps/rejected": -109.92259216308594,
      "loss": 0.0195,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6500252485275269,
      "rewards/margins": 4.029621124267578,
      "rewards/rejected": -2.379595994949341,
      "step": 1125
    },
    {
      "epoch": 0.4504,
      "grad_norm": 10.827905654907227,
      "learning_rate": 8.499999999999999e-07,
      "logits/chosen": -2.499717950820923,
      "logits/rejected": -2.8513894081115723,
      "logps/chosen": -170.2755584716797,
      "logps/rejected": -107.19267272949219,
      "loss": 0.146,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.594140648841858,
      "rewards/margins": 3.628974437713623,
      "rewards/rejected": -2.0348339080810547,
      "step": 1126
    },
    {
      "epoch": 0.4508,
      "grad_norm": 0.6000107526779175,
      "learning_rate": 8.498666666666666e-07,
      "logits/chosen": -2.6909713745117188,
      "logits/rejected": -3.0462474822998047,
      "logps/chosen": -167.67562866210938,
      "logps/rejected": -136.70623779296875,
      "loss": 0.0073,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4730238914489746,
      "rewards/margins": 5.644964694976807,
      "rewards/rejected": -3.171940803527832,
      "step": 1127
    },
    {
      "epoch": 0.4512,
      "grad_norm": 0.15695783495903015,
      "learning_rate": 8.497333333333333e-07,
      "logits/chosen": -1.9699122905731201,
      "logits/rejected": -2.864086151123047,
      "logps/chosen": -114.32728576660156,
      "logps/rejected": -136.81573486328125,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3921313285827637,
      "rewards/margins": 6.59895658493042,
      "rewards/rejected": -3.206824779510498,
      "step": 1128
    },
    {
      "epoch": 0.4516,
      "grad_norm": 1.1337077617645264,
      "learning_rate": 8.496e-07,
      "logits/chosen": -2.2630608081817627,
      "logits/rejected": -2.194422721862793,
      "logps/chosen": -101.43923950195312,
      "logps/rejected": -100.48216247558594,
      "loss": 0.022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9332687854766846,
      "rewards/margins": 4.053693771362305,
      "rewards/rejected": -2.120424747467041,
      "step": 1129
    },
    {
      "epoch": 0.452,
      "grad_norm": 6.556703567504883,
      "learning_rate": 8.494666666666667e-07,
      "logits/chosen": -2.105656147003174,
      "logits/rejected": -2.480259418487549,
      "logps/chosen": -79.63032531738281,
      "logps/rejected": -107.42529296875,
      "loss": 0.0805,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1125552654266357,
      "rewards/margins": 4.360153675079346,
      "rewards/rejected": -2.24759840965271,
      "step": 1130
    },
    {
      "epoch": 0.4524,
      "grad_norm": 0.6061076521873474,
      "learning_rate": 8.493333333333334e-07,
      "logits/chosen": -2.393672466278076,
      "logits/rejected": -2.8610925674438477,
      "logps/chosen": -129.62991333007812,
      "logps/rejected": -164.88833618164062,
      "loss": 0.0073,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5920257568359375,
      "rewards/margins": 5.278134346008301,
      "rewards/rejected": -2.6861085891723633,
      "step": 1131
    },
    {
      "epoch": 0.4528,
      "grad_norm": 0.25976651906967163,
      "learning_rate": 8.492e-07,
      "logits/chosen": -2.662475347518921,
      "logits/rejected": -2.736456871032715,
      "logps/chosen": -159.13638305664062,
      "logps/rejected": -135.02268981933594,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8260016441345215,
      "rewards/margins": 6.694919109344482,
      "rewards/rejected": -2.868917226791382,
      "step": 1132
    },
    {
      "epoch": 0.4532,
      "grad_norm": 5.252460956573486,
      "learning_rate": 8.490666666666666e-07,
      "logits/chosen": -2.279024600982666,
      "logits/rejected": -2.445221424102783,
      "logps/chosen": -113.11271667480469,
      "logps/rejected": -85.57432556152344,
      "loss": 0.0516,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1047582626342773,
      "rewards/margins": 3.3435020446777344,
      "rewards/rejected": -1.2387440204620361,
      "step": 1133
    },
    {
      "epoch": 0.4536,
      "grad_norm": 0.2752933204174042,
      "learning_rate": 8.489333333333332e-07,
      "logits/chosen": -2.6636781692504883,
      "logits/rejected": -2.6951756477355957,
      "logps/chosen": -155.49676513671875,
      "logps/rejected": -134.15728759765625,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5333313941955566,
      "rewards/margins": 5.6307220458984375,
      "rewards/rejected": -3.097391128540039,
      "step": 1134
    },
    {
      "epoch": 0.454,
      "grad_norm": 0.12977540493011475,
      "learning_rate": 8.487999999999999e-07,
      "logits/chosen": -1.9896297454833984,
      "logits/rejected": -2.4078941345214844,
      "logps/chosen": -76.70378112792969,
      "logps/rejected": -120.20172119140625,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6950273513793945,
      "rewards/margins": 7.338471412658691,
      "rewards/rejected": -3.643444061279297,
      "step": 1135
    },
    {
      "epoch": 0.4544,
      "grad_norm": 0.7726789712905884,
      "learning_rate": 8.486666666666666e-07,
      "logits/chosen": -2.1167359352111816,
      "logits/rejected": -3.6272077560424805,
      "logps/chosen": -158.0750274658203,
      "logps/rejected": -138.47238159179688,
      "loss": 0.0102,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2662575244903564,
      "rewards/margins": 5.187443733215332,
      "rewards/rejected": -2.9211862087249756,
      "step": 1136
    },
    {
      "epoch": 0.4548,
      "grad_norm": 0.11290790885686874,
      "learning_rate": 8.485333333333333e-07,
      "logits/chosen": -2.24194598197937,
      "logits/rejected": -2.9049971103668213,
      "logps/chosen": -100.60031127929688,
      "logps/rejected": -185.39385986328125,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.910029649734497,
      "rewards/margins": 7.028423309326172,
      "rewards/rejected": -3.118393898010254,
      "step": 1137
    },
    {
      "epoch": 0.4552,
      "grad_norm": 0.4918477237224579,
      "learning_rate": 8.484e-07,
      "logits/chosen": -2.0478553771972656,
      "logits/rejected": -2.6150598526000977,
      "logps/chosen": -117.7969741821289,
      "logps/rejected": -159.64492797851562,
      "loss": 0.0063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6489639282226562,
      "rewards/margins": 5.063536643981934,
      "rewards/rejected": -2.4145729541778564,
      "step": 1138
    },
    {
      "epoch": 0.4556,
      "grad_norm": 0.6194621920585632,
      "learning_rate": 8.482666666666666e-07,
      "logits/chosen": -2.5861072540283203,
      "logits/rejected": -2.8204762935638428,
      "logps/chosen": -110.75212097167969,
      "logps/rejected": -146.75697326660156,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7934280633926392,
      "rewards/margins": 5.680166244506836,
      "rewards/rejected": -3.8867383003234863,
      "step": 1139
    },
    {
      "epoch": 0.456,
      "grad_norm": 2.510101556777954,
      "learning_rate": 8.481333333333333e-07,
      "logits/chosen": -2.550199031829834,
      "logits/rejected": -3.050227165222168,
      "logps/chosen": -150.8756561279297,
      "logps/rejected": -109.82000732421875,
      "loss": 0.0281,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.942572832107544,
      "rewards/margins": 4.3599700927734375,
      "rewards/rejected": -2.4173970222473145,
      "step": 1140
    },
    {
      "epoch": 0.4564,
      "grad_norm": 2.8262922763824463,
      "learning_rate": 8.48e-07,
      "logits/chosen": -2.4276881217956543,
      "logits/rejected": -2.742851734161377,
      "logps/chosen": -130.339111328125,
      "logps/rejected": -131.5236358642578,
      "loss": 0.0417,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.766377329826355,
      "rewards/margins": 5.1771159172058105,
      "rewards/rejected": -3.410738468170166,
      "step": 1141
    },
    {
      "epoch": 0.4568,
      "grad_norm": 0.4586805999279022,
      "learning_rate": 8.478666666666667e-07,
      "logits/chosen": -1.9300624132156372,
      "logits/rejected": -2.806605815887451,
      "logps/chosen": -104.2266845703125,
      "logps/rejected": -154.83041381835938,
      "loss": 0.006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4462170600891113,
      "rewards/margins": 5.114471912384033,
      "rewards/rejected": -2.668254852294922,
      "step": 1142
    },
    {
      "epoch": 0.4572,
      "grad_norm": 0.11055278778076172,
      "learning_rate": 8.477333333333332e-07,
      "logits/chosen": -2.317695140838623,
      "logits/rejected": -2.9032483100891113,
      "logps/chosen": -157.4061279296875,
      "logps/rejected": -143.653564453125,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5148086547851562,
      "rewards/margins": 6.386585235595703,
      "rewards/rejected": -2.871776580810547,
      "step": 1143
    },
    {
      "epoch": 0.4576,
      "grad_norm": 0.7500808835029602,
      "learning_rate": 8.475999999999999e-07,
      "logits/chosen": -2.5145716667175293,
      "logits/rejected": -3.137063980102539,
      "logps/chosen": -236.38800048828125,
      "logps/rejected": -139.396484375,
      "loss": 0.0065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3787360191345215,
      "rewards/margins": 6.501054286956787,
      "rewards/rejected": -3.1223182678222656,
      "step": 1144
    },
    {
      "epoch": 0.458,
      "grad_norm": 0.46675992012023926,
      "learning_rate": 8.474666666666666e-07,
      "logits/chosen": -2.0599565505981445,
      "logits/rejected": -3.0669538974761963,
      "logps/chosen": -80.11166381835938,
      "logps/rejected": -126.27342224121094,
      "loss": 0.0081,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.520545244216919,
      "rewards/margins": 5.07904577255249,
      "rewards/rejected": -2.5585007667541504,
      "step": 1145
    },
    {
      "epoch": 0.4584,
      "grad_norm": 12.309978485107422,
      "learning_rate": 8.473333333333333e-07,
      "logits/chosen": -2.7432971000671387,
      "logits/rejected": -3.01263427734375,
      "logps/chosen": -175.79425048828125,
      "logps/rejected": -124.49615478515625,
      "loss": 0.1515,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9051185846328735,
      "rewards/margins": 3.451115131378174,
      "rewards/rejected": -1.5459964275360107,
      "step": 1146
    },
    {
      "epoch": 0.4588,
      "grad_norm": 0.04592454805970192,
      "learning_rate": 8.471999999999999e-07,
      "logits/chosen": -2.4583115577697754,
      "logits/rejected": -2.9823460578918457,
      "logps/chosen": -144.72161865234375,
      "logps/rejected": -129.14141845703125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.685387134552002,
      "rewards/margins": 7.6575093269348145,
      "rewards/rejected": -3.9721221923828125,
      "step": 1147
    },
    {
      "epoch": 0.4592,
      "grad_norm": 3.448596954345703,
      "learning_rate": 8.470666666666666e-07,
      "logits/chosen": -2.992314100265503,
      "logits/rejected": -2.8302149772644043,
      "logps/chosen": -161.317626953125,
      "logps/rejected": -146.96383666992188,
      "loss": 0.0326,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4269485473632812,
      "rewards/margins": 4.628419876098633,
      "rewards/rejected": -3.2014710903167725,
      "step": 1148
    },
    {
      "epoch": 0.4596,
      "grad_norm": 0.019269825890660286,
      "learning_rate": 8.469333333333333e-07,
      "logits/chosen": -2.0932514667510986,
      "logits/rejected": -2.960777759552002,
      "logps/chosen": -105.58580780029297,
      "logps/rejected": -169.58389282226562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.649229526519775,
      "rewards/margins": 8.370944023132324,
      "rewards/rejected": -3.7217140197753906,
      "step": 1149
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.017595486715435982,
      "learning_rate": 8.468e-07,
      "logits/chosen": -2.014641523361206,
      "logits/rejected": -3.038898468017578,
      "logps/chosen": -110.22096252441406,
      "logps/rejected": -149.78900146484375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.212736129760742,
      "rewards/margins": 8.414013862609863,
      "rewards/rejected": -4.201277732849121,
      "step": 1150
    },
    {
      "epoch": 0.4604,
      "grad_norm": 0.4214557111263275,
      "learning_rate": 8.466666666666667e-07,
      "logits/chosen": -2.2750205993652344,
      "logits/rejected": -3.053307056427002,
      "logps/chosen": -113.01104736328125,
      "logps/rejected": -122.62979125976562,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.248877763748169,
      "rewards/margins": 5.395477771759033,
      "rewards/rejected": -2.1466000080108643,
      "step": 1151
    },
    {
      "epoch": 0.4608,
      "grad_norm": 0.7063553333282471,
      "learning_rate": 8.465333333333334e-07,
      "logits/chosen": -2.2433218955993652,
      "logits/rejected": -2.9356775283813477,
      "logps/chosen": -144.989013671875,
      "logps/rejected": -119.98484802246094,
      "loss": 0.0063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1862518787384033,
      "rewards/margins": 5.177833557128906,
      "rewards/rejected": -2.991581439971924,
      "step": 1152
    },
    {
      "epoch": 0.4612,
      "grad_norm": 0.10768558830022812,
      "learning_rate": 8.464e-07,
      "logits/chosen": -2.376471996307373,
      "logits/rejected": -2.9173359870910645,
      "logps/chosen": -183.14218139648438,
      "logps/rejected": -125.89025115966797,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.800726890563965,
      "rewards/margins": 7.203814506530762,
      "rewards/rejected": -2.403087615966797,
      "step": 1153
    },
    {
      "epoch": 0.4616,
      "grad_norm": 0.8827125430107117,
      "learning_rate": 8.462666666666665e-07,
      "logits/chosen": -2.5063579082489014,
      "logits/rejected": -2.8143415451049805,
      "logps/chosen": -124.90799713134766,
      "logps/rejected": -118.54403686523438,
      "loss": 0.0111,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6559693813323975,
      "rewards/margins": 4.786500453948975,
      "rewards/rejected": -2.130531072616577,
      "step": 1154
    },
    {
      "epoch": 0.462,
      "grad_norm": 4.063684463500977,
      "learning_rate": 8.461333333333332e-07,
      "logits/chosen": -2.6173267364501953,
      "logits/rejected": -3.1064200401306152,
      "logps/chosen": -90.64857482910156,
      "logps/rejected": -115.82921600341797,
      "loss": 0.0625,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6565884351730347,
      "rewards/margins": 3.812235116958618,
      "rewards/rejected": -2.155646562576294,
      "step": 1155
    },
    {
      "epoch": 0.4624,
      "grad_norm": 0.13672290742397308,
      "learning_rate": 8.459999999999999e-07,
      "logits/chosen": -2.4898009300231934,
      "logits/rejected": -2.403167963027954,
      "logps/chosen": -182.73199462890625,
      "logps/rejected": -130.2166290283203,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.45760440826416,
      "rewards/margins": 6.603767395019531,
      "rewards/rejected": -3.146162986755371,
      "step": 1156
    },
    {
      "epoch": 0.4628,
      "grad_norm": 0.46217766404151917,
      "learning_rate": 8.458666666666666e-07,
      "logits/chosen": -2.57071590423584,
      "logits/rejected": -3.7738723754882812,
      "logps/chosen": -104.47767639160156,
      "logps/rejected": -196.22447204589844,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.511416435241699,
      "rewards/margins": 5.71236515045166,
      "rewards/rejected": -3.200949192047119,
      "step": 1157
    },
    {
      "epoch": 0.4632,
      "grad_norm": 0.2407529503107071,
      "learning_rate": 8.457333333333333e-07,
      "logits/chosen": -2.642123222351074,
      "logits/rejected": -2.9359047412872314,
      "logps/chosen": -153.943115234375,
      "logps/rejected": -142.24411010742188,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9767723083496094,
      "rewards/margins": 6.140717506408691,
      "rewards/rejected": -3.163945436477661,
      "step": 1158
    },
    {
      "epoch": 0.4636,
      "grad_norm": 2.8161423206329346,
      "learning_rate": 8.456e-07,
      "logits/chosen": -2.298475742340088,
      "logits/rejected": -2.5422306060791016,
      "logps/chosen": -87.82106018066406,
      "logps/rejected": -95.15751647949219,
      "loss": 0.033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0615651607513428,
      "rewards/margins": 4.733338356018066,
      "rewards/rejected": -2.6717734336853027,
      "step": 1159
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.18619439005851746,
      "learning_rate": 8.454666666666667e-07,
      "logits/chosen": -2.0719592571258545,
      "logits/rejected": -2.8126726150512695,
      "logps/chosen": -99.29428100585938,
      "logps/rejected": -119.65364074707031,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.027164936065674,
      "rewards/margins": 6.272768974304199,
      "rewards/rejected": -3.2456040382385254,
      "step": 1160
    },
    {
      "epoch": 0.4644,
      "grad_norm": 0.1448793113231659,
      "learning_rate": 8.453333333333334e-07,
      "logits/chosen": -2.599289655685425,
      "logits/rejected": -3.4117984771728516,
      "logps/chosen": -150.87379455566406,
      "logps/rejected": -147.3308563232422,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.3456926345825195,
      "rewards/margins": 6.86362361907959,
      "rewards/rejected": -2.5179309844970703,
      "step": 1161
    },
    {
      "epoch": 0.4648,
      "grad_norm": 0.4975354075431824,
      "learning_rate": 8.451999999999999e-07,
      "logits/chosen": -2.4629554748535156,
      "logits/rejected": -2.3365867137908936,
      "logps/chosen": -103.43301391601562,
      "logps/rejected": -165.15609741210938,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7326016426086426,
      "rewards/margins": 5.7535881996154785,
      "rewards/rejected": -2.020986557006836,
      "step": 1162
    },
    {
      "epoch": 0.4652,
      "grad_norm": 1.2871915102005005,
      "learning_rate": 8.450666666666666e-07,
      "logits/chosen": -2.1620981693267822,
      "logits/rejected": -3.013684034347534,
      "logps/chosen": -156.89199829101562,
      "logps/rejected": -129.11386108398438,
      "loss": 0.013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8860230445861816,
      "rewards/margins": 5.046128273010254,
      "rewards/rejected": -3.1601052284240723,
      "step": 1163
    },
    {
      "epoch": 0.4656,
      "grad_norm": 0.3215360641479492,
      "learning_rate": 8.449333333333332e-07,
      "logits/chosen": -2.4615397453308105,
      "logits/rejected": -3.270293951034546,
      "logps/chosen": -130.52145385742188,
      "logps/rejected": -149.53451538085938,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.253800868988037,
      "rewards/margins": 6.889359474182129,
      "rewards/rejected": -2.635558605194092,
      "step": 1164
    },
    {
      "epoch": 0.466,
      "grad_norm": 0.5843353271484375,
      "learning_rate": 8.447999999999999e-07,
      "logits/chosen": -2.831329822540283,
      "logits/rejected": -3.1222195625305176,
      "logps/chosen": -175.29934692382812,
      "logps/rejected": -148.191162109375,
      "loss": 0.0056,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7617005109786987,
      "rewards/margins": 5.347483158111572,
      "rewards/rejected": -3.585782527923584,
      "step": 1165
    },
    {
      "epoch": 0.4664,
      "grad_norm": 0.21941137313842773,
      "learning_rate": 8.446666666666666e-07,
      "logits/chosen": -2.951871871948242,
      "logits/rejected": -3.280423641204834,
      "logps/chosen": -178.35134887695312,
      "logps/rejected": -168.67266845703125,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3473384380340576,
      "rewards/margins": 6.153267860412598,
      "rewards/rejected": -3.805929183959961,
      "step": 1166
    },
    {
      "epoch": 0.4668,
      "grad_norm": 1.9358830451965332,
      "learning_rate": 8.445333333333333e-07,
      "logits/chosen": -2.760929584503174,
      "logits/rejected": -3.0401158332824707,
      "logps/chosen": -145.89260864257812,
      "logps/rejected": -115.45069885253906,
      "loss": 0.0346,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.029669165611267,
      "rewards/margins": 3.580923318862915,
      "rewards/rejected": -2.5512540340423584,
      "step": 1167
    },
    {
      "epoch": 0.4672,
      "grad_norm": 1.3582448959350586,
      "learning_rate": 8.444e-07,
      "logits/chosen": -2.0438148975372314,
      "logits/rejected": -3.3731460571289062,
      "logps/chosen": -100.35346984863281,
      "logps/rejected": -117.30746459960938,
      "loss": 0.0085,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3661017417907715,
      "rewards/margins": 6.089666366577148,
      "rewards/rejected": -2.7235641479492188,
      "step": 1168
    },
    {
      "epoch": 0.4676,
      "grad_norm": 0.25944092869758606,
      "learning_rate": 8.442666666666667e-07,
      "logits/chosen": -1.903259515762329,
      "logits/rejected": -2.5651941299438477,
      "logps/chosen": -102.71669006347656,
      "logps/rejected": -96.09286499023438,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.001842498779297,
      "rewards/margins": 6.618264198303223,
      "rewards/rejected": -2.6164214611053467,
      "step": 1169
    },
    {
      "epoch": 0.468,
      "grad_norm": 0.5969776511192322,
      "learning_rate": 8.441333333333333e-07,
      "logits/chosen": -2.3903446197509766,
      "logits/rejected": -2.882307529449463,
      "logps/chosen": -116.3565673828125,
      "logps/rejected": -141.780029296875,
      "loss": 0.007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.904325246810913,
      "rewards/margins": 5.314353942871094,
      "rewards/rejected": -2.4100289344787598,
      "step": 1170
    },
    {
      "epoch": 0.4684,
      "grad_norm": 1.0597867965698242,
      "learning_rate": 8.439999999999999e-07,
      "logits/chosen": -2.5407931804656982,
      "logits/rejected": -2.3986873626708984,
      "logps/chosen": -105.58880615234375,
      "logps/rejected": -136.7283935546875,
      "loss": 0.014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3950743675231934,
      "rewards/margins": 4.259861469268799,
      "rewards/rejected": -1.864786982536316,
      "step": 1171
    },
    {
      "epoch": 0.4688,
      "grad_norm": 0.5720253586769104,
      "learning_rate": 8.438666666666666e-07,
      "logits/chosen": -2.6733016967773438,
      "logits/rejected": -2.860450267791748,
      "logps/chosen": -152.62509155273438,
      "logps/rejected": -132.77198791503906,
      "loss": 0.0067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0021355152130127,
      "rewards/margins": 5.260775566101074,
      "rewards/rejected": -2.2586400508880615,
      "step": 1172
    },
    {
      "epoch": 0.4692,
      "grad_norm": 0.4218292534351349,
      "learning_rate": 8.437333333333333e-07,
      "logits/chosen": -2.2941222190856934,
      "logits/rejected": -2.6964049339294434,
      "logps/chosen": -123.28681945800781,
      "logps/rejected": -141.0786895751953,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.132497787475586,
      "rewards/margins": 5.664209365844727,
      "rewards/rejected": -2.5317115783691406,
      "step": 1173
    },
    {
      "epoch": 0.4696,
      "grad_norm": 0.32179972529411316,
      "learning_rate": 8.436e-07,
      "logits/chosen": -2.267911434173584,
      "logits/rejected": -2.867000102996826,
      "logps/chosen": -146.1827392578125,
      "logps/rejected": -166.50811767578125,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3992958068847656,
      "rewards/margins": 5.528785705566406,
      "rewards/rejected": -3.129490375518799,
      "step": 1174
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.6112672090530396,
      "learning_rate": 8.434666666666666e-07,
      "logits/chosen": -2.507005214691162,
      "logits/rejected": -2.6650550365448,
      "logps/chosen": -109.54106140136719,
      "logps/rejected": -127.32085418701172,
      "loss": 0.0246,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.82653546333313,
      "rewards/margins": 5.233706474304199,
      "rewards/rejected": -2.4071712493896484,
      "step": 1175
    },
    {
      "epoch": 0.4704,
      "grad_norm": 0.07777849584817886,
      "learning_rate": 8.433333333333333e-07,
      "logits/chosen": -2.031147003173828,
      "logits/rejected": -3.3446130752563477,
      "logps/chosen": -128.24746704101562,
      "logps/rejected": -160.94586181640625,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9450697898864746,
      "rewards/margins": 7.276190757751465,
      "rewards/rejected": -3.3311209678649902,
      "step": 1176
    },
    {
      "epoch": 0.4708,
      "grad_norm": 0.8294489979743958,
      "learning_rate": 8.431999999999999e-07,
      "logits/chosen": -1.9029947519302368,
      "logits/rejected": -2.602130889892578,
      "logps/chosen": -63.07111358642578,
      "logps/rejected": -111.23313903808594,
      "loss": 0.0128,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.284255266189575,
      "rewards/margins": 4.776678085327148,
      "rewards/rejected": -2.4924230575561523,
      "step": 1177
    },
    {
      "epoch": 0.4712,
      "grad_norm": 4.548637390136719,
      "learning_rate": 8.430666666666666e-07,
      "logits/chosen": -1.8261966705322266,
      "logits/rejected": -3.058465003967285,
      "logps/chosen": -76.66316223144531,
      "logps/rejected": -125.64129638671875,
      "loss": 0.0337,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2083258628845215,
      "rewards/margins": 4.800291061401367,
      "rewards/rejected": -2.5919647216796875,
      "step": 1178
    },
    {
      "epoch": 0.4716,
      "grad_norm": 0.7756760120391846,
      "learning_rate": 8.429333333333333e-07,
      "logits/chosen": -2.056386709213257,
      "logits/rejected": -2.5232582092285156,
      "logps/chosen": -106.92015075683594,
      "logps/rejected": -112.40935516357422,
      "loss": 0.0117,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.37890625,
      "rewards/margins": 5.260143280029297,
      "rewards/rejected": -1.8812370300292969,
      "step": 1179
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.1353921741247177,
      "learning_rate": 8.428e-07,
      "logits/chosen": -2.589928150177002,
      "logits/rejected": -3.0295729637145996,
      "logps/chosen": -170.23629760742188,
      "logps/rejected": -143.17742919921875,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.348404884338379,
      "rewards/margins": 7.10567045211792,
      "rewards/rejected": -2.757265567779541,
      "step": 1180
    },
    {
      "epoch": 0.4724,
      "grad_norm": 8.765909194946289,
      "learning_rate": 8.426666666666666e-07,
      "logits/chosen": -2.0343570709228516,
      "logits/rejected": -2.699281692504883,
      "logps/chosen": -83.68953704833984,
      "logps/rejected": -96.15296936035156,
      "loss": 0.0663,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.177600145339966,
      "rewards/margins": 3.476490020751953,
      "rewards/rejected": -1.2988899946212769,
      "step": 1181
    },
    {
      "epoch": 0.4728,
      "grad_norm": 0.16273371875286102,
      "learning_rate": 8.425333333333333e-07,
      "logits/chosen": -2.2713756561279297,
      "logits/rejected": -2.485198497772217,
      "logps/chosen": -123.56329345703125,
      "logps/rejected": -131.17596435546875,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4953103065490723,
      "rewards/margins": 6.323049545288086,
      "rewards/rejected": -2.8277392387390137,
      "step": 1182
    },
    {
      "epoch": 0.4732,
      "grad_norm": 0.1337657868862152,
      "learning_rate": 8.424e-07,
      "logits/chosen": -2.581221342086792,
      "logits/rejected": -2.5697474479675293,
      "logps/chosen": -96.93516540527344,
      "logps/rejected": -130.13064575195312,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.3872880935668945,
      "rewards/margins": 7.535483360290527,
      "rewards/rejected": -3.148195266723633,
      "step": 1183
    },
    {
      "epoch": 0.4736,
      "grad_norm": 3.7209672927856445,
      "learning_rate": 8.422666666666667e-07,
      "logits/chosen": -2.353388547897339,
      "logits/rejected": -3.090226411819458,
      "logps/chosen": -150.38380432128906,
      "logps/rejected": -126.75653076171875,
      "loss": 0.0409,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.118757724761963,
      "rewards/margins": 4.454058647155762,
      "rewards/rejected": -2.335300922393799,
      "step": 1184
    },
    {
      "epoch": 0.474,
      "grad_norm": 20.755470275878906,
      "learning_rate": 8.421333333333333e-07,
      "logits/chosen": -2.6195812225341797,
      "logits/rejected": -1.9334226846694946,
      "logps/chosen": -132.50665283203125,
      "logps/rejected": -113.37269592285156,
      "loss": 0.2195,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8268646001815796,
      "rewards/margins": 2.336430072784424,
      "rewards/rejected": -0.5095653533935547,
      "step": 1185
    },
    {
      "epoch": 0.4744,
      "grad_norm": 0.6060892343521118,
      "learning_rate": 8.419999999999999e-07,
      "logits/chosen": -2.247678756713867,
      "logits/rejected": -2.9362335205078125,
      "logps/chosen": -73.64869689941406,
      "logps/rejected": -126.2586669921875,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.351801633834839,
      "rewards/margins": 6.507011413574219,
      "rewards/rejected": -3.15520977973938,
      "step": 1186
    },
    {
      "epoch": 0.4748,
      "grad_norm": 3.060743808746338,
      "learning_rate": 8.418666666666666e-07,
      "logits/chosen": -2.5511879920959473,
      "logits/rejected": -2.9310646057128906,
      "logps/chosen": -225.5057373046875,
      "logps/rejected": -139.0279083251953,
      "loss": 0.0377,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.26756972074508667,
      "rewards/margins": 3.296445369720459,
      "rewards/rejected": -3.0288758277893066,
      "step": 1187
    },
    {
      "epoch": 0.4752,
      "grad_norm": 2.0630440711975098,
      "learning_rate": 8.417333333333333e-07,
      "logits/chosen": -2.289618492126465,
      "logits/rejected": -3.1335792541503906,
      "logps/chosen": -153.68580627441406,
      "logps/rejected": -125.50846862792969,
      "loss": 0.0319,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2194008827209473,
      "rewards/margins": 5.646770477294922,
      "rewards/rejected": -3.4273695945739746,
      "step": 1188
    },
    {
      "epoch": 0.4756,
      "grad_norm": 0.6285253763198853,
      "learning_rate": 8.416e-07,
      "logits/chosen": -2.3522725105285645,
      "logits/rejected": -2.1211018562316895,
      "logps/chosen": -82.81944274902344,
      "logps/rejected": -142.33746337890625,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.7162933349609375,
      "rewards/margins": 6.909230709075928,
      "rewards/rejected": -2.1929373741149902,
      "step": 1189
    },
    {
      "epoch": 0.476,
      "grad_norm": 1.1851170063018799,
      "learning_rate": 8.414666666666667e-07,
      "logits/chosen": -2.9530277252197266,
      "logits/rejected": -2.7992100715637207,
      "logps/chosen": -260.91412353515625,
      "logps/rejected": -179.66079711914062,
      "loss": 0.0119,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.14575651288032532,
      "rewards/margins": 4.463274002075195,
      "rewards/rejected": -4.609030246734619,
      "step": 1190
    },
    {
      "epoch": 0.4764,
      "grad_norm": 0.02943662367761135,
      "learning_rate": 8.413333333333333e-07,
      "logits/chosen": -2.3432514667510986,
      "logits/rejected": -2.962221622467041,
      "logps/chosen": -137.83253479003906,
      "logps/rejected": -133.54718017578125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.739014625549316,
      "rewards/margins": 8.09170150756836,
      "rewards/rejected": -3.352687358856201,
      "step": 1191
    },
    {
      "epoch": 0.4768,
      "grad_norm": 8.08389949798584,
      "learning_rate": 8.411999999999999e-07,
      "logits/chosen": -2.390934944152832,
      "logits/rejected": -2.7414751052856445,
      "logps/chosen": -148.64068603515625,
      "logps/rejected": -114.86204528808594,
      "loss": 0.0867,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9334877729415894,
      "rewards/margins": 3.2015371322631836,
      "rewards/rejected": -2.2680492401123047,
      "step": 1192
    },
    {
      "epoch": 0.4772,
      "grad_norm": 1.0813839435577393,
      "learning_rate": 8.410666666666666e-07,
      "logits/chosen": -2.752838611602783,
      "logits/rejected": -2.95733642578125,
      "logps/chosen": -156.5286407470703,
      "logps/rejected": -225.33218383789062,
      "loss": 0.0085,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5372871160507202,
      "rewards/margins": 4.961703300476074,
      "rewards/rejected": -3.4244165420532227,
      "step": 1193
    },
    {
      "epoch": 0.4776,
      "grad_norm": 0.11948966979980469,
      "learning_rate": 8.409333333333333e-07,
      "logits/chosen": -2.113074779510498,
      "logits/rejected": -3.169255495071411,
      "logps/chosen": -143.012939453125,
      "logps/rejected": -172.46055603027344,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.094970703125,
      "rewards/margins": 6.668266773223877,
      "rewards/rejected": -3.5732955932617188,
      "step": 1194
    },
    {
      "epoch": 0.478,
      "grad_norm": 0.2661239206790924,
      "learning_rate": 8.408e-07,
      "logits/chosen": -2.194751262664795,
      "logits/rejected": -3.014176845550537,
      "logps/chosen": -122.49471282958984,
      "logps/rejected": -164.62307739257812,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8053452968597412,
      "rewards/margins": 6.083994388580322,
      "rewards/rejected": -4.27864933013916,
      "step": 1195
    },
    {
      "epoch": 0.4784,
      "grad_norm": 0.12422382086515427,
      "learning_rate": 8.406666666666667e-07,
      "logits/chosen": -2.3080902099609375,
      "logits/rejected": -2.908843994140625,
      "logps/chosen": -205.1843719482422,
      "logps/rejected": -130.86892700195312,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3979387283325195,
      "rewards/margins": 6.508759498596191,
      "rewards/rejected": -3.11082124710083,
      "step": 1196
    },
    {
      "epoch": 0.4788,
      "grad_norm": 1.533792495727539,
      "learning_rate": 8.405333333333333e-07,
      "logits/chosen": -2.3504061698913574,
      "logits/rejected": -3.1955952644348145,
      "logps/chosen": -103.57630157470703,
      "logps/rejected": -136.47259521484375,
      "loss": 0.0201,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0682331323623657,
      "rewards/margins": 3.904694080352783,
      "rewards/rejected": -2.836460828781128,
      "step": 1197
    },
    {
      "epoch": 0.4792,
      "grad_norm": 0.12577566504478455,
      "learning_rate": 8.404e-07,
      "logits/chosen": -2.491100788116455,
      "logits/rejected": -3.1400928497314453,
      "logps/chosen": -162.61373901367188,
      "logps/rejected": -170.32260131835938,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.398423194885254,
      "rewards/margins": 6.971128940582275,
      "rewards/rejected": -3.5727059841156006,
      "step": 1198
    },
    {
      "epoch": 0.4796,
      "grad_norm": 8.248403549194336,
      "learning_rate": 8.402666666666667e-07,
      "logits/chosen": -2.4627857208251953,
      "logits/rejected": -2.2545108795166016,
      "logps/chosen": -131.65213012695312,
      "logps/rejected": -108.08197021484375,
      "loss": 0.0808,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.774747133255005,
      "rewards/margins": 4.584525108337402,
      "rewards/rejected": -0.8097778558731079,
      "step": 1199
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.8313347101211548,
      "learning_rate": 8.401333333333332e-07,
      "logits/chosen": -2.4413795471191406,
      "logits/rejected": -2.4985783100128174,
      "logps/chosen": -165.51431274414062,
      "logps/rejected": -154.7100372314453,
      "loss": 0.0091,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9753406047821045,
      "rewards/margins": 4.707734107971191,
      "rewards/rejected": -2.732393741607666,
      "step": 1200
    },
    {
      "epoch": 0.4804,
      "grad_norm": 0.864094078540802,
      "learning_rate": 8.399999999999999e-07,
      "logits/chosen": -2.5000863075256348,
      "logits/rejected": -2.9188966751098633,
      "logps/chosen": -126.50509643554688,
      "logps/rejected": -125.25178527832031,
      "loss": 0.0094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7907527685165405,
      "rewards/margins": 5.045605659484863,
      "rewards/rejected": -3.254852771759033,
      "step": 1201
    },
    {
      "epoch": 0.4808,
      "grad_norm": 1.7173006534576416,
      "learning_rate": 8.398666666666666e-07,
      "logits/chosen": -2.3865814208984375,
      "logits/rejected": -2.5846927165985107,
      "logps/chosen": -89.78297424316406,
      "logps/rejected": -123.58578491210938,
      "loss": 0.024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2752647399902344,
      "rewards/margins": 5.759117126464844,
      "rewards/rejected": -3.4838523864746094,
      "step": 1202
    },
    {
      "epoch": 0.4812,
      "grad_norm": 0.37727636098861694,
      "learning_rate": 8.397333333333333e-07,
      "logits/chosen": -2.1835544109344482,
      "logits/rejected": -2.5704402923583984,
      "logps/chosen": -118.19779968261719,
      "logps/rejected": -131.93948364257812,
      "loss": 0.0045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2767062187194824,
      "rewards/margins": 6.207159042358398,
      "rewards/rejected": -2.930452823638916,
      "step": 1203
    },
    {
      "epoch": 0.4816,
      "grad_norm": 3.2855396270751953,
      "learning_rate": 8.396e-07,
      "logits/chosen": -2.019198417663574,
      "logits/rejected": -2.7761473655700684,
      "logps/chosen": -107.55986022949219,
      "logps/rejected": -128.3523712158203,
      "loss": 0.0441,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.465740203857422,
      "rewards/margins": 5.707036018371582,
      "rewards/rejected": -3.24129581451416,
      "step": 1204
    },
    {
      "epoch": 0.482,
      "grad_norm": 0.17028848826885223,
      "learning_rate": 8.394666666666667e-07,
      "logits/chosen": -2.1560544967651367,
      "logits/rejected": -3.0692925453186035,
      "logps/chosen": -106.83025360107422,
      "logps/rejected": -161.83802795410156,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.177896976470947,
      "rewards/margins": 6.893095016479492,
      "rewards/rejected": -2.715197801589966,
      "step": 1205
    },
    {
      "epoch": 0.4824,
      "grad_norm": 0.01536295935511589,
      "learning_rate": 8.393333333333334e-07,
      "logits/chosen": -2.0692176818847656,
      "logits/rejected": -3.1160078048706055,
      "logps/chosen": -91.46197509765625,
      "logps/rejected": -155.17489624023438,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.340932846069336,
      "rewards/margins": 8.730186462402344,
      "rewards/rejected": -4.389254093170166,
      "step": 1206
    },
    {
      "epoch": 0.4828,
      "grad_norm": 0.01554353442043066,
      "learning_rate": 8.391999999999999e-07,
      "logits/chosen": -2.4079649448394775,
      "logits/rejected": -3.241044521331787,
      "logps/chosen": -109.34037780761719,
      "logps/rejected": -161.71847534179688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 5.16245174407959,
      "rewards/margins": 8.563880920410156,
      "rewards/rejected": -3.4014294147491455,
      "step": 1207
    },
    {
      "epoch": 0.4832,
      "grad_norm": 0.37114179134368896,
      "learning_rate": 8.390666666666666e-07,
      "logits/chosen": -2.288907527923584,
      "logits/rejected": -2.895434856414795,
      "logps/chosen": -89.60716247558594,
      "logps/rejected": -127.02677917480469,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3076281547546387,
      "rewards/margins": 5.940998077392578,
      "rewards/rejected": -3.6333699226379395,
      "step": 1208
    },
    {
      "epoch": 0.4836,
      "grad_norm": 0.4281388521194458,
      "learning_rate": 8.389333333333332e-07,
      "logits/chosen": -1.9060723781585693,
      "logits/rejected": -2.8146982192993164,
      "logps/chosen": -104.92884063720703,
      "logps/rejected": -123.36564636230469,
      "loss": 0.0048,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7164818048477173,
      "rewards/margins": 5.910911560058594,
      "rewards/rejected": -4.194429874420166,
      "step": 1209
    },
    {
      "epoch": 0.484,
      "grad_norm": 12.733681678771973,
      "learning_rate": 8.387999999999999e-07,
      "logits/chosen": -1.8506319522857666,
      "logits/rejected": -2.665832757949829,
      "logps/chosen": -137.03753662109375,
      "logps/rejected": -106.67172241210938,
      "loss": 0.1556,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9441696405410767,
      "rewards/margins": 4.249591827392578,
      "rewards/rejected": -2.305421829223633,
      "step": 1210
    },
    {
      "epoch": 0.4844,
      "grad_norm": 0.7403209209442139,
      "learning_rate": 8.386666666666666e-07,
      "logits/chosen": -2.575909376144409,
      "logits/rejected": -2.3683037757873535,
      "logps/chosen": -112.70210266113281,
      "logps/rejected": -114.82342529296875,
      "loss": 0.0086,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.156741142272949,
      "rewards/margins": 6.261785984039307,
      "rewards/rejected": -2.1050448417663574,
      "step": 1211
    },
    {
      "epoch": 0.4848,
      "grad_norm": 0.041260555386543274,
      "learning_rate": 8.385333333333333e-07,
      "logits/chosen": -2.496464729309082,
      "logits/rejected": -3.0362658500671387,
      "logps/chosen": -84.9457015991211,
      "logps/rejected": -134.85470581054688,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.695786714553833,
      "rewards/margins": 7.6619954109191895,
      "rewards/rejected": -4.966208457946777,
      "step": 1212
    },
    {
      "epoch": 0.4852,
      "grad_norm": 0.11188101768493652,
      "learning_rate": 8.384e-07,
      "logits/chosen": -2.4100699424743652,
      "logits/rejected": -3.0200533866882324,
      "logps/chosen": -126.1397933959961,
      "logps/rejected": -191.55174255371094,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.609606981277466,
      "rewards/margins": 7.45789909362793,
      "rewards/rejected": -3.8482918739318848,
      "step": 1213
    },
    {
      "epoch": 0.4856,
      "grad_norm": 0.11270464956760406,
      "learning_rate": 8.382666666666667e-07,
      "logits/chosen": -2.33473801612854,
      "logits/rejected": -3.005765438079834,
      "logps/chosen": -128.74142456054688,
      "logps/rejected": -132.2066650390625,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6997077465057373,
      "rewards/margins": 7.2503204345703125,
      "rewards/rejected": -3.550612688064575,
      "step": 1214
    },
    {
      "epoch": 0.486,
      "grad_norm": 0.2172701507806778,
      "learning_rate": 8.381333333333333e-07,
      "logits/chosen": -2.1197073459625244,
      "logits/rejected": -2.969508647918701,
      "logps/chosen": -103.59430694580078,
      "logps/rejected": -125.80147552490234,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.760018825531006,
      "rewards/margins": 6.393975734710693,
      "rewards/rejected": -2.6339566707611084,
      "step": 1215
    },
    {
      "epoch": 0.4864,
      "grad_norm": 0.06675176322460175,
      "learning_rate": 8.38e-07,
      "logits/chosen": -2.141291618347168,
      "logits/rejected": -3.059492826461792,
      "logps/chosen": -112.03799438476562,
      "logps/rejected": -124.1690673828125,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.455023765563965,
      "rewards/margins": 7.470606803894043,
      "rewards/rejected": -3.01558256149292,
      "step": 1216
    },
    {
      "epoch": 0.4868,
      "grad_norm": 0.18411439657211304,
      "learning_rate": 8.378666666666667e-07,
      "logits/chosen": -2.081843376159668,
      "logits/rejected": -2.9936275482177734,
      "logps/chosen": -85.55133056640625,
      "logps/rejected": -106.80574035644531,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.385904312133789,
      "rewards/margins": 6.034163475036621,
      "rewards/rejected": -2.648259401321411,
      "step": 1217
    },
    {
      "epoch": 0.4872,
      "grad_norm": 5.847512722015381,
      "learning_rate": 8.377333333333333e-07,
      "logits/chosen": -2.7802653312683105,
      "logits/rejected": -3.0509448051452637,
      "logps/chosen": -172.20028686523438,
      "logps/rejected": -121.35086822509766,
      "loss": 0.0622,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8064624667167664,
      "rewards/margins": 3.5930538177490234,
      "rewards/rejected": -2.7865915298461914,
      "step": 1218
    },
    {
      "epoch": 0.4876,
      "grad_norm": 0.15940703451633453,
      "learning_rate": 8.375999999999999e-07,
      "logits/chosen": -2.3434882164001465,
      "logits/rejected": -2.3738932609558105,
      "logps/chosen": -133.91448974609375,
      "logps/rejected": -139.06927490234375,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6721959114074707,
      "rewards/margins": 6.73552942276001,
      "rewards/rejected": -3.063333511352539,
      "step": 1219
    },
    {
      "epoch": 0.488,
      "grad_norm": 1.812208652496338,
      "learning_rate": 8.374666666666666e-07,
      "logits/chosen": -2.310214042663574,
      "logits/rejected": -2.573463201522827,
      "logps/chosen": -135.5627899169922,
      "logps/rejected": -123.12985229492188,
      "loss": 0.0214,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.156365156173706,
      "rewards/margins": 3.8897476196289062,
      "rewards/rejected": -2.7333824634552,
      "step": 1220
    },
    {
      "epoch": 0.4884,
      "grad_norm": 2.8405213356018066,
      "learning_rate": 8.373333333333333e-07,
      "logits/chosen": -2.197807788848877,
      "logits/rejected": -2.806720495223999,
      "logps/chosen": -83.82852172851562,
      "logps/rejected": -110.94308471679688,
      "loss": 0.0212,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.972353458404541,
      "rewards/margins": 4.681127548217773,
      "rewards/rejected": -2.7087738513946533,
      "step": 1221
    },
    {
      "epoch": 0.4888,
      "grad_norm": 0.9760357737541199,
      "learning_rate": 8.372e-07,
      "logits/chosen": -2.2226450443267822,
      "logits/rejected": -2.982177972793579,
      "logps/chosen": -81.6799545288086,
      "logps/rejected": -126.22441101074219,
      "loss": 0.0138,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.578070878982544,
      "rewards/margins": 5.520532131195068,
      "rewards/rejected": -2.9424610137939453,
      "step": 1222
    },
    {
      "epoch": 0.4892,
      "grad_norm": 0.5039832592010498,
      "learning_rate": 8.370666666666666e-07,
      "logits/chosen": -2.0866293907165527,
      "logits/rejected": -2.3575406074523926,
      "logps/chosen": -168.13442993164062,
      "logps/rejected": -153.00328063964844,
      "loss": 0.0049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.357501268386841,
      "rewards/margins": 5.889082908630371,
      "rewards/rejected": -2.5315818786621094,
      "step": 1223
    },
    {
      "epoch": 0.4896,
      "grad_norm": 0.30100393295288086,
      "learning_rate": 8.369333333333333e-07,
      "logits/chosen": -2.47096848487854,
      "logits/rejected": -3.195054054260254,
      "logps/chosen": -172.49240112304688,
      "logps/rejected": -135.38729858398438,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0083017349243164,
      "rewards/margins": 6.6203532218933105,
      "rewards/rejected": -3.6120517253875732,
      "step": 1224
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6229120492935181,
      "learning_rate": 8.368e-07,
      "logits/chosen": -2.5309531688690186,
      "logits/rejected": -2.974377155303955,
      "logps/chosen": -135.63656616210938,
      "logps/rejected": -121.54103088378906,
      "loss": 0.0078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6682838201522827,
      "rewards/margins": 4.853989601135254,
      "rewards/rejected": -3.1857059001922607,
      "step": 1225
    },
    {
      "epoch": 0.4904,
      "grad_norm": 1.0822880268096924,
      "learning_rate": 8.366666666666667e-07,
      "logits/chosen": -3.002941370010376,
      "logits/rejected": -3.4683375358581543,
      "logps/chosen": -189.30548095703125,
      "logps/rejected": -196.04107666015625,
      "loss": 0.0132,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5544769763946533,
      "rewards/margins": 4.943378448486328,
      "rewards/rejected": -3.388901710510254,
      "step": 1226
    },
    {
      "epoch": 0.4908,
      "grad_norm": 2.1507794857025146,
      "learning_rate": 8.365333333333334e-07,
      "logits/chosen": -2.0369839668273926,
      "logits/rejected": -2.8573412895202637,
      "logps/chosen": -117.31446075439453,
      "logps/rejected": -126.61087036132812,
      "loss": 0.0248,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5134365558624268,
      "rewards/margins": 5.160345077514648,
      "rewards/rejected": -2.646908760070801,
      "step": 1227
    },
    {
      "epoch": 0.4912,
      "grad_norm": 0.9560794830322266,
      "learning_rate": 8.363999999999999e-07,
      "logits/chosen": -2.407045364379883,
      "logits/rejected": -3.141322374343872,
      "logps/chosen": -88.63706970214844,
      "logps/rejected": -129.54971313476562,
      "loss": 0.01,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1555659770965576,
      "rewards/margins": 5.7757463455200195,
      "rewards/rejected": -2.620180606842041,
      "step": 1228
    },
    {
      "epoch": 0.4916,
      "grad_norm": 0.17881087958812714,
      "learning_rate": 8.362666666666666e-07,
      "logits/chosen": -2.279672145843506,
      "logits/rejected": -2.172370433807373,
      "logps/chosen": -86.38658142089844,
      "logps/rejected": -103.56564331054688,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.855422258377075,
      "rewards/margins": 6.250973701477051,
      "rewards/rejected": -2.3955514430999756,
      "step": 1229
    },
    {
      "epoch": 0.492,
      "grad_norm": 0.8287453055381775,
      "learning_rate": 8.361333333333332e-07,
      "logits/chosen": -2.494147777557373,
      "logits/rejected": -2.9395103454589844,
      "logps/chosen": -176.67381286621094,
      "logps/rejected": -115.49447631835938,
      "loss": 0.0097,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7864999771118164,
      "rewards/margins": 5.432002067565918,
      "rewards/rejected": -2.6455025672912598,
      "step": 1230
    },
    {
      "epoch": 0.4924,
      "grad_norm": 0.25882983207702637,
      "learning_rate": 8.359999999999999e-07,
      "logits/chosen": -2.2803049087524414,
      "logits/rejected": -3.2233195304870605,
      "logps/chosen": -186.33737182617188,
      "logps/rejected": -153.22021484375,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.300153374671936,
      "rewards/margins": 5.992100715637207,
      "rewards/rejected": -4.691946983337402,
      "step": 1231
    },
    {
      "epoch": 0.4928,
      "grad_norm": 0.2825477421283722,
      "learning_rate": 8.358666666666666e-07,
      "logits/chosen": -2.219723701477051,
      "logits/rejected": -3.224374294281006,
      "logps/chosen": -109.88778686523438,
      "logps/rejected": -141.89556884765625,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7900121212005615,
      "rewards/margins": 6.1922125816345215,
      "rewards/rejected": -3.40220046043396,
      "step": 1232
    },
    {
      "epoch": 0.4932,
      "grad_norm": 2.260103702545166,
      "learning_rate": 8.357333333333333e-07,
      "logits/chosen": -2.147211790084839,
      "logits/rejected": -2.513561248779297,
      "logps/chosen": -79.09524536132812,
      "logps/rejected": -113.74441528320312,
      "loss": 0.0273,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6255297660827637,
      "rewards/margins": 4.157587051391602,
      "rewards/rejected": -1.532057523727417,
      "step": 1233
    },
    {
      "epoch": 0.4936,
      "grad_norm": 0.29941806197166443,
      "learning_rate": 8.356e-07,
      "logits/chosen": -1.8867309093475342,
      "logits/rejected": -1.7125645875930786,
      "logps/chosen": -99.33045959472656,
      "logps/rejected": -90.87980651855469,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.380589723587036,
      "rewards/margins": 5.82426643371582,
      "rewards/rejected": -2.443676710128784,
      "step": 1234
    },
    {
      "epoch": 0.494,
      "grad_norm": 0.8298376202583313,
      "learning_rate": 8.354666666666667e-07,
      "logits/chosen": -1.9963157176971436,
      "logits/rejected": -3.2047417163848877,
      "logps/chosen": -86.64887237548828,
      "logps/rejected": -123.40201568603516,
      "loss": 0.0116,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.987196445465088,
      "rewards/margins": 4.45364236831665,
      "rewards/rejected": -2.4664459228515625,
      "step": 1235
    },
    {
      "epoch": 0.4944,
      "grad_norm": 0.48087942600250244,
      "learning_rate": 8.353333333333334e-07,
      "logits/chosen": -2.2127389907836914,
      "logits/rejected": -3.130411148071289,
      "logps/chosen": -130.96133422851562,
      "logps/rejected": -192.20199584960938,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4002976417541504,
      "rewards/margins": 6.243194580078125,
      "rewards/rejected": -2.8428966999053955,
      "step": 1236
    },
    {
      "epoch": 0.4948,
      "grad_norm": 0.6528928875923157,
      "learning_rate": 8.352000000000001e-07,
      "logits/chosen": -2.111362934112549,
      "logits/rejected": -2.98051118850708,
      "logps/chosen": -90.88801574707031,
      "logps/rejected": -169.01870727539062,
      "loss": 0.0078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.794769287109375,
      "rewards/margins": 6.961976051330566,
      "rewards/rejected": -4.167206764221191,
      "step": 1237
    },
    {
      "epoch": 0.4952,
      "grad_norm": 0.20932425558567047,
      "learning_rate": 8.350666666666665e-07,
      "logits/chosen": -2.1367688179016113,
      "logits/rejected": -3.3172550201416016,
      "logps/chosen": -97.28581237792969,
      "logps/rejected": -124.12884521484375,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.691096067428589,
      "rewards/margins": 6.35205078125,
      "rewards/rejected": -2.660954713821411,
      "step": 1238
    },
    {
      "epoch": 0.4956,
      "grad_norm": 1.0399318933486938,
      "learning_rate": 8.349333333333332e-07,
      "logits/chosen": -2.4228272438049316,
      "logits/rejected": -2.911680221557617,
      "logps/chosen": -147.008056640625,
      "logps/rejected": -120.74823760986328,
      "loss": 0.0134,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.117147922515869,
      "rewards/margins": 4.616870880126953,
      "rewards/rejected": -2.499722957611084,
      "step": 1239
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.20680472254753113,
      "learning_rate": 8.347999999999999e-07,
      "logits/chosen": -2.354222536087036,
      "logits/rejected": -3.309695243835449,
      "logps/chosen": -124.8944091796875,
      "logps/rejected": -157.36587524414062,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.004957675933838,
      "rewards/margins": 6.49143123626709,
      "rewards/rejected": -4.486473560333252,
      "step": 1240
    },
    {
      "epoch": 0.4964,
      "grad_norm": 0.2839202582836151,
      "learning_rate": 8.346666666666666e-07,
      "logits/chosen": -1.9607558250427246,
      "logits/rejected": -3.0544443130493164,
      "logps/chosen": -85.12083435058594,
      "logps/rejected": -113.65931701660156,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9200968742370605,
      "rewards/margins": 5.666479110717773,
      "rewards/rejected": -1.7463825941085815,
      "step": 1241
    },
    {
      "epoch": 0.4968,
      "grad_norm": 0.07382311671972275,
      "learning_rate": 8.345333333333333e-07,
      "logits/chosen": -2.3732008934020996,
      "logits/rejected": -2.4571421146392822,
      "logps/chosen": -70.01224517822266,
      "logps/rejected": -129.367919921875,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.931007146835327,
      "rewards/margins": 7.061123847961426,
      "rewards/rejected": -3.1301167011260986,
      "step": 1242
    },
    {
      "epoch": 0.4972,
      "grad_norm": 0.15814249217510223,
      "learning_rate": 8.344e-07,
      "logits/chosen": -1.9499075412750244,
      "logits/rejected": -3.3741724491119385,
      "logps/chosen": -124.67587280273438,
      "logps/rejected": -169.7624053955078,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4895496368408203,
      "rewards/margins": 7.373357772827148,
      "rewards/rejected": -3.88380765914917,
      "step": 1243
    },
    {
      "epoch": 0.4976,
      "grad_norm": 1.0925129652023315,
      "learning_rate": 8.342666666666667e-07,
      "logits/chosen": -2.640403985977173,
      "logits/rejected": -2.80159854888916,
      "logps/chosen": -140.50277709960938,
      "logps/rejected": -122.19766235351562,
      "loss": 0.0122,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4126884937286377,
      "rewards/margins": 4.5343217849731445,
      "rewards/rejected": -3.121633529663086,
      "step": 1244
    },
    {
      "epoch": 0.498,
      "grad_norm": 0.49004554748535156,
      "learning_rate": 8.341333333333333e-07,
      "logits/chosen": -2.1206889152526855,
      "logits/rejected": -3.004836320877075,
      "logps/chosen": -102.28132629394531,
      "logps/rejected": -157.10211181640625,
      "loss": 0.0062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.826495885848999,
      "rewards/margins": 6.836208343505859,
      "rewards/rejected": -3.0097124576568604,
      "step": 1245
    },
    {
      "epoch": 0.4984,
      "grad_norm": 0.055634912103414536,
      "learning_rate": 8.34e-07,
      "logits/chosen": -2.497620105743408,
      "logits/rejected": -3.361804485321045,
      "logps/chosen": -118.97634887695312,
      "logps/rejected": -144.75723266601562,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6014983654022217,
      "rewards/margins": 7.6058807373046875,
      "rewards/rejected": -4.004382610321045,
      "step": 1246
    },
    {
      "epoch": 0.4988,
      "grad_norm": 0.24168387055397034,
      "learning_rate": 8.338666666666666e-07,
      "logits/chosen": -2.4528005123138428,
      "logits/rejected": -2.239286422729492,
      "logps/chosen": -73.66847229003906,
      "logps/rejected": -98.86322021484375,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6750102043151855,
      "rewards/margins": 5.98013973236084,
      "rewards/rejected": -2.3051295280456543,
      "step": 1247
    },
    {
      "epoch": 0.4992,
      "grad_norm": 0.42758283019065857,
      "learning_rate": 8.337333333333333e-07,
      "logits/chosen": -2.4702296257019043,
      "logits/rejected": -2.775946855545044,
      "logps/chosen": -100.66687774658203,
      "logps/rejected": -128.64012145996094,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7257497310638428,
      "rewards/margins": 5.871822357177734,
      "rewards/rejected": -4.146072864532471,
      "step": 1248
    },
    {
      "epoch": 0.4996,
      "grad_norm": 0.8961630463600159,
      "learning_rate": 8.335999999999999e-07,
      "logits/chosen": -2.4635424613952637,
      "logits/rejected": -2.149160861968994,
      "logps/chosen": -80.24744415283203,
      "logps/rejected": -144.1299285888672,
      "loss": 0.0081,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2519619464874268,
      "rewards/margins": 4.816882610321045,
      "rewards/rejected": -2.5649209022521973,
      "step": 1249
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.1517016887664795,
      "learning_rate": 8.334666666666666e-07,
      "logits/chosen": -2.676281452178955,
      "logits/rejected": -3.1975560188293457,
      "logps/chosen": -130.20706176757812,
      "logps/rejected": -146.43988037109375,
      "loss": 0.0105,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5905739068984985,
      "rewards/margins": 4.705410957336426,
      "rewards/rejected": -3.1148369312286377,
      "step": 1250
    },
    {
      "epoch": 0.5004,
      "grad_norm": 0.050112444907426834,
      "learning_rate": 8.333333333333333e-07,
      "logits/chosen": -2.447385549545288,
      "logits/rejected": -2.7724251747131348,
      "logps/chosen": -76.14097595214844,
      "logps/rejected": -119.43571472167969,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.154806137084961,
      "rewards/margins": 7.538768291473389,
      "rewards/rejected": -3.3839619159698486,
      "step": 1251
    },
    {
      "epoch": 0.5008,
      "grad_norm": 1.5123906135559082,
      "learning_rate": 8.332e-07,
      "logits/chosen": -2.456660747528076,
      "logits/rejected": -3.052358627319336,
      "logps/chosen": -174.5110321044922,
      "logps/rejected": -135.81808471679688,
      "loss": 0.0131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.484978199005127,
      "rewards/margins": 5.515201568603516,
      "rewards/rejected": -3.0302236080169678,
      "step": 1252
    },
    {
      "epoch": 0.5012,
      "grad_norm": 0.9763529300689697,
      "learning_rate": 8.330666666666666e-07,
      "logits/chosen": -2.570453405380249,
      "logits/rejected": -3.4320168495178223,
      "logps/chosen": -116.34793853759766,
      "logps/rejected": -143.60128784179688,
      "loss": 0.0089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4694843292236328,
      "rewards/margins": 5.431690692901611,
      "rewards/rejected": -3.9622063636779785,
      "step": 1253
    },
    {
      "epoch": 0.5016,
      "grad_norm": 2.013646125793457,
      "learning_rate": 8.329333333333333e-07,
      "logits/chosen": -1.7194437980651855,
      "logits/rejected": -3.129237174987793,
      "logps/chosen": -85.72981262207031,
      "logps/rejected": -119.15008544921875,
      "loss": 0.0112,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1667404174804688,
      "rewards/margins": 4.916688919067383,
      "rewards/rejected": -2.749948501586914,
      "step": 1254
    },
    {
      "epoch": 0.502,
      "grad_norm": 3.621666193008423,
      "learning_rate": 8.328e-07,
      "logits/chosen": -1.974958896636963,
      "logits/rejected": -2.3376305103302,
      "logps/chosen": -98.02134704589844,
      "logps/rejected": -97.42698669433594,
      "loss": 0.0696,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0859057903289795,
      "rewards/margins": 3.6125404834747314,
      "rewards/rejected": -2.526634693145752,
      "step": 1255
    },
    {
      "epoch": 0.5024,
      "grad_norm": 0.11424964666366577,
      "learning_rate": 8.326666666666666e-07,
      "logits/chosen": -2.027514696121216,
      "logits/rejected": -2.95833420753479,
      "logps/chosen": -156.11065673828125,
      "logps/rejected": -175.28900146484375,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.909834861755371,
      "rewards/margins": 6.995649337768555,
      "rewards/rejected": -3.0858147144317627,
      "step": 1256
    },
    {
      "epoch": 0.5028,
      "grad_norm": 0.37878158688545227,
      "learning_rate": 8.325333333333333e-07,
      "logits/chosen": -2.0313737392425537,
      "logits/rejected": -3.669679880142212,
      "logps/chosen": -89.28863525390625,
      "logps/rejected": -151.1627197265625,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5048255920410156,
      "rewards/margins": 7.08597469329834,
      "rewards/rejected": -4.581149101257324,
      "step": 1257
    },
    {
      "epoch": 0.5032,
      "grad_norm": 0.2981053590774536,
      "learning_rate": 8.324e-07,
      "logits/chosen": -2.257173776626587,
      "logits/rejected": -3.317039966583252,
      "logps/chosen": -131.87213134765625,
      "logps/rejected": -158.91098022460938,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.610464572906494,
      "rewards/margins": 6.5067138671875,
      "rewards/rejected": -3.896249532699585,
      "step": 1258
    },
    {
      "epoch": 0.5036,
      "grad_norm": 0.45224568247795105,
      "learning_rate": 8.322666666666667e-07,
      "logits/chosen": -2.3931725025177,
      "logits/rejected": -3.042015790939331,
      "logps/chosen": -104.52590942382812,
      "logps/rejected": -128.7017059326172,
      "loss": 0.0051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2803890705108643,
      "rewards/margins": 5.362212181091309,
      "rewards/rejected": -4.081823348999023,
      "step": 1259
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.7406005263328552,
      "learning_rate": 8.321333333333332e-07,
      "logits/chosen": -2.6364598274230957,
      "logits/rejected": -3.1029932498931885,
      "logps/chosen": -169.8434600830078,
      "logps/rejected": -140.3264617919922,
      "loss": 0.0094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.088045597076416,
      "rewards/margins": 4.669247627258301,
      "rewards/rejected": -2.581202268600464,
      "step": 1260
    },
    {
      "epoch": 0.5044,
      "grad_norm": 1.0830801725387573,
      "learning_rate": 8.319999999999999e-07,
      "logits/chosen": -2.5240726470947266,
      "logits/rejected": -2.971282720565796,
      "logps/chosen": -144.43441772460938,
      "logps/rejected": -170.8912811279297,
      "loss": 0.0106,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0818276405334473,
      "rewards/margins": 5.270963668823242,
      "rewards/rejected": -3.189135789871216,
      "step": 1261
    },
    {
      "epoch": 0.5048,
      "grad_norm": 0.5701231360435486,
      "learning_rate": 8.318666666666666e-07,
      "logits/chosen": -2.202529191970825,
      "logits/rejected": -2.353672981262207,
      "logps/chosen": -113.52902221679688,
      "logps/rejected": -101.05123901367188,
      "loss": 0.0102,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0861618518829346,
      "rewards/margins": 4.751427173614502,
      "rewards/rejected": -2.6652653217315674,
      "step": 1262
    },
    {
      "epoch": 0.5052,
      "grad_norm": 0.7973072528839111,
      "learning_rate": 8.317333333333333e-07,
      "logits/chosen": -2.3946890830993652,
      "logits/rejected": -3.19399356842041,
      "logps/chosen": -126.68939208984375,
      "logps/rejected": -156.64651489257812,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9681196212768555,
      "rewards/margins": 5.4362945556640625,
      "rewards/rejected": -2.468175172805786,
      "step": 1263
    },
    {
      "epoch": 0.5056,
      "grad_norm": 0.6933305263519287,
      "learning_rate": 8.316e-07,
      "logits/chosen": -2.2964019775390625,
      "logits/rejected": -2.8997292518615723,
      "logps/chosen": -63.65898132324219,
      "logps/rejected": -116.5440902709961,
      "loss": 0.0119,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.062952756881714,
      "rewards/margins": 4.425601959228516,
      "rewards/rejected": -2.362649440765381,
      "step": 1264
    },
    {
      "epoch": 0.506,
      "grad_norm": 0.14170874655246735,
      "learning_rate": 8.314666666666667e-07,
      "logits/chosen": -2.4059133529663086,
      "logits/rejected": -3.3612289428710938,
      "logps/chosen": -134.9783477783203,
      "logps/rejected": -138.4615936279297,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5875110626220703,
      "rewards/margins": 6.4832305908203125,
      "rewards/rejected": -3.895719528198242,
      "step": 1265
    },
    {
      "epoch": 0.5064,
      "grad_norm": 0.8568979501724243,
      "learning_rate": 8.313333333333333e-07,
      "logits/chosen": -2.3201985359191895,
      "logits/rejected": -2.9009222984313965,
      "logps/chosen": -147.24295043945312,
      "logps/rejected": -130.29324340820312,
      "loss": 0.0106,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9694794416427612,
      "rewards/margins": 4.640720367431641,
      "rewards/rejected": -3.671241044998169,
      "step": 1266
    },
    {
      "epoch": 0.5068,
      "grad_norm": 0.07618732005357742,
      "learning_rate": 8.312e-07,
      "logits/chosen": -2.443554401397705,
      "logits/rejected": -3.0268702507019043,
      "logps/chosen": -104.55006408691406,
      "logps/rejected": -165.7503204345703,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.116328239440918,
      "rewards/margins": 7.232289791107178,
      "rewards/rejected": -3.1159615516662598,
      "step": 1267
    },
    {
      "epoch": 0.5072,
      "grad_norm": 1.1745954751968384,
      "learning_rate": 8.310666666666666e-07,
      "logits/chosen": -2.4875833988189697,
      "logits/rejected": -2.7131333351135254,
      "logps/chosen": -113.2845230102539,
      "logps/rejected": -94.62452697753906,
      "loss": 0.0152,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5360610485076904,
      "rewards/margins": 4.285592079162598,
      "rewards/rejected": -1.7495307922363281,
      "step": 1268
    },
    {
      "epoch": 0.5076,
      "grad_norm": 0.5092080235481262,
      "learning_rate": 8.309333333333333e-07,
      "logits/chosen": -2.3304638862609863,
      "logits/rejected": -2.6454272270202637,
      "logps/chosen": -115.101806640625,
      "logps/rejected": -166.76800537109375,
      "loss": 0.0052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3255410194396973,
      "rewards/margins": 5.343541622161865,
      "rewards/rejected": -3.018000602722168,
      "step": 1269
    },
    {
      "epoch": 0.508,
      "grad_norm": 18.661401748657227,
      "learning_rate": 8.308e-07,
      "logits/chosen": -2.215064764022827,
      "logits/rejected": -2.4655542373657227,
      "logps/chosen": -94.959228515625,
      "logps/rejected": -93.80792236328125,
      "loss": 0.2423,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6705868244171143,
      "rewards/margins": 4.075664043426514,
      "rewards/rejected": -1.4050769805908203,
      "step": 1270
    },
    {
      "epoch": 0.5084,
      "grad_norm": 1.5211105346679688,
      "learning_rate": 8.306666666666666e-07,
      "logits/chosen": -2.119194984436035,
      "logits/rejected": -2.2537546157836914,
      "logps/chosen": -104.94819641113281,
      "logps/rejected": -112.74757385253906,
      "loss": 0.0241,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4431099891662598,
      "rewards/margins": 5.227058410644531,
      "rewards/rejected": -1.783948540687561,
      "step": 1271
    },
    {
      "epoch": 0.5088,
      "grad_norm": 5.151634216308594,
      "learning_rate": 8.305333333333333e-07,
      "logits/chosen": -2.5159618854522705,
      "logits/rejected": -3.123335361480713,
      "logps/chosen": -129.87051391601562,
      "logps/rejected": -155.28164672851562,
      "loss": 0.0456,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9986705780029297,
      "rewards/margins": 5.738535404205322,
      "rewards/rejected": -3.7398648262023926,
      "step": 1272
    },
    {
      "epoch": 0.5092,
      "grad_norm": 0.6200929880142212,
      "learning_rate": 8.304e-07,
      "logits/chosen": -2.187171697616577,
      "logits/rejected": -3.307765245437622,
      "logps/chosen": -101.25990295410156,
      "logps/rejected": -142.92132568359375,
      "loss": 0.0057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3367061614990234,
      "rewards/margins": 5.8284783363342285,
      "rewards/rejected": -4.491772174835205,
      "step": 1273
    },
    {
      "epoch": 0.5096,
      "grad_norm": 0.11065883934497833,
      "learning_rate": 8.302666666666667e-07,
      "logits/chosen": -2.155651807785034,
      "logits/rejected": -3.362438678741455,
      "logps/chosen": -136.66061401367188,
      "logps/rejected": -145.61178588867188,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2807507514953613,
      "rewards/margins": 6.6153669357299805,
      "rewards/rejected": -3.334616184234619,
      "step": 1274
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.28462880849838257,
      "learning_rate": 8.301333333333332e-07,
      "logits/chosen": -2.107011318206787,
      "logits/rejected": -2.7680892944335938,
      "logps/chosen": -83.25334930419922,
      "logps/rejected": -114.59144592285156,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.392117977142334,
      "rewards/margins": 5.586739540100098,
      "rewards/rejected": -3.1946215629577637,
      "step": 1275
    },
    {
      "epoch": 0.5104,
      "grad_norm": 0.18897385895252228,
      "learning_rate": 8.299999999999999e-07,
      "logits/chosen": -2.1114678382873535,
      "logits/rejected": -3.162687301635742,
      "logps/chosen": -83.29129028320312,
      "logps/rejected": -147.98529052734375,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.0999531745910645,
      "rewards/margins": 7.054199695587158,
      "rewards/rejected": -2.9542465209960938,
      "step": 1276
    },
    {
      "epoch": 0.5108,
      "grad_norm": 0.1776031106710434,
      "learning_rate": 8.298666666666666e-07,
      "logits/chosen": -2.1987602710723877,
      "logits/rejected": -3.3145623207092285,
      "logps/chosen": -88.66625213623047,
      "logps/rejected": -172.04635620117188,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2730093002319336,
      "rewards/margins": 6.989470481872559,
      "rewards/rejected": -3.716461658477783,
      "step": 1277
    },
    {
      "epoch": 0.5112,
      "grad_norm": 0.09824801236391068,
      "learning_rate": 8.297333333333333e-07,
      "logits/chosen": -2.451274871826172,
      "logits/rejected": -2.6376729011535645,
      "logps/chosen": -183.75148010253906,
      "logps/rejected": -154.8017578125,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7691736221313477,
      "rewards/margins": 7.390280246734619,
      "rewards/rejected": -3.6211066246032715,
      "step": 1278
    },
    {
      "epoch": 0.5116,
      "grad_norm": 2.3704562187194824,
      "learning_rate": 8.296e-07,
      "logits/chosen": -1.9810190200805664,
      "logits/rejected": -3.132857084274292,
      "logps/chosen": -103.10258483886719,
      "logps/rejected": -117.77074432373047,
      "loss": 0.031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2357220649719238,
      "rewards/margins": 5.048701286315918,
      "rewards/rejected": -3.812979221343994,
      "step": 1279
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.19456715881824493,
      "learning_rate": 8.294666666666667e-07,
      "logits/chosen": -2.7976512908935547,
      "logits/rejected": -2.751817226409912,
      "logps/chosen": -89.78753662109375,
      "logps/rejected": -131.95777893066406,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9385533332824707,
      "rewards/margins": 6.201714515686035,
      "rewards/rejected": -3.2631614208221436,
      "step": 1280
    },
    {
      "epoch": 0.5124,
      "grad_norm": 1.0948535203933716,
      "learning_rate": 8.293333333333333e-07,
      "logits/chosen": -2.627387046813965,
      "logits/rejected": -3.10384464263916,
      "logps/chosen": -121.3003158569336,
      "logps/rejected": -126.82774353027344,
      "loss": 0.0108,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8414589166641235,
      "rewards/margins": 4.945775985717773,
      "rewards/rejected": -4.1043171882629395,
      "step": 1281
    },
    {
      "epoch": 0.5128,
      "grad_norm": 0.3177645802497864,
      "learning_rate": 8.292e-07,
      "logits/chosen": -1.994201421737671,
      "logits/rejected": -3.1043319702148438,
      "logps/chosen": -125.22270202636719,
      "logps/rejected": -122.93045043945312,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2631826400756836,
      "rewards/margins": 5.372437000274658,
      "rewards/rejected": -3.1092545986175537,
      "step": 1282
    },
    {
      "epoch": 0.5132,
      "grad_norm": 1.0246137380599976,
      "learning_rate": 8.290666666666666e-07,
      "logits/chosen": -2.34373140335083,
      "logits/rejected": -2.8508639335632324,
      "logps/chosen": -106.0748291015625,
      "logps/rejected": -153.2535400390625,
      "loss": 0.0117,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9406704902648926,
      "rewards/margins": 5.852156162261963,
      "rewards/rejected": -3.9114856719970703,
      "step": 1283
    },
    {
      "epoch": 0.5136,
      "grad_norm": 0.06711193919181824,
      "learning_rate": 8.289333333333332e-07,
      "logits/chosen": -2.0497593879699707,
      "logits/rejected": -2.6351914405822754,
      "logps/chosen": -111.89932250976562,
      "logps/rejected": -127.31898498535156,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.04343843460083,
      "rewards/margins": 7.045785903930664,
      "rewards/rejected": -3.002347230911255,
      "step": 1284
    },
    {
      "epoch": 0.514,
      "grad_norm": 6.134422302246094,
      "learning_rate": 8.287999999999999e-07,
      "logits/chosen": -2.515855312347412,
      "logits/rejected": -3.4972739219665527,
      "logps/chosen": -121.10094451904297,
      "logps/rejected": -130.8553009033203,
      "loss": 0.0884,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7476356625556946,
      "rewards/margins": 3.426823616027832,
      "rewards/rejected": -2.679187774658203,
      "step": 1285
    },
    {
      "epoch": 0.5144,
      "grad_norm": 1.5961085557937622,
      "learning_rate": 8.286666666666666e-07,
      "logits/chosen": -2.7860212326049805,
      "logits/rejected": -2.86091947555542,
      "logps/chosen": -129.09332275390625,
      "logps/rejected": -166.32778930664062,
      "loss": 0.0114,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1831891536712646,
      "rewards/margins": 5.539083957672119,
      "rewards/rejected": -3.3558950424194336,
      "step": 1286
    },
    {
      "epoch": 0.5148,
      "grad_norm": 4.268334865570068,
      "learning_rate": 8.285333333333333e-07,
      "logits/chosen": -2.5700106620788574,
      "logits/rejected": -3.4671640396118164,
      "logps/chosen": -174.08224487304688,
      "logps/rejected": -133.61007690429688,
      "loss": 0.0463,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7507064938545227,
      "rewards/margins": 3.1828513145446777,
      "rewards/rejected": -3.9335575103759766,
      "step": 1287
    },
    {
      "epoch": 0.5152,
      "grad_norm": 0.16779853403568268,
      "learning_rate": 8.284e-07,
      "logits/chosen": -2.1299829483032227,
      "logits/rejected": -2.516303539276123,
      "logps/chosen": -102.18936157226562,
      "logps/rejected": -127.63648223876953,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.1675848960876465,
      "rewards/margins": 7.144835472106934,
      "rewards/rejected": -2.977250576019287,
      "step": 1288
    },
    {
      "epoch": 0.5156,
      "grad_norm": 0.036496393382549286,
      "learning_rate": 8.282666666666667e-07,
      "logits/chosen": -2.282072067260742,
      "logits/rejected": -3.0978894233703613,
      "logps/chosen": -155.00868225097656,
      "logps/rejected": -142.22811889648438,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.148282051086426,
      "rewards/margins": 7.837909698486328,
      "rewards/rejected": -4.689627647399902,
      "step": 1289
    },
    {
      "epoch": 0.516,
      "grad_norm": 0.35642769932746887,
      "learning_rate": 8.281333333333334e-07,
      "logits/chosen": -2.0576515197753906,
      "logits/rejected": -3.026160955429077,
      "logps/chosen": -108.52674102783203,
      "logps/rejected": -137.23355102539062,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0537288188934326,
      "rewards/margins": 6.085196495056152,
      "rewards/rejected": -4.031467437744141,
      "step": 1290
    },
    {
      "epoch": 0.5164,
      "grad_norm": 1.4124279022216797,
      "learning_rate": 8.28e-07,
      "logits/chosen": -2.479128837585449,
      "logits/rejected": -3.2752225399017334,
      "logps/chosen": -89.91690063476562,
      "logps/rejected": -147.1763458251953,
      "loss": 0.0127,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7563294172286987,
      "rewards/margins": 4.8582868576049805,
      "rewards/rejected": -3.101957321166992,
      "step": 1291
    },
    {
      "epoch": 0.5168,
      "grad_norm": 0.024303879588842392,
      "learning_rate": 8.278666666666666e-07,
      "logits/chosen": -2.23960542678833,
      "logits/rejected": -3.293578863143921,
      "logps/chosen": -104.90815734863281,
      "logps/rejected": -153.95213317871094,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7755117416381836,
      "rewards/margins": 8.234973907470703,
      "rewards/rejected": -4.459462642669678,
      "step": 1292
    },
    {
      "epoch": 0.5172,
      "grad_norm": 0.1593656688928604,
      "learning_rate": 8.277333333333333e-07,
      "logits/chosen": -2.1984734535217285,
      "logits/rejected": -3.2617201805114746,
      "logps/chosen": -156.60939025878906,
      "logps/rejected": -128.86279296875,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.421222686767578,
      "rewards/margins": 6.504275798797607,
      "rewards/rejected": -3.08305287361145,
      "step": 1293
    },
    {
      "epoch": 0.5176,
      "grad_norm": 4.555875778198242,
      "learning_rate": 8.275999999999999e-07,
      "logits/chosen": -2.033501625061035,
      "logits/rejected": -2.1745898723602295,
      "logps/chosen": -126.07547760009766,
      "logps/rejected": -128.75990295410156,
      "loss": 0.0423,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5803205966949463,
      "rewards/margins": 5.3385701179504395,
      "rewards/rejected": -2.758249282836914,
      "step": 1294
    },
    {
      "epoch": 0.518,
      "grad_norm": 0.2948347330093384,
      "learning_rate": 8.274666666666666e-07,
      "logits/chosen": -2.7269206047058105,
      "logits/rejected": -2.914405107498169,
      "logps/chosen": -154.3231201171875,
      "logps/rejected": -138.9078369140625,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.859243869781494,
      "rewards/margins": 6.5763092041015625,
      "rewards/rejected": -3.7170655727386475,
      "step": 1295
    },
    {
      "epoch": 0.5184,
      "grad_norm": 0.16230928897857666,
      "learning_rate": 8.273333333333333e-07,
      "logits/chosen": -2.290898084640503,
      "logits/rejected": -3.550358295440674,
      "logps/chosen": -111.14788818359375,
      "logps/rejected": -193.9827880859375,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5493078231811523,
      "rewards/margins": 6.742731094360352,
      "rewards/rejected": -3.1934235095977783,
      "step": 1296
    },
    {
      "epoch": 0.5188,
      "grad_norm": 0.4882347583770752,
      "learning_rate": 8.272e-07,
      "logits/chosen": -2.495490074157715,
      "logits/rejected": -3.221627712249756,
      "logps/chosen": -90.35444641113281,
      "logps/rejected": -152.2492218017578,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.875162124633789,
      "rewards/margins": 5.557273864746094,
      "rewards/rejected": -3.682112216949463,
      "step": 1297
    },
    {
      "epoch": 0.5192,
      "grad_norm": 0.1908750981092453,
      "learning_rate": 8.270666666666666e-07,
      "logits/chosen": -2.409113883972168,
      "logits/rejected": -2.9491565227508545,
      "logps/chosen": -126.30908966064453,
      "logps/rejected": -231.99026489257812,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6683969497680664,
      "rewards/margins": 7.310066223144531,
      "rewards/rejected": -3.641669511795044,
      "step": 1298
    },
    {
      "epoch": 0.5196,
      "grad_norm": 0.08332928270101547,
      "learning_rate": 8.269333333333333e-07,
      "logits/chosen": -2.2500405311584473,
      "logits/rejected": -3.0832629203796387,
      "logps/chosen": -114.58883666992188,
      "logps/rejected": -146.8128662109375,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.273374080657959,
      "rewards/margins": 7.038362503051758,
      "rewards/rejected": -3.7649879455566406,
      "step": 1299
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.18386846780776978,
      "learning_rate": 8.268e-07,
      "logits/chosen": -2.567660331726074,
      "logits/rejected": -2.77705717086792,
      "logps/chosen": -129.0362548828125,
      "logps/rejected": -151.7320556640625,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6495959758758545,
      "rewards/margins": 6.338932991027832,
      "rewards/rejected": -3.6893372535705566,
      "step": 1300
    },
    {
      "epoch": 0.5204,
      "grad_norm": 0.04337890073657036,
      "learning_rate": 8.266666666666667e-07,
      "logits/chosen": -2.4303669929504395,
      "logits/rejected": -3.420424461364746,
      "logps/chosen": -186.58499145507812,
      "logps/rejected": -143.89971923828125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.862851619720459,
      "rewards/margins": 7.640806674957275,
      "rewards/rejected": -3.7779550552368164,
      "step": 1301
    },
    {
      "epoch": 0.5208,
      "grad_norm": 0.15924319624900818,
      "learning_rate": 8.265333333333333e-07,
      "logits/chosen": -1.8579730987548828,
      "logits/rejected": -3.034221649169922,
      "logps/chosen": -70.36038970947266,
      "logps/rejected": -139.32603454589844,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.817974328994751,
      "rewards/margins": 6.454792022705078,
      "rewards/rejected": -3.636817693710327,
      "step": 1302
    },
    {
      "epoch": 0.5212,
      "grad_norm": 0.40316447615623474,
      "learning_rate": 8.263999999999999e-07,
      "logits/chosen": -2.32204532623291,
      "logits/rejected": -3.0069925785064697,
      "logps/chosen": -122.36856842041016,
      "logps/rejected": -148.60748291015625,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.107769012451172,
      "rewards/margins": 6.3983917236328125,
      "rewards/rejected": -3.2906222343444824,
      "step": 1303
    },
    {
      "epoch": 0.5216,
      "grad_norm": 0.3909183144569397,
      "learning_rate": 8.262666666666666e-07,
      "logits/chosen": -2.6809580326080322,
      "logits/rejected": -3.532278060913086,
      "logps/chosen": -126.20773315429688,
      "logps/rejected": -159.58010864257812,
      "loss": 0.0052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.18339309096336365,
      "rewards/margins": 5.25493049621582,
      "rewards/rejected": -5.438323020935059,
      "step": 1304
    },
    {
      "epoch": 0.522,
      "grad_norm": 2.25710391998291,
      "learning_rate": 8.261333333333333e-07,
      "logits/chosen": -2.131713390350342,
      "logits/rejected": -2.711003541946411,
      "logps/chosen": -104.65315246582031,
      "logps/rejected": -154.55801391601562,
      "loss": 0.0301,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2656636238098145,
      "rewards/margins": 4.906295299530029,
      "rewards/rejected": -2.640631914138794,
      "step": 1305
    },
    {
      "epoch": 0.5224,
      "grad_norm": 0.2883557677268982,
      "learning_rate": 8.259999999999999e-07,
      "logits/chosen": -2.699509859085083,
      "logits/rejected": -2.974609136581421,
      "logps/chosen": -143.09146118164062,
      "logps/rejected": -142.63153076171875,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.20089054107666,
      "rewards/margins": 7.398258686065674,
      "rewards/rejected": -3.1973679065704346,
      "step": 1306
    },
    {
      "epoch": 0.5228,
      "grad_norm": 0.5871666073799133,
      "learning_rate": 8.258666666666666e-07,
      "logits/chosen": -2.552638530731201,
      "logits/rejected": -3.2953948974609375,
      "logps/chosen": -182.39651489257812,
      "logps/rejected": -126.7783203125,
      "loss": 0.006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5665626525878906,
      "rewards/margins": 5.574920177459717,
      "rewards/rejected": -3.008357286453247,
      "step": 1307
    },
    {
      "epoch": 0.5232,
      "grad_norm": 0.07304667681455612,
      "learning_rate": 8.257333333333333e-07,
      "logits/chosen": -2.437375068664551,
      "logits/rejected": -3.2042582035064697,
      "logps/chosen": -82.31475830078125,
      "logps/rejected": -157.8261260986328,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4264333248138428,
      "rewards/margins": 7.599878787994385,
      "rewards/rejected": -5.173445701599121,
      "step": 1308
    },
    {
      "epoch": 0.5236,
      "grad_norm": 0.999708354473114,
      "learning_rate": 8.256e-07,
      "logits/chosen": -1.693085789680481,
      "logits/rejected": -3.0305819511413574,
      "logps/chosen": -94.58738708496094,
      "logps/rejected": -159.05368041992188,
      "loss": 0.0081,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5775058269500732,
      "rewards/margins": 6.068147659301758,
      "rewards/rejected": -3.4906420707702637,
      "step": 1309
    },
    {
      "epoch": 0.524,
      "grad_norm": 0.2705634534358978,
      "learning_rate": 8.254666666666667e-07,
      "logits/chosen": -2.447718381881714,
      "logits/rejected": -3.224684715270996,
      "logps/chosen": -73.17884063720703,
      "logps/rejected": -140.7873077392578,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4637928009033203,
      "rewards/margins": 5.659445285797119,
      "rewards/rejected": -3.195652484893799,
      "step": 1310
    },
    {
      "epoch": 0.5244,
      "grad_norm": 0.09511527419090271,
      "learning_rate": 8.253333333333334e-07,
      "logits/chosen": -2.092543601989746,
      "logits/rejected": -2.3824918270111084,
      "logps/chosen": -100.54585266113281,
      "logps/rejected": -130.26287841796875,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.366461277008057,
      "rewards/margins": 7.562255382537842,
      "rewards/rejected": -3.1957945823669434,
      "step": 1311
    },
    {
      "epoch": 0.5248,
      "grad_norm": 0.1566864550113678,
      "learning_rate": 8.252000000000001e-07,
      "logits/chosen": -2.3638346195220947,
      "logits/rejected": -2.890626907348633,
      "logps/chosen": -73.01896667480469,
      "logps/rejected": -122.89269256591797,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.999235153198242,
      "rewards/margins": 6.307770729064941,
      "rewards/rejected": -2.3085358142852783,
      "step": 1312
    },
    {
      "epoch": 0.5252,
      "grad_norm": 0.1714099496603012,
      "learning_rate": 8.250666666666665e-07,
      "logits/chosen": -2.3920087814331055,
      "logits/rejected": -2.568953037261963,
      "logps/chosen": -112.77333068847656,
      "logps/rejected": -115.01102447509766,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.747832775115967,
      "rewards/margins": 5.909042835235596,
      "rewards/rejected": -2.161210060119629,
      "step": 1313
    },
    {
      "epoch": 0.5256,
      "grad_norm": 0.05088496208190918,
      "learning_rate": 8.249333333333332e-07,
      "logits/chosen": -2.663397789001465,
      "logits/rejected": -3.4324278831481934,
      "logps/chosen": -155.3348846435547,
      "logps/rejected": -149.76490783691406,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5291638374328613,
      "rewards/margins": 7.503973484039307,
      "rewards/rejected": -4.974809646606445,
      "step": 1314
    },
    {
      "epoch": 0.526,
      "grad_norm": 0.19319768249988556,
      "learning_rate": 8.247999999999999e-07,
      "logits/chosen": -2.0544893741607666,
      "logits/rejected": -3.6404478549957275,
      "logps/chosen": -109.01546478271484,
      "logps/rejected": -142.55413818359375,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.869248390197754,
      "rewards/margins": 7.023534774780273,
      "rewards/rejected": -4.1542863845825195,
      "step": 1315
    },
    {
      "epoch": 0.5264,
      "grad_norm": 0.03956567868590355,
      "learning_rate": 8.246666666666666e-07,
      "logits/chosen": -2.397494316101074,
      "logits/rejected": -3.1357898712158203,
      "logps/chosen": -184.89633178710938,
      "logps/rejected": -184.65310668945312,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.113325595855713,
      "rewards/margins": 8.004415512084961,
      "rewards/rejected": -4.891090393066406,
      "step": 1316
    },
    {
      "epoch": 0.5268,
      "grad_norm": 0.09526045620441437,
      "learning_rate": 8.245333333333333e-07,
      "logits/chosen": -2.1940114498138428,
      "logits/rejected": -3.211029291152954,
      "logps/chosen": -115.05432891845703,
      "logps/rejected": -161.17279052734375,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0933151245117188,
      "rewards/margins": 7.123518466949463,
      "rewards/rejected": -5.030203342437744,
      "step": 1317
    },
    {
      "epoch": 0.5272,
      "grad_norm": 0.7200462818145752,
      "learning_rate": 8.244e-07,
      "logits/chosen": -2.427044630050659,
      "logits/rejected": -3.0453686714172363,
      "logps/chosen": -98.99311828613281,
      "logps/rejected": -126.1367416381836,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4768781661987305,
      "rewards/margins": 5.623455047607422,
      "rewards/rejected": -3.1465771198272705,
      "step": 1318
    },
    {
      "epoch": 0.5276,
      "grad_norm": 7.550698757171631,
      "learning_rate": 8.242666666666667e-07,
      "logits/chosen": -2.298208236694336,
      "logits/rejected": -2.269282341003418,
      "logps/chosen": -70.53868865966797,
      "logps/rejected": -98.6155776977539,
      "loss": 0.0807,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7108392715454102,
      "rewards/margins": 4.085910797119141,
      "rewards/rejected": -2.3750715255737305,
      "step": 1319
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.39750704169273376,
      "learning_rate": 8.241333333333334e-07,
      "logits/chosen": -2.477109909057617,
      "logits/rejected": -3.0630617141723633,
      "logps/chosen": -119.44910430908203,
      "logps/rejected": -122.68846130371094,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0126161575317383,
      "rewards/margins": 6.303346157073975,
      "rewards/rejected": -3.2907299995422363,
      "step": 1320
    },
    {
      "epoch": 0.5284,
      "grad_norm": 0.29296085238456726,
      "learning_rate": 8.24e-07,
      "logits/chosen": -2.6395301818847656,
      "logits/rejected": -3.0413317680358887,
      "logps/chosen": -146.10452270507812,
      "logps/rejected": -117.763671875,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9772602319717407,
      "rewards/margins": 5.4144978523254395,
      "rewards/rejected": -3.4372377395629883,
      "step": 1321
    },
    {
      "epoch": 0.5288,
      "grad_norm": 0.7296185493469238,
      "learning_rate": 8.238666666666666e-07,
      "logits/chosen": -2.225363254547119,
      "logits/rejected": -2.1082310676574707,
      "logps/chosen": -104.50192260742188,
      "logps/rejected": -114.5511245727539,
      "loss": 0.0065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.193722724914551,
      "rewards/margins": 6.077485084533691,
      "rewards/rejected": -2.883762836456299,
      "step": 1322
    },
    {
      "epoch": 0.5292,
      "grad_norm": 1.655897617340088,
      "learning_rate": 8.237333333333332e-07,
      "logits/chosen": -2.4790518283843994,
      "logits/rejected": -2.299082040786743,
      "logps/chosen": -132.4713592529297,
      "logps/rejected": -105.47952270507812,
      "loss": 0.0158,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3870809078216553,
      "rewards/margins": 5.075725555419922,
      "rewards/rejected": -2.6886444091796875,
      "step": 1323
    },
    {
      "epoch": 0.5296,
      "grad_norm": 0.04737954959273338,
      "learning_rate": 8.235999999999999e-07,
      "logits/chosen": -2.5167839527130127,
      "logits/rejected": -3.0571460723876953,
      "logps/chosen": -185.8928680419922,
      "logps/rejected": -148.6611328125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6868577003479004,
      "rewards/margins": 7.715926647186279,
      "rewards/rejected": -4.029068946838379,
      "step": 1324
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.11177660524845123,
      "learning_rate": 8.234666666666666e-07,
      "logits/chosen": -2.7464168071746826,
      "logits/rejected": -2.692476511001587,
      "logps/chosen": -204.4783477783203,
      "logps/rejected": -131.1650390625,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.432375431060791,
      "rewards/margins": 7.388131141662598,
      "rewards/rejected": -3.9557557106018066,
      "step": 1325
    },
    {
      "epoch": 0.5304,
      "grad_norm": 0.18596063554286957,
      "learning_rate": 8.233333333333333e-07,
      "logits/chosen": -2.0546035766601562,
      "logits/rejected": -2.2523303031921387,
      "logps/chosen": -62.815650939941406,
      "logps/rejected": -95.36996459960938,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.1226983070373535,
      "rewards/margins": 5.930617332458496,
      "rewards/rejected": -1.8079190254211426,
      "step": 1326
    },
    {
      "epoch": 0.5308,
      "grad_norm": 0.03639296442270279,
      "learning_rate": 8.232e-07,
      "logits/chosen": -2.6529650688171387,
      "logits/rejected": -3.0548176765441895,
      "logps/chosen": -151.13009643554688,
      "logps/rejected": -154.6731719970703,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.471747398376465,
      "rewards/margins": 8.115663528442383,
      "rewards/rejected": -3.643915891647339,
      "step": 1327
    },
    {
      "epoch": 0.5312,
      "grad_norm": 0.07899145781993866,
      "learning_rate": 8.230666666666666e-07,
      "logits/chosen": -2.207818031311035,
      "logits/rejected": -2.920560359954834,
      "logps/chosen": -115.09910583496094,
      "logps/rejected": -234.17605590820312,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.123518466949463,
      "rewards/margins": 7.879699230194092,
      "rewards/rejected": -3.756180763244629,
      "step": 1328
    },
    {
      "epoch": 0.5316,
      "grad_norm": 3.3615782260894775,
      "learning_rate": 8.229333333333333e-07,
      "logits/chosen": -2.9145960807800293,
      "logits/rejected": -3.1365256309509277,
      "logps/chosen": -259.09295654296875,
      "logps/rejected": -172.349853515625,
      "loss": 0.0364,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0539100170135498,
      "rewards/margins": 3.424896240234375,
      "rewards/rejected": -2.370986223220825,
      "step": 1329
    },
    {
      "epoch": 0.532,
      "grad_norm": 0.7509462237358093,
      "learning_rate": 8.228e-07,
      "logits/chosen": -2.656926393508911,
      "logits/rejected": -2.895658016204834,
      "logps/chosen": -160.8792724609375,
      "logps/rejected": -176.77224731445312,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9821381568908691,
      "rewards/margins": 6.095464706420898,
      "rewards/rejected": -4.113326549530029,
      "step": 1330
    },
    {
      "epoch": 0.5324,
      "grad_norm": 0.09762454777956009,
      "learning_rate": 8.226666666666666e-07,
      "logits/chosen": -2.076150894165039,
      "logits/rejected": -2.891835927963257,
      "logps/chosen": -133.66136169433594,
      "logps/rejected": -147.7758026123047,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1462185382843018,
      "rewards/margins": 7.030421257019043,
      "rewards/rejected": -3.884202480316162,
      "step": 1331
    },
    {
      "epoch": 0.5328,
      "grad_norm": 0.499004989862442,
      "learning_rate": 8.225333333333333e-07,
      "logits/chosen": -2.3221092224121094,
      "logits/rejected": -2.9471564292907715,
      "logps/chosen": -159.75405883789062,
      "logps/rejected": -115.01242065429688,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0438485145568848,
      "rewards/margins": 5.629015922546387,
      "rewards/rejected": -2.585167407989502,
      "step": 1332
    },
    {
      "epoch": 0.5332,
      "grad_norm": 0.06255802512168884,
      "learning_rate": 8.224e-07,
      "logits/chosen": -2.427093029022217,
      "logits/rejected": -3.0153493881225586,
      "logps/chosen": -100.9781723022461,
      "logps/rejected": -157.71255493164062,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5714173316955566,
      "rewards/margins": 7.2996907234191895,
      "rewards/rejected": -3.728273391723633,
      "step": 1333
    },
    {
      "epoch": 0.5336,
      "grad_norm": 3.0702500343322754,
      "learning_rate": 8.222666666666666e-07,
      "logits/chosen": -1.9864510297775269,
      "logits/rejected": -2.9882354736328125,
      "logps/chosen": -87.02499389648438,
      "logps/rejected": -145.00848388671875,
      "loss": 0.0363,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2702629566192627,
      "rewards/margins": 4.7161784172058105,
      "rewards/rejected": -3.4459152221679688,
      "step": 1334
    },
    {
      "epoch": 0.534,
      "grad_norm": 0.42982542514801025,
      "learning_rate": 8.221333333333333e-07,
      "logits/chosen": -1.4573628902435303,
      "logits/rejected": -2.986238956451416,
      "logps/chosen": -97.03833770751953,
      "logps/rejected": -119.7531509399414,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.036963701248169,
      "rewards/margins": 6.243045806884766,
      "rewards/rejected": -3.206082582473755,
      "step": 1335
    },
    {
      "epoch": 0.5344,
      "grad_norm": 1.701074242591858,
      "learning_rate": 8.219999999999999e-07,
      "logits/chosen": -2.7553813457489014,
      "logits/rejected": -2.980724811553955,
      "logps/chosen": -203.34197998046875,
      "logps/rejected": -154.6084442138672,
      "loss": 0.0197,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9768310785293579,
      "rewards/margins": 3.9593758583068848,
      "rewards/rejected": -2.9825446605682373,
      "step": 1336
    },
    {
      "epoch": 0.5348,
      "grad_norm": 0.92960524559021,
      "learning_rate": 8.218666666666666e-07,
      "logits/chosen": -2.367095470428467,
      "logits/rejected": -2.689181089401245,
      "logps/chosen": -146.16526794433594,
      "logps/rejected": -117.8543930053711,
      "loss": 0.013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.238130569458008,
      "rewards/margins": 4.839771270751953,
      "rewards/rejected": -2.6016411781311035,
      "step": 1337
    },
    {
      "epoch": 0.5352,
      "grad_norm": 8.070682525634766,
      "learning_rate": 8.217333333333333e-07,
      "logits/chosen": -1.9570820331573486,
      "logits/rejected": -3.3243470191955566,
      "logps/chosen": -94.24105072021484,
      "logps/rejected": -115.52113342285156,
      "loss": 0.1325,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3163493871688843,
      "rewards/margins": 4.474077224731445,
      "rewards/rejected": -3.1577279567718506,
      "step": 1338
    },
    {
      "epoch": 0.5356,
      "grad_norm": 0.06368836015462875,
      "learning_rate": 8.216e-07,
      "logits/chosen": -2.668957233428955,
      "logits/rejected": -2.8477210998535156,
      "logps/chosen": -108.0386734008789,
      "logps/rejected": -144.23300170898438,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.615945339202881,
      "rewards/margins": 7.28568696975708,
      "rewards/rejected": -3.669741630554199,
      "step": 1339
    },
    {
      "epoch": 0.536,
      "grad_norm": 1.0362937450408936,
      "learning_rate": 8.214666666666667e-07,
      "logits/chosen": -2.399512767791748,
      "logits/rejected": -3.186471700668335,
      "logps/chosen": -160.76889038085938,
      "logps/rejected": -156.6409912109375,
      "loss": 0.0074,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.890416145324707,
      "rewards/margins": 5.801139831542969,
      "rewards/rejected": -2.910723924636841,
      "step": 1340
    },
    {
      "epoch": 0.5364,
      "grad_norm": 0.6625850200653076,
      "learning_rate": 8.213333333333333e-07,
      "logits/chosen": -2.3062057495117188,
      "logits/rejected": -3.3735880851745605,
      "logps/chosen": -85.9689712524414,
      "logps/rejected": -132.42788696289062,
      "loss": 0.0079,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9906593561172485,
      "rewards/margins": 4.933499813079834,
      "rewards/rejected": -3.942840576171875,
      "step": 1341
    },
    {
      "epoch": 0.5368,
      "grad_norm": 0.09731549769639969,
      "learning_rate": 8.212e-07,
      "logits/chosen": -2.1631112098693848,
      "logits/rejected": -3.1926965713500977,
      "logps/chosen": -66.12409210205078,
      "logps/rejected": -116.41078186035156,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.580920457839966,
      "rewards/margins": 7.017314434051514,
      "rewards/rejected": -3.4363937377929688,
      "step": 1342
    },
    {
      "epoch": 0.5372,
      "grad_norm": 0.16247141361236572,
      "learning_rate": 8.210666666666666e-07,
      "logits/chosen": -2.308887243270874,
      "logits/rejected": -3.485948324203491,
      "logps/chosen": -110.35379028320312,
      "logps/rejected": -131.04498291015625,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2150399684906006,
      "rewards/margins": 6.461182594299316,
      "rewards/rejected": -3.246142625808716,
      "step": 1343
    },
    {
      "epoch": 0.5376,
      "grad_norm": 0.6305299997329712,
      "learning_rate": 8.209333333333332e-07,
      "logits/chosen": -2.0756325721740723,
      "logits/rejected": -3.2229361534118652,
      "logps/chosen": -159.07843017578125,
      "logps/rejected": -145.82066345214844,
      "loss": 0.0072,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1878743171691895,
      "rewards/margins": 5.944703102111816,
      "rewards/rejected": -3.756829261779785,
      "step": 1344
    },
    {
      "epoch": 0.538,
      "grad_norm": 0.251577228307724,
      "learning_rate": 8.207999999999999e-07,
      "logits/chosen": -1.9193346500396729,
      "logits/rejected": -2.794644355773926,
      "logps/chosen": -117.43905639648438,
      "logps/rejected": -147.17115783691406,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8819007873535156,
      "rewards/margins": 6.306256294250488,
      "rewards/rejected": -4.424355506896973,
      "step": 1345
    },
    {
      "epoch": 0.5384,
      "grad_norm": 0.7076241970062256,
      "learning_rate": 8.206666666666666e-07,
      "logits/chosen": -2.169893741607666,
      "logits/rejected": -2.937532424926758,
      "logps/chosen": -108.05215454101562,
      "logps/rejected": -139.36123657226562,
      "loss": 0.0086,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0877166986465454,
      "rewards/margins": 5.437198638916016,
      "rewards/rejected": -4.34948205947876,
      "step": 1346
    },
    {
      "epoch": 0.5388,
      "grad_norm": 0.9271373748779297,
      "learning_rate": 8.205333333333333e-07,
      "logits/chosen": -2.442003011703491,
      "logits/rejected": -2.775324821472168,
      "logps/chosen": -97.32540130615234,
      "logps/rejected": -108.31016540527344,
      "loss": 0.012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0722997188568115,
      "rewards/margins": 4.818957328796387,
      "rewards/rejected": -2.7466578483581543,
      "step": 1347
    },
    {
      "epoch": 0.5392,
      "grad_norm": 0.12805473804473877,
      "learning_rate": 8.204e-07,
      "logits/chosen": -2.021817922592163,
      "logits/rejected": -2.821074962615967,
      "logps/chosen": -95.4549560546875,
      "logps/rejected": -231.40342712402344,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8971805572509766,
      "rewards/margins": 6.824271202087402,
      "rewards/rejected": -2.927090644836426,
      "step": 1348
    },
    {
      "epoch": 0.5396,
      "grad_norm": 0.06165897101163864,
      "learning_rate": 8.202666666666667e-07,
      "logits/chosen": -2.2269480228424072,
      "logits/rejected": -2.440136194229126,
      "logps/chosen": -83.16543579101562,
      "logps/rejected": -167.41587829589844,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7195215225219727,
      "rewards/margins": 7.282905578613281,
      "rewards/rejected": -3.5633842945098877,
      "step": 1349
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.28803759813308716,
      "learning_rate": 8.201333333333333e-07,
      "logits/chosen": -2.1842164993286133,
      "logits/rejected": -2.509521007537842,
      "logps/chosen": -100.85420227050781,
      "logps/rejected": -117.31717681884766,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.435211181640625,
      "rewards/margins": 5.956225395202637,
      "rewards/rejected": -3.5210142135620117,
      "step": 1350
    },
    {
      "epoch": 0.5404,
      "grad_norm": 3.610896110534668,
      "learning_rate": 8.199999999999999e-07,
      "logits/chosen": -2.303467273712158,
      "logits/rejected": -3.2842326164245605,
      "logps/chosen": -89.35572814941406,
      "logps/rejected": -139.26361083984375,
      "loss": 0.0313,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8552417755126953,
      "rewards/margins": 5.629733562469482,
      "rewards/rejected": -2.774491548538208,
      "step": 1351
    },
    {
      "epoch": 0.5408,
      "grad_norm": 0.19920147955417633,
      "learning_rate": 8.198666666666666e-07,
      "logits/chosen": -2.0682244300842285,
      "logits/rejected": -2.8038434982299805,
      "logps/chosen": -100.34957885742188,
      "logps/rejected": -141.3238525390625,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4161806106567383,
      "rewards/margins": 7.024672031402588,
      "rewards/rejected": -4.608491897583008,
      "step": 1352
    },
    {
      "epoch": 0.5412,
      "grad_norm": 2.061075210571289,
      "learning_rate": 8.197333333333333e-07,
      "logits/chosen": -2.2605409622192383,
      "logits/rejected": -2.735137462615967,
      "logps/chosen": -132.8876495361328,
      "logps/rejected": -121.7732162475586,
      "loss": 0.0223,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.113848090171814,
      "rewards/margins": 3.901989459991455,
      "rewards/rejected": -2.7881412506103516,
      "step": 1353
    },
    {
      "epoch": 0.5416,
      "grad_norm": 0.15410932898521423,
      "learning_rate": 8.196e-07,
      "logits/chosen": -2.2947609424591064,
      "logits/rejected": -3.242522954940796,
      "logps/chosen": -143.3863983154297,
      "logps/rejected": -177.40574645996094,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.981688976287842,
      "rewards/margins": 6.403347015380859,
      "rewards/rejected": -3.4216575622558594,
      "step": 1354
    },
    {
      "epoch": 0.542,
      "grad_norm": 0.11263065785169601,
      "learning_rate": 8.194666666666666e-07,
      "logits/chosen": -2.365091323852539,
      "logits/rejected": -3.1051502227783203,
      "logps/chosen": -82.48260498046875,
      "logps/rejected": -122.67082214355469,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.161205768585205,
      "rewards/margins": 6.750385284423828,
      "rewards/rejected": -3.589179515838623,
      "step": 1355
    },
    {
      "epoch": 0.5424,
      "grad_norm": 0.1455507129430771,
      "learning_rate": 8.193333333333333e-07,
      "logits/chosen": -2.154873847961426,
      "logits/rejected": -2.381171703338623,
      "logps/chosen": -71.252197265625,
      "logps/rejected": -118.08757781982422,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1374974250793457,
      "rewards/margins": 6.399870872497559,
      "rewards/rejected": -3.262373447418213,
      "step": 1356
    },
    {
      "epoch": 0.5428,
      "grad_norm": 0.7005122900009155,
      "learning_rate": 8.192e-07,
      "logits/chosen": -1.8309073448181152,
      "logits/rejected": -2.8765926361083984,
      "logps/chosen": -110.71001434326172,
      "logps/rejected": -107.49496459960938,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9659104347229004,
      "rewards/margins": 5.901630878448486,
      "rewards/rejected": -2.935720443725586,
      "step": 1357
    },
    {
      "epoch": 0.5432,
      "grad_norm": 0.5202021598815918,
      "learning_rate": 8.190666666666667e-07,
      "logits/chosen": -2.1417603492736816,
      "logits/rejected": -3.080000638961792,
      "logps/chosen": -97.86113739013672,
      "logps/rejected": -163.7994384765625,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.071310043334961,
      "rewards/margins": 6.669565200805664,
      "rewards/rejected": -4.598254680633545,
      "step": 1358
    },
    {
      "epoch": 0.5436,
      "grad_norm": 0.1434997171163559,
      "learning_rate": 8.189333333333332e-07,
      "logits/chosen": -2.1784050464630127,
      "logits/rejected": -2.6853270530700684,
      "logps/chosen": -94.52436065673828,
      "logps/rejected": -134.47140502929688,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.99517560005188,
      "rewards/margins": 6.516786575317383,
      "rewards/rejected": -3.521610736846924,
      "step": 1359
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.03557053953409195,
      "learning_rate": 8.187999999999999e-07,
      "logits/chosen": -2.105827808380127,
      "logits/rejected": -3.026546001434326,
      "logps/chosen": -147.09310913085938,
      "logps/rejected": -213.32925415039062,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.376239776611328,
      "rewards/margins": 7.890561103820801,
      "rewards/rejected": -4.514321327209473,
      "step": 1360
    },
    {
      "epoch": 0.5444,
      "grad_norm": 2.5729644298553467,
      "learning_rate": 8.186666666666666e-07,
      "logits/chosen": -2.0363950729370117,
      "logits/rejected": -2.667754888534546,
      "logps/chosen": -102.37330627441406,
      "logps/rejected": -133.1470947265625,
      "loss": 0.0298,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8594971299171448,
      "rewards/margins": 5.398479461669922,
      "rewards/rejected": -4.538982391357422,
      "step": 1361
    },
    {
      "epoch": 0.5448,
      "grad_norm": 0.3612530529499054,
      "learning_rate": 8.185333333333333e-07,
      "logits/chosen": -2.0426864624023438,
      "logits/rejected": -2.8954458236694336,
      "logps/chosen": -104.20401000976562,
      "logps/rejected": -109.69401550292969,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5409313440322876,
      "rewards/margins": 5.438925743103027,
      "rewards/rejected": -3.8979947566986084,
      "step": 1362
    },
    {
      "epoch": 0.5452,
      "grad_norm": 0.8076857328414917,
      "learning_rate": 8.184e-07,
      "logits/chosen": -2.216151237487793,
      "logits/rejected": -3.2398715019226074,
      "logps/chosen": -181.66970825195312,
      "logps/rejected": -127.74678039550781,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2493081092834473,
      "rewards/margins": 5.391735076904297,
      "rewards/rejected": -3.1424269676208496,
      "step": 1363
    },
    {
      "epoch": 0.5456,
      "grad_norm": 0.0997445359826088,
      "learning_rate": 8.182666666666667e-07,
      "logits/chosen": -2.3965537548065186,
      "logits/rejected": -2.816533327102661,
      "logps/chosen": -78.377685546875,
      "logps/rejected": -137.10533142089844,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5847904682159424,
      "rewards/margins": 7.824341773986816,
      "rewards/rejected": -4.239551067352295,
      "step": 1364
    },
    {
      "epoch": 0.546,
      "grad_norm": 0.3541145920753479,
      "learning_rate": 8.181333333333334e-07,
      "logits/chosen": -2.2662925720214844,
      "logits/rejected": -2.9441914558410645,
      "logps/chosen": -106.84696960449219,
      "logps/rejected": -141.57620239257812,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.089759588241577,
      "rewards/margins": 6.7758989334106445,
      "rewards/rejected": -3.6861393451690674,
      "step": 1365
    },
    {
      "epoch": 0.5464,
      "grad_norm": 1.1763834953308105,
      "learning_rate": 8.179999999999999e-07,
      "logits/chosen": -2.8006701469421387,
      "logits/rejected": -3.3335049152374268,
      "logps/chosen": -148.5935821533203,
      "logps/rejected": -198.18994140625,
      "loss": 0.0096,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.514315605163574,
      "rewards/margins": 6.145716667175293,
      "rewards/rejected": -2.6314010620117188,
      "step": 1366
    },
    {
      "epoch": 0.5468,
      "grad_norm": 2.0106008052825928,
      "learning_rate": 8.178666666666666e-07,
      "logits/chosen": -2.5332999229431152,
      "logits/rejected": -2.861604690551758,
      "logps/chosen": -110.98637390136719,
      "logps/rejected": -126.48281860351562,
      "loss": 0.0258,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2900123596191406,
      "rewards/margins": 3.7320785522460938,
      "rewards/rejected": -2.442066192626953,
      "step": 1367
    },
    {
      "epoch": 0.5472,
      "grad_norm": 0.23037460446357727,
      "learning_rate": 8.177333333333333e-07,
      "logits/chosen": -2.410067319869995,
      "logits/rejected": -3.4129910469055176,
      "logps/chosen": -169.6265869140625,
      "logps/rejected": -147.62579345703125,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1711151599884033,
      "rewards/margins": 6.636329174041748,
      "rewards/rejected": -4.465214252471924,
      "step": 1368
    },
    {
      "epoch": 0.5476,
      "grad_norm": 0.8442983627319336,
      "learning_rate": 8.175999999999999e-07,
      "logits/chosen": -2.3718795776367188,
      "logits/rejected": -2.9297027587890625,
      "logps/chosen": -132.6585235595703,
      "logps/rejected": -222.70748901367188,
      "loss": 0.0077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.088104248046875,
      "rewards/margins": 5.01609992980957,
      "rewards/rejected": -3.927995443344116,
      "step": 1369
    },
    {
      "epoch": 0.548,
      "grad_norm": 0.20189696550369263,
      "learning_rate": 8.174666666666666e-07,
      "logits/chosen": -2.3081612586975098,
      "logits/rejected": -2.7394907474517822,
      "logps/chosen": -63.18353271484375,
      "logps/rejected": -124.9476318359375,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.504112958908081,
      "rewards/margins": 6.252042770385742,
      "rewards/rejected": -3.747929573059082,
      "step": 1370
    },
    {
      "epoch": 0.5484,
      "grad_norm": 0.28983595967292786,
      "learning_rate": 8.173333333333333e-07,
      "logits/chosen": -1.9263051748275757,
      "logits/rejected": -3.053603172302246,
      "logps/chosen": -123.00804138183594,
      "logps/rejected": -176.78347778320312,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.580955982208252,
      "rewards/margins": 6.051331043243408,
      "rewards/rejected": -4.470375061035156,
      "step": 1371
    },
    {
      "epoch": 0.5488,
      "grad_norm": 0.9548665881156921,
      "learning_rate": 8.172e-07,
      "logits/chosen": -2.009714126586914,
      "logits/rejected": -2.922085762023926,
      "logps/chosen": -101.52427673339844,
      "logps/rejected": -125.75798797607422,
      "loss": 0.0125,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8519485592842102,
      "rewards/margins": 4.607800006866455,
      "rewards/rejected": -3.7558512687683105,
      "step": 1372
    },
    {
      "epoch": 0.5492,
      "grad_norm": 0.044025175273418427,
      "learning_rate": 8.170666666666667e-07,
      "logits/chosen": -2.3513166904449463,
      "logits/rejected": -3.2787351608276367,
      "logps/chosen": -150.37692260742188,
      "logps/rejected": -150.4435272216797,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9694933891296387,
      "rewards/margins": 7.992666244506836,
      "rewards/rejected": -4.0231733322143555,
      "step": 1373
    },
    {
      "epoch": 0.5496,
      "grad_norm": 1.6517668962478638,
      "learning_rate": 8.169333333333333e-07,
      "logits/chosen": -2.0736870765686035,
      "logits/rejected": -3.026808261871338,
      "logps/chosen": -146.355224609375,
      "logps/rejected": -117.0868148803711,
      "loss": 0.0163,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6938045620918274,
      "rewards/margins": 4.224743366241455,
      "rewards/rejected": -3.5309388637542725,
      "step": 1374
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.12779726088047028,
      "learning_rate": 8.168e-07,
      "logits/chosen": -2.8381595611572266,
      "logits/rejected": -2.6602911949157715,
      "logps/chosen": -117.0439224243164,
      "logps/rejected": -126.33016204833984,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.639261245727539,
      "rewards/margins": 6.6705322265625,
      "rewards/rejected": -4.031270503997803,
      "step": 1375
    },
    {
      "epoch": 0.5504,
      "grad_norm": 0.06759074330329895,
      "learning_rate": 8.166666666666666e-07,
      "logits/chosen": -2.2767529487609863,
      "logits/rejected": -3.25278902053833,
      "logps/chosen": -170.27679443359375,
      "logps/rejected": -149.09242248535156,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.0398712158203125,
      "rewards/margins": 7.327136993408203,
      "rewards/rejected": -3.287266254425049,
      "step": 1376
    },
    {
      "epoch": 0.5508,
      "grad_norm": 0.08464404195547104,
      "learning_rate": 8.165333333333333e-07,
      "logits/chosen": -2.2517571449279785,
      "logits/rejected": -2.9243316650390625,
      "logps/chosen": -62.91513442993164,
      "logps/rejected": -108.596435546875,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.594916820526123,
      "rewards/margins": 7.003890037536621,
      "rewards/rejected": -3.408972978591919,
      "step": 1377
    },
    {
      "epoch": 0.5512,
      "grad_norm": 0.44083279371261597,
      "learning_rate": 8.163999999999999e-07,
      "logits/chosen": -2.0934324264526367,
      "logits/rejected": -2.8070197105407715,
      "logps/chosen": -104.92501831054688,
      "logps/rejected": -127.420654296875,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.659029960632324,
      "rewards/margins": 5.827817440032959,
      "rewards/rejected": -3.1687874794006348,
      "step": 1378
    },
    {
      "epoch": 0.5516,
      "grad_norm": 0.4690041244029999,
      "learning_rate": 8.162666666666666e-07,
      "logits/chosen": -1.8038146495819092,
      "logits/rejected": -3.1772589683532715,
      "logps/chosen": -83.13636779785156,
      "logps/rejected": -132.4525909423828,
      "loss": 0.0059,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5195510387420654,
      "rewards/margins": 5.154632568359375,
      "rewards/rejected": -3.6350810527801514,
      "step": 1379
    },
    {
      "epoch": 0.552,
      "grad_norm": 0.1549840122461319,
      "learning_rate": 8.161333333333333e-07,
      "logits/chosen": -2.719332695007324,
      "logits/rejected": -2.6808485984802246,
      "logps/chosen": -121.72164154052734,
      "logps/rejected": -116.14988708496094,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8383727073669434,
      "rewards/margins": 6.328452110290527,
      "rewards/rejected": -3.490079402923584,
      "step": 1380
    },
    {
      "epoch": 0.5524,
      "grad_norm": 1.3442764282226562,
      "learning_rate": 8.159999999999999e-07,
      "logits/chosen": -2.1217293739318848,
      "logits/rejected": -3.3284716606140137,
      "logps/chosen": -95.83027648925781,
      "logps/rejected": -137.57894897460938,
      "loss": 0.0205,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.207891821861267,
      "rewards/margins": 4.189959526062012,
      "rewards/rejected": -2.9820680618286133,
      "step": 1381
    },
    {
      "epoch": 0.5528,
      "grad_norm": 0.5712348818778992,
      "learning_rate": 8.158666666666666e-07,
      "logits/chosen": -2.2055482864379883,
      "logits/rejected": -2.982642650604248,
      "logps/chosen": -95.56420135498047,
      "logps/rejected": -136.50958251953125,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.698094129562378,
      "rewards/margins": 6.082461833953857,
      "rewards/rejected": -3.3843674659729004,
      "step": 1382
    },
    {
      "epoch": 0.5532,
      "grad_norm": 2.594291925430298,
      "learning_rate": 8.157333333333333e-07,
      "logits/chosen": -2.333428382873535,
      "logits/rejected": -3.221005439758301,
      "logps/chosen": -118.37870025634766,
      "logps/rejected": -142.1295166015625,
      "loss": 0.018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.802874743938446,
      "rewards/margins": 4.756659507751465,
      "rewards/rejected": -3.953784704208374,
      "step": 1383
    },
    {
      "epoch": 0.5536,
      "grad_norm": 0.169491246342659,
      "learning_rate": 8.156e-07,
      "logits/chosen": -2.333202838897705,
      "logits/rejected": -2.874831438064575,
      "logps/chosen": -104.50300598144531,
      "logps/rejected": -127.77046203613281,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.95940899848938,
      "rewards/margins": 6.565345764160156,
      "rewards/rejected": -3.6059370040893555,
      "step": 1384
    },
    {
      "epoch": 0.554,
      "grad_norm": 0.6751608848571777,
      "learning_rate": 8.154666666666667e-07,
      "logits/chosen": -2.4680287837982178,
      "logits/rejected": -3.041289806365967,
      "logps/chosen": -95.09580993652344,
      "logps/rejected": -136.72024536132812,
      "loss": 0.0072,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1369545459747314,
      "rewards/margins": 5.265592575073242,
      "rewards/rejected": -4.128637790679932,
      "step": 1385
    },
    {
      "epoch": 0.5544,
      "grad_norm": 2.8705127239227295,
      "learning_rate": 8.153333333333334e-07,
      "logits/chosen": -2.0426056385040283,
      "logits/rejected": -2.491199493408203,
      "logps/chosen": -102.38643646240234,
      "logps/rejected": -150.42800903320312,
      "loss": 0.0209,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6123520135879517,
      "rewards/margins": 4.055596351623535,
      "rewards/rejected": -3.443244457244873,
      "step": 1386
    },
    {
      "epoch": 0.5548,
      "grad_norm": 0.5458569526672363,
      "learning_rate": 8.152e-07,
      "logits/chosen": -2.4167556762695312,
      "logits/rejected": -2.5664591789245605,
      "logps/chosen": -105.6480484008789,
      "logps/rejected": -106.80630493164062,
      "loss": 0.0059,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0350940227508545,
      "rewards/margins": 5.766817092895508,
      "rewards/rejected": -3.7317230701446533,
      "step": 1387
    },
    {
      "epoch": 0.5552,
      "grad_norm": 3.0896239280700684,
      "learning_rate": 8.150666666666666e-07,
      "logits/chosen": -2.155428647994995,
      "logits/rejected": -2.342444658279419,
      "logps/chosen": -83.52989959716797,
      "logps/rejected": -110.36243438720703,
      "loss": 0.0393,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9375519752502441,
      "rewards/margins": 4.504535675048828,
      "rewards/rejected": -2.566983461380005,
      "step": 1388
    },
    {
      "epoch": 0.5556,
      "grad_norm": 0.02249857783317566,
      "learning_rate": 8.149333333333332e-07,
      "logits/chosen": -2.3275249004364014,
      "logits/rejected": -2.646376132965088,
      "logps/chosen": -124.03237915039062,
      "logps/rejected": -165.39776611328125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1814627647399902,
      "rewards/margins": 8.582880973815918,
      "rewards/rejected": -5.401418209075928,
      "step": 1389
    },
    {
      "epoch": 0.556,
      "grad_norm": 0.18056058883666992,
      "learning_rate": 8.147999999999999e-07,
      "logits/chosen": -2.434542655944824,
      "logits/rejected": -2.9815196990966797,
      "logps/chosen": -134.02320861816406,
      "logps/rejected": -148.74624633789062,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1533687114715576,
      "rewards/margins": 6.200014114379883,
      "rewards/rejected": -3.046645402908325,
      "step": 1390
    },
    {
      "epoch": 0.5564,
      "grad_norm": 8.26070785522461,
      "learning_rate": 8.146666666666666e-07,
      "logits/chosen": -2.1717538833618164,
      "logits/rejected": -3.209113121032715,
      "logps/chosen": -188.623291015625,
      "logps/rejected": -130.9550018310547,
      "loss": 0.0967,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6799991726875305,
      "rewards/margins": 3.0692455768585205,
      "rewards/rejected": -3.7492446899414062,
      "step": 1391
    },
    {
      "epoch": 0.5568,
      "grad_norm": 0.349500447511673,
      "learning_rate": 8.145333333333333e-07,
      "logits/chosen": -2.1023008823394775,
      "logits/rejected": -3.2557621002197266,
      "logps/chosen": -150.33065795898438,
      "logps/rejected": -204.556396484375,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3347800970077515,
      "rewards/margins": 5.593705177307129,
      "rewards/rejected": -4.258924961090088,
      "step": 1392
    },
    {
      "epoch": 0.5572,
      "grad_norm": 0.19294944405555725,
      "learning_rate": 8.144e-07,
      "logits/chosen": -2.185462236404419,
      "logits/rejected": -3.6023969650268555,
      "logps/chosen": -85.9786376953125,
      "logps/rejected": -127.56790924072266,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9816346168518066,
      "rewards/margins": 6.315155506134033,
      "rewards/rejected": -3.3335208892822266,
      "step": 1393
    },
    {
      "epoch": 0.5576,
      "grad_norm": 0.47243764996528625,
      "learning_rate": 8.142666666666667e-07,
      "logits/chosen": -2.6760246753692627,
      "logits/rejected": -2.7510809898376465,
      "logps/chosen": -189.44003295898438,
      "logps/rejected": -128.54556274414062,
      "loss": 0.0049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9698593616485596,
      "rewards/margins": 5.396262168884277,
      "rewards/rejected": -2.426403045654297,
      "step": 1394
    },
    {
      "epoch": 0.558,
      "grad_norm": 1.241945505142212,
      "learning_rate": 8.141333333333334e-07,
      "logits/chosen": -1.9059460163116455,
      "logits/rejected": -3.054417848587036,
      "logps/chosen": -77.4175033569336,
      "logps/rejected": -134.20596313476562,
      "loss": 0.016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.55022394657135,
      "rewards/margins": 5.584228515625,
      "rewards/rejected": -4.0340046882629395,
      "step": 1395
    },
    {
      "epoch": 0.5584,
      "grad_norm": 5.184137344360352,
      "learning_rate": 8.14e-07,
      "logits/chosen": -2.0288944244384766,
      "logits/rejected": -2.604325532913208,
      "logps/chosen": -82.32173156738281,
      "logps/rejected": -112.41671752929688,
      "loss": 0.0566,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22813528776168823,
      "rewards/margins": 3.34941029548645,
      "rewards/rejected": -3.121274948120117,
      "step": 1396
    },
    {
      "epoch": 0.5588,
      "grad_norm": 0.10346592962741852,
      "learning_rate": 8.138666666666665e-07,
      "logits/chosen": -1.9775903224945068,
      "logits/rejected": -2.9775002002716064,
      "logps/chosen": -128.81202697753906,
      "logps/rejected": -165.85629272460938,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9114826917648315,
      "rewards/margins": 6.861816883087158,
      "rewards/rejected": -4.950334548950195,
      "step": 1397
    },
    {
      "epoch": 0.5592,
      "grad_norm": 0.5358392000198364,
      "learning_rate": 8.137333333333332e-07,
      "logits/chosen": -2.2901835441589355,
      "logits/rejected": -2.9359166622161865,
      "logps/chosen": -82.63034057617188,
      "logps/rejected": -136.5924530029297,
      "loss": 0.0051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.841862201690674,
      "rewards/margins": 6.388023853302002,
      "rewards/rejected": -3.546161651611328,
      "step": 1398
    },
    {
      "epoch": 0.5596,
      "grad_norm": 0.6096543073654175,
      "learning_rate": 8.135999999999999e-07,
      "logits/chosen": -1.8596992492675781,
      "logits/rejected": -2.7796380519866943,
      "logps/chosen": -132.63458251953125,
      "logps/rejected": -145.13230895996094,
      "loss": 0.0075,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8279004096984863,
      "rewards/margins": 6.076992034912109,
      "rewards/rejected": -2.249091386795044,
      "step": 1399
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.24943837523460388,
      "learning_rate": 8.134666666666666e-07,
      "logits/chosen": -2.1107797622680664,
      "logits/rejected": -3.063664436340332,
      "logps/chosen": -142.32766723632812,
      "logps/rejected": -195.04373168945312,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.243781328201294,
      "rewards/margins": 7.949974536895752,
      "rewards/rejected": -5.706192970275879,
      "step": 1400
    },
    {
      "epoch": 0.5604,
      "grad_norm": 0.06037570536136627,
      "learning_rate": 8.133333333333333e-07,
      "logits/chosen": -2.4821102619171143,
      "logits/rejected": -3.0928940773010254,
      "logps/chosen": -166.77293395996094,
      "logps/rejected": -148.46080017089844,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.34548807144165,
      "rewards/margins": 7.979382038116455,
      "rewards/rejected": -3.6338939666748047,
      "step": 1401
    },
    {
      "epoch": 0.5608,
      "grad_norm": 0.1963835209608078,
      "learning_rate": 8.132e-07,
      "logits/chosen": -2.440861225128174,
      "logits/rejected": -3.331449031829834,
      "logps/chosen": -113.3202133178711,
      "logps/rejected": -131.869384765625,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7533655166625977,
      "rewards/margins": 6.181339740753174,
      "rewards/rejected": -3.4279744625091553,
      "step": 1402
    },
    {
      "epoch": 0.5612,
      "grad_norm": 0.41276952624320984,
      "learning_rate": 8.130666666666667e-07,
      "logits/chosen": -2.069911479949951,
      "logits/rejected": -3.049759864807129,
      "logps/chosen": -102.7514877319336,
      "logps/rejected": -127.79585266113281,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.851311683654785,
      "rewards/margins": 6.112323760986328,
      "rewards/rejected": -3.261012077331543,
      "step": 1403
    },
    {
      "epoch": 0.5616,
      "grad_norm": 1.0714350938796997,
      "learning_rate": 8.129333333333333e-07,
      "logits/chosen": -2.548649787902832,
      "logits/rejected": -2.878201484680176,
      "logps/chosen": -103.06436157226562,
      "logps/rejected": -113.90949249267578,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7885184288024902,
      "rewards/margins": 7.1585164070129395,
      "rewards/rejected": -3.36999773979187,
      "step": 1404
    },
    {
      "epoch": 0.562,
      "grad_norm": 0.12366432696580887,
      "learning_rate": 8.128e-07,
      "logits/chosen": -2.4356515407562256,
      "logits/rejected": -2.1302151679992676,
      "logps/chosen": -115.99898529052734,
      "logps/rejected": -123.76464080810547,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.110992431640625,
      "rewards/margins": 6.718920707702637,
      "rewards/rejected": -3.60792875289917,
      "step": 1405
    },
    {
      "epoch": 0.5624,
      "grad_norm": 0.8873561024665833,
      "learning_rate": 8.126666666666666e-07,
      "logits/chosen": -2.1022350788116455,
      "logits/rejected": -2.7320199012756348,
      "logps/chosen": -82.03731536865234,
      "logps/rejected": -122.22348022460938,
      "loss": 0.007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0244879722595215,
      "rewards/margins": 5.3747687339782715,
      "rewards/rejected": -3.35028076171875,
      "step": 1406
    },
    {
      "epoch": 0.5628,
      "grad_norm": 0.165993332862854,
      "learning_rate": 8.125333333333333e-07,
      "logits/chosen": -2.1022136211395264,
      "logits/rejected": -2.8427114486694336,
      "logps/chosen": -131.35018920898438,
      "logps/rejected": -182.08709716796875,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8625895977020264,
      "rewards/margins": 6.701104164123535,
      "rewards/rejected": -3.838514804840088,
      "step": 1407
    },
    {
      "epoch": 0.5632,
      "grad_norm": 0.022947467863559723,
      "learning_rate": 8.123999999999999e-07,
      "logits/chosen": -2.569672107696533,
      "logits/rejected": -2.808469295501709,
      "logps/chosen": -123.01006317138672,
      "logps/rejected": -162.17379760742188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.401764869689941,
      "rewards/margins": 8.75935173034668,
      "rewards/rejected": -4.357586860656738,
      "step": 1408
    },
    {
      "epoch": 0.5636,
      "grad_norm": 30.425310134887695,
      "learning_rate": 8.122666666666666e-07,
      "logits/chosen": -2.2423088550567627,
      "logits/rejected": -2.263758659362793,
      "logps/chosen": -129.98696899414062,
      "logps/rejected": -114.80706024169922,
      "loss": 0.2016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1325943022966385,
      "rewards/margins": 2.6813695430755615,
      "rewards/rejected": -2.5487751960754395,
      "step": 1409
    },
    {
      "epoch": 0.564,
      "grad_norm": 0.1418197602033615,
      "learning_rate": 8.121333333333333e-07,
      "logits/chosen": -2.5181736946105957,
      "logits/rejected": -3.0138795375823975,
      "logps/chosen": -124.31654357910156,
      "logps/rejected": -137.4385986328125,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6284573078155518,
      "rewards/margins": 6.953444004058838,
      "rewards/rejected": -3.324986696243286,
      "step": 1410
    },
    {
      "epoch": 0.5644,
      "grad_norm": 0.12287309020757675,
      "learning_rate": 8.12e-07,
      "logits/chosen": -2.2452890872955322,
      "logits/rejected": -3.3128750324249268,
      "logps/chosen": -74.86231231689453,
      "logps/rejected": -142.83990478515625,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.10054612159729,
      "rewards/margins": 7.199059963226318,
      "rewards/rejected": -4.098513603210449,
      "step": 1411
    },
    {
      "epoch": 0.5648,
      "grad_norm": 0.009746219031512737,
      "learning_rate": 8.118666666666666e-07,
      "logits/chosen": -2.3849081993103027,
      "logits/rejected": -3.3089685440063477,
      "logps/chosen": -116.71521759033203,
      "logps/rejected": -162.02723693847656,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.017916202545166,
      "rewards/margins": 9.081097602844238,
      "rewards/rejected": -5.063181400299072,
      "step": 1412
    },
    {
      "epoch": 0.5652,
      "grad_norm": 1.4521028995513916,
      "learning_rate": 8.117333333333333e-07,
      "logits/chosen": -2.2124409675598145,
      "logits/rejected": -2.9437355995178223,
      "logps/chosen": -130.9766082763672,
      "logps/rejected": -157.53555297851562,
      "loss": 0.0103,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.934652328491211,
      "rewards/margins": 5.796454429626465,
      "rewards/rejected": -3.861802101135254,
      "step": 1413
    },
    {
      "epoch": 0.5656,
      "grad_norm": 0.2307768017053604,
      "learning_rate": 8.116e-07,
      "logits/chosen": -2.620824098587036,
      "logits/rejected": -3.042008638381958,
      "logps/chosen": -132.6708526611328,
      "logps/rejected": -156.22369384765625,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2399094104766846,
      "rewards/margins": 6.921675682067871,
      "rewards/rejected": -4.681766510009766,
      "step": 1414
    },
    {
      "epoch": 0.566,
      "grad_norm": 0.6399866342544556,
      "learning_rate": 8.114666666666667e-07,
      "logits/chosen": -2.370759963989258,
      "logits/rejected": -2.789923667907715,
      "logps/chosen": -136.47677612304688,
      "logps/rejected": -144.26145935058594,
      "loss": 0.0072,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4413719177246094,
      "rewards/margins": 5.151664733886719,
      "rewards/rejected": -3.710292339324951,
      "step": 1415
    },
    {
      "epoch": 0.5664,
      "grad_norm": 4.041889667510986,
      "learning_rate": 8.113333333333333e-07,
      "logits/chosen": -2.903606414794922,
      "logits/rejected": -3.4427428245544434,
      "logps/chosen": -168.0550079345703,
      "logps/rejected": -116.00105285644531,
      "loss": 0.0379,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8348149061203003,
      "rewards/margins": 4.989677429199219,
      "rewards/rejected": -3.154862403869629,
      "step": 1416
    },
    {
      "epoch": 0.5668,
      "grad_norm": 0.7177549004554749,
      "learning_rate": 8.112e-07,
      "logits/chosen": -2.408535957336426,
      "logits/rejected": -3.314708709716797,
      "logps/chosen": -79.31867980957031,
      "logps/rejected": -155.98526000976562,
      "loss": 0.0061,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6596755981445312,
      "rewards/margins": 6.44870138168335,
      "rewards/rejected": -3.7890255451202393,
      "step": 1417
    },
    {
      "epoch": 0.5672,
      "grad_norm": 1.2545392513275146,
      "learning_rate": 8.110666666666667e-07,
      "logits/chosen": -2.471045970916748,
      "logits/rejected": -2.9411253929138184,
      "logps/chosen": -117.83527374267578,
      "logps/rejected": -141.546875,
      "loss": 0.0092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.072779893875122,
      "rewards/margins": 5.737468719482422,
      "rewards/rejected": -3.6646885871887207,
      "step": 1418
    },
    {
      "epoch": 0.5676,
      "grad_norm": 0.08686299622058868,
      "learning_rate": 8.109333333333332e-07,
      "logits/chosen": -1.8181973695755005,
      "logits/rejected": -2.312307357788086,
      "logps/chosen": -70.2554931640625,
      "logps/rejected": -109.8953857421875,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2858188152313232,
      "rewards/margins": 6.8268723487854,
      "rewards/rejected": -3.541053295135498,
      "step": 1419
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.34345680475234985,
      "learning_rate": 8.107999999999999e-07,
      "logits/chosen": -1.6504366397857666,
      "logits/rejected": -2.3786067962646484,
      "logps/chosen": -110.55117797851562,
      "logps/rejected": -105.35038757324219,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8477375507354736,
      "rewards/margins": 5.900060176849365,
      "rewards/rejected": -3.0523228645324707,
      "step": 1420
    },
    {
      "epoch": 0.5684,
      "grad_norm": 1.0612998008728027,
      "learning_rate": 8.106666666666666e-07,
      "logits/chosen": -2.3805038928985596,
      "logits/rejected": -2.808913230895996,
      "logps/chosen": -140.8147735595703,
      "logps/rejected": -169.42446899414062,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.034045696258545,
      "rewards/margins": 4.932064056396484,
      "rewards/rejected": -2.8980178833007812,
      "step": 1421
    },
    {
      "epoch": 0.5688,
      "grad_norm": 0.1565454602241516,
      "learning_rate": 8.105333333333333e-07,
      "logits/chosen": -2.585771083831787,
      "logits/rejected": -2.9281504154205322,
      "logps/chosen": -136.53079223632812,
      "logps/rejected": -131.70965576171875,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7636306285858154,
      "rewards/margins": 6.238153457641602,
      "rewards/rejected": -4.474522590637207,
      "step": 1422
    },
    {
      "epoch": 0.5692,
      "grad_norm": 0.3850236237049103,
      "learning_rate": 8.104e-07,
      "logits/chosen": -2.1331546306610107,
      "logits/rejected": -2.783714532852173,
      "logps/chosen": -143.24090576171875,
      "logps/rejected": -160.90200805664062,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.55561900138855,
      "rewards/margins": 5.787209987640381,
      "rewards/rejected": -3.231590986251831,
      "step": 1423
    },
    {
      "epoch": 0.5696,
      "grad_norm": 1.1486936807632446,
      "learning_rate": 8.102666666666667e-07,
      "logits/chosen": -2.584484577178955,
      "logits/rejected": -3.621924877166748,
      "logps/chosen": -178.27732849121094,
      "logps/rejected": -130.43362426757812,
      "loss": 0.0108,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4243083000183105,
      "rewards/margins": 6.874740123748779,
      "rewards/rejected": -3.4504318237304688,
      "step": 1424
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.020536640658974648,
      "learning_rate": 8.101333333333334e-07,
      "logits/chosen": -2.4696712493896484,
      "logits/rejected": -2.7165074348449707,
      "logps/chosen": -114.12322235107422,
      "logps/rejected": -184.78848266601562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.415921211242676,
      "rewards/margins": 8.411701202392578,
      "rewards/rejected": -4.995779037475586,
      "step": 1425
    },
    {
      "epoch": 0.5704,
      "grad_norm": 0.8608390092849731,
      "learning_rate": 8.1e-07,
      "logits/chosen": -2.418928384780884,
      "logits/rejected": -3.424034595489502,
      "logps/chosen": -133.12246704101562,
      "logps/rejected": -146.70655822753906,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.220506429672241,
      "rewards/margins": 6.064222812652588,
      "rewards/rejected": -3.8437161445617676,
      "step": 1426
    },
    {
      "epoch": 0.5708,
      "grad_norm": 0.020473118871450424,
      "learning_rate": 8.098666666666666e-07,
      "logits/chosen": -2.28671932220459,
      "logits/rejected": -3.1506199836730957,
      "logps/chosen": -165.18121337890625,
      "logps/rejected": -159.1195068359375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.260343074798584,
      "rewards/margins": 8.582880973815918,
      "rewards/rejected": -4.322537422180176,
      "step": 1427
    },
    {
      "epoch": 0.5712,
      "grad_norm": 0.46394675970077515,
      "learning_rate": 8.097333333333333e-07,
      "logits/chosen": -2.0790064334869385,
      "logits/rejected": -3.1746695041656494,
      "logps/chosen": -152.03802490234375,
      "logps/rejected": -219.97361755371094,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1704063415527344,
      "rewards/margins": 5.907146453857422,
      "rewards/rejected": -3.7367396354675293,
      "step": 1428
    },
    {
      "epoch": 0.5716,
      "grad_norm": 3.702688694000244,
      "learning_rate": 8.095999999999999e-07,
      "logits/chosen": -2.544482707977295,
      "logits/rejected": -3.164294958114624,
      "logps/chosen": -140.77957153320312,
      "logps/rejected": -145.7736053466797,
      "loss": 0.0326,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0077636241912842,
      "rewards/margins": 3.686836004257202,
      "rewards/rejected": -4.694599628448486,
      "step": 1429
    },
    {
      "epoch": 0.572,
      "grad_norm": 0.14396759867668152,
      "learning_rate": 8.094666666666666e-07,
      "logits/chosen": -2.2745282649993896,
      "logits/rejected": -2.750945568084717,
      "logps/chosen": -98.32865905761719,
      "logps/rejected": -120.48497772216797,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.098345994949341,
      "rewards/margins": 6.412298202514648,
      "rewards/rejected": -4.3139519691467285,
      "step": 1430
    },
    {
      "epoch": 0.5724,
      "grad_norm": 0.2511109411716461,
      "learning_rate": 8.093333333333333e-07,
      "logits/chosen": -2.3597874641418457,
      "logits/rejected": -2.760014295578003,
      "logps/chosen": -156.64273071289062,
      "logps/rejected": -105.6834716796875,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7073020935058594,
      "rewards/margins": 6.100115776062012,
      "rewards/rejected": -3.3928136825561523,
      "step": 1431
    },
    {
      "epoch": 0.5728,
      "grad_norm": 1.540626049041748,
      "learning_rate": 8.092e-07,
      "logits/chosen": -2.09210467338562,
      "logits/rejected": -3.0713682174682617,
      "logps/chosen": -109.13885498046875,
      "logps/rejected": -145.48391723632812,
      "loss": 0.012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8557018041610718,
      "rewards/margins": 5.19179630279541,
      "rewards/rejected": -3.336094856262207,
      "step": 1432
    },
    {
      "epoch": 0.5732,
      "grad_norm": 0.7031272053718567,
      "learning_rate": 8.090666666666667e-07,
      "logits/chosen": -2.2283453941345215,
      "logits/rejected": -3.4604339599609375,
      "logps/chosen": -167.51278686523438,
      "logps/rejected": -200.93765258789062,
      "loss": 0.0064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2240066528320312,
      "rewards/margins": 5.830786228179932,
      "rewards/rejected": -4.6067795753479,
      "step": 1433
    },
    {
      "epoch": 0.5736,
      "grad_norm": 0.44514307379722595,
      "learning_rate": 8.089333333333333e-07,
      "logits/chosen": -1.8581721782684326,
      "logits/rejected": -2.1653709411621094,
      "logps/chosen": -122.38770294189453,
      "logps/rejected": -129.61770629882812,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.147916793823242,
      "rewards/margins": 5.325597286224365,
      "rewards/rejected": -2.177680730819702,
      "step": 1434
    },
    {
      "epoch": 0.574,
      "grad_norm": 0.8002324104309082,
      "learning_rate": 8.087999999999999e-07,
      "logits/chosen": -2.1934807300567627,
      "logits/rejected": -3.5208559036254883,
      "logps/chosen": -83.32239532470703,
      "logps/rejected": -144.64163208007812,
      "loss": 0.0064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1091949939727783,
      "rewards/margins": 5.8018927574157715,
      "rewards/rejected": -3.692697525024414,
      "step": 1435
    },
    {
      "epoch": 0.5744,
      "grad_norm": 0.04721732437610626,
      "learning_rate": 8.086666666666666e-07,
      "logits/chosen": -2.204834222793579,
      "logits/rejected": -2.990945339202881,
      "logps/chosen": -114.1139144897461,
      "logps/rejected": -156.73675537109375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8744277954101562,
      "rewards/margins": 7.931584358215332,
      "rewards/rejected": -4.057156562805176,
      "step": 1436
    },
    {
      "epoch": 0.5748,
      "grad_norm": 0.015235322527587414,
      "learning_rate": 8.085333333333333e-07,
      "logits/chosen": -2.0979456901550293,
      "logits/rejected": -2.744560718536377,
      "logps/chosen": -103.54415893554688,
      "logps/rejected": -166.68017578125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7884552478790283,
      "rewards/margins": 8.635028839111328,
      "rewards/rejected": -4.846573829650879,
      "step": 1437
    },
    {
      "epoch": 0.5752,
      "grad_norm": 0.0670328438282013,
      "learning_rate": 8.084e-07,
      "logits/chosen": -2.4459598064422607,
      "logits/rejected": -2.838188886642456,
      "logps/chosen": -125.88882446289062,
      "logps/rejected": -164.45494079589844,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.087299823760986,
      "rewards/margins": 7.340952396392822,
      "rewards/rejected": -3.2536520957946777,
      "step": 1438
    },
    {
      "epoch": 0.5756,
      "grad_norm": 1.3871337175369263,
      "learning_rate": 8.082666666666667e-07,
      "logits/chosen": -2.0879008769989014,
      "logits/rejected": -2.4958560466766357,
      "logps/chosen": -130.92401123046875,
      "logps/rejected": -171.68753051757812,
      "loss": 0.0169,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.701803684234619,
      "rewards/margins": 4.593260765075684,
      "rewards/rejected": -1.8914573192596436,
      "step": 1439
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.41663023829460144,
      "learning_rate": 8.081333333333333e-07,
      "logits/chosen": -2.0638961791992188,
      "logits/rejected": -2.894864082336426,
      "logps/chosen": -71.99911499023438,
      "logps/rejected": -118.76962280273438,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.18636417388916,
      "rewards/margins": 6.181209564208984,
      "rewards/rejected": -2.994845390319824,
      "step": 1440
    },
    {
      "epoch": 0.5764,
      "grad_norm": 0.25500017404556274,
      "learning_rate": 8.08e-07,
      "logits/chosen": -2.4917163848876953,
      "logits/rejected": -2.980083465576172,
      "logps/chosen": -97.83539581298828,
      "logps/rejected": -172.39390563964844,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5915658473968506,
      "rewards/margins": 7.757344722747803,
      "rewards/rejected": -5.165779113769531,
      "step": 1441
    },
    {
      "epoch": 0.5768,
      "grad_norm": 0.24428454041481018,
      "learning_rate": 8.078666666666666e-07,
      "logits/chosen": -2.4383740425109863,
      "logits/rejected": -3.2380130290985107,
      "logps/chosen": -127.57970428466797,
      "logps/rejected": -125.53582000732422,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8320512771606445,
      "rewards/margins": 6.950620174407959,
      "rewards/rejected": -4.118569374084473,
      "step": 1442
    },
    {
      "epoch": 0.5772,
      "grad_norm": 0.2631043493747711,
      "learning_rate": 8.077333333333333e-07,
      "logits/chosen": -2.419729232788086,
      "logits/rejected": -3.4337453842163086,
      "logps/chosen": -128.61056518554688,
      "logps/rejected": -150.41612243652344,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6517159938812256,
      "rewards/margins": 7.463291645050049,
      "rewards/rejected": -4.811575412750244,
      "step": 1443
    },
    {
      "epoch": 0.5776,
      "grad_norm": 0.6884620189666748,
      "learning_rate": 8.075999999999999e-07,
      "logits/chosen": -2.1739187240600586,
      "logits/rejected": -2.7721729278564453,
      "logps/chosen": -86.99357604980469,
      "logps/rejected": -109.616943359375,
      "loss": 0.0097,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0581204891204834,
      "rewards/margins": 4.940797805786133,
      "rewards/rejected": -2.8826777935028076,
      "step": 1444
    },
    {
      "epoch": 0.578,
      "grad_norm": 2.327791213989258,
      "learning_rate": 8.074666666666666e-07,
      "logits/chosen": -2.1844372749328613,
      "logits/rejected": -2.6933178901672363,
      "logps/chosen": -142.98538208007812,
      "logps/rejected": -103.43428802490234,
      "loss": 0.0313,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5710220336914062,
      "rewards/margins": 3.6415300369262695,
      "rewards/rejected": -3.0705080032348633,
      "step": 1445
    },
    {
      "epoch": 0.5784,
      "grad_norm": 0.15849971771240234,
      "learning_rate": 8.073333333333333e-07,
      "logits/chosen": -1.9882781505584717,
      "logits/rejected": -2.9735798835754395,
      "logps/chosen": -84.68745422363281,
      "logps/rejected": -126.0217056274414,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2863075733184814,
      "rewards/margins": 7.036451816558838,
      "rewards/rejected": -3.7501444816589355,
      "step": 1446
    },
    {
      "epoch": 0.5788,
      "grad_norm": 0.9490106105804443,
      "learning_rate": 8.072e-07,
      "logits/chosen": -2.494473457336426,
      "logits/rejected": -3.0023353099823,
      "logps/chosen": -125.43944549560547,
      "logps/rejected": -126.60884094238281,
      "loss": 0.0103,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3504250049591064,
      "rewards/margins": 4.629581451416016,
      "rewards/rejected": -3.27915620803833,
      "step": 1447
    },
    {
      "epoch": 0.5792,
      "grad_norm": 3.509965419769287,
      "learning_rate": 8.070666666666667e-07,
      "logits/chosen": -1.8351953029632568,
      "logits/rejected": -2.3844079971313477,
      "logps/chosen": -118.59474182128906,
      "logps/rejected": -111.81045532226562,
      "loss": 0.0225,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4364070892333984,
      "rewards/margins": 5.648932456970215,
      "rewards/rejected": -3.2125253677368164,
      "step": 1448
    },
    {
      "epoch": 0.5796,
      "grad_norm": 0.07240763306617737,
      "learning_rate": 8.069333333333333e-07,
      "logits/chosen": -2.4602713584899902,
      "logits/rejected": -2.8980250358581543,
      "logps/chosen": -142.47509765625,
      "logps/rejected": -139.17318725585938,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8109054565429688,
      "rewards/margins": 8.160367012023926,
      "rewards/rejected": -4.349461555480957,
      "step": 1449
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.06312092393636703,
      "learning_rate": 8.067999999999999e-07,
      "logits/chosen": -2.271472454071045,
      "logits/rejected": -3.2108922004699707,
      "logps/chosen": -207.97091674804688,
      "logps/rejected": -175.01388549804688,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6881890296936035,
      "rewards/margins": 7.850480079650879,
      "rewards/rejected": -6.162291526794434,
      "step": 1450
    },
    {
      "epoch": 0.5804,
      "grad_norm": 2.083397388458252,
      "learning_rate": 8.066666666666666e-07,
      "logits/chosen": -2.4848742485046387,
      "logits/rejected": -3.135239601135254,
      "logps/chosen": -100.35978698730469,
      "logps/rejected": -129.2379150390625,
      "loss": 0.0231,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8924083709716797,
      "rewards/margins": 4.504242897033691,
      "rewards/rejected": -3.6118342876434326,
      "step": 1451
    },
    {
      "epoch": 0.5808,
      "grad_norm": 3.7200446128845215,
      "learning_rate": 8.065333333333333e-07,
      "logits/chosen": -2.668041229248047,
      "logits/rejected": -2.530031681060791,
      "logps/chosen": -229.1495819091797,
      "logps/rejected": -136.1616973876953,
      "loss": 0.0262,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7333152294158936,
      "rewards/margins": 5.122823715209961,
      "rewards/rejected": -3.3895084857940674,
      "step": 1452
    },
    {
      "epoch": 0.5812,
      "grad_norm": 1.0949172973632812,
      "learning_rate": 8.064e-07,
      "logits/chosen": -2.624824047088623,
      "logits/rejected": -2.6960887908935547,
      "logps/chosen": -229.97085571289062,
      "logps/rejected": -143.014892578125,
      "loss": 0.0115,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.714514970779419,
      "rewards/margins": 4.730788707733154,
      "rewards/rejected": -2.0162734985351562,
      "step": 1453
    },
    {
      "epoch": 0.5816,
      "grad_norm": 0.7888593673706055,
      "learning_rate": 8.062666666666666e-07,
      "logits/chosen": -2.077165126800537,
      "logits/rejected": -3.434432029724121,
      "logps/chosen": -90.43135833740234,
      "logps/rejected": -151.18467712402344,
      "loss": 0.0092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3399059474468231,
      "rewards/margins": 4.752970218658447,
      "rewards/rejected": -5.092876434326172,
      "step": 1454
    },
    {
      "epoch": 0.582,
      "grad_norm": 0.24284550547599792,
      "learning_rate": 8.061333333333333e-07,
      "logits/chosen": -2.373811721801758,
      "logits/rejected": -3.5254006385803223,
      "logps/chosen": -141.43605041503906,
      "logps/rejected": -167.51145935058594,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7078800201416016,
      "rewards/margins": 6.518720626831055,
      "rewards/rejected": -2.810840606689453,
      "step": 1455
    },
    {
      "epoch": 0.5824,
      "grad_norm": 0.05921309441328049,
      "learning_rate": 8.06e-07,
      "logits/chosen": -1.9769376516342163,
      "logits/rejected": -3.1807188987731934,
      "logps/chosen": -133.215576171875,
      "logps/rejected": -155.664794921875,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8439559936523438,
      "rewards/margins": 8.517232894897461,
      "rewards/rejected": -4.673276901245117,
      "step": 1456
    },
    {
      "epoch": 0.5828,
      "grad_norm": 1.7392709255218506,
      "learning_rate": 8.058666666666666e-07,
      "logits/chosen": -2.2625842094421387,
      "logits/rejected": -2.81691837310791,
      "logps/chosen": -137.76983642578125,
      "logps/rejected": -130.4996337890625,
      "loss": 0.0186,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7421700954437256,
      "rewards/margins": 5.599038124084473,
      "rewards/rejected": -3.856867790222168,
      "step": 1457
    },
    {
      "epoch": 0.5832,
      "grad_norm": 0.2482825368642807,
      "learning_rate": 8.057333333333333e-07,
      "logits/chosen": -1.872104287147522,
      "logits/rejected": -3.0136473178863525,
      "logps/chosen": -108.71188354492188,
      "logps/rejected": -136.3902587890625,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4539059400558472,
      "rewards/margins": 6.454010963439941,
      "rewards/rejected": -5.000104904174805,
      "step": 1458
    },
    {
      "epoch": 0.5836,
      "grad_norm": 0.71074378490448,
      "learning_rate": 8.056e-07,
      "logits/chosen": -2.547703742980957,
      "logits/rejected": -2.8918776512145996,
      "logps/chosen": -140.4224090576172,
      "logps/rejected": -154.44712829589844,
      "loss": 0.0062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2925498485565186,
      "rewards/margins": 7.105434417724609,
      "rewards/rejected": -4.812884330749512,
      "step": 1459
    },
    {
      "epoch": 0.584,
      "grad_norm": 0.3468582332134247,
      "learning_rate": 8.054666666666667e-07,
      "logits/chosen": -1.969536304473877,
      "logits/rejected": -3.3033857345581055,
      "logps/chosen": -78.61708068847656,
      "logps/rejected": -127.6502685546875,
      "loss": 0.005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2929630279541016,
      "rewards/margins": 5.677745342254639,
      "rewards/rejected": -3.384782314300537,
      "step": 1460
    },
    {
      "epoch": 0.5844,
      "grad_norm": 0.15899530053138733,
      "learning_rate": 8.053333333333333e-07,
      "logits/chosen": -2.380575656890869,
      "logits/rejected": -2.5824570655822754,
      "logps/chosen": -110.49059295654297,
      "logps/rejected": -106.27642822265625,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.363827705383301,
      "rewards/margins": 6.803566932678223,
      "rewards/rejected": -3.439739227294922,
      "step": 1461
    },
    {
      "epoch": 0.5848,
      "grad_norm": 0.9498111009597778,
      "learning_rate": 8.052e-07,
      "logits/chosen": -2.6074934005737305,
      "logits/rejected": -3.1734459400177,
      "logps/chosen": -192.62060546875,
      "logps/rejected": -214.81768798828125,
      "loss": 0.0082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.324942111968994,
      "rewards/margins": 5.711398601531982,
      "rewards/rejected": -3.3864564895629883,
      "step": 1462
    },
    {
      "epoch": 0.5852,
      "grad_norm": 0.19546036422252655,
      "learning_rate": 8.050666666666666e-07,
      "logits/chosen": -2.5171337127685547,
      "logits/rejected": -2.7555735111236572,
      "logps/chosen": -118.43854522705078,
      "logps/rejected": -145.03366088867188,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3465957641601562,
      "rewards/margins": 6.744515419006348,
      "rewards/rejected": -3.3979196548461914,
      "step": 1463
    },
    {
      "epoch": 0.5856,
      "grad_norm": 0.028441213071346283,
      "learning_rate": 8.049333333333332e-07,
      "logits/chosen": -2.505469799041748,
      "logits/rejected": -3.0077667236328125,
      "logps/chosen": -103.76396179199219,
      "logps/rejected": -162.44183349609375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3517372608184814,
      "rewards/margins": 8.119405746459961,
      "rewards/rejected": -4.767668724060059,
      "step": 1464
    },
    {
      "epoch": 0.586,
      "grad_norm": 0.5257797241210938,
      "learning_rate": 8.047999999999999e-07,
      "logits/chosen": -1.7976984977722168,
      "logits/rejected": -1.6997497081756592,
      "logps/chosen": -74.68382263183594,
      "logps/rejected": -92.28651428222656,
      "loss": 0.0064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7902560234069824,
      "rewards/margins": 5.103218078613281,
      "rewards/rejected": -2.312962055206299,
      "step": 1465
    },
    {
      "epoch": 0.5864,
      "grad_norm": 0.06253549456596375,
      "learning_rate": 8.046666666666666e-07,
      "logits/chosen": -2.0450639724731445,
      "logits/rejected": -2.4375221729278564,
      "logps/chosen": -109.87469482421875,
      "logps/rejected": -127.46501159667969,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0669612884521484,
      "rewards/margins": 7.144220352172852,
      "rewards/rejected": -4.077259540557861,
      "step": 1466
    },
    {
      "epoch": 0.5868,
      "grad_norm": 0.18602199852466583,
      "learning_rate": 8.045333333333333e-07,
      "logits/chosen": -1.998112678527832,
      "logits/rejected": -3.061596393585205,
      "logps/chosen": -69.14292907714844,
      "logps/rejected": -125.61817169189453,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.112602710723877,
      "rewards/margins": 6.051634311676025,
      "rewards/rejected": -3.9390316009521484,
      "step": 1467
    },
    {
      "epoch": 0.5872,
      "grad_norm": 0.1346173882484436,
      "learning_rate": 8.044e-07,
      "logits/chosen": -1.9650132656097412,
      "logits/rejected": -3.2007691860198975,
      "logps/chosen": -64.59576416015625,
      "logps/rejected": -127.43424987792969,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9866620302200317,
      "rewards/margins": 6.136902809143066,
      "rewards/rejected": -4.150240898132324,
      "step": 1468
    },
    {
      "epoch": 0.5876,
      "grad_norm": 1.3260730504989624,
      "learning_rate": 8.042666666666667e-07,
      "logits/chosen": -2.487698554992676,
      "logits/rejected": -3.578169345855713,
      "logps/chosen": -193.73995971679688,
      "logps/rejected": -108.97579956054688,
      "loss": 0.0138,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.238314151763916,
      "rewards/margins": 4.507101058959961,
      "rewards/rejected": -2.268786668777466,
      "step": 1469
    },
    {
      "epoch": 0.588,
      "grad_norm": 0.9564722776412964,
      "learning_rate": 8.041333333333334e-07,
      "logits/chosen": -2.3227972984313965,
      "logits/rejected": -3.496717929840088,
      "logps/chosen": -98.38040161132812,
      "logps/rejected": -147.26742553710938,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9670257568359375,
      "rewards/margins": 5.685808181762695,
      "rewards/rejected": -4.718782424926758,
      "step": 1470
    },
    {
      "epoch": 0.5884,
      "grad_norm": 1.105922818183899,
      "learning_rate": 8.04e-07,
      "logits/chosen": -3.010284900665283,
      "logits/rejected": -3.511028289794922,
      "logps/chosen": -300.1108093261719,
      "logps/rejected": -168.0399169921875,
      "loss": 0.0074,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8872292041778564,
      "rewards/margins": 6.452001571655273,
      "rewards/rejected": -4.564772129058838,
      "step": 1471
    },
    {
      "epoch": 0.5888,
      "grad_norm": 0.010532877407968044,
      "learning_rate": 8.038666666666665e-07,
      "logits/chosen": -2.284883975982666,
      "logits/rejected": -3.3580074310302734,
      "logps/chosen": -111.93983459472656,
      "logps/rejected": -154.15298461914062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.377716541290283,
      "rewards/margins": 9.02884292602539,
      "rewards/rejected": -4.651126861572266,
      "step": 1472
    },
    {
      "epoch": 0.5892,
      "grad_norm": 0.693286657333374,
      "learning_rate": 8.037333333333332e-07,
      "logits/chosen": -2.2581124305725098,
      "logits/rejected": -2.2767856121063232,
      "logps/chosen": -114.9168701171875,
      "logps/rejected": -111.84442901611328,
      "loss": 0.005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4166059494018555,
      "rewards/margins": 5.877175331115723,
      "rewards/rejected": -2.460569381713867,
      "step": 1473
    },
    {
      "epoch": 0.5896,
      "grad_norm": 2.4350929260253906,
      "learning_rate": 8.035999999999999e-07,
      "logits/chosen": -2.4578020572662354,
      "logits/rejected": -2.6873443126678467,
      "logps/chosen": -141.9727325439453,
      "logps/rejected": -151.68821716308594,
      "loss": 0.0264,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1567203998565674,
      "rewards/margins": 4.352604866027832,
      "rewards/rejected": -3.1958842277526855,
      "step": 1474
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.986609697341919,
      "learning_rate": 8.034666666666666e-07,
      "logits/chosen": -2.5642800331115723,
      "logits/rejected": -2.610184669494629,
      "logps/chosen": -100.65420532226562,
      "logps/rejected": -108.35789489746094,
      "loss": 0.0368,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38618773221969604,
      "rewards/margins": 4.109541893005371,
      "rewards/rejected": -3.7233543395996094,
      "step": 1475
    },
    {
      "epoch": 0.5904,
      "grad_norm": 0.5255550146102905,
      "learning_rate": 8.033333333333333e-07,
      "logits/chosen": -2.623591661453247,
      "logits/rejected": -2.9361977577209473,
      "logps/chosen": -178.17344665527344,
      "logps/rejected": -146.3112335205078,
      "loss": 0.0068,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9402153491973877,
      "rewards/margins": 7.128429412841797,
      "rewards/rejected": -5.18821382522583,
      "step": 1476
    },
    {
      "epoch": 0.5908,
      "grad_norm": 0.812605619430542,
      "learning_rate": 8.032e-07,
      "logits/chosen": -1.5834338665008545,
      "logits/rejected": -2.6932504177093506,
      "logps/chosen": -88.59780883789062,
      "logps/rejected": -110.61004638671875,
      "loss": 0.0097,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6020350456237793,
      "rewards/margins": 4.650925636291504,
      "rewards/rejected": -3.0488905906677246,
      "step": 1477
    },
    {
      "epoch": 0.5912,
      "grad_norm": 3.3006362915039062,
      "learning_rate": 8.030666666666667e-07,
      "logits/chosen": -2.5249786376953125,
      "logits/rejected": -2.5799918174743652,
      "logps/chosen": -136.8280792236328,
      "logps/rejected": -132.0389404296875,
      "loss": 0.0319,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8011718988418579,
      "rewards/margins": 4.069931983947754,
      "rewards/rejected": -3.2687602043151855,
      "step": 1478
    },
    {
      "epoch": 0.5916,
      "grad_norm": 0.3716278672218323,
      "learning_rate": 8.029333333333334e-07,
      "logits/chosen": -2.376903772354126,
      "logits/rejected": -2.9591004848480225,
      "logps/chosen": -116.14147186279297,
      "logps/rejected": -213.92654418945312,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2876782417297363,
      "rewards/margins": 8.374687194824219,
      "rewards/rejected": -5.087008476257324,
      "step": 1479
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.7180634140968323,
      "learning_rate": 8.028e-07,
      "logits/chosen": -2.021841049194336,
      "logits/rejected": -3.1689987182617188,
      "logps/chosen": -78.91912841796875,
      "logps/rejected": -131.85873413085938,
      "loss": 0.0071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3065173625946045,
      "rewards/margins": 5.866982460021973,
      "rewards/rejected": -3.5604653358459473,
      "step": 1480
    },
    {
      "epoch": 0.5924,
      "grad_norm": 0.8898426294326782,
      "learning_rate": 8.026666666666667e-07,
      "logits/chosen": -2.3517303466796875,
      "logits/rejected": -3.3495941162109375,
      "logps/chosen": -114.11119079589844,
      "logps/rejected": -136.10830688476562,
      "loss": 0.0094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.107487201690674,
      "rewards/margins": 7.002821445465088,
      "rewards/rejected": -3.895334005355835,
      "step": 1481
    },
    {
      "epoch": 0.5928,
      "grad_norm": 0.046031493693590164,
      "learning_rate": 8.025333333333332e-07,
      "logits/chosen": -2.5622658729553223,
      "logits/rejected": -3.425830841064453,
      "logps/chosen": -144.1149139404297,
      "logps/rejected": -172.93356323242188,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1274075508117676,
      "rewards/margins": 8.412914276123047,
      "rewards/rejected": -5.2855072021484375,
      "step": 1482
    },
    {
      "epoch": 0.5932,
      "grad_norm": 0.22632066905498505,
      "learning_rate": 8.023999999999999e-07,
      "logits/chosen": -1.9878671169281006,
      "logits/rejected": -3.0679359436035156,
      "logps/chosen": -120.2923583984375,
      "logps/rejected": -152.70855712890625,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.458059310913086,
      "rewards/margins": 6.589698791503906,
      "rewards/rejected": -4.1316399574279785,
      "step": 1483
    },
    {
      "epoch": 0.5936,
      "grad_norm": 0.08215666562318802,
      "learning_rate": 8.022666666666666e-07,
      "logits/chosen": -1.9668569564819336,
      "logits/rejected": -3.4383015632629395,
      "logps/chosen": -80.34062194824219,
      "logps/rejected": -139.5098419189453,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.257984161376953,
      "rewards/margins": 8.39072322845459,
      "rewards/rejected": -4.1327385902404785,
      "step": 1484
    },
    {
      "epoch": 0.594,
      "grad_norm": 0.8670967817306519,
      "learning_rate": 8.021333333333333e-07,
      "logits/chosen": -2.0107767581939697,
      "logits/rejected": -2.8926939964294434,
      "logps/chosen": -113.2335433959961,
      "logps/rejected": -142.02679443359375,
      "loss": 0.0131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.543098211288452,
      "rewards/margins": 5.4193806648254395,
      "rewards/rejected": -2.8762826919555664,
      "step": 1485
    },
    {
      "epoch": 0.5944,
      "grad_norm": 1.5152865648269653,
      "learning_rate": 8.02e-07,
      "logits/chosen": -2.7841858863830566,
      "logits/rejected": -2.476029872894287,
      "logps/chosen": -145.2806396484375,
      "logps/rejected": -116.08213806152344,
      "loss": 0.016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.127955675125122,
      "rewards/margins": 6.219552993774414,
      "rewards/rejected": -3.091597080230713,
      "step": 1486
    },
    {
      "epoch": 0.5948,
      "grad_norm": 0.11296942085027695,
      "learning_rate": 8.018666666666666e-07,
      "logits/chosen": -2.650925636291504,
      "logits/rejected": -2.7273740768432617,
      "logps/chosen": -111.28141784667969,
      "logps/rejected": -127.98637390136719,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.547696113586426,
      "rewards/margins": 7.385541915893555,
      "rewards/rejected": -3.837845802307129,
      "step": 1487
    },
    {
      "epoch": 0.5952,
      "grad_norm": 0.16481101512908936,
      "learning_rate": 8.017333333333333e-07,
      "logits/chosen": -2.3738667964935303,
      "logits/rejected": -3.401392936706543,
      "logps/chosen": -91.08158874511719,
      "logps/rejected": -161.40676879882812,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7146965265274048,
      "rewards/margins": 7.725730895996094,
      "rewards/rejected": -6.01103401184082,
      "step": 1488
    },
    {
      "epoch": 0.5956,
      "grad_norm": 0.5443803071975708,
      "learning_rate": 8.016e-07,
      "logits/chosen": -1.8986157178878784,
      "logits/rejected": -2.8112947940826416,
      "logps/chosen": -142.75997924804688,
      "logps/rejected": -136.36505126953125,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.958078384399414,
      "rewards/margins": 5.829462051391602,
      "rewards/rejected": -3.8713834285736084,
      "step": 1489
    },
    {
      "epoch": 0.596,
      "grad_norm": 0.1748451590538025,
      "learning_rate": 8.014666666666667e-07,
      "logits/chosen": -2.341381072998047,
      "logits/rejected": -3.3917112350463867,
      "logps/chosen": -178.42884826660156,
      "logps/rejected": -157.84341430664062,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6296448707580566,
      "rewards/margins": 7.147287845611572,
      "rewards/rejected": -4.517642974853516,
      "step": 1490
    },
    {
      "epoch": 0.5964,
      "grad_norm": 0.2402382493019104,
      "learning_rate": 8.013333333333333e-07,
      "logits/chosen": -2.2556309700012207,
      "logits/rejected": -3.088392734527588,
      "logps/chosen": -149.8101806640625,
      "logps/rejected": -140.04034423828125,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.007254123687744,
      "rewards/margins": 6.429914474487305,
      "rewards/rejected": -3.4226601123809814,
      "step": 1491
    },
    {
      "epoch": 0.5968,
      "grad_norm": 0.6315672397613525,
      "learning_rate": 8.012e-07,
      "logits/chosen": -2.636082649230957,
      "logits/rejected": -3.3587889671325684,
      "logps/chosen": -70.73580932617188,
      "logps/rejected": -135.4864959716797,
      "loss": 0.0088,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5639885663986206,
      "rewards/margins": 4.903811931610107,
      "rewards/rejected": -3.3398232460021973,
      "step": 1492
    },
    {
      "epoch": 0.5972,
      "grad_norm": 0.7656000256538391,
      "learning_rate": 8.010666666666666e-07,
      "logits/chosen": -1.7592661380767822,
      "logits/rejected": -2.121061086654663,
      "logps/chosen": -96.78163146972656,
      "logps/rejected": -96.50973510742188,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.716141700744629,
      "rewards/margins": 5.337562561035156,
      "rewards/rejected": -2.6214210987091064,
      "step": 1493
    },
    {
      "epoch": 0.5976,
      "grad_norm": 0.9404783844947815,
      "learning_rate": 8.009333333333333e-07,
      "logits/chosen": -2.4326462745666504,
      "logits/rejected": -3.152350664138794,
      "logps/chosen": -113.47028350830078,
      "logps/rejected": -119.69042205810547,
      "loss": 0.0161,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7669914960861206,
      "rewards/margins": 4.122465133666992,
      "rewards/rejected": -3.355473518371582,
      "step": 1494
    },
    {
      "epoch": 0.598,
      "grad_norm": 0.14317114651203156,
      "learning_rate": 8.007999999999999e-07,
      "logits/chosen": -2.325611114501953,
      "logits/rejected": -2.40767502784729,
      "logps/chosen": -96.22843933105469,
      "logps/rejected": -164.82801818847656,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9934582710266113,
      "rewards/margins": 6.924204349517822,
      "rewards/rejected": -3.930746555328369,
      "step": 1495
    },
    {
      "epoch": 0.5984,
      "grad_norm": 0.10862676799297333,
      "learning_rate": 8.006666666666666e-07,
      "logits/chosen": -1.9279588460922241,
      "logits/rejected": -2.7845633029937744,
      "logps/chosen": -90.39739990234375,
      "logps/rejected": -97.3083267211914,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.408052921295166,
      "rewards/margins": 6.757503986358643,
      "rewards/rejected": -3.3494510650634766,
      "step": 1496
    },
    {
      "epoch": 0.5988,
      "grad_norm": 10.994245529174805,
      "learning_rate": 8.005333333333333e-07,
      "logits/chosen": -2.3812673091888428,
      "logits/rejected": -3.012450695037842,
      "logps/chosen": -92.04023742675781,
      "logps/rejected": -125.92884826660156,
      "loss": 0.1201,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6172165870666504,
      "rewards/margins": 3.902728796005249,
      "rewards/rejected": -2.2855122089385986,
      "step": 1497
    },
    {
      "epoch": 0.5992,
      "grad_norm": 1.79697585105896,
      "learning_rate": 8.004e-07,
      "logits/chosen": -2.2560904026031494,
      "logits/rejected": -2.93792724609375,
      "logps/chosen": -153.01339721679688,
      "logps/rejected": -124.2825927734375,
      "loss": 0.0185,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9817123413085938,
      "rewards/margins": 4.519020080566406,
      "rewards/rejected": -3.5373077392578125,
      "step": 1498
    },
    {
      "epoch": 0.5996,
      "grad_norm": 0.7314362525939941,
      "learning_rate": 8.002666666666667e-07,
      "logits/chosen": -2.724212408065796,
      "logits/rejected": -2.799896717071533,
      "logps/chosen": -123.97003173828125,
      "logps/rejected": -133.94107055664062,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.39078688621521,
      "rewards/margins": 5.830481052398682,
      "rewards/rejected": -3.439694404602051,
      "step": 1499
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.040768858045339584,
      "learning_rate": 8.001333333333334e-07,
      "logits/chosen": -2.3448472023010254,
      "logits/rejected": -3.6931257247924805,
      "logps/chosen": -104.85884857177734,
      "logps/rejected": -148.01412963867188,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8513827323913574,
      "rewards/margins": 7.584356784820557,
      "rewards/rejected": -3.732974052429199,
      "step": 1500
    },
    {
      "epoch": 0.6004,
      "grad_norm": 2.050213575363159,
      "learning_rate": 8e-07,
      "logits/chosen": -1.9122645854949951,
      "logits/rejected": -2.9843122959136963,
      "logps/chosen": -114.20175170898438,
      "logps/rejected": -136.84371948242188,
      "loss": 0.022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1695812940597534,
      "rewards/margins": 4.332303047180176,
      "rewards/rejected": -3.162722110748291,
      "step": 1501
    },
    {
      "epoch": 0.6008,
      "grad_norm": 0.24245156347751617,
      "learning_rate": 7.998666666666665e-07,
      "logits/chosen": -2.3558554649353027,
      "logits/rejected": -3.025040626525879,
      "logps/chosen": -124.45036315917969,
      "logps/rejected": -160.33956909179688,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0925137996673584,
      "rewards/margins": 7.377338409423828,
      "rewards/rejected": -4.284824848175049,
      "step": 1502
    },
    {
      "epoch": 0.6012,
      "grad_norm": 0.15940341353416443,
      "learning_rate": 7.997333333333332e-07,
      "logits/chosen": -2.30430269241333,
      "logits/rejected": -3.474785804748535,
      "logps/chosen": -81.76558685302734,
      "logps/rejected": -152.5533447265625,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2428562641143799,
      "rewards/margins": 6.290988922119141,
      "rewards/rejected": -5.04813289642334,
      "step": 1503
    },
    {
      "epoch": 0.6016,
      "grad_norm": 0.054867956787347794,
      "learning_rate": 7.995999999999999e-07,
      "logits/chosen": -2.0936930179595947,
      "logits/rejected": -2.636770725250244,
      "logps/chosen": -117.81547546386719,
      "logps/rejected": -147.1496124267578,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5756373405456543,
      "rewards/margins": 7.4491801261901855,
      "rewards/rejected": -3.8735427856445312,
      "step": 1504
    },
    {
      "epoch": 0.602,
      "grad_norm": 0.8060466647148132,
      "learning_rate": 7.994666666666666e-07,
      "logits/chosen": -2.3280892372131348,
      "logits/rejected": -2.729287624359131,
      "logps/chosen": -181.63116455078125,
      "logps/rejected": -142.48788452148438,
      "loss": 0.0074,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.644068956375122,
      "rewards/margins": 5.258903503417969,
      "rewards/rejected": -3.6148345470428467,
      "step": 1505
    },
    {
      "epoch": 0.6024,
      "grad_norm": 0.06240799278020859,
      "learning_rate": 7.993333333333333e-07,
      "logits/chosen": -2.2483725547790527,
      "logits/rejected": -3.8500242233276367,
      "logps/chosen": -75.02313232421875,
      "logps/rejected": -140.05859375,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1695306301116943,
      "rewards/margins": 8.256500244140625,
      "rewards/rejected": -5.086969375610352,
      "step": 1506
    },
    {
      "epoch": 0.6028,
      "grad_norm": 0.2045820653438568,
      "learning_rate": 7.992e-07,
      "logits/chosen": -2.445990562438965,
      "logits/rejected": -2.9976415634155273,
      "logps/chosen": -134.5965576171875,
      "logps/rejected": -151.653564453125,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.64158296585083,
      "rewards/margins": 5.984616756439209,
      "rewards/rejected": -4.343033790588379,
      "step": 1507
    },
    {
      "epoch": 0.6032,
      "grad_norm": 0.8535957336425781,
      "learning_rate": 7.990666666666667e-07,
      "logits/chosen": -2.2483129501342773,
      "logits/rejected": -3.1731410026550293,
      "logps/chosen": -138.13558959960938,
      "logps/rejected": -145.92678833007812,
      "loss": 0.0091,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0225563049316406,
      "rewards/margins": 6.047582626342773,
      "rewards/rejected": -4.025026321411133,
      "step": 1508
    },
    {
      "epoch": 0.6036,
      "grad_norm": 0.2796647250652313,
      "learning_rate": 7.989333333333334e-07,
      "logits/chosen": -2.3568668365478516,
      "logits/rejected": -3.079349994659424,
      "logps/chosen": -146.2170867919922,
      "logps/rejected": -195.5679168701172,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8558883666992188,
      "rewards/margins": 6.8184309005737305,
      "rewards/rejected": -4.962542533874512,
      "step": 1509
    },
    {
      "epoch": 0.604,
      "grad_norm": 0.7867849469184875,
      "learning_rate": 7.987999999999999e-07,
      "logits/chosen": -1.9670518636703491,
      "logits/rejected": -2.483529806137085,
      "logps/chosen": -143.73953247070312,
      "logps/rejected": -148.7789306640625,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0848109722137451,
      "rewards/margins": 5.870145797729492,
      "rewards/rejected": -4.785334587097168,
      "step": 1510
    },
    {
      "epoch": 0.6044,
      "grad_norm": 0.41151684522628784,
      "learning_rate": 7.986666666666666e-07,
      "logits/chosen": -2.423337936401367,
      "logits/rejected": -2.9952054023742676,
      "logps/chosen": -116.33302307128906,
      "logps/rejected": -133.61614990234375,
      "loss": 0.0049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.321922779083252,
      "rewards/margins": 5.820713520050049,
      "rewards/rejected": -3.498790740966797,
      "step": 1511
    },
    {
      "epoch": 0.6048,
      "grad_norm": 0.09067461639642715,
      "learning_rate": 7.985333333333333e-07,
      "logits/chosen": -2.341672897338867,
      "logits/rejected": -3.4729559421539307,
      "logps/chosen": -129.20608520507812,
      "logps/rejected": -142.21282958984375,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9523167610168457,
      "rewards/margins": 6.664656162261963,
      "rewards/rejected": -3.712339401245117,
      "step": 1512
    },
    {
      "epoch": 0.6052,
      "grad_norm": 1.7695097923278809,
      "learning_rate": 7.984e-07,
      "logits/chosen": -2.1325325965881348,
      "logits/rejected": -2.435530662536621,
      "logps/chosen": -119.9722900390625,
      "logps/rejected": -123.21090698242188,
      "loss": 0.0235,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.936906099319458,
      "rewards/margins": 6.225142955780029,
      "rewards/rejected": -4.28823709487915,
      "step": 1513
    },
    {
      "epoch": 0.6056,
      "grad_norm": 0.2925688922405243,
      "learning_rate": 7.982666666666666e-07,
      "logits/chosen": -2.069838523864746,
      "logits/rejected": -2.459101438522339,
      "logps/chosen": -133.968505859375,
      "logps/rejected": -133.14463806152344,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4674431085586548,
      "rewards/margins": 5.552956581115723,
      "rewards/rejected": -4.085513591766357,
      "step": 1514
    },
    {
      "epoch": 0.606,
      "grad_norm": 0.009734469465911388,
      "learning_rate": 7.981333333333333e-07,
      "logits/chosen": -2.006037712097168,
      "logits/rejected": -3.187622547149658,
      "logps/chosen": -85.0361328125,
      "logps/rejected": -166.16018676757812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.166364669799805,
      "rewards/margins": 9.12157917022705,
      "rewards/rejected": -4.955214023590088,
      "step": 1515
    },
    {
      "epoch": 0.6064,
      "grad_norm": 0.1786152571439743,
      "learning_rate": 7.98e-07,
      "logits/chosen": -2.505237102508545,
      "logits/rejected": -2.981072187423706,
      "logps/chosen": -133.16726684570312,
      "logps/rejected": -142.5060272216797,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5177788734436035,
      "rewards/margins": 7.325465679168701,
      "rewards/rejected": -4.807686805725098,
      "step": 1516
    },
    {
      "epoch": 0.6068,
      "grad_norm": 0.13697971403598785,
      "learning_rate": 7.978666666666666e-07,
      "logits/chosen": -2.440553903579712,
      "logits/rejected": -3.0997958183288574,
      "logps/chosen": -65.98797607421875,
      "logps/rejected": -137.38229370117188,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.276059627532959,
      "rewards/margins": 7.573041915893555,
      "rewards/rejected": -4.2969818115234375,
      "step": 1517
    },
    {
      "epoch": 0.6072,
      "grad_norm": 1.8780598640441895,
      "learning_rate": 7.977333333333333e-07,
      "logits/chosen": -2.11838960647583,
      "logits/rejected": -3.067483901977539,
      "logps/chosen": -113.5423812866211,
      "logps/rejected": -119.9410629272461,
      "loss": 0.0167,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4556984901428223,
      "rewards/margins": 6.097740173339844,
      "rewards/rejected": -3.6420419216156006,
      "step": 1518
    },
    {
      "epoch": 0.6076,
      "grad_norm": 0.2859410047531128,
      "learning_rate": 7.975999999999999e-07,
      "logits/chosen": -2.6441309452056885,
      "logits/rejected": -2.7966084480285645,
      "logps/chosen": -172.62899780273438,
      "logps/rejected": -162.8141632080078,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0836776494979858,
      "rewards/margins": 5.685493469238281,
      "rewards/rejected": -4.601816177368164,
      "step": 1519
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.054154302924871445,
      "learning_rate": 7.974666666666666e-07,
      "logits/chosen": -2.616407871246338,
      "logits/rejected": -3.4451491832733154,
      "logps/chosen": -201.25961303710938,
      "logps/rejected": -152.9423828125,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.418191432952881,
      "rewards/margins": 7.628907680511475,
      "rewards/rejected": -4.210716247558594,
      "step": 1520
    },
    {
      "epoch": 0.6084,
      "grad_norm": 0.5739803314208984,
      "learning_rate": 7.973333333333333e-07,
      "logits/chosen": -2.1208858489990234,
      "logits/rejected": -2.9273762702941895,
      "logps/chosen": -93.45928955078125,
      "logps/rejected": -137.77261352539062,
      "loss": 0.0059,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9817013144493103,
      "rewards/margins": 5.725839614868164,
      "rewards/rejected": -4.744138717651367,
      "step": 1521
    },
    {
      "epoch": 0.6088,
      "grad_norm": 0.3723940849304199,
      "learning_rate": 7.972e-07,
      "logits/chosen": -2.1229605674743652,
      "logits/rejected": -2.951587677001953,
      "logps/chosen": -110.72147369384766,
      "logps/rejected": -222.45169067382812,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2644968032836914,
      "rewards/margins": 7.105758190155029,
      "rewards/rejected": -4.841261386871338,
      "step": 1522
    },
    {
      "epoch": 0.6092,
      "grad_norm": 0.9282848834991455,
      "learning_rate": 7.970666666666667e-07,
      "logits/chosen": -2.3937129974365234,
      "logits/rejected": -2.5465903282165527,
      "logps/chosen": -160.19024658203125,
      "logps/rejected": -170.35769653320312,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3465614318847656,
      "rewards/margins": 7.121482849121094,
      "rewards/rejected": -4.774921417236328,
      "step": 1523
    },
    {
      "epoch": 0.6096,
      "grad_norm": 0.44736143946647644,
      "learning_rate": 7.969333333333333e-07,
      "logits/chosen": -2.749143123626709,
      "logits/rejected": -3.329061985015869,
      "logps/chosen": -143.21096801757812,
      "logps/rejected": -125.57453918457031,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.572721242904663,
      "rewards/margins": 6.2512030601501465,
      "rewards/rejected": -3.6784815788269043,
      "step": 1524
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.01666877418756485,
      "learning_rate": 7.967999999999999e-07,
      "logits/chosen": -1.874964952468872,
      "logits/rejected": -3.2726731300354004,
      "logps/chosen": -84.82675170898438,
      "logps/rejected": -141.097900390625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.765305519104004,
      "rewards/margins": 8.945616722106934,
      "rewards/rejected": -5.18031120300293,
      "step": 1525
    },
    {
      "epoch": 0.6104,
      "grad_norm": 0.2907528579235077,
      "learning_rate": 7.966666666666666e-07,
      "logits/chosen": -2.0799922943115234,
      "logits/rejected": -3.0344090461730957,
      "logps/chosen": -97.87250518798828,
      "logps/rejected": -159.02288818359375,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0168004035949707,
      "rewards/margins": 7.983427047729492,
      "rewards/rejected": -4.96662712097168,
      "step": 1526
    },
    {
      "epoch": 0.6108,
      "grad_norm": 0.029177993535995483,
      "learning_rate": 7.965333333333333e-07,
      "logits/chosen": -2.1043167114257812,
      "logits/rejected": -3.585493564605713,
      "logps/chosen": -104.83477020263672,
      "logps/rejected": -169.98025512695312,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5236434936523438,
      "rewards/margins": 8.065840721130371,
      "rewards/rejected": -4.542196750640869,
      "step": 1527
    },
    {
      "epoch": 0.6112,
      "grad_norm": 0.07704643905162811,
      "learning_rate": 7.964e-07,
      "logits/chosen": -1.803406000137329,
      "logits/rejected": -2.6036417484283447,
      "logps/chosen": -64.59496307373047,
      "logps/rejected": -119.61334228515625,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.173398971557617,
      "rewards/margins": 7.341790199279785,
      "rewards/rejected": -4.168391227722168,
      "step": 1528
    },
    {
      "epoch": 0.6116,
      "grad_norm": 0.0078104594722390175,
      "learning_rate": 7.962666666666666e-07,
      "logits/chosen": -2.1991872787475586,
      "logits/rejected": -3.271679162979126,
      "logps/chosen": -126.96553802490234,
      "logps/rejected": -201.6377410888672,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.43276834487915,
      "rewards/margins": 9.491961479187012,
      "rewards/rejected": -5.059193134307861,
      "step": 1529
    },
    {
      "epoch": 0.612,
      "grad_norm": 0.16984105110168457,
      "learning_rate": 7.961333333333333e-07,
      "logits/chosen": -2.8928205966949463,
      "logits/rejected": -3.0331168174743652,
      "logps/chosen": -242.34779357910156,
      "logps/rejected": -153.78662109375,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5681710243225098,
      "rewards/margins": 6.701467037200928,
      "rewards/rejected": -4.133296012878418,
      "step": 1530
    },
    {
      "epoch": 0.6124,
      "grad_norm": 0.07384578883647919,
      "learning_rate": 7.96e-07,
      "logits/chosen": -2.3860368728637695,
      "logits/rejected": -3.244126081466675,
      "logps/chosen": -133.4102325439453,
      "logps/rejected": -139.5097198486328,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.529664516448975,
      "rewards/margins": 7.548016548156738,
      "rewards/rejected": -3.0183517932891846,
      "step": 1531
    },
    {
      "epoch": 0.6128,
      "grad_norm": 0.7965008616447449,
      "learning_rate": 7.958666666666666e-07,
      "logits/chosen": -2.192946672439575,
      "logits/rejected": -2.1332149505615234,
      "logps/chosen": -154.44970703125,
      "logps/rejected": -144.30685424804688,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0416507720947266,
      "rewards/margins": 5.017163276672363,
      "rewards/rejected": -2.975512742996216,
      "step": 1532
    },
    {
      "epoch": 0.6132,
      "grad_norm": 0.3919503688812256,
      "learning_rate": 7.957333333333333e-07,
      "logits/chosen": -1.4481875896453857,
      "logits/rejected": -3.3974337577819824,
      "logps/chosen": -140.1405792236328,
      "logps/rejected": -149.33859252929688,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5339069366455078,
      "rewards/margins": 6.047146320343018,
      "rewards/rejected": -4.51323938369751,
      "step": 1533
    },
    {
      "epoch": 0.6136,
      "grad_norm": 0.06616470217704773,
      "learning_rate": 7.956e-07,
      "logits/chosen": -2.5704028606414795,
      "logits/rejected": -2.6969447135925293,
      "logps/chosen": -142.97103881835938,
      "logps/rejected": -146.38058471679688,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.816864490509033,
      "rewards/margins": 7.236557960510254,
      "rewards/rejected": -3.419693946838379,
      "step": 1534
    },
    {
      "epoch": 0.614,
      "grad_norm": 0.11702582985162735,
      "learning_rate": 7.954666666666666e-07,
      "logits/chosen": -1.8682619333267212,
      "logits/rejected": -2.435830593109131,
      "logps/chosen": -91.97186279296875,
      "logps/rejected": -146.799072265625,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.532351016998291,
      "rewards/margins": 7.798611640930176,
      "rewards/rejected": -4.266261100769043,
      "step": 1535
    },
    {
      "epoch": 0.6144,
      "grad_norm": 2.4350435733795166,
      "learning_rate": 7.953333333333333e-07,
      "logits/chosen": -1.9905518293380737,
      "logits/rejected": -3.326824903488159,
      "logps/chosen": -145.00054931640625,
      "logps/rejected": -118.40626525878906,
      "loss": 0.0156,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6218704581260681,
      "rewards/margins": 4.752135276794434,
      "rewards/rejected": -4.130265235900879,
      "step": 1536
    },
    {
      "epoch": 0.6148,
      "grad_norm": 0.3090739846229553,
      "learning_rate": 7.952e-07,
      "logits/chosen": -2.678349018096924,
      "logits/rejected": -3.8191585540771484,
      "logps/chosen": -155.80812072753906,
      "logps/rejected": -195.44284057617188,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3426861763000488,
      "rewards/margins": 7.750007629394531,
      "rewards/rejected": -6.407320976257324,
      "step": 1537
    },
    {
      "epoch": 0.6152,
      "grad_norm": 3.385390281677246,
      "learning_rate": 7.950666666666666e-07,
      "logits/chosen": -2.2068419456481934,
      "logits/rejected": -3.265225410461426,
      "logps/chosen": -88.56892395019531,
      "logps/rejected": -142.76861572265625,
      "loss": 0.049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6084384918212891,
      "rewards/margins": 3.519289255142212,
      "rewards/rejected": -4.127727508544922,
      "step": 1538
    },
    {
      "epoch": 0.6156,
      "grad_norm": 2.0250461101531982,
      "learning_rate": 7.949333333333333e-07,
      "logits/chosen": -1.9612927436828613,
      "logits/rejected": -3.043050527572632,
      "logps/chosen": -133.3063201904297,
      "logps/rejected": -137.8739471435547,
      "loss": 0.0187,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3931221961975098,
      "rewards/margins": 4.939553260803223,
      "rewards/rejected": -3.546431541442871,
      "step": 1539
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.05256149172782898,
      "learning_rate": 7.947999999999999e-07,
      "logits/chosen": -2.1518523693084717,
      "logits/rejected": -2.6977176666259766,
      "logps/chosen": -210.51663208007812,
      "logps/rejected": -194.42666625976562,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3699593544006348,
      "rewards/margins": 9.104583740234375,
      "rewards/rejected": -5.734624862670898,
      "step": 1540
    },
    {
      "epoch": 0.6164,
      "grad_norm": 1.1779810190200806,
      "learning_rate": 7.946666666666666e-07,
      "logits/chosen": -2.422163486480713,
      "logits/rejected": -3.338022232055664,
      "logps/chosen": -199.96975708007812,
      "logps/rejected": -159.96044921875,
      "loss": 0.0104,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1625664234161377,
      "rewards/margins": 5.999659061431885,
      "rewards/rejected": -4.837092399597168,
      "step": 1541
    },
    {
      "epoch": 0.6168,
      "grad_norm": 0.4186166524887085,
      "learning_rate": 7.945333333333333e-07,
      "logits/chosen": -2.197965383529663,
      "logits/rejected": -2.0772409439086914,
      "logps/chosen": -101.46517181396484,
      "logps/rejected": -106.26412963867188,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9145348072052002,
      "rewards/margins": 5.153853416442871,
      "rewards/rejected": -3.239318370819092,
      "step": 1542
    },
    {
      "epoch": 0.6172,
      "grad_norm": 0.0735931321978569,
      "learning_rate": 7.944e-07,
      "logits/chosen": -1.9173846244812012,
      "logits/rejected": -3.6222991943359375,
      "logps/chosen": -98.71491241455078,
      "logps/rejected": -167.12255859375,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.677534580230713,
      "rewards/margins": 7.568990230560303,
      "rewards/rejected": -5.89145565032959,
      "step": 1543
    },
    {
      "epoch": 0.6176,
      "grad_norm": 0.12933090329170227,
      "learning_rate": 7.942666666666667e-07,
      "logits/chosen": -2.374333143234253,
      "logits/rejected": -2.659658432006836,
      "logps/chosen": -211.3031005859375,
      "logps/rejected": -146.24818420410156,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8913583755493164,
      "rewards/margins": 7.721796989440918,
      "rewards/rejected": -3.8304386138916016,
      "step": 1544
    },
    {
      "epoch": 0.618,
      "grad_norm": 4.958609580993652,
      "learning_rate": 7.941333333333334e-07,
      "logits/chosen": -2.4233198165893555,
      "logits/rejected": -2.8730626106262207,
      "logps/chosen": -187.04547119140625,
      "logps/rejected": -132.61712646484375,
      "loss": 0.0442,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7990440130233765,
      "rewards/margins": 5.243068695068359,
      "rewards/rejected": -3.4440245628356934,
      "step": 1545
    },
    {
      "epoch": 0.6184,
      "grad_norm": 3.01629900932312,
      "learning_rate": 7.94e-07,
      "logits/chosen": -2.266495704650879,
      "logits/rejected": -3.1897006034851074,
      "logps/chosen": -158.11422729492188,
      "logps/rejected": -163.164794921875,
      "loss": 0.0385,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7916629910469055,
      "rewards/margins": 4.376358985900879,
      "rewards/rejected": -5.168022155761719,
      "step": 1546
    },
    {
      "epoch": 0.6188,
      "grad_norm": 24.04617691040039,
      "learning_rate": 7.938666666666667e-07,
      "logits/chosen": -3.2223777770996094,
      "logits/rejected": -3.4198176860809326,
      "logps/chosen": -253.7622528076172,
      "logps/rejected": -157.63226318359375,
      "loss": 0.2388,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9119614362716675,
      "rewards/margins": 2.443063735961914,
      "rewards/rejected": -4.355025291442871,
      "step": 1547
    },
    {
      "epoch": 0.6192,
      "grad_norm": 0.1211041584610939,
      "learning_rate": 7.937333333333332e-07,
      "logits/chosen": -1.9301868677139282,
      "logits/rejected": -3.3914756774902344,
      "logps/chosen": -79.09440612792969,
      "logps/rejected": -130.501220703125,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.388213634490967,
      "rewards/margins": 6.698213577270508,
      "rewards/rejected": -4.309999942779541,
      "step": 1548
    },
    {
      "epoch": 0.6196,
      "grad_norm": 0.01586451567709446,
      "learning_rate": 7.935999999999999e-07,
      "logits/chosen": -2.3391880989074707,
      "logits/rejected": -3.209902763366699,
      "logps/chosen": -133.61767578125,
      "logps/rejected": -186.6527862548828,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.201633453369141,
      "rewards/margins": 9.001436233520508,
      "rewards/rejected": -4.799802780151367,
      "step": 1549
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.5420079231262207,
      "learning_rate": 7.934666666666666e-07,
      "logits/chosen": -1.5033013820648193,
      "logits/rejected": -2.5937294960021973,
      "logps/chosen": -101.3107681274414,
      "logps/rejected": -130.79298400878906,
      "loss": 0.0182,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.653713583946228,
      "rewards/margins": 4.110278129577637,
      "rewards/rejected": -3.4565649032592773,
      "step": 1550
    },
    {
      "epoch": 0.6204,
      "grad_norm": 0.10366273671388626,
      "learning_rate": 7.933333333333333e-07,
      "logits/chosen": -1.672980785369873,
      "logits/rejected": -2.9456515312194824,
      "logps/chosen": -232.32376098632812,
      "logps/rejected": -175.63653564453125,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.357989549636841,
      "rewards/margins": 7.050318241119385,
      "rewards/rejected": -4.692328453063965,
      "step": 1551
    },
    {
      "epoch": 0.6208,
      "grad_norm": 0.047393180429935455,
      "learning_rate": 7.932e-07,
      "logits/chosen": -2.315779685974121,
      "logits/rejected": -3.0620198249816895,
      "logps/chosen": -139.64508056640625,
      "logps/rejected": -234.89610290527344,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.287562370300293,
      "rewards/margins": 7.892148017883301,
      "rewards/rejected": -4.604585647583008,
      "step": 1552
    },
    {
      "epoch": 0.6212,
      "grad_norm": 0.35723990201950073,
      "learning_rate": 7.930666666666667e-07,
      "logits/chosen": -2.2963027954101562,
      "logits/rejected": -2.5578880310058594,
      "logps/chosen": -154.72634887695312,
      "logps/rejected": -200.0771484375,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8674559593200684,
      "rewards/margins": 5.741772651672363,
      "rewards/rejected": -2.874316453933716,
      "step": 1553
    },
    {
      "epoch": 0.6216,
      "grad_norm": 0.0478944256901741,
      "learning_rate": 7.929333333333334e-07,
      "logits/chosen": -1.9995465278625488,
      "logits/rejected": -2.7226850986480713,
      "logps/chosen": -92.45176696777344,
      "logps/rejected": -128.65182495117188,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.833430528640747,
      "rewards/margins": 7.48835563659668,
      "rewards/rejected": -4.654925346374512,
      "step": 1554
    },
    {
      "epoch": 0.622,
      "grad_norm": 0.061221372336149216,
      "learning_rate": 7.928e-07,
      "logits/chosen": -2.4512438774108887,
      "logits/rejected": -2.7432827949523926,
      "logps/chosen": -122.74456787109375,
      "logps/rejected": -143.13589477539062,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.235611915588379,
      "rewards/margins": 7.19222354888916,
      "rewards/rejected": -2.9566116333007812,
      "step": 1555
    },
    {
      "epoch": 0.6224,
      "grad_norm": 4.955804347991943,
      "learning_rate": 7.926666666666666e-07,
      "logits/chosen": -2.5069124698638916,
      "logits/rejected": -2.642001152038574,
      "logps/chosen": -115.99723052978516,
      "logps/rejected": -170.8712615966797,
      "loss": 0.0501,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.686846971511841,
      "rewards/margins": 5.445432662963867,
      "rewards/rejected": -2.7585854530334473,
      "step": 1556
    },
    {
      "epoch": 0.6228,
      "grad_norm": 0.03696054220199585,
      "learning_rate": 7.925333333333332e-07,
      "logits/chosen": -2.0765645503997803,
      "logits/rejected": -2.848823070526123,
      "logps/chosen": -91.79147338867188,
      "logps/rejected": -136.75491333007812,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9312806129455566,
      "rewards/margins": 8.088327407836914,
      "rewards/rejected": -4.157047271728516,
      "step": 1557
    },
    {
      "epoch": 0.6232,
      "grad_norm": 1.1893956661224365,
      "learning_rate": 7.923999999999999e-07,
      "logits/chosen": -2.405730724334717,
      "logits/rejected": -3.1871843338012695,
      "logps/chosen": -141.72589111328125,
      "logps/rejected": -162.8897705078125,
      "loss": 0.0104,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7154076099395752,
      "rewards/margins": 5.495388984680176,
      "rewards/rejected": -3.7799813747406006,
      "step": 1558
    },
    {
      "epoch": 0.6236,
      "grad_norm": 0.06655307114124298,
      "learning_rate": 7.922666666666666e-07,
      "logits/chosen": -2.229243278503418,
      "logits/rejected": -3.301142692565918,
      "logps/chosen": -192.869384765625,
      "logps/rejected": -145.81602478027344,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.469700336456299,
      "rewards/margins": 7.360440254211426,
      "rewards/rejected": -3.890739917755127,
      "step": 1559
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.213801771402359,
      "learning_rate": 7.921333333333333e-07,
      "logits/chosen": -2.5992908477783203,
      "logits/rejected": -2.9937644004821777,
      "logps/chosen": -192.08746337890625,
      "logps/rejected": -203.28924560546875,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8226014375686646,
      "rewards/margins": 6.320549011230469,
      "rewards/rejected": -4.497947692871094,
      "step": 1560
    },
    {
      "epoch": 0.6244,
      "grad_norm": 0.42551684379577637,
      "learning_rate": 7.92e-07,
      "logits/chosen": -1.9515219926834106,
      "logits/rejected": -3.0014331340789795,
      "logps/chosen": -144.76361083984375,
      "logps/rejected": -146.76690673828125,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2544312477111816,
      "rewards/margins": 6.447182655334473,
      "rewards/rejected": -4.192751407623291,
      "step": 1561
    },
    {
      "epoch": 0.6248,
      "grad_norm": 0.1929008513689041,
      "learning_rate": 7.918666666666667e-07,
      "logits/chosen": -2.515385627746582,
      "logits/rejected": -3.5920467376708984,
      "logps/chosen": -209.6860809326172,
      "logps/rejected": -220.3995819091797,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.084372043609619,
      "rewards/margins": 7.969316482543945,
      "rewards/rejected": -5.884944915771484,
      "step": 1562
    },
    {
      "epoch": 0.6252,
      "grad_norm": 0.3338682949542999,
      "learning_rate": 7.917333333333333e-07,
      "logits/chosen": -2.2687458992004395,
      "logits/rejected": -2.8585264682769775,
      "logps/chosen": -101.20549011230469,
      "logps/rejected": -155.6092529296875,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7565953731536865,
      "rewards/margins": 7.65223503112793,
      "rewards/rejected": -3.895639419555664,
      "step": 1563
    },
    {
      "epoch": 0.6256,
      "grad_norm": 0.5135201215744019,
      "learning_rate": 7.916e-07,
      "logits/chosen": -2.4614346027374268,
      "logits/rejected": -3.2689194679260254,
      "logps/chosen": -72.74989318847656,
      "logps/rejected": -132.89236450195312,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9740262031555176,
      "rewards/margins": 6.82614803314209,
      "rewards/rejected": -3.8521220684051514,
      "step": 1564
    },
    {
      "epoch": 0.626,
      "grad_norm": 0.05827812850475311,
      "learning_rate": 7.914666666666667e-07,
      "logits/chosen": -2.6219143867492676,
      "logits/rejected": -3.9338912963867188,
      "logps/chosen": -151.75347900390625,
      "logps/rejected": -154.90101623535156,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.214980125427246,
      "rewards/margins": 7.533608913421631,
      "rewards/rejected": -4.318628787994385,
      "step": 1565
    },
    {
      "epoch": 0.6264,
      "grad_norm": 2.0713045597076416,
      "learning_rate": 7.913333333333332e-07,
      "logits/chosen": -2.641010046005249,
      "logits/rejected": -3.4381518363952637,
      "logps/chosen": -119.06370544433594,
      "logps/rejected": -149.64688110351562,
      "loss": 0.0248,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6009784936904907,
      "rewards/margins": 6.488199234008789,
      "rewards/rejected": -4.887220859527588,
      "step": 1566
    },
    {
      "epoch": 0.6268,
      "grad_norm": 0.018065854907035828,
      "learning_rate": 7.911999999999999e-07,
      "logits/chosen": -2.183898448944092,
      "logits/rejected": -3.137289047241211,
      "logps/chosen": -79.08447265625,
      "logps/rejected": -160.84719848632812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.059545993804932,
      "rewards/margins": 8.96738338470459,
      "rewards/rejected": -4.907837867736816,
      "step": 1567
    },
    {
      "epoch": 0.6272,
      "grad_norm": 1.3750388622283936,
      "learning_rate": 7.910666666666666e-07,
      "logits/chosen": -2.5625524520874023,
      "logits/rejected": -2.8855371475219727,
      "logps/chosen": -124.79821014404297,
      "logps/rejected": -120.34967041015625,
      "loss": 0.0149,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3550231456756592,
      "rewards/margins": 4.647022247314453,
      "rewards/rejected": -3.291999101638794,
      "step": 1568
    },
    {
      "epoch": 0.6276,
      "grad_norm": 0.430742472410202,
      "learning_rate": 7.909333333333333e-07,
      "logits/chosen": -2.208235740661621,
      "logits/rejected": -2.72255802154541,
      "logps/chosen": -80.20172882080078,
      "logps/rejected": -116.47337341308594,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1037163734436035,
      "rewards/margins": 6.380946159362793,
      "rewards/rejected": -3.2772293090820312,
      "step": 1569
    },
    {
      "epoch": 0.628,
      "grad_norm": 0.21994903683662415,
      "learning_rate": 7.907999999999999e-07,
      "logits/chosen": -2.420802116394043,
      "logits/rejected": -2.5013625621795654,
      "logps/chosen": -96.92461395263672,
      "logps/rejected": -144.89999389648438,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.518082618713379,
      "rewards/margins": 6.89613151550293,
      "rewards/rejected": -3.378048896789551,
      "step": 1570
    },
    {
      "epoch": 0.6284,
      "grad_norm": 0.17957636713981628,
      "learning_rate": 7.906666666666666e-07,
      "logits/chosen": -1.9695738554000854,
      "logits/rejected": -2.729278564453125,
      "logps/chosen": -71.92924499511719,
      "logps/rejected": -144.9795379638672,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8899643421173096,
      "rewards/margins": 6.9251708984375,
      "rewards/rejected": -4.035206317901611,
      "step": 1571
    },
    {
      "epoch": 0.6288,
      "grad_norm": 0.7017395496368408,
      "learning_rate": 7.905333333333333e-07,
      "logits/chosen": -2.2193551063537598,
      "logits/rejected": -2.6662206649780273,
      "logps/chosen": -106.32633972167969,
      "logps/rejected": -148.92311096191406,
      "loss": 0.0062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5566768646240234,
      "rewards/margins": 5.1753644943237305,
      "rewards/rejected": -2.618687629699707,
      "step": 1572
    },
    {
      "epoch": 0.6292,
      "grad_norm": 0.044721439480781555,
      "learning_rate": 7.904e-07,
      "logits/chosen": -2.6664345264434814,
      "logits/rejected": -3.419724941253662,
      "logps/chosen": -123.29898071289062,
      "logps/rejected": -152.73863220214844,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.241128921508789,
      "rewards/margins": 7.783413887023926,
      "rewards/rejected": -4.542284965515137,
      "step": 1573
    },
    {
      "epoch": 0.6296,
      "grad_norm": 0.1266334354877472,
      "learning_rate": 7.902666666666667e-07,
      "logits/chosen": -1.4399982690811157,
      "logits/rejected": -2.756537914276123,
      "logps/chosen": -65.25965118408203,
      "logps/rejected": -114.04112243652344,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.606719493865967,
      "rewards/margins": 6.558257102966309,
      "rewards/rejected": -2.951537609100342,
      "step": 1574
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.646323561668396,
      "learning_rate": 7.901333333333334e-07,
      "logits/chosen": -1.9297850131988525,
      "logits/rejected": -2.8362669944763184,
      "logps/chosen": -103.69438934326172,
      "logps/rejected": -134.06759643554688,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8204094171524048,
      "rewards/margins": 5.868105888366699,
      "rewards/rejected": -4.047696113586426,
      "step": 1575
    },
    {
      "epoch": 0.6304,
      "grad_norm": 0.018929289653897285,
      "learning_rate": 7.9e-07,
      "logits/chosen": -2.315476179122925,
      "logits/rejected": -3.4235732555389404,
      "logps/chosen": -121.0666732788086,
      "logps/rejected": -204.03863525390625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.480924606323242,
      "rewards/margins": 8.673095703125,
      "rewards/rejected": -4.1921706199646,
      "step": 1576
    },
    {
      "epoch": 0.6308,
      "grad_norm": 0.13892945647239685,
      "learning_rate": 7.898666666666666e-07,
      "logits/chosen": -2.0771431922912598,
      "logits/rejected": -3.0743143558502197,
      "logps/chosen": -173.62730407714844,
      "logps/rejected": -138.4644775390625,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1758084297180176,
      "rewards/margins": 6.699117660522461,
      "rewards/rejected": -4.523309707641602,
      "step": 1577
    },
    {
      "epoch": 0.6312,
      "grad_norm": 0.5519231557846069,
      "learning_rate": 7.897333333333332e-07,
      "logits/chosen": -2.0722761154174805,
      "logits/rejected": -3.0804014205932617,
      "logps/chosen": -90.09217834472656,
      "logps/rejected": -122.62159729003906,
      "loss": 0.0062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6938531398773193,
      "rewards/margins": 6.508637428283691,
      "rewards/rejected": -3.814784049987793,
      "step": 1578
    },
    {
      "epoch": 0.6316,
      "grad_norm": 10.25706958770752,
      "learning_rate": 7.895999999999999e-07,
      "logits/chosen": -1.9885600805282593,
      "logits/rejected": -2.7719802856445312,
      "logps/chosen": -84.82178497314453,
      "logps/rejected": -122.12275695800781,
      "loss": 0.0741,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0652122497558594,
      "rewards/margins": 4.109532356262207,
      "rewards/rejected": -3.0443201065063477,
      "step": 1579
    },
    {
      "epoch": 0.632,
      "grad_norm": 0.05598660558462143,
      "learning_rate": 7.894666666666666e-07,
      "logits/chosen": -2.0198233127593994,
      "logits/rejected": -3.169504404067993,
      "logps/chosen": -127.68301391601562,
      "logps/rejected": -153.97735595703125,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.251366376876831,
      "rewards/margins": 7.374128818511963,
      "rewards/rejected": -4.122762680053711,
      "step": 1580
    },
    {
      "epoch": 0.6324,
      "grad_norm": 4.589612007141113,
      "learning_rate": 7.893333333333333e-07,
      "logits/chosen": -2.5622453689575195,
      "logits/rejected": -2.6397814750671387,
      "logps/chosen": -122.16292572021484,
      "logps/rejected": -172.41268920898438,
      "loss": 0.0281,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2403770685195923,
      "rewards/margins": 5.815713882446289,
      "rewards/rejected": -4.575336456298828,
      "step": 1581
    },
    {
      "epoch": 0.6328,
      "grad_norm": 0.5677971243858337,
      "learning_rate": 7.892e-07,
      "logits/chosen": -2.1932456493377686,
      "logits/rejected": -2.677598476409912,
      "logps/chosen": -168.47140502929688,
      "logps/rejected": -159.70291137695312,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8693368434906006,
      "rewards/margins": 7.251967430114746,
      "rewards/rejected": -4.382630825042725,
      "step": 1582
    },
    {
      "epoch": 0.6332,
      "grad_norm": 0.5374950766563416,
      "learning_rate": 7.890666666666667e-07,
      "logits/chosen": -2.3693621158599854,
      "logits/rejected": -2.8921895027160645,
      "logps/chosen": -138.5672149658203,
      "logps/rejected": -162.67039489746094,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6655800342559814,
      "rewards/margins": 6.698243141174316,
      "rewards/rejected": -5.032662868499756,
      "step": 1583
    },
    {
      "epoch": 0.6336,
      "grad_norm": 1.190477967262268,
      "learning_rate": 7.889333333333334e-07,
      "logits/chosen": -2.377748489379883,
      "logits/rejected": -3.037367105484009,
      "logps/chosen": -183.39190673828125,
      "logps/rejected": -121.78076171875,
      "loss": 0.0107,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9629204273223877,
      "rewards/margins": 4.7939653396606445,
      "rewards/rejected": -3.831044912338257,
      "step": 1584
    },
    {
      "epoch": 0.634,
      "grad_norm": 0.5250198841094971,
      "learning_rate": 7.887999999999999e-07,
      "logits/chosen": -1.9454630613327026,
      "logits/rejected": -3.1451449394226074,
      "logps/chosen": -78.67239379882812,
      "logps/rejected": -168.71746826171875,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.318364381790161,
      "rewards/margins": 7.775082588195801,
      "rewards/rejected": -5.456718444824219,
      "step": 1585
    },
    {
      "epoch": 0.6344,
      "grad_norm": 0.020364243537187576,
      "learning_rate": 7.886666666666666e-07,
      "logits/chosen": -2.6160941123962402,
      "logits/rejected": -3.2065067291259766,
      "logps/chosen": -194.92349243164062,
      "logps/rejected": -156.15907287597656,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.844738006591797,
      "rewards/margins": 9.510110855102539,
      "rewards/rejected": -4.665372848510742,
      "step": 1586
    },
    {
      "epoch": 0.6348,
      "grad_norm": 2.5462253093719482,
      "learning_rate": 7.885333333333332e-07,
      "logits/chosen": -2.2889199256896973,
      "logits/rejected": -2.4463136196136475,
      "logps/chosen": -101.16079711914062,
      "logps/rejected": -131.96881103515625,
      "loss": 0.0189,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1158173084259033,
      "rewards/margins": 4.786218166351318,
      "rewards/rejected": -3.670401096343994,
      "step": 1587
    },
    {
      "epoch": 0.6352,
      "grad_norm": 0.3137862980365753,
      "learning_rate": 7.883999999999999e-07,
      "logits/chosen": -2.367701768875122,
      "logits/rejected": -3.481576442718506,
      "logps/chosen": -142.6498565673828,
      "logps/rejected": -154.94874572753906,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.98028564453125,
      "rewards/margins": 6.745401382446289,
      "rewards/rejected": -4.765115737915039,
      "step": 1588
    },
    {
      "epoch": 0.6356,
      "grad_norm": 0.030250566080212593,
      "learning_rate": 7.882666666666666e-07,
      "logits/chosen": -2.28436541557312,
      "logits/rejected": -3.1536664962768555,
      "logps/chosen": -137.32662963867188,
      "logps/rejected": -178.40338134765625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.574488639831543,
      "rewards/margins": 8.570706367492676,
      "rewards/rejected": -4.996217727661133,
      "step": 1589
    },
    {
      "epoch": 0.636,
      "grad_norm": 0.057932049036026,
      "learning_rate": 7.881333333333333e-07,
      "logits/chosen": -2.522709369659424,
      "logits/rejected": -2.792727470397949,
      "logps/chosen": -112.53129577636719,
      "logps/rejected": -135.7243194580078,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.032048225402832,
      "rewards/margins": 7.383513450622559,
      "rewards/rejected": -4.351465702056885,
      "step": 1590
    },
    {
      "epoch": 0.6364,
      "grad_norm": 0.02990899421274662,
      "learning_rate": 7.88e-07,
      "logits/chosen": -2.2327253818511963,
      "logits/rejected": -3.268206834793091,
      "logps/chosen": -65.15328979492188,
      "logps/rejected": -158.57015991210938,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.455152988433838,
      "rewards/margins": 8.603668212890625,
      "rewards/rejected": -5.148514747619629,
      "step": 1591
    },
    {
      "epoch": 0.6368,
      "grad_norm": 0.003264587139710784,
      "learning_rate": 7.878666666666667e-07,
      "logits/chosen": -2.3488426208496094,
      "logits/rejected": -3.6066925525665283,
      "logps/chosen": -121.07254791259766,
      "logps/rejected": -182.84657287597656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9811761379241943,
      "rewards/margins": 10.514650344848633,
      "rewards/rejected": -6.533473968505859,
      "step": 1592
    },
    {
      "epoch": 0.6372,
      "grad_norm": 0.03880119323730469,
      "learning_rate": 7.877333333333333e-07,
      "logits/chosen": -1.6354047060012817,
      "logits/rejected": -3.2881503105163574,
      "logps/chosen": -72.3244400024414,
      "logps/rejected": -124.61744689941406,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1216366291046143,
      "rewards/margins": 7.760680198669434,
      "rewards/rejected": -4.639042854309082,
      "step": 1593
    },
    {
      "epoch": 0.6376,
      "grad_norm": 0.2308884561061859,
      "learning_rate": 7.875999999999999e-07,
      "logits/chosen": -2.5424342155456543,
      "logits/rejected": -3.350409984588623,
      "logps/chosen": -232.85032653808594,
      "logps/rejected": -168.31832885742188,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4325287342071533,
      "rewards/margins": 6.244478225708008,
      "rewards/rejected": -4.811949253082275,
      "step": 1594
    },
    {
      "epoch": 0.638,
      "grad_norm": 0.09231563657522202,
      "learning_rate": 7.874666666666666e-07,
      "logits/chosen": -2.7308502197265625,
      "logits/rejected": -3.091668128967285,
      "logps/chosen": -153.1441192626953,
      "logps/rejected": -179.34010314941406,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.235600471496582,
      "rewards/margins": 8.721534729003906,
      "rewards/rejected": -4.485934257507324,
      "step": 1595
    },
    {
      "epoch": 0.6384,
      "grad_norm": 0.5422954559326172,
      "learning_rate": 7.873333333333333e-07,
      "logits/chosen": -2.154623031616211,
      "logits/rejected": -2.580955743789673,
      "logps/chosen": -127.77793884277344,
      "logps/rejected": -161.71502685546875,
      "loss": 0.0056,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4042507410049438,
      "rewards/margins": 5.34681510925293,
      "rewards/rejected": -3.9425644874572754,
      "step": 1596
    },
    {
      "epoch": 0.6388,
      "grad_norm": 0.2542083263397217,
      "learning_rate": 7.872e-07,
      "logits/chosen": -2.0338664054870605,
      "logits/rejected": -2.7311623096466064,
      "logps/chosen": -106.29275512695312,
      "logps/rejected": -153.6135711669922,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6131470203399658,
      "rewards/margins": 6.987654685974121,
      "rewards/rejected": -5.374507904052734,
      "step": 1597
    },
    {
      "epoch": 0.6392,
      "grad_norm": 0.6033085584640503,
      "learning_rate": 7.870666666666666e-07,
      "logits/chosen": -1.7910314798355103,
      "logits/rejected": -3.0472517013549805,
      "logps/chosen": -144.40084838867188,
      "logps/rejected": -145.8977813720703,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0222053527832031,
      "rewards/margins": 6.18092155456543,
      "rewards/rejected": -5.158716201782227,
      "step": 1598
    },
    {
      "epoch": 0.6396,
      "grad_norm": 0.09282515943050385,
      "learning_rate": 7.869333333333333e-07,
      "logits/chosen": -2.051300525665283,
      "logits/rejected": -3.296970844268799,
      "logps/chosen": -100.43417358398438,
      "logps/rejected": -157.45523071289062,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9220685958862305,
      "rewards/margins": 8.542108535766602,
      "rewards/rejected": -5.620039939880371,
      "step": 1599
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.02650490030646324,
      "learning_rate": 7.868e-07,
      "logits/chosen": -2.5586092472076416,
      "logits/rejected": -2.491722345352173,
      "logps/chosen": -129.0724639892578,
      "logps/rejected": -157.77651977539062,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.513080596923828,
      "rewards/margins": 8.622560501098633,
      "rewards/rejected": -5.109479904174805,
      "step": 1600
    },
    {
      "epoch": 0.6404,
      "grad_norm": 6.9535980224609375,
      "learning_rate": 7.866666666666666e-07,
      "logits/chosen": -2.5805587768554688,
      "logits/rejected": -3.0354931354522705,
      "logps/chosen": -166.01150512695312,
      "logps/rejected": -172.9395294189453,
      "loss": 0.0679,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.930182695388794,
      "rewards/margins": 5.606607437133789,
      "rewards/rejected": -4.676424980163574,
      "step": 1601
    },
    {
      "epoch": 0.6408,
      "grad_norm": 0.34227535128593445,
      "learning_rate": 7.865333333333333e-07,
      "logits/chosen": -2.1469674110412598,
      "logits/rejected": -3.0724258422851562,
      "logps/chosen": -178.9408721923828,
      "logps/rejected": -143.86062622070312,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1185593605041504,
      "rewards/margins": 5.896983623504639,
      "rewards/rejected": -3.7784245014190674,
      "step": 1602
    },
    {
      "epoch": 0.6412,
      "grad_norm": 1.66141939163208,
      "learning_rate": 7.864e-07,
      "logits/chosen": -2.7147603034973145,
      "logits/rejected": -2.7906289100646973,
      "logps/chosen": -176.73814392089844,
      "logps/rejected": -181.93283081054688,
      "loss": 0.0189,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23337440192699432,
      "rewards/margins": 4.454707145690918,
      "rewards/rejected": -4.221332550048828,
      "step": 1603
    },
    {
      "epoch": 0.6416,
      "grad_norm": 0.10329046845436096,
      "learning_rate": 7.862666666666666e-07,
      "logits/chosen": -2.08359432220459,
      "logits/rejected": -2.7035272121429443,
      "logps/chosen": -99.45061492919922,
      "logps/rejected": -142.649658203125,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9657554626464844,
      "rewards/margins": 7.194572448730469,
      "rewards/rejected": -4.228816509246826,
      "step": 1604
    },
    {
      "epoch": 0.642,
      "grad_norm": 0.0681878849864006,
      "learning_rate": 7.861333333333333e-07,
      "logits/chosen": -2.7269811630249023,
      "logits/rejected": -3.6437835693359375,
      "logps/chosen": -228.1355743408203,
      "logps/rejected": -194.88809204101562,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1752586364746094,
      "rewards/margins": 9.974377632141113,
      "rewards/rejected": -6.799118995666504,
      "step": 1605
    },
    {
      "epoch": 0.6424,
      "grad_norm": 0.14194989204406738,
      "learning_rate": 7.86e-07,
      "logits/chosen": -2.575348377227783,
      "logits/rejected": -3.136813163757324,
      "logps/chosen": -94.927001953125,
      "logps/rejected": -138.05238342285156,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0396649837493896,
      "rewards/margins": 6.7759175300598145,
      "rewards/rejected": -3.736252784729004,
      "step": 1606
    },
    {
      "epoch": 0.6428,
      "grad_norm": 0.11678028851747513,
      "learning_rate": 7.858666666666667e-07,
      "logits/chosen": -2.8817038536071777,
      "logits/rejected": -3.4084343910217285,
      "logps/chosen": -224.00709533691406,
      "logps/rejected": -176.2484893798828,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8883476257324219,
      "rewards/margins": 6.792982578277588,
      "rewards/rejected": -4.904634952545166,
      "step": 1607
    },
    {
      "epoch": 0.6432,
      "grad_norm": 0.24873891472816467,
      "learning_rate": 7.857333333333332e-07,
      "logits/chosen": -2.29109787940979,
      "logits/rejected": -2.9381051063537598,
      "logps/chosen": -137.6481170654297,
      "logps/rejected": -148.50230407714844,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0167808532714844,
      "rewards/margins": 7.059087753295898,
      "rewards/rejected": -5.042306900024414,
      "step": 1608
    },
    {
      "epoch": 0.6436,
      "grad_norm": 0.0843677967786789,
      "learning_rate": 7.855999999999999e-07,
      "logits/chosen": -2.433979034423828,
      "logits/rejected": -3.0939548015594482,
      "logps/chosen": -121.8953857421875,
      "logps/rejected": -146.4505615234375,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.031970500946045,
      "rewards/margins": 7.721534252166748,
      "rewards/rejected": -4.689563751220703,
      "step": 1609
    },
    {
      "epoch": 0.644,
      "grad_norm": 0.20095877349376678,
      "learning_rate": 7.854666666666666e-07,
      "logits/chosen": -2.184723138809204,
      "logits/rejected": -2.933082103729248,
      "logps/chosen": -116.76594543457031,
      "logps/rejected": -148.9056396484375,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3914215564727783,
      "rewards/margins": 6.365671634674072,
      "rewards/rejected": -4.974249839782715,
      "step": 1610
    },
    {
      "epoch": 0.6444,
      "grad_norm": 2.281687021255493,
      "learning_rate": 7.853333333333333e-07,
      "logits/chosen": -2.0240845680236816,
      "logits/rejected": -3.297111988067627,
      "logps/chosen": -106.97563171386719,
      "logps/rejected": -144.77569580078125,
      "loss": 0.02,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.43450090289115906,
      "rewards/margins": 4.386601448059082,
      "rewards/rejected": -4.821102619171143,
      "step": 1611
    },
    {
      "epoch": 0.6448,
      "grad_norm": 0.6521690487861633,
      "learning_rate": 7.852e-07,
      "logits/chosen": -2.4479551315307617,
      "logits/rejected": -3.3762903213500977,
      "logps/chosen": -138.98211669921875,
      "logps/rejected": -137.34190368652344,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4384751319885254,
      "rewards/margins": 4.940835952758789,
      "rewards/rejected": -3.5023605823516846,
      "step": 1612
    },
    {
      "epoch": 0.6452,
      "grad_norm": 0.013054137118160725,
      "learning_rate": 7.850666666666666e-07,
      "logits/chosen": -2.337937831878662,
      "logits/rejected": -3.5406012535095215,
      "logps/chosen": -153.61666870117188,
      "logps/rejected": -161.7715606689453,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.668495178222656,
      "rewards/margins": 8.79440689086914,
      "rewards/rejected": -4.125911712646484,
      "step": 1613
    },
    {
      "epoch": 0.6456,
      "grad_norm": 0.9141188263893127,
      "learning_rate": 7.849333333333333e-07,
      "logits/chosen": -1.7601008415222168,
      "logits/rejected": -2.718410015106201,
      "logps/chosen": -134.6009521484375,
      "logps/rejected": -133.56170654296875,
      "loss": 0.0052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.799503207206726,
      "rewards/margins": 6.454705238342285,
      "rewards/rejected": -4.655202388763428,
      "step": 1614
    },
    {
      "epoch": 0.646,
      "grad_norm": 0.016366969794034958,
      "learning_rate": 7.848e-07,
      "logits/chosen": -2.389364719390869,
      "logits/rejected": -3.2731847763061523,
      "logps/chosen": -132.86741638183594,
      "logps/rejected": -158.52621459960938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.483217716217041,
      "rewards/margins": 8.52614688873291,
      "rewards/rejected": -5.042928695678711,
      "step": 1615
    },
    {
      "epoch": 0.6464,
      "grad_norm": 2.1394333839416504,
      "learning_rate": 7.846666666666666e-07,
      "logits/chosen": -2.5083398818969727,
      "logits/rejected": -2.0603909492492676,
      "logps/chosen": -184.029296875,
      "logps/rejected": -142.61038208007812,
      "loss": 0.0145,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.597287178039551,
      "rewards/margins": 5.763444900512695,
      "rewards/rejected": -3.1661577224731445,
      "step": 1616
    },
    {
      "epoch": 0.6468,
      "grad_norm": 0.10211930423974991,
      "learning_rate": 7.845333333333333e-07,
      "logits/chosen": -1.852926254272461,
      "logits/rejected": -2.131366014480591,
      "logps/chosen": -129.22569274902344,
      "logps/rejected": -141.66400146484375,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.637702465057373,
      "rewards/margins": 7.0046067237854,
      "rewards/rejected": -4.366904258728027,
      "step": 1617
    },
    {
      "epoch": 0.6472,
      "grad_norm": 0.022590164095163345,
      "learning_rate": 7.844e-07,
      "logits/chosen": -2.442006826400757,
      "logits/rejected": -3.227863073348999,
      "logps/chosen": -136.72193908691406,
      "logps/rejected": -135.95358276367188,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5900590419769287,
      "rewards/margins": 8.531402587890625,
      "rewards/rejected": -4.941344261169434,
      "step": 1618
    },
    {
      "epoch": 0.6476,
      "grad_norm": 0.09894166141748428,
      "learning_rate": 7.842666666666666e-07,
      "logits/chosen": -2.4693775177001953,
      "logits/rejected": -2.5095090866088867,
      "logps/chosen": -84.91609191894531,
      "logps/rejected": -150.0957794189453,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9398746490478516,
      "rewards/margins": 7.879208564758301,
      "rewards/rejected": -3.93933367729187,
      "step": 1619
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.47411826252937317,
      "learning_rate": 7.841333333333333e-07,
      "logits/chosen": -2.7315926551818848,
      "logits/rejected": -3.794908285140991,
      "logps/chosen": -161.62457275390625,
      "logps/rejected": -139.3594970703125,
      "loss": 0.0059,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40397873520851135,
      "rewards/margins": 5.397985458374023,
      "rewards/rejected": -4.994006633758545,
      "step": 1620
    },
    {
      "epoch": 0.6484,
      "grad_norm": 0.13645613193511963,
      "learning_rate": 7.84e-07,
      "logits/chosen": -2.0339198112487793,
      "logits/rejected": -2.7922892570495605,
      "logps/chosen": -119.09935760498047,
      "logps/rejected": -167.9035186767578,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3304283618927,
      "rewards/margins": 7.735671043395996,
      "rewards/rejected": -4.405242919921875,
      "step": 1621
    },
    {
      "epoch": 0.6488,
      "grad_norm": 0.1178516373038292,
      "learning_rate": 7.838666666666667e-07,
      "logits/chosen": -2.0678658485412598,
      "logits/rejected": -3.6082091331481934,
      "logps/chosen": -125.75416564941406,
      "logps/rejected": -190.98825073242188,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0463309288024902,
      "rewards/margins": 8.589930534362793,
      "rewards/rejected": -5.543599605560303,
      "step": 1622
    },
    {
      "epoch": 0.6492,
      "grad_norm": 1.9633028507232666,
      "learning_rate": 7.837333333333332e-07,
      "logits/chosen": -2.0459437370300293,
      "logits/rejected": -3.340182304382324,
      "logps/chosen": -76.03822326660156,
      "logps/rejected": -151.31546020507812,
      "loss": 0.0142,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2046971321105957,
      "rewards/margins": 5.722200870513916,
      "rewards/rejected": -3.5175037384033203,
      "step": 1623
    },
    {
      "epoch": 0.6496,
      "grad_norm": 0.17402160167694092,
      "learning_rate": 7.835999999999999e-07,
      "logits/chosen": -1.9860762357711792,
      "logits/rejected": -2.7396059036254883,
      "logps/chosen": -72.14045715332031,
      "logps/rejected": -142.5001220703125,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2727012634277344,
      "rewards/margins": 7.424153804779053,
      "rewards/rejected": -4.151452541351318,
      "step": 1624
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.4877704381942749,
      "learning_rate": 7.834666666666666e-07,
      "logits/chosen": -1.6962820291519165,
      "logits/rejected": -3.2241711616516113,
      "logps/chosen": -127.45362091064453,
      "logps/rejected": -194.31808471679688,
      "loss": 0.0044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5466866493225098,
      "rewards/margins": 6.992578506469727,
      "rewards/rejected": -5.445892333984375,
      "step": 1625
    },
    {
      "epoch": 0.6504,
      "grad_norm": 0.004760621581226587,
      "learning_rate": 7.833333333333333e-07,
      "logits/chosen": -2.3441545963287354,
      "logits/rejected": -3.1514813899993896,
      "logps/chosen": -118.860595703125,
      "logps/rejected": -222.7657470703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.870718002319336,
      "rewards/margins": 10.294673919677734,
      "rewards/rejected": -6.423956394195557,
      "step": 1626
    },
    {
      "epoch": 0.6508,
      "grad_norm": 0.011230726726353168,
      "learning_rate": 7.832e-07,
      "logits/chosen": -2.1964640617370605,
      "logits/rejected": -2.924053192138672,
      "logps/chosen": -117.86634826660156,
      "logps/rejected": -147.11062622070312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.468371391296387,
      "rewards/margins": 9.199590682983398,
      "rewards/rejected": -4.7312188148498535,
      "step": 1627
    },
    {
      "epoch": 0.6512,
      "grad_norm": 0.22401948273181915,
      "learning_rate": 7.830666666666667e-07,
      "logits/chosen": -2.6643619537353516,
      "logits/rejected": -2.32889986038208,
      "logps/chosen": -119.28306579589844,
      "logps/rejected": -111.4485092163086,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.092806339263916,
      "rewards/margins": 6.29434871673584,
      "rewards/rejected": -3.2015421390533447,
      "step": 1628
    },
    {
      "epoch": 0.6516,
      "grad_norm": 1.4091233015060425,
      "learning_rate": 7.829333333333334e-07,
      "logits/chosen": -2.3002841472625732,
      "logits/rejected": -3.581714391708374,
      "logps/chosen": -242.4056854248047,
      "logps/rejected": -153.24917602539062,
      "loss": 0.0113,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4070793092250824,
      "rewards/margins": 4.6653852462768555,
      "rewards/rejected": -5.072464466094971,
      "step": 1629
    },
    {
      "epoch": 0.652,
      "grad_norm": 0.02757025510072708,
      "learning_rate": 7.828e-07,
      "logits/chosen": -2.214744806289673,
      "logits/rejected": -3.6324896812438965,
      "logps/chosen": -65.07907104492188,
      "logps/rejected": -158.55807495117188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8033344745635986,
      "rewards/margins": 9.04654598236084,
      "rewards/rejected": -5.24321174621582,
      "step": 1630
    },
    {
      "epoch": 0.6524,
      "grad_norm": 0.0627841204404831,
      "learning_rate": 7.826666666666666e-07,
      "logits/chosen": -2.5286805629730225,
      "logits/rejected": -2.650869369506836,
      "logps/chosen": -147.39108276367188,
      "logps/rejected": -192.80035400390625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.033937931060791,
      "rewards/margins": 7.495713233947754,
      "rewards/rejected": -5.461775302886963,
      "step": 1631
    },
    {
      "epoch": 0.6528,
      "grad_norm": 0.07879886031150818,
      "learning_rate": 7.825333333333332e-07,
      "logits/chosen": -1.9841489791870117,
      "logits/rejected": -2.564124584197998,
      "logps/chosen": -72.71775817871094,
      "logps/rejected": -136.04718017578125,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6156253814697266,
      "rewards/margins": 8.362557411193848,
      "rewards/rejected": -4.746932029724121,
      "step": 1632
    },
    {
      "epoch": 0.6532,
      "grad_norm": 0.03315444663167,
      "learning_rate": 7.823999999999999e-07,
      "logits/chosen": -1.8146419525146484,
      "logits/rejected": -3.15981388092041,
      "logps/chosen": -88.42250061035156,
      "logps/rejected": -155.5806884765625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.897284507751465,
      "rewards/margins": 9.203786849975586,
      "rewards/rejected": -5.306501865386963,
      "step": 1633
    },
    {
      "epoch": 0.6536,
      "grad_norm": 0.12381255626678467,
      "learning_rate": 7.822666666666666e-07,
      "logits/chosen": -2.252689838409424,
      "logits/rejected": -3.039522171020508,
      "logps/chosen": -66.8321533203125,
      "logps/rejected": -136.58514404296875,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.587573289871216,
      "rewards/margins": 6.719754695892334,
      "rewards/rejected": -4.132181167602539,
      "step": 1634
    },
    {
      "epoch": 0.654,
      "grad_norm": 2.7642757892608643,
      "learning_rate": 7.821333333333333e-07,
      "logits/chosen": -1.8781417608261108,
      "logits/rejected": -3.122058868408203,
      "logps/chosen": -88.10910034179688,
      "logps/rejected": -125.7797622680664,
      "loss": 0.0306,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5120040774345398,
      "rewards/margins": 3.491986036300659,
      "rewards/rejected": -2.9799818992614746,
      "step": 1635
    },
    {
      "epoch": 0.6544,
      "grad_norm": 0.037841737270355225,
      "learning_rate": 7.82e-07,
      "logits/chosen": -1.7782163619995117,
      "logits/rejected": -3.116879940032959,
      "logps/chosen": -124.59231567382812,
      "logps/rejected": -157.84954833984375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.823862075805664,
      "rewards/margins": 8.302428245544434,
      "rewards/rejected": -4.4785661697387695,
      "step": 1636
    },
    {
      "epoch": 0.6548,
      "grad_norm": 0.857978105545044,
      "learning_rate": 7.818666666666667e-07,
      "logits/chosen": -1.974729061126709,
      "logits/rejected": -2.675748348236084,
      "logps/chosen": -74.71407318115234,
      "logps/rejected": -120.92118835449219,
      "loss": 0.0078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5435066223144531,
      "rewards/margins": 4.848196983337402,
      "rewards/rejected": -4.304690361022949,
      "step": 1637
    },
    {
      "epoch": 0.6552,
      "grad_norm": 0.017218466848134995,
      "learning_rate": 7.817333333333333e-07,
      "logits/chosen": -2.3128790855407715,
      "logits/rejected": -3.4534263610839844,
      "logps/chosen": -87.68852233886719,
      "logps/rejected": -169.55511474609375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.964827060699463,
      "rewards/margins": 8.748693466186523,
      "rewards/rejected": -5.783866882324219,
      "step": 1638
    },
    {
      "epoch": 0.6556,
      "grad_norm": 0.6922194361686707,
      "learning_rate": 7.816e-07,
      "logits/chosen": -2.1327552795410156,
      "logits/rejected": -2.5283031463623047,
      "logps/chosen": -100.01567077636719,
      "logps/rejected": -227.48121643066406,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.511775493621826,
      "rewards/margins": 6.112485885620117,
      "rewards/rejected": -3.600709915161133,
      "step": 1639
    },
    {
      "epoch": 0.656,
      "grad_norm": 1.4447259902954102,
      "learning_rate": 7.814666666666666e-07,
      "logits/chosen": -2.256683588027954,
      "logits/rejected": -2.8944015502929688,
      "logps/chosen": -125.63274383544922,
      "logps/rejected": -118.74714660644531,
      "loss": 0.0122,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.64732825756073,
      "rewards/margins": 5.574462890625,
      "rewards/rejected": -3.9271347522735596,
      "step": 1640
    },
    {
      "epoch": 0.6564,
      "grad_norm": 0.01417080219835043,
      "learning_rate": 7.813333333333332e-07,
      "logits/chosen": -2.5065219402313232,
      "logits/rejected": -3.5684213638305664,
      "logps/chosen": -137.47894287109375,
      "logps/rejected": -162.81253051757812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.627887725830078,
      "rewards/margins": 8.823881149291992,
      "rewards/rejected": -5.195993423461914,
      "step": 1641
    },
    {
      "epoch": 0.6568,
      "grad_norm": 0.09935501962900162,
      "learning_rate": 7.811999999999999e-07,
      "logits/chosen": -2.243257522583008,
      "logits/rejected": -3.0896010398864746,
      "logps/chosen": -75.5925521850586,
      "logps/rejected": -118.12019348144531,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3531126976013184,
      "rewards/margins": 7.573737144470215,
      "rewards/rejected": -4.220623970031738,
      "step": 1642
    },
    {
      "epoch": 0.6572,
      "grad_norm": 0.3160841763019562,
      "learning_rate": 7.810666666666666e-07,
      "logits/chosen": -2.6856865882873535,
      "logits/rejected": -3.4428772926330566,
      "logps/chosen": -198.75726318359375,
      "logps/rejected": -162.51124572753906,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9307701587677002,
      "rewards/margins": 5.774322509765625,
      "rewards/rejected": -4.843552589416504,
      "step": 1643
    },
    {
      "epoch": 0.6576,
      "grad_norm": 0.180815652012825,
      "learning_rate": 7.809333333333333e-07,
      "logits/chosen": -2.4585530757904053,
      "logits/rejected": -2.3197779655456543,
      "logps/chosen": -90.29425048828125,
      "logps/rejected": -129.80850219726562,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0155866146087646,
      "rewards/margins": 7.379302024841309,
      "rewards/rejected": -4.363715171813965,
      "step": 1644
    },
    {
      "epoch": 0.658,
      "grad_norm": 0.9483364224433899,
      "learning_rate": 7.808e-07,
      "logits/chosen": -2.448298454284668,
      "logits/rejected": -2.914353609085083,
      "logps/chosen": -108.19003295898438,
      "logps/rejected": -127.95740509033203,
      "loss": 0.0067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5296499729156494,
      "rewards/margins": 6.468925476074219,
      "rewards/rejected": -3.9392757415771484,
      "step": 1645
    },
    {
      "epoch": 0.6584,
      "grad_norm": 0.053976353257894516,
      "learning_rate": 7.806666666666666e-07,
      "logits/chosen": -2.406883716583252,
      "logits/rejected": -3.515089511871338,
      "logps/chosen": -118.71038055419922,
      "logps/rejected": -159.47378540039062,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7954845428466797,
      "rewards/margins": 7.601095199584961,
      "rewards/rejected": -5.805610179901123,
      "step": 1646
    },
    {
      "epoch": 0.6588,
      "grad_norm": 0.1431543231010437,
      "learning_rate": 7.805333333333333e-07,
      "logits/chosen": -2.391329526901245,
      "logits/rejected": -3.189436674118042,
      "logps/chosen": -174.47860717773438,
      "logps/rejected": -142.7582244873047,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9483181238174438,
      "rewards/margins": 7.019730091094971,
      "rewards/rejected": -5.071412086486816,
      "step": 1647
    },
    {
      "epoch": 0.6592,
      "grad_norm": 0.7263720631599426,
      "learning_rate": 7.804e-07,
      "logits/chosen": -2.724196434020996,
      "logits/rejected": -3.3155155181884766,
      "logps/chosen": -204.82777404785156,
      "logps/rejected": -139.51568603515625,
      "loss": 0.0067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1747055053710938,
      "rewards/margins": 5.565354824066162,
      "rewards/rejected": -3.3906493186950684,
      "step": 1648
    },
    {
      "epoch": 0.6596,
      "grad_norm": 0.127239391207695,
      "learning_rate": 7.802666666666667e-07,
      "logits/chosen": -2.193514823913574,
      "logits/rejected": -2.8222923278808594,
      "logps/chosen": -79.27296447753906,
      "logps/rejected": -142.66854858398438,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6620213985443115,
      "rewards/margins": 7.215683937072754,
      "rewards/rejected": -4.553662300109863,
      "step": 1649
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.41838735342025757,
      "learning_rate": 7.801333333333334e-07,
      "logits/chosen": -2.101771593093872,
      "logits/rejected": -2.724825382232666,
      "logps/chosen": -104.4151611328125,
      "logps/rejected": -118.35940551757812,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5656135082244873,
      "rewards/margins": 6.388290882110596,
      "rewards/rejected": -3.8226771354675293,
      "step": 1650
    },
    {
      "epoch": 0.6604,
      "grad_norm": 0.3373362421989441,
      "learning_rate": 7.799999999999999e-07,
      "logits/chosen": -2.405599594116211,
      "logits/rejected": -2.968543529510498,
      "logps/chosen": -106.83419799804688,
      "logps/rejected": -117.97721862792969,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2206201553344727,
      "rewards/margins": 7.851889610290527,
      "rewards/rejected": -4.631269454956055,
      "step": 1651
    },
    {
      "epoch": 0.6608,
      "grad_norm": 0.2679584324359894,
      "learning_rate": 7.798666666666666e-07,
      "logits/chosen": -2.2158989906311035,
      "logits/rejected": -3.1942901611328125,
      "logps/chosen": -97.32315063476562,
      "logps/rejected": -183.55831909179688,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8441959619522095,
      "rewards/margins": 6.713624477386475,
      "rewards/rejected": -5.869428634643555,
      "step": 1652
    },
    {
      "epoch": 0.6612,
      "grad_norm": 0.17044992744922638,
      "learning_rate": 7.797333333333332e-07,
      "logits/chosen": -2.3832902908325195,
      "logits/rejected": -3.2653748989105225,
      "logps/chosen": -123.5593490600586,
      "logps/rejected": -122.39752197265625,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0723118782043457,
      "rewards/margins": 7.038197040557861,
      "rewards/rejected": -3.9658851623535156,
      "step": 1653
    },
    {
      "epoch": 0.6616,
      "grad_norm": 0.7765957713127136,
      "learning_rate": 7.795999999999999e-07,
      "logits/chosen": -2.764435291290283,
      "logits/rejected": -3.12054443359375,
      "logps/chosen": -144.6914825439453,
      "logps/rejected": -144.52816772460938,
      "loss": 0.0078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0156128406524658,
      "rewards/margins": 5.4547119140625,
      "rewards/rejected": -4.439098834991455,
      "step": 1654
    },
    {
      "epoch": 0.662,
      "grad_norm": 0.05132583528757095,
      "learning_rate": 7.794666666666666e-07,
      "logits/chosen": -1.9417117834091187,
      "logits/rejected": -3.345527410507202,
      "logps/chosen": -71.64856719970703,
      "logps/rejected": -121.20915985107422,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.566222667694092,
      "rewards/margins": 7.949080944061279,
      "rewards/rejected": -4.3828582763671875,
      "step": 1655
    },
    {
      "epoch": 0.6624,
      "grad_norm": 0.5083946585655212,
      "learning_rate": 7.793333333333333e-07,
      "logits/chosen": -2.3451812267303467,
      "logits/rejected": -3.087789535522461,
      "logps/chosen": -132.19940185546875,
      "logps/rejected": -173.3503875732422,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5767813920974731,
      "rewards/margins": 6.517077445983887,
      "rewards/rejected": -4.940296173095703,
      "step": 1656
    },
    {
      "epoch": 0.6628,
      "grad_norm": 0.3299896717071533,
      "learning_rate": 7.792e-07,
      "logits/chosen": -2.2201006412506104,
      "logits/rejected": -3.2190299034118652,
      "logps/chosen": -168.6922607421875,
      "logps/rejected": -150.89122009277344,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1878219842910767,
      "rewards/margins": 6.320207595825195,
      "rewards/rejected": -5.13238525390625,
      "step": 1657
    },
    {
      "epoch": 0.6632,
      "grad_norm": 18.111032485961914,
      "learning_rate": 7.790666666666667e-07,
      "logits/chosen": -2.5378048419952393,
      "logits/rejected": -2.7144017219543457,
      "logps/chosen": -185.03366088867188,
      "logps/rejected": -107.88408660888672,
      "loss": 0.141,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.07719874382019043,
      "rewards/margins": 3.1730244159698486,
      "rewards/rejected": -3.095825672149658,
      "step": 1658
    },
    {
      "epoch": 0.6636,
      "grad_norm": 0.1947418600320816,
      "learning_rate": 7.789333333333334e-07,
      "logits/chosen": -1.8764426708221436,
      "logits/rejected": -3.0986948013305664,
      "logps/chosen": -92.34091186523438,
      "logps/rejected": -150.38365173339844,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9609241485595703,
      "rewards/margins": 7.317155838012695,
      "rewards/rejected": -5.356231689453125,
      "step": 1659
    },
    {
      "epoch": 0.664,
      "grad_norm": 1.355668067932129,
      "learning_rate": 7.788000000000001e-07,
      "logits/chosen": -2.1970410346984863,
      "logits/rejected": -3.054539203643799,
      "logps/chosen": -164.06439208984375,
      "logps/rejected": -150.69448852539062,
      "loss": 0.0141,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3274040222167969,
      "rewards/margins": 5.631516456604004,
      "rewards/rejected": -4.304112434387207,
      "step": 1660
    },
    {
      "epoch": 0.6644,
      "grad_norm": 0.01983722299337387,
      "learning_rate": 7.786666666666665e-07,
      "logits/chosen": -2.385721206665039,
      "logits/rejected": -3.172213315963745,
      "logps/chosen": -82.275634765625,
      "logps/rejected": -147.86260986328125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.883851051330566,
      "rewards/margins": 9.29470443725586,
      "rewards/rejected": -4.410852432250977,
      "step": 1661
    },
    {
      "epoch": 0.6648,
      "grad_norm": 0.028262147679924965,
      "learning_rate": 7.785333333333332e-07,
      "logits/chosen": -2.057861566543579,
      "logits/rejected": -3.0221176147460938,
      "logps/chosen": -69.04029846191406,
      "logps/rejected": -121.64869689941406,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.777655839920044,
      "rewards/margins": 8.084125518798828,
      "rewards/rejected": -4.306469440460205,
      "step": 1662
    },
    {
      "epoch": 0.6652,
      "grad_norm": 3.3300063610076904,
      "learning_rate": 7.783999999999999e-07,
      "logits/chosen": -2.035388946533203,
      "logits/rejected": -3.0292282104492188,
      "logps/chosen": -139.0419464111328,
      "logps/rejected": -127.63134765625,
      "loss": 0.0261,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.49055445194244385,
      "rewards/margins": 4.061976432800293,
      "rewards/rejected": -3.5714218616485596,
      "step": 1663
    },
    {
      "epoch": 0.6656,
      "grad_norm": 0.4516476094722748,
      "learning_rate": 7.782666666666666e-07,
      "logits/chosen": -2.341928005218506,
      "logits/rejected": -3.2521121501922607,
      "logps/chosen": -152.9445343017578,
      "logps/rejected": -155.42782592773438,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.186811923980713,
      "rewards/margins": 7.31027889251709,
      "rewards/rejected": -5.123466968536377,
      "step": 1664
    },
    {
      "epoch": 0.666,
      "grad_norm": 0.02701679803431034,
      "learning_rate": 7.781333333333333e-07,
      "logits/chosen": -2.9348442554473877,
      "logits/rejected": -3.680130958557129,
      "logps/chosen": -188.50103759765625,
      "logps/rejected": -167.59634399414062,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1751770973205566,
      "rewards/margins": 8.30111026763916,
      "rewards/rejected": -5.1259331703186035,
      "step": 1665
    },
    {
      "epoch": 0.6664,
      "grad_norm": 2.2578911781311035,
      "learning_rate": 7.78e-07,
      "logits/chosen": -2.950505018234253,
      "logits/rejected": -3.3045847415924072,
      "logps/chosen": -166.005615234375,
      "logps/rejected": -151.97525024414062,
      "loss": 0.0187,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0026390552520752,
      "rewards/margins": 5.302482604980469,
      "rewards/rejected": -4.2998433113098145,
      "step": 1666
    },
    {
      "epoch": 0.6668,
      "grad_norm": 0.03647501394152641,
      "learning_rate": 7.778666666666667e-07,
      "logits/chosen": -2.0617940425872803,
      "logits/rejected": -2.6663994789123535,
      "logps/chosen": -157.70416259765625,
      "logps/rejected": -202.50689697265625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5933220386505127,
      "rewards/margins": 8.940571784973145,
      "rewards/rejected": -7.347249507904053,
      "step": 1667
    },
    {
      "epoch": 0.6672,
      "grad_norm": 0.048642467707395554,
      "learning_rate": 7.777333333333334e-07,
      "logits/chosen": -1.6022429466247559,
      "logits/rejected": -2.7412288188934326,
      "logps/chosen": -51.78916549682617,
      "logps/rejected": -115.58712005615234,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.001575469970703,
      "rewards/margins": 7.561555862426758,
      "rewards/rejected": -3.559980869293213,
      "step": 1668
    },
    {
      "epoch": 0.6676,
      "grad_norm": 0.08893756568431854,
      "learning_rate": 7.776e-07,
      "logits/chosen": -2.565876007080078,
      "logits/rejected": -2.9830541610717773,
      "logps/chosen": -159.02700805664062,
      "logps/rejected": -158.79205322265625,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9319849014282227,
      "rewards/margins": 7.356407642364502,
      "rewards/rejected": -4.4244232177734375,
      "step": 1669
    },
    {
      "epoch": 0.668,
      "grad_norm": 0.1050974503159523,
      "learning_rate": 7.774666666666666e-07,
      "logits/chosen": -2.752436399459839,
      "logits/rejected": -3.0169780254364014,
      "logps/chosen": -182.35830688476562,
      "logps/rejected": -190.84812927246094,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.103186845779419,
      "rewards/margins": 7.865735054016113,
      "rewards/rejected": -5.762548446655273,
      "step": 1670
    },
    {
      "epoch": 0.6684,
      "grad_norm": 0.06676384806632996,
      "learning_rate": 7.773333333333333e-07,
      "logits/chosen": -2.286705732345581,
      "logits/rejected": -3.1062021255493164,
      "logps/chosen": -162.662353515625,
      "logps/rejected": -167.5512237548828,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.57509708404541,
      "rewards/margins": 8.288423538208008,
      "rewards/rejected": -5.713326454162598,
      "step": 1671
    },
    {
      "epoch": 0.6688,
      "grad_norm": 0.13251358270645142,
      "learning_rate": 7.771999999999999e-07,
      "logits/chosen": -1.9400923252105713,
      "logits/rejected": -3.0150463581085205,
      "logps/chosen": -90.18043518066406,
      "logps/rejected": -129.6532440185547,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9696838855743408,
      "rewards/margins": 6.9412736892700195,
      "rewards/rejected": -4.971589088439941,
      "step": 1672
    },
    {
      "epoch": 0.6692,
      "grad_norm": 0.44935524463653564,
      "learning_rate": 7.770666666666666e-07,
      "logits/chosen": -2.1395318508148193,
      "logits/rejected": -2.546384334564209,
      "logps/chosen": -70.34144592285156,
      "logps/rejected": -119.34503173828125,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3588993549346924,
      "rewards/margins": 6.889975070953369,
      "rewards/rejected": -4.531075954437256,
      "step": 1673
    },
    {
      "epoch": 0.6696,
      "grad_norm": 0.1283394992351532,
      "learning_rate": 7.769333333333333e-07,
      "logits/chosen": -2.18225359916687,
      "logits/rejected": -3.458904266357422,
      "logps/chosen": -116.33403015136719,
      "logps/rejected": -185.1268310546875,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8534579873085022,
      "rewards/margins": 6.76873779296875,
      "rewards/rejected": -5.915279865264893,
      "step": 1674
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.20606741309165955,
      "learning_rate": 7.768e-07,
      "logits/chosen": -1.7690082788467407,
      "logits/rejected": -2.870728015899658,
      "logps/chosen": -134.23764038085938,
      "logps/rejected": -161.36270141601562,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.933073878288269,
      "rewards/margins": 6.877630233764648,
      "rewards/rejected": -4.944556713104248,
      "step": 1675
    },
    {
      "epoch": 0.6704,
      "grad_norm": 0.388211727142334,
      "learning_rate": 7.766666666666666e-07,
      "logits/chosen": -2.5685462951660156,
      "logits/rejected": -3.0781140327453613,
      "logps/chosen": -111.0574951171875,
      "logps/rejected": -142.78807067871094,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.445720911026001,
      "rewards/margins": 6.225537300109863,
      "rewards/rejected": -3.7798166275024414,
      "step": 1676
    },
    {
      "epoch": 0.6708,
      "grad_norm": 3.4261505603790283,
      "learning_rate": 7.765333333333333e-07,
      "logits/chosen": -2.3610668182373047,
      "logits/rejected": -2.1420435905456543,
      "logps/chosen": -149.05369567871094,
      "logps/rejected": -128.94308471679688,
      "loss": 0.0287,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2632591128349304,
      "rewards/margins": 4.689440727233887,
      "rewards/rejected": -4.952700138092041,
      "step": 1677
    },
    {
      "epoch": 0.6712,
      "grad_norm": 0.6772450804710388,
      "learning_rate": 7.764e-07,
      "logits/chosen": -2.3528494834899902,
      "logits/rejected": -2.7267138957977295,
      "logps/chosen": -199.06094360351562,
      "logps/rejected": -142.15501403808594,
      "loss": 0.0075,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8732507228851318,
      "rewards/margins": 4.899517059326172,
      "rewards/rejected": -3.026266098022461,
      "step": 1678
    },
    {
      "epoch": 0.6716,
      "grad_norm": 1.9406459331512451,
      "learning_rate": 7.762666666666666e-07,
      "logits/chosen": -2.7968499660491943,
      "logits/rejected": -3.348564386367798,
      "logps/chosen": -223.798583984375,
      "logps/rejected": -136.7270965576172,
      "loss": 0.0173,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9330864548683167,
      "rewards/margins": 5.049017906188965,
      "rewards/rejected": -4.115931510925293,
      "step": 1679
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.04715009406208992,
      "learning_rate": 7.761333333333333e-07,
      "logits/chosen": -2.2152178287506104,
      "logits/rejected": -3.3208580017089844,
      "logps/chosen": -140.89813232421875,
      "logps/rejected": -161.80767822265625,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.489441394805908,
      "rewards/margins": 7.588922023773193,
      "rewards/rejected": -5.099480628967285,
      "step": 1680
    },
    {
      "epoch": 0.6724,
      "grad_norm": 0.5751269459724426,
      "learning_rate": 7.76e-07,
      "logits/chosen": -2.1894516944885254,
      "logits/rejected": -3.5541746616363525,
      "logps/chosen": -138.3654327392578,
      "logps/rejected": -157.53285217285156,
      "loss": 0.0067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9977371692657471,
      "rewards/margins": 5.248218059539795,
      "rewards/rejected": -4.250481128692627,
      "step": 1681
    },
    {
      "epoch": 0.6728,
      "grad_norm": 0.58514004945755,
      "learning_rate": 7.758666666666667e-07,
      "logits/chosen": -2.0727715492248535,
      "logits/rejected": -2.8433659076690674,
      "logps/chosen": -96.4144515991211,
      "logps/rejected": -130.25967407226562,
      "loss": 0.0049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.052638292312622,
      "rewards/margins": 5.453490257263184,
      "rewards/rejected": -3.4008517265319824,
      "step": 1682
    },
    {
      "epoch": 0.6732,
      "grad_norm": 1.004526972770691,
      "learning_rate": 7.757333333333333e-07,
      "logits/chosen": -2.5580222606658936,
      "logits/rejected": -4.106906890869141,
      "logps/chosen": -238.94532775878906,
      "logps/rejected": -173.46212768554688,
      "loss": 0.0115,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8233924508094788,
      "rewards/margins": 5.943251609802246,
      "rewards/rejected": -5.11985969543457,
      "step": 1683
    },
    {
      "epoch": 0.6736,
      "grad_norm": 1.7113628387451172,
      "learning_rate": 7.755999999999999e-07,
      "logits/chosen": -2.08933162689209,
      "logits/rejected": -2.858919620513916,
      "logps/chosen": -99.50758361816406,
      "logps/rejected": -117.48294830322266,
      "loss": 0.0203,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7704654932022095,
      "rewards/margins": 4.567752361297607,
      "rewards/rejected": -3.7972867488861084,
      "step": 1684
    },
    {
      "epoch": 0.674,
      "grad_norm": 0.45393189787864685,
      "learning_rate": 7.754666666666666e-07,
      "logits/chosen": -2.2888431549072266,
      "logits/rejected": -3.3088011741638184,
      "logps/chosen": -137.89486694335938,
      "logps/rejected": -173.4217987060547,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1529542207717896,
      "rewards/margins": 6.847062587738037,
      "rewards/rejected": -5.694108009338379,
      "step": 1685
    },
    {
      "epoch": 0.6744,
      "grad_norm": 0.3423803746700287,
      "learning_rate": 7.753333333333333e-07,
      "logits/chosen": -2.6201815605163574,
      "logits/rejected": -3.1357836723327637,
      "logps/chosen": -125.28517150878906,
      "logps/rejected": -154.9192657470703,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.297478675842285,
      "rewards/margins": 6.289106369018555,
      "rewards/rejected": -2.9916276931762695,
      "step": 1686
    },
    {
      "epoch": 0.6748,
      "grad_norm": 0.10773692280054092,
      "learning_rate": 7.752e-07,
      "logits/chosen": -2.396240472793579,
      "logits/rejected": -2.9906368255615234,
      "logps/chosen": -131.03237915039062,
      "logps/rejected": -231.9273681640625,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9044806957244873,
      "rewards/margins": 8.684650421142578,
      "rewards/rejected": -5.780170440673828,
      "step": 1687
    },
    {
      "epoch": 0.6752,
      "grad_norm": 0.047141630202531815,
      "learning_rate": 7.750666666666667e-07,
      "logits/chosen": -2.423048257827759,
      "logits/rejected": -2.991793155670166,
      "logps/chosen": -225.9501953125,
      "logps/rejected": -140.0639190673828,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.829934597015381,
      "rewards/margins": 7.799135208129883,
      "rewards/rejected": -4.969200134277344,
      "step": 1688
    },
    {
      "epoch": 0.6756,
      "grad_norm": 6.018564224243164,
      "learning_rate": 7.749333333333333e-07,
      "logits/chosen": -1.930124282836914,
      "logits/rejected": -2.9510397911071777,
      "logps/chosen": -101.66926574707031,
      "logps/rejected": -111.83617401123047,
      "loss": 0.043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2835559844970703,
      "rewards/margins": 4.805098533630371,
      "rewards/rejected": -3.52154278755188,
      "step": 1689
    },
    {
      "epoch": 0.676,
      "grad_norm": 0.40942099690437317,
      "learning_rate": 7.748e-07,
      "logits/chosen": -1.7459993362426758,
      "logits/rejected": -3.591679096221924,
      "logps/chosen": -120.76473999023438,
      "logps/rejected": -160.2813262939453,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.345280170440674,
      "rewards/margins": 7.698883056640625,
      "rewards/rejected": -5.353603363037109,
      "step": 1690
    },
    {
      "epoch": 0.6764,
      "grad_norm": 0.35635653138160706,
      "learning_rate": 7.746666666666666e-07,
      "logits/chosen": -2.1719579696655273,
      "logits/rejected": -3.031372547149658,
      "logps/chosen": -114.41127014160156,
      "logps/rejected": -145.4789276123047,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1590218544006348,
      "rewards/margins": 5.574959754943848,
      "rewards/rejected": -3.415937900543213,
      "step": 1691
    },
    {
      "epoch": 0.6768,
      "grad_norm": 0.049987051635980606,
      "learning_rate": 7.745333333333333e-07,
      "logits/chosen": -1.367135763168335,
      "logits/rejected": -3.473323345184326,
      "logps/chosen": -77.5490493774414,
      "logps/rejected": -155.27999877929688,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9307498931884766,
      "rewards/margins": 8.282011985778809,
      "rewards/rejected": -5.351262092590332,
      "step": 1692
    },
    {
      "epoch": 0.6772,
      "grad_norm": 0.03120533563196659,
      "learning_rate": 7.743999999999999e-07,
      "logits/chosen": -2.1283040046691895,
      "logits/rejected": -3.5662097930908203,
      "logps/chosen": -194.77734375,
      "logps/rejected": -145.45204162597656,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.158640384674072,
      "rewards/margins": 8.963018417358398,
      "rewards/rejected": -4.804378509521484,
      "step": 1693
    },
    {
      "epoch": 0.6776,
      "grad_norm": 0.18684495985507965,
      "learning_rate": 7.742666666666666e-07,
      "logits/chosen": -1.8952617645263672,
      "logits/rejected": -4.041790962219238,
      "logps/chosen": -97.85244750976562,
      "logps/rejected": -152.06593322753906,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9352684020996094,
      "rewards/margins": 7.341174125671387,
      "rewards/rejected": -5.405905723571777,
      "step": 1694
    },
    {
      "epoch": 0.678,
      "grad_norm": 0.1783580482006073,
      "learning_rate": 7.741333333333333e-07,
      "logits/chosen": -2.1149790287017822,
      "logits/rejected": -2.9106252193450928,
      "logps/chosen": -104.29463195800781,
      "logps/rejected": -133.89126586914062,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.145059108734131,
      "rewards/margins": 6.686383247375488,
      "rewards/rejected": -4.541323661804199,
      "step": 1695
    },
    {
      "epoch": 0.6784,
      "grad_norm": 0.03243347629904747,
      "learning_rate": 7.74e-07,
      "logits/chosen": -2.2389800548553467,
      "logits/rejected": -3.046998977661133,
      "logps/chosen": -130.175537109375,
      "logps/rejected": -146.6099395751953,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.219326972961426,
      "rewards/margins": 7.92462158203125,
      "rewards/rejected": -4.705294609069824,
      "step": 1696
    },
    {
      "epoch": 0.6788,
      "grad_norm": 0.016522899270057678,
      "learning_rate": 7.738666666666667e-07,
      "logits/chosen": -2.395629405975342,
      "logits/rejected": -2.586517810821533,
      "logps/chosen": -140.5134735107422,
      "logps/rejected": -153.81884765625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3843681812286377,
      "rewards/margins": 8.878250122070312,
      "rewards/rejected": -5.4938812255859375,
      "step": 1697
    },
    {
      "epoch": 0.6792,
      "grad_norm": 0.013479702174663544,
      "learning_rate": 7.737333333333333e-07,
      "logits/chosen": -2.461648464202881,
      "logits/rejected": -3.251767635345459,
      "logps/chosen": -148.85617065429688,
      "logps/rejected": -179.12574768066406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.927093505859375,
      "rewards/margins": 9.093276023864746,
      "rewards/rejected": -5.166182518005371,
      "step": 1698
    },
    {
      "epoch": 0.6796,
      "grad_norm": 0.23650918900966644,
      "learning_rate": 7.735999999999999e-07,
      "logits/chosen": -2.5078988075256348,
      "logits/rejected": -3.5501794815063477,
      "logps/chosen": -147.1337890625,
      "logps/rejected": -194.0235595703125,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1613197326660156,
      "rewards/margins": 8.060464859008789,
      "rewards/rejected": -6.899145126342773,
      "step": 1699
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.020771773532032967,
      "learning_rate": 7.734666666666666e-07,
      "logits/chosen": -2.4102044105529785,
      "logits/rejected": -2.830634117126465,
      "logps/chosen": -145.348388671875,
      "logps/rejected": -199.59498596191406,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5853018760681152,
      "rewards/margins": 8.559510231018066,
      "rewards/rejected": -4.974208354949951,
      "step": 1700
    },
    {
      "epoch": 0.6804,
      "grad_norm": 0.9913546442985535,
      "learning_rate": 7.733333333333333e-07,
      "logits/chosen": -1.9600706100463867,
      "logits/rejected": -2.351149559020996,
      "logps/chosen": -89.03399658203125,
      "logps/rejected": -131.69334411621094,
      "loss": 0.0077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9336986541748047,
      "rewards/margins": 6.46804141998291,
      "rewards/rejected": -4.534343242645264,
      "step": 1701
    },
    {
      "epoch": 0.6808,
      "grad_norm": 0.6391534209251404,
      "learning_rate": 7.732e-07,
      "logits/chosen": -2.1711010932922363,
      "logits/rejected": -2.8048832416534424,
      "logps/chosen": -121.26219177246094,
      "logps/rejected": -149.01583862304688,
      "loss": 0.0062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8867884874343872,
      "rewards/margins": 5.943362236022949,
      "rewards/rejected": -5.056573867797852,
      "step": 1702
    },
    {
      "epoch": 0.6812,
      "grad_norm": 0.026302605867385864,
      "learning_rate": 7.730666666666667e-07,
      "logits/chosen": -2.4868319034576416,
      "logits/rejected": -3.432804584503174,
      "logps/chosen": -104.40080261230469,
      "logps/rejected": -186.26434326171875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.919724941253662,
      "rewards/margins": 8.865161895751953,
      "rewards/rejected": -4.945437431335449,
      "step": 1703
    },
    {
      "epoch": 0.6816,
      "grad_norm": 0.11900916695594788,
      "learning_rate": 7.729333333333333e-07,
      "logits/chosen": -2.7280592918395996,
      "logits/rejected": -3.2933285236358643,
      "logps/chosen": -167.67002868652344,
      "logps/rejected": -131.93331909179688,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9256486892700195,
      "rewards/margins": 7.353374481201172,
      "rewards/rejected": -3.4277255535125732,
      "step": 1704
    },
    {
      "epoch": 0.682,
      "grad_norm": 0.1231059655547142,
      "learning_rate": 7.728e-07,
      "logits/chosen": -2.4851598739624023,
      "logits/rejected": -3.290649175643921,
      "logps/chosen": -144.4374237060547,
      "logps/rejected": -148.70718383789062,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8200607299804688,
      "rewards/margins": 6.97769832611084,
      "rewards/rejected": -4.157637596130371,
      "step": 1705
    },
    {
      "epoch": 0.6824,
      "grad_norm": 0.2719235420227051,
      "learning_rate": 7.726666666666666e-07,
      "logits/chosen": -2.7337446212768555,
      "logits/rejected": -3.4661622047424316,
      "logps/chosen": -177.7454071044922,
      "logps/rejected": -160.58328247070312,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7877098321914673,
      "rewards/margins": 6.272551536560059,
      "rewards/rejected": -5.484841346740723,
      "step": 1706
    },
    {
      "epoch": 0.6828,
      "grad_norm": 0.009807956404983997,
      "learning_rate": 7.725333333333332e-07,
      "logits/chosen": -2.6772661209106445,
      "logits/rejected": -3.2333078384399414,
      "logps/chosen": -133.09701538085938,
      "logps/rejected": -212.740478515625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.490880012512207,
      "rewards/margins": 9.570700645446777,
      "rewards/rejected": -5.07982063293457,
      "step": 1707
    },
    {
      "epoch": 0.6832,
      "grad_norm": 3.671356201171875,
      "learning_rate": 7.723999999999999e-07,
      "logits/chosen": -2.2608461380004883,
      "logits/rejected": -2.7273309230804443,
      "logps/chosen": -120.41322326660156,
      "logps/rejected": -113.48828887939453,
      "loss": 0.0396,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1178600788116455,
      "rewards/margins": 4.133201599121094,
      "rewards/rejected": -3.0153417587280273,
      "step": 1708
    },
    {
      "epoch": 0.6836,
      "grad_norm": 0.010376556776463985,
      "learning_rate": 7.722666666666666e-07,
      "logits/chosen": -2.0427727699279785,
      "logits/rejected": -2.543288230895996,
      "logps/chosen": -88.70684051513672,
      "logps/rejected": -199.20245361328125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.239686012268066,
      "rewards/margins": 9.824579238891602,
      "rewards/rejected": -5.584892749786377,
      "step": 1709
    },
    {
      "epoch": 0.684,
      "grad_norm": 0.07697370648384094,
      "learning_rate": 7.721333333333333e-07,
      "logits/chosen": -2.2888596057891846,
      "logits/rejected": -2.7312004566192627,
      "logps/chosen": -83.48712158203125,
      "logps/rejected": -124.87745666503906,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8186678886413574,
      "rewards/margins": 7.9283647537231445,
      "rewards/rejected": -5.109696388244629,
      "step": 1710
    },
    {
      "epoch": 0.6844,
      "grad_norm": 0.7417539358139038,
      "learning_rate": 7.72e-07,
      "logits/chosen": -2.486520290374756,
      "logits/rejected": -2.289293050765991,
      "logps/chosen": -129.16366577148438,
      "logps/rejected": -129.005859375,
      "loss": 0.0071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.45145845413208,
      "rewards/margins": 5.602722644805908,
      "rewards/rejected": -3.151264190673828,
      "step": 1711
    },
    {
      "epoch": 0.6848,
      "grad_norm": 0.01677669771015644,
      "learning_rate": 7.718666666666667e-07,
      "logits/chosen": -2.4202516078948975,
      "logits/rejected": -3.3007912635803223,
      "logps/chosen": -173.26925659179688,
      "logps/rejected": -162.97616577148438,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.72257137298584,
      "rewards/margins": 8.70923137664795,
      "rewards/rejected": -3.986659526824951,
      "step": 1712
    },
    {
      "epoch": 0.6852,
      "grad_norm": 0.06502419710159302,
      "learning_rate": 7.717333333333334e-07,
      "logits/chosen": -2.4478442668914795,
      "logits/rejected": -2.828488826751709,
      "logps/chosen": -103.25625610351562,
      "logps/rejected": -129.0594940185547,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0849735736846924,
      "rewards/margins": 7.333743572235107,
      "rewards/rejected": -4.248769760131836,
      "step": 1713
    },
    {
      "epoch": 0.6856,
      "grad_norm": 0.009998276829719543,
      "learning_rate": 7.716e-07,
      "logits/chosen": -1.8704042434692383,
      "logits/rejected": -3.1098976135253906,
      "logps/chosen": -98.86444854736328,
      "logps/rejected": -156.6175079345703,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2720422744750977,
      "rewards/margins": 9.458674430847168,
      "rewards/rejected": -6.18663215637207,
      "step": 1714
    },
    {
      "epoch": 0.686,
      "grad_norm": 0.534099817276001,
      "learning_rate": 7.714666666666666e-07,
      "logits/chosen": -2.744767189025879,
      "logits/rejected": -2.5165491104125977,
      "logps/chosen": -112.62823486328125,
      "logps/rejected": -130.35665893554688,
      "loss": 0.005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.05495548248291,
      "rewards/margins": 7.0241899490356445,
      "rewards/rejected": -3.9692344665527344,
      "step": 1715
    },
    {
      "epoch": 0.6864,
      "grad_norm": 2.151482105255127,
      "learning_rate": 7.713333333333333e-07,
      "logits/chosen": -2.6329493522644043,
      "logits/rejected": -2.858464002609253,
      "logps/chosen": -236.38674926757812,
      "logps/rejected": -131.9765625,
      "loss": 0.0158,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.47031325101852417,
      "rewards/margins": 4.834916591644287,
      "rewards/rejected": -4.364603042602539,
      "step": 1716
    },
    {
      "epoch": 0.6868,
      "grad_norm": 0.8679258823394775,
      "learning_rate": 7.711999999999999e-07,
      "logits/chosen": -2.042534589767456,
      "logits/rejected": -2.8055825233459473,
      "logps/chosen": -96.97993469238281,
      "logps/rejected": -125.59402465820312,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.007810592651367,
      "rewards/margins": 6.723690986633301,
      "rewards/rejected": -4.715880393981934,
      "step": 1717
    },
    {
      "epoch": 0.6872,
      "grad_norm": 2.5166938304901123,
      "learning_rate": 7.710666666666666e-07,
      "logits/chosen": -2.7788820266723633,
      "logits/rejected": -3.4923384189605713,
      "logps/chosen": -140.11578369140625,
      "logps/rejected": -151.40447998046875,
      "loss": 0.0364,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04288288950920105,
      "rewards/margins": 4.4746413230896,
      "rewards/rejected": -4.431758403778076,
      "step": 1718
    },
    {
      "epoch": 0.6876,
      "grad_norm": 0.2583521902561188,
      "learning_rate": 7.709333333333333e-07,
      "logits/chosen": -2.2546286582946777,
      "logits/rejected": -3.2420473098754883,
      "logps/chosen": -142.22080993652344,
      "logps/rejected": -237.41241455078125,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.239319324493408,
      "rewards/margins": 6.356091499328613,
      "rewards/rejected": -4.116772651672363,
      "step": 1719
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.3121475875377655,
      "learning_rate": 7.708e-07,
      "logits/chosen": -3.03840970993042,
      "logits/rejected": -3.015176773071289,
      "logps/chosen": -166.22647094726562,
      "logps/rejected": -150.51258850097656,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42796555161476135,
      "rewards/margins": 5.697541236877441,
      "rewards/rejected": -5.269576072692871,
      "step": 1720
    },
    {
      "epoch": 0.6884,
      "grad_norm": 0.15256300568580627,
      "learning_rate": 7.706666666666667e-07,
      "logits/chosen": -2.316906452178955,
      "logits/rejected": -2.4441490173339844,
      "logps/chosen": -130.44300842285156,
      "logps/rejected": -149.246337890625,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8398911952972412,
      "rewards/margins": 6.577963829040527,
      "rewards/rejected": -4.738072395324707,
      "step": 1721
    },
    {
      "epoch": 0.6888,
      "grad_norm": 0.011792137287557125,
      "learning_rate": 7.705333333333333e-07,
      "logits/chosen": -2.5071237087249756,
      "logits/rejected": -3.3239076137542725,
      "logps/chosen": -232.04588317871094,
      "logps/rejected": -191.85086059570312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.278432607650757,
      "rewards/margins": 9.883861541748047,
      "rewards/rejected": -7.605428695678711,
      "step": 1722
    },
    {
      "epoch": 0.6892,
      "grad_norm": 0.09864829480648041,
      "learning_rate": 7.704e-07,
      "logits/chosen": -1.849735140800476,
      "logits/rejected": -3.893742561340332,
      "logps/chosen": -109.69702911376953,
      "logps/rejected": -135.28326416015625,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4293158054351807,
      "rewards/margins": 6.910819053649902,
      "rewards/rejected": -4.481503486633301,
      "step": 1723
    },
    {
      "epoch": 0.6896,
      "grad_norm": 0.04909677430987358,
      "learning_rate": 7.702666666666667e-07,
      "logits/chosen": -2.09679913520813,
      "logits/rejected": -3.3057775497436523,
      "logps/chosen": -150.60105895996094,
      "logps/rejected": -146.94761657714844,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5579278469085693,
      "rewards/margins": 7.55296516418457,
      "rewards/rejected": -3.995037078857422,
      "step": 1724
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.10707336664199829,
      "learning_rate": 7.701333333333333e-07,
      "logits/chosen": -2.3988196849823,
      "logits/rejected": -3.195596694946289,
      "logps/chosen": -165.57174682617188,
      "logps/rejected": -193.82241821289062,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6899399757385254,
      "rewards/margins": 8.56689453125,
      "rewards/rejected": -5.876955032348633,
      "step": 1725
    },
    {
      "epoch": 0.6904,
      "grad_norm": 0.019563868641853333,
      "learning_rate": 7.699999999999999e-07,
      "logits/chosen": -2.4364676475524902,
      "logits/rejected": -3.62697434425354,
      "logps/chosen": -155.2420654296875,
      "logps/rejected": -156.27452087402344,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.0028977394104,
      "rewards/margins": 8.798561096191406,
      "rewards/rejected": -4.795663833618164,
      "step": 1726
    },
    {
      "epoch": 0.6908,
      "grad_norm": 1.621819257736206,
      "learning_rate": 7.698666666666666e-07,
      "logits/chosen": -2.603128433227539,
      "logits/rejected": -3.0881118774414062,
      "logps/chosen": -133.98284912109375,
      "logps/rejected": -126.50811767578125,
      "loss": 0.0193,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27673569321632385,
      "rewards/margins": 4.235991477966309,
      "rewards/rejected": -3.9592556953430176,
      "step": 1727
    },
    {
      "epoch": 0.6912,
      "grad_norm": 0.4305039644241333,
      "learning_rate": 7.697333333333333e-07,
      "logits/chosen": -2.247897148132324,
      "logits/rejected": -3.0909018516540527,
      "logps/chosen": -96.43557739257812,
      "logps/rejected": -114.04496765136719,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4032864570617676,
      "rewards/margins": 5.796142578125,
      "rewards/rejected": -3.3928561210632324,
      "step": 1728
    },
    {
      "epoch": 0.6916,
      "grad_norm": 0.07241451740264893,
      "learning_rate": 7.695999999999999e-07,
      "logits/chosen": -2.088197708129883,
      "logits/rejected": -3.085258960723877,
      "logps/chosen": -159.389404296875,
      "logps/rejected": -175.22705078125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.221726179122925,
      "rewards/margins": 9.077190399169922,
      "rewards/rejected": -6.855463981628418,
      "step": 1729
    },
    {
      "epoch": 0.692,
      "grad_norm": 0.02358311228454113,
      "learning_rate": 7.694666666666666e-07,
      "logits/chosen": -2.5750465393066406,
      "logits/rejected": -3.4734582901000977,
      "logps/chosen": -129.17361450195312,
      "logps/rejected": -171.58724975585938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.752549648284912,
      "rewards/margins": 8.317564964294434,
      "rewards/rejected": -5.5650153160095215,
      "step": 1730
    },
    {
      "epoch": 0.6924,
      "grad_norm": 7.524443626403809,
      "learning_rate": 7.693333333333333e-07,
      "logits/chosen": -1.5916728973388672,
      "logits/rejected": -2.8273391723632812,
      "logps/chosen": -87.03962707519531,
      "logps/rejected": -121.52774047851562,
      "loss": 0.0533,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3131039142608643,
      "rewards/margins": 5.231511116027832,
      "rewards/rejected": -3.9184072017669678,
      "step": 1731
    },
    {
      "epoch": 0.6928,
      "grad_norm": 0.038546886295080185,
      "learning_rate": 7.692e-07,
      "logits/chosen": -2.1754794120788574,
      "logits/rejected": -3.343029022216797,
      "logps/chosen": -101.46171569824219,
      "logps/rejected": -210.77175903320312,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2869906425476074,
      "rewards/margins": 8.011051177978516,
      "rewards/rejected": -4.724060535430908,
      "step": 1732
    },
    {
      "epoch": 0.6932,
      "grad_norm": 1.1268644332885742,
      "learning_rate": 7.690666666666667e-07,
      "logits/chosen": -2.031263828277588,
      "logits/rejected": -2.8949780464172363,
      "logps/chosen": -92.23828887939453,
      "logps/rejected": -137.55239868164062,
      "loss": 0.0112,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4941855669021606,
      "rewards/margins": 5.822783470153809,
      "rewards/rejected": -4.3285980224609375,
      "step": 1733
    },
    {
      "epoch": 0.6936,
      "grad_norm": 1.1663262844085693,
      "learning_rate": 7.689333333333334e-07,
      "logits/chosen": -2.130680561065674,
      "logits/rejected": -3.081584930419922,
      "logps/chosen": -86.86956787109375,
      "logps/rejected": -166.11964416503906,
      "loss": 0.0092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4756224155426025,
      "rewards/margins": 6.872236251831055,
      "rewards/rejected": -5.396613597869873,
      "step": 1734
    },
    {
      "epoch": 0.694,
      "grad_norm": 0.07069151848554611,
      "learning_rate": 7.688000000000001e-07,
      "logits/chosen": -2.1031312942504883,
      "logits/rejected": -3.422226905822754,
      "logps/chosen": -167.01211547851562,
      "logps/rejected": -145.70736694335938,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7429957389831543,
      "rewards/margins": 8.436006546020508,
      "rewards/rejected": -4.6930108070373535,
      "step": 1735
    },
    {
      "epoch": 0.6944,
      "grad_norm": 0.15496686100959778,
      "learning_rate": 7.686666666666666e-07,
      "logits/chosen": -1.7136330604553223,
      "logits/rejected": -3.431580066680908,
      "logps/chosen": -136.11309814453125,
      "logps/rejected": -185.32327270507812,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7515449523925781,
      "rewards/margins": 6.935798168182373,
      "rewards/rejected": -6.184253215789795,
      "step": 1736
    },
    {
      "epoch": 0.6948,
      "grad_norm": 0.06270929425954819,
      "learning_rate": 7.685333333333332e-07,
      "logits/chosen": -2.3003714084625244,
      "logits/rejected": -3.253471851348877,
      "logps/chosen": -123.77911376953125,
      "logps/rejected": -148.63369750976562,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0667736530303955,
      "rewards/margins": 7.700394630432129,
      "rewards/rejected": -4.6336212158203125,
      "step": 1737
    },
    {
      "epoch": 0.6952,
      "grad_norm": 0.06057961285114288,
      "learning_rate": 7.683999999999999e-07,
      "logits/chosen": -2.131828784942627,
      "logits/rejected": -2.917224884033203,
      "logps/chosen": -84.01780700683594,
      "logps/rejected": -128.80685424804688,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.852275848388672,
      "rewards/margins": 7.191326141357422,
      "rewards/rejected": -4.339050769805908,
      "step": 1738
    },
    {
      "epoch": 0.6956,
      "grad_norm": 0.21321254968643188,
      "learning_rate": 7.682666666666666e-07,
      "logits/chosen": -1.7145190238952637,
      "logits/rejected": -2.9052958488464355,
      "logps/chosen": -95.42796325683594,
      "logps/rejected": -127.9964828491211,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.450232982635498,
      "rewards/margins": 5.933995246887207,
      "rewards/rejected": -3.483762264251709,
      "step": 1739
    },
    {
      "epoch": 0.696,
      "grad_norm": 2.65112042427063,
      "learning_rate": 7.681333333333333e-07,
      "logits/chosen": -2.365774631500244,
      "logits/rejected": -2.7070014476776123,
      "logps/chosen": -78.93663024902344,
      "logps/rejected": -102.82470703125,
      "loss": 0.0384,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2122879028320312,
      "rewards/margins": 6.506765842437744,
      "rewards/rejected": -3.294477939605713,
      "step": 1740
    },
    {
      "epoch": 0.6964,
      "grad_norm": 0.20394256711006165,
      "learning_rate": 7.68e-07,
      "logits/chosen": -2.188070774078369,
      "logits/rejected": -3.2576656341552734,
      "logps/chosen": -101.97801208496094,
      "logps/rejected": -165.13955688476562,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.339359760284424,
      "rewards/margins": 7.108590126037598,
      "rewards/rejected": -4.769230365753174,
      "step": 1741
    },
    {
      "epoch": 0.6968,
      "grad_norm": 0.15726403892040253,
      "learning_rate": 7.678666666666667e-07,
      "logits/chosen": -1.914780616760254,
      "logits/rejected": -2.9035868644714355,
      "logps/chosen": -207.95960998535156,
      "logps/rejected": -161.1311798095703,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5359723567962646,
      "rewards/margins": 6.993534088134766,
      "rewards/rejected": -4.457561492919922,
      "step": 1742
    },
    {
      "epoch": 0.6972,
      "grad_norm": 0.7386451959609985,
      "learning_rate": 7.677333333333334e-07,
      "logits/chosen": -1.6931266784667969,
      "logits/rejected": -2.694887161254883,
      "logps/chosen": -98.13130950927734,
      "logps/rejected": -114.6755142211914,
      "loss": 0.0071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0912747383117676,
      "rewards/margins": 5.0269670486450195,
      "rewards/rejected": -3.93569278717041,
      "step": 1743
    },
    {
      "epoch": 0.6976,
      "grad_norm": 0.2108416110277176,
      "learning_rate": 7.676e-07,
      "logits/chosen": -1.8205287456512451,
      "logits/rejected": -2.6950185298919678,
      "logps/chosen": -152.46951293945312,
      "logps/rejected": -165.1590576171875,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.337644577026367,
      "rewards/margins": 8.482475280761719,
      "rewards/rejected": -6.14483118057251,
      "step": 1744
    },
    {
      "epoch": 0.698,
      "grad_norm": 0.217279851436615,
      "learning_rate": 7.674666666666666e-07,
      "logits/chosen": -2.2244672775268555,
      "logits/rejected": -2.850987434387207,
      "logps/chosen": -79.32510375976562,
      "logps/rejected": -145.62147521972656,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6816799640655518,
      "rewards/margins": 6.994091987609863,
      "rewards/rejected": -3.3124125003814697,
      "step": 1745
    },
    {
      "epoch": 0.6984,
      "grad_norm": 2.685962438583374,
      "learning_rate": 7.673333333333332e-07,
      "logits/chosen": -2.2687108516693115,
      "logits/rejected": -2.943162202835083,
      "logps/chosen": -100.5166015625,
      "logps/rejected": -137.37620544433594,
      "loss": 0.0197,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.46615299582481384,
      "rewards/margins": 4.419386863708496,
      "rewards/rejected": -4.885540008544922,
      "step": 1746
    },
    {
      "epoch": 0.6988,
      "grad_norm": 0.1234717071056366,
      "learning_rate": 7.671999999999999e-07,
      "logits/chosen": -2.417178153991699,
      "logits/rejected": -3.5784835815429688,
      "logps/chosen": -167.38253784179688,
      "logps/rejected": -153.71932983398438,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4420876502990723,
      "rewards/margins": 6.830132484436035,
      "rewards/rejected": -4.388044834136963,
      "step": 1747
    },
    {
      "epoch": 0.6992,
      "grad_norm": 1.0973656177520752,
      "learning_rate": 7.670666666666666e-07,
      "logits/chosen": -1.9635114669799805,
      "logits/rejected": -3.097904682159424,
      "logps/chosen": -172.7927703857422,
      "logps/rejected": -179.6182098388672,
      "loss": 0.011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0572361946105957,
      "rewards/margins": 6.590753555297852,
      "rewards/rejected": -4.533516883850098,
      "step": 1748
    },
    {
      "epoch": 0.6996,
      "grad_norm": 0.6991702914237976,
      "learning_rate": 7.669333333333333e-07,
      "logits/chosen": -1.8136118650436401,
      "logits/rejected": -3.012695550918579,
      "logps/chosen": -109.52256774902344,
      "logps/rejected": -135.57577514648438,
      "loss": 0.0069,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3676180839538574,
      "rewards/margins": 5.278740406036377,
      "rewards/rejected": -2.9111223220825195,
      "step": 1749
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.01858731359243393,
      "learning_rate": 7.668e-07,
      "logits/chosen": -2.5128977298736572,
      "logits/rejected": -2.8528528213500977,
      "logps/chosen": -206.65164184570312,
      "logps/rejected": -148.60690307617188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.433799743652344,
      "rewards/margins": 8.640361785888672,
      "rewards/rejected": -4.20656156539917,
      "step": 1750
    },
    {
      "epoch": 0.7004,
      "grad_norm": 0.11095655709505081,
      "learning_rate": 7.666666666666667e-07,
      "logits/chosen": -1.5390434265136719,
      "logits/rejected": -3.2500855922698975,
      "logps/chosen": -65.97669219970703,
      "logps/rejected": -144.3024444580078,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2320151329040527,
      "rewards/margins": 7.603386878967285,
      "rewards/rejected": -4.371371746063232,
      "step": 1751
    },
    {
      "epoch": 0.7008,
      "grad_norm": 0.8861795663833618,
      "learning_rate": 7.665333333333333e-07,
      "logits/chosen": -2.647365093231201,
      "logits/rejected": -2.7752914428710938,
      "logps/chosen": -138.55941772460938,
      "logps/rejected": -161.74801635742188,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4825761318206787,
      "rewards/margins": 7.019496440887451,
      "rewards/rejected": -4.536920547485352,
      "step": 1752
    },
    {
      "epoch": 0.7012,
      "grad_norm": 0.017273476347327232,
      "learning_rate": 7.664e-07,
      "logits/chosen": -1.9638795852661133,
      "logits/rejected": -3.4854135513305664,
      "logps/chosen": -96.88797760009766,
      "logps/rejected": -196.4097900390625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.487628221511841,
      "rewards/margins": 8.850221633911133,
      "rewards/rejected": -6.362593173980713,
      "step": 1753
    },
    {
      "epoch": 0.7016,
      "grad_norm": 0.3131779730319977,
      "learning_rate": 7.662666666666666e-07,
      "logits/chosen": -2.101505994796753,
      "logits/rejected": -3.0463290214538574,
      "logps/chosen": -67.36639404296875,
      "logps/rejected": -148.24209594726562,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1573383808135986,
      "rewards/margins": 6.398609161376953,
      "rewards/rejected": -4.241271018981934,
      "step": 1754
    },
    {
      "epoch": 0.702,
      "grad_norm": 1.9039212465286255,
      "learning_rate": 7.661333333333333e-07,
      "logits/chosen": -2.1465001106262207,
      "logits/rejected": -3.0944530963897705,
      "logps/chosen": -106.08968353271484,
      "logps/rejected": -149.3438720703125,
      "loss": 0.0214,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.986620306968689,
      "rewards/margins": 6.741198539733887,
      "rewards/rejected": -5.754578113555908,
      "step": 1755
    },
    {
      "epoch": 0.7024,
      "grad_norm": 0.14873582124710083,
      "learning_rate": 7.66e-07,
      "logits/chosen": -2.3077609539031982,
      "logits/rejected": -2.9040732383728027,
      "logps/chosen": -123.37158203125,
      "logps/rejected": -163.3900146484375,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.397599220275879,
      "rewards/margins": 7.886192321777344,
      "rewards/rejected": -5.488593101501465,
      "step": 1756
    },
    {
      "epoch": 0.7028,
      "grad_norm": 0.20659089088439941,
      "learning_rate": 7.658666666666666e-07,
      "logits/chosen": -1.9556230306625366,
      "logits/rejected": -2.7885990142822266,
      "logps/chosen": -82.21620178222656,
      "logps/rejected": -141.1275634765625,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2507660388946533,
      "rewards/margins": 7.20674991607666,
      "rewards/rejected": -4.955984115600586,
      "step": 1757
    },
    {
      "epoch": 0.7032,
      "grad_norm": 0.7193794846534729,
      "learning_rate": 7.657333333333333e-07,
      "logits/chosen": -2.3094377517700195,
      "logits/rejected": -3.4178466796875,
      "logps/chosen": -154.61802673339844,
      "logps/rejected": -186.65725708007812,
      "loss": 0.0084,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9170093536376953,
      "rewards/margins": 4.772886276245117,
      "rewards/rejected": -3.855876922607422,
      "step": 1758
    },
    {
      "epoch": 0.7036,
      "grad_norm": 1.444579839706421,
      "learning_rate": 7.655999999999999e-07,
      "logits/chosen": -2.168032646179199,
      "logits/rejected": -3.4501793384552,
      "logps/chosen": -60.41530990600586,
      "logps/rejected": -131.30755615234375,
      "loss": 0.0086,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1447510719299316,
      "rewards/margins": 6.9975905418396,
      "rewards/rejected": -4.852839469909668,
      "step": 1759
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.32620924711227417,
      "learning_rate": 7.654666666666666e-07,
      "logits/chosen": -2.1085872650146484,
      "logits/rejected": -2.2679688930511475,
      "logps/chosen": -81.02749633789062,
      "logps/rejected": -115.15674591064453,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3064632415771484,
      "rewards/margins": 6.394089698791504,
      "rewards/rejected": -4.087625980377197,
      "step": 1760
    },
    {
      "epoch": 0.7044,
      "grad_norm": 0.053411439061164856,
      "learning_rate": 7.653333333333333e-07,
      "logits/chosen": -2.4602770805358887,
      "logits/rejected": -3.0039639472961426,
      "logps/chosen": -113.33351135253906,
      "logps/rejected": -170.08554077148438,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.70326042175293,
      "rewards/margins": 8.761785507202148,
      "rewards/rejected": -4.058525085449219,
      "step": 1761
    },
    {
      "epoch": 0.7048,
      "grad_norm": 7.313350677490234,
      "learning_rate": 7.652e-07,
      "logits/chosen": -2.25657320022583,
      "logits/rejected": -3.0500073432922363,
      "logps/chosen": -115.98544311523438,
      "logps/rejected": -143.78118896484375,
      "loss": 0.0487,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12425994873046875,
      "rewards/margins": 5.976048469543457,
      "rewards/rejected": -5.851788520812988,
      "step": 1762
    },
    {
      "epoch": 0.7052,
      "grad_norm": 0.2503880560398102,
      "learning_rate": 7.650666666666667e-07,
      "logits/chosen": -2.4017982482910156,
      "logits/rejected": -2.7863736152648926,
      "logps/chosen": -162.56735229492188,
      "logps/rejected": -122.7481460571289,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5085368156433105,
      "rewards/margins": 6.3742804527282715,
      "rewards/rejected": -3.8657431602478027,
      "step": 1763
    },
    {
      "epoch": 0.7056,
      "grad_norm": 0.04714333638548851,
      "learning_rate": 7.649333333333333e-07,
      "logits/chosen": -2.4358339309692383,
      "logits/rejected": -2.9269275665283203,
      "logps/chosen": -95.13327026367188,
      "logps/rejected": -158.10678100585938,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.414236068725586,
      "rewards/margins": 9.868181228637695,
      "rewards/rejected": -5.453945636749268,
      "step": 1764
    },
    {
      "epoch": 0.706,
      "grad_norm": 0.6404719948768616,
      "learning_rate": 7.648e-07,
      "logits/chosen": -2.0960707664489746,
      "logits/rejected": -2.6984894275665283,
      "logps/chosen": -113.7760009765625,
      "logps/rejected": -138.926025390625,
      "loss": 0.0062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5360569953918457,
      "rewards/margins": 6.640542030334473,
      "rewards/rejected": -4.104484558105469,
      "step": 1765
    },
    {
      "epoch": 0.7064,
      "grad_norm": 0.7201524972915649,
      "learning_rate": 7.646666666666667e-07,
      "logits/chosen": -2.344172477722168,
      "logits/rejected": -3.458568572998047,
      "logps/chosen": -127.3160400390625,
      "logps/rejected": -154.57040405273438,
      "loss": 0.0052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0133308172225952,
      "rewards/margins": 6.360858917236328,
      "rewards/rejected": -5.347527980804443,
      "step": 1766
    },
    {
      "epoch": 0.7068,
      "grad_norm": 0.028901755809783936,
      "learning_rate": 7.645333333333332e-07,
      "logits/chosen": -2.1593754291534424,
      "logits/rejected": -3.5634422302246094,
      "logps/chosen": -145.51522827148438,
      "logps/rejected": -167.02938842773438,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.690624237060547,
      "rewards/margins": 8.77660083770752,
      "rewards/rejected": -6.085976600646973,
      "step": 1767
    },
    {
      "epoch": 0.7072,
      "grad_norm": 0.3699217140674591,
      "learning_rate": 7.643999999999999e-07,
      "logits/chosen": -1.5726990699768066,
      "logits/rejected": -3.2935009002685547,
      "logps/chosen": -105.30226135253906,
      "logps/rejected": -164.64776611328125,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9816563129425049,
      "rewards/margins": 6.584169387817383,
      "rewards/rejected": -4.602513313293457,
      "step": 1768
    },
    {
      "epoch": 0.7076,
      "grad_norm": 0.10831227898597717,
      "learning_rate": 7.642666666666666e-07,
      "logits/chosen": -1.9265635013580322,
      "logits/rejected": -2.714550018310547,
      "logps/chosen": -202.6377716064453,
      "logps/rejected": -183.4951171875,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.080350637435913,
      "rewards/margins": 7.070729732513428,
      "rewards/rejected": -4.990379333496094,
      "step": 1769
    },
    {
      "epoch": 0.708,
      "grad_norm": 0.0879887267947197,
      "learning_rate": 7.641333333333333e-07,
      "logits/chosen": -2.210602045059204,
      "logits/rejected": -3.585496187210083,
      "logps/chosen": -113.72919464111328,
      "logps/rejected": -152.04129028320312,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5807759761810303,
      "rewards/margins": 8.404088973999023,
      "rewards/rejected": -5.823312759399414,
      "step": 1770
    },
    {
      "epoch": 0.7084,
      "grad_norm": 1.0870018005371094,
      "learning_rate": 7.64e-07,
      "logits/chosen": -1.992945909500122,
      "logits/rejected": -3.0831730365753174,
      "logps/chosen": -98.52281951904297,
      "logps/rejected": -125.78694152832031,
      "loss": 0.0133,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.193455219268799,
      "rewards/margins": 6.767597198486328,
      "rewards/rejected": -4.574141979217529,
      "step": 1771
    },
    {
      "epoch": 0.7088,
      "grad_norm": 0.017910700291395187,
      "learning_rate": 7.638666666666667e-07,
      "logits/chosen": -2.3778092861175537,
      "logits/rejected": -2.6483633518218994,
      "logps/chosen": -112.92557525634766,
      "logps/rejected": -147.47096252441406,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4578776359558105,
      "rewards/margins": 8.638334274291992,
      "rewards/rejected": -5.180456161499023,
      "step": 1772
    },
    {
      "epoch": 0.7092,
      "grad_norm": 0.01690504513680935,
      "learning_rate": 7.637333333333333e-07,
      "logits/chosen": -2.444291114807129,
      "logits/rejected": -3.4004650115966797,
      "logps/chosen": -131.47926330566406,
      "logps/rejected": -225.67747497558594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6318683624267578,
      "rewards/margins": 8.891180992126465,
      "rewards/rejected": -7.259312629699707,
      "step": 1773
    },
    {
      "epoch": 0.7096,
      "grad_norm": 0.03528397157788277,
      "learning_rate": 7.635999999999999e-07,
      "logits/chosen": -1.963165283203125,
      "logits/rejected": -3.5939016342163086,
      "logps/chosen": -84.5936279296875,
      "logps/rejected": -184.24392700195312,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.43658185005188,
      "rewards/margins": 9.016559600830078,
      "rewards/rejected": -6.579977512359619,
      "step": 1774
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.5709987878799438,
      "learning_rate": 7.634666666666666e-07,
      "logits/chosen": -2.3700170516967773,
      "logits/rejected": -2.7393386363983154,
      "logps/chosen": -178.35498046875,
      "logps/rejected": -204.39840698242188,
      "loss": 0.0169,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8817664980888367,
      "rewards/margins": 4.251344203948975,
      "rewards/rejected": -5.133111000061035,
      "step": 1775
    },
    {
      "epoch": 0.7104,
      "grad_norm": 0.6764405369758606,
      "learning_rate": 7.633333333333333e-07,
      "logits/chosen": -2.799483299255371,
      "logits/rejected": -3.2254109382629395,
      "logps/chosen": -113.61799621582031,
      "logps/rejected": -134.3315887451172,
      "loss": 0.0064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.386077404022217,
      "rewards/margins": 5.815038681030273,
      "rewards/rejected": -2.4289612770080566,
      "step": 1776
    },
    {
      "epoch": 0.7108,
      "grad_norm": 0.07982783019542694,
      "learning_rate": 7.632e-07,
      "logits/chosen": -2.1412594318389893,
      "logits/rejected": -3.293732166290283,
      "logps/chosen": -118.48463439941406,
      "logps/rejected": -144.97251892089844,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0880637168884277,
      "rewards/margins": 7.430383205413818,
      "rewards/rejected": -5.342319488525391,
      "step": 1777
    },
    {
      "epoch": 0.7112,
      "grad_norm": 0.11185603588819504,
      "learning_rate": 7.630666666666666e-07,
      "logits/chosen": -2.0250556468963623,
      "logits/rejected": -3.303934097290039,
      "logps/chosen": -125.16154479980469,
      "logps/rejected": -180.2789306640625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.979400634765625,
      "rewards/margins": 8.955669403076172,
      "rewards/rejected": -6.976268768310547,
      "step": 1778
    },
    {
      "epoch": 0.7116,
      "grad_norm": 0.0042245169170200825,
      "learning_rate": 7.629333333333333e-07,
      "logits/chosen": -2.1272637844085693,
      "logits/rejected": -3.3044321537017822,
      "logps/chosen": -92.84030151367188,
      "logps/rejected": -156.13467407226562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4621124267578125,
      "rewards/margins": 11.006641387939453,
      "rewards/rejected": -7.544528961181641,
      "step": 1779
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.11695357412099838,
      "learning_rate": 7.628e-07,
      "logits/chosen": -2.4187963008880615,
      "logits/rejected": -2.7849907875061035,
      "logps/chosen": -100.52984619140625,
      "logps/rejected": -136.42996215820312,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.918367862701416,
      "rewards/margins": 6.525782585144043,
      "rewards/rejected": -4.607415199279785,
      "step": 1780
    },
    {
      "epoch": 0.7124,
      "grad_norm": 0.007252165116369724,
      "learning_rate": 7.626666666666667e-07,
      "logits/chosen": -2.2368991374969482,
      "logits/rejected": -3.707357883453369,
      "logps/chosen": -180.8966064453125,
      "logps/rejected": -207.9166259765625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.642279863357544,
      "rewards/margins": 9.615543365478516,
      "rewards/rejected": -5.973263740539551,
      "step": 1781
    },
    {
      "epoch": 0.7128,
      "grad_norm": 0.18541745841503143,
      "learning_rate": 7.625333333333332e-07,
      "logits/chosen": -1.761113166809082,
      "logits/rejected": -3.214381694793701,
      "logps/chosen": -87.85140991210938,
      "logps/rejected": -122.86083984375,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6160426139831543,
      "rewards/margins": 6.7205095291137695,
      "rewards/rejected": -3.104466676712036,
      "step": 1782
    },
    {
      "epoch": 0.7132,
      "grad_norm": 0.08879028260707855,
      "learning_rate": 7.623999999999999e-07,
      "logits/chosen": -1.7378219366073608,
      "logits/rejected": -3.0122389793395996,
      "logps/chosen": -103.36625671386719,
      "logps/rejected": -141.2521514892578,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.32574462890625,
      "rewards/margins": 7.3708696365356445,
      "rewards/rejected": -5.0451250076293945,
      "step": 1783
    },
    {
      "epoch": 0.7136,
      "grad_norm": 8.900458335876465,
      "learning_rate": 7.622666666666666e-07,
      "logits/chosen": -2.166823387145996,
      "logits/rejected": -3.2315611839294434,
      "logps/chosen": -95.64425659179688,
      "logps/rejected": -189.6907958984375,
      "loss": 0.0476,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3623641729354858,
      "rewards/margins": 6.008179187774658,
      "rewards/rejected": -4.645815372467041,
      "step": 1784
    },
    {
      "epoch": 0.714,
      "grad_norm": 0.04398276284337044,
      "learning_rate": 7.621333333333333e-07,
      "logits/chosen": -2.4611096382141113,
      "logits/rejected": -2.585031032562256,
      "logps/chosen": -170.53857421875,
      "logps/rejected": -124.00254821777344,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.094036102294922,
      "rewards/margins": 7.856054306030273,
      "rewards/rejected": -4.762018203735352,
      "step": 1785
    },
    {
      "epoch": 0.7144,
      "grad_norm": 0.05600292235612869,
      "learning_rate": 7.62e-07,
      "logits/chosen": -1.7454601526260376,
      "logits/rejected": -2.7964398860931396,
      "logps/chosen": -82.49546813964844,
      "logps/rejected": -119.74626159667969,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9823238849639893,
      "rewards/margins": 7.335912227630615,
      "rewards/rejected": -4.353588581085205,
      "step": 1786
    },
    {
      "epoch": 0.7148,
      "grad_norm": 6.9156951904296875,
      "learning_rate": 7.618666666666667e-07,
      "logits/chosen": -2.9900918006896973,
      "logits/rejected": -3.6380209922790527,
      "logps/chosen": -240.85806274414062,
      "logps/rejected": -167.96624755859375,
      "loss": 0.0321,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5632407665252686,
      "rewards/margins": 6.5564284324646,
      "rewards/rejected": -4.99318790435791,
      "step": 1787
    },
    {
      "epoch": 0.7152,
      "grad_norm": 1.8514349460601807,
      "learning_rate": 7.617333333333334e-07,
      "logits/chosen": -2.2260189056396484,
      "logits/rejected": -3.007110118865967,
      "logps/chosen": -102.25820922851562,
      "logps/rejected": -121.55062103271484,
      "loss": 0.0256,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8501439094543457,
      "rewards/margins": 5.250157356262207,
      "rewards/rejected": -3.4000139236450195,
      "step": 1788
    },
    {
      "epoch": 0.7156,
      "grad_norm": 0.15423829853534698,
      "learning_rate": 7.616e-07,
      "logits/chosen": -2.2599754333496094,
      "logits/rejected": -3.03961443901062,
      "logps/chosen": -139.74209594726562,
      "logps/rejected": -143.8114013671875,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0341174602508545,
      "rewards/margins": 7.026308059692383,
      "rewards/rejected": -3.9921908378601074,
      "step": 1789
    },
    {
      "epoch": 0.716,
      "grad_norm": 0.06531693786382675,
      "learning_rate": 7.614666666666666e-07,
      "logits/chosen": -2.7099952697753906,
      "logits/rejected": -2.9577879905700684,
      "logps/chosen": -152.9845733642578,
      "logps/rejected": -186.8420867919922,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9235260486602783,
      "rewards/margins": 8.495759010314941,
      "rewards/rejected": -5.572233200073242,
      "step": 1790
    },
    {
      "epoch": 0.7164,
      "grad_norm": 0.1835479587316513,
      "learning_rate": 7.613333333333333e-07,
      "logits/chosen": -2.4492850303649902,
      "logits/rejected": -3.534839630126953,
      "logps/chosen": -151.21258544921875,
      "logps/rejected": -177.39503479003906,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10304147005081177,
      "rewards/margins": 6.325226783752441,
      "rewards/rejected": -6.222185134887695,
      "step": 1791
    },
    {
      "epoch": 0.7168,
      "grad_norm": 0.11047238111495972,
      "learning_rate": 7.611999999999999e-07,
      "logits/chosen": -1.908341884613037,
      "logits/rejected": -3.1541333198547363,
      "logps/chosen": -125.76158142089844,
      "logps/rejected": -166.54541015625,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8937934637069702,
      "rewards/margins": 6.73982048034668,
      "rewards/rejected": -4.846027374267578,
      "step": 1792
    },
    {
      "epoch": 0.7172,
      "grad_norm": 0.003846030216664076,
      "learning_rate": 7.610666666666666e-07,
      "logits/chosen": -2.1541547775268555,
      "logits/rejected": -2.7844038009643555,
      "logps/chosen": -112.17320251464844,
      "logps/rejected": -166.55892944335938,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.0680766105651855,
      "rewards/margins": 10.180370330810547,
      "rewards/rejected": -6.1122941970825195,
      "step": 1793
    },
    {
      "epoch": 0.7176,
      "grad_norm": 0.4899400770664215,
      "learning_rate": 7.609333333333333e-07,
      "logits/chosen": -2.1451668739318848,
      "logits/rejected": -2.994389533996582,
      "logps/chosen": -162.84054565429688,
      "logps/rejected": -135.5325469970703,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.674877166748047,
      "rewards/margins": 5.265164375305176,
      "rewards/rejected": -2.590287446975708,
      "step": 1794
    },
    {
      "epoch": 0.718,
      "grad_norm": 0.06883785128593445,
      "learning_rate": 7.608e-07,
      "logits/chosen": -1.847445011138916,
      "logits/rejected": -2.9210729598999023,
      "logps/chosen": -120.96469116210938,
      "logps/rejected": -149.98585510253906,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.713442802429199,
      "rewards/margins": 8.72630786895752,
      "rewards/rejected": -6.01286506652832,
      "step": 1795
    },
    {
      "epoch": 0.7184,
      "grad_norm": 0.010360724292695522,
      "learning_rate": 7.606666666666667e-07,
      "logits/chosen": -2.6159796714782715,
      "logits/rejected": -3.2389016151428223,
      "logps/chosen": -76.37246704101562,
      "logps/rejected": -134.88027954101562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.817972183227539,
      "rewards/margins": 9.119083404541016,
      "rewards/rejected": -4.301111698150635,
      "step": 1796
    },
    {
      "epoch": 0.7188,
      "grad_norm": 0.23184433579444885,
      "learning_rate": 7.605333333333333e-07,
      "logits/chosen": -2.1079282760620117,
      "logits/rejected": -2.9255928993225098,
      "logps/chosen": -100.03424072265625,
      "logps/rejected": -139.06759643554688,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2187641859054565,
      "rewards/margins": 5.75742244720459,
      "rewards/rejected": -4.538658142089844,
      "step": 1797
    },
    {
      "epoch": 0.7192,
      "grad_norm": 19.018497467041016,
      "learning_rate": 7.604e-07,
      "logits/chosen": -2.335641860961914,
      "logits/rejected": -2.7073798179626465,
      "logps/chosen": -154.55393981933594,
      "logps/rejected": -218.32415771484375,
      "loss": 0.1756,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27382469177246094,
      "rewards/margins": 4.454596042633057,
      "rewards/rejected": -4.180771350860596,
      "step": 1798
    },
    {
      "epoch": 0.7196,
      "grad_norm": 0.021080009639263153,
      "learning_rate": 7.602666666666666e-07,
      "logits/chosen": -2.485518455505371,
      "logits/rejected": -3.4883430004119873,
      "logps/chosen": -108.15179443359375,
      "logps/rejected": -148.10594177246094,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.482283115386963,
      "rewards/margins": 8.585441589355469,
      "rewards/rejected": -5.103158950805664,
      "step": 1799
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6025546193122864,
      "learning_rate": 7.601333333333333e-07,
      "logits/chosen": -2.2379398345947266,
      "logits/rejected": -3.609185218811035,
      "logps/chosen": -105.8026123046875,
      "logps/rejected": -165.2725830078125,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.267587184906006,
      "rewards/margins": 6.938727378845215,
      "rewards/rejected": -4.671139717102051,
      "step": 1800
    },
    {
      "epoch": 0.7204,
      "grad_norm": 0.03350432962179184,
      "learning_rate": 7.599999999999999e-07,
      "logits/chosen": -2.4702041149139404,
      "logits/rejected": -2.9982235431671143,
      "logps/chosen": -109.21942901611328,
      "logps/rejected": -153.47802734375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.579329013824463,
      "rewards/margins": 8.650690078735352,
      "rewards/rejected": -5.071361541748047,
      "step": 1801
    },
    {
      "epoch": 0.7208,
      "grad_norm": 0.10843107104301453,
      "learning_rate": 7.598666666666666e-07,
      "logits/chosen": -2.49955415725708,
      "logits/rejected": -3.412824869155884,
      "logps/chosen": -167.04574584960938,
      "logps/rejected": -149.45767211914062,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.127307891845703,
      "rewards/margins": 6.884220123291016,
      "rewards/rejected": -4.7569122314453125,
      "step": 1802
    },
    {
      "epoch": 0.7212,
      "grad_norm": 0.09143281728029251,
      "learning_rate": 7.597333333333333e-07,
      "logits/chosen": -2.426072597503662,
      "logits/rejected": -3.1270737648010254,
      "logps/chosen": -133.4606475830078,
      "logps/rejected": -148.2056884765625,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5589287281036377,
      "rewards/margins": 8.163227081298828,
      "rewards/rejected": -5.6042985916137695,
      "step": 1803
    },
    {
      "epoch": 0.7216,
      "grad_norm": 0.07335170358419418,
      "learning_rate": 7.596e-07,
      "logits/chosen": -2.0900464057922363,
      "logits/rejected": -2.9631128311157227,
      "logps/chosen": -110.37289428710938,
      "logps/rejected": -154.660888671875,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.482657432556152,
      "rewards/margins": 8.820028305053711,
      "rewards/rejected": -4.337370872497559,
      "step": 1804
    },
    {
      "epoch": 0.722,
      "grad_norm": 0.12452983111143112,
      "learning_rate": 7.594666666666666e-07,
      "logits/chosen": -2.7933859825134277,
      "logits/rejected": -3.28200101852417,
      "logps/chosen": -201.51492309570312,
      "logps/rejected": -186.47914123535156,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5761871337890625,
      "rewards/margins": 7.166316986083984,
      "rewards/rejected": -5.590129852294922,
      "step": 1805
    },
    {
      "epoch": 0.7224,
      "grad_norm": 0.21904876828193665,
      "learning_rate": 7.593333333333333e-07,
      "logits/chosen": -2.2928354740142822,
      "logits/rejected": -2.879028081893921,
      "logps/chosen": -74.93534851074219,
      "logps/rejected": -126.06542205810547,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.539618730545044,
      "rewards/margins": 7.529446125030518,
      "rewards/rejected": -3.9898273944854736,
      "step": 1806
    },
    {
      "epoch": 0.7228,
      "grad_norm": 0.025677623227238655,
      "learning_rate": 7.592e-07,
      "logits/chosen": -2.519160270690918,
      "logits/rejected": -2.930992603302002,
      "logps/chosen": -145.36962890625,
      "logps/rejected": -160.36517333984375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.943326950073242,
      "rewards/margins": 8.341806411743164,
      "rewards/rejected": -5.398478984832764,
      "step": 1807
    },
    {
      "epoch": 0.7232,
      "grad_norm": 0.04929323494434357,
      "learning_rate": 7.590666666666667e-07,
      "logits/chosen": -2.141268253326416,
      "logits/rejected": -3.1057052612304688,
      "logps/chosen": -83.79496765136719,
      "logps/rejected": -134.41665649414062,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6224069595336914,
      "rewards/margins": 8.115055084228516,
      "rewards/rejected": -4.492648124694824,
      "step": 1808
    },
    {
      "epoch": 0.7236,
      "grad_norm": 0.0015495922416448593,
      "learning_rate": 7.589333333333334e-07,
      "logits/chosen": -2.0436577796936035,
      "logits/rejected": -3.451204299926758,
      "logps/chosen": -106.56509399414062,
      "logps/rejected": -176.18795776367188,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.340929985046387,
      "rewards/margins": 11.190508842468262,
      "rewards/rejected": -6.849577903747559,
      "step": 1809
    },
    {
      "epoch": 0.724,
      "grad_norm": 0.31527426838874817,
      "learning_rate": 7.588e-07,
      "logits/chosen": -1.730268120765686,
      "logits/rejected": -3.2332763671875,
      "logps/chosen": -126.32627868652344,
      "logps/rejected": -153.30526733398438,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7548531293869019,
      "rewards/margins": 6.848780155181885,
      "rewards/rejected": -5.093927383422852,
      "step": 1810
    },
    {
      "epoch": 0.7244,
      "grad_norm": 0.5698728561401367,
      "learning_rate": 7.586666666666666e-07,
      "logits/chosen": -1.7045719623565674,
      "logits/rejected": -3.0678606033325195,
      "logps/chosen": -126.70437622070312,
      "logps/rejected": -152.9966278076172,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.881865382194519,
      "rewards/margins": 6.589306831359863,
      "rewards/rejected": -4.707441329956055,
      "step": 1811
    },
    {
      "epoch": 0.7248,
      "grad_norm": 0.6357083320617676,
      "learning_rate": 7.585333333333332e-07,
      "logits/chosen": -2.3624558448791504,
      "logits/rejected": -2.512634515762329,
      "logps/chosen": -140.06175231933594,
      "logps/rejected": -223.51109313964844,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.537633180618286,
      "rewards/margins": 6.591004371643066,
      "rewards/rejected": -3.0533711910247803,
      "step": 1812
    },
    {
      "epoch": 0.7252,
      "grad_norm": 0.6576436161994934,
      "learning_rate": 7.583999999999999e-07,
      "logits/chosen": -2.549435615539551,
      "logits/rejected": -2.8838062286376953,
      "logps/chosen": -145.71627807617188,
      "logps/rejected": -179.6444854736328,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4000396728515625,
      "rewards/margins": 7.514806747436523,
      "rewards/rejected": -4.114767551422119,
      "step": 1813
    },
    {
      "epoch": 0.7256,
      "grad_norm": 0.051248520612716675,
      "learning_rate": 7.582666666666666e-07,
      "logits/chosen": -2.3224329948425293,
      "logits/rejected": -3.289151668548584,
      "logps/chosen": -119.17108154296875,
      "logps/rejected": -138.4046630859375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4980556964874268,
      "rewards/margins": 7.952149391174316,
      "rewards/rejected": -4.454093933105469,
      "step": 1814
    },
    {
      "epoch": 0.726,
      "grad_norm": 0.06549655646085739,
      "learning_rate": 7.581333333333333e-07,
      "logits/chosen": -2.060800790786743,
      "logits/rejected": -2.7860164642333984,
      "logps/chosen": -146.95974731445312,
      "logps/rejected": -162.37942504882812,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1079964637756348,
      "rewards/margins": 7.751723289489746,
      "rewards/rejected": -4.6437273025512695,
      "step": 1815
    },
    {
      "epoch": 0.7264,
      "grad_norm": 0.027804743498563766,
      "learning_rate": 7.58e-07,
      "logits/chosen": -2.5316667556762695,
      "logits/rejected": -3.3218164443969727,
      "logps/chosen": -139.7788543701172,
      "logps/rejected": -226.8495330810547,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.193337917327881,
      "rewards/margins": 9.928789138793945,
      "rewards/rejected": -6.735450744628906,
      "step": 1816
    },
    {
      "epoch": 0.7268,
      "grad_norm": 0.19545920193195343,
      "learning_rate": 7.578666666666667e-07,
      "logits/chosen": -1.9333388805389404,
      "logits/rejected": -3.226912260055542,
      "logps/chosen": -78.8597640991211,
      "logps/rejected": -134.89498901367188,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.58937931060791,
      "rewards/margins": 6.362163543701172,
      "rewards/rejected": -3.772784471511841,
      "step": 1817
    },
    {
      "epoch": 0.7272,
      "grad_norm": 0.17912054061889648,
      "learning_rate": 7.577333333333334e-07,
      "logits/chosen": -1.6073224544525146,
      "logits/rejected": -2.7890710830688477,
      "logps/chosen": -84.90835571289062,
      "logps/rejected": -145.05929565429688,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6058716773986816,
      "rewards/margins": 6.733458995819092,
      "rewards/rejected": -4.12758731842041,
      "step": 1818
    },
    {
      "epoch": 0.7276,
      "grad_norm": 0.004660635255277157,
      "learning_rate": 7.576000000000001e-07,
      "logits/chosen": -2.5634093284606934,
      "logits/rejected": -3.1576828956604004,
      "logps/chosen": -117.38138580322266,
      "logps/rejected": -180.65261840820312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.29145622253418,
      "rewards/margins": 10.337966918945312,
      "rewards/rejected": -6.046510696411133,
      "step": 1819
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.05719158798456192,
      "learning_rate": 7.574666666666665e-07,
      "logits/chosen": -2.31990385055542,
      "logits/rejected": -3.3279621601104736,
      "logps/chosen": -144.51914978027344,
      "logps/rejected": -128.56414794921875,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.102621078491211,
      "rewards/margins": 7.160551071166992,
      "rewards/rejected": -4.057929992675781,
      "step": 1820
    },
    {
      "epoch": 0.7284,
      "grad_norm": 0.056500427424907684,
      "learning_rate": 7.573333333333332e-07,
      "logits/chosen": -2.2976553440093994,
      "logits/rejected": -2.949876308441162,
      "logps/chosen": -112.41742706298828,
      "logps/rejected": -127.97236633300781,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5537562370300293,
      "rewards/margins": 7.615106105804443,
      "rewards/rejected": -5.061349868774414,
      "step": 1821
    },
    {
      "epoch": 0.7288,
      "grad_norm": 0.17322969436645508,
      "learning_rate": 7.571999999999999e-07,
      "logits/chosen": -2.377868175506592,
      "logits/rejected": -3.3953728675842285,
      "logps/chosen": -170.60208129882812,
      "logps/rejected": -185.10072326660156,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.30674436688423157,
      "rewards/margins": 6.383975982666016,
      "rewards/rejected": -6.690720558166504,
      "step": 1822
    },
    {
      "epoch": 0.7292,
      "grad_norm": 0.640737771987915,
      "learning_rate": 7.570666666666666e-07,
      "logits/chosen": -1.9246044158935547,
      "logits/rejected": -3.3050990104675293,
      "logps/chosen": -176.4619903564453,
      "logps/rejected": -147.94757080078125,
      "loss": 0.0055,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7332401275634766,
      "rewards/margins": 5.947168827056885,
      "rewards/rejected": -5.213928699493408,
      "step": 1823
    },
    {
      "epoch": 0.7296,
      "grad_norm": 0.584365963935852,
      "learning_rate": 7.569333333333333e-07,
      "logits/chosen": -2.498661994934082,
      "logits/rejected": -3.4867422580718994,
      "logps/chosen": -107.54020690917969,
      "logps/rejected": -165.27549743652344,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6575367450714111,
      "rewards/margins": 7.029404640197754,
      "rewards/rejected": -5.371868133544922,
      "step": 1824
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.08408941328525543,
      "learning_rate": 7.568e-07,
      "logits/chosen": -2.2974438667297363,
      "logits/rejected": -3.2932162284851074,
      "logps/chosen": -103.03132629394531,
      "logps/rejected": -143.89207458496094,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7355237007141113,
      "rewards/margins": 8.084331512451172,
      "rewards/rejected": -5.348807334899902,
      "step": 1825
    },
    {
      "epoch": 0.7304,
      "grad_norm": 0.9783997535705566,
      "learning_rate": 7.566666666666667e-07,
      "logits/chosen": -2.7068047523498535,
      "logits/rejected": -3.4406275749206543,
      "logps/chosen": -93.54161071777344,
      "logps/rejected": -157.95120239257812,
      "loss": 0.0064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08859863877296448,
      "rewards/margins": 5.463591575622559,
      "rewards/rejected": -5.374992847442627,
      "step": 1826
    },
    {
      "epoch": 0.7308,
      "grad_norm": 0.08532893657684326,
      "learning_rate": 7.565333333333333e-07,
      "logits/chosen": -2.072294235229492,
      "logits/rejected": -2.4922499656677246,
      "logps/chosen": -113.50877380371094,
      "logps/rejected": -127.31552124023438,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.472510814666748,
      "rewards/margins": 7.135926246643066,
      "rewards/rejected": -3.6634154319763184,
      "step": 1827
    },
    {
      "epoch": 0.7312,
      "grad_norm": 0.974138617515564,
      "learning_rate": 7.564e-07,
      "logits/chosen": -1.9312493801116943,
      "logits/rejected": -2.977849006652832,
      "logps/chosen": -108.37362670898438,
      "logps/rejected": -130.09213256835938,
      "loss": 0.0101,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8733363747596741,
      "rewards/margins": 5.62010383605957,
      "rewards/rejected": -4.746767520904541,
      "step": 1828
    },
    {
      "epoch": 0.7316,
      "grad_norm": 0.02042534202337265,
      "learning_rate": 7.562666666666666e-07,
      "logits/chosen": -2.2660422325134277,
      "logits/rejected": -3.3465328216552734,
      "logps/chosen": -80.11656951904297,
      "logps/rejected": -151.94564819335938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7341630458831787,
      "rewards/margins": 9.608826637268066,
      "rewards/rejected": -5.874663829803467,
      "step": 1829
    },
    {
      "epoch": 0.732,
      "grad_norm": 0.07394466549158096,
      "learning_rate": 7.561333333333332e-07,
      "logits/chosen": -2.2727322578430176,
      "logits/rejected": -3.350160598754883,
      "logps/chosen": -83.14866638183594,
      "logps/rejected": -151.8743896484375,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.202301263809204,
      "rewards/margins": 7.463517665863037,
      "rewards/rejected": -6.261216163635254,
      "step": 1830
    },
    {
      "epoch": 0.7324,
      "grad_norm": 0.9526703953742981,
      "learning_rate": 7.559999999999999e-07,
      "logits/chosen": -2.3981876373291016,
      "logits/rejected": -2.9036617279052734,
      "logps/chosen": -137.77365112304688,
      "logps/rejected": -140.07603454589844,
      "loss": 0.0123,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3232818841934204,
      "rewards/margins": 5.54649543762207,
      "rewards/rejected": -5.223213195800781,
      "step": 1831
    },
    {
      "epoch": 0.7328,
      "grad_norm": 0.03976179286837578,
      "learning_rate": 7.558666666666666e-07,
      "logits/chosen": -2.4530506134033203,
      "logits/rejected": -3.367664337158203,
      "logps/chosen": -199.55203247070312,
      "logps/rejected": -189.48086547851562,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.63057804107666,
      "rewards/margins": 8.003952026367188,
      "rewards/rejected": -5.3733744621276855,
      "step": 1832
    },
    {
      "epoch": 0.7332,
      "grad_norm": 1.1482176780700684,
      "learning_rate": 7.557333333333333e-07,
      "logits/chosen": -2.2980105876922607,
      "logits/rejected": -1.8625348806381226,
      "logps/chosen": -105.79852294921875,
      "logps/rejected": -145.90585327148438,
      "loss": 0.0147,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7538173198699951,
      "rewards/margins": 6.198849201202393,
      "rewards/rejected": -4.445031642913818,
      "step": 1833
    },
    {
      "epoch": 0.7336,
      "grad_norm": 0.03482387587428093,
      "learning_rate": 7.556e-07,
      "logits/chosen": -2.289764165878296,
      "logits/rejected": -2.969827651977539,
      "logps/chosen": -109.45658111572266,
      "logps/rejected": -136.92239379882812,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.513240098953247,
      "rewards/margins": 8.010478973388672,
      "rewards/rejected": -4.497239589691162,
      "step": 1834
    },
    {
      "epoch": 0.734,
      "grad_norm": 0.007632522378116846,
      "learning_rate": 7.554666666666666e-07,
      "logits/chosen": -2.302349090576172,
      "logits/rejected": -3.072763681411743,
      "logps/chosen": -115.22149658203125,
      "logps/rejected": -195.95901489257812,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.465843677520752,
      "rewards/margins": 10.920580863952637,
      "rewards/rejected": -7.454737186431885,
      "step": 1835
    },
    {
      "epoch": 0.7344,
      "grad_norm": 0.01830531284213066,
      "learning_rate": 7.553333333333333e-07,
      "logits/chosen": -2.2979869842529297,
      "logits/rejected": -2.853226661682129,
      "logps/chosen": -98.753173828125,
      "logps/rejected": -166.4287872314453,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1451010704040527,
      "rewards/margins": 10.260980606079102,
      "rewards/rejected": -7.115879058837891,
      "step": 1836
    },
    {
      "epoch": 0.7348,
      "grad_norm": 0.022102627903223038,
      "learning_rate": 7.552e-07,
      "logits/chosen": -2.3070011138916016,
      "logits/rejected": -3.3172645568847656,
      "logps/chosen": -84.40013885498047,
      "logps/rejected": -152.52565002441406,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0337772369384766,
      "rewards/margins": 8.617498397827148,
      "rewards/rejected": -5.583721160888672,
      "step": 1837
    },
    {
      "epoch": 0.7352,
      "grad_norm": 0.3984682261943817,
      "learning_rate": 7.550666666666667e-07,
      "logits/chosen": -2.73656964302063,
      "logits/rejected": -3.2456178665161133,
      "logps/chosen": -266.05206298828125,
      "logps/rejected": -170.20663452148438,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1348915100097656,
      "rewards/margins": 6.220278263092041,
      "rewards/rejected": -5.085386753082275,
      "step": 1838
    },
    {
      "epoch": 0.7356,
      "grad_norm": 0.06516524404287338,
      "learning_rate": 7.549333333333333e-07,
      "logits/chosen": -2.204418659210205,
      "logits/rejected": -3.006861448287964,
      "logps/chosen": -91.66407775878906,
      "logps/rejected": -146.35336303710938,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.363948106765747,
      "rewards/margins": 8.45945930480957,
      "rewards/rejected": -5.095511436462402,
      "step": 1839
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.09387798607349396,
      "learning_rate": 7.548e-07,
      "logits/chosen": -2.026496410369873,
      "logits/rejected": -3.2701058387756348,
      "logps/chosen": -134.37387084960938,
      "logps/rejected": -166.83486938476562,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6763694286346436,
      "rewards/margins": 8.406543731689453,
      "rewards/rejected": -5.7301740646362305,
      "step": 1840
    },
    {
      "epoch": 0.7364,
      "grad_norm": 0.191945418715477,
      "learning_rate": 7.546666666666666e-07,
      "logits/chosen": -2.3973608016967773,
      "logits/rejected": -3.151843547821045,
      "logps/chosen": -118.220703125,
      "logps/rejected": -133.85682678222656,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7357555627822876,
      "rewards/margins": 6.9350690841674805,
      "rewards/rejected": -5.199313163757324,
      "step": 1841
    },
    {
      "epoch": 0.7368,
      "grad_norm": 0.43695029616355896,
      "learning_rate": 7.545333333333332e-07,
      "logits/chosen": -2.0657947063446045,
      "logits/rejected": -3.606693744659424,
      "logps/chosen": -160.05435180664062,
      "logps/rejected": -154.6946563720703,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3196632862091064,
      "rewards/margins": 6.92411994934082,
      "rewards/rejected": -5.604456901550293,
      "step": 1842
    },
    {
      "epoch": 0.7372,
      "grad_norm": 0.018040399998426437,
      "learning_rate": 7.543999999999999e-07,
      "logits/chosen": -2.260716199874878,
      "logits/rejected": -2.9810681343078613,
      "logps/chosen": -105.058837890625,
      "logps/rejected": -132.14089965820312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.1533989906311035,
      "rewards/margins": 8.511487007141113,
      "rewards/rejected": -4.35808801651001,
      "step": 1843
    },
    {
      "epoch": 0.7376,
      "grad_norm": 0.4097062349319458,
      "learning_rate": 7.542666666666666e-07,
      "logits/chosen": -1.9844496250152588,
      "logits/rejected": -3.1704177856445312,
      "logps/chosen": -65.40974426269531,
      "logps/rejected": -143.25302124023438,
      "loss": 0.0052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1979604959487915,
      "rewards/margins": 5.831459999084473,
      "rewards/rejected": -4.633499622344971,
      "step": 1844
    },
    {
      "epoch": 0.738,
      "grad_norm": 0.23811551928520203,
      "learning_rate": 7.541333333333333e-07,
      "logits/chosen": -1.9356060028076172,
      "logits/rejected": -2.9470889568328857,
      "logps/chosen": -129.83473205566406,
      "logps/rejected": -159.53509521484375,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1913914680480957,
      "rewards/margins": 7.32703971862793,
      "rewards/rejected": -5.135648250579834,
      "step": 1845
    },
    {
      "epoch": 0.7384,
      "grad_norm": 0.008987599983811378,
      "learning_rate": 7.54e-07,
      "logits/chosen": -2.457977056503296,
      "logits/rejected": -2.6352505683898926,
      "logps/chosen": -172.15811157226562,
      "logps/rejected": -176.0017547607422,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5119667053222656,
      "rewards/margins": 9.527467727661133,
      "rewards/rejected": -6.015501022338867,
      "step": 1846
    },
    {
      "epoch": 0.7388,
      "grad_norm": 0.019084010273218155,
      "learning_rate": 7.538666666666667e-07,
      "logits/chosen": -2.340545177459717,
      "logits/rejected": -3.149512529373169,
      "logps/chosen": -141.08132934570312,
      "logps/rejected": -163.478515625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.492602586746216,
      "rewards/margins": 8.987505912780762,
      "rewards/rejected": -5.494903564453125,
      "step": 1847
    },
    {
      "epoch": 0.7392,
      "grad_norm": 0.16539721190929413,
      "learning_rate": 7.537333333333333e-07,
      "logits/chosen": -2.203472137451172,
      "logits/rejected": -2.775421619415283,
      "logps/chosen": -135.9778289794922,
      "logps/rejected": -233.79421997070312,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6880134344100952,
      "rewards/margins": 6.489200592041016,
      "rewards/rejected": -5.801187515258789,
      "step": 1848
    },
    {
      "epoch": 0.7396,
      "grad_norm": 0.05798422917723656,
      "learning_rate": 7.536e-07,
      "logits/chosen": -1.7579079866409302,
      "logits/rejected": -2.960749387741089,
      "logps/chosen": -114.73056030273438,
      "logps/rejected": -135.97647094726562,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8237900733947754,
      "rewards/margins": 7.74915885925293,
      "rewards/rejected": -3.9253687858581543,
      "step": 1849
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.15818260610103607,
      "learning_rate": 7.534666666666666e-07,
      "logits/chosen": -2.3392739295959473,
      "logits/rejected": -3.275266647338867,
      "logps/chosen": -68.41461181640625,
      "logps/rejected": -125.14601135253906,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4005074501037598,
      "rewards/margins": 7.0660200119018555,
      "rewards/rejected": -3.6655125617980957,
      "step": 1850
    },
    {
      "epoch": 0.7404,
      "grad_norm": 0.49931657314300537,
      "learning_rate": 7.533333333333332e-07,
      "logits/chosen": -2.595003604888916,
      "logits/rejected": -3.212453842163086,
      "logps/chosen": -137.7366180419922,
      "logps/rejected": -123.99966430664062,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6591289043426514,
      "rewards/margins": 6.143085479736328,
      "rewards/rejected": -4.483956336975098,
      "step": 1851
    },
    {
      "epoch": 0.7408,
      "grad_norm": 0.04836731031537056,
      "learning_rate": 7.531999999999999e-07,
      "logits/chosen": -2.1901144981384277,
      "logits/rejected": -2.7548468112945557,
      "logps/chosen": -77.68296813964844,
      "logps/rejected": -186.83750915527344,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.792611598968506,
      "rewards/margins": 9.797060012817383,
      "rewards/rejected": -7.004448890686035,
      "step": 1852
    },
    {
      "epoch": 0.7412,
      "grad_norm": 0.3063547909259796,
      "learning_rate": 7.530666666666666e-07,
      "logits/chosen": -2.4496474266052246,
      "logits/rejected": -3.133021354675293,
      "logps/chosen": -83.78041076660156,
      "logps/rejected": -150.52175903320312,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.200515031814575,
      "rewards/margins": 8.142921447753906,
      "rewards/rejected": -5.94240665435791,
      "step": 1853
    },
    {
      "epoch": 0.7416,
      "grad_norm": 0.025231890380382538,
      "learning_rate": 7.529333333333333e-07,
      "logits/chosen": -1.9188700914382935,
      "logits/rejected": -2.9629483222961426,
      "logps/chosen": -113.27119445800781,
      "logps/rejected": -184.40225219726562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7791383266448975,
      "rewards/margins": 8.434585571289062,
      "rewards/rejected": -5.655447483062744,
      "step": 1854
    },
    {
      "epoch": 0.742,
      "grad_norm": 0.2534777820110321,
      "learning_rate": 7.528e-07,
      "logits/chosen": -2.2820427417755127,
      "logits/rejected": -3.0018489360809326,
      "logps/chosen": -135.75393676757812,
      "logps/rejected": -172.40487670898438,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1271206140518188,
      "rewards/margins": 5.874980926513672,
      "rewards/rejected": -4.747859954833984,
      "step": 1855
    },
    {
      "epoch": 0.7424,
      "grad_norm": 0.035204023122787476,
      "learning_rate": 7.526666666666667e-07,
      "logits/chosen": -2.2175657749176025,
      "logits/rejected": -3.958143711090088,
      "logps/chosen": -150.91595458984375,
      "logps/rejected": -154.3173370361328,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8820929527282715,
      "rewards/margins": 8.021233558654785,
      "rewards/rejected": -4.139140605926514,
      "step": 1856
    },
    {
      "epoch": 0.7428,
      "grad_norm": 1.5630277395248413,
      "learning_rate": 7.525333333333334e-07,
      "logits/chosen": -2.602478504180908,
      "logits/rejected": -3.1946306228637695,
      "logps/chosen": -167.078125,
      "logps/rejected": -150.47872924804688,
      "loss": 0.0207,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.861709713935852,
      "rewards/margins": 6.658857822418213,
      "rewards/rejected": -4.79714822769165,
      "step": 1857
    },
    {
      "epoch": 0.7432,
      "grad_norm": 0.06998956203460693,
      "learning_rate": 7.523999999999999e-07,
      "logits/chosen": -2.1926658153533936,
      "logits/rejected": -3.005682945251465,
      "logps/chosen": -106.43359375,
      "logps/rejected": -126.67083740234375,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.946018695831299,
      "rewards/margins": 7.903485298156738,
      "rewards/rejected": -3.9574666023254395,
      "step": 1858
    },
    {
      "epoch": 0.7436,
      "grad_norm": 3.4628517627716064,
      "learning_rate": 7.522666666666666e-07,
      "logits/chosen": -2.510707378387451,
      "logits/rejected": -3.358616352081299,
      "logps/chosen": -179.68003845214844,
      "logps/rejected": -179.46121215820312,
      "loss": 0.0239,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3840019404888153,
      "rewards/margins": 4.103598594665527,
      "rewards/rejected": -4.487600326538086,
      "step": 1859
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.8805884122848511,
      "learning_rate": 7.521333333333333e-07,
      "logits/chosen": -2.683375120162964,
      "logits/rejected": -2.9616966247558594,
      "logps/chosen": -105.99568939208984,
      "logps/rejected": -141.34918212890625,
      "loss": 0.0095,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38222619891166687,
      "rewards/margins": 4.930874824523926,
      "rewards/rejected": -4.548648834228516,
      "step": 1860
    },
    {
      "epoch": 0.7444,
      "grad_norm": 0.12802216410636902,
      "learning_rate": 7.52e-07,
      "logits/chosen": -1.9485645294189453,
      "logits/rejected": -3.5843753814697266,
      "logps/chosen": -175.21495056152344,
      "logps/rejected": -207.13735961914062,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2612216472625732,
      "rewards/margins": 6.961954116821289,
      "rewards/rejected": -5.700732231140137,
      "step": 1861
    },
    {
      "epoch": 0.7448,
      "grad_norm": 113.32215881347656,
      "learning_rate": 7.518666666666666e-07,
      "logits/chosen": -0.9399471282958984,
      "logits/rejected": -2.7052507400512695,
      "logps/chosen": -244.14254760742188,
      "logps/rejected": -127.55695343017578,
      "loss": 0.3919,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.3293067216873169,
      "rewards/margins": 3.7210335731506348,
      "rewards/rejected": -4.050340175628662,
      "step": 1862
    },
    {
      "epoch": 0.7452,
      "grad_norm": 0.07497673481702805,
      "learning_rate": 7.517333333333333e-07,
      "logits/chosen": -1.888498306274414,
      "logits/rejected": -3.6821818351745605,
      "logps/chosen": -134.67417907714844,
      "logps/rejected": -174.8464813232422,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3515114784240723,
      "rewards/margins": 7.505548477172852,
      "rewards/rejected": -5.154036998748779,
      "step": 1863
    },
    {
      "epoch": 0.7456,
      "grad_norm": 0.024332232773303986,
      "learning_rate": 7.516e-07,
      "logits/chosen": -2.346834182739258,
      "logits/rejected": -3.0478646755218506,
      "logps/chosen": -152.1710205078125,
      "logps/rejected": -186.74069213867188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.52130126953125,
      "rewards/margins": 8.374567985534668,
      "rewards/rejected": -4.853266716003418,
      "step": 1864
    },
    {
      "epoch": 0.746,
      "grad_norm": 0.0022916796151548624,
      "learning_rate": 7.514666666666666e-07,
      "logits/chosen": -2.163076877593994,
      "logits/rejected": -3.0464401245117188,
      "logps/chosen": -119.71717071533203,
      "logps/rejected": -172.68374633789062,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.515564918518066,
      "rewards/margins": 10.879822731018066,
      "rewards/rejected": -6.3642578125,
      "step": 1865
    },
    {
      "epoch": 0.7464,
      "grad_norm": 0.1332446187734604,
      "learning_rate": 7.513333333333333e-07,
      "logits/chosen": -2.6917519569396973,
      "logits/rejected": -3.380755662918091,
      "logps/chosen": -166.5966339111328,
      "logps/rejected": -158.10665893554688,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2948689460754395,
      "rewards/margins": 7.927395820617676,
      "rewards/rejected": -4.632526874542236,
      "step": 1866
    },
    {
      "epoch": 0.7468,
      "grad_norm": 0.37564870715141296,
      "learning_rate": 7.511999999999999e-07,
      "logits/chosen": -2.2516419887542725,
      "logits/rejected": -2.747039318084717,
      "logps/chosen": -78.07218933105469,
      "logps/rejected": -124.32611083984375,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7401689291000366,
      "rewards/margins": 6.426654815673828,
      "rewards/rejected": -4.686485767364502,
      "step": 1867
    },
    {
      "epoch": 0.7472,
      "grad_norm": 0.49832549691200256,
      "learning_rate": 7.510666666666666e-07,
      "logits/chosen": -2.5996246337890625,
      "logits/rejected": -3.0246291160583496,
      "logps/chosen": -195.57931518554688,
      "logps/rejected": -186.68557739257812,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19524914026260376,
      "rewards/margins": 6.750492095947266,
      "rewards/rejected": -6.555243015289307,
      "step": 1868
    },
    {
      "epoch": 0.7476,
      "grad_norm": 0.1165120080113411,
      "learning_rate": 7.509333333333333e-07,
      "logits/chosen": -2.771463632583618,
      "logits/rejected": -3.391296148300171,
      "logps/chosen": -176.44305419921875,
      "logps/rejected": -134.64553833007812,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8337295055389404,
      "rewards/margins": 6.629153251647949,
      "rewards/rejected": -4.79542350769043,
      "step": 1869
    },
    {
      "epoch": 0.748,
      "grad_norm": 0.2933099865913391,
      "learning_rate": 7.508e-07,
      "logits/chosen": -1.9504790306091309,
      "logits/rejected": -3.1023621559143066,
      "logps/chosen": -89.41503143310547,
      "logps/rejected": -204.0164337158203,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2013275623321533,
      "rewards/margins": 7.574007034301758,
      "rewards/rejected": -6.372679233551025,
      "step": 1870
    },
    {
      "epoch": 0.7484,
      "grad_norm": 1.6249428987503052,
      "learning_rate": 7.506666666666667e-07,
      "logits/chosen": -3.1524758338928223,
      "logits/rejected": -3.642458915710449,
      "logps/chosen": -147.15106201171875,
      "logps/rejected": -238.7769775390625,
      "loss": 0.0182,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.203626275062561,
      "rewards/margins": 7.142204284667969,
      "rewards/rejected": -5.938578128814697,
      "step": 1871
    },
    {
      "epoch": 0.7488,
      "grad_norm": 0.203450009226799,
      "learning_rate": 7.505333333333334e-07,
      "logits/chosen": -2.574277400970459,
      "logits/rejected": -3.110200881958008,
      "logps/chosen": -93.50450134277344,
      "logps/rejected": -137.91348266601562,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0767383575439453,
      "rewards/margins": 6.255891799926758,
      "rewards/rejected": -5.1791534423828125,
      "step": 1872
    },
    {
      "epoch": 0.7492,
      "grad_norm": 0.046583376824855804,
      "learning_rate": 7.503999999999999e-07,
      "logits/chosen": -2.6109766960144043,
      "logits/rejected": -3.363365650177002,
      "logps/chosen": -229.25399780273438,
      "logps/rejected": -180.26902770996094,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.398465156555176,
      "rewards/margins": 8.275619506835938,
      "rewards/rejected": -5.87715482711792,
      "step": 1873
    },
    {
      "epoch": 0.7496,
      "grad_norm": 0.18926411867141724,
      "learning_rate": 7.502666666666666e-07,
      "logits/chosen": -2.068274974822998,
      "logits/rejected": -3.376396894454956,
      "logps/chosen": -126.35747528076172,
      "logps/rejected": -146.5570068359375,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7389194965362549,
      "rewards/margins": 6.253115653991699,
      "rewards/rejected": -4.514195919036865,
      "step": 1874
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.002933397190645337,
      "learning_rate": 7.501333333333333e-07,
      "logits/chosen": -1.9713268280029297,
      "logits/rejected": -3.1430211067199707,
      "logps/chosen": -158.54847717285156,
      "logps/rejected": -177.35459899902344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.887728214263916,
      "rewards/margins": 10.887555122375488,
      "rewards/rejected": -6.9998273849487305,
      "step": 1875
    },
    {
      "epoch": 0.7504,
      "grad_norm": 0.20804156363010406,
      "learning_rate": 7.5e-07,
      "logits/chosen": -2.5253043174743652,
      "logits/rejected": -2.669362783432007,
      "logps/chosen": -181.9683074951172,
      "logps/rejected": -141.51593017578125,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0702760219573975,
      "rewards/margins": 6.58725643157959,
      "rewards/rejected": -4.5169806480407715,
      "step": 1876
    },
    {
      "epoch": 0.7508,
      "grad_norm": 0.23812441527843475,
      "learning_rate": 7.498666666666666e-07,
      "logits/chosen": -2.013650894165039,
      "logits/rejected": -3.179166793823242,
      "logps/chosen": -83.8204574584961,
      "logps/rejected": -177.91387939453125,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0359959602355957,
      "rewards/margins": 8.807598114013672,
      "rewards/rejected": -6.771601676940918,
      "step": 1877
    },
    {
      "epoch": 0.7512,
      "grad_norm": 0.013670642860233784,
      "learning_rate": 7.497333333333333e-07,
      "logits/chosen": -2.616886615753174,
      "logits/rejected": -3.6647226810455322,
      "logps/chosen": -159.49624633789062,
      "logps/rejected": -181.757568359375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.03027081489563,
      "rewards/margins": 9.450799942016602,
      "rewards/rejected": -6.420529365539551,
      "step": 1878
    },
    {
      "epoch": 0.7516,
      "grad_norm": 0.2480558454990387,
      "learning_rate": 7.496e-07,
      "logits/chosen": -2.2872157096862793,
      "logits/rejected": -2.853574752807617,
      "logps/chosen": -120.66242980957031,
      "logps/rejected": -154.3688507080078,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7428274154663086,
      "rewards/margins": 7.412096977233887,
      "rewards/rejected": -5.669269561767578,
      "step": 1879
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.024184247478842735,
      "learning_rate": 7.494666666666666e-07,
      "logits/chosen": -2.3725240230560303,
      "logits/rejected": -3.0781917572021484,
      "logps/chosen": -123.11767578125,
      "logps/rejected": -218.2134552001953,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.803353309631348,
      "rewards/margins": 9.400790214538574,
      "rewards/rejected": -4.597436904907227,
      "step": 1880
    },
    {
      "epoch": 0.7524,
      "grad_norm": 0.10134975612163544,
      "learning_rate": 7.493333333333333e-07,
      "logits/chosen": -2.2423810958862305,
      "logits/rejected": -3.1311638355255127,
      "logps/chosen": -197.7117462158203,
      "logps/rejected": -153.40167236328125,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9480366706848145,
      "rewards/margins": 7.492277145385742,
      "rewards/rejected": -5.5442399978637695,
      "step": 1881
    },
    {
      "epoch": 0.7528,
      "grad_norm": 0.47208836674690247,
      "learning_rate": 7.492e-07,
      "logits/chosen": -1.821549415588379,
      "logits/rejected": -2.832858085632324,
      "logps/chosen": -126.55619812011719,
      "logps/rejected": -116.22122192382812,
      "loss": 0.0048,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2562339305877686,
      "rewards/margins": 5.870779991149902,
      "rewards/rejected": -3.6145458221435547,
      "step": 1882
    },
    {
      "epoch": 0.7532,
      "grad_norm": 0.13199451565742493,
      "learning_rate": 7.490666666666667e-07,
      "logits/chosen": -2.029165267944336,
      "logits/rejected": -3.4172239303588867,
      "logps/chosen": -123.72129821777344,
      "logps/rejected": -175.54043579101562,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9913746118545532,
      "rewards/margins": 6.907853126525879,
      "rewards/rejected": -5.916478157043457,
      "step": 1883
    },
    {
      "epoch": 0.7536,
      "grad_norm": 0.07317253202199936,
      "learning_rate": 7.489333333333333e-07,
      "logits/chosen": -2.2253804206848145,
      "logits/rejected": -2.863377571105957,
      "logps/chosen": -148.90646362304688,
      "logps/rejected": -161.00485229492188,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.625518798828125,
      "rewards/margins": 7.88173246383667,
      "rewards/rejected": -5.256213665008545,
      "step": 1884
    },
    {
      "epoch": 0.754,
      "grad_norm": 0.48468509316444397,
      "learning_rate": 7.488e-07,
      "logits/chosen": -1.9928841590881348,
      "logits/rejected": -2.9875648021698,
      "logps/chosen": -143.05099487304688,
      "logps/rejected": -134.939697265625,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0386513471603394,
      "rewards/margins": 6.557432174682617,
      "rewards/rejected": -5.5187811851501465,
      "step": 1885
    },
    {
      "epoch": 0.7544,
      "grad_norm": 0.7317161560058594,
      "learning_rate": 7.486666666666666e-07,
      "logits/chosen": -2.644465923309326,
      "logits/rejected": -3.2680914402008057,
      "logps/chosen": -113.081298828125,
      "logps/rejected": -139.12124633789062,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8319569826126099,
      "rewards/margins": 6.938724517822266,
      "rewards/rejected": -5.106767654418945,
      "step": 1886
    },
    {
      "epoch": 0.7548,
      "grad_norm": 0.01810602843761444,
      "learning_rate": 7.485333333333333e-07,
      "logits/chosen": -2.587890386581421,
      "logits/rejected": -3.628899335861206,
      "logps/chosen": -109.86087799072266,
      "logps/rejected": -186.60203552246094,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2687950134277344,
      "rewards/margins": 9.351441383361816,
      "rewards/rejected": -6.082646369934082,
      "step": 1887
    },
    {
      "epoch": 0.7552,
      "grad_norm": 0.07709472626447678,
      "learning_rate": 7.483999999999999e-07,
      "logits/chosen": -2.337306499481201,
      "logits/rejected": -3.652963638305664,
      "logps/chosen": -82.76950073242188,
      "logps/rejected": -153.42498779296875,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8921408653259277,
      "rewards/margins": 8.345161437988281,
      "rewards/rejected": -5.453021049499512,
      "step": 1888
    },
    {
      "epoch": 0.7556,
      "grad_norm": 0.010158700868487358,
      "learning_rate": 7.482666666666666e-07,
      "logits/chosen": -2.0867807865142822,
      "logits/rejected": -2.7724499702453613,
      "logps/chosen": -80.27352142333984,
      "logps/rejected": -153.97311401367188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.395293712615967,
      "rewards/margins": 10.308219909667969,
      "rewards/rejected": -6.91292667388916,
      "step": 1889
    },
    {
      "epoch": 0.756,
      "grad_norm": 0.7982025146484375,
      "learning_rate": 7.481333333333333e-07,
      "logits/chosen": -2.2869396209716797,
      "logits/rejected": -2.995100975036621,
      "logps/chosen": -122.75120544433594,
      "logps/rejected": -140.87924194335938,
      "loss": 0.0086,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6211876273155212,
      "rewards/margins": 5.075077533721924,
      "rewards/rejected": -4.453889846801758,
      "step": 1890
    },
    {
      "epoch": 0.7564,
      "grad_norm": 0.4043554663658142,
      "learning_rate": 7.48e-07,
      "logits/chosen": -2.9148411750793457,
      "logits/rejected": -2.8680028915405273,
      "logps/chosen": -122.22280883789062,
      "logps/rejected": -145.39678955078125,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3270022869110107,
      "rewards/margins": 6.844956398010254,
      "rewards/rejected": -4.517953395843506,
      "step": 1891
    },
    {
      "epoch": 0.7568,
      "grad_norm": 0.44043952226638794,
      "learning_rate": 7.478666666666667e-07,
      "logits/chosen": -1.8733916282653809,
      "logits/rejected": -3.18068790435791,
      "logps/chosen": -168.28814697265625,
      "logps/rejected": -179.3385009765625,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4840202331542969,
      "rewards/margins": 8.297975540161133,
      "rewards/rejected": -6.813955307006836,
      "step": 1892
    },
    {
      "epoch": 0.7572,
      "grad_norm": 0.02976890839636326,
      "learning_rate": 7.477333333333334e-07,
      "logits/chosen": -2.3055803775787354,
      "logits/rejected": -2.7870683670043945,
      "logps/chosen": -165.72467041015625,
      "logps/rejected": -180.73782348632812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.095745086669922,
      "rewards/margins": 8.896512985229492,
      "rewards/rejected": -5.80076789855957,
      "step": 1893
    },
    {
      "epoch": 0.7576,
      "grad_norm": 1.258142113685608,
      "learning_rate": 7.476e-07,
      "logits/chosen": -2.7497024536132812,
      "logits/rejected": -3.562612533569336,
      "logps/chosen": -159.96340942382812,
      "logps/rejected": -168.0134735107422,
      "loss": 0.009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.486871361732483,
      "rewards/margins": 5.772517204284668,
      "rewards/rejected": -4.285645961761475,
      "step": 1894
    },
    {
      "epoch": 0.758,
      "grad_norm": 0.08564826101064682,
      "learning_rate": 7.474666666666665e-07,
      "logits/chosen": -2.1857595443725586,
      "logits/rejected": -2.9837846755981445,
      "logps/chosen": -103.77812194824219,
      "logps/rejected": -183.64767456054688,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3500614166259766,
      "rewards/margins": 7.457569122314453,
      "rewards/rejected": -5.107507705688477,
      "step": 1895
    },
    {
      "epoch": 0.7584,
      "grad_norm": 1.3085565567016602,
      "learning_rate": 7.473333333333332e-07,
      "logits/chosen": -2.0589799880981445,
      "logits/rejected": -2.8987441062927246,
      "logps/chosen": -149.3647003173828,
      "logps/rejected": -131.7489471435547,
      "loss": 0.0161,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11129951477050781,
      "rewards/margins": 4.126482009887695,
      "rewards/rejected": -4.0151824951171875,
      "step": 1896
    },
    {
      "epoch": 0.7588,
      "grad_norm": 0.13144049048423767,
      "learning_rate": 7.471999999999999e-07,
      "logits/chosen": -2.0094218254089355,
      "logits/rejected": -2.5975399017333984,
      "logps/chosen": -124.82632446289062,
      "logps/rejected": -138.18087768554688,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5710513591766357,
      "rewards/margins": 7.3474836349487305,
      "rewards/rejected": -4.776432037353516,
      "step": 1897
    },
    {
      "epoch": 0.7592,
      "grad_norm": 0.017261074855923653,
      "learning_rate": 7.470666666666666e-07,
      "logits/chosen": -2.4337382316589355,
      "logits/rejected": -3.4349865913391113,
      "logps/chosen": -123.66610717773438,
      "logps/rejected": -172.03892517089844,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.756937026977539,
      "rewards/margins": 9.302200317382812,
      "rewards/rejected": -5.545262336730957,
      "step": 1898
    },
    {
      "epoch": 0.7596,
      "grad_norm": 0.01841713860630989,
      "learning_rate": 7.469333333333333e-07,
      "logits/chosen": -2.652803421020508,
      "logits/rejected": -3.1517062187194824,
      "logps/chosen": -155.22567749023438,
      "logps/rejected": -189.10317993164062,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.453601121902466,
      "rewards/margins": 8.68887710571289,
      "rewards/rejected": -5.235276222229004,
      "step": 1899
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.009797156788408756,
      "learning_rate": 7.468e-07,
      "logits/chosen": -2.5756843090057373,
      "logits/rejected": -2.7082698345184326,
      "logps/chosen": -99.41424560546875,
      "logps/rejected": -208.7714385986328,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.791012287139893,
      "rewards/margins": 9.852371215820312,
      "rewards/rejected": -5.061358451843262,
      "step": 1900
    },
    {
      "epoch": 0.7604,
      "grad_norm": 0.170979306101799,
      "learning_rate": 7.466666666666667e-07,
      "logits/chosen": -1.8710086345672607,
      "logits/rejected": -3.062407970428467,
      "logps/chosen": -98.88650512695312,
      "logps/rejected": -133.49615478515625,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5362367630004883,
      "rewards/margins": 6.563610076904297,
      "rewards/rejected": -4.027373313903809,
      "step": 1901
    },
    {
      "epoch": 0.7608,
      "grad_norm": 0.06643948704004288,
      "learning_rate": 7.465333333333334e-07,
      "logits/chosen": -2.2929065227508545,
      "logits/rejected": -3.3389124870300293,
      "logps/chosen": -97.10799407958984,
      "logps/rejected": -138.36013793945312,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9198460578918457,
      "rewards/margins": 8.26102066040039,
      "rewards/rejected": -4.341174602508545,
      "step": 1902
    },
    {
      "epoch": 0.7612,
      "grad_norm": 0.08949197083711624,
      "learning_rate": 7.464e-07,
      "logits/chosen": -1.933159589767456,
      "logits/rejected": -2.8857903480529785,
      "logps/chosen": -116.08193969726562,
      "logps/rejected": -196.34703063964844,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9279247522354126,
      "rewards/margins": 7.41929292678833,
      "rewards/rejected": -5.491368293762207,
      "step": 1903
    },
    {
      "epoch": 0.7616,
      "grad_norm": 0.279868483543396,
      "learning_rate": 7.462666666666667e-07,
      "logits/chosen": -1.866959810256958,
      "logits/rejected": -2.6314239501953125,
      "logps/chosen": -117.7615737915039,
      "logps/rejected": -134.6890869140625,
      "loss": 0.0047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9511650800704956,
      "rewards/margins": 6.74877405166626,
      "rewards/rejected": -4.797608852386475,
      "step": 1904
    },
    {
      "epoch": 0.762,
      "grad_norm": 0.04707631468772888,
      "learning_rate": 7.461333333333332e-07,
      "logits/chosen": -2.4057440757751465,
      "logits/rejected": -3.530454397201538,
      "logps/chosen": -146.1305694580078,
      "logps/rejected": -187.13427734375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.044586181640625,
      "rewards/margins": 8.133681297302246,
      "rewards/rejected": -5.089095115661621,
      "step": 1905
    },
    {
      "epoch": 0.7624,
      "grad_norm": 0.14011338353157043,
      "learning_rate": 7.459999999999999e-07,
      "logits/chosen": -2.3325066566467285,
      "logits/rejected": -3.540274143218994,
      "logps/chosen": -102.10325622558594,
      "logps/rejected": -154.26370239257812,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4998817443847656,
      "rewards/margins": 6.649867057800293,
      "rewards/rejected": -5.149985313415527,
      "step": 1906
    },
    {
      "epoch": 0.7628,
      "grad_norm": 0.027490127831697464,
      "learning_rate": 7.458666666666666e-07,
      "logits/chosen": -2.2053675651550293,
      "logits/rejected": -3.198456287384033,
      "logps/chosen": -110.89927673339844,
      "logps/rejected": -203.55702209472656,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.302172899246216,
      "rewards/margins": 10.43259048461914,
      "rewards/rejected": -7.130417823791504,
      "step": 1907
    },
    {
      "epoch": 0.7632,
      "grad_norm": 0.02295099012553692,
      "learning_rate": 7.457333333333333e-07,
      "logits/chosen": -2.00608491897583,
      "logits/rejected": -2.950960397720337,
      "logps/chosen": -77.7720718383789,
      "logps/rejected": -151.43389892578125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6629819869995117,
      "rewards/margins": 8.450782775878906,
      "rewards/rejected": -4.787801265716553,
      "step": 1908
    },
    {
      "epoch": 0.7636,
      "grad_norm": 0.16871212422847748,
      "learning_rate": 7.456e-07,
      "logits/chosen": -2.755075216293335,
      "logits/rejected": -3.102203369140625,
      "logps/chosen": -164.42935180664062,
      "logps/rejected": -153.78167724609375,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.403881788253784,
      "rewards/margins": 6.821394920349121,
      "rewards/rejected": -4.417513370513916,
      "step": 1909
    },
    {
      "epoch": 0.764,
      "grad_norm": 0.6340078711509705,
      "learning_rate": 7.454666666666667e-07,
      "logits/chosen": -2.412614345550537,
      "logits/rejected": -2.987622022628784,
      "logps/chosen": -174.48985290527344,
      "logps/rejected": -176.43365478515625,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2454540729522705,
      "rewards/margins": 8.017799377441406,
      "rewards/rejected": -5.772345542907715,
      "step": 1910
    },
    {
      "epoch": 0.7644,
      "grad_norm": 5.743634223937988,
      "learning_rate": 7.453333333333333e-07,
      "logits/chosen": -2.821756601333618,
      "logits/rejected": -3.3678674697875977,
      "logps/chosen": -157.02806091308594,
      "logps/rejected": -176.06573486328125,
      "loss": 0.0542,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2962658405303955,
      "rewards/margins": 5.914890766143799,
      "rewards/rejected": -5.618624687194824,
      "step": 1911
    },
    {
      "epoch": 0.7648,
      "grad_norm": 0.005109846591949463,
      "learning_rate": 7.452e-07,
      "logits/chosen": -2.8906960487365723,
      "logits/rejected": -3.4109458923339844,
      "logps/chosen": -120.89558410644531,
      "logps/rejected": -194.156494140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5074071884155273,
      "rewards/margins": 10.230318069458008,
      "rewards/rejected": -6.722910404205322,
      "step": 1912
    },
    {
      "epoch": 0.7652,
      "grad_norm": 0.2597619593143463,
      "learning_rate": 7.450666666666667e-07,
      "logits/chosen": -2.049095392227173,
      "logits/rejected": -2.6256237030029297,
      "logps/chosen": -94.45278930664062,
      "logps/rejected": -171.2255859375,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.326841115951538,
      "rewards/margins": 6.0807695388793945,
      "rewards/rejected": -3.7539284229278564,
      "step": 1913
    },
    {
      "epoch": 0.7656,
      "grad_norm": 0.05921415612101555,
      "learning_rate": 7.449333333333333e-07,
      "logits/chosen": -1.787508249282837,
      "logits/rejected": -2.554114818572998,
      "logps/chosen": -161.95989990234375,
      "logps/rejected": -158.9586639404297,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.67647123336792,
      "rewards/margins": 7.624472618103027,
      "rewards/rejected": -4.948000907897949,
      "step": 1914
    },
    {
      "epoch": 0.766,
      "grad_norm": 0.14163357019424438,
      "learning_rate": 7.447999999999999e-07,
      "logits/chosen": -2.547637939453125,
      "logits/rejected": -2.68228816986084,
      "logps/chosen": -171.5996551513672,
      "logps/rejected": -158.58445739746094,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4458484649658203,
      "rewards/margins": 6.791413307189941,
      "rewards/rejected": -4.345564842224121,
      "step": 1915
    },
    {
      "epoch": 0.7664,
      "grad_norm": 0.08247459679841995,
      "learning_rate": 7.446666666666666e-07,
      "logits/chosen": -2.1643800735473633,
      "logits/rejected": -2.914193630218506,
      "logps/chosen": -102.77250671386719,
      "logps/rejected": -167.0628204345703,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5811574459075928,
      "rewards/margins": 7.803396224975586,
      "rewards/rejected": -4.222238540649414,
      "step": 1916
    },
    {
      "epoch": 0.7668,
      "grad_norm": 0.08435924351215363,
      "learning_rate": 7.445333333333333e-07,
      "logits/chosen": -2.4073562622070312,
      "logits/rejected": -3.1982882022857666,
      "logps/chosen": -127.1390609741211,
      "logps/rejected": -196.117431640625,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5274338722229004,
      "rewards/margins": 8.31303596496582,
      "rewards/rejected": -5.78560209274292,
      "step": 1917
    },
    {
      "epoch": 0.7672,
      "grad_norm": 0.08940009027719498,
      "learning_rate": 7.443999999999999e-07,
      "logits/chosen": -2.2863831520080566,
      "logits/rejected": -3.3620691299438477,
      "logps/chosen": -121.0732192993164,
      "logps/rejected": -136.32492065429688,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.413039445877075,
      "rewards/margins": 7.3447957038879395,
      "rewards/rejected": -4.931756019592285,
      "step": 1918
    },
    {
      "epoch": 0.7676,
      "grad_norm": 0.7486031651496887,
      "learning_rate": 7.442666666666666e-07,
      "logits/chosen": -2.175199508666992,
      "logits/rejected": -3.5978102684020996,
      "logps/chosen": -124.51849365234375,
      "logps/rejected": -149.13278198242188,
      "loss": 0.0069,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8137286901473999,
      "rewards/margins": 5.20670223236084,
      "rewards/rejected": -4.392972946166992,
      "step": 1919
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.45013076066970825,
      "learning_rate": 7.441333333333333e-07,
      "logits/chosen": -2.153046131134033,
      "logits/rejected": -2.9654483795166016,
      "logps/chosen": -95.65806579589844,
      "logps/rejected": -175.585205078125,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9728443622589111,
      "rewards/margins": 6.733717918395996,
      "rewards/rejected": -4.760873317718506,
      "step": 1920
    },
    {
      "epoch": 0.7684,
      "grad_norm": 0.613192081451416,
      "learning_rate": 7.44e-07,
      "logits/chosen": -1.7124733924865723,
      "logits/rejected": -3.004638671875,
      "logps/chosen": -138.93658447265625,
      "logps/rejected": -144.13990783691406,
      "loss": 0.007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08803711831569672,
      "rewards/margins": 5.078248023986816,
      "rewards/rejected": -5.166285514831543,
      "step": 1921
    },
    {
      "epoch": 0.7688,
      "grad_norm": 0.017617160454392433,
      "learning_rate": 7.438666666666667e-07,
      "logits/chosen": -2.306281566619873,
      "logits/rejected": -3.3169760704040527,
      "logps/chosen": -125.18873596191406,
      "logps/rejected": -183.61184692382812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.776390552520752,
      "rewards/margins": 9.145583152770996,
      "rewards/rejected": -5.369192123413086,
      "step": 1922
    },
    {
      "epoch": 0.7692,
      "grad_norm": 1.6894875764846802,
      "learning_rate": 7.437333333333334e-07,
      "logits/chosen": -2.7222652435302734,
      "logits/rejected": -2.9553980827331543,
      "logps/chosen": -182.490966796875,
      "logps/rejected": -138.972412109375,
      "loss": 0.0188,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10484810173511505,
      "rewards/margins": 4.220090866088867,
      "rewards/rejected": -4.324938774108887,
      "step": 1923
    },
    {
      "epoch": 0.7696,
      "grad_norm": 0.024105237796902657,
      "learning_rate": 7.436e-07,
      "logits/chosen": -2.741741180419922,
      "logits/rejected": -3.142049551010132,
      "logps/chosen": -118.74617004394531,
      "logps/rejected": -167.37130737304688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1570253372192383,
      "rewards/margins": 8.903133392333984,
      "rewards/rejected": -5.746108055114746,
      "step": 1924
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.02529035694897175,
      "learning_rate": 7.434666666666667e-07,
      "logits/chosen": -2.354973554611206,
      "logits/rejected": -3.2399020195007324,
      "logps/chosen": -129.41119384765625,
      "logps/rejected": -169.03245544433594,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6252760887145996,
      "rewards/margins": 9.596136093139648,
      "rewards/rejected": -5.970860004425049,
      "step": 1925
    },
    {
      "epoch": 0.7704,
      "grad_norm": 0.06215489283204079,
      "learning_rate": 7.433333333333332e-07,
      "logits/chosen": -2.0216312408447266,
      "logits/rejected": -2.5713000297546387,
      "logps/chosen": -112.36616516113281,
      "logps/rejected": -152.52589416503906,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7802876234054565,
      "rewards/margins": 7.634012222290039,
      "rewards/rejected": -5.853724479675293,
      "step": 1926
    },
    {
      "epoch": 0.7708,
      "grad_norm": 1.1773416996002197,
      "learning_rate": 7.431999999999999e-07,
      "logits/chosen": -1.9792829751968384,
      "logits/rejected": -2.9088587760925293,
      "logps/chosen": -110.52947998046875,
      "logps/rejected": -167.42906188964844,
      "loss": 0.0122,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.601260781288147,
      "rewards/margins": 5.432578086853027,
      "rewards/rejected": -6.033838748931885,
      "step": 1927
    },
    {
      "epoch": 0.7712,
      "grad_norm": 0.04424517601728439,
      "learning_rate": 7.430666666666666e-07,
      "logits/chosen": -2.066735029220581,
      "logits/rejected": -3.3193979263305664,
      "logps/chosen": -125.858642578125,
      "logps/rejected": -170.86392211914062,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9030699729919434,
      "rewards/margins": 7.709678649902344,
      "rewards/rejected": -4.8066086769104,
      "step": 1928
    },
    {
      "epoch": 0.7716,
      "grad_norm": 0.059688497334718704,
      "learning_rate": 7.429333333333333e-07,
      "logits/chosen": -2.585672378540039,
      "logits/rejected": -2.8905861377716064,
      "logps/chosen": -178.27835083007812,
      "logps/rejected": -157.4463348388672,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4488234519958496,
      "rewards/margins": 9.178731918334961,
      "rewards/rejected": -6.729907989501953,
      "step": 1929
    },
    {
      "epoch": 0.772,
      "grad_norm": 0.47005340456962585,
      "learning_rate": 7.428e-07,
      "logits/chosen": -2.1212830543518066,
      "logits/rejected": -3.2100398540496826,
      "logps/chosen": -122.20265197753906,
      "logps/rejected": -130.81980895996094,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.967922568321228,
      "rewards/margins": 5.183041572570801,
      "rewards/rejected": -4.215119361877441,
      "step": 1930
    },
    {
      "epoch": 0.7724,
      "grad_norm": 0.03643283620476723,
      "learning_rate": 7.426666666666667e-07,
      "logits/chosen": -2.2482242584228516,
      "logits/rejected": -3.318735122680664,
      "logps/chosen": -115.53965759277344,
      "logps/rejected": -185.9447021484375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7089734077453613,
      "rewards/margins": 8.642017364501953,
      "rewards/rejected": -5.933043479919434,
      "step": 1931
    },
    {
      "epoch": 0.7728,
      "grad_norm": 1.435496211051941,
      "learning_rate": 7.425333333333334e-07,
      "logits/chosen": -2.2816991806030273,
      "logits/rejected": -2.908255100250244,
      "logps/chosen": -121.37213134765625,
      "logps/rejected": -127.40506744384766,
      "loss": 0.0178,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.48372724652290344,
      "rewards/margins": 4.281705856323242,
      "rewards/rejected": -3.797978401184082,
      "step": 1932
    },
    {
      "epoch": 0.7732,
      "grad_norm": 0.039961956441402435,
      "learning_rate": 7.423999999999999e-07,
      "logits/chosen": -2.611467123031616,
      "logits/rejected": -3.444610118865967,
      "logps/chosen": -184.02838134765625,
      "logps/rejected": -175.25848388671875,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8212761878967285,
      "rewards/margins": 7.8085174560546875,
      "rewards/rejected": -4.987241268157959,
      "step": 1933
    },
    {
      "epoch": 0.7736,
      "grad_norm": 0.11341537535190582,
      "learning_rate": 7.422666666666666e-07,
      "logits/chosen": -2.5996642112731934,
      "logits/rejected": -3.5437324047088623,
      "logps/chosen": -94.98110961914062,
      "logps/rejected": -167.65444946289062,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.876943588256836,
      "rewards/margins": 7.2510833740234375,
      "rewards/rejected": -5.374139785766602,
      "step": 1934
    },
    {
      "epoch": 0.774,
      "grad_norm": 0.0035784554202109575,
      "learning_rate": 7.421333333333333e-07,
      "logits/chosen": -1.996020793914795,
      "logits/rejected": -3.048161029815674,
      "logps/chosen": -138.49685668945312,
      "logps/rejected": -157.60968017578125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4384260177612305,
      "rewards/margins": 10.108255386352539,
      "rewards/rejected": -6.66982889175415,
      "step": 1935
    },
    {
      "epoch": 0.7744,
      "grad_norm": 0.7364325523376465,
      "learning_rate": 7.42e-07,
      "logits/chosen": -1.6864985227584839,
      "logits/rejected": -2.953949451446533,
      "logps/chosen": -128.6228790283203,
      "logps/rejected": -161.82077026367188,
      "loss": 0.0077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8602913022041321,
      "rewards/margins": 5.716145038604736,
      "rewards/rejected": -4.855854034423828,
      "step": 1936
    },
    {
      "epoch": 0.7748,
      "grad_norm": 0.012722264043986797,
      "learning_rate": 7.418666666666666e-07,
      "logits/chosen": -2.1642661094665527,
      "logits/rejected": -3.0380096435546875,
      "logps/chosen": -102.05683898925781,
      "logps/rejected": -172.70294189453125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.566788196563721,
      "rewards/margins": 9.677655220031738,
      "rewards/rejected": -5.110867500305176,
      "step": 1937
    },
    {
      "epoch": 0.7752,
      "grad_norm": 0.04536427557468414,
      "learning_rate": 7.417333333333333e-07,
      "logits/chosen": -1.9858312606811523,
      "logits/rejected": -3.2420668601989746,
      "logps/chosen": -129.17263793945312,
      "logps/rejected": -156.448974609375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2911252975463867,
      "rewards/margins": 8.427664756774902,
      "rewards/rejected": -5.136539459228516,
      "step": 1938
    },
    {
      "epoch": 0.7756,
      "grad_norm": 0.028285078704357147,
      "learning_rate": 7.416e-07,
      "logits/chosen": -2.183459520339966,
      "logits/rejected": -3.246582508087158,
      "logps/chosen": -85.27574157714844,
      "logps/rejected": -146.18118286132812,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6020150184631348,
      "rewards/margins": 8.217269897460938,
      "rewards/rejected": -5.615255355834961,
      "step": 1939
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.15902352333068848,
      "learning_rate": 7.414666666666667e-07,
      "logits/chosen": -2.0597360134124756,
      "logits/rejected": -2.29367733001709,
      "logps/chosen": -88.10116577148438,
      "logps/rejected": -148.271484375,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.657635688781738,
      "rewards/margins": 7.858752250671387,
      "rewards/rejected": -3.2011163234710693,
      "step": 1940
    },
    {
      "epoch": 0.7764,
      "grad_norm": 0.03690721467137337,
      "learning_rate": 7.413333333333333e-07,
      "logits/chosen": -2.3189687728881836,
      "logits/rejected": -3.5116872787475586,
      "logps/chosen": -118.88507080078125,
      "logps/rejected": -172.94073486328125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9041953086853027,
      "rewards/margins": 9.440786361694336,
      "rewards/rejected": -6.536590576171875,
      "step": 1941
    },
    {
      "epoch": 0.7768,
      "grad_norm": 0.1520835906267166,
      "learning_rate": 7.411999999999999e-07,
      "logits/chosen": -2.1351702213287354,
      "logits/rejected": -2.5880913734436035,
      "logps/chosen": -133.58897399902344,
      "logps/rejected": -190.62478637695312,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8368306159973145,
      "rewards/margins": 8.532188415527344,
      "rewards/rejected": -4.695357322692871,
      "step": 1942
    },
    {
      "epoch": 0.7772,
      "grad_norm": 0.549598217010498,
      "learning_rate": 7.410666666666666e-07,
      "logits/chosen": -3.1621336936950684,
      "logits/rejected": -3.3268208503723145,
      "logps/chosen": -154.6827850341797,
      "logps/rejected": -127.59739685058594,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.343902587890625,
      "rewards/margins": 5.871066093444824,
      "rewards/rejected": -4.527163982391357,
      "step": 1943
    },
    {
      "epoch": 0.7776,
      "grad_norm": 0.3376791775226593,
      "learning_rate": 7.409333333333333e-07,
      "logits/chosen": -3.2631850242614746,
      "logits/rejected": -3.4672627449035645,
      "logps/chosen": -167.5145721435547,
      "logps/rejected": -159.37892150878906,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8370258808135986,
      "rewards/margins": 7.085928440093994,
      "rewards/rejected": -5.248902797698975,
      "step": 1944
    },
    {
      "epoch": 0.778,
      "grad_norm": 0.08748690038919449,
      "learning_rate": 7.408e-07,
      "logits/chosen": -2.342970371246338,
      "logits/rejected": -3.451470375061035,
      "logps/chosen": -83.32183837890625,
      "logps/rejected": -139.2376708984375,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5866408348083496,
      "rewards/margins": 8.113643646240234,
      "rewards/rejected": -4.527002334594727,
      "step": 1945
    },
    {
      "epoch": 0.7784,
      "grad_norm": 0.13537319004535675,
      "learning_rate": 7.406666666666667e-07,
      "logits/chosen": -2.6879725456237793,
      "logits/rejected": -2.9123244285583496,
      "logps/chosen": -116.64029693603516,
      "logps/rejected": -140.1047821044922,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1091365814208984,
      "rewards/margins": 6.6559247970581055,
      "rewards/rejected": -4.546787738800049,
      "step": 1946
    },
    {
      "epoch": 0.7788,
      "grad_norm": 0.0011389877181500196,
      "learning_rate": 7.405333333333333e-07,
      "logits/chosen": -2.525395393371582,
      "logits/rejected": -3.009105682373047,
      "logps/chosen": -162.862060546875,
      "logps/rejected": -157.0176239013672,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 5.638396263122559,
      "rewards/margins": 11.84634780883789,
      "rewards/rejected": -6.207951545715332,
      "step": 1947
    },
    {
      "epoch": 0.7792,
      "grad_norm": 1.915661096572876,
      "learning_rate": 7.403999999999999e-07,
      "logits/chosen": -2.295609951019287,
      "logits/rejected": -3.0268282890319824,
      "logps/chosen": -159.98240661621094,
      "logps/rejected": -151.0193328857422,
      "loss": 0.0107,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.742558240890503,
      "rewards/margins": 6.911489963531494,
      "rewards/rejected": -5.168931484222412,
      "step": 1948
    },
    {
      "epoch": 0.7796,
      "grad_norm": 0.04778605327010155,
      "learning_rate": 7.402666666666666e-07,
      "logits/chosen": -2.046776056289673,
      "logits/rejected": -3.1804416179656982,
      "logps/chosen": -69.31510925292969,
      "logps/rejected": -160.765625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.238129138946533,
      "rewards/margins": 8.913318634033203,
      "rewards/rejected": -5.675189971923828,
      "step": 1949
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.04004066437482834,
      "learning_rate": 7.401333333333333e-07,
      "logits/chosen": -2.113107919692993,
      "logits/rejected": -3.3121442794799805,
      "logps/chosen": -98.93780517578125,
      "logps/rejected": -169.9886932373047,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2592310905456543,
      "rewards/margins": 8.706317901611328,
      "rewards/rejected": -5.447086334228516,
      "step": 1950
    },
    {
      "epoch": 0.7804,
      "grad_norm": 1.7191590070724487,
      "learning_rate": 7.4e-07,
      "logits/chosen": -1.8358721733093262,
      "logits/rejected": -2.623755931854248,
      "logps/chosen": -141.6778106689453,
      "logps/rejected": -124.54354858398438,
      "loss": 0.018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.21000710129737854,
      "rewards/margins": 4.218407154083252,
      "rewards/rejected": -4.428414344787598,
      "step": 1951
    },
    {
      "epoch": 0.7808,
      "grad_norm": 0.41376301646232605,
      "learning_rate": 7.398666666666666e-07,
      "logits/chosen": -2.4186737537384033,
      "logits/rejected": -2.5496277809143066,
      "logps/chosen": -108.95188903808594,
      "logps/rejected": -126.76675415039062,
      "loss": 0.0045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.116060733795166,
      "rewards/margins": 7.525426387786865,
      "rewards/rejected": -4.409365653991699,
      "step": 1952
    },
    {
      "epoch": 0.7812,
      "grad_norm": 0.020159052684903145,
      "learning_rate": 7.397333333333333e-07,
      "logits/chosen": -2.458920955657959,
      "logits/rejected": -2.791165351867676,
      "logps/chosen": -121.70053100585938,
      "logps/rejected": -169.06382751464844,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2763452529907227,
      "rewards/margins": 8.511636734008789,
      "rewards/rejected": -5.235291004180908,
      "step": 1953
    },
    {
      "epoch": 0.7816,
      "grad_norm": 0.17166581749916077,
      "learning_rate": 7.396e-07,
      "logits/chosen": -2.2509636878967285,
      "logits/rejected": -2.6264090538024902,
      "logps/chosen": -112.22537231445312,
      "logps/rejected": -123.7654037475586,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8315387964248657,
      "rewards/margins": 6.058815002441406,
      "rewards/rejected": -4.22727632522583,
      "step": 1954
    },
    {
      "epoch": 0.782,
      "grad_norm": 7.655786037445068,
      "learning_rate": 7.394666666666667e-07,
      "logits/chosen": -2.192183494567871,
      "logits/rejected": -3.2131524085998535,
      "logps/chosen": -110.954345703125,
      "logps/rejected": -166.57872009277344,
      "loss": 0.0628,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0016666650772095,
      "rewards/margins": 3.8111300468444824,
      "rewards/rejected": -4.812796592712402,
      "step": 1955
    },
    {
      "epoch": 0.7824,
      "grad_norm": 0.08834926038980484,
      "learning_rate": 7.393333333333333e-07,
      "logits/chosen": -2.44618558883667,
      "logits/rejected": -2.930819511413574,
      "logps/chosen": -185.8160400390625,
      "logps/rejected": -173.38092041015625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.684731960296631,
      "rewards/margins": 8.340450286865234,
      "rewards/rejected": -4.655717849731445,
      "step": 1956
    },
    {
      "epoch": 0.7828,
      "grad_norm": 0.5739191770553589,
      "learning_rate": 7.392e-07,
      "logits/chosen": -1.745039701461792,
      "logits/rejected": -2.894425868988037,
      "logps/chosen": -101.88394165039062,
      "logps/rejected": -128.79116821289062,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38857537508010864,
      "rewards/margins": 5.051902770996094,
      "rewards/rejected": -4.663327217102051,
      "step": 1957
    },
    {
      "epoch": 0.7832,
      "grad_norm": 1.8687018156051636,
      "learning_rate": 7.390666666666666e-07,
      "logits/chosen": -2.288362741470337,
      "logits/rejected": -2.6099295616149902,
      "logps/chosen": -92.52244567871094,
      "logps/rejected": -124.01876831054688,
      "loss": 0.0209,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12331163883209229,
      "rewards/margins": 4.853666305541992,
      "rewards/rejected": -4.730354309082031,
      "step": 1958
    },
    {
      "epoch": 0.7836,
      "grad_norm": 0.00394646218046546,
      "learning_rate": 7.389333333333333e-07,
      "logits/chosen": -2.4233484268188477,
      "logits/rejected": -3.409111499786377,
      "logps/chosen": -157.23684692382812,
      "logps/rejected": -168.14112854003906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4422364234924316,
      "rewards/margins": 10.534185409545898,
      "rewards/rejected": -7.091948986053467,
      "step": 1959
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.10468918830156326,
      "learning_rate": 7.388e-07,
      "logits/chosen": -2.5287299156188965,
      "logits/rejected": -3.5974483489990234,
      "logps/chosen": -100.01876831054688,
      "logps/rejected": -184.02774047851562,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6393080949783325,
      "rewards/margins": 6.933823108673096,
      "rewards/rejected": -5.294515132904053,
      "step": 1960
    },
    {
      "epoch": 0.7844,
      "grad_norm": 0.10826602578163147,
      "learning_rate": 7.386666666666666e-07,
      "logits/chosen": -2.4027609825134277,
      "logits/rejected": -3.0990986824035645,
      "logps/chosen": -124.49641418457031,
      "logps/rejected": -179.13467407226562,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7730808258056641,
      "rewards/margins": 7.0114545822143555,
      "rewards/rejected": -6.238373756408691,
      "step": 1961
    },
    {
      "epoch": 0.7848,
      "grad_norm": 0.5355828404426575,
      "learning_rate": 7.385333333333333e-07,
      "logits/chosen": -2.714799404144287,
      "logits/rejected": -3.2755298614501953,
      "logps/chosen": -181.81527709960938,
      "logps/rejected": -141.57577514648438,
      "loss": 0.0055,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1590416431427,
      "rewards/margins": 6.283014297485352,
      "rewards/rejected": -4.123972415924072,
      "step": 1962
    },
    {
      "epoch": 0.7852,
      "grad_norm": 0.8386468291282654,
      "learning_rate": 7.383999999999999e-07,
      "logits/chosen": -2.1247425079345703,
      "logits/rejected": -3.300966262817383,
      "logps/chosen": -155.129638671875,
      "logps/rejected": -175.46839904785156,
      "loss": 0.0071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.49102330207824707,
      "rewards/margins": 6.517979145050049,
      "rewards/rejected": -6.026955604553223,
      "step": 1963
    },
    {
      "epoch": 0.7856,
      "grad_norm": 0.023816054686903954,
      "learning_rate": 7.382666666666666e-07,
      "logits/chosen": -2.352694034576416,
      "logits/rejected": -2.878390312194824,
      "logps/chosen": -129.06866455078125,
      "logps/rejected": -158.7012176513672,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8615684509277344,
      "rewards/margins": 8.606023788452148,
      "rewards/rejected": -5.744455337524414,
      "step": 1964
    },
    {
      "epoch": 0.786,
      "grad_norm": 0.5426878929138184,
      "learning_rate": 7.381333333333333e-07,
      "logits/chosen": -2.041121482849121,
      "logits/rejected": -3.6370506286621094,
      "logps/chosen": -84.69799041748047,
      "logps/rejected": -187.30392456054688,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4080820083618164,
      "rewards/margins": 7.577579498291016,
      "rewards/rejected": -6.169497489929199,
      "step": 1965
    },
    {
      "epoch": 0.7864,
      "grad_norm": 0.06211621314287186,
      "learning_rate": 7.38e-07,
      "logits/chosen": -2.1237411499023438,
      "logits/rejected": -2.496863842010498,
      "logps/chosen": -141.15835571289062,
      "logps/rejected": -132.2823944091797,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3980050086975098,
      "rewards/margins": 7.339271068572998,
      "rewards/rejected": -4.941266059875488,
      "step": 1966
    },
    {
      "epoch": 0.7868,
      "grad_norm": 0.43068772554397583,
      "learning_rate": 7.378666666666667e-07,
      "logits/chosen": -2.2953057289123535,
      "logits/rejected": -3.2124288082122803,
      "logps/chosen": -130.22775268554688,
      "logps/rejected": -186.17996215820312,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3174927234649658,
      "rewards/margins": 6.880537033081055,
      "rewards/rejected": -5.563044548034668,
      "step": 1967
    },
    {
      "epoch": 0.7872,
      "grad_norm": 0.025295685976743698,
      "learning_rate": 7.377333333333333e-07,
      "logits/chosen": -2.285109281539917,
      "logits/rejected": -2.921896457672119,
      "logps/chosen": -90.416259765625,
      "logps/rejected": -140.96051025390625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8248496055603027,
      "rewards/margins": 8.342208862304688,
      "rewards/rejected": -5.517359256744385,
      "step": 1968
    },
    {
      "epoch": 0.7876,
      "grad_norm": 0.1019236296415329,
      "learning_rate": 7.376e-07,
      "logits/chosen": -2.276610851287842,
      "logits/rejected": -2.7392115592956543,
      "logps/chosen": -87.68232727050781,
      "logps/rejected": -144.71438598632812,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9129276275634766,
      "rewards/margins": 8.788036346435547,
      "rewards/rejected": -4.87510871887207,
      "step": 1969
    },
    {
      "epoch": 0.788,
      "grad_norm": 0.010739208199083805,
      "learning_rate": 7.374666666666667e-07,
      "logits/chosen": -1.9697482585906982,
      "logits/rejected": -3.1072263717651367,
      "logps/chosen": -69.07892608642578,
      "logps/rejected": -130.14407348632812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.573922157287598,
      "rewards/margins": 9.221382141113281,
      "rewards/rejected": -4.647459030151367,
      "step": 1970
    },
    {
      "epoch": 0.7884,
      "grad_norm": 0.3010532259941101,
      "learning_rate": 7.373333333333332e-07,
      "logits/chosen": -2.171337127685547,
      "logits/rejected": -3.3527913093566895,
      "logps/chosen": -152.55307006835938,
      "logps/rejected": -146.20480346679688,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.378706455230713,
      "rewards/margins": 6.821237564086914,
      "rewards/rejected": -5.442531585693359,
      "step": 1971
    },
    {
      "epoch": 0.7888,
      "grad_norm": 0.0059476676397025585,
      "learning_rate": 7.371999999999999e-07,
      "logits/chosen": -2.2725234031677246,
      "logits/rejected": -3.391958475112915,
      "logps/chosen": -131.5640411376953,
      "logps/rejected": -177.14251708984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.387304306030273,
      "rewards/margins": 10.46902084350586,
      "rewards/rejected": -6.081716537475586,
      "step": 1972
    },
    {
      "epoch": 0.7892,
      "grad_norm": 1.7975444793701172,
      "learning_rate": 7.370666666666666e-07,
      "logits/chosen": -1.5757098197937012,
      "logits/rejected": -2.5924155712127686,
      "logps/chosen": -93.46513366699219,
      "logps/rejected": -120.48873901367188,
      "loss": 0.0281,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03488272428512573,
      "rewards/margins": 4.48020601272583,
      "rewards/rejected": -4.4453229904174805,
      "step": 1973
    },
    {
      "epoch": 0.7896,
      "grad_norm": 0.10950271040201187,
      "learning_rate": 7.369333333333333e-07,
      "logits/chosen": -2.0356605052948,
      "logits/rejected": -2.8282008171081543,
      "logps/chosen": -153.8505859375,
      "logps/rejected": -141.13851928710938,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4970054626464844,
      "rewards/margins": 7.627423286437988,
      "rewards/rejected": -4.130417346954346,
      "step": 1974
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.09672345966100693,
      "learning_rate": 7.368e-07,
      "logits/chosen": -2.6493825912475586,
      "logits/rejected": -3.156951427459717,
      "logps/chosen": -114.66905975341797,
      "logps/rejected": -164.47207641601562,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7207329273223877,
      "rewards/margins": 6.989654541015625,
      "rewards/rejected": -5.268921852111816,
      "step": 1975
    },
    {
      "epoch": 0.7904,
      "grad_norm": 2.237366199493408,
      "learning_rate": 7.366666666666667e-07,
      "logits/chosen": -2.323435068130493,
      "logits/rejected": -2.8153796195983887,
      "logps/chosen": -83.11956787109375,
      "logps/rejected": -108.5725326538086,
      "loss": 0.0249,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.273129463195801,
      "rewards/margins": 5.548264026641846,
      "rewards/rejected": -3.275134563446045,
      "step": 1976
    },
    {
      "epoch": 0.7908,
      "grad_norm": 1.138264775276184,
      "learning_rate": 7.365333333333334e-07,
      "logits/chosen": -2.2817931175231934,
      "logits/rejected": -2.980194091796875,
      "logps/chosen": -195.3453369140625,
      "logps/rejected": -160.6095733642578,
      "loss": 0.0074,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.189944863319397,
      "rewards/margins": 5.920859336853027,
      "rewards/rejected": -4.730914115905762,
      "step": 1977
    },
    {
      "epoch": 0.7912,
      "grad_norm": 0.11653321981430054,
      "learning_rate": 7.364000000000001e-07,
      "logits/chosen": -3.264587879180908,
      "logits/rejected": -3.576718330383301,
      "logps/chosen": -127.40200805664062,
      "logps/rejected": -174.61627197265625,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.572557806968689,
      "rewards/margins": 7.54696798324585,
      "rewards/rejected": -6.974410057067871,
      "step": 1978
    },
    {
      "epoch": 0.7916,
      "grad_norm": 0.21927767992019653,
      "learning_rate": 7.362666666666666e-07,
      "logits/chosen": -2.3045668601989746,
      "logits/rejected": -3.5653159618377686,
      "logps/chosen": -254.8009490966797,
      "logps/rejected": -169.24725341796875,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4433731138706207,
      "rewards/margins": 6.176644802093506,
      "rewards/rejected": -5.733271598815918,
      "step": 1979
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.14574529230594635,
      "learning_rate": 7.361333333333332e-07,
      "logits/chosen": -2.2629051208496094,
      "logits/rejected": -2.9300875663757324,
      "logps/chosen": -79.39657592773438,
      "logps/rejected": -133.18014526367188,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8043996095657349,
      "rewards/margins": 6.47493839263916,
      "rewards/rejected": -4.670538902282715,
      "step": 1980
    },
    {
      "epoch": 0.7924,
      "grad_norm": 0.24621567130088806,
      "learning_rate": 7.359999999999999e-07,
      "logits/chosen": -2.5971243381500244,
      "logits/rejected": -3.2971160411834717,
      "logps/chosen": -181.1005401611328,
      "logps/rejected": -174.36668395996094,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1182382106781006,
      "rewards/margins": 6.44706916809082,
      "rewards/rejected": -4.328831195831299,
      "step": 1981
    },
    {
      "epoch": 0.7928,
      "grad_norm": 2.6137709617614746,
      "learning_rate": 7.358666666666666e-07,
      "logits/chosen": -2.14176607131958,
      "logits/rejected": -3.449357032775879,
      "logps/chosen": -125.05116271972656,
      "logps/rejected": -133.3697052001953,
      "loss": 0.0284,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7580578327178955,
      "rewards/margins": 3.6573305130004883,
      "rewards/rejected": -4.415388584136963,
      "step": 1982
    },
    {
      "epoch": 0.7932,
      "grad_norm": 0.06785650551319122,
      "learning_rate": 7.357333333333333e-07,
      "logits/chosen": -2.605907917022705,
      "logits/rejected": -3.419556140899658,
      "logps/chosen": -176.93601989746094,
      "logps/rejected": -169.69293212890625,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.799395799636841,
      "rewards/margins": 7.640946388244629,
      "rewards/rejected": -4.841550827026367,
      "step": 1983
    },
    {
      "epoch": 0.7936,
      "grad_norm": 0.8006277680397034,
      "learning_rate": 7.356e-07,
      "logits/chosen": -2.438754081726074,
      "logits/rejected": -3.093543291091919,
      "logps/chosen": -134.2016143798828,
      "logps/rejected": -146.58224487304688,
      "loss": 0.0051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7350212335586548,
      "rewards/margins": 6.851954936981201,
      "rewards/rejected": -5.116933822631836,
      "step": 1984
    },
    {
      "epoch": 0.794,
      "grad_norm": 0.41908201575279236,
      "learning_rate": 7.354666666666667e-07,
      "logits/chosen": -2.360875129699707,
      "logits/rejected": -3.367379665374756,
      "logps/chosen": -181.95510864257812,
      "logps/rejected": -143.14674377441406,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9167076349258423,
      "rewards/margins": 5.810413360595703,
      "rewards/rejected": -4.893706321716309,
      "step": 1985
    },
    {
      "epoch": 0.7944,
      "grad_norm": 0.05489202216267586,
      "learning_rate": 7.353333333333333e-07,
      "logits/chosen": -2.1729965209960938,
      "logits/rejected": -2.9992966651916504,
      "logps/chosen": -87.24252319335938,
      "logps/rejected": -124.96593475341797,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.337596893310547,
      "rewards/margins": 7.721405506134033,
      "rewards/rejected": -4.383808612823486,
      "step": 1986
    },
    {
      "epoch": 0.7948,
      "grad_norm": 0.00883351918309927,
      "learning_rate": 7.352e-07,
      "logits/chosen": -2.1110527515411377,
      "logits/rejected": -3.4081430435180664,
      "logps/chosen": -87.91511535644531,
      "logps/rejected": -177.3359375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5435612201690674,
      "rewards/margins": 9.278838157653809,
      "rewards/rejected": -6.735276699066162,
      "step": 1987
    },
    {
      "epoch": 0.7952,
      "grad_norm": 0.757159948348999,
      "learning_rate": 7.350666666666667e-07,
      "logits/chosen": -2.5762715339660645,
      "logits/rejected": -3.184216260910034,
      "logps/chosen": -96.66304779052734,
      "logps/rejected": -126.6583480834961,
      "loss": 0.0063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5404610633850098,
      "rewards/margins": 7.132810115814209,
      "rewards/rejected": -4.592349529266357,
      "step": 1988
    },
    {
      "epoch": 0.7956,
      "grad_norm": 0.19039694964885712,
      "learning_rate": 7.349333333333332e-07,
      "logits/chosen": -1.6073942184448242,
      "logits/rejected": -3.043844223022461,
      "logps/chosen": -112.43907928466797,
      "logps/rejected": -137.0368194580078,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0550804138183594,
      "rewards/margins": 6.171274185180664,
      "rewards/rejected": -5.116193771362305,
      "step": 1989
    },
    {
      "epoch": 0.796,
      "grad_norm": 0.08943501114845276,
      "learning_rate": 7.347999999999999e-07,
      "logits/chosen": -2.3177878856658936,
      "logits/rejected": -3.077800750732422,
      "logps/chosen": -103.88460540771484,
      "logps/rejected": -172.29051208496094,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.44633150100708,
      "rewards/margins": 8.620248794555664,
      "rewards/rejected": -6.173917293548584,
      "step": 1990
    },
    {
      "epoch": 0.7964,
      "grad_norm": 0.016040092334151268,
      "learning_rate": 7.346666666666666e-07,
      "logits/chosen": -1.9961422681808472,
      "logits/rejected": -3.080451011657715,
      "logps/chosen": -128.4978790283203,
      "logps/rejected": -166.67481994628906,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3177592754364014,
      "rewards/margins": 9.226921081542969,
      "rewards/rejected": -5.9091620445251465,
      "step": 1991
    },
    {
      "epoch": 0.7968,
      "grad_norm": 0.016848107799887657,
      "learning_rate": 7.345333333333333e-07,
      "logits/chosen": -2.2821576595306396,
      "logits/rejected": -3.1796939373016357,
      "logps/chosen": -121.78172302246094,
      "logps/rejected": -173.88665771484375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9370243549346924,
      "rewards/margins": 8.958661079406738,
      "rewards/rejected": -6.021636962890625,
      "step": 1992
    },
    {
      "epoch": 0.7972,
      "grad_norm": 0.19044627249240875,
      "learning_rate": 7.344e-07,
      "logits/chosen": -2.271655559539795,
      "logits/rejected": -3.3363137245178223,
      "logps/chosen": -148.82858276367188,
      "logps/rejected": -144.75936889648438,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2419688701629639,
      "rewards/margins": 7.522228240966797,
      "rewards/rejected": -6.280259132385254,
      "step": 1993
    },
    {
      "epoch": 0.7976,
      "grad_norm": 0.00707982387393713,
      "learning_rate": 7.342666666666666e-07,
      "logits/chosen": -2.258533477783203,
      "logits/rejected": -3.0246763229370117,
      "logps/chosen": -169.6448211669922,
      "logps/rejected": -210.97476196289062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.354672908782959,
      "rewards/margins": 9.758291244506836,
      "rewards/rejected": -7.403618812561035,
      "step": 1994
    },
    {
      "epoch": 0.798,
      "grad_norm": 4.054647445678711,
      "learning_rate": 7.341333333333333e-07,
      "logits/chosen": -2.812711715698242,
      "logits/rejected": -3.817938804626465,
      "logps/chosen": -234.84396362304688,
      "logps/rejected": -238.3766632080078,
      "loss": 0.0352,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01144111156463623,
      "rewards/margins": 6.54117488861084,
      "rewards/rejected": -6.529733657836914,
      "step": 1995
    },
    {
      "epoch": 0.7984,
      "grad_norm": 0.032830819487571716,
      "learning_rate": 7.34e-07,
      "logits/chosen": -2.0153679847717285,
      "logits/rejected": -3.1012122631073,
      "logps/chosen": -101.1314468383789,
      "logps/rejected": -163.65231323242188,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7350454330444336,
      "rewards/margins": 8.620991706848145,
      "rewards/rejected": -5.885946273803711,
      "step": 1996
    },
    {
      "epoch": 0.7988,
      "grad_norm": 0.03334909677505493,
      "learning_rate": 7.338666666666667e-07,
      "logits/chosen": -2.453378915786743,
      "logits/rejected": -2.3565287590026855,
      "logps/chosen": -119.52887725830078,
      "logps/rejected": -149.79005432128906,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.083410739898682,
      "rewards/margins": 8.538305282592773,
      "rewards/rejected": -4.45489501953125,
      "step": 1997
    },
    {
      "epoch": 0.7992,
      "grad_norm": 0.025282379239797592,
      "learning_rate": 7.337333333333334e-07,
      "logits/chosen": -2.306584358215332,
      "logits/rejected": -3.0812697410583496,
      "logps/chosen": -74.88768768310547,
      "logps/rejected": -148.66342163085938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5253868103027344,
      "rewards/margins": 9.045654296875,
      "rewards/rejected": -5.520267486572266,
      "step": 1998
    },
    {
      "epoch": 0.7996,
      "grad_norm": 2.143547296524048,
      "learning_rate": 7.336e-07,
      "logits/chosen": -2.4469428062438965,
      "logits/rejected": -3.039076805114746,
      "logps/chosen": -119.77661895751953,
      "logps/rejected": -120.88721466064453,
      "loss": 0.0261,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0029800385236740112,
      "rewards/margins": 4.025445461273193,
      "rewards/rejected": -4.028425693511963,
      "step": 1999
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.1436588019132614,
      "learning_rate": 7.334666666666666e-07,
      "logits/chosen": -2.1027956008911133,
      "logits/rejected": -2.86155366897583,
      "logps/chosen": -100.92118835449219,
      "logps/rejected": -152.76779174804688,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.430696487426758,
      "rewards/margins": 7.585379600524902,
      "rewards/rejected": -4.1546831130981445,
      "step": 2000
    },
    {
      "epoch": 0.8004,
      "grad_norm": 3.7302818298339844,
      "learning_rate": 7.333333333333332e-07,
      "logits/chosen": -2.1929993629455566,
      "logits/rejected": -3.0227651596069336,
      "logps/chosen": -110.97144317626953,
      "logps/rejected": -144.5474090576172,
      "loss": 0.0246,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5305656790733337,
      "rewards/margins": 5.146407127380371,
      "rewards/rejected": -5.676972389221191,
      "step": 2001
    },
    {
      "epoch": 0.8008,
      "grad_norm": 0.457937628030777,
      "learning_rate": 7.331999999999999e-07,
      "logits/chosen": -1.91951584815979,
      "logits/rejected": -3.1999382972717285,
      "logps/chosen": -105.24873352050781,
      "logps/rejected": -150.8958740234375,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2832660675048828,
      "rewards/margins": 7.146393299102783,
      "rewards/rejected": -5.8631272315979,
      "step": 2002
    },
    {
      "epoch": 0.8012,
      "grad_norm": 0.08825628459453583,
      "learning_rate": 7.330666666666666e-07,
      "logits/chosen": -2.8431646823883057,
      "logits/rejected": -3.339456558227539,
      "logps/chosen": -140.20098876953125,
      "logps/rejected": -172.16653442382812,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.506631851196289,
      "rewards/margins": 7.337732315063477,
      "rewards/rejected": -5.8311004638671875,
      "step": 2003
    },
    {
      "epoch": 0.8016,
      "grad_norm": 4.899322509765625,
      "learning_rate": 7.329333333333333e-07,
      "logits/chosen": -2.3279991149902344,
      "logits/rejected": -3.127732515335083,
      "logps/chosen": -130.71563720703125,
      "logps/rejected": -135.4180908203125,
      "loss": 0.044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8613929748535156,
      "rewards/margins": 5.809908866882324,
      "rewards/rejected": -3.9485158920288086,
      "step": 2004
    },
    {
      "epoch": 0.802,
      "grad_norm": 4.49344539642334,
      "learning_rate": 7.328e-07,
      "logits/chosen": -2.4089198112487793,
      "logits/rejected": -3.2813868522644043,
      "logps/chosen": -93.25806427001953,
      "logps/rejected": -127.17262268066406,
      "loss": 0.0367,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5870251655578613,
      "rewards/margins": 6.893237113952637,
      "rewards/rejected": -6.306211948394775,
      "step": 2005
    },
    {
      "epoch": 0.8024,
      "grad_norm": 0.3638381063938141,
      "learning_rate": 7.326666666666667e-07,
      "logits/chosen": -2.2278683185577393,
      "logits/rejected": -2.4873998165130615,
      "logps/chosen": -145.24237060546875,
      "logps/rejected": -138.06741333007812,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0785938501358032,
      "rewards/margins": 6.11899471282959,
      "rewards/rejected": -5.040400505065918,
      "step": 2006
    },
    {
      "epoch": 0.8028,
      "grad_norm": 0.007500834763050079,
      "learning_rate": 7.325333333333334e-07,
      "logits/chosen": -2.497124195098877,
      "logits/rejected": -3.434302568435669,
      "logps/chosen": -182.57203674316406,
      "logps/rejected": -262.7179870605469,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4888789653778076,
      "rewards/margins": 9.782344818115234,
      "rewards/rejected": -7.293466567993164,
      "step": 2007
    },
    {
      "epoch": 0.8032,
      "grad_norm": 0.06212484836578369,
      "learning_rate": 7.324e-07,
      "logits/chosen": -2.2980458736419678,
      "logits/rejected": -2.8500514030456543,
      "logps/chosen": -151.24107360839844,
      "logps/rejected": -149.65957641601562,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.365368366241455,
      "rewards/margins": 8.139185905456543,
      "rewards/rejected": -4.773818016052246,
      "step": 2008
    },
    {
      "epoch": 0.8036,
      "grad_norm": 0.15462736785411835,
      "learning_rate": 7.322666666666666e-07,
      "logits/chosen": -1.9290854930877686,
      "logits/rejected": -3.2551767826080322,
      "logps/chosen": -127.35888671875,
      "logps/rejected": -183.68356323242188,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7868560552597046,
      "rewards/margins": 6.841374397277832,
      "rewards/rejected": -6.054518222808838,
      "step": 2009
    },
    {
      "epoch": 0.804,
      "grad_norm": 0.02268155664205551,
      "learning_rate": 7.321333333333332e-07,
      "logits/chosen": -2.037736654281616,
      "logits/rejected": -3.4596810340881348,
      "logps/chosen": -135.8175048828125,
      "logps/rejected": -163.67953491210938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4229393005371094,
      "rewards/margins": 8.630169868469238,
      "rewards/rejected": -6.207230091094971,
      "step": 2010
    },
    {
      "epoch": 0.8044,
      "grad_norm": 0.08190689980983734,
      "learning_rate": 7.319999999999999e-07,
      "logits/chosen": -1.8412196636199951,
      "logits/rejected": -3.5732994079589844,
      "logps/chosen": -90.89889526367188,
      "logps/rejected": -161.14700317382812,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7142642736434937,
      "rewards/margins": 7.448951244354248,
      "rewards/rejected": -5.734686851501465,
      "step": 2011
    },
    {
      "epoch": 0.8048,
      "grad_norm": 0.1657206416130066,
      "learning_rate": 7.318666666666666e-07,
      "logits/chosen": -1.9960119724273682,
      "logits/rejected": -3.180572986602783,
      "logps/chosen": -152.52694702148438,
      "logps/rejected": -146.62167358398438,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2253899574279785,
      "rewards/margins": 8.09796142578125,
      "rewards/rejected": -4.872570991516113,
      "step": 2012
    },
    {
      "epoch": 0.8052,
      "grad_norm": 0.21442610025405884,
      "learning_rate": 7.317333333333333e-07,
      "logits/chosen": -2.6531624794006348,
      "logits/rejected": -3.182102680206299,
      "logps/chosen": -193.7029266357422,
      "logps/rejected": -168.5861358642578,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9865715503692627,
      "rewards/margins": 8.138303756713867,
      "rewards/rejected": -6.151731967926025,
      "step": 2013
    },
    {
      "epoch": 0.8056,
      "grad_norm": 0.6596077084541321,
      "learning_rate": 7.316e-07,
      "logits/chosen": -2.330336570739746,
      "logits/rejected": -3.221269130706787,
      "logps/chosen": -156.95938110351562,
      "logps/rejected": -153.37918090820312,
      "loss": 0.0051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5516555309295654,
      "rewards/margins": 7.137112140655518,
      "rewards/rejected": -4.585456848144531,
      "step": 2014
    },
    {
      "epoch": 0.806,
      "grad_norm": 0.18364447355270386,
      "learning_rate": 7.314666666666667e-07,
      "logits/chosen": -2.329219341278076,
      "logits/rejected": -3.404886484146118,
      "logps/chosen": -155.56549072265625,
      "logps/rejected": -154.81210327148438,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.466217279434204,
      "rewards/margins": 8.526437759399414,
      "rewards/rejected": -6.060220718383789,
      "step": 2015
    },
    {
      "epoch": 0.8064,
      "grad_norm": 1.0864149332046509,
      "learning_rate": 7.313333333333333e-07,
      "logits/chosen": -2.338123083114624,
      "logits/rejected": -3.09010910987854,
      "logps/chosen": -102.59487915039062,
      "logps/rejected": -189.7576141357422,
      "loss": 0.0107,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3252289295196533,
      "rewards/margins": 7.103982925415039,
      "rewards/rejected": -4.778753757476807,
      "step": 2016
    },
    {
      "epoch": 0.8068,
      "grad_norm": 0.047536950558423996,
      "learning_rate": 7.311999999999999e-07,
      "logits/chosen": -2.342679023742676,
      "logits/rejected": -3.5421996116638184,
      "logps/chosen": -118.0730209350586,
      "logps/rejected": -154.81439208984375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6216676235198975,
      "rewards/margins": 7.671916961669922,
      "rewards/rejected": -4.050249099731445,
      "step": 2017
    },
    {
      "epoch": 0.8072,
      "grad_norm": 0.005593979265540838,
      "learning_rate": 7.310666666666666e-07,
      "logits/chosen": -1.950852632522583,
      "logits/rejected": -3.065220832824707,
      "logps/chosen": -134.086181640625,
      "logps/rejected": -151.7860107421875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.853771209716797,
      "rewards/margins": 9.912103652954102,
      "rewards/rejected": -6.058332443237305,
      "step": 2018
    },
    {
      "epoch": 0.8076,
      "grad_norm": 0.41227132081985474,
      "learning_rate": 7.309333333333333e-07,
      "logits/chosen": -2.222238540649414,
      "logits/rejected": -2.769594430923462,
      "logps/chosen": -170.62437438964844,
      "logps/rejected": -130.28085327148438,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6824586391448975,
      "rewards/margins": 5.623382568359375,
      "rewards/rejected": -3.9409241676330566,
      "step": 2019
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.01136134285479784,
      "learning_rate": 7.308e-07,
      "logits/chosen": -2.2337112426757812,
      "logits/rejected": -3.1081204414367676,
      "logps/chosen": -135.1879425048828,
      "logps/rejected": -180.30838012695312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.038434982299805,
      "rewards/margins": 9.214926719665527,
      "rewards/rejected": -5.176491737365723,
      "step": 2020
    },
    {
      "epoch": 0.8084,
      "grad_norm": 0.1878744214773178,
      "learning_rate": 7.306666666666666e-07,
      "logits/chosen": -2.1421101093292236,
      "logits/rejected": -2.4848427772521973,
      "logps/chosen": -80.13829040527344,
      "logps/rejected": -117.86701965332031,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2073395252227783,
      "rewards/margins": 6.881916046142578,
      "rewards/rejected": -4.674576759338379,
      "step": 2021
    },
    {
      "epoch": 0.8088,
      "grad_norm": 0.05793152004480362,
      "learning_rate": 7.305333333333333e-07,
      "logits/chosen": -2.22180438041687,
      "logits/rejected": -2.73957896232605,
      "logps/chosen": -136.49935913085938,
      "logps/rejected": -206.66513061523438,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9683494567871094,
      "rewards/margins": 8.664510726928711,
      "rewards/rejected": -4.696161270141602,
      "step": 2022
    },
    {
      "epoch": 0.8092,
      "grad_norm": 0.1384723037481308,
      "learning_rate": 7.304e-07,
      "logits/chosen": -2.489401340484619,
      "logits/rejected": -3.1717453002929688,
      "logps/chosen": -195.1037139892578,
      "logps/rejected": -216.58126831054688,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8503353595733643,
      "rewards/margins": 7.995223045349121,
      "rewards/rejected": -6.144887447357178,
      "step": 2023
    },
    {
      "epoch": 0.8096,
      "grad_norm": 1.3860045671463013,
      "learning_rate": 7.302666666666666e-07,
      "logits/chosen": -2.021641969680786,
      "logits/rejected": -3.209176778793335,
      "logps/chosen": -104.08282470703125,
      "logps/rejected": -120.90489196777344,
      "loss": 0.0251,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3816051483154297,
      "rewards/margins": 3.676647186279297,
      "rewards/rejected": -3.295042037963867,
      "step": 2024
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.029933620244264603,
      "learning_rate": 7.301333333333333e-07,
      "logits/chosen": -2.278907537460327,
      "logits/rejected": -3.2988216876983643,
      "logps/chosen": -170.8638458251953,
      "logps/rejected": -160.8858642578125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3063392639160156,
      "rewards/margins": 8.380751609802246,
      "rewards/rejected": -6.0744123458862305,
      "step": 2025
    },
    {
      "epoch": 0.8104,
      "grad_norm": 0.0716085135936737,
      "learning_rate": 7.3e-07,
      "logits/chosen": -2.5918402671813965,
      "logits/rejected": -2.7902164459228516,
      "logps/chosen": -143.16329956054688,
      "logps/rejected": -146.95384216308594,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7775869369506836,
      "rewards/margins": 8.19398021697998,
      "rewards/rejected": -4.416393756866455,
      "step": 2026
    },
    {
      "epoch": 0.8108,
      "grad_norm": 0.004537233617156744,
      "learning_rate": 7.298666666666666e-07,
      "logits/chosen": -2.4421660900115967,
      "logits/rejected": -3.3090343475341797,
      "logps/chosen": -116.18252563476562,
      "logps/rejected": -166.60079956054688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.548649787902832,
      "rewards/margins": 10.164958000183105,
      "rewards/rejected": -5.616308212280273,
      "step": 2027
    },
    {
      "epoch": 0.8112,
      "grad_norm": 0.22524021565914154,
      "learning_rate": 7.297333333333333e-07,
      "logits/chosen": -1.8383667469024658,
      "logits/rejected": -2.896376609802246,
      "logps/chosen": -107.83157348632812,
      "logps/rejected": -121.12272644042969,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3929858207702637,
      "rewards/margins": 7.368831634521484,
      "rewards/rejected": -4.9758453369140625,
      "step": 2028
    },
    {
      "epoch": 0.8116,
      "grad_norm": 0.3478519320487976,
      "learning_rate": 7.296e-07,
      "logits/chosen": -2.3942596912384033,
      "logits/rejected": -3.320798397064209,
      "logps/chosen": -114.6794204711914,
      "logps/rejected": -178.5965118408203,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4949902296066284,
      "rewards/margins": 8.361289978027344,
      "rewards/rejected": -6.866299629211426,
      "step": 2029
    },
    {
      "epoch": 0.812,
      "grad_norm": 0.5179818868637085,
      "learning_rate": 7.294666666666667e-07,
      "logits/chosen": -2.297186851501465,
      "logits/rejected": -3.0185813903808594,
      "logps/chosen": -94.68064880371094,
      "logps/rejected": -135.5928955078125,
      "loss": 0.0065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.449266195297241,
      "rewards/margins": 6.836730003356934,
      "rewards/rejected": -4.387463569641113,
      "step": 2030
    },
    {
      "epoch": 0.8124,
      "grad_norm": 0.07995748519897461,
      "learning_rate": 7.293333333333332e-07,
      "logits/chosen": -2.720353126525879,
      "logits/rejected": -3.222888708114624,
      "logps/chosen": -259.0653076171875,
      "logps/rejected": -159.5015869140625,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3429665565490723,
      "rewards/margins": 7.2697672843933105,
      "rewards/rejected": -5.926800727844238,
      "step": 2031
    },
    {
      "epoch": 0.8128,
      "grad_norm": 0.02718808501958847,
      "learning_rate": 7.291999999999999e-07,
      "logits/chosen": -2.4819042682647705,
      "logits/rejected": -3.179323196411133,
      "logps/chosen": -77.87434387207031,
      "logps/rejected": -170.78829956054688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.155150890350342,
      "rewards/margins": 9.714447021484375,
      "rewards/rejected": -6.559296607971191,
      "step": 2032
    },
    {
      "epoch": 0.8132,
      "grad_norm": 0.06806143373250961,
      "learning_rate": 7.290666666666666e-07,
      "logits/chosen": -2.216029405593872,
      "logits/rejected": -2.7333831787109375,
      "logps/chosen": -103.04576110839844,
      "logps/rejected": -143.7733917236328,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.273073196411133,
      "rewards/margins": 7.418676376342773,
      "rewards/rejected": -5.145603179931641,
      "step": 2033
    },
    {
      "epoch": 0.8136,
      "grad_norm": 0.03231013938784599,
      "learning_rate": 7.289333333333333e-07,
      "logits/chosen": -2.5747334957122803,
      "logits/rejected": -3.5798959732055664,
      "logps/chosen": -207.90032958984375,
      "logps/rejected": -168.1468048095703,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.940479278564453,
      "rewards/margins": 8.568265914916992,
      "rewards/rejected": -4.627786636352539,
      "step": 2034
    },
    {
      "epoch": 0.814,
      "grad_norm": 0.019877348095178604,
      "learning_rate": 7.288e-07,
      "logits/chosen": -2.3765058517456055,
      "logits/rejected": -3.612295150756836,
      "logps/chosen": -103.95404052734375,
      "logps/rejected": -229.46409606933594,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.655117988586426,
      "rewards/margins": 9.986555099487305,
      "rewards/rejected": -7.3314361572265625,
      "step": 2035
    },
    {
      "epoch": 0.8144,
      "grad_norm": 0.2896023690700531,
      "learning_rate": 7.286666666666666e-07,
      "logits/chosen": -1.7601853609085083,
      "logits/rejected": -2.5861799716949463,
      "logps/chosen": -133.25222778320312,
      "logps/rejected": -149.1905059814453,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5944507718086243,
      "rewards/margins": 7.492672920227051,
      "rewards/rejected": -6.898221969604492,
      "step": 2036
    },
    {
      "epoch": 0.8148,
      "grad_norm": 0.012936553917825222,
      "learning_rate": 7.285333333333333e-07,
      "logits/chosen": -2.331000804901123,
      "logits/rejected": -3.217291831970215,
      "logps/chosen": -84.4053726196289,
      "logps/rejected": -164.62911987304688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.163315773010254,
      "rewards/margins": 9.060503959655762,
      "rewards/rejected": -4.897188186645508,
      "step": 2037
    },
    {
      "epoch": 0.8152,
      "grad_norm": 0.03707044571638107,
      "learning_rate": 7.284e-07,
      "logits/chosen": -2.7305140495300293,
      "logits/rejected": -3.2854461669921875,
      "logps/chosen": -206.541259765625,
      "logps/rejected": -164.2650909423828,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2901909351348877,
      "rewards/margins": 8.707000732421875,
      "rewards/rejected": -5.41680908203125,
      "step": 2038
    },
    {
      "epoch": 0.8156,
      "grad_norm": 0.013089773245155811,
      "learning_rate": 7.282666666666666e-07,
      "logits/chosen": -2.346799373626709,
      "logits/rejected": -2.9758434295654297,
      "logps/chosen": -164.93759155273438,
      "logps/rejected": -180.04763793945312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3956918716430664,
      "rewards/margins": 9.329753875732422,
      "rewards/rejected": -5.9340620040893555,
      "step": 2039
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.15412987768650055,
      "learning_rate": 7.281333333333333e-07,
      "logits/chosen": -2.4721906185150146,
      "logits/rejected": -2.9862489700317383,
      "logps/chosen": -130.05111694335938,
      "logps/rejected": -149.40066528320312,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.496655225753784,
      "rewards/margins": 6.933384895324707,
      "rewards/rejected": -4.436729907989502,
      "step": 2040
    },
    {
      "epoch": 0.8164,
      "grad_norm": 0.2825670838356018,
      "learning_rate": 7.28e-07,
      "logits/chosen": -2.090428352355957,
      "logits/rejected": -3.0195701122283936,
      "logps/chosen": -120.71508026123047,
      "logps/rejected": -163.967529296875,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.270034074783325,
      "rewards/margins": 6.6923699378967285,
      "rewards/rejected": -4.422335624694824,
      "step": 2041
    },
    {
      "epoch": 0.8168,
      "grad_norm": 0.07970105856657028,
      "learning_rate": 7.278666666666666e-07,
      "logits/chosen": -2.18106746673584,
      "logits/rejected": -2.9683523178100586,
      "logps/chosen": -178.0334930419922,
      "logps/rejected": -154.9132080078125,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.383635997772217,
      "rewards/margins": 7.532651901245117,
      "rewards/rejected": -4.1490159034729,
      "step": 2042
    },
    {
      "epoch": 0.8172,
      "grad_norm": 0.007044652942568064,
      "learning_rate": 7.277333333333333e-07,
      "logits/chosen": -1.8936431407928467,
      "logits/rejected": -2.6344494819641113,
      "logps/chosen": -94.39578247070312,
      "logps/rejected": -165.70404052734375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3402013778686523,
      "rewards/margins": 9.680173873901367,
      "rewards/rejected": -7.339972496032715,
      "step": 2043
    },
    {
      "epoch": 0.8176,
      "grad_norm": 0.5300168991088867,
      "learning_rate": 7.276e-07,
      "logits/chosen": -2.563864231109619,
      "logits/rejected": -3.359492778778076,
      "logps/chosen": -175.50823974609375,
      "logps/rejected": -138.33755493164062,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9215099215507507,
      "rewards/margins": 5.963015556335449,
      "rewards/rejected": -5.041505336761475,
      "step": 2044
    },
    {
      "epoch": 0.818,
      "grad_norm": 0.005230950657278299,
      "learning_rate": 7.274666666666667e-07,
      "logits/chosen": -2.483095645904541,
      "logits/rejected": -3.3282580375671387,
      "logps/chosen": -135.18011474609375,
      "logps/rejected": -186.79916381835938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.159276008605957,
      "rewards/margins": 9.730245590209961,
      "rewards/rejected": -5.570969104766846,
      "step": 2045
    },
    {
      "epoch": 0.8184,
      "grad_norm": 0.04197850450873375,
      "learning_rate": 7.273333333333333e-07,
      "logits/chosen": -2.106095790863037,
      "logits/rejected": -2.6633713245391846,
      "logps/chosen": -141.83053588867188,
      "logps/rejected": -256.3140563964844,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6961700916290283,
      "rewards/margins": 8.209098815917969,
      "rewards/rejected": -5.5129289627075195,
      "step": 2046
    },
    {
      "epoch": 0.8188,
      "grad_norm": 0.2825341820716858,
      "learning_rate": 7.271999999999999e-07,
      "logits/chosen": -2.1353135108947754,
      "logits/rejected": -3.211698055267334,
      "logps/chosen": -104.33000183105469,
      "logps/rejected": -178.18736267089844,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0786919593811035,
      "rewards/margins": 6.873938083648682,
      "rewards/rejected": -5.795246124267578,
      "step": 2047
    },
    {
      "epoch": 0.8192,
      "grad_norm": 13.508248329162598,
      "learning_rate": 7.270666666666666e-07,
      "logits/chosen": -2.7808189392089844,
      "logits/rejected": -3.264603614807129,
      "logps/chosen": -173.86489868164062,
      "logps/rejected": -129.65325927734375,
      "loss": 0.1011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1926482915878296,
      "rewards/margins": 4.970518112182617,
      "rewards/rejected": -3.777869701385498,
      "step": 2048
    },
    {
      "epoch": 0.8196,
      "grad_norm": 0.3510120213031769,
      "learning_rate": 7.269333333333333e-07,
      "logits/chosen": -1.986743450164795,
      "logits/rejected": -3.27616024017334,
      "logps/chosen": -95.54298400878906,
      "logps/rejected": -201.0083770751953,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5075936317443848,
      "rewards/margins": 5.592685699462891,
      "rewards/rejected": -3.0850918292999268,
      "step": 2049
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.014037084765732288,
      "learning_rate": 7.268e-07,
      "logits/chosen": -2.4736380577087402,
      "logits/rejected": -3.2982945442199707,
      "logps/chosen": -111.8674545288086,
      "logps/rejected": -181.41622924804688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.331010341644287,
      "rewards/margins": 9.160094261169434,
      "rewards/rejected": -5.829083442687988,
      "step": 2050
    },
    {
      "epoch": 0.8204,
      "grad_norm": 0.00627545453608036,
      "learning_rate": 7.266666666666667e-07,
      "logits/chosen": -2.1691408157348633,
      "logits/rejected": -3.6509227752685547,
      "logps/chosen": -154.64266967773438,
      "logps/rejected": -198.75518798828125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.07094669342041,
      "rewards/margins": 10.022928237915039,
      "rewards/rejected": -5.951982498168945,
      "step": 2051
    },
    {
      "epoch": 0.8208,
      "grad_norm": 0.010838896967470646,
      "learning_rate": 7.265333333333334e-07,
      "logits/chosen": -2.1655681133270264,
      "logits/rejected": -3.0305089950561523,
      "logps/chosen": -100.32772827148438,
      "logps/rejected": -212.81993103027344,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.87477970123291,
      "rewards/margins": 10.17490005493164,
      "rewards/rejected": -7.300120830535889,
      "step": 2052
    },
    {
      "epoch": 0.8212,
      "grad_norm": 0.45464861392974854,
      "learning_rate": 7.264e-07,
      "logits/chosen": -2.1105599403381348,
      "logits/rejected": -2.537017822265625,
      "logps/chosen": -123.04537200927734,
      "logps/rejected": -109.9251708984375,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5903311967849731,
      "rewards/margins": 5.548661231994629,
      "rewards/rejected": -3.9583301544189453,
      "step": 2053
    },
    {
      "epoch": 0.8216,
      "grad_norm": 35.091861724853516,
      "learning_rate": 7.262666666666666e-07,
      "logits/chosen": -2.0596041679382324,
      "logits/rejected": -2.8597965240478516,
      "logps/chosen": -86.96630096435547,
      "logps/rejected": -112.8471450805664,
      "loss": 0.5041,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.14467203617095947,
      "rewards/margins": 3.3622961044311523,
      "rewards/rejected": -3.2176239490509033,
      "step": 2054
    },
    {
      "epoch": 0.822,
      "grad_norm": 0.493607759475708,
      "learning_rate": 7.261333333333332e-07,
      "logits/chosen": -2.1895322799682617,
      "logits/rejected": -3.3540921211242676,
      "logps/chosen": -128.1400146484375,
      "logps/rejected": -153.7774658203125,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.44159966707229614,
      "rewards/margins": 6.218915939331055,
      "rewards/rejected": -5.777316093444824,
      "step": 2055
    },
    {
      "epoch": 0.8224,
      "grad_norm": 0.08220769464969635,
      "learning_rate": 7.259999999999999e-07,
      "logits/chosen": -2.7768077850341797,
      "logits/rejected": -2.8429133892059326,
      "logps/chosen": -165.94105529785156,
      "logps/rejected": -147.2458953857422,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8208099603652954,
      "rewards/margins": 7.139915466308594,
      "rewards/rejected": -5.31910514831543,
      "step": 2056
    },
    {
      "epoch": 0.8228,
      "grad_norm": 0.014149848371744156,
      "learning_rate": 7.258666666666666e-07,
      "logits/chosen": -2.311047077178955,
      "logits/rejected": -3.3179831504821777,
      "logps/chosen": -121.51908874511719,
      "logps/rejected": -156.9288330078125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.095361709594727,
      "rewards/margins": 8.588592529296875,
      "rewards/rejected": -4.493230819702148,
      "step": 2057
    },
    {
      "epoch": 0.8232,
      "grad_norm": 0.5390204787254333,
      "learning_rate": 7.257333333333333e-07,
      "logits/chosen": -2.8541383743286133,
      "logits/rejected": -3.198784112930298,
      "logps/chosen": -133.01797485351562,
      "logps/rejected": -115.51036071777344,
      "loss": 0.0065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2742462158203125,
      "rewards/margins": 5.210640907287598,
      "rewards/rejected": -2.9363949298858643,
      "step": 2058
    },
    {
      "epoch": 0.8236,
      "grad_norm": 2.431135416030884,
      "learning_rate": 7.256e-07,
      "logits/chosen": -2.1815624237060547,
      "logits/rejected": -2.644771099090576,
      "logps/chosen": -192.06997680664062,
      "logps/rejected": -156.33839416503906,
      "loss": 0.0207,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2983726263046265,
      "rewards/margins": 5.4779558181762695,
      "rewards/rejected": -4.179583549499512,
      "step": 2059
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.062195174396038055,
      "learning_rate": 7.254666666666667e-07,
      "logits/chosen": -1.8113293647766113,
      "logits/rejected": -3.616389274597168,
      "logps/chosen": -62.05147171020508,
      "logps/rejected": -160.23794555664062,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1427364349365234,
      "rewards/margins": 7.528604507446289,
      "rewards/rejected": -5.385868072509766,
      "step": 2060
    },
    {
      "epoch": 0.8244,
      "grad_norm": 0.01029650866985321,
      "learning_rate": 7.253333333333334e-07,
      "logits/chosen": -1.9413831233978271,
      "logits/rejected": -3.59323787689209,
      "logps/chosen": -139.474853515625,
      "logps/rejected": -154.0756378173828,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.217634677886963,
      "rewards/margins": 9.468375205993652,
      "rewards/rejected": -7.2507405281066895,
      "step": 2061
    },
    {
      "epoch": 0.8248,
      "grad_norm": 0.04287586733698845,
      "learning_rate": 7.252e-07,
      "logits/chosen": -2.5814640522003174,
      "logits/rejected": -3.1891984939575195,
      "logps/chosen": -168.17852783203125,
      "logps/rejected": -139.8725128173828,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1814780235290527,
      "rewards/margins": 8.236993789672852,
      "rewards/rejected": -5.055515289306641,
      "step": 2062
    },
    {
      "epoch": 0.8252,
      "grad_norm": 0.0843287780880928,
      "learning_rate": 7.250666666666666e-07,
      "logits/chosen": -2.1792869567871094,
      "logits/rejected": -2.9997811317443848,
      "logps/chosen": -153.36961364746094,
      "logps/rejected": -157.27655029296875,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.934539556503296,
      "rewards/margins": 7.112905025482178,
      "rewards/rejected": -5.178365707397461,
      "step": 2063
    },
    {
      "epoch": 0.8256,
      "grad_norm": 0.024620965123176575,
      "learning_rate": 7.249333333333332e-07,
      "logits/chosen": -2.883737087249756,
      "logits/rejected": -3.39492130279541,
      "logps/chosen": -197.34925842285156,
      "logps/rejected": -194.3761444091797,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1895365715026855,
      "rewards/margins": 8.745857238769531,
      "rewards/rejected": -5.556321144104004,
      "step": 2064
    },
    {
      "epoch": 0.826,
      "grad_norm": 1.0569701194763184,
      "learning_rate": 7.247999999999999e-07,
      "logits/chosen": -2.1354925632476807,
      "logits/rejected": -3.133502721786499,
      "logps/chosen": -132.5045166015625,
      "logps/rejected": -172.92742919921875,
      "loss": 0.0137,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8650264739990234,
      "rewards/margins": 7.115322113037109,
      "rewards/rejected": -5.250296115875244,
      "step": 2065
    },
    {
      "epoch": 0.8264,
      "grad_norm": 0.020963648334145546,
      "learning_rate": 7.246666666666666e-07,
      "logits/chosen": -1.8781442642211914,
      "logits/rejected": -3.255870819091797,
      "logps/chosen": -138.910400390625,
      "logps/rejected": -172.1749725341797,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.725278615951538,
      "rewards/margins": 8.418596267700195,
      "rewards/rejected": -6.693317413330078,
      "step": 2066
    },
    {
      "epoch": 0.8268,
      "grad_norm": 0.5839645266532898,
      "learning_rate": 7.245333333333333e-07,
      "logits/chosen": -1.919102430343628,
      "logits/rejected": -3.030971050262451,
      "logps/chosen": -117.66613006591797,
      "logps/rejected": -144.9873504638672,
      "loss": 0.0052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7534255981445312,
      "rewards/margins": 7.663887977600098,
      "rewards/rejected": -4.910462379455566,
      "step": 2067
    },
    {
      "epoch": 0.8272,
      "grad_norm": 0.1848231703042984,
      "learning_rate": 7.244e-07,
      "logits/chosen": -1.967153787612915,
      "logits/rejected": -3.420264482498169,
      "logps/chosen": -150.7670135498047,
      "logps/rejected": -192.46658325195312,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1386516094207764,
      "rewards/margins": 7.667369842529297,
      "rewards/rejected": -5.528717994689941,
      "step": 2068
    },
    {
      "epoch": 0.8276,
      "grad_norm": 0.07588589191436768,
      "learning_rate": 7.242666666666666e-07,
      "logits/chosen": -1.9796068668365479,
      "logits/rejected": -2.8736767768859863,
      "logps/chosen": -97.39485931396484,
      "logps/rejected": -159.97909545898438,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9259984493255615,
      "rewards/margins": 7.215798854827881,
      "rewards/rejected": -5.289800643920898,
      "step": 2069
    },
    {
      "epoch": 0.828,
      "grad_norm": 0.10182762145996094,
      "learning_rate": 7.241333333333333e-07,
      "logits/chosen": -2.0979371070861816,
      "logits/rejected": -2.9068055152893066,
      "logps/chosen": -89.21752166748047,
      "logps/rejected": -144.39767456054688,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3045458793640137,
      "rewards/margins": 6.644903659820557,
      "rewards/rejected": -4.340357780456543,
      "step": 2070
    },
    {
      "epoch": 0.8284,
      "grad_norm": 0.01033917535096407,
      "learning_rate": 7.24e-07,
      "logits/chosen": -2.3215389251708984,
      "logits/rejected": -3.258525848388672,
      "logps/chosen": -86.3365478515625,
      "logps/rejected": -136.68817138671875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.195339679718018,
      "rewards/margins": 9.174501419067383,
      "rewards/rejected": -4.979162216186523,
      "step": 2071
    },
    {
      "epoch": 0.8288,
      "grad_norm": 0.30496400594711304,
      "learning_rate": 7.238666666666667e-07,
      "logits/chosen": -2.6739532947540283,
      "logits/rejected": -3.252037525177002,
      "logps/chosen": -206.68438720703125,
      "logps/rejected": -186.15640258789062,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.675743579864502,
      "rewards/margins": 8.579534530639648,
      "rewards/rejected": -5.903791427612305,
      "step": 2072
    },
    {
      "epoch": 0.8292,
      "grad_norm": 0.06330033391714096,
      "learning_rate": 7.237333333333334e-07,
      "logits/chosen": -1.9381191730499268,
      "logits/rejected": -2.461886405944824,
      "logps/chosen": -72.06851196289062,
      "logps/rejected": -123.01355743408203,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.29276967048645,
      "rewards/margins": 7.925257682800293,
      "rewards/rejected": -4.632487773895264,
      "step": 2073
    },
    {
      "epoch": 0.8296,
      "grad_norm": 0.053904201835393906,
      "learning_rate": 7.235999999999999e-07,
      "logits/chosen": -2.3744957447052,
      "logits/rejected": -3.095306873321533,
      "logps/chosen": -159.478515625,
      "logps/rejected": -159.62596130371094,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.371675968170166,
      "rewards/margins": 8.385147094726562,
      "rewards/rejected": -6.013471603393555,
      "step": 2074
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.4935993254184723,
      "learning_rate": 7.234666666666666e-07,
      "logits/chosen": -2.2218942642211914,
      "logits/rejected": -2.6709396839141846,
      "logps/chosen": -102.82577514648438,
      "logps/rejected": -169.37933349609375,
      "loss": 0.0048,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6710119247436523,
      "rewards/margins": 7.2710466384887695,
      "rewards/rejected": -4.600035190582275,
      "step": 2075
    },
    {
      "epoch": 0.8304,
      "grad_norm": 0.6673961877822876,
      "learning_rate": 7.233333333333333e-07,
      "logits/chosen": -2.3308162689208984,
      "logits/rejected": -2.8560142517089844,
      "logps/chosen": -147.920166015625,
      "logps/rejected": -193.41831970214844,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5122146606445312,
      "rewards/margins": 8.252166748046875,
      "rewards/rejected": -5.7399516105651855,
      "step": 2076
    },
    {
      "epoch": 0.8308,
      "grad_norm": 0.1904277801513672,
      "learning_rate": 7.231999999999999e-07,
      "logits/chosen": -1.8557647466659546,
      "logits/rejected": -3.145977020263672,
      "logps/chosen": -112.39671325683594,
      "logps/rejected": -160.8363494873047,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4294044971466064,
      "rewards/margins": 7.905463218688965,
      "rewards/rejected": -6.476058006286621,
      "step": 2077
    },
    {
      "epoch": 0.8312,
      "grad_norm": 0.040802229195833206,
      "learning_rate": 7.230666666666666e-07,
      "logits/chosen": -1.9015488624572754,
      "logits/rejected": -3.167186737060547,
      "logps/chosen": -92.89175415039062,
      "logps/rejected": -165.7765655517578,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.98301362991333,
      "rewards/margins": 8.902872085571289,
      "rewards/rejected": -5.919858932495117,
      "step": 2078
    },
    {
      "epoch": 0.8316,
      "grad_norm": 0.027926530689001083,
      "learning_rate": 7.229333333333333e-07,
      "logits/chosen": -2.038088798522949,
      "logits/rejected": -3.1336283683776855,
      "logps/chosen": -151.10165405273438,
      "logps/rejected": -169.71739196777344,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7994279861450195,
      "rewards/margins": 9.294370651245117,
      "rewards/rejected": -6.4949421882629395,
      "step": 2079
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.019823895767331123,
      "learning_rate": 7.228e-07,
      "logits/chosen": -2.451575517654419,
      "logits/rejected": -3.4874634742736816,
      "logps/chosen": -81.2077865600586,
      "logps/rejected": -133.2215118408203,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7406692504882812,
      "rewards/margins": 8.310701370239258,
      "rewards/rejected": -4.570032119750977,
      "step": 2080
    },
    {
      "epoch": 0.8324,
      "grad_norm": 0.025836238637566566,
      "learning_rate": 7.226666666666667e-07,
      "logits/chosen": -2.322348117828369,
      "logits/rejected": -3.0582756996154785,
      "logps/chosen": -93.46029663085938,
      "logps/rejected": -125.64389038085938,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5165963172912598,
      "rewards/margins": 8.403618812561035,
      "rewards/rejected": -4.887022495269775,
      "step": 2081
    },
    {
      "epoch": 0.8328,
      "grad_norm": 0.006587618961930275,
      "learning_rate": 7.225333333333334e-07,
      "logits/chosen": -1.8472349643707275,
      "logits/rejected": -2.835202693939209,
      "logps/chosen": -200.8995819091797,
      "logps/rejected": -280.5631408691406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.973654270172119,
      "rewards/margins": 11.303662300109863,
      "rewards/rejected": -7.330008506774902,
      "step": 2082
    },
    {
      "epoch": 0.8332,
      "grad_norm": 0.25428542494773865,
      "learning_rate": 7.224e-07,
      "logits/chosen": -2.369262933731079,
      "logits/rejected": -3.131704568862915,
      "logps/chosen": -145.74256896972656,
      "logps/rejected": -265.55810546875,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4468917846679688,
      "rewards/margins": 7.584820747375488,
      "rewards/rejected": -5.1379289627075195,
      "step": 2083
    },
    {
      "epoch": 0.8336,
      "grad_norm": 0.048411451280117035,
      "learning_rate": 7.222666666666665e-07,
      "logits/chosen": -2.5805373191833496,
      "logits/rejected": -2.842881202697754,
      "logps/chosen": -118.80679321289062,
      "logps/rejected": -196.67007446289062,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.050422191619873,
      "rewards/margins": 8.193719863891602,
      "rewards/rejected": -5.1432976722717285,
      "step": 2084
    },
    {
      "epoch": 0.834,
      "grad_norm": 1.8577090501785278,
      "learning_rate": 7.221333333333332e-07,
      "logits/chosen": -2.255676746368408,
      "logits/rejected": -2.9825873374938965,
      "logps/chosen": -102.64140319824219,
      "logps/rejected": -153.46939086914062,
      "loss": 0.01,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.662853479385376,
      "rewards/margins": 7.365786552429199,
      "rewards/rejected": -5.702932834625244,
      "step": 2085
    },
    {
      "epoch": 0.8344,
      "grad_norm": 0.08043143153190613,
      "learning_rate": 7.219999999999999e-07,
      "logits/chosen": -2.2151565551757812,
      "logits/rejected": -2.9202864170074463,
      "logps/chosen": -113.52566528320312,
      "logps/rejected": -148.0102996826172,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.990551471710205,
      "rewards/margins": 7.979440689086914,
      "rewards/rejected": -5.988889694213867,
      "step": 2086
    },
    {
      "epoch": 0.8348,
      "grad_norm": 0.23509693145751953,
      "learning_rate": 7.218666666666666e-07,
      "logits/chosen": -2.2157278060913086,
      "logits/rejected": -3.7219738960266113,
      "logps/chosen": -112.63214111328125,
      "logps/rejected": -154.38821411132812,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.138331651687622,
      "rewards/margins": 7.477415084838867,
      "rewards/rejected": -5.339083671569824,
      "step": 2087
    },
    {
      "epoch": 0.8352,
      "grad_norm": 0.3430801331996918,
      "learning_rate": 7.217333333333333e-07,
      "logits/chosen": -2.5176851749420166,
      "logits/rejected": -2.9704248905181885,
      "logps/chosen": -212.6205596923828,
      "logps/rejected": -140.11465454101562,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1621193885803223,
      "rewards/margins": 6.900064468383789,
      "rewards/rejected": -5.737945556640625,
      "step": 2088
    },
    {
      "epoch": 0.8356,
      "grad_norm": 2.0277504920959473,
      "learning_rate": 7.216e-07,
      "logits/chosen": -2.1665198802948,
      "logits/rejected": -2.861588478088379,
      "logps/chosen": -134.21200561523438,
      "logps/rejected": -136.75393676757812,
      "loss": 0.01,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6106598377227783,
      "rewards/margins": 6.261435508728027,
      "rewards/rejected": -3.650775909423828,
      "step": 2089
    },
    {
      "epoch": 0.836,
      "grad_norm": 0.3892325460910797,
      "learning_rate": 7.214666666666667e-07,
      "logits/chosen": -2.567126989364624,
      "logits/rejected": -2.5492939949035645,
      "logps/chosen": -124.90318298339844,
      "logps/rejected": -117.43717956542969,
      "loss": 0.0057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6468746662139893,
      "rewards/margins": 5.335170745849609,
      "rewards/rejected": -3.688295841217041,
      "step": 2090
    },
    {
      "epoch": 0.8364,
      "grad_norm": 0.14623214304447174,
      "learning_rate": 7.213333333333334e-07,
      "logits/chosen": -1.743947148323059,
      "logits/rejected": -3.006793260574341,
      "logps/chosen": -81.08946990966797,
      "logps/rejected": -157.5113525390625,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6645199060440063,
      "rewards/margins": 7.249054431915283,
      "rewards/rejected": -5.584534645080566,
      "step": 2091
    },
    {
      "epoch": 0.8368,
      "grad_norm": 0.22209645807743073,
      "learning_rate": 7.211999999999999e-07,
      "logits/chosen": -2.153064012527466,
      "logits/rejected": -3.4555819034576416,
      "logps/chosen": -138.96484375,
      "logps/rejected": -149.771728515625,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.354238986968994,
      "rewards/margins": 7.276924133300781,
      "rewards/rejected": -4.922685623168945,
      "step": 2092
    },
    {
      "epoch": 0.8372,
      "grad_norm": 0.07421964406967163,
      "learning_rate": 7.210666666666666e-07,
      "logits/chosen": -1.965416669845581,
      "logits/rejected": -2.8706283569335938,
      "logps/chosen": -91.47808837890625,
      "logps/rejected": -125.61763000488281,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9506301879882812,
      "rewards/margins": 7.982441425323486,
      "rewards/rejected": -5.031811237335205,
      "step": 2093
    },
    {
      "epoch": 0.8376,
      "grad_norm": 0.09550692141056061,
      "learning_rate": 7.209333333333333e-07,
      "logits/chosen": -2.4894862174987793,
      "logits/rejected": -2.690781593322754,
      "logps/chosen": -90.23861694335938,
      "logps/rejected": -187.76602172851562,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8280200958251953,
      "rewards/margins": 8.431100845336914,
      "rewards/rejected": -4.6030802726745605,
      "step": 2094
    },
    {
      "epoch": 0.838,
      "grad_norm": 0.0041077327914536,
      "learning_rate": 7.207999999999999e-07,
      "logits/chosen": -2.035670042037964,
      "logits/rejected": -2.905832529067993,
      "logps/chosen": -144.2915496826172,
      "logps/rejected": -168.24998474121094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.153909683227539,
      "rewards/margins": 10.221540451049805,
      "rewards/rejected": -6.067630767822266,
      "step": 2095
    },
    {
      "epoch": 0.8384,
      "grad_norm": 0.007911616936326027,
      "learning_rate": 7.206666666666666e-07,
      "logits/chosen": -1.5800414085388184,
      "logits/rejected": -3.808541774749756,
      "logps/chosen": -95.77165222167969,
      "logps/rejected": -200.9261474609375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.009280204772949,
      "rewards/margins": 9.629997253417969,
      "rewards/rejected": -5.6207170486450195,
      "step": 2096
    },
    {
      "epoch": 0.8388,
      "grad_norm": 1.5734120607376099,
      "learning_rate": 7.205333333333333e-07,
      "logits/chosen": -1.9407529830932617,
      "logits/rejected": -3.45515775680542,
      "logps/chosen": -115.9686279296875,
      "logps/rejected": -209.8317108154297,
      "loss": 0.0083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3532695472240448,
      "rewards/margins": 6.160867691040039,
      "rewards/rejected": -6.514137268066406,
      "step": 2097
    },
    {
      "epoch": 0.8392,
      "grad_norm": 0.30694520473480225,
      "learning_rate": 7.204e-07,
      "logits/chosen": -2.308140277862549,
      "logits/rejected": -3.0310840606689453,
      "logps/chosen": -119.3799057006836,
      "logps/rejected": -133.5887451171875,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9798249006271362,
      "rewards/margins": 6.263829231262207,
      "rewards/rejected": -4.2840046882629395,
      "step": 2098
    },
    {
      "epoch": 0.8396,
      "grad_norm": 0.45013442635536194,
      "learning_rate": 7.202666666666667e-07,
      "logits/chosen": -2.581207752227783,
      "logits/rejected": -3.325648784637451,
      "logps/chosen": -151.13363647460938,
      "logps/rejected": -130.70571899414062,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1080026626586914,
      "rewards/margins": 6.166454315185547,
      "rewards/rejected": -4.0584516525268555,
      "step": 2099
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.28142720460891724,
      "learning_rate": 7.201333333333333e-07,
      "logits/chosen": -1.8336000442504883,
      "logits/rejected": -2.4984731674194336,
      "logps/chosen": -93.22216796875,
      "logps/rejected": -116.59281158447266,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8569507598876953,
      "rewards/margins": 7.711945056915283,
      "rewards/rejected": -3.854994297027588,
      "step": 2100
    },
    {
      "epoch": 0.8404,
      "grad_norm": 0.008694957010447979,
      "learning_rate": 7.2e-07,
      "logits/chosen": -2.1527669429779053,
      "logits/rejected": -2.771078586578369,
      "logps/chosen": -104.73391723632812,
      "logps/rejected": -144.1501007080078,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.451578140258789,
      "rewards/margins": 9.422074317932129,
      "rewards/rejected": -5.97049617767334,
      "step": 2101
    },
    {
      "epoch": 0.8408,
      "grad_norm": 0.17619958519935608,
      "learning_rate": 7.198666666666666e-07,
      "logits/chosen": -2.254082202911377,
      "logits/rejected": -3.328056812286377,
      "logps/chosen": -81.87913513183594,
      "logps/rejected": -158.14450073242188,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.739081621170044,
      "rewards/margins": 7.38714599609375,
      "rewards/rejected": -5.648064613342285,
      "step": 2102
    },
    {
      "epoch": 0.8412,
      "grad_norm": 0.010290687903761864,
      "learning_rate": 7.197333333333333e-07,
      "logits/chosen": -2.1459460258483887,
      "logits/rejected": -3.420071601867676,
      "logps/chosen": -112.37513732910156,
      "logps/rejected": -237.50643920898438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6939005851745605,
      "rewards/margins": 9.61220932006836,
      "rewards/rejected": -5.918308258056641,
      "step": 2103
    },
    {
      "epoch": 0.8416,
      "grad_norm": 0.12076128274202347,
      "learning_rate": 7.196e-07,
      "logits/chosen": -2.2691776752471924,
      "logits/rejected": -3.1406943798065186,
      "logps/chosen": -96.40489196777344,
      "logps/rejected": -139.1816864013672,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.635535717010498,
      "rewards/margins": 7.9404706954956055,
      "rewards/rejected": -5.304934501647949,
      "step": 2104
    },
    {
      "epoch": 0.842,
      "grad_norm": 0.04224838688969612,
      "learning_rate": 7.194666666666667e-07,
      "logits/chosen": -1.9207878112792969,
      "logits/rejected": -3.1026790142059326,
      "logps/chosen": -122.94583892822266,
      "logps/rejected": -138.7127685546875,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.360093116760254,
      "rewards/margins": 8.263069152832031,
      "rewards/rejected": -4.902975559234619,
      "step": 2105
    },
    {
      "epoch": 0.8424,
      "grad_norm": 0.08417552709579468,
      "learning_rate": 7.193333333333333e-07,
      "logits/chosen": -2.1589484214782715,
      "logits/rejected": -2.899758815765381,
      "logps/chosen": -206.99659729003906,
      "logps/rejected": -142.2993621826172,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.012329578399658,
      "rewards/margins": 7.169094085693359,
      "rewards/rejected": -5.156764030456543,
      "step": 2106
    },
    {
      "epoch": 0.8428,
      "grad_norm": 0.7772648334503174,
      "learning_rate": 7.191999999999999e-07,
      "logits/chosen": -1.9733675718307495,
      "logits/rejected": -2.798327922821045,
      "logps/chosen": -116.39383697509766,
      "logps/rejected": -129.37155151367188,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0991477966308594,
      "rewards/margins": 7.167072296142578,
      "rewards/rejected": -5.067924499511719,
      "step": 2107
    },
    {
      "epoch": 0.8432,
      "grad_norm": 0.043077245354652405,
      "learning_rate": 7.190666666666666e-07,
      "logits/chosen": -2.095726490020752,
      "logits/rejected": -2.4253082275390625,
      "logps/chosen": -80.3134994506836,
      "logps/rejected": -116.98780822753906,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.572086811065674,
      "rewards/margins": 7.725781440734863,
      "rewards/rejected": -5.1536946296691895,
      "step": 2108
    },
    {
      "epoch": 0.8436,
      "grad_norm": 0.23584148287773132,
      "learning_rate": 7.189333333333333e-07,
      "logits/chosen": -2.769896984100342,
      "logits/rejected": -3.202239513397217,
      "logps/chosen": -239.28793334960938,
      "logps/rejected": -174.0440673828125,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.695014238357544,
      "rewards/margins": 6.072197914123535,
      "rewards/rejected": -4.377183437347412,
      "step": 2109
    },
    {
      "epoch": 0.844,
      "grad_norm": 0.15140122175216675,
      "learning_rate": 7.188e-07,
      "logits/chosen": -1.4703679084777832,
      "logits/rejected": -2.4402971267700195,
      "logps/chosen": -74.15546417236328,
      "logps/rejected": -118.79138946533203,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7555932998657227,
      "rewards/margins": 7.099039077758789,
      "rewards/rejected": -4.343445777893066,
      "step": 2110
    },
    {
      "epoch": 0.8444,
      "grad_norm": 0.10094933211803436,
      "learning_rate": 7.186666666666667e-07,
      "logits/chosen": -2.3436365127563477,
      "logits/rejected": -2.895754814147949,
      "logps/chosen": -84.43287658691406,
      "logps/rejected": -130.3055419921875,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.163630723953247,
      "rewards/margins": 7.0375847816467285,
      "rewards/rejected": -4.873953819274902,
      "step": 2111
    },
    {
      "epoch": 0.8448,
      "grad_norm": 0.031852561980485916,
      "learning_rate": 7.185333333333333e-07,
      "logits/chosen": -2.1664271354675293,
      "logits/rejected": -3.004020929336548,
      "logps/chosen": -135.66468811035156,
      "logps/rejected": -138.45529174804688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1996281147003174,
      "rewards/margins": 8.396610260009766,
      "rewards/rejected": -5.196982383728027,
      "step": 2112
    },
    {
      "epoch": 0.8452,
      "grad_norm": 0.050164852291345596,
      "learning_rate": 7.184e-07,
      "logits/chosen": -2.0537357330322266,
      "logits/rejected": -3.1679728031158447,
      "logps/chosen": -132.90060424804688,
      "logps/rejected": -149.3570098876953,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3039498329162598,
      "rewards/margins": 8.19347095489502,
      "rewards/rejected": -5.88952112197876,
      "step": 2113
    },
    {
      "epoch": 0.8456,
      "grad_norm": 0.023362111300230026,
      "learning_rate": 7.182666666666667e-07,
      "logits/chosen": -1.7836058139801025,
      "logits/rejected": -3.2258362770080566,
      "logps/chosen": -93.6331558227539,
      "logps/rejected": -163.85433959960938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3281418085098267,
      "rewards/margins": 8.640440940856934,
      "rewards/rejected": -7.3122992515563965,
      "step": 2114
    },
    {
      "epoch": 0.846,
      "grad_norm": 0.04920775815844536,
      "learning_rate": 7.181333333333333e-07,
      "logits/chosen": -2.4607067108154297,
      "logits/rejected": -2.3932526111602783,
      "logps/chosen": -130.16574096679688,
      "logps/rejected": -184.1229705810547,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.323791742324829,
      "rewards/margins": 9.983369827270508,
      "rewards/rejected": -7.6595778465271,
      "step": 2115
    },
    {
      "epoch": 0.8464,
      "grad_norm": 0.3975047171115875,
      "learning_rate": 7.179999999999999e-07,
      "logits/chosen": -1.875230312347412,
      "logits/rejected": -3.279385566711426,
      "logps/chosen": -57.45616912841797,
      "logps/rejected": -145.62750244140625,
      "loss": 0.0028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8839631080627441,
      "rewards/margins": 6.622353553771973,
      "rewards/rejected": -4.7383904457092285,
      "step": 2116
    },
    {
      "epoch": 0.8468,
      "grad_norm": 4.867856979370117,
      "learning_rate": 7.178666666666666e-07,
      "logits/chosen": -2.618870735168457,
      "logits/rejected": -3.2019429206848145,
      "logps/chosen": -156.677978515625,
      "logps/rejected": -149.34751892089844,
      "loss": 0.0415,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3533637523651123,
      "rewards/margins": 5.7668023109436035,
      "rewards/rejected": -5.41343879699707,
      "step": 2117
    },
    {
      "epoch": 0.8472,
      "grad_norm": 0.03771436959505081,
      "learning_rate": 7.177333333333333e-07,
      "logits/chosen": -2.607640504837036,
      "logits/rejected": -3.0817971229553223,
      "logps/chosen": -112.12017059326172,
      "logps/rejected": -163.96707153320312,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.195377826690674,
      "rewards/margins": 8.389351844787598,
      "rewards/rejected": -6.193974494934082,
      "step": 2118
    },
    {
      "epoch": 0.8476,
      "grad_norm": 0.1256408542394638,
      "learning_rate": 7.176e-07,
      "logits/chosen": -2.028512954711914,
      "logits/rejected": -3.6363301277160645,
      "logps/chosen": -122.89030456542969,
      "logps/rejected": -188.20809936523438,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.756784439086914,
      "rewards/margins": 8.53812026977539,
      "rewards/rejected": -5.781335830688477,
      "step": 2119
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.19019833207130432,
      "learning_rate": 7.174666666666667e-07,
      "logits/chosen": -1.8932952880859375,
      "logits/rejected": -3.136693000793457,
      "logps/chosen": -91.18070220947266,
      "logps/rejected": -155.3094940185547,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.665761709213257,
      "rewards/margins": 8.09739875793457,
      "rewards/rejected": -5.431637763977051,
      "step": 2120
    },
    {
      "epoch": 0.8484,
      "grad_norm": 0.0029107891023159027,
      "learning_rate": 7.173333333333333e-07,
      "logits/chosen": -2.1260251998901367,
      "logits/rejected": -3.1105432510375977,
      "logps/chosen": -131.67037963867188,
      "logps/rejected": -194.14199829101562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.201526641845703,
      "rewards/margins": 10.595134735107422,
      "rewards/rejected": -6.393608093261719,
      "step": 2121
    },
    {
      "epoch": 0.8488,
      "grad_norm": 0.025475123897194862,
      "learning_rate": 7.171999999999999e-07,
      "logits/chosen": -1.9533145427703857,
      "logits/rejected": -2.972355365753174,
      "logps/chosen": -88.98311614990234,
      "logps/rejected": -171.07778930664062,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5747365951538086,
      "rewards/margins": 9.457805633544922,
      "rewards/rejected": -5.883069038391113,
      "step": 2122
    },
    {
      "epoch": 0.8492,
      "grad_norm": 0.12452400475740433,
      "learning_rate": 7.170666666666666e-07,
      "logits/chosen": -2.6143064498901367,
      "logits/rejected": -3.0572712421417236,
      "logps/chosen": -130.181640625,
      "logps/rejected": -118.40571594238281,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.040271520614624,
      "rewards/margins": 6.5123209953308105,
      "rewards/rejected": -4.472049713134766,
      "step": 2123
    },
    {
      "epoch": 0.8496,
      "grad_norm": 0.008374682627618313,
      "learning_rate": 7.169333333333333e-07,
      "logits/chosen": -1.9605759382247925,
      "logits/rejected": -3.3422837257385254,
      "logps/chosen": -114.59236145019531,
      "logps/rejected": -152.1580810546875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.095828533172607,
      "rewards/margins": 9.758773803710938,
      "rewards/rejected": -5.662945747375488,
      "step": 2124
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.23591919243335724,
      "learning_rate": 7.168e-07,
      "logits/chosen": -1.5972115993499756,
      "logits/rejected": -3.0839004516601562,
      "logps/chosen": -179.937255859375,
      "logps/rejected": -159.1043701171875,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2051589488983154,
      "rewards/margins": 7.715899467468262,
      "rewards/rejected": -5.510740756988525,
      "step": 2125
    },
    {
      "epoch": 0.8504,
      "grad_norm": 0.003620623843744397,
      "learning_rate": 7.166666666666667e-07,
      "logits/chosen": -2.525972843170166,
      "logits/rejected": -3.102775812149048,
      "logps/chosen": -139.37667846679688,
      "logps/rejected": -150.63162231445312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.129482746124268,
      "rewards/margins": 10.127684593200684,
      "rewards/rejected": -5.998201847076416,
      "step": 2126
    },
    {
      "epoch": 0.8508,
      "grad_norm": 0.14872027933597565,
      "learning_rate": 7.165333333333333e-07,
      "logits/chosen": -2.415347099304199,
      "logits/rejected": -3.3480417728424072,
      "logps/chosen": -112.18206024169922,
      "logps/rejected": -241.8856201171875,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1663966178894043,
      "rewards/margins": 6.679014205932617,
      "rewards/rejected": -4.512617111206055,
      "step": 2127
    },
    {
      "epoch": 0.8512,
      "grad_norm": 3.0619451999664307,
      "learning_rate": 7.164e-07,
      "logits/chosen": -2.1941075325012207,
      "logits/rejected": -3.0612449645996094,
      "logps/chosen": -173.70689392089844,
      "logps/rejected": -306.33673095703125,
      "loss": 0.0302,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6421764492988586,
      "rewards/margins": 6.316934585571289,
      "rewards/rejected": -5.674757957458496,
      "step": 2128
    },
    {
      "epoch": 0.8516,
      "grad_norm": 0.254525750875473,
      "learning_rate": 7.162666666666667e-07,
      "logits/chosen": -1.9643850326538086,
      "logits/rejected": -2.5416762828826904,
      "logps/chosen": -109.74192810058594,
      "logps/rejected": -123.40292358398438,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6971927881240845,
      "rewards/margins": 6.029294013977051,
      "rewards/rejected": -4.332101345062256,
      "step": 2129
    },
    {
      "epoch": 0.852,
      "grad_norm": 0.08849568665027618,
      "learning_rate": 7.161333333333332e-07,
      "logits/chosen": -2.393533706665039,
      "logits/rejected": -2.9041357040405273,
      "logps/chosen": -78.88885498046875,
      "logps/rejected": -153.66366577148438,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.35615873336792,
      "rewards/margins": 7.8348612785339355,
      "rewards/rejected": -4.478702545166016,
      "step": 2130
    },
    {
      "epoch": 0.8524,
      "grad_norm": 0.013176267966628075,
      "learning_rate": 7.159999999999999e-07,
      "logits/chosen": -2.6014668941497803,
      "logits/rejected": -3.3242287635803223,
      "logps/chosen": -128.90939331054688,
      "logps/rejected": -192.0370635986328,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1815288066864014,
      "rewards/margins": 9.08798599243164,
      "rewards/rejected": -5.906457424163818,
      "step": 2131
    },
    {
      "epoch": 0.8528,
      "grad_norm": 11.399519920349121,
      "learning_rate": 7.158666666666666e-07,
      "logits/chosen": -1.8024401664733887,
      "logits/rejected": -2.467653751373291,
      "logps/chosen": -103.71896362304688,
      "logps/rejected": -123.24262237548828,
      "loss": 0.0728,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.05669105052947998,
      "rewards/margins": 4.716607093811035,
      "rewards/rejected": -4.773298263549805,
      "step": 2132
    },
    {
      "epoch": 0.8532,
      "grad_norm": 0.4177187979221344,
      "learning_rate": 7.157333333333333e-07,
      "logits/chosen": -2.0927734375,
      "logits/rejected": -3.4738874435424805,
      "logps/chosen": -87.43971252441406,
      "logps/rejected": -138.96817016601562,
      "loss": 0.005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8061295747756958,
      "rewards/margins": 6.655747413635254,
      "rewards/rejected": -4.849617958068848,
      "step": 2133
    },
    {
      "epoch": 0.8536,
      "grad_norm": 0.09940945357084274,
      "learning_rate": 7.156e-07,
      "logits/chosen": -1.8202886581420898,
      "logits/rejected": -3.0390217304229736,
      "logps/chosen": -134.884033203125,
      "logps/rejected": -175.18161010742188,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0716034173965454,
      "rewards/margins": 7.338186264038086,
      "rewards/rejected": -6.26658296585083,
      "step": 2134
    },
    {
      "epoch": 0.854,
      "grad_norm": 1.114751935005188,
      "learning_rate": 7.154666666666667e-07,
      "logits/chosen": -2.0665371417999268,
      "logits/rejected": -2.6359002590179443,
      "logps/chosen": -117.08416748046875,
      "logps/rejected": -217.32582092285156,
      "loss": 0.0111,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4321987628936768,
      "rewards/margins": 5.404543876647949,
      "rewards/rejected": -3.9723448753356934,
      "step": 2135
    },
    {
      "epoch": 0.8544,
      "grad_norm": 8.758878707885742,
      "learning_rate": 7.153333333333334e-07,
      "logits/chosen": -2.242377996444702,
      "logits/rejected": -2.4995951652526855,
      "logps/chosen": -103.25286865234375,
      "logps/rejected": -93.99790954589844,
      "loss": 0.1019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6915683746337891,
      "rewards/margins": 2.393165111541748,
      "rewards/rejected": -1.7015968561172485,
      "step": 2136
    },
    {
      "epoch": 0.8548,
      "grad_norm": 11.511646270751953,
      "learning_rate": 7.151999999999999e-07,
      "logits/chosen": -2.644698143005371,
      "logits/rejected": -2.9352922439575195,
      "logps/chosen": -162.14291381835938,
      "logps/rejected": -147.68148803710938,
      "loss": 0.083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9389320611953735,
      "rewards/margins": 3.5320167541503906,
      "rewards/rejected": -4.470948696136475,
      "step": 2137
    },
    {
      "epoch": 0.8552,
      "grad_norm": 0.07285735756158829,
      "learning_rate": 7.150666666666666e-07,
      "logits/chosen": -2.2672908306121826,
      "logits/rejected": -2.678589344024658,
      "logps/chosen": -172.67381286621094,
      "logps/rejected": -179.54164123535156,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6733551025390625,
      "rewards/margins": 9.254141807556152,
      "rewards/rejected": -5.58078670501709,
      "step": 2138
    },
    {
      "epoch": 0.8556,
      "grad_norm": 0.014012307859957218,
      "learning_rate": 7.149333333333333e-07,
      "logits/chosen": -2.5724987983703613,
      "logits/rejected": -3.276869297027588,
      "logps/chosen": -86.32523345947266,
      "logps/rejected": -150.2854461669922,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3644556999206543,
      "rewards/margins": 8.864405632019043,
      "rewards/rejected": -5.4999494552612305,
      "step": 2139
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.5977694988250732,
      "learning_rate": 7.147999999999999e-07,
      "logits/chosen": -2.466115951538086,
      "logits/rejected": -2.7461657524108887,
      "logps/chosen": -111.18753051757812,
      "logps/rejected": -159.90060424804688,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0184929370880127,
      "rewards/margins": 6.879000663757324,
      "rewards/rejected": -3.8605074882507324,
      "step": 2140
    },
    {
      "epoch": 0.8564,
      "grad_norm": 0.09519024193286896,
      "learning_rate": 7.146666666666666e-07,
      "logits/chosen": -1.9289462566375732,
      "logits/rejected": -3.1240639686584473,
      "logps/chosen": -128.23818969726562,
      "logps/rejected": -148.54359436035156,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3771480321884155,
      "rewards/margins": 7.128905296325684,
      "rewards/rejected": -5.7517571449279785,
      "step": 2141
    },
    {
      "epoch": 0.8568,
      "grad_norm": 0.10426799952983856,
      "learning_rate": 7.145333333333333e-07,
      "logits/chosen": -2.8960747718811035,
      "logits/rejected": -3.0248823165893555,
      "logps/chosen": -226.31826782226562,
      "logps/rejected": -194.61279296875,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.207717180252075,
      "rewards/margins": 7.6804962158203125,
      "rewards/rejected": -5.4727783203125,
      "step": 2142
    },
    {
      "epoch": 0.8572,
      "grad_norm": 6.540618896484375,
      "learning_rate": 7.144e-07,
      "logits/chosen": -2.3312668800354004,
      "logits/rejected": -3.3924779891967773,
      "logps/chosen": -125.79633331298828,
      "logps/rejected": -157.6482391357422,
      "loss": 0.0531,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0447803735733032,
      "rewards/margins": 6.785694599151611,
      "rewards/rejected": -5.7409138679504395,
      "step": 2143
    },
    {
      "epoch": 0.8576,
      "grad_norm": 0.12511824071407318,
      "learning_rate": 7.142666666666667e-07,
      "logits/chosen": -2.557077169418335,
      "logits/rejected": -2.810739040374756,
      "logps/chosen": -194.20285034179688,
      "logps/rejected": -215.69778442382812,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5393424034118652,
      "rewards/margins": 7.354389190673828,
      "rewards/rejected": -4.815046787261963,
      "step": 2144
    },
    {
      "epoch": 0.858,
      "grad_norm": 0.09589685499668121,
      "learning_rate": 7.141333333333333e-07,
      "logits/chosen": -2.3081576824188232,
      "logits/rejected": -3.193775177001953,
      "logps/chosen": -83.990966796875,
      "logps/rejected": -136.02523803710938,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4518680572509766,
      "rewards/margins": 8.661892890930176,
      "rewards/rejected": -6.210024833679199,
      "step": 2145
    },
    {
      "epoch": 0.8584,
      "grad_norm": 0.2374386489391327,
      "learning_rate": 7.14e-07,
      "logits/chosen": -2.388990640640259,
      "logits/rejected": -2.201857328414917,
      "logps/chosen": -107.64186096191406,
      "logps/rejected": -121.61367797851562,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9459571838378906,
      "rewards/margins": 7.41785192489624,
      "rewards/rejected": -4.471894264221191,
      "step": 2146
    },
    {
      "epoch": 0.8588,
      "grad_norm": 0.040097229182720184,
      "learning_rate": 7.138666666666667e-07,
      "logits/chosen": -2.0286571979522705,
      "logits/rejected": -3.052861213684082,
      "logps/chosen": -133.96444702148438,
      "logps/rejected": -166.73793029785156,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.712786912918091,
      "rewards/margins": 9.633402824401855,
      "rewards/rejected": -5.920616149902344,
      "step": 2147
    },
    {
      "epoch": 0.8592,
      "grad_norm": 0.06289202719926834,
      "learning_rate": 7.137333333333333e-07,
      "logits/chosen": -2.1190989017486572,
      "logits/rejected": -2.9718732833862305,
      "logps/chosen": -114.08098602294922,
      "logps/rejected": -166.54312133789062,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1763482093811035,
      "rewards/margins": 8.194884300231934,
      "rewards/rejected": -5.01853609085083,
      "step": 2148
    },
    {
      "epoch": 0.8596,
      "grad_norm": 0.1065393015742302,
      "learning_rate": 7.135999999999999e-07,
      "logits/chosen": -2.341019630432129,
      "logits/rejected": -3.220200777053833,
      "logps/chosen": -133.25131225585938,
      "logps/rejected": -157.900146484375,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0112377405166626,
      "rewards/margins": 6.835244178771973,
      "rewards/rejected": -5.824006080627441,
      "step": 2149
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.944279134273529,
      "learning_rate": 7.134666666666666e-07,
      "logits/chosen": -2.2080235481262207,
      "logits/rejected": -3.0098085403442383,
      "logps/chosen": -104.4478988647461,
      "logps/rejected": -180.569091796875,
      "loss": 0.0084,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.496649146080017,
      "rewards/margins": 5.987672805786133,
      "rewards/rejected": -4.491023540496826,
      "step": 2150
    },
    {
      "epoch": 0.8604,
      "grad_norm": 0.10041401535272598,
      "learning_rate": 7.133333333333333e-07,
      "logits/chosen": -1.8117629289627075,
      "logits/rejected": -3.22851300239563,
      "logps/chosen": -101.43772888183594,
      "logps/rejected": -150.19052124023438,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4361492395401,
      "rewards/margins": 7.311648368835449,
      "rewards/rejected": -5.875499725341797,
      "step": 2151
    },
    {
      "epoch": 0.8608,
      "grad_norm": 0.11107593029737473,
      "learning_rate": 7.131999999999999e-07,
      "logits/chosen": -2.703138828277588,
      "logits/rejected": -2.7039599418640137,
      "logps/chosen": -105.4543228149414,
      "logps/rejected": -129.06077575683594,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6594229936599731,
      "rewards/margins": 7.192424774169922,
      "rewards/rejected": -5.533001899719238,
      "step": 2152
    },
    {
      "epoch": 0.8612,
      "grad_norm": 0.5697186589241028,
      "learning_rate": 7.130666666666666e-07,
      "logits/chosen": -1.7435851097106934,
      "logits/rejected": -3.3060896396636963,
      "logps/chosen": -131.8433837890625,
      "logps/rejected": -193.64010620117188,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0034599304199219,
      "rewards/margins": 5.969841957092285,
      "rewards/rejected": -4.966382026672363,
      "step": 2153
    },
    {
      "epoch": 0.8616,
      "grad_norm": 0.0027495825197547674,
      "learning_rate": 7.129333333333333e-07,
      "logits/chosen": -2.896080255508423,
      "logits/rejected": -3.323126792907715,
      "logps/chosen": -140.86134338378906,
      "logps/rejected": -153.4039764404297,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.6479172706604,
      "rewards/margins": 10.52740478515625,
      "rewards/rejected": -5.879487991333008,
      "step": 2154
    },
    {
      "epoch": 0.862,
      "grad_norm": 0.017213402315974236,
      "learning_rate": 7.128e-07,
      "logits/chosen": -2.112151622772217,
      "logits/rejected": -2.8016276359558105,
      "logps/chosen": -118.52433776855469,
      "logps/rejected": -165.47926330566406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0009994506835938,
      "rewards/margins": 9.018512725830078,
      "rewards/rejected": -6.017513275146484,
      "step": 2155
    },
    {
      "epoch": 0.8624,
      "grad_norm": 0.01215366180986166,
      "learning_rate": 7.126666666666667e-07,
      "logits/chosen": -2.572373390197754,
      "logits/rejected": -3.2515268325805664,
      "logps/chosen": -111.72688293457031,
      "logps/rejected": -161.7183837890625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.100968599319458,
      "rewards/margins": 9.073785781860352,
      "rewards/rejected": -5.972817420959473,
      "step": 2156
    },
    {
      "epoch": 0.8628,
      "grad_norm": 0.8723729252815247,
      "learning_rate": 7.125333333333334e-07,
      "logits/chosen": -2.8331265449523926,
      "logits/rejected": -2.868368148803711,
      "logps/chosen": -227.75997924804688,
      "logps/rejected": -241.3045196533203,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0918054580688477,
      "rewards/margins": 7.385537624359131,
      "rewards/rejected": -5.293732166290283,
      "step": 2157
    },
    {
      "epoch": 0.8632,
      "grad_norm": 0.2187870442867279,
      "learning_rate": 7.124e-07,
      "logits/chosen": -1.8621983528137207,
      "logits/rejected": -3.085507392883301,
      "logps/chosen": -132.85772705078125,
      "logps/rejected": -165.3190155029297,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4132039546966553,
      "rewards/margins": 8.20506763458252,
      "rewards/rejected": -5.791863441467285,
      "step": 2158
    },
    {
      "epoch": 0.8636,
      "grad_norm": 0.12127511948347092,
      "learning_rate": 7.122666666666666e-07,
      "logits/chosen": -2.290736198425293,
      "logits/rejected": -3.2263741493225098,
      "logps/chosen": -113.34461212158203,
      "logps/rejected": -151.91062927246094,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8434253931045532,
      "rewards/margins": 7.02313232421875,
      "rewards/rejected": -6.179706573486328,
      "step": 2159
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.37487077713012695,
      "learning_rate": 7.121333333333332e-07,
      "logits/chosen": -2.2616000175476074,
      "logits/rejected": -3.4034600257873535,
      "logps/chosen": -123.64085388183594,
      "logps/rejected": -146.62242126464844,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7886577248573303,
      "rewards/margins": 7.497016906738281,
      "rewards/rejected": -6.708359241485596,
      "step": 2160
    },
    {
      "epoch": 0.8644,
      "grad_norm": 0.011069552041590214,
      "learning_rate": 7.119999999999999e-07,
      "logits/chosen": -2.7444839477539062,
      "logits/rejected": -3.4694995880126953,
      "logps/chosen": -143.60720825195312,
      "logps/rejected": -179.666259765625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9883289337158203,
      "rewards/margins": 9.320289611816406,
      "rewards/rejected": -5.331960678100586,
      "step": 2161
    },
    {
      "epoch": 0.8648,
      "grad_norm": 0.2268988937139511,
      "learning_rate": 7.118666666666666e-07,
      "logits/chosen": -2.1545114517211914,
      "logits/rejected": -3.4676458835601807,
      "logps/chosen": -121.47142028808594,
      "logps/rejected": -178.16476440429688,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0664299726486206,
      "rewards/margins": 9.541900634765625,
      "rewards/rejected": -8.475469589233398,
      "step": 2162
    },
    {
      "epoch": 0.8652,
      "grad_norm": 2.42441463470459,
      "learning_rate": 7.117333333333333e-07,
      "logits/chosen": -3.008723258972168,
      "logits/rejected": -2.6529154777526855,
      "logps/chosen": -129.05657958984375,
      "logps/rejected": -142.29336547851562,
      "loss": 0.0183,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3329906463623047,
      "rewards/margins": 6.942631721496582,
      "rewards/rejected": -4.609641075134277,
      "step": 2163
    },
    {
      "epoch": 0.8656,
      "grad_norm": 0.005448879674077034,
      "learning_rate": 7.116e-07,
      "logits/chosen": -2.2299675941467285,
      "logits/rejected": -3.7817506790161133,
      "logps/chosen": -144.8860321044922,
      "logps/rejected": -251.38113403320312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7906813621520996,
      "rewards/margins": 10.651047706604004,
      "rewards/rejected": -7.860365867614746,
      "step": 2164
    },
    {
      "epoch": 0.866,
      "grad_norm": 0.007921095937490463,
      "learning_rate": 7.114666666666667e-07,
      "logits/chosen": -2.0429909229278564,
      "logits/rejected": -2.869271993637085,
      "logps/chosen": -104.54595947265625,
      "logps/rejected": -170.9861602783203,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5010581016540527,
      "rewards/margins": 9.653678894042969,
      "rewards/rejected": -6.152621269226074,
      "step": 2165
    },
    {
      "epoch": 0.8664,
      "grad_norm": 0.5889561772346497,
      "learning_rate": 7.113333333333334e-07,
      "logits/chosen": -2.6002349853515625,
      "logits/rejected": -2.919302225112915,
      "logps/chosen": -157.17567443847656,
      "logps/rejected": -137.4412078857422,
      "loss": 0.004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3366315364837646,
      "rewards/margins": 6.291695594787598,
      "rewards/rejected": -3.955063819885254,
      "step": 2166
    },
    {
      "epoch": 0.8668,
      "grad_norm": 0.10209497809410095,
      "learning_rate": 7.112000000000001e-07,
      "logits/chosen": -1.886624813079834,
      "logits/rejected": -3.852963447570801,
      "logps/chosen": -100.59825897216797,
      "logps/rejected": -190.50413513183594,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0706650018692017,
      "rewards/margins": 7.8043413162231445,
      "rewards/rejected": -6.733676433563232,
      "step": 2167
    },
    {
      "epoch": 0.8672,
      "grad_norm": 0.19285914301872253,
      "learning_rate": 7.110666666666665e-07,
      "logits/chosen": -2.2466437816619873,
      "logits/rejected": -2.9039883613586426,
      "logps/chosen": -98.19255065917969,
      "logps/rejected": -165.744873046875,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.255155563354492,
      "rewards/margins": 9.073369979858398,
      "rewards/rejected": -6.818213939666748,
      "step": 2168
    },
    {
      "epoch": 0.8676,
      "grad_norm": 0.3214268684387207,
      "learning_rate": 7.109333333333332e-07,
      "logits/chosen": -2.621614456176758,
      "logits/rejected": -3.6144957542419434,
      "logps/chosen": -153.619873046875,
      "logps/rejected": -163.46438598632812,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.971783399581909,
      "rewards/margins": 8.133442878723145,
      "rewards/rejected": -5.161659240722656,
      "step": 2169
    },
    {
      "epoch": 0.868,
      "grad_norm": 0.03315483033657074,
      "learning_rate": 7.107999999999999e-07,
      "logits/chosen": -1.9311633110046387,
      "logits/rejected": -2.657381057739258,
      "logps/chosen": -106.32748413085938,
      "logps/rejected": -225.14639282226562,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0070672035217285,
      "rewards/margins": 8.644393920898438,
      "rewards/rejected": -5.637326240539551,
      "step": 2170
    },
    {
      "epoch": 0.8684,
      "grad_norm": 0.011811251752078533,
      "learning_rate": 7.106666666666666e-07,
      "logits/chosen": -2.358513116836548,
      "logits/rejected": -3.4045543670654297,
      "logps/chosen": -109.78213500976562,
      "logps/rejected": -156.88002014160156,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6556382179260254,
      "rewards/margins": 9.429895401000977,
      "rewards/rejected": -5.774258136749268,
      "step": 2171
    },
    {
      "epoch": 0.8688,
      "grad_norm": 0.10420844703912735,
      "learning_rate": 7.105333333333333e-07,
      "logits/chosen": -1.7890623807907104,
      "logits/rejected": -2.2222342491149902,
      "logps/chosen": -95.91496276855469,
      "logps/rejected": -118.96871948242188,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7902092933654785,
      "rewards/margins": 7.040805816650391,
      "rewards/rejected": -5.25059700012207,
      "step": 2172
    },
    {
      "epoch": 0.8692,
      "grad_norm": 0.020809341222047806,
      "learning_rate": 7.104e-07,
      "logits/chosen": -1.8714265823364258,
      "logits/rejected": -2.7549567222595215,
      "logps/chosen": -109.05506134033203,
      "logps/rejected": -167.24200439453125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3179383277893066,
      "rewards/margins": 9.111559867858887,
      "rewards/rejected": -5.793621063232422,
      "step": 2173
    },
    {
      "epoch": 0.8696,
      "grad_norm": 3.58246111869812,
      "learning_rate": 7.102666666666667e-07,
      "logits/chosen": -3.2458653450012207,
      "logits/rejected": -2.8752036094665527,
      "logps/chosen": -126.2142333984375,
      "logps/rejected": -143.98141479492188,
      "loss": 0.0291,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2559452056884766,
      "rewards/margins": 5.767532825469971,
      "rewards/rejected": -4.511587619781494,
      "step": 2174
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.3451421558856964,
      "learning_rate": 7.101333333333333e-07,
      "logits/chosen": -1.9885996580123901,
      "logits/rejected": -2.85113525390625,
      "logps/chosen": -102.94830322265625,
      "logps/rejected": -132.33340454101562,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3916163444519043,
      "rewards/margins": 7.368892669677734,
      "rewards/rejected": -3.97727632522583,
      "step": 2175
    },
    {
      "epoch": 0.8704,
      "grad_norm": 0.21677911281585693,
      "learning_rate": 7.1e-07,
      "logits/chosen": -2.167320489883423,
      "logits/rejected": -2.8924245834350586,
      "logps/chosen": -141.93603515625,
      "logps/rejected": -139.14450073242188,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7325806617736816,
      "rewards/margins": 7.2420759201049805,
      "rewards/rejected": -4.509495735168457,
      "step": 2176
    },
    {
      "epoch": 0.8708,
      "grad_norm": 0.13341915607452393,
      "learning_rate": 7.098666666666666e-07,
      "logits/chosen": -2.3983166217803955,
      "logits/rejected": -2.518270492553711,
      "logps/chosen": -277.91015625,
      "logps/rejected": -213.88539123535156,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8200950622558594,
      "rewards/margins": 8.220474243164062,
      "rewards/rejected": -4.400378227233887,
      "step": 2177
    },
    {
      "epoch": 0.8712,
      "grad_norm": 0.00783336441963911,
      "learning_rate": 7.097333333333333e-07,
      "logits/chosen": -2.3613405227661133,
      "logits/rejected": -3.2682113647460938,
      "logps/chosen": -192.77719116210938,
      "logps/rejected": -198.9151153564453,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.377633571624756,
      "rewards/margins": 10.296713829040527,
      "rewards/rejected": -6.9190802574157715,
      "step": 2178
    },
    {
      "epoch": 0.8716,
      "grad_norm": 0.229421928524971,
      "learning_rate": 7.096e-07,
      "logits/chosen": -2.2366676330566406,
      "logits/rejected": -3.143308639526367,
      "logps/chosen": -147.39630126953125,
      "logps/rejected": -162.42721557617188,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8723541498184204,
      "rewards/margins": 6.985722541809082,
      "rewards/rejected": -5.113368034362793,
      "step": 2179
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.3051559329032898,
      "learning_rate": 7.094666666666666e-07,
      "logits/chosen": -2.6709628105163574,
      "logits/rejected": -3.4998202323913574,
      "logps/chosen": -192.32667541503906,
      "logps/rejected": -157.76821899414062,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45800474286079407,
      "rewards/margins": 5.715619087219238,
      "rewards/rejected": -5.257614612579346,
      "step": 2180
    },
    {
      "epoch": 0.8724,
      "grad_norm": 0.017603717744350433,
      "learning_rate": 7.093333333333333e-07,
      "logits/chosen": -2.527933120727539,
      "logits/rejected": -3.5742130279541016,
      "logps/chosen": -172.45272827148438,
      "logps/rejected": -193.58193969726562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5965847969055176,
      "rewards/margins": 9.036528587341309,
      "rewards/rejected": -7.439943790435791,
      "step": 2181
    },
    {
      "epoch": 0.8728,
      "grad_norm": 0.43476051092147827,
      "learning_rate": 7.092e-07,
      "logits/chosen": -2.3199424743652344,
      "logits/rejected": -3.365691661834717,
      "logps/chosen": -110.53030395507812,
      "logps/rejected": -133.22332763671875,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9437122344970703,
      "rewards/margins": 5.236547470092773,
      "rewards/rejected": -4.292835235595703,
      "step": 2182
    },
    {
      "epoch": 0.8732,
      "grad_norm": 0.005761230364441872,
      "learning_rate": 7.090666666666666e-07,
      "logits/chosen": -1.6630024909973145,
      "logits/rejected": -4.025460243225098,
      "logps/chosen": -62.83917999267578,
      "logps/rejected": -194.10977172851562,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7916033267974854,
      "rewards/margins": 10.141274452209473,
      "rewards/rejected": -7.349671363830566,
      "step": 2183
    },
    {
      "epoch": 0.8736,
      "grad_norm": 0.024716947227716446,
      "learning_rate": 7.089333333333333e-07,
      "logits/chosen": -2.903831720352173,
      "logits/rejected": -3.5370728969573975,
      "logps/chosen": -117.58800506591797,
      "logps/rejected": -199.439208984375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.99153995513916,
      "rewards/margins": 11.093568801879883,
      "rewards/rejected": -7.102029323577881,
      "step": 2184
    },
    {
      "epoch": 0.874,
      "grad_norm": 0.23885641992092133,
      "learning_rate": 7.088e-07,
      "logits/chosen": -2.324045181274414,
      "logits/rejected": -3.018580198287964,
      "logps/chosen": -141.10205078125,
      "logps/rejected": -141.28482055664062,
      "loss": 0.0032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7698814868927002,
      "rewards/margins": 5.91362190246582,
      "rewards/rejected": -4.143740177154541,
      "step": 2185
    },
    {
      "epoch": 0.8744,
      "grad_norm": 0.009184113703668118,
      "learning_rate": 7.086666666666667e-07,
      "logits/chosen": -2.148500919342041,
      "logits/rejected": -3.7218761444091797,
      "logps/chosen": -81.27890014648438,
      "logps/rejected": -161.37615966796875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3870186805725098,
      "rewards/margins": 9.422708511352539,
      "rewards/rejected": -6.035689353942871,
      "step": 2186
    },
    {
      "epoch": 0.8748,
      "grad_norm": 0.13524048030376434,
      "learning_rate": 7.085333333333333e-07,
      "logits/chosen": -1.9388394355773926,
      "logits/rejected": -3.2280168533325195,
      "logps/chosen": -176.3175506591797,
      "logps/rejected": -130.75357055664062,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.978963613510132,
      "rewards/margins": 6.815360069274902,
      "rewards/rejected": -3.8363964557647705,
      "step": 2187
    },
    {
      "epoch": 0.8752,
      "grad_norm": 1.9769344329833984,
      "learning_rate": 7.084e-07,
      "logits/chosen": -1.7348891496658325,
      "logits/rejected": -2.7804760932922363,
      "logps/chosen": -130.4860076904297,
      "logps/rejected": -116.05039978027344,
      "loss": 0.0241,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.36418724060058594,
      "rewards/margins": 4.029339790344238,
      "rewards/rejected": -4.393527507781982,
      "step": 2188
    },
    {
      "epoch": 0.8756,
      "grad_norm": 0.03499886393547058,
      "learning_rate": 7.082666666666667e-07,
      "logits/chosen": -1.7435836791992188,
      "logits/rejected": -2.809434413909912,
      "logps/chosen": -124.76079559326172,
      "logps/rejected": -148.46426391601562,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.792736530303955,
      "rewards/margins": 8.496088027954102,
      "rewards/rejected": -4.703351020812988,
      "step": 2189
    },
    {
      "epoch": 0.876,
      "grad_norm": 0.16305068135261536,
      "learning_rate": 7.081333333333332e-07,
      "logits/chosen": -2.1667613983154297,
      "logits/rejected": -2.7795839309692383,
      "logps/chosen": -96.44021606445312,
      "logps/rejected": -137.9489288330078,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6029529571533203,
      "rewards/margins": 7.556764125823975,
      "rewards/rejected": -5.9538116455078125,
      "step": 2190
    },
    {
      "epoch": 0.8764,
      "grad_norm": 0.04638426750898361,
      "learning_rate": 7.079999999999999e-07,
      "logits/chosen": -2.5467138290405273,
      "logits/rejected": -3.1091442108154297,
      "logps/chosen": -157.9820556640625,
      "logps/rejected": -145.52642822265625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2144203186035156,
      "rewards/margins": 8.347074508666992,
      "rewards/rejected": -5.132654190063477,
      "step": 2191
    },
    {
      "epoch": 0.8768,
      "grad_norm": 0.08852844685316086,
      "learning_rate": 7.078666666666666e-07,
      "logits/chosen": -2.1806280612945557,
      "logits/rejected": -2.820620059967041,
      "logps/chosen": -121.29901123046875,
      "logps/rejected": -159.36386108398438,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8239154815673828,
      "rewards/margins": 7.917473793029785,
      "rewards/rejected": -6.093558311462402,
      "step": 2192
    },
    {
      "epoch": 0.8772,
      "grad_norm": 0.2386011928319931,
      "learning_rate": 7.077333333333333e-07,
      "logits/chosen": -1.9392058849334717,
      "logits/rejected": -3.2805967330932617,
      "logps/chosen": -118.89224243164062,
      "logps/rejected": -145.5284423828125,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1887741088867188,
      "rewards/margins": 6.979792594909668,
      "rewards/rejected": -5.791018009185791,
      "step": 2193
    },
    {
      "epoch": 0.8776,
      "grad_norm": 0.005429273005574942,
      "learning_rate": 7.076e-07,
      "logits/chosen": -2.0354714393615723,
      "logits/rejected": -3.2158970832824707,
      "logps/chosen": -100.8954849243164,
      "logps/rejected": -226.558837890625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4164700508117676,
      "rewards/margins": 10.373296737670898,
      "rewards/rejected": -6.956827163696289,
      "step": 2194
    },
    {
      "epoch": 0.878,
      "grad_norm": 0.41531550884246826,
      "learning_rate": 7.074666666666667e-07,
      "logits/chosen": -2.468519926071167,
      "logits/rejected": -2.955872058868408,
      "logps/chosen": -200.83184814453125,
      "logps/rejected": -148.5011444091797,
      "loss": 0.0042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4345120191574097,
      "rewards/margins": 5.73709774017334,
      "rewards/rejected": -4.302585601806641,
      "step": 2195
    },
    {
      "epoch": 0.8784,
      "grad_norm": 0.04802975058555603,
      "learning_rate": 7.073333333333333e-07,
      "logits/chosen": -2.6806118488311768,
      "logits/rejected": -3.6678318977355957,
      "logps/chosen": -121.22941589355469,
      "logps/rejected": -182.602783203125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.757933497428894,
      "rewards/margins": 8.29983139038086,
      "rewards/rejected": -6.541898727416992,
      "step": 2196
    },
    {
      "epoch": 0.8788,
      "grad_norm": 0.39436066150665283,
      "learning_rate": 7.072e-07,
      "logits/chosen": -2.2496066093444824,
      "logits/rejected": -3.243741989135742,
      "logps/chosen": -135.98023986816406,
      "logps/rejected": -137.0192108154297,
      "loss": 0.0026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0543065071105957,
      "rewards/margins": 7.386585712432861,
      "rewards/rejected": -4.332279205322266,
      "step": 2197
    },
    {
      "epoch": 0.8792,
      "grad_norm": 0.1264246553182602,
      "learning_rate": 7.070666666666666e-07,
      "logits/chosen": -2.506706953048706,
      "logits/rejected": -3.128962516784668,
      "logps/chosen": -97.89324188232422,
      "logps/rejected": -170.5733642578125,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2949615716934204,
      "rewards/margins": 7.643112659454346,
      "rewards/rejected": -6.348151206970215,
      "step": 2198
    },
    {
      "epoch": 0.8796,
      "grad_norm": 0.07084047794342041,
      "learning_rate": 7.069333333333333e-07,
      "logits/chosen": -2.1194446086883545,
      "logits/rejected": -2.7811689376831055,
      "logps/chosen": -130.69964599609375,
      "logps/rejected": -123.16465759277344,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3314857482910156,
      "rewards/margins": 7.528147220611572,
      "rewards/rejected": -5.196661472320557,
      "step": 2199
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.0032087676227092743,
      "learning_rate": 7.068e-07,
      "logits/chosen": -2.072519063949585,
      "logits/rejected": -3.2777042388916016,
      "logps/chosen": -126.77143096923828,
      "logps/rejected": -161.1476287841797,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.1044816970825195,
      "rewards/margins": 10.756433486938477,
      "rewards/rejected": -6.651951789855957,
      "step": 2200
    },
    {
      "epoch": 0.8804,
      "grad_norm": 0.01346501987427473,
      "learning_rate": 7.066666666666666e-07,
      "logits/chosen": -2.1220688819885254,
      "logits/rejected": -3.2449259757995605,
      "logps/chosen": -152.4923553466797,
      "logps/rejected": -187.12689208984375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.8269410133361816,
      "rewards/margins": 9.946547508239746,
      "rewards/rejected": -6.1196064949035645,
      "step": 2201
    },
    {
      "epoch": 0.8808,
      "grad_norm": 2.134033203125,
      "learning_rate": 7.065333333333333e-07,
      "logits/chosen": -1.851266860961914,
      "logits/rejected": -2.9727299213409424,
      "logps/chosen": -133.66259765625,
      "logps/rejected": -142.0332489013672,
      "loss": 0.0293,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.011250317096710205,
      "rewards/margins": 4.82269287109375,
      "rewards/rejected": -4.8339433670043945,
      "step": 2202
    },
    {
      "epoch": 0.8812,
      "grad_norm": 0.5364342927932739,
      "learning_rate": 7.064e-07,
      "logits/chosen": -2.130248546600342,
      "logits/rejected": -3.256974697113037,
      "logps/chosen": -138.85751342773438,
      "logps/rejected": -164.64608764648438,
      "loss": 0.0036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0889296531677246,
      "rewards/margins": 6.844178676605225,
      "rewards/rejected": -5.7552490234375,
      "step": 2203
    },
    {
      "epoch": 0.8816,
      "grad_norm": 0.5853009223937988,
      "learning_rate": 7.062666666666667e-07,
      "logits/chosen": -2.16256046295166,
      "logits/rejected": -3.225555896759033,
      "logps/chosen": -126.18833923339844,
      "logps/rejected": -147.0494384765625,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4390000104904175,
      "rewards/margins": 6.51739501953125,
      "rewards/rejected": -6.078394889831543,
      "step": 2204
    },
    {
      "epoch": 0.882,
      "grad_norm": 0.06008777767419815,
      "learning_rate": 7.061333333333332e-07,
      "logits/chosen": -2.2508606910705566,
      "logits/rejected": -2.9518842697143555,
      "logps/chosen": -199.08546447753906,
      "logps/rejected": -165.08779907226562,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.174372911453247,
      "rewards/margins": 7.277864456176758,
      "rewards/rejected": -6.10349178314209,
      "step": 2205
    },
    {
      "epoch": 0.8824,
      "grad_norm": 0.4133131206035614,
      "learning_rate": 7.059999999999999e-07,
      "logits/chosen": -2.2486467361450195,
      "logits/rejected": -3.2269883155822754,
      "logps/chosen": -121.10501861572266,
      "logps/rejected": -127.60598754882812,
      "loss": 0.0034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.484610080718994,
      "rewards/margins": 6.882988929748535,
      "rewards/rejected": -4.398378849029541,
      "step": 2206
    },
    {
      "epoch": 0.8828,
      "grad_norm": 0.008221650496125221,
      "learning_rate": 7.058666666666666e-07,
      "logits/chosen": -2.2284586429595947,
      "logits/rejected": -3.110236167907715,
      "logps/chosen": -109.02412414550781,
      "logps/rejected": -157.2748565673828,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6361148357391357,
      "rewards/margins": 9.569663047790527,
      "rewards/rejected": -5.9335479736328125,
      "step": 2207
    },
    {
      "epoch": 0.8832,
      "grad_norm": 6.376903057098389,
      "learning_rate": 7.057333333333333e-07,
      "logits/chosen": -1.9450435638427734,
      "logits/rejected": -3.119727611541748,
      "logps/chosen": -214.8318328857422,
      "logps/rejected": -129.48138427734375,
      "loss": 0.0465,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.509901523590088,
      "rewards/margins": 6.078988075256348,
      "rewards/rejected": -4.56908655166626,
      "step": 2208
    },
    {
      "epoch": 0.8836,
      "grad_norm": 0.030188245698809624,
      "learning_rate": 7.056e-07,
      "logits/chosen": -2.449969530105591,
      "logits/rejected": -3.1639649868011475,
      "logps/chosen": -205.82406616210938,
      "logps/rejected": -210.6341552734375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7319130897521973,
      "rewards/margins": 9.013738632202148,
      "rewards/rejected": -6.281826019287109,
      "step": 2209
    },
    {
      "epoch": 0.884,
      "grad_norm": 0.00832702498883009,
      "learning_rate": 7.054666666666667e-07,
      "logits/chosen": -2.5188450813293457,
      "logits/rejected": -3.244765281677246,
      "logps/chosen": -125.1212158203125,
      "logps/rejected": -187.3660888671875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.950428009033203,
      "rewards/margins": 9.606523513793945,
      "rewards/rejected": -6.656095504760742,
      "step": 2210
    },
    {
      "epoch": 0.8844,
      "grad_norm": 0.21191728115081787,
      "learning_rate": 7.053333333333333e-07,
      "logits/chosen": -2.5672736167907715,
      "logits/rejected": -3.390285015106201,
      "logps/chosen": -185.44985961914062,
      "logps/rejected": -170.5615234375,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1531531810760498,
      "rewards/margins": 8.873271942138672,
      "rewards/rejected": -7.720118522644043,
      "step": 2211
    },
    {
      "epoch": 0.8848,
      "grad_norm": 0.04329805448651314,
      "learning_rate": 7.052e-07,
      "logits/chosen": -2.1667580604553223,
      "logits/rejected": -3.769899368286133,
      "logps/chosen": -103.71559143066406,
      "logps/rejected": -185.8719482421875,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8919880390167236,
      "rewards/margins": 8.280981063842773,
      "rewards/rejected": -6.388992786407471,
      "step": 2212
    },
    {
      "epoch": 0.8852,
      "grad_norm": 0.054438214749097824,
      "learning_rate": 7.050666666666666e-07,
      "logits/chosen": -2.1716322898864746,
      "logits/rejected": -3.0511887073516846,
      "logps/chosen": -127.96176147460938,
      "logps/rejected": -168.0404510498047,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4837563037872314,
      "rewards/margins": 7.710366725921631,
      "rewards/rejected": -4.2266106605529785,
      "step": 2213
    },
    {
      "epoch": 0.8856,
      "grad_norm": 0.09367147833108902,
      "learning_rate": 7.049333333333333e-07,
      "logits/chosen": -2.030606985092163,
      "logits/rejected": -2.8177967071533203,
      "logps/chosen": -115.1824951171875,
      "logps/rejected": -146.45016479492188,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4815654754638672,
      "rewards/margins": 7.62003231048584,
      "rewards/rejected": -6.138466835021973,
      "step": 2214
    },
    {
      "epoch": 0.886,
      "grad_norm": 0.353722482919693,
      "learning_rate": 7.047999999999999e-07,
      "logits/chosen": -2.268099308013916,
      "logits/rejected": -2.707247734069824,
      "logps/chosen": -97.22076416015625,
      "logps/rejected": -136.2556610107422,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4782719612121582,
      "rewards/margins": 7.222609996795654,
      "rewards/rejected": -5.744338035583496,
      "step": 2215
    },
    {
      "epoch": 0.8864,
      "grad_norm": 0.004667892120778561,
      "learning_rate": 7.046666666666666e-07,
      "logits/chosen": -2.0916895866394043,
      "logits/rejected": -2.985637903213501,
      "logps/chosen": -92.72842407226562,
      "logps/rejected": -159.33505249023438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.09097957611084,
      "rewards/margins": 10.112628936767578,
      "rewards/rejected": -6.021649360656738,
      "step": 2216
    },
    {
      "epoch": 0.8868,
      "grad_norm": 0.5854437947273254,
      "learning_rate": 7.045333333333333e-07,
      "logits/chosen": -2.4747328758239746,
      "logits/rejected": -3.416396141052246,
      "logps/chosen": -99.17644500732422,
      "logps/rejected": -152.66525268554688,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2454830408096313,
      "rewards/margins": 7.515469551086426,
      "rewards/rejected": -6.269986152648926,
      "step": 2217
    },
    {
      "epoch": 0.8872,
      "grad_norm": 0.013215476647019386,
      "learning_rate": 7.044e-07,
      "logits/chosen": -2.136220693588257,
      "logits/rejected": -2.9310383796691895,
      "logps/chosen": -101.32449340820312,
      "logps/rejected": -141.37686157226562,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5064024925231934,
      "rewards/margins": 9.081451416015625,
      "rewards/rejected": -5.575048446655273,
      "step": 2218
    },
    {
      "epoch": 0.8876,
      "grad_norm": 0.6735912561416626,
      "learning_rate": 7.042666666666667e-07,
      "logits/chosen": -1.6407798528671265,
      "logits/rejected": -3.5035557746887207,
      "logps/chosen": -65.60861206054688,
      "logps/rejected": -164.1824951171875,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7385196685791016,
      "rewards/margins": 8.11470890045166,
      "rewards/rejected": -6.376189231872559,
      "step": 2219
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.2611224353313446,
      "learning_rate": 7.041333333333334e-07,
      "logits/chosen": -2.170858383178711,
      "logits/rejected": -2.61384916305542,
      "logps/chosen": -97.08111572265625,
      "logps/rejected": -141.86029052734375,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4215009212493896,
      "rewards/margins": 7.4243974685668945,
      "rewards/rejected": -5.002896308898926,
      "step": 2220
    },
    {
      "epoch": 0.8884,
      "grad_norm": 0.13550059497356415,
      "learning_rate": 7.04e-07,
      "logits/chosen": -2.1388964653015137,
      "logits/rejected": -3.3008525371551514,
      "logps/chosen": -164.82232666015625,
      "logps/rejected": -198.16455078125,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.545975923538208,
      "rewards/margins": 6.675487995147705,
      "rewards/rejected": -5.129511833190918,
      "step": 2221
    },
    {
      "epoch": 0.8888,
      "grad_norm": 0.049536678940057755,
      "learning_rate": 7.038666666666666e-07,
      "logits/chosen": -2.515557289123535,
      "logits/rejected": -3.370077133178711,
      "logps/chosen": -125.58475494384766,
      "logps/rejected": -149.64163208007812,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.499105930328369,
      "rewards/margins": 9.076448440551758,
      "rewards/rejected": -5.5773420333862305,
      "step": 2222
    },
    {
      "epoch": 0.8892,
      "grad_norm": 2.551081895828247,
      "learning_rate": 7.037333333333333e-07,
      "logits/chosen": -2.208319664001465,
      "logits/rejected": -2.6573753356933594,
      "logps/chosen": -119.64205932617188,
      "logps/rejected": -130.1544647216797,
      "loss": 0.0333,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0687167644500732,
      "rewards/margins": 7.526712894439697,
      "rewards/rejected": -4.457995891571045,
      "step": 2223
    },
    {
      "epoch": 0.8896,
      "grad_norm": 0.17670008540153503,
      "learning_rate": 7.035999999999999e-07,
      "logits/chosen": -2.3156185150146484,
      "logits/rejected": -3.151601791381836,
      "logps/chosen": -133.42031860351562,
      "logps/rejected": -169.2801513671875,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6636803150177002,
      "rewards/margins": 7.268027305603027,
      "rewards/rejected": -5.604347229003906,
      "step": 2224
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.0033797097858041525,
      "learning_rate": 7.034666666666666e-07,
      "logits/chosen": -2.289895534515381,
      "logits/rejected": -3.3085107803344727,
      "logps/chosen": -106.45519256591797,
      "logps/rejected": -165.66314697265625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4686927795410156,
      "rewards/margins": 10.435819625854492,
      "rewards/rejected": -6.967126846313477,
      "step": 2225
    },
    {
      "epoch": 0.8904,
      "grad_norm": 0.047182634472846985,
      "learning_rate": 7.033333333333333e-07,
      "logits/chosen": -1.837748646736145,
      "logits/rejected": -2.8881137371063232,
      "logps/chosen": -67.12368774414062,
      "logps/rejected": -144.01205444335938,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3314058780670166,
      "rewards/margins": 8.03862476348877,
      "rewards/rejected": -4.707219123840332,
      "step": 2226
    },
    {
      "epoch": 0.8908,
      "grad_norm": 0.0477362684905529,
      "learning_rate": 7.032e-07,
      "logits/chosen": -2.6244397163391113,
      "logits/rejected": -3.1473922729492188,
      "logps/chosen": -118.5342788696289,
      "logps/rejected": -161.89947509765625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6129646301269531,
      "rewards/margins": 7.922279357910156,
      "rewards/rejected": -6.309314250946045,
      "step": 2227
    },
    {
      "epoch": 0.8912,
      "grad_norm": 0.17445175349712372,
      "learning_rate": 7.030666666666666e-07,
      "logits/chosen": -2.0697572231292725,
      "logits/rejected": -2.7577767372131348,
      "logps/chosen": -97.21592712402344,
      "logps/rejected": -121.5372314453125,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7959041595458984,
      "rewards/margins": 6.651115894317627,
      "rewards/rejected": -4.8552117347717285,
      "step": 2228
    },
    {
      "epoch": 0.8916,
      "grad_norm": 0.04546821862459183,
      "learning_rate": 7.029333333333333e-07,
      "logits/chosen": -2.307976245880127,
      "logits/rejected": -3.894071102142334,
      "logps/chosen": -93.598876953125,
      "logps/rejected": -164.19699096679688,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9656245708465576,
      "rewards/margins": 8.363870620727539,
      "rewards/rejected": -6.398245811462402,
      "step": 2229
    },
    {
      "epoch": 0.892,
      "grad_norm": 0.5042212009429932,
      "learning_rate": 7.028e-07,
      "logits/chosen": -2.4925267696380615,
      "logits/rejected": -3.4259390830993652,
      "logps/chosen": -189.9931640625,
      "logps/rejected": -153.49942016601562,
      "loss": 0.0053,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9853695034980774,
      "rewards/margins": 5.912287712097168,
      "rewards/rejected": -4.926918029785156,
      "step": 2230
    },
    {
      "epoch": 0.8924,
      "grad_norm": 0.04843263700604439,
      "learning_rate": 7.026666666666667e-07,
      "logits/chosen": -2.4699249267578125,
      "logits/rejected": -3.362154722213745,
      "logps/chosen": -126.70440673828125,
      "logps/rejected": -139.90353393554688,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8228988647460938,
      "rewards/margins": 7.645176887512207,
      "rewards/rejected": -4.822278022766113,
      "step": 2231
    },
    {
      "epoch": 0.8928,
      "grad_norm": 0.8141261339187622,
      "learning_rate": 7.025333333333334e-07,
      "logits/chosen": -1.7815608978271484,
      "logits/rejected": -2.9163169860839844,
      "logps/chosen": -67.85214233398438,
      "logps/rejected": -111.74073791503906,
      "loss": 0.0052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.65922212600708,
      "rewards/margins": 6.5031585693359375,
      "rewards/rejected": -3.8439364433288574,
      "step": 2232
    },
    {
      "epoch": 0.8932,
      "grad_norm": 0.11353901028633118,
      "learning_rate": 7.024e-07,
      "logits/chosen": -2.389484405517578,
      "logits/rejected": -2.9390385150909424,
      "logps/chosen": -199.71739196777344,
      "logps/rejected": -180.92237854003906,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7257308959960938,
      "rewards/margins": 8.914321899414062,
      "rewards/rejected": -6.188591480255127,
      "step": 2233
    },
    {
      "epoch": 0.8936,
      "grad_norm": 0.03097589686512947,
      "learning_rate": 7.022666666666666e-07,
      "logits/chosen": -2.223269462585449,
      "logits/rejected": -3.9529590606689453,
      "logps/chosen": -99.61044311523438,
      "logps/rejected": -201.98068237304688,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.175588607788086,
      "rewards/margins": 8.247238159179688,
      "rewards/rejected": -5.071648597717285,
      "step": 2234
    },
    {
      "epoch": 0.894,
      "grad_norm": 0.07032160460948944,
      "learning_rate": 7.021333333333333e-07,
      "logits/chosen": -2.6447906494140625,
      "logits/rejected": -3.296213150024414,
      "logps/chosen": -121.93632507324219,
      "logps/rejected": -160.13601684570312,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0887444019317627,
      "rewards/margins": 7.548274517059326,
      "rewards/rejected": -6.459530353546143,
      "step": 2235
    },
    {
      "epoch": 0.8944,
      "grad_norm": 0.023773949593305588,
      "learning_rate": 7.019999999999999e-07,
      "logits/chosen": -2.967604160308838,
      "logits/rejected": -3.0527493953704834,
      "logps/chosen": -110.33712768554688,
      "logps/rejected": -163.21945190429688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0901942253112793,
      "rewards/margins": 8.468194007873535,
      "rewards/rejected": -6.377999305725098,
      "step": 2236
    },
    {
      "epoch": 0.8948,
      "grad_norm": 0.01656801998615265,
      "learning_rate": 7.018666666666666e-07,
      "logits/chosen": -2.0820460319519043,
      "logits/rejected": -2.9834752082824707,
      "logps/chosen": -114.482666015625,
      "logps/rejected": -174.11459350585938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8551208972930908,
      "rewards/margins": 9.19390869140625,
      "rewards/rejected": -7.338788032531738,
      "step": 2237
    },
    {
      "epoch": 0.8952,
      "grad_norm": 0.02012573927640915,
      "learning_rate": 7.017333333333333e-07,
      "logits/chosen": -2.182868003845215,
      "logits/rejected": -3.16542387008667,
      "logps/chosen": -108.78976440429688,
      "logps/rejected": -162.96273803710938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.9833555221557617,
      "rewards/margins": 9.464900970458984,
      "rewards/rejected": -5.481545448303223,
      "step": 2238
    },
    {
      "epoch": 0.8956,
      "grad_norm": 0.3296869993209839,
      "learning_rate": 7.016e-07,
      "logits/chosen": -2.480045795440674,
      "logits/rejected": -2.665471315383911,
      "logps/chosen": -160.24896240234375,
      "logps/rejected": -162.6687774658203,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6679824590682983,
      "rewards/margins": 7.7109527587890625,
      "rewards/rejected": -6.042970657348633,
      "step": 2239
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.020789949223399162,
      "learning_rate": 7.014666666666667e-07,
      "logits/chosen": -1.6871755123138428,
      "logits/rejected": -3.1911799907684326,
      "logps/chosen": -122.6614761352539,
      "logps/rejected": -157.73825073242188,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2077488899230957,
      "rewards/margins": 8.905379295349121,
      "rewards/rejected": -5.697630405426025,
      "step": 2240
    },
    {
      "epoch": 0.8964,
      "grad_norm": 0.2277364879846573,
      "learning_rate": 7.013333333333334e-07,
      "logits/chosen": -1.5800824165344238,
      "logits/rejected": -3.8272669315338135,
      "logps/chosen": -99.81696319580078,
      "logps/rejected": -167.3865203857422,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6526062488555908,
      "rewards/margins": 7.2258405685424805,
      "rewards/rejected": -5.573234558105469,
      "step": 2241
    },
    {
      "epoch": 0.8968,
      "grad_norm": 0.44196605682373047,
      "learning_rate": 7.012000000000001e-07,
      "logits/chosen": -2.202608346939087,
      "logits/rejected": -3.1024680137634277,
      "logps/chosen": -87.263427734375,
      "logps/rejected": -130.621337890625,
      "loss": 0.0066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4675934314727783,
      "rewards/margins": 5.938898086547852,
      "rewards/rejected": -4.471304416656494,
      "step": 2242
    },
    {
      "epoch": 0.8972,
      "grad_norm": 0.021360520273447037,
      "learning_rate": 7.010666666666665e-07,
      "logits/chosen": -2.4716713428497314,
      "logits/rejected": -3.426684856414795,
      "logps/chosen": -128.41351318359375,
      "logps/rejected": -160.87342834472656,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2500336170196533,
      "rewards/margins": 8.492012023925781,
      "rewards/rejected": -6.241978645324707,
      "step": 2243
    },
    {
      "epoch": 0.8976,
      "grad_norm": 0.061243124306201935,
      "learning_rate": 7.009333333333332e-07,
      "logits/chosen": -2.0186607837677,
      "logits/rejected": -2.6930394172668457,
      "logps/chosen": -67.51213073730469,
      "logps/rejected": -119.62067413330078,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3882155418395996,
      "rewards/margins": 7.542871475219727,
      "rewards/rejected": -4.154655933380127,
      "step": 2244
    },
    {
      "epoch": 0.898,
      "grad_norm": 0.4554857313632965,
      "learning_rate": 7.007999999999999e-07,
      "logits/chosen": -2.20544171333313,
      "logits/rejected": -3.268876075744629,
      "logps/chosen": -127.85096740722656,
      "logps/rejected": -143.46920776367188,
      "loss": 0.0043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9936493635177612,
      "rewards/margins": 6.6723127365112305,
      "rewards/rejected": -5.678663730621338,
      "step": 2245
    },
    {
      "epoch": 0.8984,
      "grad_norm": 4.743954658508301,
      "learning_rate": 7.006666666666666e-07,
      "logits/chosen": -2.3440423011779785,
      "logits/rejected": -3.444948673248291,
      "logps/chosen": -203.85035705566406,
      "logps/rejected": -196.20571899414062,
      "loss": 0.0359,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0932273864746094,
      "rewards/margins": 4.709404945373535,
      "rewards/rejected": -5.8026323318481445,
      "step": 2246
    },
    {
      "epoch": 0.8988,
      "grad_norm": 0.0072396788746118546,
      "learning_rate": 7.005333333333333e-07,
      "logits/chosen": -2.4335741996765137,
      "logits/rejected": -3.036461353302002,
      "logps/chosen": -179.13961791992188,
      "logps/rejected": -185.41896057128906,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.363530158996582,
      "rewards/margins": 10.522520065307617,
      "rewards/rejected": -7.158990859985352,
      "step": 2247
    },
    {
      "epoch": 0.8992,
      "grad_norm": 2.177001714706421,
      "learning_rate": 7.004e-07,
      "logits/chosen": -2.396202325820923,
      "logits/rejected": -3.469144582748413,
      "logps/chosen": -122.32223510742188,
      "logps/rejected": -147.8547821044922,
      "loss": 0.0184,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6930458545684814,
      "rewards/margins": 6.8342742919921875,
      "rewards/rejected": -5.141228199005127,
      "step": 2248
    },
    {
      "epoch": 0.8996,
      "grad_norm": 0.018850160762667656,
      "learning_rate": 7.002666666666667e-07,
      "logits/chosen": -2.3759608268737793,
      "logits/rejected": -3.648637294769287,
      "logps/chosen": -82.93095397949219,
      "logps/rejected": -166.64752197265625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.261584758758545,
      "rewards/margins": 9.189836502075195,
      "rewards/rejected": -6.928251266479492,
      "step": 2249
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.10902184993028641,
      "learning_rate": 7.001333333333334e-07,
      "logits/chosen": -1.9555881023406982,
      "logits/rejected": -2.804469585418701,
      "logps/chosen": -117.95606994628906,
      "logps/rejected": -205.59100341796875,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.857873558998108,
      "rewards/margins": 6.778933048248291,
      "rewards/rejected": -4.921059608459473,
      "step": 2250
    },
    {
      "epoch": 0.9004,
      "grad_norm": 0.035451408475637436,
      "learning_rate": 7e-07,
      "logits/chosen": -2.0134730339050293,
      "logits/rejected": -2.970553398132324,
      "logps/chosen": -93.40202331542969,
      "logps/rejected": -184.33612060546875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2311935424804688,
      "rewards/margins": 8.232755661010742,
      "rewards/rejected": -7.001562595367432,
      "step": 2251
    },
    {
      "epoch": 0.9008,
      "grad_norm": 0.04373570904135704,
      "learning_rate": 6.998666666666666e-07,
      "logits/chosen": -2.5874247550964355,
      "logits/rejected": -3.3182363510131836,
      "logps/chosen": -115.71626281738281,
      "logps/rejected": -150.70361328125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3640060424804688,
      "rewards/margins": 7.853560924530029,
      "rewards/rejected": -6.489554405212402,
      "step": 2252
    },
    {
      "epoch": 0.9012,
      "grad_norm": 9.086993217468262,
      "learning_rate": 6.997333333333332e-07,
      "logits/chosen": -2.5602216720581055,
      "logits/rejected": -3.1386361122131348,
      "logps/chosen": -156.3778533935547,
      "logps/rejected": -143.8133544921875,
      "loss": 0.1077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.00614166259765625,
      "rewards/margins": 4.992031097412109,
      "rewards/rejected": -4.998172760009766,
      "step": 2253
    },
    {
      "epoch": 0.9016,
      "grad_norm": 2.781137704849243,
      "learning_rate": 6.995999999999999e-07,
      "logits/chosen": -2.9364733695983887,
      "logits/rejected": -2.970754623413086,
      "logps/chosen": -203.99729919433594,
      "logps/rejected": -275.2266540527344,
      "loss": 0.019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5466201901435852,
      "rewards/margins": 4.5067138671875,
      "rewards/rejected": -5.0533342361450195,
      "step": 2254
    },
    {
      "epoch": 0.902,
      "grad_norm": 0.012531126849353313,
      "learning_rate": 6.994666666666666e-07,
      "logits/chosen": -2.541149616241455,
      "logits/rejected": -3.21608304977417,
      "logps/chosen": -153.69065856933594,
      "logps/rejected": -204.8504638671875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5409317016601562,
      "rewards/margins": 10.75230598449707,
      "rewards/rejected": -7.211374282836914,
      "step": 2255
    },
    {
      "epoch": 0.9024,
      "grad_norm": 0.14485950767993927,
      "learning_rate": 6.993333333333333e-07,
      "logits/chosen": -2.8661255836486816,
      "logits/rejected": -2.9897818565368652,
      "logps/chosen": -221.51443481445312,
      "logps/rejected": -175.89288330078125,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0745460987091064,
      "rewards/margins": 7.087125301361084,
      "rewards/rejected": -6.012578964233398,
      "step": 2256
    },
    {
      "epoch": 0.9028,
      "grad_norm": 0.05098958685994148,
      "learning_rate": 6.992e-07,
      "logits/chosen": -2.4808077812194824,
      "logits/rejected": -3.5126733779907227,
      "logps/chosen": -168.9813995361328,
      "logps/rejected": -166.8772735595703,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6189637184143066,
      "rewards/margins": 7.7644853591918945,
      "rewards/rejected": -5.14552116394043,
      "step": 2257
    },
    {
      "epoch": 0.9032,
      "grad_norm": 0.2752719521522522,
      "learning_rate": 6.990666666666666e-07,
      "logits/chosen": -1.9298570156097412,
      "logits/rejected": -2.5726373195648193,
      "logps/chosen": -145.3185577392578,
      "logps/rejected": -142.60244750976562,
      "loss": 0.003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6293659210205078,
      "rewards/margins": 6.008251190185547,
      "rewards/rejected": -5.378885269165039,
      "step": 2258
    },
    {
      "epoch": 0.9036,
      "grad_norm": 0.0028057743329554796,
      "learning_rate": 6.989333333333333e-07,
      "logits/chosen": -2.512162446975708,
      "logits/rejected": -3.2178657054901123,
      "logps/chosen": -94.26307678222656,
      "logps/rejected": -200.7686767578125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.601956367492676,
      "rewards/margins": 11.161832809448242,
      "rewards/rejected": -6.559876441955566,
      "step": 2259
    },
    {
      "epoch": 0.904,
      "grad_norm": 2.6963798999786377,
      "learning_rate": 6.988e-07,
      "logits/chosen": -2.385272264480591,
      "logits/rejected": -2.96519136428833,
      "logps/chosen": -108.23815155029297,
      "logps/rejected": -139.47894287109375,
      "loss": 0.0217,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.817063570022583,
      "rewards/margins": 7.15451717376709,
      "rewards/rejected": -4.337453842163086,
      "step": 2260
    },
    {
      "epoch": 0.9044,
      "grad_norm": 6.006587028503418,
      "learning_rate": 6.986666666666667e-07,
      "logits/chosen": -2.3542540073394775,
      "logits/rejected": -2.8401260375976562,
      "logps/chosen": -143.8843994140625,
      "logps/rejected": -136.1962890625,
      "loss": 0.0426,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.17425692081451416,
      "rewards/margins": 5.551322937011719,
      "rewards/rejected": -5.725579261779785,
      "step": 2261
    },
    {
      "epoch": 0.9048,
      "grad_norm": 0.032554056495428085,
      "learning_rate": 6.985333333333333e-07,
      "logits/chosen": -2.147226095199585,
      "logits/rejected": -3.0972533226013184,
      "logps/chosen": -122.62383270263672,
      "logps/rejected": -162.12803649902344,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2931151390075684,
      "rewards/margins": 8.327919006347656,
      "rewards/rejected": -6.034804344177246,
      "step": 2262
    },
    {
      "epoch": 0.9052,
      "grad_norm": 0.1465328335762024,
      "learning_rate": 6.984e-07,
      "logits/chosen": -2.003157615661621,
      "logits/rejected": -2.8256778717041016,
      "logps/chosen": -118.35948944091797,
      "logps/rejected": -145.42552185058594,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.716794013977051,
      "rewards/margins": 8.270027160644531,
      "rewards/rejected": -4.553234100341797,
      "step": 2263
    },
    {
      "epoch": 0.9056,
      "grad_norm": 0.18757203221321106,
      "learning_rate": 6.982666666666666e-07,
      "logits/chosen": -2.29862904548645,
      "logits/rejected": -2.97127628326416,
      "logps/chosen": -96.02870178222656,
      "logps/rejected": -137.92739868164062,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.310424327850342,
      "rewards/margins": 7.6525702476501465,
      "rewards/rejected": -5.342145919799805,
      "step": 2264
    },
    {
      "epoch": 0.906,
      "grad_norm": 0.00649124663323164,
      "learning_rate": 6.981333333333333e-07,
      "logits/chosen": -2.1409122943878174,
      "logits/rejected": -3.7489542961120605,
      "logps/chosen": -88.84806060791016,
      "logps/rejected": -186.89039611816406,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.264683485031128,
      "rewards/margins": 10.053960800170898,
      "rewards/rejected": -6.789276599884033,
      "step": 2265
    },
    {
      "epoch": 0.9064,
      "grad_norm": 0.08115831017494202,
      "learning_rate": 6.979999999999999e-07,
      "logits/chosen": -2.128674030303955,
      "logits/rejected": -2.5551390647888184,
      "logps/chosen": -75.5509033203125,
      "logps/rejected": -118.19937133789062,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6621522903442383,
      "rewards/margins": 7.309062957763672,
      "rewards/rejected": -4.646910667419434,
      "step": 2266
    },
    {
      "epoch": 0.9068,
      "grad_norm": 0.08757045865058899,
      "learning_rate": 6.978666666666666e-07,
      "logits/chosen": -1.975314736366272,
      "logits/rejected": -3.3673791885375977,
      "logps/chosen": -114.44034576416016,
      "logps/rejected": -151.77862548828125,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9591900706291199,
      "rewards/margins": 7.385563850402832,
      "rewards/rejected": -6.426373481750488,
      "step": 2267
    },
    {
      "epoch": 0.9072,
      "grad_norm": 0.041103970259428024,
      "learning_rate": 6.977333333333333e-07,
      "logits/chosen": -2.082186222076416,
      "logits/rejected": -2.98458194732666,
      "logps/chosen": -149.574951171875,
      "logps/rejected": -156.65159606933594,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.956059455871582,
      "rewards/margins": 9.295571327209473,
      "rewards/rejected": -5.339511871337891,
      "step": 2268
    },
    {
      "epoch": 0.9076,
      "grad_norm": 0.004431560635566711,
      "learning_rate": 6.976e-07,
      "logits/chosen": -2.106125593185425,
      "logits/rejected": -3.034592628479004,
      "logps/chosen": -86.24446868896484,
      "logps/rejected": -202.7021484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.027371406555176,
      "rewards/margins": 10.457748413085938,
      "rewards/rejected": -6.43037748336792,
      "step": 2269
    },
    {
      "epoch": 0.908,
      "grad_norm": 1.0616517066955566,
      "learning_rate": 6.974666666666667e-07,
      "logits/chosen": -2.278550148010254,
      "logits/rejected": -2.863748550415039,
      "logps/chosen": -89.826904296875,
      "logps/rejected": -144.4639892578125,
      "loss": 0.0123,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4491157531738281,
      "rewards/margins": 6.534964561462402,
      "rewards/rejected": -5.085848808288574,
      "step": 2270
    },
    {
      "epoch": 0.9084,
      "grad_norm": 0.006797339767217636,
      "learning_rate": 6.973333333333333e-07,
      "logits/chosen": -2.486292839050293,
      "logits/rejected": -3.3989486694335938,
      "logps/chosen": -131.1087646484375,
      "logps/rejected": -212.09814453125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.854518175125122,
      "rewards/margins": 10.126413345336914,
      "rewards/rejected": -6.271895408630371,
      "step": 2271
    },
    {
      "epoch": 0.9088,
      "grad_norm": 0.032672155648469925,
      "learning_rate": 6.972e-07,
      "logits/chosen": -2.3638405799865723,
      "logits/rejected": -2.8519492149353027,
      "logps/chosen": -181.1370849609375,
      "logps/rejected": -238.5245819091797,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7364044189453125,
      "rewards/margins": 9.374768257141113,
      "rewards/rejected": -5.638363838195801,
      "step": 2272
    },
    {
      "epoch": 0.9092,
      "grad_norm": 0.023003077134490013,
      "learning_rate": 6.970666666666666e-07,
      "logits/chosen": -2.086517095565796,
      "logits/rejected": -3.347646951675415,
      "logps/chosen": -96.80696105957031,
      "logps/rejected": -178.36282348632812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8785791397094727,
      "rewards/margins": 9.460785865783691,
      "rewards/rejected": -6.582206726074219,
      "step": 2273
    },
    {
      "epoch": 0.9096,
      "grad_norm": 3.569899320602417,
      "learning_rate": 6.969333333333332e-07,
      "logits/chosen": -2.9628500938415527,
      "logits/rejected": -2.472994327545166,
      "logps/chosen": -152.6266632080078,
      "logps/rejected": -154.76295471191406,
      "loss": 0.0176,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.17278176546096802,
      "rewards/margins": 5.475379467010498,
      "rewards/rejected": -5.648160934448242,
      "step": 2274
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.08425857871770859,
      "learning_rate": 6.967999999999999e-07,
      "logits/chosen": -2.192422389984131,
      "logits/rejected": -2.846142292022705,
      "logps/chosen": -80.85079956054688,
      "logps/rejected": -151.9709014892578,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.660820960998535,
      "rewards/margins": 9.280150413513184,
      "rewards/rejected": -5.619329929351807,
      "step": 2275
    },
    {
      "epoch": 0.9104,
      "grad_norm": 0.03207678347826004,
      "learning_rate": 6.966666666666666e-07,
      "logits/chosen": -2.5495548248291016,
      "logits/rejected": -3.2231743335723877,
      "logps/chosen": -178.8694610595703,
      "logps/rejected": -147.18658447265625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7253894805908203,
      "rewards/margins": 8.544290542602539,
      "rewards/rejected": -5.8189005851745605,
      "step": 2276
    },
    {
      "epoch": 0.9108,
      "grad_norm": 0.07437628507614136,
      "learning_rate": 6.965333333333333e-07,
      "logits/chosen": -3.2270238399505615,
      "logits/rejected": -2.9752302169799805,
      "logps/chosen": -235.17958068847656,
      "logps/rejected": -191.66848754882812,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.658639669418335,
      "rewards/margins": 7.452466011047363,
      "rewards/rejected": -5.793826103210449,
      "step": 2277
    },
    {
      "epoch": 0.9112,
      "grad_norm": 0.18219877779483795,
      "learning_rate": 6.964e-07,
      "logits/chosen": -2.617457866668701,
      "logits/rejected": -3.064822196960449,
      "logps/chosen": -189.59756469726562,
      "logps/rejected": -158.78521728515625,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7152191400527954,
      "rewards/margins": 6.603024482727051,
      "rewards/rejected": -4.887805938720703,
      "step": 2278
    },
    {
      "epoch": 0.9116,
      "grad_norm": 0.1343955546617508,
      "learning_rate": 6.962666666666667e-07,
      "logits/chosen": -2.1785495281219482,
      "logits/rejected": -3.4723105430603027,
      "logps/chosen": -232.76560974121094,
      "logps/rejected": -161.29550170898438,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.656023383140564,
      "rewards/margins": 7.06927490234375,
      "rewards/rejected": -5.413251876831055,
      "step": 2279
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.2934489846229553,
      "learning_rate": 6.961333333333334e-07,
      "logits/chosen": -2.0106983184814453,
      "logits/rejected": -2.7904772758483887,
      "logps/chosen": -81.87406921386719,
      "logps/rejected": -159.7347412109375,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.155881404876709,
      "rewards/margins": 7.581387996673584,
      "rewards/rejected": -5.425506591796875,
      "step": 2280
    },
    {
      "epoch": 0.9124,
      "grad_norm": 0.11469109356403351,
      "learning_rate": 6.959999999999999e-07,
      "logits/chosen": -2.754232883453369,
      "logits/rejected": -3.6225204467773438,
      "logps/chosen": -168.01651000976562,
      "logps/rejected": -174.014892578125,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0389366149902344,
      "rewards/margins": 8.518699645996094,
      "rewards/rejected": -5.479762554168701,
      "step": 2281
    },
    {
      "epoch": 0.9128,
      "grad_norm": 0.0012269985163584352,
      "learning_rate": 6.958666666666666e-07,
      "logits/chosen": -2.5238375663757324,
      "logits/rejected": -3.7729544639587402,
      "logps/chosen": -107.53828430175781,
      "logps/rejected": -191.15074157714844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.509270191192627,
      "rewards/margins": 11.41836166381836,
      "rewards/rejected": -6.909090995788574,
      "step": 2282
    },
    {
      "epoch": 0.9132,
      "grad_norm": 0.004550907760858536,
      "learning_rate": 6.957333333333333e-07,
      "logits/chosen": -2.5445573329925537,
      "logits/rejected": -3.0473198890686035,
      "logps/chosen": -172.48931884765625,
      "logps/rejected": -170.33261108398438,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.478672027587891,
      "rewards/margins": 10.9805269241333,
      "rewards/rejected": -6.50185489654541,
      "step": 2283
    },
    {
      "epoch": 0.9136,
      "grad_norm": 0.09876719117164612,
      "learning_rate": 6.956e-07,
      "logits/chosen": -2.265801429748535,
      "logits/rejected": -3.430178642272949,
      "logps/chosen": -111.32902526855469,
      "logps/rejected": -159.77279663085938,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5696690082550049,
      "rewards/margins": 8.203035354614258,
      "rewards/rejected": -6.633365631103516,
      "step": 2284
    },
    {
      "epoch": 0.914,
      "grad_norm": 0.07543006539344788,
      "learning_rate": 6.954666666666666e-07,
      "logits/chosen": -2.3239705562591553,
      "logits/rejected": -3.259444236755371,
      "logps/chosen": -134.99484252929688,
      "logps/rejected": -170.78958129882812,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9480526447296143,
      "rewards/margins": 9.254171371459961,
      "rewards/rejected": -6.306118965148926,
      "step": 2285
    },
    {
      "epoch": 0.9144,
      "grad_norm": 0.07619946449995041,
      "learning_rate": 6.953333333333333e-07,
      "logits/chosen": -2.3737874031066895,
      "logits/rejected": -3.081770420074463,
      "logps/chosen": -161.29470825195312,
      "logps/rejected": -145.7581787109375,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7698235511779785,
      "rewards/margins": 7.455856800079346,
      "rewards/rejected": -4.686033248901367,
      "step": 2286
    },
    {
      "epoch": 0.9148,
      "grad_norm": 0.058333754539489746,
      "learning_rate": 6.952e-07,
      "logits/chosen": -2.1238555908203125,
      "logits/rejected": -2.920506000518799,
      "logps/chosen": -100.3043212890625,
      "logps/rejected": -163.305908203125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1169097423553467,
      "rewards/margins": 8.095719337463379,
      "rewards/rejected": -4.978809356689453,
      "step": 2287
    },
    {
      "epoch": 0.9152,
      "grad_norm": 0.010724115185439587,
      "learning_rate": 6.950666666666667e-07,
      "logits/chosen": -2.0741987228393555,
      "logits/rejected": -3.4075541496276855,
      "logps/chosen": -84.5709228515625,
      "logps/rejected": -168.2048797607422,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.194080114364624,
      "rewards/margins": 9.250246047973633,
      "rewards/rejected": -6.05616569519043,
      "step": 2288
    },
    {
      "epoch": 0.9156,
      "grad_norm": 0.25588753819465637,
      "learning_rate": 6.949333333333333e-07,
      "logits/chosen": -1.733028531074524,
      "logits/rejected": -2.7392847537994385,
      "logps/chosen": -103.71926879882812,
      "logps/rejected": -200.93968200683594,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.451566696166992,
      "rewards/margins": 9.03390884399414,
      "rewards/rejected": -5.582342624664307,
      "step": 2289
    },
    {
      "epoch": 0.916,
      "grad_norm": 0.9663800597190857,
      "learning_rate": 6.947999999999999e-07,
      "logits/chosen": -2.3254706859588623,
      "logits/rejected": -3.1455187797546387,
      "logps/chosen": -140.565673828125,
      "logps/rejected": -151.95144653320312,
      "loss": 0.0093,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4296364188194275,
      "rewards/margins": 4.922124862670898,
      "rewards/rejected": -5.351761341094971,
      "step": 2290
    },
    {
      "epoch": 0.9164,
      "grad_norm": 0.005049953702837229,
      "learning_rate": 6.946666666666666e-07,
      "logits/chosen": -1.6247515678405762,
      "logits/rejected": -2.93412446975708,
      "logps/chosen": -97.0936050415039,
      "logps/rejected": -175.77581787109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.710421085357666,
      "rewards/margins": 10.46270751953125,
      "rewards/rejected": -7.752285957336426,
      "step": 2291
    },
    {
      "epoch": 0.9168,
      "grad_norm": 0.06188785284757614,
      "learning_rate": 6.945333333333333e-07,
      "logits/chosen": -2.3011927604675293,
      "logits/rejected": -3.1674914360046387,
      "logps/chosen": -207.9693603515625,
      "logps/rejected": -146.82669067382812,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.1605262756347656,
      "rewards/margins": 7.513263702392578,
      "rewards/rejected": -5.3527374267578125,
      "step": 2292
    },
    {
      "epoch": 0.9172,
      "grad_norm": 0.27499091625213623,
      "learning_rate": 6.944e-07,
      "logits/chosen": -1.9767940044403076,
      "logits/rejected": -3.140411853790283,
      "logps/chosen": -103.37313079833984,
      "logps/rejected": -148.5960235595703,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.084912896156311,
      "rewards/margins": 6.340502738952637,
      "rewards/rejected": -5.255589485168457,
      "step": 2293
    },
    {
      "epoch": 0.9176,
      "grad_norm": 0.006458422634750605,
      "learning_rate": 6.942666666666667e-07,
      "logits/chosen": -2.468710422515869,
      "logits/rejected": -3.455718517303467,
      "logps/chosen": -76.29447174072266,
      "logps/rejected": -152.8096466064453,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.831632614135742,
      "rewards/margins": 9.853050231933594,
      "rewards/rejected": -6.021417617797852,
      "step": 2294
    },
    {
      "epoch": 0.918,
      "grad_norm": 0.16780687868595123,
      "learning_rate": 6.941333333333334e-07,
      "logits/chosen": -1.748690128326416,
      "logits/rejected": -3.7313480377197266,
      "logps/chosen": -93.27323913574219,
      "logps/rejected": -176.2093505859375,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4053211510181427,
      "rewards/margins": 7.258064270019531,
      "rewards/rejected": -6.852743148803711,
      "step": 2295
    },
    {
      "epoch": 0.9184,
      "grad_norm": 0.21908706426620483,
      "learning_rate": 6.939999999999999e-07,
      "logits/chosen": -1.9781858921051025,
      "logits/rejected": -3.2288548946380615,
      "logps/chosen": -72.73987579345703,
      "logps/rejected": -139.2681427001953,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0878727436065674,
      "rewards/margins": 7.055403709411621,
      "rewards/rejected": -3.9675307273864746,
      "step": 2296
    },
    {
      "epoch": 0.9188,
      "grad_norm": 0.16351135075092316,
      "learning_rate": 6.938666666666666e-07,
      "logits/chosen": -2.1967110633850098,
      "logits/rejected": -2.6761302947998047,
      "logps/chosen": -142.65817260742188,
      "logps/rejected": -134.02896118164062,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2627357244491577,
      "rewards/margins": 6.613351345062256,
      "rewards/rejected": -5.350615501403809,
      "step": 2297
    },
    {
      "epoch": 0.9192,
      "grad_norm": 0.07136930525302887,
      "learning_rate": 6.937333333333333e-07,
      "logits/chosen": -2.600269317626953,
      "logits/rejected": -3.376828193664551,
      "logps/chosen": -137.0059814453125,
      "logps/rejected": -167.02903747558594,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.121894121170044,
      "rewards/margins": 8.154158592224121,
      "rewards/rejected": -6.032264709472656,
      "step": 2298
    },
    {
      "epoch": 0.9196,
      "grad_norm": 2.5778727531433105,
      "learning_rate": 6.935999999999999e-07,
      "logits/chosen": -1.8609142303466797,
      "logits/rejected": -3.02256441116333,
      "logps/chosen": -128.47500610351562,
      "logps/rejected": -187.54905700683594,
      "loss": 0.0225,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5363884568214417,
      "rewards/margins": 5.879053115844727,
      "rewards/rejected": -5.34266471862793,
      "step": 2299
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.031001882627606392,
      "learning_rate": 6.934666666666666e-07,
      "logits/chosen": -2.505375385284424,
      "logits/rejected": -3.2434380054473877,
      "logps/chosen": -103.66442108154297,
      "logps/rejected": -194.4322052001953,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0063374042510986,
      "rewards/margins": 9.015983581542969,
      "rewards/rejected": -7.009646415710449,
      "step": 2300
    },
    {
      "epoch": 0.9204,
      "grad_norm": 0.0014473228948190808,
      "learning_rate": 6.933333333333333e-07,
      "logits/chosen": -2.035615921020508,
      "logits/rejected": -3.4547085762023926,
      "logps/chosen": -95.10186004638672,
      "logps/rejected": -158.55059814453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.664370059967041,
      "rewards/margins": 11.305370330810547,
      "rewards/rejected": -6.640999794006348,
      "step": 2301
    },
    {
      "epoch": 0.9208,
      "grad_norm": 0.47052451968193054,
      "learning_rate": 6.932e-07,
      "logits/chosen": -2.6738967895507812,
      "logits/rejected": -3.587881565093994,
      "logps/chosen": -103.35576629638672,
      "logps/rejected": -134.3961639404297,
      "loss": 0.0052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.095393657684326,
      "rewards/margins": 6.5521240234375,
      "rewards/rejected": -4.456730365753174,
      "step": 2302
    },
    {
      "epoch": 0.9212,
      "grad_norm": 0.04174390435218811,
      "learning_rate": 6.930666666666667e-07,
      "logits/chosen": -2.337608814239502,
      "logits/rejected": -3.462286949157715,
      "logps/chosen": -121.81440734863281,
      "logps/rejected": -158.8795166015625,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6633849143981934,
      "rewards/margins": 9.541690826416016,
      "rewards/rejected": -6.878305912017822,
      "step": 2303
    },
    {
      "epoch": 0.9216,
      "grad_norm": 0.013595697470009327,
      "learning_rate": 6.929333333333333e-07,
      "logits/chosen": -2.1830544471740723,
      "logits/rejected": -3.2713208198547363,
      "logps/chosen": -118.1462173461914,
      "logps/rejected": -171.1597900390625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.6337389945983887,
      "rewards/margins": 8.932514190673828,
      "rewards/rejected": -5.298775672912598,
      "step": 2304
    },
    {
      "epoch": 0.922,
      "grad_norm": 0.11683931201696396,
      "learning_rate": 6.928e-07,
      "logits/chosen": -2.3887739181518555,
      "logits/rejected": -2.7242836952209473,
      "logps/chosen": -144.7977294921875,
      "logps/rejected": -208.79965209960938,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8456702828407288,
      "rewards/margins": 6.869497299194336,
      "rewards/rejected": -6.023827075958252,
      "step": 2305
    },
    {
      "epoch": 0.9224,
      "grad_norm": 0.006338325794786215,
      "learning_rate": 6.926666666666666e-07,
      "logits/chosen": -2.417886734008789,
      "logits/rejected": -3.3032450675964355,
      "logps/chosen": -101.67584228515625,
      "logps/rejected": -168.37088012695312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.176656723022461,
      "rewards/margins": 11.05659294128418,
      "rewards/rejected": -6.879936218261719,
      "step": 2306
    },
    {
      "epoch": 0.9228,
      "grad_norm": 0.007531343027949333,
      "learning_rate": 6.925333333333333e-07,
      "logits/chosen": -2.305847406387329,
      "logits/rejected": -3.260249376296997,
      "logps/chosen": -122.07398986816406,
      "logps/rejected": -217.65719604492188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7172558307647705,
      "rewards/margins": 10.36661148071289,
      "rewards/rejected": -7.649355411529541,
      "step": 2307
    },
    {
      "epoch": 0.9232,
      "grad_norm": 0.7950069904327393,
      "learning_rate": 6.924e-07,
      "logits/chosen": -2.2286057472229004,
      "logits/rejected": -3.197326183319092,
      "logps/chosen": -101.5661392211914,
      "logps/rejected": -146.220947265625,
      "loss": 0.0071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0434257984161377,
      "rewards/margins": 5.806056022644043,
      "rewards/rejected": -4.762630462646484,
      "step": 2308
    },
    {
      "epoch": 0.9236,
      "grad_norm": 0.07675673067569733,
      "learning_rate": 6.922666666666666e-07,
      "logits/chosen": -2.4441936016082764,
      "logits/rejected": -3.7652029991149902,
      "logps/chosen": -114.34844207763672,
      "logps/rejected": -180.18182373046875,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4110866785049438,
      "rewards/margins": 9.017730712890625,
      "rewards/rejected": -7.6066436767578125,
      "step": 2309
    },
    {
      "epoch": 0.924,
      "grad_norm": 2.507341146469116,
      "learning_rate": 6.921333333333333e-07,
      "logits/chosen": -2.4875454902648926,
      "logits/rejected": -3.334641933441162,
      "logps/chosen": -133.78915405273438,
      "logps/rejected": -180.02371215820312,
      "loss": 0.0139,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2226043939590454,
      "rewards/margins": 6.166192054748535,
      "rewards/rejected": -5.9435882568359375,
      "step": 2310
    },
    {
      "epoch": 0.9244,
      "grad_norm": 0.030444849282503128,
      "learning_rate": 6.919999999999999e-07,
      "logits/chosen": -2.0908188819885254,
      "logits/rejected": -3.2889037132263184,
      "logps/chosen": -84.67357635498047,
      "logps/rejected": -161.56732177734375,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.168938636779785,
      "rewards/margins": 8.874551773071289,
      "rewards/rejected": -5.705613613128662,
      "step": 2311
    },
    {
      "epoch": 0.9248,
      "grad_norm": 0.0880507379770279,
      "learning_rate": 6.918666666666666e-07,
      "logits/chosen": -2.320577621459961,
      "logits/rejected": -2.9622232913970947,
      "logps/chosen": -163.1790313720703,
      "logps/rejected": -151.80372619628906,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4968388080596924,
      "rewards/margins": 7.814304351806641,
      "rewards/rejected": -5.317465782165527,
      "step": 2312
    },
    {
      "epoch": 0.9252,
      "grad_norm": 0.020232433453202248,
      "learning_rate": 6.917333333333333e-07,
      "logits/chosen": -1.9142910242080688,
      "logits/rejected": -3.648036479949951,
      "logps/chosen": -156.7085723876953,
      "logps/rejected": -201.4310302734375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.930645704269409,
      "rewards/margins": 9.011509895324707,
      "rewards/rejected": -6.080863952636719,
      "step": 2313
    },
    {
      "epoch": 0.9256,
      "grad_norm": 14.392733573913574,
      "learning_rate": 6.916e-07,
      "logits/chosen": -2.5763497352600098,
      "logits/rejected": -2.9951353073120117,
      "logps/chosen": -131.7490997314453,
      "logps/rejected": -131.40560913085938,
      "loss": 0.0675,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.11044919490814209,
      "rewards/margins": 5.436036109924316,
      "rewards/rejected": -5.54648494720459,
      "step": 2314
    },
    {
      "epoch": 0.926,
      "grad_norm": 1.2195943593978882,
      "learning_rate": 6.914666666666667e-07,
      "logits/chosen": -1.9067944288253784,
      "logits/rejected": -2.8031699657440186,
      "logps/chosen": -102.68460845947266,
      "logps/rejected": -105.5086669921875,
      "loss": 0.0159,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9424377679824829,
      "rewards/margins": 4.223090171813965,
      "rewards/rejected": -3.2806522846221924,
      "step": 2315
    },
    {
      "epoch": 0.9264,
      "grad_norm": 0.029975375160574913,
      "learning_rate": 6.913333333333334e-07,
      "logits/chosen": -1.8231675624847412,
      "logits/rejected": -3.084230661392212,
      "logps/chosen": -94.95008850097656,
      "logps/rejected": -142.99887084960938,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.767150402069092,
      "rewards/margins": 8.200166702270508,
      "rewards/rejected": -5.433016300201416,
      "step": 2316
    },
    {
      "epoch": 0.9268,
      "grad_norm": 0.012602078728377819,
      "learning_rate": 6.912e-07,
      "logits/chosen": -2.151176929473877,
      "logits/rejected": -3.4629769325256348,
      "logps/chosen": -148.17572021484375,
      "logps/rejected": -177.16510009765625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.407214164733887,
      "rewards/margins": 9.424653053283691,
      "rewards/rejected": -5.017438888549805,
      "step": 2317
    },
    {
      "epoch": 0.9272,
      "grad_norm": 0.3464704751968384,
      "learning_rate": 6.910666666666666e-07,
      "logits/chosen": -2.5247440338134766,
      "logits/rejected": -3.5114173889160156,
      "logps/chosen": -101.79986572265625,
      "logps/rejected": -172.12982177734375,
      "loss": 0.0025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6895653009414673,
      "rewards/margins": 6.358715057373047,
      "rewards/rejected": -4.669149875640869,
      "step": 2318
    },
    {
      "epoch": 0.9276,
      "grad_norm": 0.45342200994491577,
      "learning_rate": 6.909333333333332e-07,
      "logits/chosen": -1.9633243083953857,
      "logits/rejected": -3.8004794120788574,
      "logps/chosen": -91.49031066894531,
      "logps/rejected": -168.9766845703125,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7485436201095581,
      "rewards/margins": 6.814903736114502,
      "rewards/rejected": -6.0663604736328125,
      "step": 2319
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.557835042476654,
      "learning_rate": 6.907999999999999e-07,
      "logits/chosen": -2.9199154376983643,
      "logits/rejected": -3.1851704120635986,
      "logps/chosen": -130.52108764648438,
      "logps/rejected": -160.27500915527344,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0601773262023926,
      "rewards/margins": 7.526828765869141,
      "rewards/rejected": -5.466651439666748,
      "step": 2320
    },
    {
      "epoch": 0.9284,
      "grad_norm": 0.09076947718858719,
      "learning_rate": 6.906666666666666e-07,
      "logits/chosen": -2.107971668243408,
      "logits/rejected": -3.108401298522949,
      "logps/chosen": -126.09393310546875,
      "logps/rejected": -155.60821533203125,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.434908628463745,
      "rewards/margins": 8.561800003051758,
      "rewards/rejected": -5.12689208984375,
      "step": 2321
    },
    {
      "epoch": 0.9288,
      "grad_norm": 0.006380920298397541,
      "learning_rate": 6.905333333333333e-07,
      "logits/chosen": -2.2272965908050537,
      "logits/rejected": -3.648346424102783,
      "logps/chosen": -124.84109497070312,
      "logps/rejected": -165.07752990722656,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7727789878845215,
      "rewards/margins": 9.970209121704102,
      "rewards/rejected": -6.197430610656738,
      "step": 2322
    },
    {
      "epoch": 0.9292,
      "grad_norm": 0.10817437618970871,
      "learning_rate": 6.904e-07,
      "logits/chosen": -2.559077739715576,
      "logits/rejected": -3.357832431793213,
      "logps/chosen": -104.03715515136719,
      "logps/rejected": -177.70242309570312,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.447942018508911,
      "rewards/margins": 7.671427249908447,
      "rewards/rejected": -5.223484992980957,
      "step": 2323
    },
    {
      "epoch": 0.9296,
      "grad_norm": 0.04013579338788986,
      "learning_rate": 6.902666666666667e-07,
      "logits/chosen": -2.126467704772949,
      "logits/rejected": -3.0930044651031494,
      "logps/chosen": -156.58602905273438,
      "logps/rejected": -156.07440185546875,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5559067726135254,
      "rewards/margins": 8.123835563659668,
      "rewards/rejected": -4.567928791046143,
      "step": 2324
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.03145534172654152,
      "learning_rate": 6.901333333333334e-07,
      "logits/chosen": -1.8671050071716309,
      "logits/rejected": -2.8566689491271973,
      "logps/chosen": -65.15709686279297,
      "logps/rejected": -117.64500427246094,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.832273244857788,
      "rewards/margins": 8.130270004272461,
      "rewards/rejected": -4.297996997833252,
      "step": 2325
    },
    {
      "epoch": 0.9304,
      "grad_norm": 0.0794462040066719,
      "learning_rate": 6.9e-07,
      "logits/chosen": -2.3958780765533447,
      "logits/rejected": -3.093543767929077,
      "logps/chosen": -131.71493530273438,
      "logps/rejected": -164.57363891601562,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7613646984100342,
      "rewards/margins": 7.624098777770996,
      "rewards/rejected": -5.862733840942383,
      "step": 2326
    },
    {
      "epoch": 0.9308,
      "grad_norm": 0.6510060429573059,
      "learning_rate": 6.898666666666665e-07,
      "logits/chosen": -2.8015997409820557,
      "logits/rejected": -3.449260711669922,
      "logps/chosen": -194.26199340820312,
      "logps/rejected": -169.5972900390625,
      "loss": 0.005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.096734046936035,
      "rewards/margins": 8.620798110961914,
      "rewards/rejected": -6.524064064025879,
      "step": 2327
    },
    {
      "epoch": 0.9312,
      "grad_norm": 1.5900206565856934,
      "learning_rate": 6.897333333333332e-07,
      "logits/chosen": -1.9560946226119995,
      "logits/rejected": -2.893655776977539,
      "logps/chosen": -155.3261260986328,
      "logps/rejected": -129.65518188476562,
      "loss": 0.0165,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6504795551300049,
      "rewards/margins": 4.099851608276367,
      "rewards/rejected": -4.750331401824951,
      "step": 2328
    },
    {
      "epoch": 0.9316,
      "grad_norm": 0.16174431145191193,
      "learning_rate": 6.895999999999999e-07,
      "logits/chosen": -2.300410747528076,
      "logits/rejected": -3.4887402057647705,
      "logps/chosen": -95.02472686767578,
      "logps/rejected": -165.82562255859375,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3774051666259766,
      "rewards/margins": 7.513991832733154,
      "rewards/rejected": -6.1365861892700195,
      "step": 2329
    },
    {
      "epoch": 0.932,
      "grad_norm": 0.44532138109207153,
      "learning_rate": 6.894666666666666e-07,
      "logits/chosen": -2.0627427101135254,
      "logits/rejected": -2.352548599243164,
      "logps/chosen": -122.60400390625,
      "logps/rejected": -124.80377197265625,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.79771888256073,
      "rewards/margins": 6.439420700073242,
      "rewards/rejected": -4.641701698303223,
      "step": 2330
    },
    {
      "epoch": 0.9324,
      "grad_norm": 0.08238810300827026,
      "learning_rate": 6.893333333333333e-07,
      "logits/chosen": -2.502985954284668,
      "logits/rejected": -2.21254301071167,
      "logps/chosen": -165.68788146972656,
      "logps/rejected": -166.74310302734375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4676568508148193,
      "rewards/margins": 7.801943778991699,
      "rewards/rejected": -4.334287166595459,
      "step": 2331
    },
    {
      "epoch": 0.9328,
      "grad_norm": 0.061402685940265656,
      "learning_rate": 6.892e-07,
      "logits/chosen": -1.8891187906265259,
      "logits/rejected": -3.2932119369506836,
      "logps/chosen": -113.83837127685547,
      "logps/rejected": -179.38555908203125,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6875176429748535,
      "rewards/margins": 9.640132904052734,
      "rewards/rejected": -6.952615737915039,
      "step": 2332
    },
    {
      "epoch": 0.9332,
      "grad_norm": 0.03740813583135605,
      "learning_rate": 6.890666666666667e-07,
      "logits/chosen": -2.5883264541625977,
      "logits/rejected": -2.753114700317383,
      "logps/chosen": -100.72296142578125,
      "logps/rejected": -130.78302001953125,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4381661415100098,
      "rewards/margins": 8.317380905151367,
      "rewards/rejected": -4.879215240478516,
      "step": 2333
    },
    {
      "epoch": 0.9336,
      "grad_norm": 0.2560746967792511,
      "learning_rate": 6.889333333333333e-07,
      "logits/chosen": -2.5867767333984375,
      "logits/rejected": -3.12045955657959,
      "logps/chosen": -95.59757232666016,
      "logps/rejected": -149.844970703125,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3800830841064453,
      "rewards/margins": 7.48206901550293,
      "rewards/rejected": -4.101985931396484,
      "step": 2334
    },
    {
      "epoch": 0.934,
      "grad_norm": 0.9645795822143555,
      "learning_rate": 6.888e-07,
      "logits/chosen": -2.6125876903533936,
      "logits/rejected": -3.586171865463257,
      "logps/chosen": -171.4463653564453,
      "logps/rejected": -243.45025634765625,
      "loss": 0.0058,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4731700420379639,
      "rewards/margins": 6.947223663330078,
      "rewards/rejected": -5.474053382873535,
      "step": 2335
    },
    {
      "epoch": 0.9344,
      "grad_norm": 0.20238812267780304,
      "learning_rate": 6.886666666666667e-07,
      "logits/chosen": -2.342562675476074,
      "logits/rejected": -3.5338268280029297,
      "logps/chosen": -145.220947265625,
      "logps/rejected": -202.37905883789062,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7872719764709473,
      "rewards/margins": 8.900422096252441,
      "rewards/rejected": -6.113150119781494,
      "step": 2336
    },
    {
      "epoch": 0.9348,
      "grad_norm": 0.0013791908277198672,
      "learning_rate": 6.885333333333333e-07,
      "logits/chosen": -2.7063546180725098,
      "logits/rejected": -3.758030652999878,
      "logps/chosen": -141.52000427246094,
      "logps/rejected": -192.92706298828125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.580500602722168,
      "rewards/margins": 11.424243927001953,
      "rewards/rejected": -6.843743324279785,
      "step": 2337
    },
    {
      "epoch": 0.9352,
      "grad_norm": 0.06289148330688477,
      "learning_rate": 6.883999999999999e-07,
      "logits/chosen": -2.084789276123047,
      "logits/rejected": -2.637204170227051,
      "logps/chosen": -114.32169342041016,
      "logps/rejected": -159.88796997070312,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8933801651000977,
      "rewards/margins": 7.701873779296875,
      "rewards/rejected": -4.808493614196777,
      "step": 2338
    },
    {
      "epoch": 0.9356,
      "grad_norm": 0.043977804481983185,
      "learning_rate": 6.882666666666666e-07,
      "logits/chosen": -2.02846622467041,
      "logits/rejected": -3.2720346450805664,
      "logps/chosen": -89.7076416015625,
      "logps/rejected": -139.0648956298828,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.416797161102295,
      "rewards/margins": 7.826755523681641,
      "rewards/rejected": -4.409958362579346,
      "step": 2339
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.33206507563591003,
      "learning_rate": 6.881333333333333e-07,
      "logits/chosen": -1.8473154306411743,
      "logits/rejected": -3.4173364639282227,
      "logps/chosen": -80.79753875732422,
      "logps/rejected": -131.95697021484375,
      "loss": 0.0033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7226921319961548,
      "rewards/margins": 6.229052543640137,
      "rewards/rejected": -5.50636100769043,
      "step": 2340
    },
    {
      "epoch": 0.9364,
      "grad_norm": 0.017003614455461502,
      "learning_rate": 6.879999999999999e-07,
      "logits/chosen": -2.279386043548584,
      "logits/rejected": -3.602266311645508,
      "logps/chosen": -90.35721588134766,
      "logps/rejected": -171.20315551757812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0086960792541504,
      "rewards/margins": 9.024375915527344,
      "rewards/rejected": -7.015680313110352,
      "step": 2341
    },
    {
      "epoch": 0.9368,
      "grad_norm": 0.08119688183069229,
      "learning_rate": 6.878666666666666e-07,
      "logits/chosen": -2.1722419261932373,
      "logits/rejected": -3.4479880332946777,
      "logps/chosen": -97.3031234741211,
      "logps/rejected": -154.88433837890625,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2384865283966064,
      "rewards/margins": 8.243900299072266,
      "rewards/rejected": -6.00541353225708,
      "step": 2342
    },
    {
      "epoch": 0.9372,
      "grad_norm": 0.9101852774620056,
      "learning_rate": 6.877333333333333e-07,
      "logits/chosen": -2.587246894836426,
      "logits/rejected": -3.0704867839813232,
      "logps/chosen": -111.53965759277344,
      "logps/rejected": -148.05023193359375,
      "loss": 0.0083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1431735754013062,
      "rewards/margins": 6.070799350738525,
      "rewards/rejected": -4.92762565612793,
      "step": 2343
    },
    {
      "epoch": 0.9376,
      "grad_norm": 1.0143425464630127,
      "learning_rate": 6.876e-07,
      "logits/chosen": -2.036600351333618,
      "logits/rejected": -2.903677463531494,
      "logps/chosen": -137.18804931640625,
      "logps/rejected": -124.58042907714844,
      "loss": 0.0073,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.300568699836731,
      "rewards/margins": 5.412353515625,
      "rewards/rejected": -4.111784934997559,
      "step": 2344
    },
    {
      "epoch": 0.938,
      "grad_norm": 3.171389579772949,
      "learning_rate": 6.874666666666667e-07,
      "logits/chosen": -2.4799556732177734,
      "logits/rejected": -3.230797290802002,
      "logps/chosen": -113.49293518066406,
      "logps/rejected": -146.6014404296875,
      "loss": 0.0291,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6882331967353821,
      "rewards/margins": 4.494842529296875,
      "rewards/rejected": -5.183075428009033,
      "step": 2345
    },
    {
      "epoch": 0.9384,
      "grad_norm": 0.033152271062135696,
      "learning_rate": 6.873333333333334e-07,
      "logits/chosen": -2.079733371734619,
      "logits/rejected": -3.146315574645996,
      "logps/chosen": -126.7078628540039,
      "logps/rejected": -142.9080047607422,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.869401454925537,
      "rewards/margins": 9.265551567077637,
      "rewards/rejected": -5.396149635314941,
      "step": 2346
    },
    {
      "epoch": 0.9388,
      "grad_norm": 0.046470124274492264,
      "learning_rate": 6.872e-07,
      "logits/chosen": -2.180612564086914,
      "logits/rejected": -3.079639434814453,
      "logps/chosen": -131.7039031982422,
      "logps/rejected": -154.83407592773438,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0504631996154785,
      "rewards/margins": 8.914320945739746,
      "rewards/rejected": -5.863858222961426,
      "step": 2347
    },
    {
      "epoch": 0.9392,
      "grad_norm": 8.957571983337402,
      "learning_rate": 6.870666666666667e-07,
      "logits/chosen": -2.548027992248535,
      "logits/rejected": -3.491511821746826,
      "logps/chosen": -143.29721069335938,
      "logps/rejected": -150.33517456054688,
      "loss": 0.0888,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45873117446899414,
      "rewards/margins": 5.106339931488037,
      "rewards/rejected": -4.647608757019043,
      "step": 2348
    },
    {
      "epoch": 0.9396,
      "grad_norm": 7.808318138122559,
      "learning_rate": 6.869333333333332e-07,
      "logits/chosen": -2.195375680923462,
      "logits/rejected": -3.563765287399292,
      "logps/chosen": -78.94401550292969,
      "logps/rejected": -150.17835998535156,
      "loss": 0.0536,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.415515184402466,
      "rewards/margins": 5.520030498504639,
      "rewards/rejected": -3.1045150756835938,
      "step": 2349
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.19233183562755585,
      "learning_rate": 6.867999999999999e-07,
      "logits/chosen": -2.235171318054199,
      "logits/rejected": -2.6170294284820557,
      "logps/chosen": -110.6065673828125,
      "logps/rejected": -118.90567016601562,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.312540054321289,
      "rewards/margins": 6.571955680847168,
      "rewards/rejected": -4.259415626525879,
      "step": 2350
    },
    {
      "epoch": 0.9404,
      "grad_norm": 0.04069026559591293,
      "learning_rate": 6.866666666666666e-07,
      "logits/chosen": -2.5842628479003906,
      "logits/rejected": -2.770010471343994,
      "logps/chosen": -169.1854705810547,
      "logps/rejected": -170.7059326171875,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2248053550720215,
      "rewards/margins": 9.559368133544922,
      "rewards/rejected": -6.334562301635742,
      "step": 2351
    },
    {
      "epoch": 0.9408,
      "grad_norm": 0.19483527541160583,
      "learning_rate": 6.865333333333333e-07,
      "logits/chosen": -2.097109794616699,
      "logits/rejected": -2.816396713256836,
      "logps/chosen": -162.65870666503906,
      "logps/rejected": -159.79891967773438,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8350800275802612,
      "rewards/margins": 6.811674118041992,
      "rewards/rejected": -4.9765944480896,
      "step": 2352
    },
    {
      "epoch": 0.9412,
      "grad_norm": 0.1771705001592636,
      "learning_rate": 6.864e-07,
      "logits/chosen": -1.939808964729309,
      "logits/rejected": -3.152313709259033,
      "logps/chosen": -109.30769348144531,
      "logps/rejected": -133.29388427734375,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0069730281829834,
      "rewards/margins": 6.405821800231934,
      "rewards/rejected": -4.398848533630371,
      "step": 2353
    },
    {
      "epoch": 0.9416,
      "grad_norm": 0.15299762785434723,
      "learning_rate": 6.862666666666667e-07,
      "logits/chosen": -2.074032783508301,
      "logits/rejected": -3.1597065925598145,
      "logps/chosen": -124.06034088134766,
      "logps/rejected": -138.90057373046875,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6245132684707642,
      "rewards/margins": 6.4480438232421875,
      "rewards/rejected": -4.823530673980713,
      "step": 2354
    },
    {
      "epoch": 0.942,
      "grad_norm": 0.035577163100242615,
      "learning_rate": 6.861333333333334e-07,
      "logits/chosen": -2.5554046630859375,
      "logits/rejected": -3.1793670654296875,
      "logps/chosen": -134.0134735107422,
      "logps/rejected": -174.47320556640625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.177994728088379,
      "rewards/margins": 9.043497085571289,
      "rewards/rejected": -5.865503311157227,
      "step": 2355
    },
    {
      "epoch": 0.9424,
      "grad_norm": 0.15951311588287354,
      "learning_rate": 6.86e-07,
      "logits/chosen": -2.361672878265381,
      "logits/rejected": -3.65484356880188,
      "logps/chosen": -144.225341796875,
      "logps/rejected": -192.20790100097656,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.260531187057495,
      "rewards/margins": 9.657371520996094,
      "rewards/rejected": -7.3968400955200195,
      "step": 2356
    },
    {
      "epoch": 0.9428,
      "grad_norm": 0.007511944510042667,
      "learning_rate": 6.858666666666666e-07,
      "logits/chosen": -2.210582733154297,
      "logits/rejected": -3.613276958465576,
      "logps/chosen": -82.11541748046875,
      "logps/rejected": -210.12850952148438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4680538177490234,
      "rewards/margins": 10.319768905639648,
      "rewards/rejected": -8.851715087890625,
      "step": 2357
    },
    {
      "epoch": 0.9432,
      "grad_norm": 0.010575730353593826,
      "learning_rate": 6.857333333333333e-07,
      "logits/chosen": -2.5335617065429688,
      "logits/rejected": -3.353107452392578,
      "logps/chosen": -126.00227355957031,
      "logps/rejected": -161.96566772460938,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6431896686553955,
      "rewards/margins": 9.469820022583008,
      "rewards/rejected": -6.826631546020508,
      "step": 2358
    },
    {
      "epoch": 0.9436,
      "grad_norm": 19.98630714416504,
      "learning_rate": 6.855999999999999e-07,
      "logits/chosen": -2.8150534629821777,
      "logits/rejected": -2.930004596710205,
      "logps/chosen": -108.69915771484375,
      "logps/rejected": -137.96786499023438,
      "loss": 0.2202,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.475785732269287,
      "rewards/margins": 2.4333393573760986,
      "rewards/rejected": -4.909125328063965,
      "step": 2359
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.0029627182520926,
      "learning_rate": 6.854666666666666e-07,
      "logits/chosen": -2.202335834503174,
      "logits/rejected": -3.6812520027160645,
      "logps/chosen": -152.2083740234375,
      "logps/rejected": -196.71885681152344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4629411697387695,
      "rewards/margins": 11.210506439208984,
      "rewards/rejected": -8.747565269470215,
      "step": 2360
    },
    {
      "epoch": 0.9444,
      "grad_norm": 0.02519574761390686,
      "learning_rate": 6.853333333333333e-07,
      "logits/chosen": -2.1995930671691895,
      "logits/rejected": -3.6310644149780273,
      "logps/chosen": -115.65585327148438,
      "logps/rejected": -210.57720947265625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0433878898620605,
      "rewards/margins": 8.489176750183105,
      "rewards/rejected": -6.445789337158203,
      "step": 2361
    },
    {
      "epoch": 0.9448,
      "grad_norm": 1.098015546798706,
      "learning_rate": 6.852e-07,
      "logits/chosen": -1.875558614730835,
      "logits/rejected": -2.23348331451416,
      "logps/chosen": -144.40480041503906,
      "logps/rejected": -128.5417022705078,
      "loss": 0.0131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0435622930526733,
      "rewards/margins": 4.358609199523926,
      "rewards/rejected": -3.315046787261963,
      "step": 2362
    },
    {
      "epoch": 0.9452,
      "grad_norm": 0.23357899487018585,
      "learning_rate": 6.850666666666667e-07,
      "logits/chosen": -2.267510175704956,
      "logits/rejected": -3.0514919757843018,
      "logps/chosen": -96.88504028320312,
      "logps/rejected": -163.59828186035156,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.854513168334961,
      "rewards/margins": 8.018004417419434,
      "rewards/rejected": -6.1634907722473145,
      "step": 2363
    },
    {
      "epoch": 0.9456,
      "grad_norm": 0.1735767275094986,
      "learning_rate": 6.849333333333333e-07,
      "logits/chosen": -2.3136796951293945,
      "logits/rejected": -3.1024599075317383,
      "logps/chosen": -131.0944061279297,
      "logps/rejected": -162.66038513183594,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7848800420761108,
      "rewards/margins": 6.445798873901367,
      "rewards/rejected": -5.660918712615967,
      "step": 2364
    },
    {
      "epoch": 0.946,
      "grad_norm": 1.0139353275299072,
      "learning_rate": 6.847999999999999e-07,
      "logits/chosen": -2.513301372528076,
      "logits/rejected": -2.715419292449951,
      "logps/chosen": -123.12724304199219,
      "logps/rejected": -153.61373901367188,
      "loss": 0.0057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.869200587272644,
      "rewards/margins": 6.33753776550293,
      "rewards/rejected": -5.468337059020996,
      "step": 2365
    },
    {
      "epoch": 0.9464,
      "grad_norm": 0.019837776198983192,
      "learning_rate": 6.846666666666666e-07,
      "logits/chosen": -2.5408785343170166,
      "logits/rejected": -3.201681613922119,
      "logps/chosen": -99.5565185546875,
      "logps/rejected": -156.32713317871094,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.161076068878174,
      "rewards/margins": 8.911578178405762,
      "rewards/rejected": -6.750502109527588,
      "step": 2366
    },
    {
      "epoch": 0.9468,
      "grad_norm": 0.02465761825442314,
      "learning_rate": 6.845333333333333e-07,
      "logits/chosen": -1.998279333114624,
      "logits/rejected": -2.922306537628174,
      "logps/chosen": -120.35610961914062,
      "logps/rejected": -154.03428649902344,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.021275758743286,
      "rewards/margins": 8.160140037536621,
      "rewards/rejected": -6.138864517211914,
      "step": 2367
    },
    {
      "epoch": 0.9472,
      "grad_norm": 0.06924372911453247,
      "learning_rate": 6.844e-07,
      "logits/chosen": -2.438579797744751,
      "logits/rejected": -2.6654653549194336,
      "logps/chosen": -196.30050659179688,
      "logps/rejected": -145.34927368164062,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.8549256324768066,
      "rewards/margins": 8.211076736450195,
      "rewards/rejected": -5.3561506271362305,
      "step": 2368
    },
    {
      "epoch": 0.9476,
      "grad_norm": 0.11914224922657013,
      "learning_rate": 6.842666666666667e-07,
      "logits/chosen": -2.4805498123168945,
      "logits/rejected": -3.1034388542175293,
      "logps/chosen": -128.39932250976562,
      "logps/rejected": -144.75177001953125,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.85933780670166,
      "rewards/margins": 8.339343070983887,
      "rewards/rejected": -4.480005264282227,
      "step": 2369
    },
    {
      "epoch": 0.948,
      "grad_norm": 0.02021213434636593,
      "learning_rate": 6.841333333333333e-07,
      "logits/chosen": -2.260666608810425,
      "logits/rejected": -3.0243825912475586,
      "logps/chosen": -125.90555572509766,
      "logps/rejected": -160.89154052734375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7209529876708984,
      "rewards/margins": 8.891847610473633,
      "rewards/rejected": -6.170893669128418,
      "step": 2370
    },
    {
      "epoch": 0.9484,
      "grad_norm": 0.18553976714611053,
      "learning_rate": 6.84e-07,
      "logits/chosen": -2.880430221557617,
      "logits/rejected": -2.612074851989746,
      "logps/chosen": -245.78750610351562,
      "logps/rejected": -221.42063903808594,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0511226654052734,
      "rewards/margins": 7.863497734069824,
      "rewards/rejected": -5.812374591827393,
      "step": 2371
    },
    {
      "epoch": 0.9488,
      "grad_norm": 0.15355518460273743,
      "learning_rate": 6.838666666666666e-07,
      "logits/chosen": -2.1071937084198,
      "logits/rejected": -3.0641379356384277,
      "logps/chosen": -107.34307861328125,
      "logps/rejected": -156.017333984375,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.40277212858200073,
      "rewards/margins": 6.871951103210449,
      "rewards/rejected": -6.469178676605225,
      "step": 2372
    },
    {
      "epoch": 0.9492,
      "grad_norm": 0.10509104281663895,
      "learning_rate": 6.837333333333333e-07,
      "logits/chosen": -2.8577322959899902,
      "logits/rejected": -3.5438637733459473,
      "logps/chosen": -145.63291931152344,
      "logps/rejected": -155.3596649169922,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8230533599853516,
      "rewards/margins": 8.18593978881836,
      "rewards/rejected": -6.362886905670166,
      "step": 2373
    },
    {
      "epoch": 0.9496,
      "grad_norm": 0.19872362911701202,
      "learning_rate": 6.836e-07,
      "logits/chosen": -2.1171274185180664,
      "logits/rejected": -3.3746156692504883,
      "logps/chosen": -125.44230651855469,
      "logps/rejected": -157.0665740966797,
      "loss": 0.0018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6251914501190186,
      "rewards/margins": 7.886957168579102,
      "rewards/rejected": -6.261765480041504,
      "step": 2374
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.09563640505075455,
      "learning_rate": 6.834666666666666e-07,
      "logits/chosen": -2.072849988937378,
      "logits/rejected": -3.2585129737854004,
      "logps/chosen": -179.71127319335938,
      "logps/rejected": -169.39523315429688,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4764785766601562,
      "rewards/margins": 8.217270851135254,
      "rewards/rejected": -6.740792274475098,
      "step": 2375
    },
    {
      "epoch": 0.9504,
      "grad_norm": 0.0015409720363095403,
      "learning_rate": 6.833333333333333e-07,
      "logits/chosen": -2.3592498302459717,
      "logits/rejected": -3.518491268157959,
      "logps/chosen": -138.4422607421875,
      "logps/rejected": -186.11257934570312,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.7665581703186035,
      "rewards/margins": 11.217266082763672,
      "rewards/rejected": -7.450708389282227,
      "step": 2376
    },
    {
      "epoch": 0.9508,
      "grad_norm": 0.04930652305483818,
      "learning_rate": 6.832e-07,
      "logits/chosen": -2.0991411209106445,
      "logits/rejected": -3.533987522125244,
      "logps/chosen": -211.07907104492188,
      "logps/rejected": -177.25833129882812,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.219137191772461,
      "rewards/margins": 8.658562660217285,
      "rewards/rejected": -6.439425468444824,
      "step": 2377
    },
    {
      "epoch": 0.9512,
      "grad_norm": 0.5654629468917847,
      "learning_rate": 6.830666666666667e-07,
      "logits/chosen": -2.746030807495117,
      "logits/rejected": -2.6092898845672607,
      "logps/chosen": -193.22279357910156,
      "logps/rejected": -130.5411376953125,
      "loss": 0.0049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3356895446777344,
      "rewards/margins": 5.50202751159668,
      "rewards/rejected": -5.166337966918945,
      "step": 2378
    },
    {
      "epoch": 0.9516,
      "grad_norm": 0.008607601746916771,
      "learning_rate": 6.829333333333333e-07,
      "logits/chosen": -1.9973487854003906,
      "logits/rejected": -3.245723247528076,
      "logps/chosen": -73.71379089355469,
      "logps/rejected": -150.33963012695312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2959647178649902,
      "rewards/margins": 9.625495910644531,
      "rewards/rejected": -6.329531669616699,
      "step": 2379
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.05220884084701538,
      "learning_rate": 6.827999999999999e-07,
      "logits/chosen": -2.4037020206451416,
      "logits/rejected": -3.7475709915161133,
      "logps/chosen": -246.03639221191406,
      "logps/rejected": -179.23580932617188,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8869843482971191,
      "rewards/margins": 8.80750846862793,
      "rewards/rejected": -6.920523643493652,
      "step": 2380
    },
    {
      "epoch": 0.9524,
      "grad_norm": 9.048072814941406,
      "learning_rate": 6.826666666666666e-07,
      "logits/chosen": -2.416616439819336,
      "logits/rejected": -2.7551045417785645,
      "logps/chosen": -139.16860961914062,
      "logps/rejected": -120.35067749023438,
      "loss": 0.0674,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5280147790908813,
      "rewards/margins": 4.029959678649902,
      "rewards/rejected": -4.557974338531494,
      "step": 2381
    },
    {
      "epoch": 0.9528,
      "grad_norm": 0.03207378834486008,
      "learning_rate": 6.825333333333333e-07,
      "logits/chosen": -2.1108603477478027,
      "logits/rejected": -3.867550849914551,
      "logps/chosen": -59.48456954956055,
      "logps/rejected": -136.9472198486328,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.628925323486328,
      "rewards/margins": 8.878801345825195,
      "rewards/rejected": -5.249876499176025,
      "step": 2382
    },
    {
      "epoch": 0.9532,
      "grad_norm": 0.002412574365735054,
      "learning_rate": 6.824e-07,
      "logits/chosen": -2.2882559299468994,
      "logits/rejected": -3.6584224700927734,
      "logps/chosen": -93.93669128417969,
      "logps/rejected": -177.34542846679688,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.140403747558594,
      "rewards/margins": 10.800971984863281,
      "rewards/rejected": -6.6605682373046875,
      "step": 2383
    },
    {
      "epoch": 0.9536,
      "grad_norm": 0.5248910188674927,
      "learning_rate": 6.822666666666666e-07,
      "logits/chosen": -2.4740147590637207,
      "logits/rejected": -2.6955208778381348,
      "logps/chosen": -95.36566925048828,
      "logps/rejected": -114.77182006835938,
      "loss": 0.0087,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5568401217460632,
      "rewards/margins": 4.755710601806641,
      "rewards/rejected": -4.198870658874512,
      "step": 2384
    },
    {
      "epoch": 0.954,
      "grad_norm": 0.16829052567481995,
      "learning_rate": 6.821333333333333e-07,
      "logits/chosen": -2.367523670196533,
      "logits/rejected": -3.1093859672546387,
      "logps/chosen": -236.87734985351562,
      "logps/rejected": -230.90740966796875,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7523231506347656,
      "rewards/margins": 7.417737007141113,
      "rewards/rejected": -5.665413856506348,
      "step": 2385
    },
    {
      "epoch": 0.9544,
      "grad_norm": 0.04821609705686569,
      "learning_rate": 6.82e-07,
      "logits/chosen": -2.448925256729126,
      "logits/rejected": -2.7143850326538086,
      "logps/chosen": -132.51422119140625,
      "logps/rejected": -178.41348266601562,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0814177989959717,
      "rewards/margins": 8.454549789428711,
      "rewards/rejected": -5.37313175201416,
      "step": 2386
    },
    {
      "epoch": 0.9548,
      "grad_norm": 0.004181843716651201,
      "learning_rate": 6.818666666666666e-07,
      "logits/chosen": -2.037330389022827,
      "logits/rejected": -3.373396873474121,
      "logps/chosen": -123.69422912597656,
      "logps/rejected": -221.9896240234375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.161953449249268,
      "rewards/margins": 10.742738723754883,
      "rewards/rejected": -6.580784797668457,
      "step": 2387
    },
    {
      "epoch": 0.9552,
      "grad_norm": 0.1374317705631256,
      "learning_rate": 6.817333333333333e-07,
      "logits/chosen": -2.2086031436920166,
      "logits/rejected": -3.1917061805725098,
      "logps/chosen": -145.75926208496094,
      "logps/rejected": -153.2559814453125,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.428678274154663,
      "rewards/margins": 9.98824691772461,
      "rewards/rejected": -6.559568405151367,
      "step": 2388
    },
    {
      "epoch": 0.9556,
      "grad_norm": 0.06727414578199387,
      "learning_rate": 6.816e-07,
      "logits/chosen": -2.199796199798584,
      "logits/rejected": -3.161555528640747,
      "logps/chosen": -236.59109497070312,
      "logps/rejected": -207.1151885986328,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34424513578414917,
      "rewards/margins": 8.186874389648438,
      "rewards/rejected": -7.8426289558410645,
      "step": 2389
    },
    {
      "epoch": 0.956,
      "grad_norm": 0.06910187751054764,
      "learning_rate": 6.814666666666667e-07,
      "logits/chosen": -2.534770965576172,
      "logits/rejected": -2.9603753089904785,
      "logps/chosen": -156.124755859375,
      "logps/rejected": -214.86798095703125,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.260355830192566,
      "rewards/margins": 7.513261795043945,
      "rewards/rejected": -6.25290584564209,
      "step": 2390
    },
    {
      "epoch": 0.9564,
      "grad_norm": 0.15776102244853973,
      "learning_rate": 6.813333333333333e-07,
      "logits/chosen": -1.944101095199585,
      "logits/rejected": -3.5758209228515625,
      "logps/chosen": -94.8717269897461,
      "logps/rejected": -188.60227966308594,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.657349705696106,
      "rewards/margins": 8.672926902770996,
      "rewards/rejected": -7.01557731628418,
      "step": 2391
    },
    {
      "epoch": 0.9568,
      "grad_norm": 0.24350453913211823,
      "learning_rate": 6.812e-07,
      "logits/chosen": -3.1601157188415527,
      "logits/rejected": -4.0454912185668945,
      "logps/chosen": -136.99061584472656,
      "logps/rejected": -152.0390625,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0977805852890015,
      "rewards/margins": 6.359950542449951,
      "rewards/rejected": -5.26216983795166,
      "step": 2392
    },
    {
      "epoch": 0.9572,
      "grad_norm": 0.13101013004779816,
      "learning_rate": 6.810666666666667e-07,
      "logits/chosen": -2.0070972442626953,
      "logits/rejected": -3.258540391921997,
      "logps/chosen": -172.28497314453125,
      "logps/rejected": -153.56942749023438,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0287857055664062,
      "rewards/margins": 7.6190690994262695,
      "rewards/rejected": -5.590283393859863,
      "step": 2393
    },
    {
      "epoch": 0.9576,
      "grad_norm": 0.3933188021183014,
      "learning_rate": 6.809333333333332e-07,
      "logits/chosen": -2.3300325870513916,
      "logits/rejected": -3.652757406234741,
      "logps/chosen": -133.7714385986328,
      "logps/rejected": -160.1371307373047,
      "loss": 0.0038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0826294422149658,
      "rewards/margins": 7.520334243774414,
      "rewards/rejected": -6.437704563140869,
      "step": 2394
    },
    {
      "epoch": 0.958,
      "grad_norm": 0.053270597010850906,
      "learning_rate": 6.807999999999999e-07,
      "logits/chosen": -1.9626930952072144,
      "logits/rejected": -3.283143997192383,
      "logps/chosen": -131.6033172607422,
      "logps/rejected": -157.14804077148438,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4857888221740723,
      "rewards/margins": 8.084158897399902,
      "rewards/rejected": -4.598370552062988,
      "step": 2395
    },
    {
      "epoch": 0.9584,
      "grad_norm": 0.20396363735198975,
      "learning_rate": 6.806666666666666e-07,
      "logits/chosen": -2.0052266120910645,
      "logits/rejected": -3.2556896209716797,
      "logps/chosen": -80.2047119140625,
      "logps/rejected": -155.59219360351562,
      "loss": 0.0017,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8816421627998352,
      "rewards/margins": 6.4042158126831055,
      "rewards/rejected": -5.522573471069336,
      "step": 2396
    },
    {
      "epoch": 0.9588,
      "grad_norm": 4.668291091918945,
      "learning_rate": 6.805333333333333e-07,
      "logits/chosen": -2.699746608734131,
      "logits/rejected": -3.0657665729522705,
      "logps/chosen": -305.47308349609375,
      "logps/rejected": -179.11688232421875,
      "loss": 0.0268,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.669189453125,
      "rewards/margins": 8.684983253479004,
      "rewards/rejected": -5.015793800354004,
      "step": 2397
    },
    {
      "epoch": 0.9592,
      "grad_norm": 0.6198081970214844,
      "learning_rate": 6.804e-07,
      "logits/chosen": -1.8589850664138794,
      "logits/rejected": -3.4680871963500977,
      "logps/chosen": -117.3913345336914,
      "logps/rejected": -146.72799682617188,
      "loss": 0.0048,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6178321838378906,
      "rewards/margins": 7.374202728271484,
      "rewards/rejected": -5.756370544433594,
      "step": 2398
    },
    {
      "epoch": 0.9596,
      "grad_norm": 3.4394707679748535,
      "learning_rate": 6.802666666666667e-07,
      "logits/chosen": -2.2565255165100098,
      "logits/rejected": -3.2971701622009277,
      "logps/chosen": -191.9730224609375,
      "logps/rejected": -150.94473266601562,
      "loss": 0.0298,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6418877840042114,
      "rewards/margins": 3.696476459503174,
      "rewards/rejected": -5.338364124298096,
      "step": 2399
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.018567072227597237,
      "learning_rate": 6.801333333333334e-07,
      "logits/chosen": -1.85965895652771,
      "logits/rejected": -2.8418922424316406,
      "logps/chosen": -130.97157287597656,
      "logps/rejected": -170.9580841064453,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4422354698181152,
      "rewards/margins": 9.214805603027344,
      "rewards/rejected": -5.772570610046387,
      "step": 2400
    },
    {
      "epoch": 0.9604,
      "grad_norm": 0.1236962303519249,
      "learning_rate": 6.800000000000001e-07,
      "logits/chosen": -2.079214572906494,
      "logits/rejected": -2.204190254211426,
      "logps/chosen": -140.9990234375,
      "logps/rejected": -142.40081787109375,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.097212314605713,
      "rewards/margins": 6.989615440368652,
      "rewards/rejected": -4.8924031257629395,
      "step": 2401
    },
    {
      "epoch": 0.9608,
      "grad_norm": 0.519507884979248,
      "learning_rate": 6.798666666666666e-07,
      "logits/chosen": -2.58539080619812,
      "logits/rejected": -3.3046469688415527,
      "logps/chosen": -187.00868225097656,
      "logps/rejected": -162.73121643066406,
      "loss": 0.0039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.231949806213379,
      "rewards/margins": 7.544915199279785,
      "rewards/rejected": -6.312965393066406,
      "step": 2402
    },
    {
      "epoch": 0.9612,
      "grad_norm": 0.3179403841495514,
      "learning_rate": 6.797333333333332e-07,
      "logits/chosen": -2.4973082542419434,
      "logits/rejected": -2.706052303314209,
      "logps/chosen": -150.4781951904297,
      "logps/rejected": -143.327880859375,
      "loss": 0.002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6289844512939453,
      "rewards/margins": 7.343062877655029,
      "rewards/rejected": -4.714077949523926,
      "step": 2403
    },
    {
      "epoch": 0.9616,
      "grad_norm": 0.6768586039543152,
      "learning_rate": 6.795999999999999e-07,
      "logits/chosen": -2.489100456237793,
      "logits/rejected": -2.6440601348876953,
      "logps/chosen": -124.30152130126953,
      "logps/rejected": -118.38328552246094,
      "loss": 0.0088,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7459724545478821,
      "rewards/margins": 4.962285041809082,
      "rewards/rejected": -4.216312885284424,
      "step": 2404
    },
    {
      "epoch": 0.962,
      "grad_norm": 0.021447833627462387,
      "learning_rate": 6.794666666666666e-07,
      "logits/chosen": -2.25022554397583,
      "logits/rejected": -3.4182140827178955,
      "logps/chosen": -90.1826171875,
      "logps/rejected": -154.05381774902344,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.067562103271484,
      "rewards/margins": 8.528053283691406,
      "rewards/rejected": -4.460490703582764,
      "step": 2405
    },
    {
      "epoch": 0.9624,
      "grad_norm": 0.04817047342658043,
      "learning_rate": 6.793333333333333e-07,
      "logits/chosen": -1.8647089004516602,
      "logits/rejected": -3.298128128051758,
      "logps/chosen": -141.1111602783203,
      "logps/rejected": -143.33062744140625,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2628822326660156,
      "rewards/margins": 7.756003379821777,
      "rewards/rejected": -5.493121147155762,
      "step": 2406
    },
    {
      "epoch": 0.9628,
      "grad_norm": 0.25231462717056274,
      "learning_rate": 6.792e-07,
      "logits/chosen": -2.11626935005188,
      "logits/rejected": -3.391801357269287,
      "logps/chosen": -189.72686767578125,
      "logps/rejected": -213.43228149414062,
      "loss": 0.0019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7712703943252563,
      "rewards/margins": 6.508354663848877,
      "rewards/rejected": -5.73708438873291,
      "step": 2407
    },
    {
      "epoch": 0.9632,
      "grad_norm": 0.013452468439936638,
      "learning_rate": 6.790666666666667e-07,
      "logits/chosen": -2.0110583305358887,
      "logits/rejected": -3.4184985160827637,
      "logps/chosen": -88.52326965332031,
      "logps/rejected": -151.27960205078125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0937938690185547,
      "rewards/margins": 9.196435928344727,
      "rewards/rejected": -6.10264253616333,
      "step": 2408
    },
    {
      "epoch": 0.9636,
      "grad_norm": 0.2639830410480499,
      "learning_rate": 6.789333333333334e-07,
      "logits/chosen": -1.9127440452575684,
      "logits/rejected": -2.917278289794922,
      "logps/chosen": -76.87259674072266,
      "logps/rejected": -164.61819458007812,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.319171905517578,
      "rewards/margins": 7.703283786773682,
      "rewards/rejected": -4.384111404418945,
      "step": 2409
    },
    {
      "epoch": 0.964,
      "grad_norm": 0.06943060457706451,
      "learning_rate": 6.788e-07,
      "logits/chosen": -2.2469799518585205,
      "logits/rejected": -2.8347275257110596,
      "logps/chosen": -164.70245361328125,
      "logps/rejected": -178.1013946533203,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6455674171447754,
      "rewards/margins": 8.952217102050781,
      "rewards/rejected": -6.306650161743164,
      "step": 2410
    },
    {
      "epoch": 0.9644,
      "grad_norm": 0.0034890947863459587,
      "learning_rate": 6.786666666666667e-07,
      "logits/chosen": -2.0865907669067383,
      "logits/rejected": -3.2635140419006348,
      "logps/chosen": -92.63154602050781,
      "logps/rejected": -176.8563995361328,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.621610641479492,
      "rewards/margins": 10.695320129394531,
      "rewards/rejected": -7.073709011077881,
      "step": 2411
    },
    {
      "epoch": 0.9648,
      "grad_norm": 0.45742520689964294,
      "learning_rate": 6.785333333333332e-07,
      "logits/chosen": -2.062798500061035,
      "logits/rejected": -2.343869209289551,
      "logps/chosen": -120.38569641113281,
      "logps/rejected": -133.7017822265625,
      "loss": 0.0056,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7814658880233765,
      "rewards/margins": 5.19826602935791,
      "rewards/rejected": -4.416800022125244,
      "step": 2412
    },
    {
      "epoch": 0.9652,
      "grad_norm": 0.11543433368206024,
      "learning_rate": 6.783999999999999e-07,
      "logits/chosen": -1.966432809829712,
      "logits/rejected": -3.219944953918457,
      "logps/chosen": -113.26493835449219,
      "logps/rejected": -158.6651611328125,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4239907264709473,
      "rewards/margins": 7.612496852874756,
      "rewards/rejected": -6.188506126403809,
      "step": 2413
    },
    {
      "epoch": 0.9656,
      "grad_norm": 0.18241707980632782,
      "learning_rate": 6.782666666666666e-07,
      "logits/chosen": -1.8379865884780884,
      "logits/rejected": -3.1945197582244873,
      "logps/chosen": -91.73988342285156,
      "logps/rejected": -147.00791931152344,
      "loss": 0.0014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4036662578582764,
      "rewards/margins": 7.899055480957031,
      "rewards/rejected": -5.495388984680176,
      "step": 2414
    },
    {
      "epoch": 0.966,
      "grad_norm": 0.08798646181821823,
      "learning_rate": 6.781333333333333e-07,
      "logits/chosen": -2.1209425926208496,
      "logits/rejected": -3.2408385276794434,
      "logps/chosen": -159.22018432617188,
      "logps/rejected": -181.93258666992188,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9253876209259033,
      "rewards/margins": 7.465092658996582,
      "rewards/rejected": -5.539705276489258,
      "step": 2415
    },
    {
      "epoch": 0.9664,
      "grad_norm": 0.274242639541626,
      "learning_rate": 6.78e-07,
      "logits/chosen": -2.543870449066162,
      "logits/rejected": -3.231661796569824,
      "logps/chosen": -137.25259399414062,
      "logps/rejected": -147.4133758544922,
      "loss": 0.0029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4128425121307373,
      "rewards/margins": 5.894830703735352,
      "rewards/rejected": -4.481987953186035,
      "step": 2416
    },
    {
      "epoch": 0.9668,
      "grad_norm": 0.2326928675174713,
      "learning_rate": 6.778666666666666e-07,
      "logits/chosen": -2.0834388732910156,
      "logits/rejected": -3.2038965225219727,
      "logps/chosen": -135.434814453125,
      "logps/rejected": -176.66773986816406,
      "loss": 0.0024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.556025981903076,
      "rewards/margins": 7.771712303161621,
      "rewards/rejected": -5.215686321258545,
      "step": 2417
    },
    {
      "epoch": 0.9672,
      "grad_norm": 0.19469965994358063,
      "learning_rate": 6.777333333333333e-07,
      "logits/chosen": -2.456083297729492,
      "logits/rejected": -3.1106929779052734,
      "logps/chosen": -145.12835693359375,
      "logps/rejected": -224.70294189453125,
      "loss": 0.0016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0865436792373657,
      "rewards/margins": 6.423187255859375,
      "rewards/rejected": -5.336644172668457,
      "step": 2418
    },
    {
      "epoch": 0.9676,
      "grad_norm": 0.013168583624064922,
      "learning_rate": 6.776e-07,
      "logits/chosen": -2.2226388454437256,
      "logits/rejected": -3.451603889465332,
      "logps/chosen": -227.88641357421875,
      "logps/rejected": -177.5902099609375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.3331375122070312,
      "rewards/margins": 8.835451126098633,
      "rewards/rejected": -6.50231409072876,
      "step": 2419
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.09114859998226166,
      "learning_rate": 6.774666666666667e-07,
      "logits/chosen": -2.41616153717041,
      "logits/rejected": -2.3726205825805664,
      "logps/chosen": -127.13070678710938,
      "logps/rejected": -275.1292724609375,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4859390258789062,
      "rewards/margins": 8.09167766571045,
      "rewards/rejected": -6.605738639831543,
      "step": 2420
    },
    {
      "epoch": 0.9684,
      "grad_norm": 0.24863220751285553,
      "learning_rate": 6.773333333333334e-07,
      "logits/chosen": -1.9609966278076172,
      "logits/rejected": -2.771026611328125,
      "logps/chosen": -77.88778686523438,
      "logps/rejected": -137.006591796875,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.2493646144866943,
      "rewards/margins": 6.890672206878662,
      "rewards/rejected": -4.641307353973389,
      "step": 2421
    },
    {
      "epoch": 0.9688,
      "grad_norm": 6.022500038146973,
      "learning_rate": 6.772e-07,
      "logits/chosen": -2.767442226409912,
      "logits/rejected": -3.1213202476501465,
      "logps/chosen": -172.93341064453125,
      "logps/rejected": -218.7270050048828,
      "loss": 0.0365,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.823469638824463,
      "rewards/margins": 6.972712516784668,
      "rewards/rejected": -5.149243354797363,
      "step": 2422
    },
    {
      "epoch": 0.9692,
      "grad_norm": 0.08951817452907562,
      "learning_rate": 6.770666666666666e-07,
      "logits/chosen": -1.9170472621917725,
      "logits/rejected": -3.054141044616699,
      "logps/chosen": -73.3996353149414,
      "logps/rejected": -129.89404296875,
      "loss": 0.0011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4557228088378906,
      "rewards/margins": 7.199824810028076,
      "rewards/rejected": -4.744102478027344,
      "step": 2423
    },
    {
      "epoch": 0.9696,
      "grad_norm": 0.015252277255058289,
      "learning_rate": 6.769333333333333e-07,
      "logits/chosen": -1.9473979473114014,
      "logits/rejected": -3.581678867340088,
      "logps/chosen": -123.02604675292969,
      "logps/rejected": -195.1375274658203,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3590130805969238,
      "rewards/margins": 8.748568534851074,
      "rewards/rejected": -7.389555931091309,
      "step": 2424
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.2251000851392746,
      "learning_rate": 6.767999999999999e-07,
      "logits/chosen": -2.512667179107666,
      "logits/rejected": -3.4901561737060547,
      "logps/chosen": -114.8808364868164,
      "logps/rejected": -156.7425994873047,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3743915557861328,
      "rewards/margins": 7.720644950866699,
      "rewards/rejected": -6.346253395080566,
      "step": 2425
    },
    {
      "epoch": 0.9704,
      "grad_norm": 0.03419334813952446,
      "learning_rate": 6.766666666666666e-07,
      "logits/chosen": -2.193610668182373,
      "logits/rejected": -2.4762368202209473,
      "logps/chosen": -80.76349639892578,
      "logps/rejected": -135.96194458007812,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.201575517654419,
      "rewards/margins": 7.936321258544922,
      "rewards/rejected": -4.734745502471924,
      "step": 2426
    },
    {
      "epoch": 0.9708,
      "grad_norm": 0.02769390679895878,
      "learning_rate": 6.765333333333333e-07,
      "logits/chosen": -1.0781100988388062,
      "logits/rejected": -3.022246837615967,
      "logps/chosen": -67.59384155273438,
      "logps/rejected": -146.55343627929688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1012678146362305,
      "rewards/margins": 9.484664916992188,
      "rewards/rejected": -6.383396625518799,
      "step": 2427
    },
    {
      "epoch": 0.9712,
      "grad_norm": 1.9844050407409668,
      "learning_rate": 6.764e-07,
      "logits/chosen": -2.023028612136841,
      "logits/rejected": -3.1443405151367188,
      "logps/chosen": -92.39889526367188,
      "logps/rejected": -146.80630493164062,
      "loss": 0.0138,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.699832558631897,
      "rewards/margins": 7.292695045471191,
      "rewards/rejected": -5.592862129211426,
      "step": 2428
    },
    {
      "epoch": 0.9716,
      "grad_norm": 0.31076306104660034,
      "learning_rate": 6.762666666666667e-07,
      "logits/chosen": -2.139536142349243,
      "logits/rejected": -3.9035863876342773,
      "logps/chosen": -128.303466796875,
      "logps/rejected": -230.216064453125,
      "loss": 0.0027,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6033870577812195,
      "rewards/margins": 6.133597373962402,
      "rewards/rejected": -5.530210494995117,
      "step": 2429
    },
    {
      "epoch": 0.972,
      "grad_norm": 0.012371832504868507,
      "learning_rate": 6.761333333333334e-07,
      "logits/chosen": -2.52239990234375,
      "logits/rejected": -3.4506468772888184,
      "logps/chosen": -132.41104125976562,
      "logps/rejected": -230.05435180664062,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2497544288635254,
      "rewards/margins": 10.746492385864258,
      "rewards/rejected": -7.496737480163574,
      "step": 2430
    },
    {
      "epoch": 0.9724,
      "grad_norm": 0.1212456226348877,
      "learning_rate": 6.76e-07,
      "logits/chosen": -2.5124924182891846,
      "logits/rejected": -3.0923924446105957,
      "logps/chosen": -129.60467529296875,
      "logps/rejected": -166.6056365966797,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0329155921936035,
      "rewards/margins": 8.543381690979004,
      "rewards/rejected": -6.5104660987854,
      "step": 2431
    },
    {
      "epoch": 0.9728,
      "grad_norm": 0.06410349160432816,
      "learning_rate": 6.758666666666666e-07,
      "logits/chosen": -2.62668514251709,
      "logits/rejected": -3.460207939147949,
      "logps/chosen": -115.0102767944336,
      "logps/rejected": -179.80682373046875,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41908493638038635,
      "rewards/margins": 7.4276533126831055,
      "rewards/rejected": -7.00856876373291,
      "step": 2432
    },
    {
      "epoch": 0.9732,
      "grad_norm": 0.18892261385917664,
      "learning_rate": 6.757333333333332e-07,
      "logits/chosen": -2.0351247787475586,
      "logits/rejected": -2.188474178314209,
      "logps/chosen": -151.34066772460938,
      "logps/rejected": -145.15577697753906,
      "loss": 0.0013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.14254093170166,
      "rewards/margins": 8.695011138916016,
      "rewards/rejected": -4.5524702072143555,
      "step": 2433
    },
    {
      "epoch": 0.9736,
      "grad_norm": 0.043170057237148285,
      "learning_rate": 6.755999999999999e-07,
      "logits/chosen": -2.142224073410034,
      "logits/rejected": -3.375843048095703,
      "logps/chosen": -138.69261169433594,
      "logps/rejected": -169.63858032226562,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.648470640182495,
      "rewards/margins": 8.794515609741211,
      "rewards/rejected": -6.146044731140137,
      "step": 2434
    },
    {
      "epoch": 0.974,
      "grad_norm": 0.5831682682037354,
      "learning_rate": 6.754666666666666e-07,
      "logits/chosen": -2.096130132675171,
      "logits/rejected": -3.1655044555664062,
      "logps/chosen": -98.06452941894531,
      "logps/rejected": -165.64404296875,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3198944330215454,
      "rewards/margins": 6.439128875732422,
      "rewards/rejected": -5.119234561920166,
      "step": 2435
    },
    {
      "epoch": 0.9744,
      "grad_norm": 0.05729619413614273,
      "learning_rate": 6.753333333333333e-07,
      "logits/chosen": -2.282454013824463,
      "logits/rejected": -3.4028258323669434,
      "logps/chosen": -116.29043579101562,
      "logps/rejected": -183.70355224609375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5974221229553223,
      "rewards/margins": 10.192185401916504,
      "rewards/rejected": -6.594763278961182,
      "step": 2436
    },
    {
      "epoch": 0.9748,
      "grad_norm": 0.009055168367922306,
      "learning_rate": 6.752e-07,
      "logits/chosen": -1.8737980127334595,
      "logits/rejected": -3.1832780838012695,
      "logps/chosen": -126.48796844482422,
      "logps/rejected": -161.63031005859375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.5963950157165527,
      "rewards/margins": 9.295040130615234,
      "rewards/rejected": -5.698644638061523,
      "step": 2437
    },
    {
      "epoch": 0.9752,
      "grad_norm": 0.07609070837497711,
      "learning_rate": 6.750666666666667e-07,
      "logits/chosen": -2.4321980476379395,
      "logits/rejected": -2.263784646987915,
      "logps/chosen": -121.73837280273438,
      "logps/rejected": -97.79275512695312,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2467668056488037,
      "rewards/margins": 7.287494659423828,
      "rewards/rejected": -4.040727615356445,
      "step": 2438
    },
    {
      "epoch": 0.9756,
      "grad_norm": 0.013086033053696156,
      "learning_rate": 6.749333333333334e-07,
      "logits/chosen": -2.0482611656188965,
      "logits/rejected": -3.086691379547119,
      "logps/chosen": -72.83871459960938,
      "logps/rejected": -145.607177734375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.1082844734191895,
      "rewards/margins": 9.072748184204102,
      "rewards/rejected": -5.96446418762207,
      "step": 2439
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.03284719958901405,
      "learning_rate": 6.747999999999999e-07,
      "logits/chosen": -2.3504838943481445,
      "logits/rejected": -3.0114951133728027,
      "logps/chosen": -255.9422149658203,
      "logps/rejected": -171.9778594970703,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.708706855773926,
      "rewards/margins": 9.530577659606934,
      "rewards/rejected": -5.821871280670166,
      "step": 2440
    },
    {
      "epoch": 0.9764,
      "grad_norm": 0.12323586642742157,
      "learning_rate": 6.746666666666666e-07,
      "logits/chosen": -2.3168118000030518,
      "logits/rejected": -3.5452611446380615,
      "logps/chosen": -103.78736877441406,
      "logps/rejected": -182.47747802734375,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6314972639083862,
      "rewards/margins": 8.982792854309082,
      "rewards/rejected": -7.351295471191406,
      "step": 2441
    },
    {
      "epoch": 0.9768,
      "grad_norm": 0.6893246173858643,
      "learning_rate": 6.745333333333333e-07,
      "logits/chosen": -2.2159459590911865,
      "logits/rejected": -3.1890742778778076,
      "logps/chosen": -118.4804458618164,
      "logps/rejected": -158.45037841796875,
      "loss": 0.0069,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.263789415359497,
      "rewards/margins": 7.977354049682617,
      "rewards/rejected": -5.713564395904541,
      "step": 2442
    },
    {
      "epoch": 0.9772,
      "grad_norm": 0.006151850800961256,
      "learning_rate": 6.744e-07,
      "logits/chosen": -2.1447484493255615,
      "logits/rejected": -3.398897409439087,
      "logps/chosen": -114.53450012207031,
      "logps/rejected": -189.947021484375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.71630597114563,
      "rewards/margins": 11.248541831970215,
      "rewards/rejected": -7.532235622406006,
      "step": 2443
    },
    {
      "epoch": 0.9776,
      "grad_norm": 0.029385564848780632,
      "learning_rate": 6.742666666666666e-07,
      "logits/chosen": -1.8183534145355225,
      "logits/rejected": -2.954193115234375,
      "logps/chosen": -95.25540161132812,
      "logps/rejected": -134.40994262695312,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0731639862060547,
      "rewards/margins": 9.06734848022461,
      "rewards/rejected": -5.994183540344238,
      "step": 2444
    },
    {
      "epoch": 0.978,
      "grad_norm": 3.5697808265686035,
      "learning_rate": 6.741333333333333e-07,
      "logits/chosen": -2.2573652267456055,
      "logits/rejected": -1.701620101928711,
      "logps/chosen": -75.78791046142578,
      "logps/rejected": -92.14817810058594,
      "loss": 0.0252,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7571738958358765,
      "rewards/margins": 3.781644105911255,
      "rewards/rejected": -3.024470329284668,
      "step": 2445
    },
    {
      "epoch": 0.9784,
      "grad_norm": 0.03050611913204193,
      "learning_rate": 6.74e-07,
      "logits/chosen": -2.2808332443237305,
      "logits/rejected": -3.2666168212890625,
      "logps/chosen": -103.1859359741211,
      "logps/rejected": -194.6287384033203,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.4292995929718018,
      "rewards/margins": 10.073003768920898,
      "rewards/rejected": -7.643703460693359,
      "step": 2446
    },
    {
      "epoch": 0.9788,
      "grad_norm": 1.6971720457077026,
      "learning_rate": 6.738666666666666e-07,
      "logits/chosen": -2.1365866661071777,
      "logits/rejected": -3.2469887733459473,
      "logps/chosen": -204.05609130859375,
      "logps/rejected": -152.1359405517578,
      "loss": 0.0123,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8726978302001953,
      "rewards/margins": 4.611795902252197,
      "rewards/rejected": -5.484493732452393,
      "step": 2447
    },
    {
      "epoch": 0.9792,
      "grad_norm": 0.002539793262258172,
      "learning_rate": 6.737333333333333e-07,
      "logits/chosen": -1.6841034889221191,
      "logits/rejected": -2.9511916637420654,
      "logps/chosen": -112.71601867675781,
      "logps/rejected": -193.04437255859375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.858489990234375,
      "rewards/margins": 10.509930610656738,
      "rewards/rejected": -6.651440620422363,
      "step": 2448
    },
    {
      "epoch": 0.9796,
      "grad_norm": 0.2701537311077118,
      "learning_rate": 6.736e-07,
      "logits/chosen": -2.714938163757324,
      "logits/rejected": -3.799914598464966,
      "logps/chosen": -187.93775939941406,
      "logps/rejected": -148.96591186523438,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.126990556716919,
      "rewards/margins": 6.616497993469238,
      "rewards/rejected": -4.48950719833374,
      "step": 2449
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.10035336017608643,
      "learning_rate": 6.734666666666666e-07,
      "logits/chosen": -2.4262075424194336,
      "logits/rejected": -3.585933208465576,
      "logps/chosen": -89.4835433959961,
      "logps/rejected": -176.91697692871094,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8138431310653687,
      "rewards/margins": 7.84294319152832,
      "rewards/rejected": -7.029099941253662,
      "step": 2450
    },
    {
      "epoch": 0.9804,
      "grad_norm": 0.07237432152032852,
      "learning_rate": 6.733333333333333e-07,
      "logits/chosen": -2.2077956199645996,
      "logits/rejected": -2.482342004776001,
      "logps/chosen": -87.63755798339844,
      "logps/rejected": -161.1732940673828,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.400038957595825,
      "rewards/margins": 7.369512557983398,
      "rewards/rejected": -4.969473361968994,
      "step": 2451
    },
    {
      "epoch": 0.9808,
      "grad_norm": 0.02800922468304634,
      "learning_rate": 6.732e-07,
      "logits/chosen": -2.4422693252563477,
      "logits/rejected": -3.375227928161621,
      "logps/chosen": -104.15269470214844,
      "logps/rejected": -162.38095092773438,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.098569393157959,
      "rewards/margins": 9.166324615478516,
      "rewards/rejected": -6.067754745483398,
      "step": 2452
    },
    {
      "epoch": 0.9812,
      "grad_norm": 0.024901872500777245,
      "learning_rate": 6.730666666666667e-07,
      "logits/chosen": -2.297358989715576,
      "logits/rejected": -2.9814391136169434,
      "logps/chosen": -131.3067626953125,
      "logps/rejected": -169.55845642089844,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4945478439331055,
      "rewards/margins": 9.322697639465332,
      "rewards/rejected": -5.828149795532227,
      "step": 2453
    },
    {
      "epoch": 0.9816,
      "grad_norm": 0.03239677846431732,
      "learning_rate": 6.729333333333334e-07,
      "logits/chosen": -2.599982738494873,
      "logits/rejected": -3.1375460624694824,
      "logps/chosen": -148.2010955810547,
      "logps/rejected": -161.04922485351562,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8368301391601562,
      "rewards/margins": 8.030135154724121,
      "rewards/rejected": -6.193305015563965,
      "step": 2454
    },
    {
      "epoch": 0.982,
      "grad_norm": 0.5808476209640503,
      "learning_rate": 6.727999999999999e-07,
      "logits/chosen": -2.0775139331817627,
      "logits/rejected": -2.9377408027648926,
      "logps/chosen": -99.67997741699219,
      "logps/rejected": -118.80075073242188,
      "loss": 0.0054,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10413970798254013,
      "rewards/margins": 5.322667121887207,
      "rewards/rejected": -5.426806926727295,
      "step": 2455
    },
    {
      "epoch": 0.9824,
      "grad_norm": 0.028073599562048912,
      "learning_rate": 6.726666666666666e-07,
      "logits/chosen": -1.9779900312423706,
      "logits/rejected": -2.649420738220215,
      "logps/chosen": -56.740196228027344,
      "logps/rejected": -122.7352523803711,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.4308063983917236,
      "rewards/margins": 8.219430923461914,
      "rewards/rejected": -4.7886247634887695,
      "step": 2456
    },
    {
      "epoch": 0.9828,
      "grad_norm": 0.012621201574802399,
      "learning_rate": 6.725333333333333e-07,
      "logits/chosen": -2.1714706420898438,
      "logits/rejected": -3.0340285301208496,
      "logps/chosen": -124.02631378173828,
      "logps/rejected": -164.297119140625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.3578362464904785,
      "rewards/margins": 9.234312057495117,
      "rewards/rejected": -5.8764753341674805,
      "step": 2457
    },
    {
      "epoch": 0.9832,
      "grad_norm": 0.0905657559633255,
      "learning_rate": 6.724e-07,
      "logits/chosen": -2.3220484256744385,
      "logits/rejected": -3.2714245319366455,
      "logps/chosen": -119.07488250732422,
      "logps/rejected": -162.47958374023438,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5802810192108154,
      "rewards/margins": 7.173504829406738,
      "rewards/rejected": -5.593223571777344,
      "step": 2458
    },
    {
      "epoch": 0.9836,
      "grad_norm": 0.023557420819997787,
      "learning_rate": 6.722666666666666e-07,
      "logits/chosen": -2.2090773582458496,
      "logits/rejected": -3.6974563598632812,
      "logps/chosen": -116.41645812988281,
      "logps/rejected": -202.97149658203125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5536510944366455,
      "rewards/margins": 10.711511611938477,
      "rewards/rejected": -8.157859802246094,
      "step": 2459
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.011766921728849411,
      "learning_rate": 6.721333333333333e-07,
      "logits/chosen": -2.174020767211914,
      "logits/rejected": -2.956752061843872,
      "logps/chosen": -152.3623046875,
      "logps/rejected": -175.13888549804688,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.431854248046875,
      "rewards/margins": 10.225088119506836,
      "rewards/rejected": -6.793233871459961,
      "step": 2460
    },
    {
      "epoch": 0.9844,
      "grad_norm": 0.006245819851756096,
      "learning_rate": 6.72e-07,
      "logits/chosen": -2.51430082321167,
      "logits/rejected": -3.202305793762207,
      "logps/chosen": -101.75971221923828,
      "logps/rejected": -159.67059326171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 4.9489216804504395,
      "rewards/margins": 11.547765731811523,
      "rewards/rejected": -6.598843574523926,
      "step": 2461
    },
    {
      "epoch": 0.9848,
      "grad_norm": 3.512901782989502,
      "learning_rate": 6.718666666666666e-07,
      "logits/chosen": -2.8689379692077637,
      "logits/rejected": -2.8597664833068848,
      "logps/chosen": -143.76913452148438,
      "logps/rejected": -120.24799346923828,
      "loss": 0.0288,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2598133087158203,
      "rewards/margins": 4.725205421447754,
      "rewards/rejected": -4.465392112731934,
      "step": 2462
    },
    {
      "epoch": 0.9852,
      "grad_norm": 0.013064293190836906,
      "learning_rate": 6.717333333333333e-07,
      "logits/chosen": -2.1835174560546875,
      "logits/rejected": -3.5520334243774414,
      "logps/chosen": -91.89543914794922,
      "logps/rejected": -150.47488403320312,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.7366554737091064,
      "rewards/margins": 9.52149772644043,
      "rewards/rejected": -6.784842491149902,
      "step": 2463
    },
    {
      "epoch": 0.9856,
      "grad_norm": 0.038706012070178986,
      "learning_rate": 6.716e-07,
      "logits/chosen": -2.3774185180664062,
      "logits/rejected": -2.3325343132019043,
      "logps/chosen": -184.0659942626953,
      "logps/rejected": -188.4684600830078,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9805443286895752,
      "rewards/margins": 8.987443923950195,
      "rewards/rejected": -7.006899833679199,
      "step": 2464
    },
    {
      "epoch": 0.986,
      "grad_norm": 5.2928924560546875,
      "learning_rate": 6.714666666666666e-07,
      "logits/chosen": -2.8231399059295654,
      "logits/rejected": -3.552203893661499,
      "logps/chosen": -187.52841186523438,
      "logps/rejected": -183.1795196533203,
      "loss": 0.0538,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9483470320701599,
      "rewards/margins": 7.634283542633057,
      "rewards/rejected": -6.685936450958252,
      "step": 2465
    },
    {
      "epoch": 0.9864,
      "grad_norm": 0.10201310366392136,
      "learning_rate": 6.713333333333333e-07,
      "logits/chosen": -1.8374890089035034,
      "logits/rejected": -2.2376577854156494,
      "logps/chosen": -83.17758178710938,
      "logps/rejected": -145.98580932617188,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8229660987854004,
      "rewards/margins": 7.8887176513671875,
      "rewards/rejected": -6.065752029418945,
      "step": 2466
    },
    {
      "epoch": 0.9868,
      "grad_norm": 0.49804985523223877,
      "learning_rate": 6.712e-07,
      "logits/chosen": -1.970914602279663,
      "logits/rejected": -3.0552477836608887,
      "logps/chosen": -123.90544891357422,
      "logps/rejected": -151.51901245117188,
      "loss": 0.0041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2662948668003082,
      "rewards/margins": 5.8995819091796875,
      "rewards/rejected": -5.633286476135254,
      "step": 2467
    },
    {
      "epoch": 0.9872,
      "grad_norm": 0.047442130744457245,
      "learning_rate": 6.710666666666667e-07,
      "logits/chosen": -1.833053708076477,
      "logits/rejected": -3.803363800048828,
      "logps/chosen": -90.03251647949219,
      "logps/rejected": -154.33595275878906,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.990630626678467,
      "rewards/margins": 8.121515274047852,
      "rewards/rejected": -5.130884170532227,
      "step": 2468
    },
    {
      "epoch": 0.9876,
      "grad_norm": 0.03907668590545654,
      "learning_rate": 6.709333333333333e-07,
      "logits/chosen": -1.9989287853240967,
      "logits/rejected": -3.194218635559082,
      "logps/chosen": -103.9942855834961,
      "logps/rejected": -134.38201904296875,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.86750864982605,
      "rewards/margins": 7.722904205322266,
      "rewards/rejected": -4.855395317077637,
      "step": 2469
    },
    {
      "epoch": 0.988,
      "grad_norm": 0.09171795099973679,
      "learning_rate": 6.707999999999999e-07,
      "logits/chosen": -2.40071177482605,
      "logits/rejected": -3.1451852321624756,
      "logps/chosen": -172.0655059814453,
      "logps/rejected": -151.9994354248047,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.0352578163146973,
      "rewards/margins": 6.971808433532715,
      "rewards/rejected": -4.936550617218018,
      "step": 2470
    },
    {
      "epoch": 0.9884,
      "grad_norm": 0.9570237398147583,
      "learning_rate": 6.706666666666666e-07,
      "logits/chosen": -2.5484366416931152,
      "logits/rejected": -2.951221227645874,
      "logps/chosen": -159.88589477539062,
      "logps/rejected": -133.04837036132812,
      "loss": 0.0068,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2617745399475098,
      "rewards/margins": 6.107575416564941,
      "rewards/rejected": -4.845800876617432,
      "step": 2471
    },
    {
      "epoch": 0.9888,
      "grad_norm": 0.024143503978848457,
      "learning_rate": 6.705333333333333e-07,
      "logits/chosen": -2.5499634742736816,
      "logits/rejected": -2.8609182834625244,
      "logps/chosen": -129.40289306640625,
      "logps/rejected": -135.95755004882812,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.976752758026123,
      "rewards/margins": 8.4959716796875,
      "rewards/rejected": -5.519219398498535,
      "step": 2472
    },
    {
      "epoch": 0.9892,
      "grad_norm": 0.027069197967648506,
      "learning_rate": 6.704e-07,
      "logits/chosen": -2.411520481109619,
      "logits/rejected": -3.4319748878479004,
      "logps/chosen": -203.41583251953125,
      "logps/rejected": -170.0001220703125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7504875659942627,
      "rewards/margins": 8.33277702331543,
      "rewards/rejected": -6.582289695739746,
      "step": 2473
    },
    {
      "epoch": 0.9896,
      "grad_norm": 0.2765357792377472,
      "learning_rate": 6.702666666666667e-07,
      "logits/chosen": -2.2582054138183594,
      "logits/rejected": -2.6956746578216553,
      "logps/chosen": -112.72303771972656,
      "logps/rejected": -169.3943634033203,
      "loss": 0.0031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7173935174942017,
      "rewards/margins": 6.1100921630859375,
      "rewards/rejected": -4.392698287963867,
      "step": 2474
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.07640150189399719,
      "learning_rate": 6.701333333333334e-07,
      "logits/chosen": -1.5364471673965454,
      "logits/rejected": -3.4714550971984863,
      "logps/chosen": -96.09439086914062,
      "logps/rejected": -178.2381591796875,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.6258902549743652,
      "rewards/margins": 8.153518676757812,
      "rewards/rejected": -5.527627944946289,
      "step": 2475
    },
    {
      "epoch": 0.9904,
      "grad_norm": 0.008666574023663998,
      "learning_rate": 6.7e-07,
      "logits/chosen": -2.081155776977539,
      "logits/rejected": -3.737943649291992,
      "logps/chosen": -91.977294921875,
      "logps/rejected": -199.77005004882812,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.8401333093643188,
      "rewards/margins": 9.87696647644043,
      "rewards/rejected": -8.036833763122559,
      "step": 2476
    },
    {
      "epoch": 0.9908,
      "grad_norm": 0.07155263423919678,
      "learning_rate": 6.698666666666667e-07,
      "logits/chosen": -2.599194049835205,
      "logits/rejected": -3.581313133239746,
      "logps/chosen": -257.4053955078125,
      "logps/rejected": -186.53346252441406,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0452585220336914,
      "rewards/margins": 8.964426040649414,
      "rewards/rejected": -5.919167995452881,
      "step": 2477
    },
    {
      "epoch": 0.9912,
      "grad_norm": 0.10666058212518692,
      "learning_rate": 6.697333333333332e-07,
      "logits/chosen": -2.1723883152008057,
      "logits/rejected": -2.995838165283203,
      "logps/chosen": -74.339111328125,
      "logps/rejected": -156.4680938720703,
      "loss": 0.001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9868459701538086,
      "rewards/margins": 9.596927642822266,
      "rewards/rejected": -6.610081672668457,
      "step": 2478
    },
    {
      "epoch": 0.9916,
      "grad_norm": 4.465003490447998,
      "learning_rate": 6.695999999999999e-07,
      "logits/chosen": -2.086552858352661,
      "logits/rejected": -3.2069194316864014,
      "logps/chosen": -162.1966552734375,
      "logps/rejected": -136.33428955078125,
      "loss": 0.029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.540249228477478,
      "rewards/margins": 5.3969316482543945,
      "rewards/rejected": -4.856682300567627,
      "step": 2479
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.5999085307121277,
      "learning_rate": 6.694666666666666e-07,
      "logits/chosen": -1.9590885639190674,
      "logits/rejected": -2.9936065673828125,
      "logps/chosen": -137.19430541992188,
      "logps/rejected": -148.75198364257812,
      "loss": 0.0063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13107873499393463,
      "rewards/margins": 5.0568318367004395,
      "rewards/rejected": -4.925753116607666,
      "step": 2480
    },
    {
      "epoch": 0.9924,
      "grad_norm": 0.052766431123018265,
      "learning_rate": 6.693333333333333e-07,
      "logits/chosen": -2.2190113067626953,
      "logits/rejected": -3.440110445022583,
      "logps/chosen": -85.68428802490234,
      "logps/rejected": -158.508056640625,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0900352001190186,
      "rewards/margins": 7.781811237335205,
      "rewards/rejected": -6.691776275634766,
      "step": 2481
    },
    {
      "epoch": 0.9928,
      "grad_norm": 0.0270058736205101,
      "learning_rate": 6.692e-07,
      "logits/chosen": -2.1238465309143066,
      "logits/rejected": -2.9680802822113037,
      "logps/chosen": -117.53772735595703,
      "logps/rejected": -144.11195373535156,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0631821155548096,
      "rewards/margins": 8.550854682922363,
      "rewards/rejected": -5.487672805786133,
      "step": 2482
    },
    {
      "epoch": 0.9932,
      "grad_norm": 0.016955552622675896,
      "learning_rate": 6.690666666666667e-07,
      "logits/chosen": -2.2148666381835938,
      "logits/rejected": -3.693223476409912,
      "logps/chosen": -166.69451904296875,
      "logps/rejected": -163.84603881835938,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.2115187644958496,
      "rewards/margins": 9.387115478515625,
      "rewards/rejected": -6.175596237182617,
      "step": 2483
    },
    {
      "epoch": 0.9936,
      "grad_norm": 0.31934043765068054,
      "learning_rate": 6.689333333333334e-07,
      "logits/chosen": -2.7220568656921387,
      "logits/rejected": -3.163228988647461,
      "logps/chosen": -214.286865234375,
      "logps/rejected": -189.57034301757812,
      "loss": 0.0021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.28421247005462646,
      "rewards/margins": 6.283362865447998,
      "rewards/rejected": -5.999150276184082,
      "step": 2484
    },
    {
      "epoch": 0.994,
      "grad_norm": 0.5120264887809753,
      "learning_rate": 6.688e-07,
      "logits/chosen": -1.7213916778564453,
      "logits/rejected": -2.8843846321105957,
      "logps/chosen": -92.7246322631836,
      "logps/rejected": -124.67950439453125,
      "loss": 0.0046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4968101680278778,
      "rewards/margins": 5.443709373474121,
      "rewards/rejected": -4.946898937225342,
      "step": 2485
    },
    {
      "epoch": 0.9944,
      "grad_norm": 0.08521057665348053,
      "learning_rate": 6.686666666666666e-07,
      "logits/chosen": -2.1211276054382324,
      "logits/rejected": -3.5484025478363037,
      "logps/chosen": -171.20875549316406,
      "logps/rejected": -232.18408203125,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4804775714874268,
      "rewards/margins": 7.489754676818848,
      "rewards/rejected": -6.00927734375,
      "step": 2486
    },
    {
      "epoch": 0.9948,
      "grad_norm": 0.006912141107022762,
      "learning_rate": 6.685333333333332e-07,
      "logits/chosen": -2.336595296859741,
      "logits/rejected": -3.7494945526123047,
      "logps/chosen": -102.6041259765625,
      "logps/rejected": -161.07330322265625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.536099433898926,
      "rewards/margins": 9.84878921508789,
      "rewards/rejected": -6.312690258026123,
      "step": 2487
    },
    {
      "epoch": 0.9952,
      "grad_norm": 3.1024630069732666,
      "learning_rate": 6.683999999999999e-07,
      "logits/chosen": -2.3239963054656982,
      "logits/rejected": -3.2169322967529297,
      "logps/chosen": -103.82768249511719,
      "logps/rejected": -130.49057006835938,
      "loss": 0.0207,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7294437885284424,
      "rewards/margins": 5.470015048980713,
      "rewards/rejected": -4.740571022033691,
      "step": 2488
    },
    {
      "epoch": 0.9956,
      "grad_norm": 0.03228077292442322,
      "learning_rate": 6.682666666666666e-07,
      "logits/chosen": -2.4571733474731445,
      "logits/rejected": -3.4055397510528564,
      "logps/chosen": -136.10252380371094,
      "logps/rejected": -151.72329711914062,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.9417343139648438,
      "rewards/margins": 8.655094146728516,
      "rewards/rejected": -5.713359832763672,
      "step": 2489
    },
    {
      "epoch": 0.996,
      "grad_norm": 0.4400515854358673,
      "learning_rate": 6.681333333333333e-07,
      "logits/chosen": -2.1892788410186768,
      "logits/rejected": -3.083662986755371,
      "logps/chosen": -129.42002868652344,
      "logps/rejected": -148.00238037109375,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.212958335876465,
      "rewards/margins": 7.828629493713379,
      "rewards/rejected": -5.615671157836914,
      "step": 2490
    },
    {
      "epoch": 0.9964,
      "grad_norm": 0.14044170081615448,
      "learning_rate": 6.68e-07,
      "logits/chosen": -1.9654240608215332,
      "logits/rejected": -3.0183990001678467,
      "logps/chosen": -197.0392303466797,
      "logps/rejected": -188.41102600097656,
      "loss": 0.0008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2558128833770752,
      "rewards/margins": 8.105728149414062,
      "rewards/rejected": -6.849915504455566,
      "step": 2491
    },
    {
      "epoch": 0.9968,
      "grad_norm": 0.09359949082136154,
      "learning_rate": 6.678666666666667e-07,
      "logits/chosen": -1.9791219234466553,
      "logits/rejected": -3.563105821609497,
      "logps/chosen": -181.2046356201172,
      "logps/rejected": -215.45628356933594,
      "loss": 0.0006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7609764337539673,
      "rewards/margins": 8.773494720458984,
      "rewards/rejected": -7.012517929077148,
      "step": 2492
    },
    {
      "epoch": 0.9972,
      "grad_norm": 0.1322631537914276,
      "learning_rate": 6.677333333333333e-07,
      "logits/chosen": -2.799485921859741,
      "logits/rejected": -3.7329983711242676,
      "logps/chosen": -170.7764434814453,
      "logps/rejected": -172.05001831054688,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7674610614776611,
      "rewards/margins": 8.056758880615234,
      "rewards/rejected": -6.289297580718994,
      "step": 2493
    },
    {
      "epoch": 0.9976,
      "grad_norm": 0.01508705411106348,
      "learning_rate": 6.676e-07,
      "logits/chosen": -2.621196746826172,
      "logits/rejected": -3.0014548301696777,
      "logps/chosen": -216.976806640625,
      "logps/rejected": -174.50289916992188,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.9055267572402954,
      "rewards/margins": 8.859487533569336,
      "rewards/rejected": -6.953960418701172,
      "step": 2494
    },
    {
      "epoch": 0.998,
      "grad_norm": 1.2673242092132568,
      "learning_rate": 6.674666666666667e-07,
      "logits/chosen": -2.1130213737487793,
      "logits/rejected": -3.327197790145874,
      "logps/chosen": -170.823486328125,
      "logps/rejected": -164.14389038085938,
      "loss": 0.0092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0187180042266846,
      "rewards/margins": 5.470829963684082,
      "rewards/rejected": -6.4895477294921875,
      "step": 2495
    },
    {
      "epoch": 0.9984,
      "grad_norm": 0.013889714144170284,
      "learning_rate": 6.673333333333334e-07,
      "logits/chosen": -2.5233986377716064,
      "logits/rejected": -3.159823417663574,
      "logps/chosen": -171.2169189453125,
      "logps/rejected": -222.2137908935547,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.806537628173828,
      "rewards/margins": 8.971294403076172,
      "rewards/rejected": -6.1647562980651855,
      "step": 2496
    },
    {
      "epoch": 0.9988,
      "grad_norm": 0.01993376947939396,
      "learning_rate": 6.671999999999999e-07,
      "logits/chosen": -2.5449533462524414,
      "logits/rejected": -3.512787103652954,
      "logps/chosen": -105.66290283203125,
      "logps/rejected": -177.05685424804688,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4066848754882812,
      "rewards/margins": 9.472274780273438,
      "rewards/rejected": -8.065589904785156,
      "step": 2497
    },
    {
      "epoch": 0.9992,
      "grad_norm": 0.015499427914619446,
      "learning_rate": 6.670666666666666e-07,
      "logits/chosen": -1.9723724126815796,
      "logits/rejected": -2.892199993133545,
      "logps/chosen": -94.98654174804688,
      "logps/rejected": -139.15249633789062,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.600850820541382,
      "rewards/margins": 8.73945426940918,
      "rewards/rejected": -6.138603687286377,
      "step": 2498
    },
    {
      "epoch": 0.9996,
      "grad_norm": 0.04427120462059975,
      "learning_rate": 6.669333333333333e-07,
      "logits/chosen": -2.613521099090576,
      "logits/rejected": -2.776344060897827,
      "logps/chosen": -114.50736999511719,
      "logps/rejected": -180.61416625976562,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 2.5030791759490967,
      "rewards/margins": 8.6430082321167,
      "rewards/rejected": -6.139928817749023,
      "step": 2499
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.01242956891655922,
      "learning_rate": 6.667999999999999e-07,
      "logits/chosen": -2.467849016189575,
      "logits/rejected": -3.389840602874756,
      "logps/chosen": -116.36892700195312,
      "logps/rejected": -181.22845458984375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 3.0802013874053955,
      "rewards/margins": 10.442777633666992,
      "rewards/rejected": -7.362576484680176,
      "step": 2500
    }
  ],
  "logging_steps": 1,
  "max_steps": 7500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
